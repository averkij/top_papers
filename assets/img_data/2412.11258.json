[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x1.png",
                "caption": "Figure 1:GaussianPropertyis a training-free framework, aiming at adding physical properties to 3D Gaussians with the assistance of LMMs. By assigning physical properties to 3D Gaussians, it promotes several downstream tasks such as physical-based generative dynamics and robot grasping in this work.",
                "position": 121
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x2.png",
                "caption": "Figure 2:Overall pipeline. Our Gausssian-Property initially leverages SAM to get the segmentation map of the object. Then the original images and the masks are sent to the foundation\nmodels like GPT-4V(ision) to get the corresponding physical properties by inquiring the material candidates. After acquiring physical properties from 2D images, we using a multi-view approach and a voting strategy to add physical properties to the reconstruction 3D Gaussians.",
                "position": 211
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x3.png",
                "caption": "Figure 3:Left: GPT-4V(ision) struggles to recognize the material when directly provided with both global and partial image inputs.Right: Enhanced with combined global-local information and association, the agent accurately characterizes the component’s properties.",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x4.png",
                "caption": "Figure 4:Qualitative results of Material Segmentation. Our model makes boundary-accurate physical material predictions.",
                "position": 456
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x5.png",
                "caption": "Figure 5:Generative Dynamics. We present a potential downstream task of 3D Gaussians with physical property, i.e., the generative dynamics. By imposing force, the 3D Gaussians generate corresponding motion. For example, in the first row, we applied a top-down force, the chair exhibited a movement corresponding to the applied force.",
                "position": 533
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x6.png",
                "caption": "Figure 6:Robot Graspingis a downstream application ofGaussianProperty. Several sample cases from robot grasping experiments are presented, where we compare our proposed method (right) against three baselines (middle columns), starting from initial configurations (left).",
                "position": 543
            }
        ]
    },
    {
        "header": "5Conclusion and Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADerivation of Grasping Force",
        "images": []
    },
    {
        "header": "Appendix BRobot Grasping Experiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/extracted/6070877/figures/jsr1_robot_platform_rmlogo.png",
                "caption": "Figure 7:The\nrobot platform (left) and the \nrobotic gripper\n(right) \nutilized in robot grasping experiments.",
                "position": 1336
            },
            {
                "img": "https://arxiv.org/html/2412.11258/extracted/6070877/figures/robot_gripper.jpg",
                "caption": "",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x7.png",
                "caption": "Figure 8:Calibration curve of robotic gripper grasping force (left) and its 5th-order polynomial smoothings (middle and right).",
                "position": 1354
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x8.png",
                "caption": "Figure 9:List of selected objects for robot grasping experiments.",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x9.png",
                "caption": "Figure 10:Complete robot grasping experiment results.The 16 test cases along with results in robot grasping experiments are listed. We compare our proposed method (right) against three baselines (middle columns), starting from initial configurations (left).You can view the MP4 videos of the experiments in our project page.",
                "position": 1372
            }
        ]
    },
    {
        "header": "Appendix CMore Results of Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x10.png",
                "caption": "Figure 11:Qualitative comparison of hardness prediction. Compared to NeRF2Physics, our method provides more accurate hardness prediction with clear boundaries.",
                "position": 1487
            }
        ]
    },
    {
        "header": "Appendix DAdditional details of Our Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x11.png",
                "caption": "Figure 12:Segmentation process using SAM at different levelsof granularity. From left to right: the input image, large-level segmentation, middle-level segmentation, and small-level segmentation. For our model, we selected the middle-level of SAM prediction to balance part-level object understanding and computational efficiency.",
                "position": 1548
            }
        ]
    },
    {
        "header": "Appendix EDetail of Data Labeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x12.png",
                "caption": "Figure 13:Examples of data labeling. These objects are sourced from the ABO-500 dataset.",
                "position": 1559
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x13.png",
                "caption": "Figure 14:Prompt used for proposing materials and other physical properties.",
                "position": 1568
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x14.png",
                "caption": "Figure 15:Effects of Frequency-based Voting Strategy. We provide an example to demonstrate the effectiveness of the frequency-based voting strategy. The result misclassified the “aluminum” and “wood” into “plastic” and “’steel’ without voting strategy.",
                "position": 1578
            }
        ]
    },
    {
        "header": "Appendix FMore qualitative results of Material Segmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11258/x15.png",
                "caption": "Figure 16:Qualitative comparison of Material Segmentation. These objects are sourced from the ABO-500 dataset.",
                "position": 1589
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x16.png",
                "caption": "Figure 17:Qualitative results of object material segmentationon MVImgNet. Our model makes reasonable and boundary-accurate material predictions for objects with multiple or single materials.",
                "position": 1592
            },
            {
                "img": "https://arxiv.org/html/2412.11258/x17.png",
                "caption": "Figure 18:Examples of Challenging Material Segmentation Cases. These objects are sourced from the ABO-500 dataset.",
                "position": 1602
            }
        ]
    },
    {
        "header": "Appendix GFailure cases",
        "images": []
    }
]