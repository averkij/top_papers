[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x1.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x2.png",
                "caption": "Figure 2:Illustration of overfitting issues in text-to-image generation, where the model tends to follow dominant colors or patterns from the style image rather than aligning precisely with the text prompt. Each prompt follows the format “A<<<color>>><<<object>>>.” From top to bottom, the objects are: bear, apple, frog, and car.",
                "position": 103
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x3.png",
                "caption": "Figure 3:Illustration of the checkerboard artifact encountered in the CSGO[36]method during inference. The leftmost column shows the results generated by SDXL[22]. The prompts, from top to bottom, are “A red apple” and “A pink cup.” All generated results use the same initial noise latent.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x4.png",
                "caption": "Figure 4:Visualization of the Cross-Attention Map for the word “apple” in the prompt “A red apple” during the generation process. When artifacts appear, the attention tends to scatter as well.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x5.png",
                "caption": "Figure 5:The illustration of our proposed cross-modal AdaIN.",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x6.png",
                "caption": "Figure 6:Pipeline for Layout Stabilization in Text-Driven Style Transfer Using a Teacher Model.\nDuring the denoising generation process, the Teacher Model (e.g., SDXL[22]) ensures layout stability, guiding the style transfer model to preserve the structure while applying the desired stylistic transformation.",
                "position": 297
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x7.png",
                "caption": "Figure 7:Qualitative comparison with state-of-the-art methods. Our approach effectively preserves image style while accurately adhering to text prompts for generation.",
                "position": 422
            }
        ]
    },
    {
        "header": "4Evaluation and Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x8.png",
                "caption": "Figure 8:Impact of Style-Based CFG. From left to right, the prompts are: “A car glides along a street lined with trees shedding their colorful, orange and red leaves”, “A car drives down a sunny street”, “A cat”, and “A blue car”. The proposed Style-Based CFG successfully eliminates unintended style elements such as “snow” and “golden leaves”, while text-based CFG fails to address these spurious attributes.",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x9.png",
                "caption": "Figure 9:Visualization of cross-attention maps for the word “apple” in the prompt “A red apple” across different models. The proposed teacher model effectively rectifies attention maps, leading to improved image generation quality.",
                "position": 606
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x10.png",
                "caption": "Figure 10:Impact of Teacher Model on Style Image Generation. The term “timestep” refers to the number of denoising steps during which the teacher model is involved.",
                "position": 609
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BEvaluation Settings and User Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x11.png",
                "caption": "Figure 11:Details of the Test Set. The prompts used in the quantitative experiments were derived from StyleAdapter[34].",
                "position": 1184
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x12.png",
                "caption": "Figure 12:Details of the Test Set. The style images used in the quantitative experiments were randomly sampled from the test set of StyleShot[9].",
                "position": 1187
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x13.png",
                "caption": "Figure 13:The questionnaire format for the user study. Each option represents the generation result of a method under a given style and prompt.",
                "position": 1193
            }
        ]
    },
    {
        "header": "Appendix CAdditional Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/",
                "caption": "Figure 14:Qualitative results of the ablation study. cross-modal AdaIN enhances text alignment while preserving style similarity, addressing style overfitting issues. Incorporating the Teacher Model improves layout stability and resolves artifacts, ensuring consistent layout arrangements across different styles, as demonstrated in the “A green apple” example.",
                "position": 1204
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x15.png",
                "caption": "Figure 15:Implementation of the Teacher Model: Comparison of substituting the Self-Attention Map and Cross-Attention Map. The results demonstrate that replacing the Self-Attention Map achieves layout stability and consistency across different styles of images.",
                "position": 1211
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x16.png",
                "caption": "Figure 16:Impact of Teacher Model on Style Image Generation. The term “timestep” refers to the number of denoising steps during which the Teacher Model is involved. Notably, these experiments were conducted without incorporating cross-modal AdaIN to isolate and evaluate the specific impact of the Teacher Model on the generated results.",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x17.png",
                "caption": "Figure 17:Compared to the image-based style transfer(I2I) provided by CSGO[36], We ensured the use of the same initial noise for both our method and the generation of the content image for I2I. It can be observed that the results obtained using the Teacher Model differ significantly from those of I2I, as I2I fails to preserve the color information of the original image.",
                "position": 1225
            }
        ]
    },
    {
        "header": "Appendix DAdditional Comparisons",
        "images": []
    },
    {
        "header": "Appendix EMore results from our study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.08503/x18.png",
                "caption": "Figure 18:Qualitative results of using cross-modal AdaIN in InstantStyle[33]. The results demonstrate that cross-modal AdaIN effectively prevents style overfitting. The final generated results consistently align with the textual descriptions.",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x19.png",
                "caption": "Figure 19:Impact of Teacher Model on InstantStyle[33]Image Generation. The term “timestep” refers to the number of denoising steps during which the Teacher Model is involved. Notably, these experiments were conducted without incorporating cross-modal AdaIN to isolate and evaluate the specific impact of the Teacher Model on the generated results. When the Teacher Model is applied to InstantStyle[33], it helps prevent the generation of artifacts, such as checkerboard patterns.",
                "position": 1278
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x20.png",
                "caption": "Figure 20:Impact of Teacher Model on StyleCrafter[18]Image Generation. The term “timestep” refers to the number of denoising steps during which the Teacher Model is involved. Notably, these experiments were conducted without incorporating cross-modal AdaIN to isolate and evaluate the specific impact of the Teacher Model on the generated results. In addition to ensuring layout stability, the Teacher Model also effectively reduces the occurrence of content leakage when applied to StyleCrafter[18].",
                "position": 1289
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x21.png",
                "caption": "Figure 21:Qualitative comparison with state-of-the-art methods. Our approach effectively preserves image style while accurately adhering to text prompts for generation.",
                "position": 1292
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x22.png",
                "caption": "Figure 22:Qualitative comparison with state-of-the-art methods. Our approach effectively preserves image style while accurately adhering to text prompts for generation.",
                "position": 1295
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x23.png",
                "caption": "Figure 23:Qualitative comparison with state-of-the-art methods. Our approach effectively maintain layout consistency across different styles under the same prompt.",
                "position": 1298
            },
            {
                "img": "https://arxiv.org/html/2412.08503/x24.png",
                "caption": "Figure 24:More results of our text-driven style transfer model. Given a style reference image, our method effectively reduces style overfitting, generating images that faithfully align with the text prompt while maintaining consistent layout structure across varying styles. Illustration of the prompt format used: “A [color] bus”.",
                "position": 1301
            }
        ]
    },
    {
        "header": "Appendix FIntegration with Other Methods",
        "images": []
    }
]