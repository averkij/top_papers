[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x1.png",
                "caption": "Figure 5:Visual comparison of the ablation study in Table2.",
                "position": 768
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x2.png",
                "caption": "Figure 6:An example failure case ofHOComp. The red boxes indicate the interaction regions.",
                "position": 787
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BExtended Details onIHOCdataset",
        "images": []
    },
    {
        "header": "Appendix CEffectiveness of Residual-based Modulation Strategy",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x3.png",
                "caption": "Figure 10:Visual results of ablation study on attention modulation strategies in Table3.",
                "position": 2230
            }
        ]
    },
    {
        "header": "Appendix DEffect of Coefficients",
        "images": []
    },
    {
        "header": "Appendix EExtended Details on Using MLLMs to Identify Interaction Types and Regions",
        "images": []
    },
    {
        "header": "Appendix FAdditional Ablation studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x4.png",
                "caption": "Figure 11:Visual results of ablation study on view numbers used in multi-view appearance loss.",
                "position": 2368
            },
            {
                "img": "https://arxiv.org/html/2507.16813/x5.png",
                "caption": "Figure 12:Visual results of ablation study on multi-view generators.",
                "position": 2371
            },
            {
                "img": "https://arxiv.org/html/2507.16813/x6.png",
                "caption": "Figure 13:Ablation study on different backbones for foreground ID encoders.",
                "position": 2605
            },
            {
                "img": "https://arxiv.org/html/2507.16813/x7.png",
                "caption": "Figure 14:Ablation study on different guidance scales (denoted as gs) during inference.",
                "position": 2755
            }
        ]
    },
    {
        "header": "Appendix GComparison with Multi-Modality Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x8.png",
                "caption": "Figure 15:Quantitative comparison with recent state-of-the-art multi-modality models. The prompts for the above three cases are: \"A woman is riding a horse\",\"A girl is holding a stack of books\", \"A model is presenting a skincare bottle\".",
                "position": 2826
            }
        ]
    },
    {
        "header": "Appendix HAdditional Comparison with Image Composition Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16813/x9.png",
                "caption": "Figure 16:Additional qualitative comparisons of ourHOCompwith 5 SOTA methods. The prompts for the above four examples are: “A boy is holding a mickey mouse toy”, “A girl is showing a perfume bottle”, “A woman is lifting a bag”, and “A sitting man is holding a balloon”.",
                "position": 2854
            },
            {
                "img": "https://arxiv.org/html/2507.16813/x10.png",
                "caption": "Figure 17:Additional qualitative results ofHOComp. Each example includes: (1) Top: the final composited image, (2) Bottom: the input background human and foreground object.",
                "position": 2980
            }
        ]
    },
    {
        "header": "Appendix IAdditional Results ofHOComp",
        "images": []
    }
]