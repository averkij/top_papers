[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/stripy_and_blob_artifacts.jpg",
                "caption": "Figure 1:Illustration of stripy or blob-like artifacts generated in VSR outputs of LR videos rendered from 3DGS. ‘VSR-Render’ shows the VSR outputs of the LR rendered videos, while ‘VSR-GT’ displays the VSR outputs of the ground truth (GT) LR videos.",
                "position": 169
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/main.jpg",
                "caption": "Figure 2:Overview of the proposed method. Given LR multi-view images, we generate subsequences (Sec.3.3) starting from each image using a simple greedy algorithm (Sec.3.2) and these subsequences are bounded by multiple thresholds (Sec.3.3). Finally, we train a 3DGS model for 3D reconstruction using the upsampled HR images.",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/subsequence.jpg",
                "caption": "Figure 3:Illustration of subsequence generation. (a) is an unordered multi-view image dataset. (b) is the result of using a simple greedy algorithm, Alg.1. (c) highlights misalignments incurred by the algorithm, and we propose to split it into subsequences based on a pose difference threshold (red dotted line) between consecutive frames.",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/lego_simple_greedy_algorithm.jpg",
                "caption": "Figure 4:An example result from the simple greedy algorithm applied to the NeRF-synthetic dataset (Lego). Two neighboring images highlighted in red demonstrate abrupt transitions caused by misalignments.",
                "position": 410
            },
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/baseline_blender.jpg",
                "caption": "Figure 5:Qualitative results on the NeRF-synthetic dataset. The PSNR values against GT are embedded in each image patch. Ours have shown superior results than the existing baselines, especially for high-frequency details.",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/baseline_mip360.jpg",
                "caption": "Figure 6:Qualitative results on Mip-NeRF 360 dataset. The PSNR values against GT are embedded in each image patch.\nOurs have shown superior results than the existing baselines, especially for high-frequency details.",
                "position": 551
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AFlexibility with VSR Baseline Models",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/PSNR_LPIPS.jpg",
                "caption": "Figure 7:Comparison with baselines.",
                "position": 1411
            },
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/misalignment_trends_all_objects.jpg",
                "caption": "Figure 8:Misalignment trends within a sequence.",
                "position": 1414
            }
        ]
    },
    {
        "header": "Appendix CMisalignment Error",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/misalignment.jpg",
                "caption": "Figure 9:Misalignment Error.",
                "position": 1421
            }
        ]
    },
    {
        "header": "Appendix DPer-object and Per-scene Quantitative Results",
        "images": []
    },
    {
        "header": "Appendix EMulti-threshold Subsequence",
        "images": []
    },
    {
        "header": "Appendix FSub-pixel Loss and Final Loss",
        "images": []
    },
    {
        "header": "Appendix GORB Feature Matching",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11525/extracted/6077927/figures/appendix_qualitative_blender.jpg",
                "caption": "Figure 10:Qualitative results on the NeRF-synthetic dataset. The PSNR values against GT are embedded in each image patch. Ours have shown superior results than the existing baselines, especially for high-frequency details.",
                "position": 2248
            }
        ]
    },
    {
        "header": "Appendix HTemporal Consistency",
        "images": []
    }
]