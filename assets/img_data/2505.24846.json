[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24846/x1.png",
                "caption": "Figure 1:Illustration of the two-stage pipeline of MiCRo for capturing personalized preferences.A mixture of reward models (Stage 1) is trained on binary-labeled data, while the context-aware router (Stage 2) dynamically adjusts preference distributions based on user-provided context. The final preference distribution is obtained through a convex combination of different preference distributions.",
                "position": 161
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Limitation of a Single Reward Function",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/combined_radar_plots.png",
                "caption": "Figure 2:Comparison of accuracy scores between the best heads of MiCRo and other baselines on multiple test dimensions.The mixture heads can disentangle diverse human preferences, with different heads excelling on different attributes. They consistently outperform the single reward model across all attributes. Overlaps where the same head dominates multiple attributes may reflect inherent attribute correlations.",
                "position": 547
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/heatmap_stage_1_rpr.png",
                "caption": "Figure 3:Heatmaps of router weights for different prompts in MiCRo Stage 1.The router assigns varying weights to different heads depending on the prompt.",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/budget_vs_accuracy_rpr.png",
                "caption": "(a)RPR test set.",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/budget_vs_accuracy_rpr.png",
                "caption": "(a)RPR test set.",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/budget_vs_accuracy_helpsteer.png",
                "caption": "(b)HelpSteer test set.",
                "position": 1110
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof of Theorem3.2",
        "images": []
    },
    {
        "header": "Appendix BReproducibility",
        "images": []
    },
    {
        "header": "Appendix CDiscussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/helpsteer_heads_bar.png",
                "caption": "(a)HelpSteer2",
                "position": 1848
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/helpsteer_heads_bar.png",
                "caption": "(a)HelpSteer2",
                "position": 1851
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/rpr_heads_bar.png",
                "caption": "(b)RPR",
                "position": 1857
            },
            {
                "img": "https://arxiv.org/html/2505.24846/extracted/6495358/content/figures/budget_vs_accuracy_rpr_selected_heads.png",
                "caption": "Figure 6:Average accuracy across different context-labeling budgets per attribute with models trained using varying values ofKùêæKitalic_K.For smallerKùêæKitalic_K, the model benefits less from additional context, as it underfits the diversity of preferences. For largerKùêæKitalic_K, while accuracy can improve, it requires more labeling budget to effectively assign context.",
                "position": 1864
            }
        ]
    },
    {
        "header": "Appendix DExperimental Details",
        "images": []
    },
    {
        "header": "Appendix EAdditional Experiment Results",
        "images": []
    }
]