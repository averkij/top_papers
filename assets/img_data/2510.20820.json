[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/x1.png",
                "caption": "Figure 1:LayerComposerintroduces aninteractive personalizationparadigm that enables a Photoshop-like experience for multi-subject T2I generation. It allows users toplace,resize, andlocksubjects on the proposedlayered canvas. A newlockingfunction is provided such thatlockedsubjects (e.g., background, snowman) are preserved with only necessary lighting adjustments, whileunlockedsubjects are flexibly injected into the scene with variations guided by the text prompt.",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/x2.png",
                "caption": "Figure 2:Locking-Aware Data Sampling Strategy.During training, layers inlayered canvas(the input to our LayerComposer) are extracted from multiple images within the same identity.Lockedlayers (e.g., background) are sampled directly from the target image, resulting in pixel alignment in input-target pair and thus preserving fidelity. In contrast,unlockedlayers (e.g., the man) are sampled from other source images, enabling variation guided by the text prompt while maintaining identity. Data augmentations are applied to all layers during training, ensuring that both locked and unlocked layers can be adapted to context in inference (e.g., lighting adjustments).",
                "position": 89
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3LayerComposer",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/x3.png",
                "caption": "Figure 3:LayerComposer Pipeline.LayerComposer conditions a diffusion model on both a text prompt and alayered canvas. The canvas consists of multiple layers that can be eitherlockedorunlocked. Each layer is first encoded using the VAE. Next, the positional embeddings are added according to the layerâ€™s locking status: locked layers share the same positional embeddings as the noisy latent[0,x,y][0,x,y], while each unlocked layer is assigned a unique layer indexjjin its positional embeddings[j,x,y][j,x,y].jjdistinguish unlocked layers when they overlap. Finally, atransparent latent pruningis performed to retain only the latents in non-transparent regions per layer, while discarding the others (gray boxes) for scalable personalized generation.",
                "position": 172
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/x4.png",
                "caption": "Figure 4:Qualitative Comparison in Four-person (4P) Personalization.While state-of-the-art baselines frequently distort, omit subjects, or produce unnatural copy-pasted artifacts, LayerComposer consistently generates high-fidelity and coherent compositions, faithfully preserving identities and their spatial arrangement. Crucially, our approach excels even when subjects are partially occluded in the input (shown inredboxes in 1stand 4throws) because of our unique layered canvas.",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2510.20820/x5.png",
                "caption": "Figure 5:Qualitative Comparison in Two-Person (2P) Personalization.When personalizing an image with two subjects, competing methods often fail to compose a coherent, interactive scene. This frequently results in missing, duplicated, or distorted subjects and unrealistic interactions. In contrast, LayerComposer produces visually coherent, high-fidelity scenes where both subjects are present and naturally interacting with each other and their surroundings, while preserving their distinct identities.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2510.20820/x6.png",
                "caption": "Figure 6:Qualitative Comparison in Single-Person (1P) Personalization.State-of-the-art 1P personalization approaches tend to inject the reference face identity with limited flexibility, resulting in copy-pasted effects. In contrast, LayerComposer generates realistic outputs, faithful to both the human identity and text prompt. Notably, our method captures diverse expressions (e.g.,laughing, 1strow), handles challenging states such asrelaxing(2ndrow), and supports diverse activities likeeating(3rdrow) andclosed eyes(4throw), which require complex body poses or expressive facial gestures.",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2510.20820/x7.png",
                "caption": "Figure 7:Ablation study.Locking can be applied to any subject, preserving the selected subjects (see their poses) with only necessary lighting and shading adjustments (e.g., reduced head reflection in the right man) in the final output. The layered canvas resolves occlusion issues; without it, overlapping details can be lost (e.g., the pom-pom on the red hat of the left woman in the rightmost column).",
                "position": 319
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmark Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/complex-coffee.jpg",
                "caption": "Figure I:Failure case in complex reasoning scenarios.LayerComposer struggles when strong spatial reasoning is required.\nIn this example, the subjects fail to sit naturally in the chairs, leading to\nunrealistic, copy-paste-like compositions that closely resemble the input images.",
                "position": 1304
            }
        ]
    },
    {
        "header": "Appendix BLimitation and Future Work",
        "images": []
    },
    {
        "header": "Appendix CLLM Usage Declaration",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p_bg/bg.jpg",
                "caption": "Figure II:4P Personalization with Background.Our layered canvas can be seamlessly integrated with the background, resulting in five layers: four persons and one background. In the final output, the inserted humans interact naturally with the background,e.g.leaning against a tree trunk or taking food from the table, while maintaining overall coherent lighting. Note the images on the left shows the collage visualization of our layered canvas.",
                "position": 1352
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/1_comparison.jpg",
                "caption": "Table I:Supplementary results for 4P personalization.",
                "position": 1388
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/11_comparison.jpg",
                "caption": "",
                "position": 1427
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/15_comparison.jpg",
                "caption": "",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/20_comparison.jpg",
                "caption": "",
                "position": 1435
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/24_comparison.jpg",
                "caption": "",
                "position": 1439
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/5_comparison.jpg",
                "caption": "",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/28_comparison.jpg",
                "caption": "",
                "position": 1447
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/4p/29_comparison.jpg",
                "caption": "",
                "position": 1451
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/0_comparison.jpg",
                "caption": "Table II:Supplementary results for 2P personalization.",
                "position": 1457
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/9_comparison.jpg",
                "caption": "",
                "position": 1496
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/5_comparison.jpg",
                "caption": "",
                "position": 1500
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/14_comparison.jpg",
                "caption": "",
                "position": 1504
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/3_comparison.jpg",
                "caption": "",
                "position": 1508
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/19_comparison.jpg",
                "caption": "",
                "position": 1512
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/2_comparison.jpg",
                "caption": "",
                "position": 1516
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/2p/6_comparison.jpg",
                "caption": "",
                "position": 1520
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/16_comparison.jpg",
                "caption": "Table III:Supplementary results for 1P personalization.",
                "position": 1526
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/19_comparison.jpg",
                "caption": "",
                "position": 1560
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/8_comparison.jpg",
                "caption": "",
                "position": 1564
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/21_comparison.jpg",
                "caption": "",
                "position": 1568
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/17_comparison.jpg",
                "caption": "",
                "position": 1572
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/24_comparison.jpg",
                "caption": "",
                "position": 1576
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/12_comparison.jpg",
                "caption": "",
                "position": 1580
            },
            {
                "img": "https://arxiv.org/html/2510.20820/figures/supp_results/1p/10_comparison.jpg",
                "caption": "",
                "position": 1584
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": []
    }
]