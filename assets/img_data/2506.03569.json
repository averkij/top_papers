[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/x1.png",
                "caption": "Figure 1:Benchmark performance of MiMo-VL-7B.",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2506.03569/x2.png",
                "caption": "",
                "position": 132
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Pre-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/x3.png",
                "caption": "Figure 2:Model architecture of MiMo-VL-7B.",
                "position": 255
            }
        ]
    },
    {
        "header": "3Post-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/x4.png",
                "caption": "Figure 3:Mixed On-policy Reinforcement Learning in post-training phase.",
                "position": 535
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/x5.png",
                "caption": "Figure 4:GUI understanding and grounding results. MiMo-VL-7B-RL achieves comparable results with GUI specialized models.",
                "position": 1596
            },
            {
                "img": "https://arxiv.org/html/2506.03569/x6.png",
                "caption": "Figure 5:Elo ratings comparison across VLMs. MiMo-VL-7B-RL achieves the highest rating among open-source models, approaching the performance of proprietary alternatives such as Claude 3.7 Sonnet.",
                "position": 1603
            },
            {
                "img": "https://arxiv.org/html/2506.03569/x7.png",
                "caption": "Figure 6:MiMo-VL-7B-SFT training curves in Stage 4.",
                "position": 1606
            },
            {
                "img": "https://arxiv.org/html/2506.03569/x8.png",
                "caption": "Figure 7:On-policy RL and vanilla GRPO shows contrasting scaling behavior: on-policy RL performance continuously improves with more data, while vanilla GRPO reaches a plateau around 20,000 samples.",
                "position": 1609
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/case/case1.png",
                "caption": "Figure 8:Examples of MiMo-VL-7B solving complicated problems.",
                "position": 1649
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/case/case1-2.png",
                "caption": "",
                "position": 1673
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/case/case2.png",
                "caption": "",
                "position": 1679
            }
        ]
    },
    {
        "header": "6Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/x9.png",
                "caption": "Figure 9:A case demonstrating the agentic capabilities of our model. MiMo-VL-7B successfully navigates a website to add the Xiaomi SU7 to the wishlist, customizing both paint and interior options. All screenshots are of size 1886*1544 (width*height).",
                "position": 1742
            }
        ]
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AContributions and Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix BModel Configuration of MiMo-VL-7B",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Benchmarks",
        "images": []
    },
    {
        "header": "Appendix DGUI Action Space",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example1.jpg",
                "caption": "Figure 10:Example of MiMo-VL-7B-RL answering all questions within a whole test paper.",
                "position": 3198
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example2.jpeg",
                "caption": "Figure 11:Example of MiMo-VL-7B-RL solving complex OCR problems with reasoning.",
                "position": 3283
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example3.png",
                "caption": "",
                "position": 3324
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example4.png",
                "caption": "Figure 12:Example of MiMo-VL-7B-RL solving detailed perception problem.",
                "position": 3356
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example5.png",
                "caption": "",
                "position": 3378
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example6.png",
                "caption": "",
                "position": 3394
            },
            {
                "img": "https://arxiv.org/html/2506.03569/extracted/6510738/figures/example/example7.png",
                "caption": "Figure 13:Example of MiMo-VL-7B-RL solving multiple geometry problems.",
                "position": 3421
            }
        ]
    },
    {
        "header": "Appendix EMore Qualitative Examples",
        "images": []
    }
]