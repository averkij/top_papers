[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16175/x1.png",
                "caption": "Figure 1:Vision-augmented action learning paradigms.(a) Visual Foresight enhances action prediction by forecasting future frames. (b) Track Guidance employs compressed visual state representations to guide action prediction. (c) Latent Action Supervision improves action learning through auxiliary latent actions.",
                "position": 164
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16175/x2.png",
                "caption": "Figure 2:Left:Progressive training recipe.Mantis progressively integrates multiple modalities to achieve stable and well-balanced optimization.Center:Overview of Mantis.The framework consists of a backbone network, a DVF head, and an action head. The DVF head predicts future frames to facilitate latent action learning, thereby improving action prediction. Language supervision helps maintain the backbone’s capability for understanding and reasoning.Right:Adaptive Temporal Ensemble.Mantis-ATE dynamically adjusts the ensemble strength based on the overlap between target tokens and dynamic tokens.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2511.16175/x3.png",
                "caption": "Figure 3:Visualization of multi-gap future frame generation.",
                "position": 279
            },
            {
                "img": "https://arxiv.org/html/2511.16175/x4.png",
                "caption": "Figure 4:Visualization of ATE.The attention heatmap uses darker colors to represent higher values, whereas in the cosine similarity heatmap the opposite holds. The parameters are set asτtarget=1\\tau_{\\text{target}}=1andτdynamic=12\\tau_{\\text{dynamic}}=12.",
                "position": 311
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16175/x5.png",
                "caption": "Figure 5:Convergence speed comparison.Compared with traditional visual foresight methods such as UnifiedVLA[wang2025unified], Mantis achieves significantly faster convergence speed, underscoring the necessity of decoupling foresight prediction from action learning.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2511.16175/x6.png",
                "caption": "Figure 6:Real World Experiments.(a) The Agilex platform. (b) Scenario setups and example instructions. Each scenario shows one ID instruction and the corresponding OOD instruction. (c) Average success counts for Mantis andπ0.5\\pi_{0.5}on ID and OOD tasks across three scenarios. (d) Per-task success counts for Mantis andπ0.5\\pi_{0.5}in Scenario 1.",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2511.16175/x7.png",
                "caption": "Figure 7:Visualization of Generated Future Frames.The last generated future frame closely mirrors the ground truth final state, substantiating the efficacy of the DVF in refining action prediction across diverse manipulation tasks.",
                "position": 533
            },
            {
                "img": "https://arxiv.org/html/2511.16175/x8.png",
                "caption": "Figure 8:Comparison between standard Mantis (TE) and Mantis-ATE.The primary vertical axis denotes success rate (SR), and the secondary vertical axis denotes inference count (IC).",
                "position": 536
            }
        ]
    },
    {
        "header": "5Conclusion, Limitations and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16175/x9.png",
                "caption": "Figure 9:Comparison between Mantis and Mantis-LU.",
                "position": 675
            }
        ]
    },
    {
        "header": "Appendix AAdaptive Temporal Ensemble",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CReal World Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16175/x10.png",
                "caption": "Figure 10:Execution examples on real-world tasks.",
                "position": 972
            }
        ]
    },
    {
        "header": "Appendix DLanguage Supervision Ablations",
        "images": []
    }
]