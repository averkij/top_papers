[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15948/images/hoi_image_click.png",
                "caption": "Figure 1:On the left example, the user clicked on the⟨dog⟩\\langle\\text{{dog}}\\rangle, and Click2Graph segmented the⟨carpet⟩\\langle\\text{{carpet}}\\rangleand predicted the⟨sitting⟩\\langle\\text{{sitting}}\\rangleactivity. On the right, we have a prompt on⟨child⟩\\langle\\text{{child}}\\ranglewhich yields⟨dog⟩\\langle\\text{{dog}}\\rangle,⟨playing⟩\\langle\\text{{playing}}\\rangleas associated object and activity.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15948/images/c2g.jpg",
                "caption": "Figure 2:Overview of theClick2Grapharchitecture for user-guided Panoptic Video Scene Graph Generation. From a single user prompt, the system segments and tracks the subject, discovers interacting objects via the Dynamic Interaction Discovery Module (DIDM), and predicts subject–object–predicate triplets using the Semantic Classification Head (SCH).",
                "position": 311
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/tcdsg-opg.png",
                "caption": "Figure 3:Architecture of theDynamic Interaction Discovery Module (DIDM). A single user-prompted subject prompt is transformed intoNqN_{q}predicted object prompts. It combines a feature vector derived from the subject mask with learnable object queries. These tokens pass through a Transformer decoder, which performs cross-attention over the image features, enabling the module to autonomously predict the precise locations (via the Point Prediction Head) of all entities interacting with the prompted subject.",
                "position": 393
            }
        ]
    },
    {
        "header": "4Dataset: OpenPVSG",
        "images": []
    },
    {
        "header": "5Evaluation Metrics",
        "images": []
    },
    {
        "header": "6Results & Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/egg.jpg",
                "caption": "(a)Prediction:adult,box,holdingGT:adult,box,holding",
                "position": 860
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/egg.jpg",
                "caption": "(a)Prediction:adult,box,holdingGT:adult,box,holding",
                "position": 863
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/bacon.jpg",
                "caption": "(b)Prediction:adult,bag,holdingGT:adult,bag,holding",
                "position": 872
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/spatula.jpg",
                "caption": "(c)Prediction:adult,spatula,holdingGT:adult,spatula,holding",
                "position": 881
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/occ_1.jpg",
                "caption": "(d)Prediction:ball,grass,onGT:ball,grass,on",
                "position": 891
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/occ_2.jpg",
                "caption": "(e)Subject temporarily occluded by camera motion",
                "position": 900
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/occ_3.jpg",
                "caption": "(f)Prediction:ball,grass,onGT:ball,grass,on",
                "position": 908
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/on_vs_sit.jpg",
                "caption": "(g)Prediction:child,floor,sittingGT:child,floor,on",
                "position": 918
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/gift.jpg",
                "caption": "(h)Prediction:child,box,holdingGT:child,gift,holding",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2511.15948/images/qualitative/helmet.jpg",
                "caption": "(i)Prediction:child,helmet,wearingTriplet not in Ground Truth",
                "position": 936
            }
        ]
    },
    {
        "header": "7Conclusions and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]