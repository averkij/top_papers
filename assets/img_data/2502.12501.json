[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12501/x1.png",
                "caption": "Figure 1:An overview of our method. By evaluating the candidate responses A/B alongside the crowd responses, the resulting crowd judgment can be used as context to enrich the evaluation of A/B responses, leading to a more comprehensive CoT judgment.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12501/x2.png",
                "caption": "Figure 2:Pipeline of our proposed crowd-based comparative evaluation.For a given instance(x,yA,yB)𝑥superscript𝑦𝐴superscript𝑦𝐵(x,y^{A},y^{B})( italic_x , italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT ), we first use the LLM to generate crowd responses{yi|i∈{C,D,E,…}}conditional-setsuperscript𝑦𝑖𝑖𝐶𝐷𝐸…\\left\\{y^{i}|i\\in\\{C,D,E,...\\}\\right\\}{ italic_y start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | italic_i ∈ { italic_C , italic_D , italic_E , … } }based onx𝑥xitalic_x. These responses are then compared withyAsuperscript𝑦𝐴y^{A}italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPTandyBsuperscript𝑦𝐵y^{B}italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPTto produce initial crowd judgments𝒥𝒥\\mathcal{J}caligraphic_J, which are subsequently refined into𝒥^^𝒥\\hat{\\mathcal{J}}over^ start_ARG caligraphic_J end_ARGafter selection and processing. Finally,𝒥^^𝒥\\hat{\\mathcal{J}}over^ start_ARG caligraphic_J end_ARGare used as contextual input to evaluate the instance(x,yA,yB)𝑥superscript𝑦𝐴superscript𝑦𝐵(x,y^{A},y^{B})( italic_x , italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT ).",
                "position": 226
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12501/x3.png",
                "caption": "Figure 3:Evaluation performance under scaling crowd judgments in the context. As the number of crowd judgments grows, both accuracy and CoT length generally increase.",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2502.12501/x4.png",
                "caption": "Figure 4:CoT Comparison.CCE’s CoT consistently yields a higher average number of key points and a higher coverage rate across all benchmarks.",
                "position": 1074
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Template",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12501/x5.png",
                "caption": "Figure 5:Prompt of Our Method.",
                "position": 1832
            },
            {
                "img": "https://arxiv.org/html/2502.12501/x6.png",
                "caption": "Figure 6:Prompt of Vanilla LLM-as-a-Judge.",
                "position": 1835
            },
            {
                "img": "https://arxiv.org/html/2502.12501/x7.png",
                "caption": "Figure 7:Prompt of 16-Criteria LLM-as-a-Judge.",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2502.12501/x8.png",
                "caption": "Figure 8:Prompt of LongPrompt LLM-as-a-Judge.",
                "position": 1841
            }
        ]
    },
    {
        "header": "Appendix BTesting Preference Benchmark",
        "images": []
    },
    {
        "header": "Appendix CDistilling CoT for Training Judge",
        "images": []
    },
    {
        "header": "Appendix DSFT Data Selection",
        "images": []
    },
    {
        "header": "Appendix EInference Scaling",
        "images": []
    },
    {
        "header": "Appendix FCoT Comparison",
        "images": []
    }
]