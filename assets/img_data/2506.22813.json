[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22813/x1.png",
                "caption": "Figure 1:(a) Existing methods train a general unified model across multiple domains, while we dynamically select and merge expert models at inference time. (b) A trained system struggles to accommodate changes in training data, while we flexibly add or remove expert models, ensuring great scalability.",
                "position": 157
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22813/x2.png",
                "caption": "Figure 2:Framework overview. Given a target domain, we select expert models from two perspectives:(a) Domain Similarity, which selects experts from domains most similar to the target domain. We compute the centroid of all data embeddings as the domain embedding and measure similarities by cosine distance.(b) Sampling Evaluation, which selects experts with better performances on sampled instances from the target domain. To reduce reliance on ground-truth labels, we ensemble predictions from all experts as (pseudo) labels.\nWe merge models within each expert subset to obtain two task-specific models.\nThe final result integrates the outputs of the two task models.",
                "position": 214
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22813/x3.png",
                "caption": "Figure 3:Performance changes with the number of experts. The horizontal axis is the number of experts for merging, and the vertical denotes the F1 scores.",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x4.png",
                "caption": "Figure 4:Performance changes with the number of data splits. The horizontal axis is the number of splits, and the vertical denotes the entity-level F1 scores.",
                "position": 997
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x5.png",
                "caption": "Figure 5:Performance changes with the number of data splits. We aggregate data from all domains into a unified dataset and subsequently conduct the split analysis.",
                "position": 1000
            }
        ]
    },
    {
        "header": "5Future Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    },
    {
        "header": "Appendix BData Merging or Model Merging",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22813/x6.png",
                "caption": "Figure 6:Distribution of the training data.",
                "position": 2180
            }
        ]
    },
    {
        "header": "Appendix CAnalysis of Cost",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22813/x7.png",
                "caption": "Figure 7:Formatted training data example. The example consists of task instructions, inputs, and outputs for training.\nFor the task instructions, the Data Source Description, Entity Type drop/mask, and ICL Demonstrations are optional, with details in section3.1. We adopt three output formats: JSON, enumeration, and natural language descriptions. The output format of ICL Demonstrations and Answers should be consistent with the specified.",
                "position": 2776
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x8.png",
                "caption": "Figure 8:Another example of our formatted training data. The instance here is the same as that of Figure7, adopting the entity type drop and mask processing methods.",
                "position": 2780
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x9.png",
                "caption": "Figure 9:Performance changes with the number of expert models (denotes askùëòkitalic_k). The horizontal axis is the number of experts for merging, and the vertical denotes the entity-level F1 scores.Only using Domain Similarity for expert selection. It can be seen that the optimalkùëòkitalic_kvaries across target domains, typically ranging from 2 to 4.",
                "position": 2783
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x10.png",
                "caption": "Figure 10:Performance changes with the number of expert models.\nThe horizontal axis is the number of experts for merging, and the vertical denotes the entity-level F1 scores.Only using Sampling Evaluation for expert selection.It exhibits similar overall trends to Figure9, but with distinct differences, indicating that both selecting strategies are important and complementary.",
                "position": 2786
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x11.png",
                "caption": "Figure 11:Performance changes with the number of data splits. The horizontal axis is the number of splits, and the vertical denotes the entity-level F1 scores.Only using Domain Similarity for expert selection.It can be seen that the Domain Similarity strategy has a minimal impact, since data from the target domain may be too homogeneous.",
                "position": 2792
            },
            {
                "img": "https://arxiv.org/html/2506.22813/x12.png",
                "caption": "Figure 12:Performance changes with the number of data splits. The horizontal axis is the number of splits, and the vertical denotes the entity-level F1 scores.Only using Sampling Evaluation for expert selection.It shows significant changes when using Sampling Evaluation, with a general downward trend.",
                "position": 2795
            }
        ]
    },
    {
        "header": "Appendix DExperimental Supplements",
        "images": []
    }
]