[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06481/x1.png",
                "caption": "Figure 1:The figure illustrates that previous extended motion generation methods often struggle with directional instructions, leading to incorrect motions. In contrast, our proposed KMM, with enhanced text-motion alignment, effectively improves the model’s understanding of text queries, resulting in more accurate motion generation.",
                "position": 74
            }
        ]
    },
    {
        "header": "Introduction",
        "images": []
    },
    {
        "header": "Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06481/x2.png",
                "caption": "Figure 2:The figure demonstrates our novel method from three different perspectives: (a) illustrates the key frame masking strategy based on local density and minimum distance to higher density calculation. (b) showcases the overall architecture of the masked bidirectional Mamba. (c) demonstrates the text-to-motion alignment, highlighting the process before and after alignment.",
                "position": 142
            }
        ]
    },
    {
        "header": "Motivation",
        "images": []
    },
    {
        "header": "Methodology",
        "images": []
    },
    {
        "header": "Experiments",
        "images": []
    },
    {
        "header": "KMM Supplementary Materials",
        "images": []
    },
    {
        "header": "Appendix AUser Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06481/x3.png",
                "caption": "Figure 3:The figure shows the user study interface where 50 participants evaluated motion sequences generated by TEACH, PriorMDM, FlowMDM, and KMM, focusing on text-motion alignment, robustness, diversity, and usability. The text prompt are randomly extracted and combined from the HumanML3D(Guo et al.2022)and BABEL(Punnakkal et al.2021)test set.",
                "position": 773
            }
        ]
    },
    {
        "header": "Appendix BQualitative Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06481/x4.png",
                "caption": "Figure 4:The figure demonstrates a qualitative comparison between the previous state-of-the-art method in extended motion generation and our KMM. The qualitative results show that our method significantly outperforms others in handling complex text queries and generating more accurate corresponding motions.",
                "position": 783
            }
        ]
    },
    {
        "header": "Appendix CGenerative Results Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06481/x5.png",
                "caption": "Figure 5:The figure presents some qualitative visualization results of our proposed KMM model. The text prompts are sourced and combined from HumanML3D(Guo et al.2022)and BABEL(Punnakkal et al.2021). The number within the brackets indicates our ability to condition the generated motion on a specific length, dynamically producing motion of the desired duration. The visualizations showcase KMM’s superior performance in generating robust and diverse motions that align closely with lengthy and complex text queries.",
                "position": 793
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]