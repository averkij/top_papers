[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Benchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22264/x1.png",
                "caption": "Figure 1.PatenTEB construction pipeline: data acquisition from Lens.org, family reconstruction, IPC3-level domain stratification (109 domains,≥\\geq100 families each), 80/10/10 splitting, task construction (15 tasks across 4 families), and various quality controls.††:",
                "position": 236
            }
        ]
    },
    {
        "header": "4.Models and Training",
        "images": []
    },
    {
        "header": "5.Evaluation Protocol",
        "images": []
    },
    {
        "header": "6.Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22264/x2.png",
                "caption": "Figure 2.Per-task performance heatmap (test set): 15 tasks×\\times10 models. patembed-large achieves the highest score on 12 of the 15 tasks.††:",
                "position": 1192
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x3.png",
                "caption": "Figure 3.Initial base models vs fine-tuned patembed variants : Multi-task fine-tuning yields substantial gains, with largest improvements on retrieval and paraphrase.††:",
                "position": 1201
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x4.png",
                "caption": "Figure 4.PatenTEB task family performance (top-8 models). patembed-large achieves highest overall score (0.654) with balanced performance across retrieval, paraphrase, classification, and clustering.††:",
                "position": 1207
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x5.png",
                "caption": "Figure 5.Domain difficulty variation for retrieval (top-8 models). IN-domain (shared IPC3, 0.29–0.51 NDCG) → MIXED-domain (partial overlap, 0.21–0.44) → OUT-domain (disjoint IPC3, 0.06–0.17) shows 3–6×\\timesperformance degradation, highlighting cross-domain retrieval challenges.††:",
                "position": 1227
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x6.png",
                "caption": "Figure 6.External validation. patembed-base achieves 0.494 V-measure on MTEB BigPatent, patembed-large reaches 0.377 NDCG@100 on DAPFAM. Panels show best scores (a,c) and prompt sensitivity (b,d).††:",
                "position": 1233
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x7.png",
                "caption": "Figure 7.Accuracy-speed efficiency frontier. patembed family traces Pareto frontier from nano (67M, 68s) to large (344M, 4100s).††:",
                "position": 1246
            }
        ]
    },
    {
        "header": "7.Ablations and Robustness",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22264/x8.png",
                "caption": "Figure 8.Training ablation: internal (PatenTEB) vs. external trade-offs.Full Multi-task training shows minor internal cost but substantial external gains, demonstrating improved generalization.††:",
                "position": 1329
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x9.png",
                "caption": "Figure 9.Prompt sensitivity per task for patembed-large. Bars show performance change when training with prompts vs. without prompts (delta = with prompts - without prompts). Positive values indicate prompts improve performance, negative values indicate prompts degrade performance. Asymmetric retrieval tasks benefit most from prompts, while paraphrase and classification tasks show stagnation or degradation.††:",
                "position": 1338
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x10.png",
                "caption": "Figure 10.Data scaling for patembed-nano distillation. Optimal efficiency at 54.6% of data retains 98% performance, with diminishing returns beyond this point.††:",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2510.22264/x11.png",
                "caption": "Figure 11.Robustness analysis overview: (a) dimension truncation retains 99% performance at 4×\\timescompression, (b) layer pruning curve at runtime shows steep degradation of performance, (c) input format change at inference time causes minimal structural degradation, (d) stable long-context performance for our four task families.††:",
                "position": 1695
            }
        ]
    },
    {
        "header": "8.Discussion",
        "images": []
    },
    {
        "header": "9.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASupplementary material",
        "images": []
    }
]