[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07586/x1.png",
                "caption": "Figure 1:Humans and machines conceptualize the world differently from each other. Mismatches in communication occur, which lead to misunderstandings. To understand and control AI, we must bridge this gap by developing new words corresponding to human and machine concepts, and use these words to control machines.",
                "position": 124
            },
            {
                "img": "https://arxiv.org/html/2502.07586/x2.png",
                "caption": "Figure 2:Machine and humans may fundamentally understand the world differently, enabling different concepts, knowledge and capabilities. Figure reproduced fromKim (2022); Schut et¬†al. (2023)with permission.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Understanding AI requires neologisms",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07586/x3.png",
                "caption": "Figure 3:Concept-based neologisms sit in-between mechanistic interpretability (which is closer to mechanistic details) and behavioral experiments/capability benchmarking (which is only concerned with the model‚Äôs output, not how it arrived there).",
                "position": 204
            }
        ]
    },
    {
        "header": "3Alternative views and rebuttals",
        "images": []
    },
    {
        "header": "4How neologisms fit into other interpretability work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07586/x4.png",
                "caption": "Figure 4:Our neologism embedding learning only updates new word embedding, preserving the original model‚Äôs responses when the new word is not used.",
                "position": 374
            }
        ]
    },
    {
        "header": "5A proof of concept: Neologism Embedding Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07586/extracted/6195662/figures/length3.png",
                "caption": "Figure 5:Base models prompted for length control fail to generate specified long generations (blue), but with a neologism (orange), they consistently generate longer responses.",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2502.07586/x5.png",
                "caption": "Figure 6:Adding a ‚Äúdiversity neologism‚Äù diversehwsuperscriptsubscriptabsentùë§‚Ñé{}_{w}^{h}start_FLOATSUBSCRIPT italic_w end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPTto a prompt substantially increases a model‚Äôs response variety, as exemplified in a number guessing game. The setup is explained inSection5.4; higher = more response variety (better).",
                "position": 499
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMethods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07586/extracted/6195662/figures/length_400_600.png",
                "caption": "Figure 7:Results for length constraint-following for both of our length categories: 400-600 words and 600-1000 words. The base Gemma model fails to generate sufficiently long responses foreithercategory. Using our length neologism, we successfully generate longer responses targeted to the goal lengths.",
                "position": 2059
            }
        ]
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    }
]