[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01650/x1.png",
                "caption": "Figure 1.Text prompts often fail to describe hairstyles precisely, and finding exact reference images is challenging. By contrast, sketches are generally clearer and more flexible.",
                "position": 125
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01650/x2.png",
                "caption": "Figure 2.Overview of our proposed framework employing a learnable multi-scale upsampling strategy via next-scale prediction and an adaptive conditioning mechanism with learnable visual tokens for sketch-based strand generation.",
                "position": 201
            }
        ]
    },
    {
        "header": "3.Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01650/x3.png",
                "caption": "Figure 3.Qualitative comparison across HAAR(Sklyarova et al.,2024), Sketch+HAAR, HairStep(Zheng et al.,2023), and our method. HAAR often ignores input conditions and defaults to short/medium styles. Sketch+HAAR improves accuracy via visual conditioning but still lacks detail fidelity. HairStep struggles with consistent geometry and produces artifacts such as incorrect back strands. In contrast, our method achieves high fidelity and precise control over diverse inputs.",
                "position": 318
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01650/x4.png",
                "caption": "Figure 4.Ablation study on upsampling strategy. (a) Comparison to common alternatives (NN, BI, HAAR’s fixed approach) shows their artifacts like clustering, over-smoothing, and inconsistencies (highlighted by red boxes). Our learnable approach better preserves fine details with realistic transitions. (b) Multi-scale (ours) vs. single-scale. The single-scale baseline fails to faithfully follow input sketches, while our progressive multi-scale strategy maintains superior conditional consistency.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2508.01650/x5.png",
                "caption": "Figure 5.Ablation of the conditioning for initial strands: fixed features fail with dense sketches; global/local features alone compromise detail fidelity or structure control. Our method resolves density mismatch, preserving adherence.",
                "position": 442
            },
            {
                "img": "https://arxiv.org/html/2508.01650/x6.png",
                "caption": "Figure 6.Adaptability to varying sketch densities. Consistent generation across the same hairstyle concept sketches with increasing densities (left to right)",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2508.01650/x7.png",
                "caption": "Figure 7.Hairstyle modification via sketch editing. Changes sketch attributes (e.g.length/curliness) reflected in outputs.",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2508.01650/x8.png",
                "caption": "Figure 8.Generalization to hand-drawn sketches.",
                "position": 513
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01650/x9.png",
                "caption": "Figure 9.Sketch generation from rendered hair. Compared to Canny edges (often cluttered) or rendering masks (often too dense/lossy), the line art extractor produces sketches closer to hand-drawn styles with varying density levels.",
                "position": 1084
            },
            {
                "img": "https://arxiv.org/html/2508.01650/x10.png",
                "caption": "Figure 10.Additional qualitative comparisons with HAAR(Sklyarova et al.,2024), Sketch+HAAR, and HairStep(Zheng et al.,2023). HAAR often ignores input conditions, producing similar short hairstyles. Sketch+HAAR improves alignment but struggles with fine-grained details. HairStep shows geometric inconsistencies, such as erroneous long strands. In contrast, our method achieves high fidelity and accurately reflects diverse inputs.",
                "position": 1087
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experiment Results",
        "images": []
    }
]