[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02160/x1.png",
                "caption": "Figure 1:Comparison of baseline and D-CORE trained LRMs in complex tool use scenarios. Baseline LRMs exhibit “Lazy Reasoning” with repetitive reflection and incorrect answers, while D-CORE trained LRMs decompose tasks into executable subtasks.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x2.png",
                "caption": "Figure 2:Comparison of LRM Qwen3 vs. instruct LLM xLAM2 performance on BFCLv3 Parallel, Irrelevance , Multi-turn andτ\\tau-bench task.",
                "position": 133
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02160/x3.png",
                "caption": "(a)Four Behaviors",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x3.png",
                "caption": "(a)Four Behaviors",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x4.png",
                "caption": "(b)Lazy Reasoning Ratio",
                "position": 178
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x5.png",
                "caption": "(c)Manual Composition",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x6.png",
                "caption": "(d)Manual Decomposition",
                "position": 188
            }
        ]
    },
    {
        "header": "2Tool Use Reasoning: Patterns and Limitations",
        "images": []
    },
    {
        "header": "3D-CORE",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02160/x7.png",
                "caption": "Figure 4:Overview of D-CORE self-distillation stage. Through self-distillation, a LRM with task decomposition and subtask execution capabilities is acquired.",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x8.png",
                "caption": "(a)Std Distribution",
                "position": 362
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x8.png",
                "caption": "(a)Std Distribution",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x9.png",
                "caption": "(b)Token Entropy",
                "position": 370
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02160/x10.png",
                "caption": "Figure 6:Training dynamics comparison across GRPO and DA-GRPO on D-CORE-8B.",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x11.png",
                "caption": "(a)Four Behaviors",
                "position": 2807
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x11.png",
                "caption": "(a)Four Behaviors",
                "position": 2810
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x12.png",
                "caption": "(b)Address Lazy Reasoning",
                "position": 2815
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02160/x13.png",
                "caption": "Figure 8:Distribution analysis of reasoning processes from Qwen3-8B rollout experiments on the MATH dataset. (a) Probability density functions of reasoning process lengths for correct vs. incorrect answers. (b) Probability density functions of reflection counts in reasoning processes for correct vs. incorrect answers. (c) Distribution and fitted function of reflection words versus reasoning length.",
                "position": 3072
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x14.png",
                "caption": "Figure 9:Distribution analysis of reasoning processes from Qwen3-8B rollout experiments on the BFCLv3 multi-turn dataset. (a) Probability density functions of reasoning process lengths for correct vs. incorrect answers. (b) Probability density functions of reflection counts in reasoning processes for correct vs. incorrect answers. (c) Distribution and fitted function of reflection words versus reasoning length.",
                "position": 3075
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x15.png",
                "caption": "(a)Filtering Reflection on Qwen3-8B",
                "position": 3091
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x15.png",
                "caption": "(a)Filtering Reflection on Qwen3-8B",
                "position": 3094
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x16.png",
                "caption": "(b)Filering Length on Qwen3-8B",
                "position": 3100
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x17.png",
                "caption": "(c)Filtering Reflection on Qwen3-32B",
                "position": 3106
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x18.png",
                "caption": "(d)Filering Length on Qwen3-32B",
                "position": 3112
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x19.png",
                "caption": "Figure 11:Workflow of converting Lazy Reasoning process to Effective Reasoning process using decomposed prompting. The model is Qwen3-8B, and the example is from the first question of BFCLv3 Multi-Turn Base task.",
                "position": 3141
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x20.png",
                "caption": "Figure 12:Distribution of Standard Deviation, Mean, and Advantage during GRPO Training on Qwen3-8B at step 0.",
                "position": 3165
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x21.png",
                "caption": "Figure 13:Distribution of Standard Deviation, Mean, and Advantage during GRPO Training on Self Distillation Qwen3-8B at step 0.",
                "position": 3168
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x22.png",
                "caption": "(a)Top 25 tokens",
                "position": 3174
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x22.png",
                "caption": "(a)Top 25 tokens",
                "position": 3177
            },
            {
                "img": "https://arxiv.org/html/2602.02160/x23.png",
                "caption": "(b)Bottom 25 tokens",
                "position": 3183
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]