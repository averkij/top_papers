[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01415/x1.png",
                "caption": "",
                "position": 146
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01415/images/main.jpg",
                "caption": "Figure 2:RoboMemory architecture with working pipeline and memory mechanisms.\n(a) Left: The agent’s pipeline. Parallel Step Summarizer and Query Generator in Information Processor (1) generate updates/queries for Lifelong Embodied Memory (2). These memories enable Closed-Loop Planning (3) for tasks like “slice and pick up the apple”—the Planner generates plans, while the Critic and memories adjust decisions via feedback from visual inputs/results (4).\n(b) Right: Spatial and Semantic memories operate in parallel with isomorphic updates. Internally, Spatial memory maintains a relevance/similarity-updated KG, and Semantic memory manages a Vector DB with analogous logic.",
                "position": 216
            }
        ]
    },
    {
        "header": "3RoboMemory",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01415/images/error_analysis_simple.png",
                "caption": "Figure 3:The reason why RoboMemory failed to complete the task.",
                "position": 627
            },
            {
                "img": "https://arxiv.org/html/2508.01415/images/error_analysis_simple.png",
                "caption": "Figure 3:The reason why RoboMemory failed to complete the task.",
                "position": 630
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x2.png",
                "caption": "Figure 4:Visualization of the experimental environment.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x2.png",
                "caption": "Figure 4:Visualization of the experimental environment.",
                "position": 743
            },
            {
                "img": "https://arxiv.org/html/2508.01415/images/real_result.png",
                "caption": "Figure 5:The improvement of RoboMemory after learning in the real world.",
                "position": 748
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01415/images/habitat.png",
                "caption": "Figure 6:Comparison of Success Rates (SR) and Goal Condition Success Rates (GC) across difficulty levels between RoboBrain and baseline methods on EB-Habitat.",
                "position": 1407
            }
        ]
    },
    {
        "header": "Appendix BAdditional Environment settings",
        "images": []
    },
    {
        "header": "Appendix CProof of Dynamic Spatial Memory Update Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01415/x3.png",
                "caption": "Figure 7:Visualization of Spatial Memory’s dynamic update process.",
                "position": 1736
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x4.png",
                "caption": "Figure 8:Case that a task is failed but the experience can help RoboMemory to succeed in the next try.",
                "position": 1755
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x5.png",
                "caption": "Figure 9:Case that a task is successful.",
                "position": 1764
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x6.png",
                "caption": "Figure 10:Case that a task is successful with the help of the critic and spatial memory modules.",
                "position": 1780
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x7.png",
                "caption": "Figure 11:Case that a task fails in an infinite loop because the critic module failed to stop the agent when its planned action is no longer suitable.",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2508.01415/x8.png",
                "caption": "Figure 12:Case that a task fails in an infinite loop because of inaccurate action planning.",
                "position": 1802
            }
        ]
    },
    {
        "header": "Appendix DSupplementary Examples for Qualitative Analysis",
        "images": []
    }
]