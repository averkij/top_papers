[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/extracted/6297025/images/teaser.jpg",
                "caption": "",
                "position": 89
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x1.png",
                "caption": "Figure 2:(a) VDM exhibits different distribution with image DM with much larger percentage in VAE decoding. (b) FlashVDM enables fast shape generation within 1 second on a consumer GPU.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x2.png",
                "caption": "Figure 3:Illustration of four main stages of VDM.",
                "position": 192
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x3.png",
                "caption": "Figure 4:The corner cases in hierarchical volume decoding.",
                "position": 213
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x4.png",
                "caption": "Figure 5:Step-by-step case study of FlashVDM acceleration techniques and their effects on inference time and IoU.",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x5.png",
                "caption": "Figure 6:Histogram of activated token counts with non-zero attention of 70,800 regions from 250 cases.",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x6.png",
                "caption": "Figure 7:Normalized histogram of activated shape tokens with non-zero attention at different regions. Zoom in for a better view. The numbers in the legend indicate the number of activated tokens.",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x7.png",
                "caption": "Figure 8:Training pipeline for Progressive Flow Distillation.",
                "position": 300
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x8.png",
                "caption": "Figure 9:Visual comparison of shape reconstruction methods.",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x9.png",
                "caption": "Figure 10:Visual comparison of image-to-3D generation between the proposed FlashVDM and other fast 3D generation methods.",
                "position": 377
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x10.png",
                "caption": "Figure 11:Visual comparison of image-to-3D generation between the proposed FlashVDM and other 3D diffusion methods.",
                "position": 405
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x11.png",
                "caption": "Figure 12:Ablation study of our progressive flow distillation.",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x12.png",
                "caption": "Figure 13:User study of FlashVDM against different methods.",
                "position": 424
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BDetails of Hierarchical Volume Decoding",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x13.png",
                "caption": "Figure 14:Comparison of reconstruction results with and without dilate and tSDF strategy for hierarchical volume decoding.",
                "position": 624
            }
        ]
    },
    {
        "header": "Appendix CDetails of Adative KV Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x14.png",
                "caption": "Figure 15:Histogram of activated token counts within different regions, measured with 300 cases.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x15.png",
                "caption": "Figure 16:Histogram of the number of total activated token within all regions, measured with 200 cases.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x16.png",
                "caption": "Figure 17:The graph shows the relationship between volume IoU and the number of TopK tokens. r4 denotes the volume is divided into43superscript434^{3}4 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTsubvolumes, and r16 denotes163superscript16316^{3}16 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTsubvolumes.",
                "position": 660
            }
        ]
    },
    {
        "header": "Appendix DDetails of Diffusion Distillation",
        "images": []
    },
    {
        "header": "Appendix EMore Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16302/x17.png",
                "caption": "Figure 18:Visual comparison of modelswith and without guidance distillation warmup. The adversarial fine-tuning and Phase1 fine-tuning are not adopted. It demonstrates that the guidance distillation warmup is essential for successful distillation.",
                "position": 730
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x18.png",
                "caption": "Figure 19:Visual comparison of models trained withL2 and huber loss. The adversarial fine-tuning and Phase1 fine-tuning are not adopted. It demonstrates that the huber loss is significantly better than l2 loss, which we hypothesis that is due to huber loss is less sensitive to outliers so that stablizes the training and makes results better.",
                "position": 733
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x19.png",
                "caption": "Figure 20:Visual comparison of models trainedwith and without EMA. The adversarial fine-tuning and Phase1 fine-tuning are not adopted. It demonstrates that the meshes tend to be broken without EMA.",
                "position": 736
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x20.png",
                "caption": "Figure 21:Visual comparison of modelswith and without guidance distillation warmup. The adversarial fine-tuning and Phase1 fine-tuning are not adopted. It demonstrates that the guidance distillation warmup is essential for successful distillation.",
                "position": 739
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x21.png",
                "caption": "Figure 22:Visual comparison of modelswith and without adversarial finetuning. All other distillation stages are used. It demonstrates that the predicted meshes are more accurate and smooth after adversarial finetuning.",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x22.png",
                "caption": "Figure 23:Visual comparison of FlashVDM generation results with different sampling steps.",
                "position": 745
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x23.png",
                "caption": "Figure 24:Shape generation results of Hunyuan3D-2 Turbo distilled with the proposed FlashVDM. Image prompts are generated by HunyuanDiT[19]. The number of inference steps is 5.",
                "position": 748
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x24.png",
                "caption": "Figure 25:Texture generation results of Hunyuan3D-2 Turbo distilled with the proposed FlashVDM and Hunyuan3D-Paint-2[57]. Image prompts are generated by HunyuanDiT[19]. The number of inference steps is 5.",
                "position": 751
            },
            {
                "img": "https://arxiv.org/html/2503.16302/x25.png",
                "caption": "Figure 26:Comparison between FlashVDM (Hunyuan3D-2 Turbo) 5 steps and other fast 3D generation methods.",
                "position": 754
            }
        ]
    },
    {
        "header": "Appendix FLimitations and Future Works.",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]