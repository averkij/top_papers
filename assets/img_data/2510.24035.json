[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Dataset Properties",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24035/x1.png",
                "caption": "(a)Categories of Computational Graph",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2510.24035/x1.png",
                "caption": "(a)Categories of Computational Graph",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2510.24035/x2.png",
                "caption": "(b)Operator Numbers of CV Models",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2510.24035/x2.png",
                "caption": "(b)Operator Numbers of CV Models",
                "position": 146
            },
            {
                "img": "https://arxiv.org/html/2510.24035/x3.png",
                "caption": "(c)Operator Numbers of NLP Models",
                "position": 152
            }
        ]
    },
    {
        "header": "3Benchmark of Tensor Compilers",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24035/Figures/St-result.jpg",
                "caption": "Figure 2:Speedup ScoreStS_{t}on NVIDIA H20 for CV and NLP workloads.The vertical axis showsStS_{t}, which integrates speedup, pass rate, and failure penalties into a unified score. HigherStS_{t}indicates better compiler performance under the correctness-aware speedup metric defined in Equation1.\nThe horizontal axisttrepresents different numerical tolerance levels used for correctness checks, where largerttimplies more relaxed thresholds.",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2510.24035/Figures/ESt-result.jpg",
                "caption": "Figure 3:Error-aware Speedup ScoreE​StES_{t}for CV and NLP workloads.The vertical axis showsE​StES_{t}values, capturing compiler performance with increasing fault tolerance.\nHigherE​StES_{t}indicates better compiler performance under the error-tolerant speedup metric defined in Equation3.\nThe horizontal axisttrepresents different tolerance levels:\nfort≤0t\\leq 0, it reflects numerical correctness thresholds (as inStS_{t});\nfort>0t>0, it encodes the categories of tolerated errors:t≥1t\\geq 1tolerates accuracy mismatches,t≥2t\\geq 2tolerates runtime crashes,\nandt≥3t\\geq 3tolerates compilation failures.",
                "position": 320
            }
        ]
    },
    {
        "header": "4Construction of GraphNet",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24035/Figures/graphnet_overview.jpg",
                "caption": "Figure 4:GraphNet Workflow Overview.The workflow consists of three stages:\n(1)Graph Extraction: Traces and captures computational graphs from DL models (e.g., PaddlePaddle, PyTorch);\n(2)Graph Validation: Performs a consistency check via re-extraction and re-execution to ensure usability;\nand (3)Compiler Evaluation: Uses the validated graphs from the dataset to benchmark the runtime speedup and correctness of various compiler backends.",
                "position": 393
            },
            {
                "img": "https://arxiv.org/html/2510.24035/Figures/dataset_composition.png",
                "caption": "Figure 5:GraphNet Sample Composition.A user’s model (left), wrapped by the@graph_netextractor, is symbolically traced to generate a standardized set of files.\nThis set forms a complete sample, including the high-level IR of the computation graph (model.py), metadata for inputs and weights (input_meta.py,weight_meta.py), and other components such as optional custom operator code.",
                "position": 426
            }
        ]
    },
    {
        "header": "5Background and Related Works",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "7Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AConfiguration of atol(t) and rtol(t)",
        "images": []
    },
    {
        "header": "Appendix BSample-level Interpretation ofStS_{t}",
        "images": []
    },
    {
        "header": "Appendix CSample-level Interpretation ofE​StES_{t}",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24035/Figures/Violin-eval-result.png",
                "caption": "Figure 6:Violin Plots of Per-sample Speedups (log2(speedup)).It shows distribution of per-sample speedups under correctness checkst=0t=0.\nEach violin shows the speedup spread for a compiler-task pair. Wider regions denote more frequent speedup values.\nSamples with log2(speedup) <0 indicate performance degradation.",
                "position": 1322
            }
        ]
    },
    {
        "header": "Appendix DDetails of Benchmark Experiments",
        "images": []
    }
]