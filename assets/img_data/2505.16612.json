[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16612/x1.png",
                "caption": "Figure 1:We compareprompt-based approacheswithsteering techniquesintervening on model internals for personalizing MT outputs in literary machine translation, employing MT quality metrics and style classifiers to disentangle the effect of steering on outputs fluency and personalization adequacy.",
                "position": 134
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16612/x2.png",
                "caption": "",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x3.png",
                "caption": "",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x4.png",
                "caption": "",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x5.png",
                "caption": "Table 2:Classifier-based personalization accuracy () and Comet-based translation quality () for zero-shot (ZS) and multi-shot (MS) prompting with 20 in-context examples averaged across all translators and languages.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x6.png",
                "caption": "",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x7.png",
                "caption": "",
                "position": 341
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x8.png",
                "caption": "",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x9.png",
                "caption": "",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x10.png",
                "caption": "",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x13.png",
                "caption": "",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x14.png",
                "caption": "",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x15.png",
                "caption": "",
                "position": 372
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x16.png",
                "caption": "",
                "position": 372
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x17.png",
                "caption": "",
                "position": 372
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x18.png",
                "caption": "Figure 2:Probing classifier performance on the human translation detection task across Gemma 2 2B layers. Activations in intermediate layers are found to capture translation style information with high precision, with layer 13 performing best across all tested languages.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x19.png",
                "caption": "",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x20.png",
                "caption": "",
                "position": 382
            }
        ]
    },
    {
        "header": "4Methods",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16612/x21.png",
                "caption": "Table 3:Averaged metric scores across all tested languages (per-language breakdown inAppendixC).H: human style accuracy, i.e.p(p(italic_p (H1)+p()+p() + italic_p (H2)))).P: personalization accuracyp‚Å¢(Hx)ùëùsubscriptùêªùë•p(H_{x})italic_p ( italic_H start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT )for the target style.Pflipflip{}_{\\textsc{flip}}start_FLOATSUBSCRIPT flip end_FLOATSUBSCRIPT: Proportion of segments for which steering has a causal impact on personalization.Œ±=5ùõº5\\alpha=5italic_Œ± = 5is used for SAE Cont. results.",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x22.png",
                "caption": "",
                "position": 558
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x23.png",
                "caption": "",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x24.png",
                "caption": "",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x25.png",
                "caption": "",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x26.png",
                "caption": "",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x27.png",
                "caption": "",
                "position": 698
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x28.png",
                "caption": "",
                "position": 705
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x29.png",
                "caption": "",
                "position": 708
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x30.png",
                "caption": "",
                "position": 708
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x31.png",
                "caption": "Figure 3:PersonalizationPandCometacross various steering intensityŒ±ùõº\\alphaitalic_Œ±for SAE Cont.hton Gemma 2 2B. The performance of prompting baselines (ZS, MS, Exp) is also reported. Results show a trade-off between steering intensity and translation quality.",
                "position": 710
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x33.png",
                "caption": "",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2505.16612/",
                "caption": "Figure 4:CometandHaccuracy acrossŒ±ùõº\\alphaitalic_Œ±steering intensity values for Gemma 2 2B, showing a major drop in translation quality for very high intensities (Œ±‚â•50ùõº50\\alpha\\geq 50italic_Œ± ‚â• 50).",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x36.png",
                "caption": "",
                "position": 714
            }
        ]
    },
    {
        "header": "6Conclusion and future work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AList of novels used",
        "images": []
    },
    {
        "header": "Appendix BExperiments reproducibility",
        "images": []
    },
    {
        "header": "Appendix CAll models results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16612/x37.png",
                "caption": "",
                "position": 1912
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x38.png",
                "caption": "Figure 5:Probing classifier performance on the human translation detection task accross Gemma 2 9B layers. For our experiments we select layer 21 as the optimal intervention point for our steering approaches.",
                "position": 1914
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x39.png",
                "caption": "",
                "position": 1982
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x40.png",
                "caption": "Figure 6:Results for every language on Gemma 2 2B.",
                "position": 1984
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x41.png",
                "caption": "Figure 7:Results for every language on Gemma 2 9B.",
                "position": 1987
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x42.png",
                "caption": "Figure 8:Results for every language on Llama 3.1 8B.",
                "position": 1990
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x43.png",
                "caption": "",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x44.png",
                "caption": "",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x45.png",
                "caption": "",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x46.png",
                "caption": "",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x47.png",
                "caption": "Table 7:Example paragraphs from ‚ÄúDream of the Red Chamber‚Äù (ZH‚Üí‚Üí\\rightarrow‚ÜíEN) translated withH1personalization. Setup outputs are from Gemma 2 2B; only MS and SAE Cont.ptsuccessfully flip theclassifier‚Äô prediction.",
                "position": 2001
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x48.png",
                "caption": "",
                "position": 2022
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x50.png",
                "caption": "",
                "position": 2357
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x51.png",
                "caption": "Table 8:Example paragraphs from ‚ÄúPinocchio‚Äù (IT‚Üí‚Üí\\rightarrow‚ÜíEN) translated withH2personalization. Setup outputs are from Gemma 2 9B; ZS-Exppt, MS, SAE Cont.htand SAE Cont.pt(bothŒ±=5ùõº5\\alpha=5italic_Œ± = 5) can flip theclassifier prediction.",
                "position": 2359
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x52.png",
                "caption": "",
                "position": 2380
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x54.png",
                "caption": "",
                "position": 2714
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x55.png",
                "caption": "Table 9:Examples from different languages being classified as Human when usingextremeŒ±ùõº\\alphaitalic_Œ±values.",
                "position": 2716
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x56.png",
                "caption": "",
                "position": 2737
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x57.png",
                "caption": "",
                "position": 2874
            },
            {
                "img": "https://arxiv.org/html/2505.16612/x58.png",
                "caption": "",
                "position": 2879
            }
        ]
    },
    {
        "header": "Appendix DExamples from dataset and different approaches",
        "images": []
    }
]