[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12769/x1.png",
                "caption": "Figure 1:Examples of some actions in Visual Instruction Feedback task, which are Visual Wake-Up, Visual Reference, Visual Interruption, and Visual Termination in order. The content in parentheses is displayed by body language instead of text or speech.",
                "position": 93
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Visual Instruction Feedback Task",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12769/x2.png",
                "caption": "Figure 2:ViSpeak is an omni-modality LMM with multiple encoders and a LLM. To support streaming video analysis, ViSpeak takes two input streams as inputs, one for user inputs and one for self-generated outputs. Two streams will be combined into a single one before sending to LLM. An informative head is trained for visual proactive output.",
                "position": 516
            }
        ]
    },
    {
        "header": "4The ViSpeak Model",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7More Details for ViSpeak-Bench and ViSpeak-Instruct",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12769/extracted/6284660/images/personnel_information.jpg",
                "caption": "Figure 3:Statistics on participants who recorded videos. The participants comprised nearly equal numbers of males and females, with ages ranging from 10 to 70 years.",
                "position": 2928
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x3.png",
                "caption": "Figure 4:Examples of Visual Wake-Up in ViSpeak-Bench and the corresponding output by ViSpeak.",
                "position": 3275
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x4.png",
                "caption": "Figure 5:Examples of Visual Termination in ViSpeak-Bench and the corresponding output by ViSpeak. The first round conversation is used as context.",
                "position": 3278
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x5.png",
                "caption": "Figure 6:Examples of Visual Interruption in ViSpeak-Bench and the corresponding output by ViSpeak. The first round conversation is used as context.",
                "position": 3281
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x6.png",
                "caption": "Figure 7:Examples of Gesture Understanding in ViSpeak-Bench and the corresponding output by ViSpeak. The first round conversation is used as context.",
                "position": 3284
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x7.png",
                "caption": "Figure 8:Examples of Anomaly Warning in ViSpeak-Bench and the corresponding output by ViSpeak.",
                "position": 3287
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x8.png",
                "caption": "Figure 9:Examples of Humor Reaction in ViSpeak-Bench and the corresponding output by ViSpeak.",
                "position": 3290
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x9.png",
                "caption": "Figure 10:Examples of Visual Reference in ViSpeak-Bench and the corresponding output by ViSpeak.",
                "position": 3293
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x10.png",
                "caption": "Figure 11:Examples of our self-annotated data for gesture understanding.",
                "position": 3296
            },
            {
                "img": "https://arxiv.org/html/2503.12769/x11.png",
                "caption": "Figure 12:Examples of failure cases. The ‘Time Mistake’ denotes the model responds at an improper time. The ‘Content Mistake’ denotes the model fails to understand the visual content in the video. The ‘Context Mistake’ means the model is unaware of the context of the conversation.",
                "position": 3299
            }
        ]
    },
    {
        "header": "8Limitation",
        "images": []
    }
]