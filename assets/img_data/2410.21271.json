[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21271/x1.png",
                "caption": "Figure 1:The proposed EoRA method tackles LLM model compensation by first projecting the compression error into the eigenspace of output activations. Leveraging PCA, we compute the eigenvalues, which serve as weights to prioritize columns in the weight matrix for error approximation. By adopting EoRA, users can achieve significantly better compensated compressed LLMs in just a few minutes, requiring only a small amount of calibration data. For instance, the LLaMA3-8B model pruned to50%percent5050\\%50 %sparsity compensated with EoRA of rank 128 can narrow the accuracy gap to the uncompressed model to as low as only6.82%percent6.826.82\\%6.82 %and5.2%percent5.25.2\\%5.2 %accuracy loss on ARC-C and MathQA.",
                "position": 88
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method: Training-freeEigenspace Low-RankApproximation (EoRA)",
        "images": []
    },
    {
        "header": "4EXPERIMENTS",
        "images": []
    },
    {
        "header": "5RELATED WORK",
        "images": []
    },
    {
        "header": "6CONCLUSION",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]