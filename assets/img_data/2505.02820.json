[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/microscope.png",
                "caption": "",
                "position": 51
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/ladder.png",
                "caption": "",
                "position": 59
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/x1.png",
                "caption": "Figure 1:AutoLibrainduces agent evaluation metrics from human feedback, and uses these metrics to evaluate agents, which can be meta-evaluated via evaluating the coverage on unseen human feedback. Here we show real examples of agent trajectories, human feedback, aspects, induced metrics, evaluation results on WebVoyager(He et al.,2024).",
                "position": 140
            }
        ]
    },
    {
        "header": "2AutoLibra",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/x2.png",
                "caption": "Figure 2:Feedback Grounding",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2505.02820/x3.png",
                "caption": "Figure 3:Behavior Clustering",
                "position": 285
            },
            {
                "img": "https://arxiv.org/html/2505.02820/x4.png",
                "caption": "Figure 4:Evaluating agents withinduced metrics",
                "position": 336
            },
            {
                "img": "https://arxiv.org/html/2505.02820/x5.png",
                "caption": "Figure 5:Meta evaluation",
                "position": 363
            }
        ]
    },
    {
        "header": "3Optimizing and validating AutoLibra",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/x6.png",
                "caption": "Figure 6:Metric optimization: optimizing the induction process through maximizing the coverage while minimizing redundancy of the metrics, calculated via the evaluation process.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2505.02820/x7.png",
                "caption": "Figure 7:Coverage and redundancy of AutoLibra metrics on four agentic datasets. Circles indicate coverage and redundancy for different induced metrics; stars indicate the the best metrics’ coverage and redundancy on held-out human feedback; squares show an ablation test, indicating the effect when good and bad behavior examples are removed from metrics, demonstrating the criticality of concrete behavior examples",
                "position": 399
            }
        ]
    },
    {
        "header": "4AutoLibra as a lens: agent evaluation with AutoLibra",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/scale.png",
                "caption": "Table 2:Comparison between AutoLibra-induced metrics and expert proposed evaluation dimensions and failure categories. The percentages in parenthesis denote frequency of -1 in AutoLibra-induced metrics, and failure frequency or score from the original papers.",
                "position": 497
            }
        ]
    },
    {
        "header": "5AutoLibra as a ladder: Agent improvement with AutoLibra",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/x8.png",
                "caption": "Figure 8:AutoLibra iteratively discovers new optimization targets throughout the agent optimization process. Each emoji pair represents an induced metric; the arrows and text between iterations represents the changes made to prompts informed by metrics. Purple boxes indicate the newly emerging metrics, and green arrows indicate significant improvements over the previous iteration. The metric names can be found in Tab.4and App. Tab.10.",
                "position": 871
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_1.png",
                "caption": "Table 4:Metrics and Turn of Inductionfor Baba-Is-AI",
                "position": 891
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_2.png",
                "caption": "",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_3.png",
                "caption": "",
                "position": 912
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_4.png",
                "caption": "",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_5.png",
                "caption": "",
                "position": 922
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_6.png",
                "caption": "",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_7.png",
                "caption": "",
                "position": 932
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_8.png",
                "caption": "",
                "position": 937
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_9.png",
                "caption": "",
                "position": 942
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Limitation and Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Content of Appendix",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm of AutoLibra Ladder Experiment",
        "images": []
    },
    {
        "header": "Appendix BAutoLibra Ladder Experiment Setup",
        "images": []
    },
    {
        "header": "Appendix CBaba-is-ai Rules and Environment Configuration",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/babaisai_env.png",
                "caption": "Figure 9:Example of the baba-is-ai environment. In this task (two_room-break_stop-make_win-distr_obj-irrelevant_rule), the agent has to break the \"wall is stop\" rule by pushing either ’wall’, ’is’, or ’stop’ out of alignment with the other blocks, and must then push the \"key\" rule block next to \"is win\" at (9, 1) to assemble the win rule, then touch the key at (7, 7) to win. Pushing the \"door\" rule block would be a mistake, as no door object is present.",
                "position": 1940
            }
        ]
    },
    {
        "header": "Appendix DBaba-is-ai Experiment Results",
        "images": []
    },
    {
        "header": "Appendix EBaba-is-ai Metric Scores",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/emoji_1.png",
                "caption": "Table 6:Metric Performance for baba-is-ai AutoLibra Iterations 0–3, Across Full (40) Environment Tasks",
                "position": 2085
            }
        ]
    },
    {
        "header": "Appendix FBaba-is-ai Metric Examples",
        "images": []
    },
    {
        "header": "Appendix GBaba-is-ai Prompts",
        "images": []
    },
    {
        "header": "Appendix HQualitative Observations of baba-is-ai Agent Performance",
        "images": []
    },
    {
        "header": "Appendix IMiniHack Rules and Environment Configuration",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/maps.png",
                "caption": "Figure 10:Overview of representative tasks used in MiniHack agent optimization process with AutoLibra.\nFrom left to right, up to down: (1)Boxoban, (2)MazeWalk, (3)Corridor Fight, and (4)Quest.",
                "position": 3767
            }
        ]
    },
    {
        "header": "Appendix JMiniHack Experiment Results",
        "images": []
    },
    {
        "header": "Appendix KMiniHack Metric Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_1.png",
                "caption": "Table 8:Metric Performance for MiniHack AutoLibra Iterations 0–2",
                "position": 3850
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_2.png",
                "caption": "",
                "position": 3887
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_3.png",
                "caption": "",
                "position": 3902
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_4.png",
                "caption": "",
                "position": 3917
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_5.png",
                "caption": "",
                "position": 3932
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_6.png",
                "caption": "",
                "position": 3947
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_7.png",
                "caption": "",
                "position": 3962
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_8.png",
                "caption": "",
                "position": 3977
            },
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_9.png",
                "caption": "",
                "position": 3992
            }
        ]
    },
    {
        "header": "Appendix LMiniHack Metric Examples",
        "images": []
    },
    {
        "header": "Appendix MMiniHack Prompts",
        "images": []
    },
    {
        "header": "Appendix NQualitative Observations of MiniHack Agent Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02820/extracted/6405651/figs/emojis/mini_1.png",
                "caption": "Table 9:Metrics and Turn of Induction for MiniHack",
                "position": 6052
            }
        ]
    },
    {
        "header": "Appendix ONNetNav-Live Induced Metrics",
        "images": []
    }
]