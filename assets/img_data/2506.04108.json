[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04108/x1.png",
                "caption": "Figure 1:Sparse decoding performance becomes worse with increasing decoding length due to error accumulation of KV cache.",
                "position": 123
            }
        ]
    },
    {
        "header": "2Rectified Sparse Attention",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04108/x2.png",
                "caption": "Figure 2:Overview of ReSA. After completing the prefill stage, the model enters sparse decoding. Once the number of generated tokens reaches the rectification frequency, a rectification step is performed to construct a lossless compact KV cache, after which sparse decoding resumes.",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x3.png",
                "caption": "Figure 3:Overview of Group Block Sparse Attention. For each group of query heads, we perform average pooling and enforce the selection of the same KV blocks across all heads within the group.",
                "position": 185
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04108/x4.png",
                "caption": "Table 1:Performance comparison on math reasoning tasks. While simple sparse decoding methods show a gap with dense decoding, ReSA achieves near lossless long-sequence generation.",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x4.png",
                "caption": "Figure 4:Top-3 next-token prediction accuracy with different rectification frequency.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x4.png",
                "caption": "Figure 4:Top-3 next-token prediction accuracy with different rectification frequency.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x5.png",
                "caption": "Figure 5:Top-3 next-token prediction accuracy with different sparsity ratio.",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x6.png",
                "caption": "Figure 6:Kernel-level latency breakdown across different sequence lengths. While Sparse Decoding achieves effective acceleration, rectification only requires a small additional overhead.",
                "position": 610
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x7.png",
                "caption": "Figure 7:End-to-end latency with FP16.",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x7.png",
                "caption": "Figure 7:End-to-end latency with FP16.",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x8.png",
                "caption": "Figure 8:End-to-end latency with INT4.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2506.04108/x9.png",
                "caption": "Figure 9:Ablation studies on different rectification frequenciesfùëìfitalic_fand sparsity ratiospùëùpitalic_pacross five math reasoning benchmarks. ReSA consistently improves over the sparse baseline. Frequenciesf=32ùëì32f=32italic_f = 32orf=64ùëì64f=64italic_f = 64achieve the best trade-off between performance and overhead.",
                "position": 655
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]