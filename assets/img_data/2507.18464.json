[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3DriftMoE: Architecture and Training Procedure",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18464/x1.png",
                "caption": "Figure 1:Prequential accuracy (%) of baseline learners and DriftMoE variants across the nine benchmark datasets",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2507.18464/extracted/6650333/figures/led_g_accuracy.png",
                "caption": "Figure 2:Accuracy over time plot for LEDgdataset",
                "position": 915
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18464/extracted/6650333/figures/experts_heatmap.png",
                "caption": "Figure 3:Grid search on the LED stream showing prequential accuracy\nas a function of the number of expertsNùëÅNitalic_Nand the gating\nparameterTop-‚Å¢KTop-ùêæ\\text{Top-}KTop- italic_K. The plateau at(N=12,Top-‚Å¢K=3)formulae-sequenceùëÅ12Top-ùêæ3(N{=}12,\\text{Top-}K{=}3)( italic_N = 12 , Top- italic_K = 3 )motivates our fixed configuration used in4.1",
                "position": 935
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]