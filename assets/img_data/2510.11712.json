[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x1.png",
                "caption": "Figure 1:Visualization ofDiT360â€™s results. The shown examples include text-to-panorama generation, inpainting, and outpainting, together with comparisons against existing methods.",
                "position": 106
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x2.png",
                "caption": "Figure 2:Overview of theDiT360hybrid training pipeline.\nFor the perspective branch, we employ (a) perspective image re-projection to transfer perspective knowledge to panoramic domain.\nFor the panoramic branch, we first apply (b) panoramic refinement to remove polar blurring and then introduce (c) position-aware circular padding, (d) rotation-consistent yaw loss and (e) distortion-aware cube loss for token-level hybrid supervision.",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2510.11712/x3.png",
                "caption": "Figure 3:Panoramic image refinement pipeline. The ERP panorama is converted into a cubemap, where pre-defined masks are applied to the central regions of the top and bottom faces. These masked regions are then reconstructed with an inpainting model and reprojected to ERP. In the figure, orange boxes represent blurry areas, and red dashed boxes indicate inpainted cubes.",
                "position": 242
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x4.png",
                "caption": "Figure 4:Qualitative comparisons on panorama generation. The representative artifacts are highlighted with red boxes. More complete results are provided inappendixD.",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2510.11712/x5.png",
                "caption": "Figure 5:Ablation results of different settings. Artifacts are marked by color-coded bounding boxes: red for spurious details, yellow for boundary discontinuities, and green for incorrect distortions.",
                "position": 449
            }
        ]
    },
    {
        "header": "5conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AEffect of Supervision on Polar Distortions",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x6.png",
                "caption": "Figure 6:Qualitative comparison of generated panoramas and their top/bottom cube faces without (left) and with (right) cube loss. Red boxes mark regions where polar artifacts are significantly reduced when supervision is applied.",
                "position": 1853
            }
        ]
    },
    {
        "header": "Appendix BInpainting and Outpainting",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x7.png",
                "caption": "Figure 7:More results on inpainting and outpainting.",
                "position": 1871
            }
        ]
    },
    {
        "header": "Appendix CExperiment Settings",
        "images": []
    },
    {
        "header": "Appendix DFull Comparision",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x8.png",
                "caption": "Figure 8:The full qualitative comparison on panorama generation. We highlight representative artifacts with red boxes.",
                "position": 1915
            }
        ]
    },
    {
        "header": "Appendix EUser Study",
        "images": []
    },
    {
        "header": "Appendix FMore Results",
        "images": []
    },
    {
        "header": "Appendix GUse of Large Language Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11712/x9.png",
                "caption": "Figure 9:More results on text-to-panorama generation.",
                "position": 2003
            },
            {
                "img": "https://arxiv.org/html/2510.11712/x10.png",
                "caption": "Figure 10:More results on text-to-panorama generation.",
                "position": 2006
            }
        ]
    },
    {
        "header": "Appendix HLimitations and Future Work",
        "images": []
    }
]