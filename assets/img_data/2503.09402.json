[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x1.png",
                "caption": "Figure 1:Key Idea of VLog.In contrast to existing video-language models that rely on token-by-token generation on language’s subword vocabulary, VLog introduces a novelgenerative retrieval method based on a narration vocabulary, achieving a significant speedup (10×\\times×) when processing long videos.",
                "position": 101
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x2.png",
                "caption": "Figure 2:Comparison between different Video-Language model architectures:(a) Generative Models:These model with complex reasoning but are slow, generating tokens one by one.(b) Retrieval Models:These enable fast vocabulary search but lack reasoning, useful only for simple alignment tasks.(c) Generative Retrieval (VLog):This approach combines fast vocabulary search with complex reasoning by using a retrieval token, merging the advantages of both methods.",
                "position": 195
            }
        ]
    },
    {
        "header": "3VLog",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x3.png",
                "caption": "Figure 3:Illustration of our Vocabulary Construction and Indexing.Upper side:Given the narrations, we process them using our NPE method, breaking down each narration into prefix and postfix parts.Lower side:For efficient indexing, we organize the vocabulary hierarchically, where first-level scenes help navigate subsets of prefix narrations. Next, we append the prefix and continue retrieving the postfix.",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x4.png",
                "caption": "Figure 4:Create video-text pairs that requires complex reasoningfrom untrimmed videos based on their temporal relationship.",
                "position": 375
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x5.png",
                "caption": "Figure 5:Agentic workflow of VLog Vocabulary upgrade.\nWhen a low retrieval score is detected, the visual inputs are sent to the LMM (LLaVA-OV-0.5B[22]) to generate scene descriptions. These descriptions are then processed by the LLM (Qwen2.5-0.5B[47]), which expands and updates the existing vocabulary.",
                "position": 402
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x6.png",
                "caption": "Figure 6:Ablation of Vocabulary Indexing Strategy",
                "position": 911
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x6.png",
                "caption": "Figure 6:Ablation of Vocabulary Indexing Strategy",
                "position": 914
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x7.png",
                "caption": "Figure 7:Ablation of Reference Video Number",
                "position": 920
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x8.png",
                "caption": "Figure 9:Illustration of VLog’s full decoding process.",
                "position": 1035
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x9.png",
                "caption": "Figure 10:Illustration of VLog’s progressively decode prefix and postfix vocabulary respectively.",
                "position": 1070
            }
        ]
    },
    {
        "header": "Appendix BQualitative Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09402/x10.png",
                "caption": "Figure 11:VLog still fail to capture the video with broad descriptive range or high-level informatione.g.characters.",
                "position": 1369
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x11.png",
                "caption": "Figure 12:VLog enables retrieval through reasoning, conditioned on different queries. Blue represents prefixes, while green represents postfixes.",
                "position": 1376
            },
            {
                "img": "https://arxiv.org/html/2503.09402/x12.png",
                "caption": "Figure 13:Illustration of VLog’s vocabulary updating process.Given the first frame of a video clip, LLaVA-OV[22]provides a brief initial description, which is then passed to Qwen2.5[47]to generate and expand the possible vocabulary.",
                "position": 1379
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]