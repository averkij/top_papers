[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x1.png",
                "caption": "Figure 1:Performance of our model against state-of-the-art methods on diverse visual reasoning benchmarks.The chart compares PC-GRPO model (Ours) with strong baselines, including Qwen-2.5-VL-7B base model. Each axis represents a different benchmark. Our method achieves competitive or superior results across the board, demonstrating that the supervision-free puzzle curriculum effectively enhances the model’s visual reasoning capabilities. Additionally, the reasoning abilities of PC-GRPO reveal critical levels of noise in popular vision benchmarks. We audit and clean some of these benchmarks (denoted with the _clean suffix) using high performance VLMs. We then benchmark PC-GRPO and existing baselines on the clean subsets.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x2.png",
                "caption": "Figure 2:PC-GRPO overcomes fundamental reasoning failures in VLMsWhen asked a simple visual reasoning question, existing GRPO-tuned models often fail byoverthinking irrelevant details, shortcutting to a statistically likely but incorrect answer, or producing a final answer that contradicts their own reasoning trace. PC-GRPO learns to produce afaithful and visually-grounded answer.",
                "position": 147
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x3.png",
                "caption": "Figure 3:An overview of our GRPO post-training framework.The process starts with input puzzles which are dynamically weighted by difficulty using a curriculum learning approach. The agent iteratively generates solutions over multiple rounds. These solutions are evaluated using GRPO rewards, which in turn are used for policy evolution. We track reasoning-answer consistency during post-training and show that PC-GRPO boosts RAC and downstream performance.",
                "position": 216
            }
        ]
    },
    {
        "header": "4Benchmark Auditing",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x4.png",
                "caption": "Figure 4:Examples of three major types ofannotation noisein vision-centric benchmarks.User studies show that10%∼20%10\\%\\sim 20\\%samples are noisy in these benchmarks. Nevertheless, our proposed method learns to producefaithful and visually-grounded answers. Left image taken from MME by Fu et al. is licensed for academic use (Source). Middle image taken from MMStar by Chen et al. is licensed under CC BY 4.0 (Source). Right image taken from MMBench by Liu et al. is licensed under Apache 2.0 (Source).",
                "position": 326
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x5.png",
                "caption": "(a)Reward variance",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x5.png",
                "caption": "(a)Reward variance",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x6.png",
                "caption": "(b)Reasoning-answer consistency",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x7.png",
                "caption": "(c)Response length (in tokens)",
                "position": 418
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x8.png",
                "caption": "(d)Reward score",
                "position": 423
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x9.png",
                "caption": "Table 1:Performance on vision-centric benchmarks with 7B baselines. Jigsaw and Rotation setups within our PC-GRPO framework outperform other annotation-free baselines; which indicates the impact of our curriculum training and the importance of reasoning-answer consistency. CL denotes our curriculum learning.",
                "position": 446
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AAdditional Discussion and Details on our Puzzles",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x9.png",
                "caption": "Figure S1:Example Jigsaw puzzle used in PC-GRPO training. The image taken from the Microsoft COCO dataset by Lin et al. is licensed under CC BY 4.0. Source:https://cocodataset.org/.",
                "position": 1978
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x10.png",
                "caption": "Figure S2:Example Rotation puzzle used in PC-GRPO training. The image taken from the Microsoft COCO dataset by Lin et al. is licensed under CC BY 4.0. Source:https://cocodataset.org/.",
                "position": 1981
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x11.png",
                "caption": "Figure S3:Example PatchFit puzzle used in PC-GRPO training. The image taken from the Microsoft COCO dataset by Lin et al. is licensed under CC BY 4.0. Source:https://cocodataset.org/.",
                "position": 1984
            }
        ]
    },
    {
        "header": "BExperimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x12.png",
                "caption": "Figure S4:Prompt for measuring Reasoning-Answer Consistency (RAC).",
                "position": 2037
            }
        ]
    },
    {
        "header": "CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14944/x13.png",
                "caption": "Table S1:Performance of PC-GRPO variants and other 7B baselines on vision-centric benchmarks under a direct-mode prompt that requests a single-letter or single-word answer, without explicit CoT.",
                "position": 2053
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x13.png",
                "caption": "Table S2:Qwen-VL-2.5 3B: comparison between our PC-GRPO variants and baselines under CoT prompting. Our approach yields consistent improvements and indicates scalability across model sizes.",
                "position": 2242
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x13.png",
                "caption": "(a)MMStar[7]",
                "position": 2364
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x13.png",
                "caption": "(a)MMStar[7]",
                "position": 2367
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x14.png",
                "caption": "(b)SEEDBench[37]",
                "position": 2373
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x15.png",
                "caption": "(c)ColorBench[39]",
                "position": 2379
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/user_study_gui.png",
                "caption": "Figure S6:The User Study Interface for Benchmark Auditing.Participants were shown an image and a question and asked to provide an answer as a probability distribution across the available choices. By using sliders to allocate percentages, users could express nuanced confidence. The interface includes a ”None of the above / cannot decide” option to explicitly capture ambiguity in the benchmarks. Image taken from the SEED-Bench dataset by Li et al. is licensed under CC BY-NC 4.0. Source:https://github.com/AILab-CVC/SEED-Bench.",
                "position": 2392
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/133_v3.png",
                "caption": "(a)What is the overall theme of the image?\nA: Beach vacation, B: Athletic lifestyle, C: Summer fashion, D: Urban street styleBenchmark Annotation: CUser Study: A: 1%, B: 2%, C: 35%,D: 47%, E: 15%",
                "position": 2456
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/133_v3.png",
                "caption": "(a)What is the overall theme of the image?\nA: Beach vacation, B: Athletic lifestyle, C: Summer fashion, D: Urban street styleBenchmark Annotation: CUser Study: A: 1%, B: 2%, C: 35%,D: 47%, E: 15%",
                "position": 2459
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/71_markup_v3.png",
                "caption": "(b)What is the fraction of females facing the camera?\nA: 0, B: 1, C: 0.8, D: 0.2Benchmark Annotation: CUser Study: A: 0.0%,B: 47%, C: 45%, D: 0%, E: 8%",
                "position": 2467
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/74.jpg",
                "caption": "(c)How many women are present in the image?\nA: 0, B: 1, C: 2, D: 3Benchmark Annotation: CUser Study: A: 0.0%,B: 73%, C: 27%, D: 0.0%, E: 0.0%",
                "position": 2477
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/76.jpg",
                "caption": "(d)If you were to sit on the chair closest to the window, which color would the chair be?\nA: Green, B: Blue, C: Red, D: WhiteBenchmark Annotation: AUser Study: A: 27%,B: 67%, C: 0%, D: 0%, E: 6%",
                "position": 2486
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/38.jpg",
                "caption": "(e)What is the image primarily displaying?\nA: Architecture, B: Animals, C: Interior design, D: LandscapingBenchmark Annotation: CUser Study: A:71%, B: 0%, C: 16%, D: 4%, E: 9%",
                "position": 2496
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MMStar/63.jpg",
                "caption": "(f)What is the main color of the large neon sign in the image?\nA: Black, B: White, C: Pink, D: RedBenchmark Annotation: CUser Study: A: 0%, B: 0%, C: 29%,D: 45%, E: 26%",
                "position": 2505
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/63856.jpg",
                "caption": "(a)What is the most noticeable feature of the image?\nA: The ocean, B: The dining table, C: The sunset, D: The chairsBenchmark Annotation: BUser Study: A: 11%, B: 37%,C: 51%, D: 1%, E: 0.0",
                "position": 2516
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/63856.jpg",
                "caption": "(a)What is the most noticeable feature of the image?\nA: The ocean, B: The dining table, C: The sunset, D: The chairsBenchmark Annotation: BUser Study: A: 11%, B: 37%,C: 51%, D: 1%, E: 0.0",
                "position": 2519
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/19488.png",
                "caption": "(b)Where is the man in a uniform positioned in the court in relation to the player with the ball?\nA: Behind the player with the ball, B: To the right of the player with the ball, C: To the left of the player with the ball, D: In front of the player with the ballBenchmark Annotation: BUser Study: A: 4%, B: 20%,C: 36%, D: 12%, E: 27",
                "position": 2528
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/13488.png",
                "caption": "(c)Where is the grass on the birthday cake located? A: It’s not shown in the image, B: In the middle, C: In the corners, D: Around the edgesBenchmark Annotation: BUser Study: A: 0%, B: 47%, C: 0%, D: 0%0,E: 53%",
                "position": 2538
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/84847.jpg",
                "caption": "(d)What type of furniture is located in the center of the room in the image?\nA: Coffee table, B: Desk, C: Dining table, D: Side tableBenchmark Annotation: BUser Study:A: 56%, B: 0%, C: 44%, D: 0%, E: 0%",
                "position": 2546
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/12416.jpg",
                "caption": "(e)What is the main feature in the background of the image? A: A park bench near the water, B: A couple sitting on a bench, C: A body of water and the Golden Gate Bridge, D: A mountain in the distance.Benchmark Annotation: BUser Study: A: 1%, B: 14%,C: 53%, D: 32%, E: 0%",
                "position": 2556
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/SEEDBench/30778.jpg",
                "caption": "(f)How would you describe the color of the sand in the image?\nA: Dark brown, B: White, C: Light gray, D: GoldenBenchmark Annotation: AUser Study: A: 22%, B: 0%, C: 0%,D: 75%, E: 3%",
                "position": 2564
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/GQA/gqa1_markup_v3.png",
                "caption": "(a)Who’s weaning the dress?Benchmark Annotation: Woman",
                "position": 2575
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/GQA/gqa1_markup_v3.png",
                "caption": "(a)Who’s weaning the dress?Benchmark Annotation: Woman",
                "position": 2578
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/GQA/gqa2_markup_v3.png",
                "caption": "(b)How tall is the chair in the bottom of the photo?Benchmark Annotation: Short",
                "position": 2585
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/GQA/gqa3.png",
                "caption": "(c)What kind of device is on top of the desk?Benchmark Annotation: Keyboard",
                "position": 2593
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/GQA/gqa5.png",
                "caption": "(d)What is around the open window?Benchmark Annotation: Drapes",
                "position": 2600
            },
            {
                "img": "https://arxiv.org/html/2512.14944/x16.png",
                "caption": "(e)Who is standing at the table?Benchmark Annotation: Woman",
                "position": 2608
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/ChartQA/chartqa1.png",
                "caption": "(a)What’s the ratio(A:B) of yellow bar and blue bar for Ages 18-29?Benchmark Annotation: 1.684722222",
                "position": 2617
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/ChartQA/chartqa1.png",
                "caption": "(a)What’s the ratio(A:B) of yellow bar and blue bar for Ages 18-29?Benchmark Annotation: 1.684722222",
                "position": 2620
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/ChartQA/chartqa3.png",
                "caption": "(b)How many colors are used in the graph?Benchmark Annotation: 1",
                "position": 2627
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/ChartQA/chartqa2.png",
                "caption": "(c)What’s the ratio of the lowest value of green bars and blue bars?Benchmark Annotation: 1.216666667",
                "position": 2635
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/ChartQA/chartqa4.png",
                "caption": "(d)How many factors are shown in the chart?Benchmark Annotation: 3",
                "position": 2642
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/37.jpg",
                "caption": "(a)The image shows a python code. Is the output of the code ’11’?Benchmark Annotation: Yes",
                "position": 2651
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/37.jpg",
                "caption": "(a)The image shows a python code. Is the output of the code ’11’?Benchmark Annotation: Yes",
                "position": 2654
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/453_markup_v4.png",
                "caption": "(b)Is the actor inside the red bounding box called William Shatner?Benchmark Annotation: Yes",
                "position": 2661
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/803.jpg",
                "caption": "(c)Is the area of the square in the picture equal to 40?Benchmark Annotation: Yes",
                "position": 2669
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/895.jpg",
                "caption": "(d)Is there a total of two display devices in the image?Benchmark Annotation: Yes",
                "position": 2676
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/1713.jpg",
                "caption": "(e)Is this photo taken in a place of auto factory?Benchmark Annotation: Yes",
                "position": 2683
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/874.jpg",
                "caption": "(f)Is there a zipper in the picture?Benchmark Annotation: No",
                "position": 2691
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/971.jpg",
                "caption": "(g)Are there yellow poles in the image?Benchmark Annotation: Yes",
                "position": 2698
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/MME/1002.jpg",
                "caption": "(h)All apples are shown in the picture. If I eat an apple every day, can I eat it for three days?Benchmark Annotation: No",
                "position": 2705
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/4.jpg",
                "caption": "(a)Is there a skis in the image?Benchmark Annotation: Yes",
                "position": 2714
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/4.jpg",
                "caption": "(a)Is there a skis in the image?Benchmark Annotation: Yes",
                "position": 2717
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/166.jpg",
                "caption": "(b)Is there a cow in the image?Benchmark Annotation: Yes",
                "position": 2724
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/34.jpg",
                "caption": "(c)Is there a bed in the image?Benchmark Annotation: Yes",
                "position": 2732
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/132.jpg",
                "caption": "(d)Is there a tv in the image?Benchmark Annotation: Yes",
                "position": 2739
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/240.jpg",
                "caption": "(e)Is there a car in the image?Benchmark Annotation: Yes",
                "position": 2746
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/353.jpg",
                "caption": "(f)Is there a bicycle in the image?Benchmark Annotation: Yes",
                "position": 2754
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/364.jpg",
                "caption": "(g)Is there a broccoli in the image?Benchmark Annotation: Yes",
                "position": 2761
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/POPE/7.jpg",
                "caption": "(h)Is there a car in the image?Benchmark Annotation: No",
                "position": 2768
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/LISA/10_markup_v3.png",
                "caption": "(a)Please provide the bounding box coordinate of the region this sentence describes: the persons who graduate",
                "position": 2777
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/LISA/10_markup_v3.png",
                "caption": "(a)Please provide the bounding box coordinate of the region this sentence describes: the persons who graduate",
                "position": 2780
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/LISA/65.jpg",
                "caption": "(b)In a cold winter when snow covers the ground, what part of the car in the picture needs to be cleared before the car can be safely driven? Please provide the bounding box coordinate of this region.",
                "position": 2785
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/LISA/21.jpg",
                "caption": "(c)In a classroom setting, students often use electronic devices to assist their learning. Can you identify an object that could provide visual information and display educational content in the picture? Please provide the bounding box coordinate of this region.",
                "position": 2791
            },
            {
                "img": "https://arxiv.org/html/2512.14944/assets/auditing/NoiseSamples/LISA/60.jpg",
                "caption": "(d)Please provide the bounding box coordinate of the region this sentence describes: something indicating the identity of the car",
                "position": 2796
            }
        ]
    },
    {
        "header": "DBenchmark Auditing Details",
        "images": []
    }
]