[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11383/figures/figure_2_base_plot.png",
                "caption": "Figure 2:Comparing format sensitivity mitigation methods in terms of their effect on accuracy and standard deviation over prompt formats. To aggregate accuracy, we first compute median accuracy over formats for each task, and then average over 52 tasks. Error bars are2×2\\;\\times(standard deviation over formats, averaged across tasks).",
                "position": 451
            }
        ]
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11383/figures/figure_3_battles.png",
                "caption": "Figure 3:Comparing format sensitivity mitigation methods against regular few-shot in terms of spread on 8 language models. Method wins against few-shot for a given model if it has statistically significantly lower spread than few-shot on 52 tasks.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/figure_4_BC_failure_half.png",
                "caption": "Figure 4:Median Matthews Correlation of robustness methods in uniform vs. unbalanced settings for LLaMA 3.1 8B, Qwen 2.5 7B, and Gemma 2 9B. Red values indicate the drop in performance under the unbalanced setting relative to the uniform case.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/scenarios.png",
                "caption": "Figure 5:Without distribution shift (left), train and test formats are sampled uniformly. Under the compositional distribution shift (right), the test set contains novel combinations of known components, requiring systematic generalization. Cross (×\\times) stands for train samples, circle (∘\\circ) for test.",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/figure_5_LoRA_comparison.png",
                "caption": "Figure 6:LoRA method under distribution shifts. To aggregate accuracy, we first compute median accuracy over formats for each task, and then average over 52 tasks. Error bars are2×2\\;\\times(standard deviation over formats, averaged over tasks).",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/deepseek-chat-v3-0324-ensemble-vs-few-shot-spread.png",
                "caption": "(a)",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/deepseek-chat-v3-0324-ensemble-vs-few-shot-spread.png",
                "caption": "(a)",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2508.11383/figures/gpt-4.1-ensemble-vs-few-shot-spread.png",
                "caption": "(b)",
                "position": 708
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AConsistency loss",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11383/figures/figure_8_base_plot.png",
                "caption": "Figure 8:Comparing LoRA with consistency loss (LoRA-JS) with other methods in terms of their effect on accuracy and standard deviation over prompt formats. To aggregate accuracy, we first compute median accuracy over formats for each task, and then average over 52 tasks. Error bars are2×2\\;\\times(standard deviation over formats, averaged across tasks).",
                "position": 1322
            }
        ]
    },
    {
        "header": "Appendix BExtended Description of Methods",
        "images": []
    },
    {
        "header": "Appendix CMethod hyperparameters",
        "images": []
    },
    {
        "header": "Appendix DTask selection",
        "images": []
    },
    {
        "header": "Appendix EDependence between spread and format complexity",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11383/figures/format_length_vs_spread.png",
                "caption": "Figure 9:Empirical dependency between spread and amount of components in format. 90% confidence interval is based on percentiles.",
                "position": 1526
            }
        ]
    },
    {
        "header": "Appendix FUse of scientific artifacts.",
        "images": []
    },
    {
        "header": "Appendix GComplete list of format components.",
        "images": []
    },
    {
        "header": "Appendix HExample of input prompt for frontier models",
        "images": []
    }
]