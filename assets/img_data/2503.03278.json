[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.03278/x1.png",
                "caption": "Figure 1:Overview of our approach. We train a 0.23B model on just 16,087 samples (1.5% of the data) and achieve similar or better results than the 7B RadVLM, pre-trained on 1 million samples, by using text descriptions that highlight key visual features of abnormalities.",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.03278/x2.png",
                "caption": "Figure 2:Overview of our method. (A) shows the pipeline for obtaining decomposed knowledge descriptions, (B) presents the model architecture and training process for the abnormality grounding task.",
                "position": 114
            }
        ]
    },
    {
        "header": "2Methods",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.03278/extracted/6253938/images/eye.png",
                "caption": "Table 1:Comparison on the VinDr-CXR and PadChest-GR datasets. Our method achieves competitive results on both datasets, with the best performance on VinDr-CXR and competitive results in azero-shotsetting on PadChest-GR. Best and second-best performances are colouredGreenandYellow. Rloc, Rshape, Rcls, and Rtotalare different aspects of the RoDeO metrics. Methods marked withindicate the dataset had not been seen during training.",
                "position": 193
            },
            {
                "img": "https://arxiv.org/html/2503.03278/x3.png",
                "caption": "Figure 3:Performance for each disease class, with the y-axis representing the RoDeo total metric. Our method achieves first place in 14 out of 21 diseases from the VinDr-CXR dataset and 3 out of 6 known diseases from the PadChest-GR dataset. The best performances are highlighted in the callout.",
                "position": 285
            },
            {
                "img": "https://arxiv.org/html/2503.03278/extracted/6253938/images/eye.png",
                "caption": "Table 2:Ablation study on the effect of knowledge descriptions.Baserefers to the Florence-2 model[2], whileOursincorporates knowledge descriptions (KD). We evaluate in-distribution performance on VinDr-CXR and assess zero-shot generalization to an unseen dataset (PadChest-Known, marked by) and to both an unseen dataset and previously unseen disease classes (PadChest-Unknown, marked by). Best performances are highlighted ingreen.",
                "position": 314
            }
        ]
    },
    {
        "header": "5Discussion and Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]