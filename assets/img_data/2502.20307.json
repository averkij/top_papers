[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20307/x1.png",
                "caption": "Figure 2.Latent Shift for looping video generation. Taking 4 latent toys pre-trained Video Diffusion ModelsÂ (VDM) as an example, we build a latent cycle and shift the start point in each denoising step in inference for text-guided looping video generation. Notice that, the shifting is conducted in the latent space, we emit the latent encoder and decoder for easy understanding.",
                "position": 198
            }
        ]
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20307/x2.png",
                "caption": "Figure 3.Frame-invariance latent decoding reduces the artifacts caused by the 3D VAE decoding.",
                "position": 297
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x3.png",
                "caption": "Figure 4.We illustrate this with the example of the toy latent video diffusion model with a context window equal to 4. The utilized RoPE-Interp. enables longer video context without training by interpolation.",
                "position": 319
            }
        ]
    },
    {
        "header": "4.Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20307/x4.png",
                "caption": "Figure 5.Compare with other methods. We give the first frame, the intermediate frame, and the last frame for comparison. Notice that, both Svd-Interp. and Cog-Interp. are frame-interpolation methods, we manually give the same start frame and end frame as key-frames.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x5.png",
                "caption": "Figure 6.Ablation study on different latent skip.The shift step in each denoising iteration will also influence the generated content.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x6.png",
                "caption": "Figure 7.Ablation study on RoPE-Interp.Under the implementation of latent shifting, different RoPE strategies can have a significant impact on the content of video generation.",
                "position": 595
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x7.png",
                "caption": "Figure 8.Limitation. The generated results might not show a very smooth video in the customized domain,e.g., the illustration, restricted by the pre-trained text-to-video diffusion model.",
                "position": 684
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20307/x8.png",
                "caption": "Figure 9.Applications on Longer Video Generation. We show some sampled frames here and the whole video is included in the supplementary video.",
                "position": 1427
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x9.png",
                "caption": "Figure 10.More comparisons on the looping video generation.",
                "position": 1430
            },
            {
                "img": "https://arxiv.org/html/2502.20307/x10.png",
                "caption": "",
                "position": 1434
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]