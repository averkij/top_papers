[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04928/x1.png",
                "caption": "",
                "position": 73
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04928/x2.png",
                "caption": "Figure 2:Pipeline of DimensionX.Our framework is mainly divided into three parts.(a) Controllable Video Generation with ST-Director.We introduce ST-Director to decompose the spatial and temporal parameters in video diffusion models by learning dimension-aware LoRA on our collected dimension-variant datasets.(b) 3D Scene Generation with S-Director.Given one view, a high-quality 3D scene is recovered from the video frames generated by S-Director.(c) 4D Scene Generation with ST-Director.Given a single image, a temporal-variant video is produced by T-Director, from which a key frame is selected to generate a spatial-variant reference video. Guided by the reference video, per-frame spatial-variant videos are generated by S-Director, which are then combined into multi-view videos. Through the multi-loop refinement of T-Director, consistent multi-view videos are then passed to optimize the 4D scene.",
                "position": 124
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04928/x3.png",
                "caption": "Figure 3:Visualization of Attention Map.The left row shows the attention maps during the denoising process of the original video diffusion model. The right row, from top to bottom, illustrates the attention map variation of S-Director and T-Director, respectively. Starting from step 0, the early denoising steps (before step 10 of total denoising step 50) have determined the outline and layouts of output videos. Specifically, the spatial component is recovered earlier than the temporal information during the denoising process.",
                "position": 197
            },
            {
                "img": "https://arxiv.org/html/2411.04928/x4.png",
                "caption": "Figure 4:Qualitative comparison in dimension-aware video generation.Given the same image and text prompt, the first row is the temporal-variant video generation (camera static), the second row is the spatial-variant video generation (camera zoom out), and the third row is the spatial- and temporal-variant video generation (camera orbit right).",
                "position": 261
            },
            {
                "img": "https://arxiv.org/html/2411.04928/x5.png",
                "caption": "Figure 5:Qualitative Comparison in sparse-view 3D generation.Given two large-angle views, our approach obviously outperforms other baselines.",
                "position": 317
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04928/x6.png",
                "caption": "Figure 6:Qualitative results of 4D scene generation.Given a real-world or synthetic single image, our DimensionX produces coherent and intricate 4D scenes with rich features.",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2411.04928/x7.png",
                "caption": "Figure 7:Ablation study on the sparse-view 3D generation: The absence of S-Director results in lower reconstruction quality.",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2411.04928/x8.png",
                "caption": "Figure 8:Ablation study on 4D generationWe ablate the design of reference video latent sharing and appearance refinement.",
                "position": 664
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]