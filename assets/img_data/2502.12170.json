[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12170/x1.png",
                "caption": "Figure 1:Downstream average accuracy of Pythia and MUDDPythia with different sizes.",
                "position": 95
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12170/x2.png",
                "caption": "Figure 2:Architecture of Multiway Dynamic Dense Connections.",
                "position": 209
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12170/x3.png",
                "caption": "Figure 3:Scaling curves of MUDDFormer and baseline models.",
                "position": 697
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x4.png",
                "caption": "Figure 4:Depth scaling of MUDDFormer and Transformer++.",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x5.png",
                "caption": "Figure 5:Cosine similarity between the inputs of the current layer and the preceding layer.",
                "position": 1950
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x6.png",
                "caption": "Figure 6:Illustrative V-composition circuits in Transformer vs. in MUDDFormer. Colored circles are MHAâ€™s inputs of the query (yellow), key (red), value (green) and residual (black) streams and output (blue). LayerNorms and MLPs are omitted.",
                "position": 1955
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x7.png",
                "caption": "Figure 7:Attention head activation ratio by layers.",
                "position": 1968
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x8.png",
                "caption": "Figure 8:PPL vs. relative training and inference speed of MUDDFormer variants.",
                "position": 2166
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APyTorch Style Pseudo-code for MUDDFormer",
        "images": []
    },
    {
        "header": "Appendix BDetails of Complexity Analysis",
        "images": []
    },
    {
        "header": "Appendix CHyperparameters and Baselines for Scaling Law Experiments",
        "images": []
    },
    {
        "header": "Appendix DImage Classification with ViT",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12170/x9.png",
                "caption": "Figure 9:Attention patterns for the 32 heads in the 25th layer of Pythia-2.8B.",
                "position": 3172
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x10.png",
                "caption": "Figure 10:Attention patterns for the 32 heads in the 25th layer of MUDDPythia-2.8B.",
                "position": 3176
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x11.png",
                "caption": "Figure 11:Mean of dynamic dense connections of MUDDPythia-2.8B.",
                "position": 3181
            },
            {
                "img": "https://arxiv.org/html/2502.12170/x12.png",
                "caption": "Figure 12:Standard deviation of dynamic dense connections of MUDDPythia-2.8B.",
                "position": 3185
            }
        ]
    },
    {
        "header": "Appendix EVisualization",
        "images": []
    }
]