[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x1.png",
                "caption": "Figure 1:V-ReasonOverview: (a) Entropy of the output distribution averaged over the MMVU(Zhao et al.,2025)dataset of 625 videos. We see clear macro-exploration and macro-exploitation phases with bigger, more accurate models showing lower overall entropy (lower and later peak, followed by a lower final entropy during the macro-exploitation). We use these key insights to adapt a model’s behavior in a training-free way using an inference-time optimization technique. (b) ApplyingV-Reasonon Qwen2.5-VL-7B-Instruct makes its entropy behave more similarly to the larger or the RL-trained Video-R1-7B model. (c) Our method achieves higher accuracy than the base LMM and bridges the accuracy gap with the RL model. (d)V-Reasonalso significantly reduces the total output tokens compared to all models due to a dedicated entropy minimization phase.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Proposed Approach:V-Reason",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x2.png",
                "caption": "Figure 2:(a) Proposed approach for enhancing video reasoning in a training-free manner using entropy-based objective.V-Reasonuses an inference optimization method to modulate the values cache of the last decoder layer with an entropy switching loss (ℒs​w​i​t​c​h\\mathcal{L}_{switch}) to further enhance the video reasoning performance. (b) The average entropy plot for Qwen-2.5-VL-7B on the MMVU dataset along with its EMA. The inset depicts the shift in the entropy maxima for the EMA curve denoted by the black arrow (c) EMA entropy plot ofV-Reasonfor a single sample that shows the micro-exploration and micro-exploitation within the macro-exploration phase before the entropy maxima and macro-exploitation phase after. (d) Plot showing theαk\\alpha_{k}switching inV-Reasonfor the corresponding example in (c) that ensures bounded entropy updates without a rapid increase.",
                "position": 196
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x3.png",
                "caption": "Figure 3:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B together with its entropy plot shown on the top right. The black arrow in the entropy plot denotes the shift in the EMA peak demonstrating longer exploration forV-Reasoncompared to the baseline. See other results inH.",
                "position": 841
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis: Bounding Entropy under Switching Loss",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CInference Time and GPU Memory",
        "images": []
    },
    {
        "header": "Appendix DAnalysis on Video duration",
        "images": []
    },
    {
        "header": "Appendix EAblation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x4.png",
                "caption": "Figure 4:Optimization step-size ablations.",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x4.png",
                "caption": "Figure 4:Optimization step-size ablations.",
                "position": 2318
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x5.png",
                "caption": "Figure 5:Alpha histogram before peak EMA entropy.",
                "position": 2328
            }
        ]
    },
    {
        "header": "Appendix FLimitations",
        "images": []
    },
    {
        "header": "Appendix GFuture Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x6.png",
                "caption": "Figure 6:LLM analysis: (a) Entropy of the output distribution averaged over 100 samples of the MATH dataset(Yang et al.,2024a). Similar to Video LMMs, we see clear macro-exploration and macro-exploitation phases (having micro-exploration and micro-exploitations) with bigger, more accurate models showing lower overall entropy (lower and later peak, followed by a lower final entropy during the macro-exploitation). This shows that these key insights can be adopted for enhancing reasoning in LLMs too in a training-free way using an inference-time optimization technique.",
                "position": 2376
            }
        ]
    },
    {
        "header": "Appendix HAdditional Qualitative results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17045/x7.png",
                "caption": "Figure 7:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2397
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x8.png",
                "caption": "Figure 8:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2400
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x9.png",
                "caption": "Figure 9:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2403
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x10.png",
                "caption": "Figure 10:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x11.png",
                "caption": "Figure 11:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2409
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x12.png",
                "caption": "Figure 12:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2412
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x13.png",
                "caption": "Figure 13:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2415
            },
            {
                "img": "https://arxiv.org/html/2510.17045/x14.png",
                "caption": "Figure 14:Qualitative result: An example output and comparison with the baseline Qwen-2.5-VL-7B. Black arrow denotes the shift in the peak demonstrating longer exploration forV-Reason.",
                "position": 2418
            }
        ]
    },
    {
        "header": "Appendix ISupplemental Information: LLM Usage",
        "images": []
    }
]