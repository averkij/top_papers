[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Model: LLaMA-Omni 2",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02625/x1.png",
                "caption": "Figure 1:Left:Model architecture of LLaMA-Omni 2.Right:Illustration of the two-stage training strategy.",
                "position": 171
            }
        ]
    },
    {
        "header": "3Data Construction",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt",
        "images": []
    },
    {
        "header": "Appendix BDetailed Latency",
        "images": []
    }
]