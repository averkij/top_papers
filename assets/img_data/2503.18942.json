[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18942/x1.png",
                "caption": "",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18942/x2.png",
                "caption": "Figure 2:Results of Test-Time Scaling for Video Generation.As the number of samples in the search space increases by scaling test-time computation (TTS), the models‚Äô performance exhibits consistent improvement (In the bar chart, light colors correspond to the results without TTS, while dark colors represent the improvement after TTS.).",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18942/x3.png",
                "caption": "Figure 3:Pipeline of Tes-Time Scaling for Video Generation.Top:Random Linear Searchfor TTS video generation is to randomly sample Gaussian noises, prompt the video generator to generate sequential of video clips through step-by-step denoising in a linear manner, and select the highest score form the test verifiers.Bottom:Tree of Frames (ToF) Searchfor TTS video generation is to divide the video generation process into three stages: (a) the first stage performs image-level alignment that influences the later frames; (b) the second stage is to apply dynamic prompt in test verifiersùí±ùí±\\mathcal{V}caligraphic_Vto focus on motion stability, physical plausibility to provide feedback that guides heuristic searching process; (c) the last stage assesses the overall quality of the video and select the video with highest alignment with text prompts.",
                "position": 144
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18942/x4.png",
                "caption": "Figure 4:Performance of random linear search on different video models and verifiers.The top row displays results for autoregressive models, while the bottom row shows diffusion-based models. The initial points of the curves represent the random video sample results without TTS. The models are arranged in order of increasing parameter count from left to right; different colored curves represent the performance trends under various verifiers, and the gray dashed line corresponds to the baseline established by VBench, which serves as a ground-truth verifier.",
                "position": 463
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x5.png",
                "caption": "Figure 5:Comparison between random linear search and ToF search.The red curve represents random linear search. The blue curve represents ToF search, with the dashed line being the predicted curve from a geometric series decay approximation. Curve fitting reveals that similar subsequent trends tend to converge to an upper limit.",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x6.png",
                "caption": "Figure 6:Qualitative TTS performance improvement ratio on different complexities of promptsacross different video generation models across diverse benchmark dimensions of Vbench.",
                "position": 554
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18942/x7.png",
                "caption": "Figure 7:Using TTS, the small model (Pyramid-Flow) achieves scores that are close to, or even exceed, those of the 13B large model (HunyuanVideo) in many dimensions. The gray dashed horizontal line in the figures indicates HunyuanVideo‚Äôs score in that dimension.",
                "position": 1942
            },
            {
                "img": "https://arxiv.org/html/2503.18942/extracted/6305288/assets/failure.jpg",
                "caption": "Figure 8:Failure cases on prompt ‚ÄúA person is clapping‚Äù.",
                "position": 2100
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x8.png",
                "caption": "Figure 9:Verifications during TTS process.",
                "position": 2103
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x9.png",
                "caption": "Figure 10:TTS performance on Appearance Style across diverse verifiers.",
                "position": 2106
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x10.png",
                "caption": "Figure 11:TTS performance on Aesthetic Quality across diverse verifiers.",
                "position": 2109
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x11.png",
                "caption": "Figure 12:TTS performance on Color across diverse verifiers.",
                "position": 2112
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x12.png",
                "caption": "Figure 13:More visual results during TTS process on Pyramid-Flow. From left to right, each row of frames are extracted from a video sequence. From top to bottom, each row represents the output video results of TTS with an increasing number of samples.",
                "position": 2115
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x13.png",
                "caption": "Figure 14:More visual results during TTS process on Pyramid-Flow. The TTS method can effectively alleviate common issues in video generation, such as those related to human motion and complex movements.",
                "position": 2118
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x14.png",
                "caption": "Figure 15:More visual results during TTS process on CogVideoX-5B.",
                "position": 2121
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x15.png",
                "caption": "Figure 16:More visual results during TTS process on CogVideoX-5B.",
                "position": 2124
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x16.png",
                "caption": "Figure 17:More visual results during TTS process on CogVideoX-2B. The TTS method can help to enhance multi-object spatial perception.",
                "position": 2127
            },
            {
                "img": "https://arxiv.org/html/2503.18942/x17.png",
                "caption": "Figure 18:More visual results during TTS process on NOVA. The TTS method improves the alignment between the spatial relationships of objects in videos and the corresponding text prompt.",
                "position": 2130
            }
        ]
    },
    {
        "header": "Appendix BMore Experiments",
        "images": []
    }
]