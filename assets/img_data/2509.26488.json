[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26488/x1.png",
                "caption": "Figure 1:Our method achieves highly parallel decoding. Compared to the original LLaDA Model, dParallel decodes over 8 tokens per step on GSM8K while preserving the accuracy.",
                "position": 78
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26488/x2.png",
                "caption": "Figure 2:Empirical Studies: (a) The average confidence score exhibits a positive correlation with generation accuracy. (b) Token confidence propagates sequentially during the decoding process. (c) Convergence trajectories of confidence for different tokens.",
                "position": 149
            },
            {
                "img": "https://arxiv.org/html/2509.26488/x3.png",
                "caption": "Figure 3:Overview of proposed certainty-forcing distillation. The dLLM is self-distilled along its original generation trajectory, ensuring consistency with the trajectory throughout training while encouraging token certainty to converge faster in parallel rather than sequentially.",
                "position": 182
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26488/x4.png",
                "caption": "Figure 4:Comparison of speedâ€“accuracy trade-off curves between confidence-threshold decoding and our method. (a) and (b) show results on the LLaDA model for GSM8K and HumanEval, respectively. (c) and (d) present results on the Dream model for GSM8K and HumanEval benchmarks.",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2509.26488/x5.png",
                "caption": "Figure 5:Average token confidence at the 8th and 16th decoding steps for LLaDA-8B-Instruct Model on GSM8K. The proposed certainty-forcing strategy reshapes the original sequential certainty convergence into a faster and more parallel convergence process.",
                "position": 818
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26488/x6.png",
                "caption": "Figure 6:Average token confidence over the first 160 tokens across the first 16 decoding steps of the LLaDA-8B-Instruct model on GSM8K. Our certainty-forcing strategy transforms the sequential certainty convergence of the baseline into a faster and more parallel convergence process.",
                "position": 1889
            },
            {
                "img": "https://arxiv.org/html/2509.26488/x7.png",
                "caption": "Figure 7:Case study on LLaDA-8B-Instruct Model with chain-of-thought reasoning problem.",
                "position": 1892
            },
            {
                "img": "https://arxiv.org/html/2509.26488/x8.png",
                "caption": "Figure 8:Case study on LLaDA-8B-Instruct Model with naive code generation task.",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2509.26488/x9.png",
                "caption": "Figure 9:Case study on LLaDA-8B-Instruct Model with instruction-based code generation task.",
                "position": 1898
            }
        ]
    },
    {
        "header": "Appendix CCase Study",
        "images": []
    },
    {
        "header": "Appendix DLimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix EEthics Statement",
        "images": []
    },
    {
        "header": "Appendix FReproducibility Statement",
        "images": []
    }
]