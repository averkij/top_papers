[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06209/images/Uncertainty_vs_PRM_v5.png",
                "caption": "Figure 1:Process reward models (top) in comparison to uncertainty quantification heads (bottom).",
                "position": 135
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Verification of Reasoning Steps with Uncertainty Quantification Heads",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06209/x1.png",
                "caption": "Table 2:PR-AUC\\uparrow\\uparrowfor detecting incorrect reasoning steps (Qweb3-8B). Best scores are shown inbold. Other competitive scores show clear advantages areunderlined. # Sample indicates the number of training samples; each sample corresponds to a reasoning trajectory with step-level labels.",
                "position": 458
            }
        ]
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06209/x1.png",
                "caption": "Table 3:Offline best-of-NNdecoding accuracy across datasets (Qwen-3 8B). For datasets with verifiable final answer, we also provide majority voting.",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x1.png",
                "caption": "Table 4:Online best-of-NNdecoding accuracy across datasets (Qwen3-8B).",
                "position": 1160
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x1.png",
                "caption": "Figure 2:Top row: PR-AUC of UHeads with increasing training set size (x-axis). Bottom row: scaling training data either by adding new unique questions or by sampling additional trajectories. One dataset per domain is shown; other tasks are covered inAppendixA.",
                "position": 1402
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06209/x2.png",
                "caption": "Table 6:Beam-Search decoding accuracy across datasets (Qwen3-8B).",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x2.png",
                "caption": "Table 7:PR-AUC for detecting incorrect reasoning steps for Phi-4. Best scores are shown inbold, and other competitive scores areunderlined. # Sample indicates the number of training samples, where each sample corresponds to a reasoning trajectory with step-level annotations.‡Qwen2.5-Math-PRM-7B’s training data is filtered from an 860K-sample dataset; the exact size after filtering is not specified in their paper.",
                "position": 1558
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x2.png",
                "caption": "Table 8:Offline Best-of-NNdecoding accuracy across datasets for Phi-4 model. For datasets with verifiable final answer, we also provide Majority Voting. We use max uncertainty aggregation over steps.",
                "position": 1806
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x2.png",
                "caption": "Figure 3:Best-of-NNperformance on GSM8k and ScienceQA for differentNNvalues (Qwen3-8B).",
                "position": 2063
            },
            {
                "img": "https://arxiv.org/html/2511.06209/x3.png",
                "caption": "Figure 4:Top row: PR-AUC of UHeads with increasing training set size (x-axis). Bottom row: scaling training data either by adding new unique questions or by sampling additional trajectories. One dataset per domain is shown.",
                "position": 2069
            }
        ]
    },
    {
        "header": "Appendix BDiscussion and Limitations",
        "images": []
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    },
    {
        "header": "Appendix DTraining Details",
        "images": []
    },
    {
        "header": "Appendix ETest Dataset Details",
        "images": []
    },
    {
        "header": "Appendix FDataset Examples",
        "images": []
    },
    {
        "header": "Appendix GHuman Validation Details",
        "images": []
    },
    {
        "header": "Appendix HThe Usage of LLMs",
        "images": []
    }
]