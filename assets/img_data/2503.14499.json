[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots_non_github/headline-green.png",
                "caption": "Figure 1:The length of tasks (measured by how long they take human professionals) that generalist autonomous frontier model agents can complete with 50% reliability has been doubling approximately every 7 months for the last 6 years (Section4).\nThe shaded region represents 95% CI calculated by hierarchical bootstrap over task families, tasks, and task attempts.\nEven if the absolute measurements are off by a factor of 10, the trend predicts that in under a decade we will see AI agents that can independently complete a large fraction of software tasks that currently take humans days or weeks(Section7).",
                "position": 341
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/images/methodology_new.png",
                "caption": "Figure 2:Our methodology for measuring AI agent time horizon. First, we create a diverse task suite of 170 tasks. Second, we have both humans and AI agents (consisting of an AI model and a scaffold) attempt these tasks, recording the time taken by successful humans and the success rate for AI agents. Third, we fit a logistic model to find the time horizon at which each AI agent has a 50% chance of success, and plot this against the release date of the model.",
                "position": 362
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Measuring AI agent performance on realistic tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/bar_chart_weighted_scores/headline.png",
                "caption": "Figure 3:Average task success rate across our entire combined suite, for each model. As with all of the results reported in the main body of this work, to reduce the influence of large task families, we weight each task by the inverse square root of the number of tasks in the family it belongs to.",
                "position": 740
            }
        ]
    },
    {
        "header": "4Computing time horizon",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/success_rates/model_success_rate_vs_human_completion_time.png",
                "caption": "Figure 4:Model success rates are negatively correlated with how much time it takes a human to complete the task. (y=‚àí0.07‚Å¢x+0.66ùë¶0.07ùë•0.66y=-0.07x+0.66italic_y = - 0.07 italic_x + 0.66,R2:0.83:superscriptùëÖ20.83R^{2}:0.83italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT : 0.83)",
                "position": 772
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/individual_histograms/default/histograms.png",
                "caption": "Figure 5:Success rates of all models on our test suite, showing the computation of time horizon as predicted 50% success rate time. The logistic fit is fairly good, though there is a jump in success rate between <1 minute tasks and >1 minute tasks, which corresponds to the boundary between SWAA and HCAST tasks.",
                "position": 775
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/p80.png",
                "caption": "Figure 6:Trend in 80% success rate time horizon. The doubling time is similar to the 50% plot, but horizons are substantially lower. 50% horizon trend shown in grey.",
                "position": 821
            }
        ]
    },
    {
        "header": "5Qualitative analysis",
        "images": []
    },
    {
        "header": "6External validity and robustness",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/single_line_2023_ga_rebench.png",
                "caption": "Figure 7:Time horizons on HCAST + RE-bench, for models starting with GPT-4 0314.",
                "position": 923
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/double_line_all_data_retrodict_excluding_swaa.png",
                "caption": "Figure 8:The full time series for the time horizon of models, by release date. We plot in blue the regression from only 2023+ data on HCAST + RE-Bench tasks, extended into the past, and in gray the regression with all tasks (including SWAA) on the whole 6 year period. Points on the graph are models‚Äô time horizons on all data including SWAA.",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/messiness/success_trend_by_messiness_and_length_with_boundary_0.5.png",
                "caption": "Figure 9:Performance trends over time for HCAST and RE-Bench tasks by length and messiness (Section6.2). The data spans only 2023‚Äì2024 as pre-2023 models score 0 on non-SWAA tasks. Whilst our messier tasks have lower average success rates, trends in model performance improvements are not obviously slower on the high messiness split.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/messiness/messiness_effect_expanded_combined_alpha_0.010.png",
                "caption": "Figure 10:We plot the excess success rate (the observed empirical task success rate, minus success rate we would predict using the task‚Äôs length, see Section4.1) against messiness score for each task. As discussed in Section6.2, there is a negative relationship between excess success rates and messiness.",
                "position": 963
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/swe_bench.png",
                "caption": "Figure 11:Performance of frontier AI models using reported SWE-bench Verified results (Section6.3). We observe a similar exponential trend to Figure1, albeit with a steeper slope.",
                "position": 973
            }
        ]
    },
    {
        "header": "7Extrapolation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/multiverse/boxplot.png",
                "caption": "Figure 12:A sensitivity analysis of the extrapolated date at which frontier AI systems will have a horizon of 1 month. In each row, we apply 10,000 random perturbations to our data and find the distribution over the date of 1-month AI implied by the perturbed data.\nBox endpoints represent the 25th and 75th percentiles, and whiskers the 10th and 90th percentiles, with outliers not displayed. Note that this plot does not account for future changes in the trend or external validity concerns, which are responsible for the majority of our uncertainty.",
                "position": 1004
            }
        ]
    },
    {
        "header": "8Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/cost/ratio_vs_length.png",
                "caption": "Figure 13:Cost of a successful run using an LLM agent as a fraction of the cost of the salary of a human expert performing the same task.",
                "position": 1181
            }
        ]
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATask suite details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/task_distribution.png",
                "caption": "Figure 14:Stacked histogram of tasks by difficulty rating. HCAST mainly includes tasks longer than 4 minutes, while we focused on tasks in the 2-second to 15-second range with SWAA in order to measure GPT-2 and GPT-3. There is a gap between the two which limits our ability to measure time horizons in this range.",
                "position": 1862
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/images/rebench.png",
                "caption": "Figure 15:The 7 original RE-Bench tasks.",
                "position": 1867
            }
        ]
    },
    {
        "header": "Appendix BMethodological details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/individual_histograms/human_baselines/histograms.png",
                "caption": "Figure 16:Success rates and time horizon of human baseliners. Note that the time horizon is not directly comparable to the time horizon of ML models (see SectionB.1.1)",
                "position": 1983
            }
        ]
    },
    {
        "header": "Appendix CQualitative analysis examples",
        "images": []
    },
    {
        "header": "Appendix DMore ablations and robustness checks",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/horizon_alternative_fits.png",
                "caption": "Figure 17:Linear, hyperbolic, and exponential fits for model time horizon since 2019.",
                "position": 2646
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/partial_scoring.png",
                "caption": "Figure 18:Time horizon with continuous (non-binarized) scoring. Claude 3.7 Sonnet has a 50% time horizon of nearly 2 hours. We think this methodology captures more signal from 8-hour RE-Bench tasks, but overstates the time horizon of recent models, since it is easier to achieve an average score of 0.5 on most tasks than to match human performance 50% of the time. The slope is also likely an overestimate, because longer tasks tend to be continuously scored.",
                "position": 2672
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/double_line_2024_trendline.png",
                "caption": "Figure 19:2024‚Äì2025 and 2019‚Äì2025 exponential fits for 50% time horizon.",
                "position": 2679
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/images/length_vs_messiness.png",
                "caption": "Figure 20:Messier tasks tend to be longer.",
                "position": 3131
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/messiness/success_trend_by_messiness_with_boundary_0.5.png",
                "caption": "Figure 21:Model success rates on HCAST + RE-Bench tasks, split by task messiness rating. Models have higher success rates on the less messy tasks, but the rate of improvement over time is similar for both subsets. Both davinci-002 and gpt-3.5-turbo instruct score 0 on the subset of HCAST + RE-Bench with higher messiness.",
                "position": 3138
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/success_correlations/observed_success_rates_correlations.png",
                "caption": "Figure 22:Correlation matrix of observed success rates across all models and tasks. Mean correlation: 0.73",
                "position": 3215
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/success_correlations/fractional_excess_success_rates_correlations.png",
                "caption": "Figure 23:Correlation matrix of excess success rates (defined bySo‚Å¢b‚Å¢s‚Å¢e‚Å¢r‚Å¢v‚Å¢e‚Å¢d‚àíSp‚Å¢r‚Å¢e‚Å¢d‚Å¢i‚Å¢c‚Å¢t‚Å¢e‚Å¢dSp‚Å¢r‚Å¢e‚Å¢d‚Å¢i‚Å¢c‚Å¢t‚Å¢e‚Å¢dsubscriptùëÜùëúùëèùë†ùëíùëüùë£ùëíùëësubscriptùëÜùëùùëüùëíùëëùëñùëêùë°ùëíùëësubscriptùëÜùëùùëüùëíùëëùëñùëêùë°ùëíùëë\\frac{S_{observed}-S_{predicted}}{S_{predicted}}divide start_ARG italic_S start_POSTSUBSCRIPT italic_o italic_b italic_s italic_e italic_r italic_v italic_e italic_d end_POSTSUBSCRIPT - italic_S start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d italic_i italic_c italic_t italic_e italic_d end_POSTSUBSCRIPT end_ARG start_ARG italic_S start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d italic_i italic_c italic_t italic_e italic_d end_POSTSUBSCRIPT end_ARG) across all models and tasks. Mean correlation: 0.40",
                "position": 3218
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/bootstrap/headline-linear.png",
                "caption": "Figure 24:Change in time horizon of frontier models over time. Note: the data displayed is the same as in Figure1, but with a linear axis.",
                "position": 3221
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/logistic/all_models.png",
                "caption": "Figure 25:Time horizon of all models we measured, including non-frontier models.",
                "position": 3224
            },
            {
                "img": "https://arxiv.org/html/2503.14499/extracted/6285858/plots/bootstrap/headline-log.png",
                "caption": "Figure 26:Length in human expert clock-time of tasks that frontier models can perform competently over time.\nSee Section4for details on time horizon length calculation.\nThe line represents the linear regression fit, with a confidence region calculated via hierarchical bootstrapping.\nIn this plot, davinci-002 and gpt-3.5-turbo-instruct are placed at the release dates of GPT-3 and GPT-3.5 respectively, and GPT-2‚Äôs score is imputed as zero for longer tasks for which our scaffolds are incompatible. Note: this is the same as Figure1but presented differently.",
                "position": 3227
            }
        ]
    },
    {
        "header": "Appendix ECode",
        "images": []
    },
    {
        "header": "Appendix FAuthor contributions",
        "images": []
    }
]