[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17191/figures/vasevl_logo.png",
                "caption": "",
                "position": 70
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17191/x1.png",
                "caption": "Figure 1:A chat example from VaseVL using QvQ-72BQwen-Team (2024)on an Archaic Greek kylix (540–530 BCE) decorated in the black-figure technique. The model identifies vessel type, period, and technique.",
                "position": 118
            },
            {
                "img": "https://arxiv.org/html/2509.17191/x2.png",
                "caption": "Figure 2:Examples from VaseVQA. Each panel shows an image with its question and ground-truth answer. The seven question types probe factual recall and compositional, descriptive reasoning.",
                "position": 124
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Data Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17191/figures/2A591E92-1C49-4FC0-84E2-27B58F0BF76C_2_ac001001.jpg",
                "caption": "Table 3:Example of a VaseVQA Dataset Table: Eight attribute-specific questions (fabric, technique, shape, provenance, date, attribution, decoration, and overall details) paired with visual input, presented in a conversational Q&A format to analyze an Athenian red-figure cup (450–400 BCE) attributed to the Codrus Painter.",
                "position": 536
            }
        ]
    },
    {
        "header": "4Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17191/x3.png",
                "caption": "Figure 3:Overall framework of VaseVL.The proposed pipeline integrates supervised fine-tuning (SFT) with reinforcement learning under the Group Relative Policy Optimization (GRPO) paradigm. Given a vase imagexx, a questionqq, and the reference answera∗a^{*}, the model refines its reasoning ability by balancing lexical and semantic rewards while constraining policy drift fromπref\\pi_{\\text{ref}}.",
                "position": 819
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Social Impact",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]