[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x1.png",
                "caption": "Figure 1:Post-training UMMs with reconstruction alignment (i.e.,RecA) substantially improves image generation and editing.Left: performance comparison on GenEval and DPGBench, where a 1.5B-parameter model post-trained withRecAsurpasses much larger models across multiple benchmarks (Table1: GenEval, DPGBench and Wise; Table3: ImgEdit and GEdit-Bench-EN);Middle: compared with GPT-4o,RecAfollows generation instructions more faithfully, especially forcolor attributesandspatial positions;Right: for editing,RecAbetter preservesinstance identity,overall layout, andobject shapesof the original images, such as the girl’s lips.",
                "position": 84
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x2.png",
                "caption": "Figure 2:Dense supervision from visual embeddings.a) Typical image generation models are trained onimage–captionpairs and/or sequences whose text is asparserepresentation of visual information.An image is worth far more than a hundred of wordsand contains rich details that text alone cannot capture.\nAs shown in the left three examples, even lengthy captions (500 words) miss key aspects such astextures, styles, layouts, shapes, and attributes, leading to imperfect generations relative to the original image.\nb) By contrast, embeddings fromvisual understanding encoders,e.g., CLIP, preserve richer and more faithful semantics.\nCan theseimage–embeddingpairs provide thedensesupervision needed to enhance image generation and editing?\nSurprisingly, the answer is yes: we find thatimage–embeddingpairs can improve T2I and image editing in azero-shotmanner.",
                "position": 93
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x3.png",
                "caption": "Figure 3:UMMs can often correctly recognize an uncommon concept (yellow broccoli) but fail to generate it, revealing misalignment between understanding and generation.",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x4.png",
                "caption": "Figure 4:Overview of the semantic reconstruction alignment (RecA) pipeline.\nA visualunderstandingencoder (e.g., CLIP or DINO) extracts semantic features from the input image, which are fused with template text embeddings and passed to a Unified Multimodal Model (UMM) to regenerate the image.\nThe UMM is optimized with a self-supervised loss (diffusion or cross-entropy) between the original and reconstructed images or image latents.At inference time,RecArequires no additional inputs, operating as a standard UMM.",
                "position": 148
            }
        ]
    },
    {
        "header": "2Reconstruction Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x5.png",
                "caption": "Figure 5:Post-training withRecArestores visual details beyond the baseline.For each query image (left), we feed its visual understanding embeddings back into the UMM with the instruction“Describe the image in detail.”The baseline model (centre)’s visual responses,i.e., images, preserve the main subject but distort layout, textures, and colors, whileRecAmarkedly restores visual details like geometry, color, and overall fidelity.",
                "position": 162
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x6.png",
                "caption": "Figure 6:Image generation resultsvs.baselines.We use Harmon-1.5B as baseline. Post-trained model better handles multiple objects, complex attributions, and spatial layouts, preserving fine details missed by the baseline.",
                "position": 920
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x7.png",
                "caption": "Figure 7:Image editing resultsvs.baselines. We use BAGEL as baseline. Our model consistently improves object addition, replacement, style transfer, and scene modification.",
                "position": 924
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x8.png",
                "caption": "Figure 8:Qualitative T2I results. The large images (1024×10241024\\times 1024) are generated by the post-trained BAGEL, while the small images (512×512512\\times 512) are generated by the post-trained Harmon. Detailed captions are listed in appendix’s Sec.F.",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x9.png",
                "caption": "Figure 9:Qualitative image editing results.Edited outputs are generated by BAGEL post-trained withRecA.\nLeft: original images; Right: edited images.",
                "position": 1052
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Templates forRecA",
        "images": []
    },
    {
        "header": "Appendix BExperimental Setup",
        "images": []
    },
    {
        "header": "Appendix CDiscussion",
        "images": []
    },
    {
        "header": "Appendix DMore Quantitative Results on Text-to-Image Generation",
        "images": []
    },
    {
        "header": "Appendix ELimitations and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x10.png",
                "caption": "Figure 10:BLIP-3o reconstruction results.We observe that BLIP-3o possesses inherent image reconstruction capabilities. FollowingRecAapplication, reconstruction quality exhibits degradation rather than improvement, suggesting that BLIP-3o incorporates reconstruction objectives during pre-training.",
                "position": 2922
            }
        ]
    },
    {
        "header": "Appendix FGenerated Captions",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x11.png",
                "caption": "Figure 11:Additional ImgEdit benchmark results.Qualitative results on image editing tasks. In each pair, the left image is generated by the baseline model and the right by theRecApost-trained model",
                "position": 2945
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x12.png",
                "caption": "Figure 12:Additional GEdit-Bench-EN results.Qualitative results on image editing tasks. In each pair, the left image is generated by the baseline BAGEL model and the right by theRecApost-trained model.",
                "position": 3003
            }
        ]
    },
    {
        "header": "Appendix GMore Qualitative Results on Image Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07295/x13.png",
                "caption": "Figure 13:Qualitative comparison of editing results across different methods. Our method achieves more faithful instruction following (e.g., rainbow dome, star addition), better identity preservation (e.g., pet and human faces), and stronger background consistency.",
                "position": 3082
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x14.png",
                "caption": "Figure 14:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A white banana and a black banana.",
                "position": 3089
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x15.png",
                "caption": "Figure 15:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A photo of a yellow broccoli.",
                "position": 3092
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x16.png",
                "caption": "Figure 16:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A photo of an orange snowboard and a green cat.",
                "position": 3095
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x17.png",
                "caption": "Figure 17:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A photo of a skis right of a zebra.",
                "position": 3098
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x18.png",
                "caption": "Figure 18:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A photo of a microwave and a truck.",
                "position": 3101
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x19.png",
                "caption": "Figure 19:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A diamond on the right, an emerald in the middle, a ruby on the left.",
                "position": 3104
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x20.png",
                "caption": "Figure 20:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: Cheerful and bright, vibrant lighting. A shell and a bright orange bear in a bright setting.",
                "position": 3107
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x21.png",
                "caption": "Figure 21:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: During the warm glow of a dwindling summer evening, a particular fussy feline with distinctive calico markings is perched atop a garden table. The cat, seemingly indifferent to its surroundings, sports a pair of large, reflective aviator sunglasses that sit comically upon its small, furry face. Around the cat, there are scattered pots of blooming flowers, contributing to the charm of the scene, and in the background, hints of orange and pink skies are visible through the foliage.",
                "position": 3110
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x22.png",
                "caption": "Figure 22:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A vivid scene unfolds where several deep red, perfectly round tomatoes spill from a woven brown basket onto a rustic wooden tabletop. The basket lies on its side as the plump tomatoes scatter across the surface, some touching the dark green leaves of a nearby herb plant. In the background, the blurred outline of an open kitchen window lets in soft, natural light, casting gentle shadows around the fallen produce.",
                "position": 3113
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x23.png",
                "caption": "Figure 23:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: A polished brown leather briefcase with visible stitching details rests on a white tablecloth, displaying a sense of organization amidst the surrounding environment. Beside the briefcase, a vibrant red fedora hat provides a striking contrast against the pristine table covering. The table, placed in a room with light beige walls, gives an impression of a professional setting with a touch of personal style.",
                "position": 3116
            },
            {
                "img": "https://arxiv.org/html/2509.07295/x24.png",
                "caption": "Figure 24:Uncurated generation results from Harmon-1.5B (top) and post-trained model (bottom). Prompt: a festive array of red and yellow balloons tied with curling ribbons, gently bobbing from the breeze of a spinning ceiling fan. The fan has wooden blades and a brass finish, which contrasts with the bright colors of the balloons. The balloons are clustered in a joyful bunch, casting soft shadows on the ceiling above.",
                "position": 3119
            }
        ]
    },
    {
        "header": "Appendix HMore Qualitative Results on Text-to-Image Generation",
        "images": []
    }
]