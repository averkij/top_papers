[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/x1.png",
                "caption": "",
                "position": 157
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x2.png",
                "caption": "",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x3.png",
                "caption": "",
                "position": 205
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x4.png",
                "caption": "",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x5.png",
                "caption": "Figure 1:Overview of the\\gradientRGBMMVU53,93,20310,10,80 benchmark.\\gradientRGBMMVU53,93,20310,10,80 includes 3,000 expert-annotated examples, covering 27 subjects across four core disciplines. It is specifically designed to assess multimodal foundation models in expert-level, knowledge-intensive video understanding and reasoning tasks.",
                "position": 220
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/x6.png",
                "caption": "Table 1:Comparison between\\gradientRGBMMVU53,93,20310,10,80 and existing multi-discipline benchmarks for evaluating foundation models. In the “QA Type” column, “MC” denotes Multiple-Choice questions, “Open” denotes Open-ended questions, and “T/F” denotes True-False questions.",
                "position": 264
            }
        ]
    },
    {
        "header": "3\\gradientRGBMMVU53,93,20310,10,80 Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/x6.png",
                "caption": "Figure 2:An overview of the\\gradientRGBMMVU53,93,20310,10,80 benchmark construction pipeline.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x7.png",
                "caption": "Figure 3:A dataset example from\\gradientRGBMMVU53,93,20310,10,80 with the discipline of chemistry. Each example in\\gradientRGBMMVU53,93,20310,10,80 includes expert annotation of relevant domain knowledge and step-by-step reasoning rational.",
                "position": 703
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x8.png",
                "caption": "Table 2:Key statistics of the\\gradientRGBMMVU53,93,20310,10,80 benchmark.",
                "position": 753
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/x8.png",
                "caption": "Figure 4:Comparison of model performance between CoT and direct answering on the validation set. The full results are provided in §C.1.",
                "position": 2172
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x9.png",
                "caption": "Figure 5:Illustrations of visual perception error and misuse or lack domain knowledge in reasoning.",
                "position": 2223
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Author Contribution",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix A\\gradientRGBMMVU53,93,20310,10,80 Preliminary Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/extracted/6146392/figures/interface/interface1.png",
                "caption": "Figure 6:Annotation Interface - Step 1: Video Collection.\nIn this step, annotators are required to input the YouTube video URL and select the desired question type. The backend system of the interface will automatically verify whether the provided YouTube video is under a Creative Commons license using the YouTube Data API v3. If the video does not meet this requirement, as shown in the figure, a warning message will be displayed, and the submission will be blocked. Once a valid example is submitted, the annotation interface will proceed to Step 2, which is illustrated in the following two figures.",
                "position": 6362
            },
            {
                "img": "https://arxiv.org/html/2501.12380/extracted/6146392/figures/interface/interface2.png",
                "caption": "Figure 7:Annotation Interface - Step 2: Multiple-choice Question Annotation.",
                "position": 6368
            },
            {
                "img": "https://arxiv.org/html/2501.12380/extracted/6146392/figures/interface/interface3.png",
                "caption": "Figure 8:Annotation Interface - Step 2: Open-ended Question Annotation.",
                "position": 6373
            },
            {
                "img": "https://arxiv.org/html/2501.12380/extracted/6146392/figures/interface/interface4.png",
                "caption": "Figure 9:Validation Interface.Human validators are required to thoroughly review each annotation feature to ensure alignment with benchmark construction criteria and annotation guidelines.\nIf revisions are not feasible, detailed feedback must be provided to the original annotator, who will then revise and resubmit the annotation for a second review.\nAdditionally, validators may discard examples deemed to be of low quality and unlikely to meet the desired criteria through revision.",
                "position": 6386
            }
        ]
    },
    {
        "header": "Appendix BExperiment Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12380/x10.png",
                "caption": "Table 10:Details of the multimodal foundation models evaluated in\\gradientRGBMMVU53,93,20310,10,80. The “Source” column includes URLs for proprietary models and Hugging Face model names for open-source models.\nThe “# Input Frames” column, for those models only support multi-image input, represents the default number of input frames, chosen from 2, 4, 8, 16, 32, based on the maximum value that does not exceed the model’s context window. “HF” means “Hugging Face”.",
                "position": 6422
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x10.png",
                "caption": "Figure 16:Comparison of model performance between CoT reasoning and direct answering on the validation set.",
                "position": 6922
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x11.png",
                "caption": "Figure 17:An error case of Thermodynamics.",
                "position": 6930
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x12.png",
                "caption": "Figure 18:An error case of Electromagnetism.",
                "position": 6934
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x13.png",
                "caption": "Figure 19:An error case of Art.",
                "position": 6938
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x14.png",
                "caption": "Figure 20:An error case of Computer Science.",
                "position": 6946
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x15.png",
                "caption": "Figure 21:An error case of Electrical Engineering.",
                "position": 6950
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x16.png",
                "caption": "Figure 22:An error case of Pharmacy.",
                "position": 6954
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x17.png",
                "caption": "Figure 23:An error case of Computer Science.",
                "position": 6962
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x18.png",
                "caption": "Figure 24:An error case of Biology.",
                "position": 6966
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x19.png",
                "caption": "Figure 25:An error case of Chemistry.",
                "position": 6970
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x20.png",
                "caption": "Figure 26:An error case of Clinical Medicine.",
                "position": 6978
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x21.png",
                "caption": "Figure 27:An error case of Management.",
                "position": 6982
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x22.png",
                "caption": "Figure 28:An error case of Mechanical Engineering.",
                "position": 6990
            },
            {
                "img": "https://arxiv.org/html/2501.12380/x23.png",
                "caption": "Figure 29:An error case of Clinical Medicine.",
                "position": 6994
            }
        ]
    },
    {
        "header": "Appendix CExperiment",
        "images": []
    }
]