[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x1.png",
                "caption": "Figure 1:An illustration of the three mechanisms for retrieving bound entities in-context. We find that as models process inputs with groups of entities: (A) binding information of three types—positional, lexical, reflexive—is encoded in the entity tokens of each group, (B) this binding information is jointly used to retrieve entities in-context, and (C) it is possible to separate the three binding signals with counterfactual patching. The counterfactual input is designed such that patching activations to the LM run on the original input results in the positional, lexical, and reflexive mechanisms predicting different entities (See §3.2).",
                "position": 134
            }
        ]
    },
    {
        "header": "2Problem Setup and Prior Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x2.png",
                "caption": "Figure 2:Results from interchange interventions on gemma-2-2b-it over a counterfactual dataset with three entities per group (m=3m=3) (See Figure1and §3.2). Outputs predicted by the positional, lexical and reflexive mechanisms are shown in dark blue, green and orange.Left: Distribution of effects for three representative entity group indices (first, middle, and last) withtentity=3t_{\\text{entity}}{}=3. At layers 16–18, the last token position carries binding information used for retrieval.Right: Distribution of effects for all indices at layer 18 fortentity∈{1,2,3}t_{\\text{entity}}{}\\in\\{1,2,3\\}, i.e., the question can be about any of the three entities in each clause. A U-shaped curve emerges: first and last indices rely more on the positional mechanism, while middle indices rely more on the lexical and reflexive mechanisms. See §Bfor replication across models and tasks, and Figure18for plots using the original prompt as the x-axis.",
                "position": 220
            }
        ]
    },
    {
        "header": "3Three Mechanisms for Retrieving Bound Entities",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x3.png",
                "caption": "Figure 3:The positional mechanism is diffuse for middle entity groups.Left: Confusion matrix (%) of the patched positional index vs. gemma-2-2b-it’s prediction after an interchange intervention (as in Figure1). Counterfactual predictions cluster near the position promoted by the positional mechanism, decaying with distance. Only themixedand positional patch effects from Figure2are shown; see Figure28for other models and tasks.Right: Mean logit distributions withiP=6,iR=14i_{P}=6,i_{R}=14, andiLi_{L}varied, illustrating interaction between the three mechanisms. The lexical and reflexive signals form one-hot peaks, while the positional is broader and more diffuse. These mechanisms also show additive and suppressive effects. See Figures21,22, and23for more distributions.",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x3.png",
                "caption": "",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x4.png",
                "caption": "",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x5.png",
                "caption": "Figure 4:Results for training our full modelℳ​\\mathcal{M}\\text{ }(Lone-hot({L}_{\\text{one-hot}},Rone-hot{R}_{\\text{one-hot}},PGauss){P}_{\\text{Gauss}}), in addition to variants, baselines and ablations.Left: JSS scores for modeling the LM next token distribution overiP,iL,iRi_{P},i_{L},i_{R}. Evaluated on gemma-2-2b-it for themusicbinding task, withte=tentityt_{e}=t_{\\text{entity}}. Our model attains near-perfect JSS, slightly below the oracle. KL values (Table3) show the same trend. All CIs are<0.02<0.02; forℳ\\mathcal{M}andℳ\\mathcal{M}w/ oracle they are<0.002<0.002.Right: Learned weightswlex,wref,wposw_{\\text{lex}},w_{\\text{ref}},w_{\\text{pos}}andσ\\sigmacurve, fortentity=2t_{\\text{entity}}{}=2. Observeσ\\sigmawidens for middle indices and narrows toward the end.",
                "position": 376
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x5.png",
                "caption": "",
                "position": 520
            }
        ]
    },
    {
        "header": "4A Simple Model for Simulating Entity Retrieval In-Context",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x6.png",
                "caption": "Figure 5:Padding results for gemma-2-2b-it on theboxestask.Left: Confusion matrix between the model’s predicted index and the positional index patched in from the counterfactual. This gets increasingly fuzzy for early tokens as padding is increased.Right: Distribution of effects as padding is increased, showing the positional mechanism strengthens at the expense of the lexical mechanism.",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x7.png",
                "caption": "",
                "position": 583
            }
        ]
    },
    {
        "header": "5Introducing Free Form Text into the Task",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AList of Binding Tasks",
        "images": []
    },
    {
        "header": "Appendix BMore Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x8.png",
                "caption": "Figure 6:Evaluation of theTargetRebindinterchange intervention in 9 different models across 3 model families spanning 2-72B parameters, for theboxesbinding task andtentity∈[2]t_{\\text{entity}}{}\\in[2]. We see that the results remain remarkably consistent.",
                "position": 1201
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x9.png",
                "caption": "",
                "position": 1210
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x10.png",
                "caption": "Figure 7:Evaluation of theTargetRebindinterchange intervention in 9 different models across 3 model families spanning 2-72B parameters, for themusicbinding task andtentity=3t_{\\text{entity}}{}=3.",
                "position": 1216
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x11.png",
                "caption": "Figure 8:Evaluation of theTargetRebindinterchange intervention at 1 and 2 layers after the evaluation in Figure6, fortentity=2t_{\\text{entity}}=2. We see that the model shifts from aggregating binding information to retrieving the entities.",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x12.png",
                "caption": "",
                "position": 1231
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x13.png",
                "caption": "Figure 9:The mean logit distribution as a function of the positional index (iPi_{P}), for qwen2.5-7b-it on theboxestask withtentity=2t_{\\text{entity}}{}=2. We can see the the positional binding signal induces a strong and concentrated signal for entity groups in the beginning and the end, while inducing a weak and diffuse one for middle groups.",
                "position": 1237
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x14.png",
                "caption": "Figure 10:Results of theTargetRebindinterchange intervention for gemma-2-2b-it across all tasks and possible values oftentityt_{\\text{entity}}{}.",
                "position": 1243
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x15.png",
                "caption": "Figure 11:Results of theTargetRebindinterchange intervention for qwen2.5-7b-it across all tasks and possible values oftentityt_{\\text{entity}}{}.",
                "position": 1246
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x16.png",
                "caption": "Figure 12:Results for theTargetRebindinterchange intervention on gemma-2-2b-it forn∈[3,20]n\\in[3,20]andtentity=3t_{\\text{entity}}{}=3on theboxestask. We see a trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle.",
                "position": 1257
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x17.png",
                "caption": "Figure 13:Results for theTargetRebindinterchange intervention on gemma-2-2b-it forn∈[3,20]n\\in[3,20]andtentity=3t_{\\text{entity}}{}=3on themusictask. We see a trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle.",
                "position": 1260
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x18.png",
                "caption": "Figure 14:Results for theTargetRebindinterchange intervention on qwen2.5-7b-it forn∈[3,20]n\\in[3,20]andtentity=3t_{\\text{entity}}{}=3on theboxestask. We see a trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle.",
                "position": 1263
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x19.png",
                "caption": "Figure 15:Results for theTargetRebindandtentity=3t_{\\text{entity}}{}=3interchange intervention on qwen2.5-7b-it forn∈[3,20]n\\in[3,20]on themusictask. We see a trend where, the more entity groups need to be bound in context, the worse the positional mechanism is at binding those in the middle.",
                "position": 1266
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x20.png",
                "caption": "Figure 16:We evaluate gemma-2-2b-it’s behavior when aligning the mechanisms for themusictask. We align the positional and reflexive mechanisms fortentity=1t_{\\text{entity}}{}=1, and the positional and lexical mechanisms fortentity=3t_{\\text{entity}}{}=3. We see that when the mechanisms point at the same entity for retrieval, the model consistently responds with the correct entity.",
                "position": 1276
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x21.png",
                "caption": "",
                "position": 1285
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x22.png",
                "caption": "Figure 17:Results for thePosSwap(left),LexSwap(middle) andRefSwap(right) interchange interventions on gemma-2-2b-it for theboxestask. Each square shows the interchange intervention accuracy (IIA) for a given layer and positional, lexical or reflexive index. We see that positional and lexical binding information exists in entity tokens in layers 12-19, while reflexive binding information does in layers 6-12.",
                "position": 1316
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x23.png",
                "caption": "Figure 18:We show results of theTargetRebindinterchange intervention on gemma-2-2b-it for theboxestask with different indices on the x-axis.Left: using the index of the queried entity group. This has little effect overall, except for dips at the first and last indices in the positional effect. UnderTargetRebind, the positions of queried entity groups cannot coincide between the counterfactual and original prompts. Thus, when the original query targets the first or last groups—where positional information is strongest—these groups are never patched, slightly weakening results on average.Right: using the lexical index. Here the pattern mirrors Figure3, with weaker effects at the edges and stronger ones in the middle.",
                "position": 1322
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x24.png",
                "caption": "Figure 19:Separability of hidden states for entity token positions and the last token position, across layers and values ofnn. PCA projections (left) and multinomial logistic regression probes (right) show that first and last entity groups are linearly separable, while middle groups overlap substantially. Separability decreases as the number of entitiesnnincreases.",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x25.png",
                "caption": "",
                "position": 1472
            }
        ]
    },
    {
        "header": "Appendix CThe Reflexive Mechanism",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x26.png",
                "caption": "Figure 20:Patch effects underTargetRebindfor gemma-2-2b-it while blocking attention to the target entity. Left: blocking attention when the model is accumulating binding information in the last token position leads to it not being able to dereference the reflexive pointer. Had the patch contained the retrieved answer, this plot would be fully orange. Right: patching at the following layer and blocking attention to the target entity. Here the plot is fully orange since the entity has already been retrieved.",
                "position": 1669
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x27.png",
                "caption": "Figure 21:Mean logit distributions underTargetRebindfor gemma-2-2b-it on themusictask. Left: fixingiL=8,iR=16i_{L}=8,i_{R}=16and varyingiPi_{P}. Right: fixingiP=6,iL=14i_{P}=6,i_{L}=14and varyingiRi_{R}.",
                "position": 1675
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x28.png",
                "caption": "",
                "position": 1684
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x29.png",
                "caption": "Figure 22:Mean logit distributions underTargetRebindfor qwen2.5-7b-it on themusic task. Left: fixingiP=6,iR=14i_{P}=6,i_{R}=14and varyingiLi_{L}. Right: fixingiP=6,iL=14i_{P}=6,i_{L}=14and varyingiRi_{R}.",
                "position": 1690
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x30.png",
                "caption": "",
                "position": 1699
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x31.png",
                "caption": "Figure 23:Mean logit distributions underTargetRebindfor qwen2.5-7b-it on thesportstask. Left: fixingiL=8,iR=16i_{L}=8,i_{R}=16and varyingiPi_{P}. Right: fixingiP=8,iL=19i_{P}=8,i_{L}=19and varyingiRi_{R}.",
                "position": 1705
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x32.png",
                "caption": "",
                "position": 1714
            }
        ]
    },
    {
        "header": "Appendix DContext Length Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06182/x33.png",
                "caption": "Figure 24:Mean patch effects per number of entities in context (nn). For eachnn, we report the standard mean patch effects (right) alongside results from padded sequences (left), where sequence length is fixed to matchn=20n=20. While padding slightly shifts the distribution of patch effects, the overall patterns remain consistent: model behavior is primarily controlled by the number of entities in context, rather than sequence length.",
                "position": 1727
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x34.png",
                "caption": "Figure 25:Left: results forTargetRebindinterchange intervention on gemma-2-2b-it withtentity=1t_{\\text{entity}}{}=1, where the query entity in the counterfactual does not exist in the original. Right: results forTargetRebindinterchange intervention on gemma-2-2b-it withtentity=2t_{\\text{entity}}{}=2, where the target entity in the counterfactual does not exist in the original. We can see in both plots that when the model can’t use the lexical and reflexive mechanisms since the entities they point to don’t exist, the model falls back to solely using the positional mechanism (distribution showed in Figure26).",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x35.png",
                "caption": "Figure 26:Left: confusion matrix for non-lexical and reflexive patch effects under theTargetRebindinterchange intervention on gemma-2-2b-it withtentity=1t_{\\text{entity}}{}=1, where the query entity in the counterfactual does not exist in the original. Right: results for non-lexical and reflexive patch effects under theTargetRebindinterchange intervention on gemma-2-2b-it withtentity=2t_{\\text{entity}}{}=2, where the queried entity in the counterfactual does not exist in the original. We can see that when the model can’t use the lexical and reflexive mechanisms, it falls back on the noisy positional mechanism.",
                "position": 1746
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x36.png",
                "caption": "Figure 27:Results forTargetRebindinterchange interventions on gemma-2-2b-it withtentity∈[2]t_{\\text{entity}}{}\\in[2], where the query entity (left) or queried entity (right) in the counterfactual do not exist in the original, patching at layerℓ+1\\ell+1. We see that the model copies the retrieved answer from the counterfactual, showing that no mechanism exists to suppresses answering with entities that do not exist in the original prompt.",
                "position": 1752
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x37.png",
                "caption": "Figure 28:Confusion matrix for non-lexical and reflexive patch effects under theTargetRebindinterchange intervention for all models, showing the diffuse distribution around the positional index. Left:tentity=1t_{\\text{entity}}{}=1. Right:tentity=2t_{\\text{entity}}{}=2.",
                "position": 1758
            },
            {
                "img": "https://arxiv.org/html/2510.06182/x38.png",
                "caption": "",
                "position": 1767
            }
        ]
    },
    {
        "header": "Appendix ELLM Usage",
        "images": []
    }
]