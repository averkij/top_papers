[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3The M1 Reasoning Model",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10449/x1.png",
                "caption": "Figure 1:Inference latency when using prompt length 256 and decoding length 4096.",
                "position": 467
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x1.png",
                "caption": "Figure 1:Inference latency when using prompt length 256 and decoding length 4096.",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x2.png",
                "caption": "Figure 2:Inference latency when using batch size 128.",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x3.png",
                "caption": "Figure 3:Number of samples vs. AIME25 accuracy (left) and generation time (seconds) vs. AIME25 accuracy (right). Both graphs include pass@1 and majority voting accuracies forM1and DeepSeek-R1-Distill-Qwen-1.5B.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x4.png",
                "caption": "",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x5.png",
                "caption": "Figure 4:Generation length vs. AIME25 accuracy (left) and generation time (seconds) vs. AIME25 accuracy (right). Sampling for both models is done using a temperature of 0.8.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2504.10449/x6.png",
                "caption": "",
                "position": 528
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10449/x7.png",
                "caption": "Figure 5:Pass@1 vs. maximum sequence length in GRPO training",
                "position": 542
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Future Work",
        "images": []
    }
]