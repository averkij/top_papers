[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.24007/x1.png",
                "caption": "Figure 1:Comparison of decoding paradigms.(a) ALMs: decode one token at a time.\n(b) DLMs (e.g.Block Diffusion): decode all tokens in a fixed block before moving to the next.\n(c) SDLM (Ours): dynamically predicts a contiguous subsequence within a fixed block.\n(d) Performancevs.Speed: MATH-500 results showing trade-off between speed (TPS) and accuracy.",
                "position": 101
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.24007/x2.png",
                "caption": "Figure 2:Structured attention mask for parallel block training and sampling.(a) Reordered input yields a mask with causal prefix (top-left), visible cross-block prefix (bottom-left), and intra-block bidirectional attention (bottom-right).\n(b) Confidence-based next sequence prediction with KV reuse. A block ofDDtokens is predicted withD−1D{-}1masks. The longest high-confidence subsequence is selected as dynamic output. Cached KV states enable efficient decoding.",
                "position": 252
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.24007/figs/ablation_tau.png",
                "caption": "Figure 3:Trade-off between performance and speed under different inference setting for SDLM-3B(D=4)(D=4)and SDLM-3B(D=8)(D=8).Adjustingτ\\tauallows a controllable trade-off between speed and performance. SpeedUp denotes the average number of tokens output per forward pass.",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2509.24007/x3.png",
                "caption": "Figure 4:Ablation on attention mask type and prediction shift strategy.We conduct the following ablation experiments: (1) No shift: predictingxtx_{t}instead ofxt+1x_{t+1}; (2) Leisure precautions: using a causal mask instead. The left image shows its model performance, while the right image shows the acceleration ratio.",
                "position": 818
            },
            {
                "img": "https://arxiv.org/html/2509.24007/x4.png",
                "caption": "Figure 5:Visualization of the sampling process.Where each blue block indicates a subsequence generated in a single decoding step.",
                "position": 841
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Training",
        "images": []
    },
    {
        "header": "Appendix BCompare with Multi-Token Prediction",
        "images": []
    }
]