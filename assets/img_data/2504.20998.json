[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x1.png",
                "caption": "Figure 1:Image Reconstruction. The generated image, conditioned on a personalized prompt, is compared with the ground truth image to calculate the image reconstruction loss.",
                "position": 161
            }
        ]
    },
    {
        "header": "3Yo’Chameleon",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x2.png",
                "caption": "Figure 2:“Soft positive” images. Retrieved images are ranked according to their similarity to positive images using CLIP image similarity scores. Images that are more similar to the actual positive images are described with more latent tokens (i.e., more details).",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2504.20998/x3.png",
                "caption": "Figure 3:Optimized tokens for one task cannot effectively perform another, and simply training on a mixture of data yields suboptimal performance across tasks. We propose a self-prompting approach, where the model predicts which task to perform first, achieving the best of both worlds. (Input images are given in Fig.LABEL:fig:feature-graphic).",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2504.20998/x4.png",
                "caption": "Figure 4:Self-prompting mechanism. When multiple tasks are presented, the model first predicts which information (latent tokens) should be used for this task first, and then performs the task.",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2504.20998/x5.png",
                "caption": "Figure 5:Qualitative comparison with Chameleon[1]and GPT-4o[2]on image prompting. Yo’Chameleon (Ours) demonstrates more precise and personalized image generation.",
                "position": 250
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x6.png",
                "caption": "Table 1:Comparisons with Chameleon[1]and GPT-4o[2]using personalized image/text prompts. Our approach achieves significantly improved personalized image generation capabilities.",
                "position": 278
            },
            {
                "img": "https://arxiv.org/html/2504.20998/x7.png",
                "caption": "Figure 7:Ablation studies for image generation tasks. Overall, using “soft positive” and increasing the latent tokens boost performance.",
                "position": 427
            }
        ]
    },
    {
        "header": "5Ablation Studies",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Full-model Finetuning vs. Soft Prompt",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x8.png",
                "caption": "Figure 8:With 300+ real images, soft-prompt tuning can match the performance of full-model fine-tuning while retaining the model’s overall abilities. We cannot show the facial results due to anonymity.",
                "position": 1411
            }
        ]
    },
    {
        "header": "8Additional Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x9.png",
                "caption": "Figure 9:Ablation studies on the number of “soft-positive” images. Generally, increasing the number of “soft-positive” images helps to boost performance.",
                "position": 1652
            }
        ]
    },
    {
        "header": "9Data Augmentation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20998/x10.png",
                "caption": "Figure 10:Comparison of data augmentation methods. Using ‘Soft-Positive” images can increase both diversity and realism of the training data.",
                "position": 1689
            },
            {
                "img": "https://arxiv.org/html/2504.20998/x11.png",
                "caption": "Figure 11:Limitations. (a) lacks of details; (b) Generate multiple subjects",
                "position": 1696
            }
        ]
    },
    {
        "header": "10Limitation",
        "images": []
    }
]