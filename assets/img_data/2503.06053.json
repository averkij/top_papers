[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06053/x1.png",
                "caption": "Figure 1:Comparisons between Composable Spatio-temporal Consistency and Integral Spatio-temporal Consistency.(a)Composable Spatio-Temporal Consistencyrefers to the straightforward combination of temporal and spatial consistency, without limiting the effects of camera movement. Studies such as MovieGen[49]and VBench++[26]are dedicated to realizing this consistency. Despite the potential emergence of a new scene post camera movement, the introduced scene tends to be stationary, precluding the onset of further motion.\n(b)Integral Spatio-Temporal Consistencyconsiders the interplay between plot development and camera techniques, along with the enduring influence of antecedent content on subsequent creation.\nThis is because a camera movement may introduce or eliminate objects, thereby overlaying and impacting the preceding storyline.\nFor example in the ‚ÄúForrest Gump‚Äù clip, achieving integral spatio-temporal consistency requires incorporating the motion of the ‚Äúcar‚Äù as it recedes following the camera‚Äôs ‚Äúturn right‚Äù action while maintaining the scene of Forrest running, ensuring that ‚ÄúForrest Gump‚Äôs right remains at a consistent distance‚Äù, preserving the correct spatial relationships.\nTemporal consistency in plot progression is highlighted in theblueregion, while theredregion denotes spatial consistency induced by camera movement",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x2.png",
                "caption": "Figure 2:TheDropletVideo-10Mdataset features diverse camera movements, long-captioned contextual descriptions, and strong spatio-temporal consistency.(a) Existing datasets, such as Panda-70M[11], place less emphasis on camera movement and contain relatively brief captions. (b) In contrast,DropletVideo-10Mconsists of spatio-temporal videos that incorporate both camera movement and event progression. Each video is paired with a caption that conveys detailed spatio-temporal information aligned with the video content, with an average caption length of 206 words. The spatio-temporal information is highlighted in red in the figure.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06053/x3.png",
                "caption": "Figure 3:The pipeline we proposed to curate theDropletVideo-10Mdataset.",
                "position": 710
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x4.png",
                "caption": "Figure 4:The aesthetics distribution and the image quality distribution ofDropletVideo-10M.These distributions demonstrate that our dataset achieveshigh scoresin both aesthetics and image quality, indicating an overallhigh-quality standardfor the dataset.",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x5.png",
                "caption": "Figure 5:Captions generated by the fine-tuned models,including InternVL2-8B[13,14], ShareGPT4Video-8B[10], ShareCaptioner-video[10], and MA-LMM[22]. InternVL2-8B[13,14]captures intricate camera work and narrative elements with high efficacy.",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x6.png",
                "caption": "Figure 6:Results of the fine-tuned video captioning model.In the prompts, descriptions related to camera motions are highlighted inred. It is evident from the training samples that the camera undergoes multiple motion changes. Moreover, the scene details in the videos are clearly described and accurately followed as the camera moves. These high-density informational text captions significantly enhance the spatio-temporal semantics of the videos. Consequently, our video captions in theDropletVideo-10Mdataset provide enriched guidance for training video generation models.",
                "position": 771
            }
        ]
    },
    {
        "header": "4The DropletVideo Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06053/x7.png",
                "caption": "Figure 7:Overview of theDropletVideoFramework.The video is processed by the 3D causal Variational Autoencoder (VAE) following adaptive equalization sampling, which is steered by the motion intensityMùëÄMitalic_M.\nThe video featurexvsubscriptùë•ùë£x_{v}italic_x start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPTis then input into the Modality-Expert Transformer, depicted on the right side of the figure, to facilitate video generation in conjunction with the text encodingxtsubscriptùë•ùë°x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and the combined encodingxT&Msubscriptùë•ùëáùëÄx_{T\\&M}italic_x start_POSTSUBSCRIPT italic_T & italic_M end_POSTSUBSCRIPTof the temporalTùëáTitalic_Tand the motion intensityMùëÄMitalic_M.\nThe upper left part illustrates the contrast between (a)the traditional sampling approachand (b)DropletVideo‚Äôs adaptive equalization sampling.\nTraditional methods involve random segment interception followed by fixed-frame-rate sampling of the intercepted segments, whereasDropletVideoemploys adaptive frame rate sampling across the entire video segments, guided byMùëÄMitalic_M.",
                "position": 802
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06053/x8.png",
                "caption": "Figure 8:DropletVideofacilitates the generation of videos that maintain integral spatio-temporal consistency.New objects or scenes introduced via camera movement are seamlessly integrated and interact logically with the pre-existing scenes. In video (a), as the camera moves, a new boat appears on the lake, the boat on the right of the original two boats continues to slowly chase the boat on the left, and the leaves on the shore still sway gently in the breeze. In video (b), as the camera moves left, the tree called for in the text prompt successfully appears in the shot, the original flock of birds continues to fly, and the grass and sky show continuity as the camera moves.",
                "position": 916
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x9.png",
                "caption": "Figure 9:DropletVideodemonstrates advanced controllability in generating scenes where new objects emerges due to camera movement.In video (a), as the camera pans right, the red apple specified in the prompt appears seamlessly, while the chef continues cooking, illustrating smooth integration of new objects. Video (b) showcases the system‚Äôs ability to handle detailed descriptions, as the prompt‚Äôs depiction of an apple with water droplets is rendered accurately, highlighting complex textures. In video (c), a prompt modification adds brown spots to the apple, which are visibly integrated, showing dynamic visual adjustments. Finally, in video (d), the prompt changes the apple to bananas, and the system adeptly features bananas, demonstrating versatility and precision in object transformation.",
                "position": 944
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x10.png",
                "caption": "Figure 10:DropletVideodemonstrates excellent 3D consistency. In the top example, the camera moves around a snowflake, showcasing significant camera movement while maintaining the snowflake‚Äôs details from multiple perspectives. In the bottom example, the camera circles around an insect, andDropletVideoensures the insect‚Äôs 3D consistency across a wide range of rotation angles. However,DropletVideostill has limitations in generating content for a full 360-degree rotation, which will be addressed in future work. Overall, these examples illustrateDropletVideo‚Äôs strong performance in spatial 3D consistency.",
                "position": 963
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x11.png",
                "caption": "Figure 11:DropletVideofacilitates precision control over video generation speed. Modifying the Input Speed parameter alters the movement speed of both the camera and target. In the third line, the camera motion parameterMùëÄMitalic_Mis doubled, and the snowflake‚Äôs rotation speed is substantially decreased compared to the initial setting.",
                "position": 981
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x12.png",
                "caption": "Figure 12:DropletVideoshowcases its robust capabilities in generating videos with diverse camera movements.Panels (a)-(e) illustrate the outcomes of specific camera motions: Camera Truck Right, Camera Truck Left, Camera Pedestal Down, Camera Tilt Up, and Camera Dolly In. Panel (f) presents a composite camera shot that combines Camera Pan Right and Tilt Up.",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x13.png",
                "caption": "Figure 13:Snow example.The videos generated byDropletVideo, Kling, and Vivago all maintain consistency with the prompt in terms of camera movement and various elements within the video. Their video quality is at the same level.",
                "position": 1029
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x14.png",
                "caption": "Figure 14:Boat example.OurDropletVideo, along with Hailuo, WanX, and Kling v1.6, correctly understood the movement of the boat and the camera motion. However, these three models failed to ensure that the motion of the leaves remained logically consistent with the camera movement, resulting in the leaves moving synchronously with the camera, which is an unnatural effect. In contrast, our model maintains the relative motion consistency between the camera, boat, and leaves in the generated video. This is a typical demonstration of its integral spatio-temporal consistency capability.",
                "position": 1032
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x15.png",
                "caption": "Figure 15:Sunset example.OnlyDropletVideoand Kling v1.6 successfully ensure the correct alignment between camera movement and object positioning. However, in Kling‚Äôs generated video, the lighting reflections on the clouds remain unchanged, lacking natural variation. In contrast, in our model‚Äôs generated video, as the camera moves, the light reflections on the clouds dynamically adjust, making the scene more consistent with real-world natural phenomena.",
                "position": 1035
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x16.png",
                "caption": "Figure 16:Kitchen example.We expect the focus of the video to transition from the chef to a red apple as the camera moves. OnlyDropletVideosuccessfully achieved this transition, while other models failed to correctly generate ‚Äúa red apple‚Äù after the camera movement. Besides, it also ensures that the apple it generates are of a reasonable size and are positioned appropriately within the scene.",
                "position": 1038
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x17.png",
                "caption": "Figure 17:Staircase example.We required the camera to move smoothly up the stairs, ensuring that its trajectory remains logically consistent with the staircase in the video. Only ourDropletVideoand Gen3 successfully maintained the correct camera movement path. However, Runway failed to generate key elements such as wall decorations and lights.",
                "position": 1041
            },
            {
                "img": "https://arxiv.org/html/2503.06053/x18.png",
                "caption": "Figure 18:Lake example.The camera movement path is complex‚Äîit first moves to the right, then tilts upward, while the elements in the video change accordingly. All other models failed to accurately capture this camera movement, except for ourDropletVideo. Our model not only strictly followed the prompt in executing the camera motion but also dynamically altered the scene, successfully revealing the sky and white clouds, which were not present in the initial image.",
                "position": 1044
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]