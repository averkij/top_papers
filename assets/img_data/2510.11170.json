[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11170/x1.png",
                "caption": "Figure 1:Left:We introduceEAGer, a generation method that dynamically allocates the per-prompt budget during decoding, branching only when high-entropy peaks are detected. For each prompt, the total number of allowed sequences is capped atMM, and we track the actual budget consumed by our preparatory stage,EAGer-init. The remaining budget is evenly allocated among prompts reaching theMMcap (EAGer-adapt) or, in case targets labels are accessible, prompts not reaching a correct final solution (i.e. with Pass@k = 0; our fullEAGer), in contrast to the fixed-budget allocation ofFull Parallelsampling.Right:Our approaches (EAGer-init,-adaptand fullEAGer) consistently reduce token usage compared to the standardFull Parallelsamplingapproach when scaling theMMlimit∈[4,8,16,24,32]\\in[4,8,16,24,32]. In addition,EAGeralways achieves a clear performance advantage over all other decoding methods.",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11170/x2.png",
                "caption": "Figure 2:For each sequence generated by Qwen3 4B withFull Parallelsampling (M=32M=32), we report its Pass Rate accuracy and the average entropy peak (pth=99.9p^{\\text{th}}=99.9). The results reveal a negative correlation (r=−0.547r=-0.547) between Pass Rate and the average entropy peak across sequences. Notably, sequences exhibiting higher entropy at any generation step are less likely to yield a correct answer.",
                "position": 216
            }
        ]
    },
    {
        "header": "3Entropy-Aware GEneRation Explained",
        "images": []
    },
    {
        "header": "4Experimental Setting and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11170/x3.png",
                "caption": "Figure 3:Compute and performance trade-offs ofEAGer-init andEAGer. Across all benchmarks and model size, the efficiency ofEAGer-init andEAGerconsistently outperformsFull Parallelsampling, requiring only half as many tokens in most cases (top). In addition, they achieve higher pass rate accuracy (bottom). For issues specific to the smallest 3B model, see AppendixB.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2510.11170/x4.png",
                "caption": "Figure 4:Performance comparison with scaling the total allowed sequences for generating (M∈{1,4,8,16,24,32}M\\in\\{1,4,8,16,24,32\\}).\nAsMMincreases (line’s markers),EAGerconsistently improves Pass@k (y-axis) while reducing the number of tokens needed to find the correct solution (x-axis), further shifting the Pareto frontier of the performance–efficiency trade-off.",
                "position": 1009
            }
        ]
    },
    {
        "header": "5Related works",
        "images": []
    },
    {
        "header": "6Conclusion and Future Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComplete results",
        "images": []
    },
    {
        "header": "Appendix BEffect of Temperature",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11170/x5.png",
                "caption": "Figure 5:Pass@k and Cons@k at low (τ=0.6\\tau=0.6) and high(τ=0.6\\tau=0.6) temperature settings. Horizontal lines show the performance for the default sampling method, while the bars showEAGer’s performance for varying entropy threshold levelsθ\\theta.",
                "position": 3067
            }
        ]
    },
    {
        "header": "Appendix CGeneration params",
        "images": []
    }
]