[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/extracted/6575244/Figs/framework.png",
                "caption": "Figure 2:Overview of NeRF unmixing approach.Given a viewing direction(θ,ϕ)𝜃italic-ϕ(\\theta,\\phi)( italic_θ , italic_ϕ )and 3D coordinates(x,y,z)𝑥𝑦𝑧(x,y,z)( italic_x , italic_y , italic_z ), our network predicts a densityσ𝜎\\sigmaitalic_σand a set of abundance vectors𝐚~~𝐚\\tilde{\\mathbf{a}}over~ start_ARG bold_a end_ARG, along with scalar factors𝐬~~𝐬\\tilde{\\mathbf{s}}over~ start_ARG bold_s end_ARGthat scale the spectral endmembers𝐄𝐄\\mathbf{E}bold_E. The scaled endmembers, when multiplied by the predicted abundances𝐚~~𝐚\\tilde{\\mathbf{a}}over~ start_ARG bold_a end_ARG, yield the diffuse reflectance component𝐜dsubscript𝐜𝑑\\mathbf{c}_{d}bold_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT.\nIn parallel, a specular reflectance𝐜ssubscript𝐜𝑠\\mathbf{c}_{s}bold_c start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTand an additional tint factorhℎhitalic_hare also predicted to capture local illumination effects.\nThe final spectral radiance is obtained by combining these diffuse and specular components𝐜d+𝐜~ssubscript𝐜𝑑subscript~𝐜𝑠\\mathbf{c}_{d}+\\tilde{\\mathbf{c}}_{s}bold_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT + over~ start_ARG bold_c end_ARG start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTunder volumetric rendering with the predicted density.\nAnℓ2subscriptℓ2\\ell_{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTloss on the reconstructed spectral signatures is sufficient to guide unmixing and specular-diffuse modeling.",
                "position": 147
            }
        ]
    },
    {
        "header": "4Proposed Method",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/x2.png",
                "caption": "Figure 3:Visualization of the top-4 performing methods for frame 51 out of 359 for the Caladium plant scene from the Bayspec dataset. The top row shows the 70th spectral channel out of the 141-channel predicted image, and the bottom row provides a raw pixel-wise mean relative absolute error heatmap of the scene.",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2506.21884/x3.png",
                "caption": "Figure 4:Visualization of the learned material abundance maps for theAnacampserosscene from the BaySpec dataset (top row) and theAjarscene from the NeSpoF dataset (bottom row). Each map represents the spatial distribution of a material’s abundance, highlighting distinct materials in the scene.",
                "position": 926
            },
            {
                "img": "https://arxiv.org/html/2506.21884/x4.png",
                "caption": "Figure 5:Unsupervised material segmentation of theAjarscene.",
                "position": 941
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]