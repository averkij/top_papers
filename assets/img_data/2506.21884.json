[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/extracted/6575244/Figs/framework.png",
                "caption": "Figure 2:Overview of NeRF unmixing approach.Given a viewing direction(Î¸,Ï•)ğœƒitalic-Ï•(\\theta,\\phi)( italic_Î¸ , italic_Ï• )and 3D coordinates(x,y,z)ğ‘¥ğ‘¦ğ‘§(x,y,z)( italic_x , italic_y , italic_z ), our network predicts a densityÏƒğœ\\sigmaitalic_Ïƒand a set of abundance vectorsğš~~ğš\\tilde{\\mathbf{a}}over~ start_ARG bold_a end_ARG, along with scalar factorsğ¬~~ğ¬\\tilde{\\mathbf{s}}over~ start_ARG bold_s end_ARGthat scale the spectral endmembersğ„ğ„\\mathbf{E}bold_E. The scaled endmembers, when multiplied by the predicted abundancesğš~~ğš\\tilde{\\mathbf{a}}over~ start_ARG bold_a end_ARG, yield the diffuse reflectance componentğœdsubscriptğœğ‘‘\\mathbf{c}_{d}bold_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT.\nIn parallel, a specular reflectanceğœssubscriptğœğ‘ \\mathbf{c}_{s}bold_c start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTand an additional tint factorhâ„hitalic_hare also predicted to capture local illumination effects.\nThe final spectral radiance is obtained by combining these diffuse and specular componentsğœd+ğœ~ssubscriptğœğ‘‘subscript~ğœğ‘ \\mathbf{c}_{d}+\\tilde{\\mathbf{c}}_{s}bold_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT + over~ start_ARG bold_c end_ARG start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTunder volumetric rendering with the predicted density.\nAnâ„“2subscriptâ„“2\\ell_{2}roman_â„“ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTloss on the reconstructed spectral signatures is sufficient to guide unmixing and specular-diffuse modeling.",
                "position": 147
            }
        ]
    },
    {
        "header": "4Proposed Method",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21884/x2.png",
                "caption": "Figure 3:Visualization of the top-4 performing methods for frame 51 out of 359 for the Caladium plant scene from the Bayspec dataset. The top row shows the 70th spectral channel out of the 141-channel predicted image, and the bottom row provides a raw pixel-wise mean relative absolute error heatmap of the scene.",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2506.21884/x3.png",
                "caption": "Figure 4:Visualization of the learned material abundance maps for theAnacampserosscene from the BaySpec dataset (top row) and theAjarscene from the NeSpoF dataset (bottom row). Each map represents the spatial distribution of a materialâ€™s abundance, highlighting distinct materials in the scene.",
                "position": 926
            },
            {
                "img": "https://arxiv.org/html/2506.21884/x4.png",
                "caption": "Figure 5:Unsupervised material segmentation of theAjarscene.",
                "position": 941
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]