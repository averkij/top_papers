[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-globe.png",
                "caption": "Table 1.Overview of number of documents, number of tokens and median sequence length per source domain comprised in the German Commons corpus.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-speech.png",
                "caption": "",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-scales.png",
                "caption": "",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-newspaper.png",
                "caption": "",
                "position": 278
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-bank.png",
                "caption": "",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-microscope.png",
                "caption": "",
                "position": 338
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Sourcing Open German Text Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-globe.png",
                "caption": "Table 2.Overview on datasets constituting the German Commons corpus. Token counts are measured using GPT-2 tokenizer. ‘Various’ licenses are open, but differ per document as per original source.",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-link.png",
                "caption": "Table 3.Licenses of data constitutingGerman Commons.",
                "position": 1575
            }
        ]
    },
    {
        "header": "4.Data Processing",
        "images": []
    },
    {
        "header": "5.Corpus Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-books.png",
                "caption": "Table 5.Split Composition by domain for different training context lengthsss. Assumes disjoint splits, i.e.,s≤8192s\\leq 8192contains all sequences2048<s≤81922048<s\\leq 8192. Percentage for∑\\sumis in relation to full dataset.",
                "position": 1985
            },
            {
                "img": "https://arxiv.org/html/2510.13996/x1.png",
                "caption": "Figure 1.Cumulative proportion of tokens by document length in corpus, normalized by domain;Xoverall (dashed), and by subset forXcultural,Xeconomic,Xlegal,Xnews,Xpolitical,Xscientific,Xweb.",
                "position": 2242
            },
            {
                "img": "https://arxiv.org/html/2510.13996/emoji-books.png",
                "caption": "Table 7.Number of tokens per license type and domain.",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2510.13996/x2.png",
                "caption": "Figure 2.Proportion of text complexity (Xeasy,Xsimple,Xeveryday,Xspecial\n) across paragraph sample, per subset.",
                "position": 2628
            },
            {
                "img": "https://arxiv.org/html/2510.13996/x3.png",
                "caption": "Figure 3.Proportion of text sentiment classes (Xnegative,Xneutral,Xpositive\n) across paragraph sample, per domain.",
                "position": 2639
            }
        ]
    },
    {
        "header": "6.Limitations and Ethical Considerations",
        "images": []
    },
    {
        "header": "7.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Filtering",
        "images": []
    },
    {
        "header": "Datasheet: German Commons",
        "images": []
    }
]