[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.17811/x1.png",
                "caption": "Figure 1:Given sparse-view images as input,MeshSplatcan directly predict the scene geometry and efficiently extract the scene mesh. Compared to MVSplat[10]and other state-of-the-art methods, Meshplat achieves more consistent and precise mesh extraction ingeneralizable sparse-view surface reconstruction.",
                "position": 76
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.17811/x2.png",
                "caption": "Figure 2:Motivation.(a) The ellipsoid shape of 3DGS leads to different intersection planes in different viewpoints, resulting in inconsistent surface. (b) 2DGS has consistent intersection planes in different viewpoints, which is more suitable for surface reconstruction. (c) When the positions and orientations of 2DGS are not regularized, there will be significant discrepancies between 2DGS and the contours of the surface, which hinders the reconstruction of scene surfaces.",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.17811/x3.png",
                "caption": "Figure 3:Overall Architecture.Taken a pair of images as input, MeshSplat begins with a multi-view backbone to extract per-view feature maps. Then we construct per-view cost volumes via the plane-sweeping to generate coarse depth maps, which can be projected to 3D point clouds and be constrained by our proposed Weighted Chamfer Distance Loss. We further feed cost volumes into our gaussian prediction network, together with a depth refinement network and a normal prediction network, to obtain pixel-aligned 2DGS. Finally, we use these 2DGS to render novel view for supervision and reconstruct the scene mesh.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x4.png",
                "caption": "Figure 4:Quanlitative Comparisons on Re10K Dataset.While the baseline methods provide meshes with holes and uneven surfaces, MeshSplat successfully reconstruct the scene with smoother and more complete meshes.",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x5.png",
                "caption": "",
                "position": 335
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.17811/x6.png",
                "caption": "Figure 6:Qualitative Comparisons in Zero-Shot Transfer Experiments on Scannet and Replica Datasets.Compared to MVSplat, MeshSplat can still extract smoother surfaces, demostrating its generalization across different datasets.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x7.png",
                "caption": "Figure 7:Visualizations of output depth and normal maps, confidence maps used in WCD loss and kappa maps used in normal loss.The confidence maps reflect the unconfident matching areas like texture-less areas and non-overlapped areas between the two views. For kappa maps, areas with higher uncertainty typically correspond to object boundaries.",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x8.png",
                "caption": "Figure 8:Qualitative Ablation Studies.(a) Ablation studies on our proposed modules. (b) Comparisons of normal maps rendered by 2DGS and 3DGS.",
                "position": 651
            }
        ]
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Uncertainty-Guided Negative Log-Likelihood Loss in Normal Prediction",
        "images": []
    },
    {
        "header": "8Datasets",
        "images": []
    },
    {
        "header": "9Additional Implementation Details",
        "images": []
    },
    {
        "header": "10Additional Experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.17811/x9.png",
                "caption": "Figure 9:Additional Visualizations of Extracted Meshes in Re10K Datasets.",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x10.png",
                "caption": "Figure 10:Additional Visualizations of Extracted Meshes in Scannet Datasets.",
                "position": 1782
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x11.png",
                "caption": "Figure 11:Visualizations of our ground-truth dense point clouds provided by COLMAP in Re10K datasets.",
                "position": 1785
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x12.png",
                "caption": "Figure 12:Additional Visualizations of Extracted Meshes in Cross-Dataset Generalization Experiments.",
                "position": 1788
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x13.png",
                "caption": "Figure 13:Visualizations of Rendered RGB Images, Depth Maps and Normal Maps in the Scannet Dataset.",
                "position": 1791
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x14.png",
                "caption": "Figure 14:Predicted Depth Maps and Normal Maps of the Gaussian Prediction Network.",
                "position": 1794
            },
            {
                "img": "https://arxiv.org/html/2508.17811/x15.png",
                "caption": "Figure 15:Failure Cases of MeshSplat.",
                "position": 1797
            }
        ]
    },
    {
        "header": "11Video Demo",
        "images": []
    }
]