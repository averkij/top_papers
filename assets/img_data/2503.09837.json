[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09837/x1.png",
                "caption": "Figure 1:Comparison of image augmentation understanding between humans and Vision Language Models (CLIP/SigLIP). While humans can recognize and describe image transformations like rotation, brightness adjustment, and contrast changes, Vision Language Models show significant limitations in comprehending these basic image manipulations.",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Dataset & Augmentation Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09837/x2.png",
                "caption": "Figure 2:Distribution of individual augmentations applied to the Flickr8k dataset. The augmentations span across multiple transformation types including geometric (rotations, flips), color adjustments (brightness, contrast, saturation), clarity modifications (blur, sharpness), and various image processing effects.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x3.png",
                "caption": "Figure 3:Distribution of augmentations applied to the dataset. The augmentations are grouped into six primary categories: Geometric (rotations and flips), Color (brightness, contrast, saturation, and hue adjustments), Clarity (blur and sharpness), Distortion (perspective and affine transformations), Size (cropping and stretching), and Processing (noise, solarization, posterization, and other effects).",
                "position": 306
            }
        ]
    },
    {
        "header": "4Evaluation of Vision Language Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09837/x4.png",
                "caption": "Figure 4:Accuracy comparison of model performance on augmented prompt recognition. Higher values indicate better understanding of the relationship between textual descriptions of transformations and their visual manifestations.",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x5.png",
                "caption": "Figure 5:Comparison of model performance on augmentations grouped according to their properties.",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x6.png",
                "caption": "Figure 6:Mean difference between similarity of augmented image with actual prompt and augmented image with augmented prompt",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x7.png",
                "caption": "Figure 7:Per Augmentation Accuracy Experiment 2",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x8.png",
                "caption": "Figure 8:Per Augmentation Accuracy Experiment 2",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2503.09837/x9.png",
                "caption": "Figure 9:Top-1 Accuracy per Augmentation type for all models",
                "position": 658
            }
        ]
    },
    {
        "header": "5Impact on Downstream task",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09837/extracted/6274377/fig/dalle_orig.jpg",
                "caption": "Table 4:Qualitative analysis table comparing input images and output transformations (rotation 90 degrees) for different models.",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2503.09837/extracted/6274377/fig/Dalle_rotated_90.jpg",
                "caption": "",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2503.09837/extracted/6274377/fig/14866578404_d4ba6f82be_c.jpg",
                "caption": "",
                "position": 788
            },
            {
                "img": "https://arxiv.org/html/2503.09837/extracted/6274377/fig/instruct_pix2pixrotate70.png",
                "caption": "",
                "position": 789
            },
            {
                "img": "https://arxiv.org/html/2503.09837/extracted/6274377/fig/ip_adapter_90.jpg",
                "caption": "",
                "position": 794
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]