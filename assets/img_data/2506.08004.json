[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08004/x1.png",
                "caption": "Figure 1:From real-world complex scenes to AI-generated videos, our method preserves identity fidelity and synthesizes plausible novel views by operating entirely in noise initialization phase.",
                "position": 101
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08004/x2.png",
                "caption": "Figure 2:Approaches to Zero-Terminal SNR Collapse Problem.(b) Low strength preserves source content but renders unseen regions as black. (c) High strength improves propagation into unseen areas but causes identity drift. (d) DDIM inverted latent as initial noise leads towashed-out, high saturation generation. (f) Our K-RNR (k=66k=6italic_k = 6) with Stochastic Latent Modulation preserves identity and completes newly visible regions with plausible content.",
                "position": 147
            }
        ]
    },
    {
        "header": "3Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08004/x3.png",
                "caption": "Figure 3:Overview of Our Method.(Left) We lift a monocular video into a dynamic 3D point cloud and render novel views under target camera trajectories, revealing unseen regions. (Right) Our method synthesizes coherent outputs by initializing noise with K-order Recursive Noise Representation, and Stochastic Latent Modulation without modifying the video model.",
                "position": 184
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08004/x4.png",
                "caption": "Figure 4:K-RNR Analysis(a) Cosine similarity between系(k)superscriptbold-italic-系\\boldsymbol{\\epsilon}^{(k)}bold_italic_系 start_POSTSUPERSCRIPT ( italic_k ) end_POSTSUPERSCRIPTand VAE-encoded latent0subscript0\\mathbf{x}_{0}bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. (b) For increasingkkitalic_kvalues, the mean and (c) the variance of系(k)superscriptbold-italic-系\\boldsymbol{\\epsilon}^{(k)}bold_italic_系 start_POSTSUPERSCRIPT ( italic_k ) end_POSTSUPERSCRIPTexplodes.",
                "position": 217
            },
            {
                "img": "https://arxiv.org/html/2506.08004/x5.png",
                "caption": "Figure 5:Expected Norm Deviation",
                "position": 269
            },
            {
                "img": "https://arxiv.org/html/2506.08004/x6.png",
                "caption": "Figure 6:Adaptive K-RNR",
                "position": 339
            },
            {
                "img": "https://arxiv.org/html/2506.08004/x7.png",
                "caption": "Figure 7:Stochastic Latent Modulation Motivation.To evaluate the models capacity for physical plausibility in unseen regions, we modify the rendered input with occlusion-filling strategies. (a) Camera motion trajectory. (b) Original render frame. (c) Occluded regions are filled by repeating a background patch. (d) Resulting frame generated by combining the filled render with系invsubscriptitalic-系inv\\epsilon_{\\text{inv}}italic_系 start_POSTSUBSCRIPT inv end_POSTSUBSCRIPTusing K-RNR, demonstrating plausible yet artifact-prone content synthesis in unseen areas.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2506.08004/x8.png",
                "caption": "Figure 8:Qualitative Comparison.K-RNR with SLM better preserves subject identity and ensures that synthesized regions remain consistent with the original scene.",
                "position": 408
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Table of Contents",
        "images": []
    },
    {
        "header": "Appendix ASymbols and Notations",
        "images": []
    },
    {
        "header": "Appendix BElaboration on Proposition 4.1",
        "images": []
    },
    {
        "header": "Appendix CElaboration on Proposition 4.2",
        "images": []
    },
    {
        "header": "Appendix DElaboration on Stochastic Latent Modulation",
        "images": []
    },
    {
        "header": "Appendix EMore Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08004/x9.png",
                "caption": "Figure 4:Video Reconstruction Strategies.We perform quantitative and qualitative evaluation on video reconstruction without camera transformation application. Video results can be found in the supplementary material.",
                "position": 1988
            }
        ]
    },
    {
        "header": "Appendix FDiscussion on Quantitative Results",
        "images": []
    }
]