[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02327/x1.png",
                "caption": "Figure 1:(a) An instance from VideoMME(Fu et al.,2024). The crucial information pertains to only a small portion of the video for different questions. (b) Performance comparison of PPLLaVA with recent strong Video LLM among video benchmarks, image benchmarks, and efficiency. All the models are based on Vicuna-7B.",
                "position": 73
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02327/x2.png",
                "caption": "Figure 2:The overview of PPLLaVA for compressing the video based on user prompts and generating responses on the input video and instructions.",
                "position": 109
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02327/x3.png",
                "caption": "Figure 3:Spatial pooling effects. We setT=16𝑇16T=16italic_T = 16andkt=dt=1subscript𝑘𝑡subscript𝑑𝑡1k_{t}=d_{t}=1italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, varying the spatial kernel size and stride.",
                "position": 1180
            },
            {
                "img": "https://arxiv.org/html/2411.02327/x3.png",
                "caption": "Figure 3:Spatial pooling effects. We setT=16𝑇16T=16italic_T = 16andkt=dt=1subscript𝑘𝑡subscript𝑑𝑡1k_{t}=d_{t}=1italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, varying the spatial kernel size and stride.",
                "position": 1183
            },
            {
                "img": "https://arxiv.org/html/2411.02327/x4.png",
                "caption": "Figure 4:Temporal pooling effects. We setT=32𝑇32T=32italic_T = 32andkw=dw=kh=dh=3subscript𝑘𝑤subscript𝑑𝑤subscript𝑘ℎsubscript𝑑ℎ3k_{w}=d_{w}=k_{h}=d_{h}=3italic_k start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT = 3, varying the temporal kernel size and stride.",
                "position": 1188
            },
            {
                "img": "https://arxiv.org/html/2411.02327/x5.png",
                "caption": "Figure 5:The visualization of the attention weights used to guide video pooling.",
                "position": 1507
            },
            {
                "img": "https://arxiv.org/html/2411.02327/x6.png",
                "caption": "Figure 6:Qualitative result of video summary and detailed video description.",
                "position": 1529
            }
        ]
    },
    {
        "header": "5Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02327/x7.png",
                "caption": "Figure 7:Qualitative result of multi-turn video conversation and reasoning.",
                "position": 1540
            }
        ]
    },
    {
        "header": "6Limitation",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]