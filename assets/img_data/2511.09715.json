[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09715/x1.png",
                "caption": "",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3SliderEdit: Continuous Image Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09715/x2.png",
                "caption": "Figure 2:Instruction-token embedding interpolation for strength control.Interpolating between instruction and null-token embeddings produces intermediate edit strengths, demonstrating the potential for achieving fine-grained control through direct manipulation of intermediate instruction embeddings.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x3.png",
                "caption": "Figure 3:Overview of the SliderEdit training pipeline.Learnable low-rank matrices are applied to the intermediate token embeddings corresponding to the target edit instruction. These adapters are trained using the Partial Prompt Suppression (PPS) loss, which encourages the model to suppress or neutralize the visual effect of the selected instruction tokens.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x4.png",
                "caption": "Figure 4:Qualitative Samples of GSTLoRA.Demonstrates smooth, continuous control over the strength of both local and global edits.",
                "position": 358
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09715/x5.png",
                "caption": "Figure 5:Controllable zero-shot multi-subject personalization with STLoRA.STLoRA enables smooth adjustment of each instruction’s strength to generate coherent, evolving image sequences, supporting story-like visual editing. (Best viewed from top-left to top-right, then bottom-right to bottom-left)",
                "position": 395
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x6.png",
                "caption": "Figure 6:Qualitative results of STLoRA on 2-instruction edit.The 2D grid shows smooth, continuous transitions, allowing precise and disentangled control over each instruction’s strength.",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x7.png",
                "caption": "Figure 7:Qualitative and quantitative comparison of GSTLoRA with CFG baselines.GSTLoRA shows smooth edit trajectories with gradual similarity changes, unlike Implicit and Explicit CFG, which exhibit abrupt transitions and greater identity drift.",
                "position": 651
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "6Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09715/x8.png",
                "caption": "Figure 8:Simplified Partial Prompt Suppression (SPPS).SPPS applies the same suppression objective as PPS but treats the entire edit prompt as a single instruction. During training, a second (bottom-row) forward pass is performed to obtain a neutralized image—either using an empty prompt (“”) or a neutral textual instruction (e.g., “keep the image the same”). This simple formulation effectively teaches the adapter to suppress undesired edit effects and generalizes well to multi-instruction editing scenarios.",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x9.png",
                "caption": "Figure 9:Qualitative results of GSTLoRA on text editing.",
                "position": 703
            }
        ]
    },
    {
        "header": "7SliderEdit: Continuous Image Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09715/x10.png",
                "caption": "Figure 10:Qualitative results of STLoRA on a 3-instruction edit.The model demonstrates smooth and continuous control over the strength of each instruction in a disentangled manner.",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x11.png",
                "caption": "Figure 11:Qualitative results of STLoRA on a 2-instruction edit for text editing.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x12.png",
                "caption": "Figure 12:Qualitative Comparison between PPS and SPPS.PPS produces a more disentangled and smoother interpolation space in multi-instruction editing scenarios, offering finer control over individual instruction directions compared to SPPS.",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x13.png",
                "caption": "Figure 13:Qualitative Comparison with Baselines.While SliderEdit (GSTLoRA variant here) and Explicit Guidance produce high-quality edits, Concept-Slider and Continuous Attribute Control perform poorly on real image editing, as they are primarily designed for text-to-image generation and rely on indirect inversion-based adaptation.",
                "position": 863
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x14.png",
                "caption": "Figure 14:Qualitative Samples of GSTLoRA.The model emonstrates smooth, continuous control over the strength of both local and global edits.",
                "position": 904
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x15.png",
                "caption": "Figure 15:Qualitative results of GSTLoRA on face editing",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x16.png",
                "caption": "Figure 16:Qualitative results of GSTLoRA on face editing",
                "position": 910
            },
            {
                "img": "https://arxiv.org/html/2511.09715/x17.png",
                "caption": "Figure 17:Qualitative results of STLoRA on 2-instruction edits.The model demonstrates smooth, continuous control over the strength of both directions.",
                "position": 913
            }
        ]
    },
    {
        "header": "8Experiments",
        "images": []
    }
]