[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/evaluation/inference_scaling.png",
                "caption": "(a)",
                "position": 112
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/evaluation/inference_scaling.png",
                "caption": "(a)",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/evaluation/canonical_resourece_allocation.png",
                "caption": "(b)",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x1.png",
                "caption": "(c)",
                "position": 125
            }
        ]
    },
    {
        "header": "2Background and Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/x2.png",
                "caption": "Figure 2:Illustration of the workflow of different LLM reasoning algorithms discussed in ¬ß2.1",
                "position": 177
            }
        ]
    },
    {
        "header": "3Certaindex Based Resource Allocation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/x3.png",
                "caption": "Figure 3:Correlations betweencertaindex strength(y-axis) and ground truthsteps to solution(x-axis) on 12 (algorithm, task dataset, LLM) settings where algorithm‚àà\\in‚àà{SC, Rebase, MCTS, ICoT}, dataset‚àà\\in‚àà{LiveCodeBench[19], GSM8K, ASDiv[34], GAME24[54]}, and LLM‚àà\\in‚àà{Llama[33], Gemma[46], Phi[2], QWQ[47]}. How certaindex is measured in each setting is shown in theyùë¶yitalic_ylabel of each plot.\nCertaindex is measured at the reasoning step marked by the black line. The orange line indicates the thresholding-based allocation. The green line illustrates a more fine-grained approach through curve fitting.\nFor all plots (except MCTS), both certaindex values and oracle steps were averaged across multiple runs to combat randomness.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x4.png",
                "caption": "Figure 4:Certaindex Values Across Different Detection Steps in Self-Consistency Reasoning",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x5.png",
                "caption": "Figure 5:Correlation between certainty measurements and mean steps required to solve problems on solvable problems. We obtain the ground-truth mean steps by solving the queries using the LLM multiple times and counting the average steps.",
                "position": 317
            }
        ]
    },
    {
        "header": "4Characterizing the Relationship Between Certaindex and Detection Steps",
        "images": []
    },
    {
        "header": "5Dynasor: System Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/arch-diagram3.png",
                "caption": "Figure 6:Left(a): Dynasor Architecture. Middle(b): Reasoning Program Interface. Right(c): Example Program (SC).",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/arch-diagram3.png",
                "caption": "",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/reasoning-program-interface.png",
                "caption": "",
                "position": 359
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/code_sc.png",
                "caption": "",
                "position": 368
            },
            {
                "img": "https://arxiv.org/html/2412.20993/extracted/6102352/figures/gang2.jpg",
                "caption": "Figure 7:Illustration of Gang Scheduling",
                "position": 437
            }
        ]
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/x6.png",
                "caption": "Figure 8:Token-to-accuracy metric on batch processing workloads. Mean performance and std (error bars) of 10 runs are reported.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x7.png",
                "caption": "Figure 9:Evaluation on 3 online workloads on Dynasor against baselines. Rows from top to bottom: (a) Program arrival rate vs SLO attainment, (b) SLO scale vs SLO attainment, (c) Accuracy vs SLO Attainment.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x8.png",
                "caption": "Figure 10:Performance improvement breakdown in online self-consistency (GSM8K) workload: Impact of gang scheduling, certaindex-based resource allocation, and SJF on mean latency given a fixed request rate of 16 pps.",
                "position": 758
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x9.png",
                "caption": "Figure 11:Performance improvement breakdown of online self-consistency (MATH) under fixed P90 SLO constraints.",
                "position": 761
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x10.png",
                "caption": "Figure 12:Performance comparison with different entropy threshold or reward score threshold.",
                "position": 767
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x11.png",
                "caption": "Figure 13:Performance comparison with LLM activation-based predictor and output length based scheduling.",
                "position": 777
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x12.png",
                "caption": "Figure 14:Finish-Time Fairness.",
                "position": 801
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x13.png",
                "caption": "Figure 15:Serving Qwen-QWQ using Dynasor.",
                "position": 804
            }
        ]
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AToken-to-accuracyPerformance of Dynasor on MATH using SC",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20993/x14.png",
                "caption": "Figure 16:Token-to-accuracy Performance Using SC on MATH",
                "position": 1574
            },
            {
                "img": "https://arxiv.org/html/2412.20993/x15.png",
                "caption": "Figure 17:Dynasor outperforms baselines in different memory settings",
                "position": 1577
            }
        ]
    },
    {
        "header": "Appendix BMemory‚Äôs Affects on Dynasor",
        "images": []
    }
]