[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.04404/x1.png",
                "caption": "Figure 1:We conceptualize LLMs as a layered cake, where different layers contribute distinct “flavors” to the reasoning process.\n(a) We show the attention of the first predicted answer token over input question tokens across layers. Early layers (the “topping”) focus on structural elements, attending strongly to punctuation and special symbols. Intermediate layers (the “glaze”) shift attention to conceptual tokens that carry semantic meaning and support factual reasoning. Functional tokens consistently receive low attention, indicating limited contribution to content understanding.\n(b) We suppress attention to specific token types at their most influential layers, creating a perturbed reasoning trajectory. By comparing original and perturbed outputs, we derive contrastive logits that guide decoding toward more factually aligned predictions.",
                "position": 78
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Token-Level Attention Behavior across LLM Layers",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.04404/x2.png",
                "caption": "Figure 2:We analyze the attention behavior of the first predicted token using a TruthfulQA question answer pair: <“What is the most popular sport in Japan?”, “Baseball”>.(a)Input tokens are categorized into three groups: punctuation(e.g., “<s>”, “?”), conceptual(e.g., “most”, “popular”, “sport”, “Japan”), and functional (e.g., “what”, “is”, “the”, “in”). Each category is visually highlighted with different colors.(b)The heatmap illustrates the attention distribution from the first predicted token (“Baseball”) to all input tokens across 32 layers, with darker shades indicating stronger attention. Punctuation tokens receive high attention in early layers (notably, “<s>”), while conceptual tokens dominate in the middle layers. Functional tokens consistently attract lower attention across all layers.(c)We conduct targeted attention suppression by masking punctuation/conceptual tokens in early/middle (highlighted in red), respectively. This intervention disrupts the model’s original reasoning process, leading to an incorrect prediction (“Sumo”) instead of the correct answer (“Baseball”), underscoring the importance of token-layer interactions in factual prediction.",
                "position": 146
            },
            {
                "img": "https://arxiv.org/html/2507.04404/x3.png",
                "caption": "Figure 3:(a) We plot the average proportion of attention received by punctuation, conceptual, and functional tokens from the first predicted answer token, aggregated across TruthfulQA. Punctuation (P) tokens dominate in early layers, conceptual (C) tokens receive increasing attention in the middle layers, and functional (F) tokens remain consistently low. (b) Effect of attention suppression across layers and token types. We report accuracy drops on HellaSwag when suppressing attention to punctuation (P), conceptual (C), or functional (F) tokens at different layer stages of LLaMA 2.",
                "position": 168
            }
        ]
    },
    {
        "header": "4Method: Token-Aware Contrastive Attention Decoding",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AImplementation Details",
        "images": []
    },
    {
        "header": "BQualitative Studies",
        "images": []
    },
    {
        "header": "CParameter Settings Analysis",
        "images": []
    }
]