[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x1.png",
                "caption": "Figure 1:Bringing LLM mechanisms of context engineering and reasoning to industrial ranking systems. (a) In LLMs, context engineering broadens the query with external knowledge from the input side, while explicit or latent reasoning guides the output process, together enhancing the model’s ability to generate accurate answers. (b) In OnePiece, user interaction history is augmented with additional reference signals, while block-wise reasoning progressively refines representations, jointly improving performance in both retrieval and ranking modes.",
                "position": 203
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3The Proposed OnePiece Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x2.png",
                "caption": "Figure 2:Overall architecture of the proposedOnePieceframework. Retrieval Mode (a) and Ranking Mode (b) both employ structured context engineering to construct unified input tokens, utilize block-wise latent reasoning to iteratively enhance representations across multiple reasoning steps, and are optimized through progressive multi-task training strategy.",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2509.18091/x3.png",
                "caption": "Figure 3:Context engineering and tokenizer design for input token sequences inOnePiece.\nBoth retrieval and ranking share the same construction of interaction history (IH), preference anchors (PA), and situational descriptors (SD).\nThe key difference is that ranking additionally incorporates candidate item set (CIS) tokens, enabling joint scoring within the single-tower architecture.",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2509.18091/x4.png",
                "caption": "Figure 4:Block-wise reasoning mask and progressive multi-task training.(a)Causal attention mask enables reasoning blocks to attend to input and previous blocks.(b)Progressive training assigns tasks of increasing complexity to successive reasoning steps to provide effective process supervision.",
                "position": 653
            }
        ]
    },
    {
        "header": "4Offline Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x5.png",
                "caption": "Figure 5:Training convergence curves of different models on retrieval and ranking tasks.",
                "position": 1409
            }
        ]
    },
    {
        "header": "5Online A/B Testing",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x6.png",
                "caption": "Figure 6:Exclusive contribution of OnePiece in the retrieval stage.",
                "position": 1701
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion and Future Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x7.png",
                "caption": "Figure 7:Comparison between existing multi-route retrieval systems and OnePiece-based unified architecture. (a) Traditional multi-route retrieval requires maintaining separate models with distinct parameters for different retrieval pathways (I2U, I2I, U2I, Q2I, etc.), each utilizing specialized architectures and storage systems. (b) OnePiece achieves unified multi-route retrieval through a single model that processes tailored prompts for different retrieval scenarios, enabling “One For All\" functionality while reducing system complexity and maintenance overhead.",
                "position": 1821
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AOffline Dataset Construction",
        "images": []
    },
    {
        "header": "Appendix BContext Engineering Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18091/x8.png",
                "caption": "(a)Case Studies on OnePiece Attention Analysis (Retrieval Mode).",
                "position": 2667
            },
            {
                "img": "https://arxiv.org/html/2509.18091/x8.png",
                "caption": "(a)Case Studies on OnePiece Attention Analysis (Retrieval Mode).",
                "position": 2670
            },
            {
                "img": "https://arxiv.org/html/2509.18091/x9.png",
                "caption": "(b)Case Studies on OnePiece Attention Analysis (Ranking Mode).",
                "position": 2676
            },
            {
                "img": "https://arxiv.org/html/2509.18091/x10.png",
                "caption": "Figure 9:Attention visualization of multi-step block-wise reasoning in OnePiece. The heatmaps show attention weights between reasoning blocks (y-axis, as queries) and input components with previous reasoning outputs (x-axis, as keys and values) for(a)retrieval mode with two reasoning steps (R1R_{1},R2R_{2}) and(b)ranking mode with three reasoning steps (R1R_{1},R2R_{2},R3R_{3}). Context Tokens include Interaction History (I), Preference Anchors (P), Situational Descriptors (S), and Candidate Items (C, ranking only).",
                "position": 2692
            }
        ]
    },
    {
        "header": "Appendix CAttention Visualization Analysis",
        "images": []
    }
]