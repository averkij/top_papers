[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04735/x1.png",
                "caption": "Figure 1:Unintended behaviors induced by fine-tuning on benign-looking data via subliminal learning.\nWe propose a new proactive task:Predicting Unintended Model Behaviors Before Trainingwith a simple yet effective method that anticipates such risks before tuning.",
                "position": 192
            }
        ]
    },
    {
        "header": "2Data-based Unintended Behavior Emergence Prediction",
        "images": []
    },
    {
        "header": "3Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04735/x2.png",
                "caption": "Figure 2:Prediction bias rate (%) on ‚ÄúPanda‚Äù and ‚ÄúNew York City‚Äù of Qwen2.5-32B-Instruct and Gemma3-12b-it.",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2602.04735/fig/gemma_logits.png",
                "caption": "(a)Log probability difference of ‚ÄúNYC‚Äù for Gemma3-12b-it.",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2602.04735/fig/gemma_logits.png",
                "caption": "(a)Log probability difference of ‚ÄúNYC‚Äù for Gemma3-12b-it.",
                "position": 753
            },
            {
                "img": "https://arxiv.org/html/2602.04735/fig/qwen_logits.png",
                "caption": "(b)Log probability difference of ‚ÄúNYC‚Äù for Qwen3-14B.",
                "position": 759
            }
        ]
    },
    {
        "header": "4Mechanistic Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04735/fig/triangle.png",
                "caption": "Figure 4:The interplay betweenData (ùíü\\mathcal{D}),Model (‚Ñ≥\\mathcal{M}), andBehavior (‚Ñ¨\\mathcal{B})serves as a fundamental lens for understanding recent advancements in LLMs.",
                "position": 838
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics and Risk Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04735/x3.png",
                "caption": "Figure 5:The instances of the dataset used in this paper.\nOur predicted trend is consistent with the trend observed after fine-tuning on this dataset.",
                "position": 1863
            }
        ]
    },
    {
        "header": "Appendix AThe Use of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix BDataset",
        "images": []
    },
    {
        "header": "Appendix CExperiment Details",
        "images": []
    }
]