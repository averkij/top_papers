[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09554/x1.png",
                "caption": "Figure 1:Accuracy-Latency Pareto Curve.We plot the Pareto accuracy-latency frontier for real-time detectors on the COCO detection val-set (top left, bottom left), COCO segmentation val-set (top right), and RF100-VL test-set (bottom right). Since RF100-VL contains 100 distinct datasets, we select target latencies for the N, S, M, L, XL, 2XL configurations, search for RF-DETR models with latencies within 10% of the target and report their average performance after fine-tuning to convergence. Importantly, all points along RF-DETR’s continuous Pareto curves for COCO are derived from a single training run.",
                "position": 67
            },
            {
                "img": "https://arxiv.org/html/2511.09554/x2.png",
                "caption": "",
                "position": 70
            },
            {
                "img": "https://arxiv.org/html/2511.09554/x3.png",
                "caption": "",
                "position": 72
            },
            {
                "img": "https://arxiv.org/html/2511.09554/x4.png",
                "caption": "",
                "position": 73
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3RF-DETR: Weight-Sharing NAS With Foundation Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09554/x5.png",
                "caption": "Figure 2:RF-DETR Architecture. RF-DETR uses a pre-trained ViT backbone to extract multi-scale features of the input image. We interleave windowed and non-windowed attention blocks to balance accuracy and latency. Notably, the deformable cross-attention layer and segmentation head both bilinearly interpolate the the output of the projector, allowing for consistent spatial organization of features. Lastly, we apply detection and segmentation losses at all decoder layers to facilitate decoder drop out at inference.",
                "position": 94
            },
            {
                "img": "https://arxiv.org/html/2511.09554/x6.png",
                "caption": "Figure 3:NAS Search Space. We vary (a) patch size, (b) number of decoder layers, (c) number of queries, (d) image resolution, and (e) number of windows per attention block in our weight-sharing NAS. In addition to training thousands of network configurations in parallel, we find that this “architecture augmentation” serves as a regularizer and improves generalization.",
                "position": 107
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BAblation on Query Tokens and Decoder Layers",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09554/figures/decoder_layers_queries_full.png",
                "caption": "Figure 4:Impact of Decoder Layers vs. Query Tokens. We evaluate the impact of inference-time query dropping for trading-off accuracy and latency in RF-DETR (nano). Interestingly, we find that dropping the 100 lowest confidence queries does not significantly reduce performance, but modestly improves latency for all decoder layers.",
                "position": 1496
            }
        ]
    },
    {
        "header": "Appendix CBenchmarking FLOPs",
        "images": []
    },
    {
        "header": "Appendix DImpact of Class-Names on Open-Vocabulary Detectors",
        "images": []
    },
    {
        "header": "Appendix EBenchmarking Larger Model Variants",
        "images": []
    },
    {
        "header": "Appendix FImpact on NAS Fine-Tuning on COCO",
        "images": []
    },
    {
        "header": "Appendix GImpact of Fixed Architecture on RF100-VL",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09554/figures/latency_accuracy_RF100-VL_Object_Detection_mAPat50_NAS_search_ablation.png",
                "caption": "Figure 5:Ablating Fixed Architecture RF100-VL. We evaluate the benefit of dataset-specific NAS by transferring the COCO-optimized RF-DETRarchitecture to RF100-VL. Although the fixed architecture was not tuned for RF100-VL, it still outperforms LW-DETR. Running NAS directly on RF100-VL further improves performance over the fixed architecture. Additional fine-tuning provides consistent gains across all model sizes, with particularly strong improvements for smaller models. This is consistent with our observations on COCO object detection.",
                "position": 2631
            }
        ]
    },
    {
        "header": "Appendix HDiscussion on Notable Discovered Architectures",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09554/x7.png",
                "caption": "Figure 6:Visualizing Model Predictions. On the left, we compare detections from RF-DETR (nano) and LW-DETR (tiny). On the right, we compare instance segmentation masks from RF-DETR-Seg (nano) and YOLOv11 (nano)",
                "position": 2925
            }
        ]
    },
    {
        "header": "Appendix IVisualizing Model Predictions",
        "images": []
    }
]