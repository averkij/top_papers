[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17641/figures/fig1.png",
                "caption": "Fig. 1:Overview ofAuditoryBench++,\nwhich assesses auditory knowledge of language models without audio input.",
                "position": 57
            }
        ]
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17641/x1.png",
                "caption": "Fig. 2:Pipeline of the proposedAIR-CoT.\n(a) Data Preparation. Training data is augmented with[imagine]tokens to mark spans requiring auditory reasoning.\n(b) Stage 1: Span Detection. The model is fine-tuned to detect the spans by generating the special tokens during decoding.\n(c) Stage 2: Knowledge Injection. When encountering the[/imagine]token, the model pauses to generate the embedding using CLAP and injects it for auditory reasoning.",
                "position": 79
            }
        ]
    },
    {
        "header": "3AuditoryBench++",
        "images": []
    },
    {
        "header": "4AIR-CoT",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]