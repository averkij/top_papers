[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18106/x1.png",
                "caption": "Figure 1:Comparison of code security assessment approaches.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18106/x2.png",
                "caption": "Figure 2:Overall workflow of A.S.E. (a) A.S.E benchmark construction: from high-quality GitHub seeds, we build the A.S.E dataset via dual mutations (structure/semantic), CVE patches, and a customized SAST tool, followed by expert curation. (b) Model code generation: given an incomplete repository, a vulnerability description and context guide LLMs to complete the repository. (c) Security evaluation: comprehensive assessment with security, quality and stability.",
                "position": 203
            }
        ]
    },
    {
        "header": "3The A.S.E Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18106/x3.png",
                "caption": "Figure 3:Overview of A.S.E benchmark construction.Algorithm-guided screening and preselection (left):aggregate CVE-linked sources and automatically filter repositories by web-related CWEs, vulnerability types (XSS, SQL injection, path traversal, command injection), and languages (Java, Python, Go, PHP, JavaScript).Expert-guided curation and refinement (right):conduct manual review, reproducibility and exploitability checks, and dual-toolchain SAST (e.g., CodeQL + Joern) with CVE-specific rules; then expand4040seed repositories via structural/semantic mutation to8080variants.",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2508.18106/x4.png",
                "caption": "Figure 4:Statistics of A.S.E benchmark.",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2508.18106/attachment/pic/logo_fast.png",
                "caption": "Table 1:The leaderboard of various advanced Code LLMs on the A.S.E. benchmark.is the fast-thinking mode andindicates slow-thinking mode.",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2508.18106/attachment/pic/logo_slow.png",
                "caption": "",
                "position": 473
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18106/x5.png",
                "caption": "Figure 5:Fast v.s. Slow Thinking.",
                "position": 802
            },
            {
                "img": "https://arxiv.org/html/2508.18106/x6.png",
                "caption": "Figure 6:Attributional distribution across Code LLMs.",
                "position": 805
            },
            {
                "img": "https://arxiv.org/html/2508.18106/x7.png",
                "caption": "Figure 7:Detailed Attribution classification of Claude-3.7-Sonnet: Original (top) and Mutation Test (bottom).",
                "position": 822
            },
            {
                "img": "https://arxiv.org/html/2508.18106/x8.png",
                "caption": "Figure 8:Detailed performance of various Code LLMs across four tasks of A.S.E benchmark.",
                "position": 825
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]