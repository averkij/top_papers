[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20626/x1.png",
                "caption": "Figure 1:Analysis of gradient distribution revealing outlier characteristics.(Left)Histogram with Gaussian reference shows long-tailed distribution.(Right)Q-Q plot quantifies deviation from normality, where points deviating from the diagonal indicate outliers.\nThese outliers can disproportionately influence the optimization process.",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2511.20626/x2.png",
                "caption": "Figure 2:Orthogonalization precision relative to ground-truth SVD.The plot tracks the Relative Error averaged over all optimized parameters (Attention QKV/O and MLP Up/Down projections). Under a fixed 5 iterations, ROOT maintains lower approximation error compared to the Muon baseline and Classic Newton-Schulz. This indicates that shape-specific coefficients provide superior fidelity across varying matrix dimensions.",
                "position": 676
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20626/x3.png",
                "caption": "Figure 3:Training loss curves for 10B tokens. ROOT variants demonstrate faster convergence and lower final loss compared to Muon baseline, with full ROOT achieving the best performance.",
                "position": 748
            },
            {
                "img": "https://arxiv.org/html/2511.20626/x4.png",
                "caption": "Figure 4:Ablation on the quantile hyperparameterpp. The curve withp=0.90p=0.90demonstrates the optimal equilibrium between suppressing gradient noise and preserving informative gradient signals.",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2511.20626/x5.png",
                "caption": "Figure 5:Ablation on the data composition for coefficient calibration. While a high ratio of real samples (Ratio 1:1) achieves lower loss here, it induces instability (loss spikes) in larger-scale experiments or when combined with ROOT (SoftThresh). The Mixed (1:3) strategy provides the optimal balance between convergence speed and robustness.",
                "position": 840
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]