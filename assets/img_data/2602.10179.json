[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x1.png",
                "caption": "Figure 1:Comparison between our Vision-Centric Jailbreak Attack (VJA) and conventional Text-Centric Jailbreak Attacks.Top: Attack scheme comparison;\nBottom: Performance comparison on a subset ofğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench},\nVJA achieves significantly higher attack success rates across four commercial models.",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x1.png",
                "caption": "",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x2.png",
                "caption": "",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2602.10179/figs/figure_overview.png",
                "caption": "Figure 2:Overview and statistics of our constructedğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}.Note that the proposed VJA is vision-only jailbreak attack, so no additional text prompts are needed.",
                "position": 155
            }
        ]
    },
    {
        "header": "2VJA: Jailbreak Attack in Vision",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x3.png",
                "caption": "Figure 3:Introspection-based Defense,which leverages a safety trigger to enhance the security of large image editing models.",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2602.10179/figs/benchmark.png",
                "caption": "Figure 4:The illustration ofğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}construction.The top figure shows the 15 risk category covered in ourğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}in a hierarchical manner, and the bottom figure shows the pipeline for dataset curation and evaluation.",
                "position": 253
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x7.png",
                "caption": "Table 1:VJA performance on our constructedğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}.The mostriskyandsafestcategory for each model are marked byredandblueseparately. No safeguard models are deployed for open-source models: BAGEL, Qwen-Local, leading to an ASR of100%. We rank the safety of models by ASR usingrespectively, indicating models ranked first, second, and third on ourğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}. Detailed distribution and examples are shown in AppendixA.2andA.3.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x8.png",
                "caption": "",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x9.png",
                "caption": "",
                "position": 289
            },
            {
                "img": "https://arxiv.org/html/2602.10179/",
                "caption": "",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x11.png",
                "caption": "",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x12.png",
                "caption": "",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x13.png",
                "caption": "Figure 5:Average harmfulness score comparison between different models onğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}.(a) shows the distribution of samples in different levels of ourğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}. (b)-(i) illustrate the average HS of models for attacks in different risk levels.",
                "position": 1035
            }
        ]
    },
    {
        "header": "3ğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}: Benchmarking the Safety of Large Image Editing Models",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x14.png",
                "caption": "Figure 6:Attack results comparison between VJA and TJA.Some weak models may fail to understand or misunderstand VJA, leading to trivial editing. Best viewed when zoom in.",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x15.png",
                "caption": "Figure 7:The malicious input classification result of our defense method.We repeat each test for 5 times.",
                "position": 1212
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "7Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x16.png",
                "caption": "Figure 8:Showcases of the images and output of 15 risk categories in our constructedğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}.Left shows the visually-prompted image, and right shows the edited image by large image editing models.",
                "position": 2217
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x17.png",
                "caption": "Figure 9:Qualitative attack results.Comparison of the outputs produced by commercial models and open-source models under the same attack setting (I1-I10) onğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}. Best viewed when zoom in.",
                "position": 2220
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x18.png",
                "caption": "Figure 10:Qualitative attack results.Note that, we mask potentially sensitive regions in the qualitative results. For categories I1, I3, and I6, we applymosaic(pixelation). For categories I9 and I12, we useblack-box masking. Except for these redactions, all images shown are the created by the respective models. Best viewed when zoom in.",
                "position": 2224
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x19.png",
                "caption": "Figure 11:Showcase ofğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}failure cases. We present samples of (i) visual reasoning failure, (ii) text editing failure, and (iii) attack failure.",
                "position": 2229
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x20.png",
                "caption": "Figure 12:Some interesting cases of failed attacks onğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}.(i) Stick figures are riding a horse.\n(ii) Stick figures are hunting a cow.\n(iii) A little hedgehog is riding on wheels.\n(iv) A strange lemon with a face.",
                "position": 2232
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x21.png",
                "caption": "Figure 13:Illustration of the sensitivity test for visual prompts.The input images are only altered with the colors, languages, text fonts, sizes and shapes.",
                "position": 2240
            }
        ]
    },
    {
        "header": "Appendix AAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x22.png",
                "caption": "Figure 14:Sensitivity Experiment Results. The percentage numbers infer the maximum influence to the evaluation metric of the average of all 4 models and the extreme values of single models compared with the default settings.",
                "position": 2296
            },
            {
                "img": "https://arxiv.org/html/2602.10179/figs/sensitivity_robust.png",
                "caption": "Figure 15:The Robustness of VJA for different models.Red line indicating the performance of default setting. The box and dots indicate the distribution of the HS and EV with those variables altering.",
                "position": 2305
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x23.png",
                "caption": "Figure 16:Harmfulness score distributions of large image editing models onğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}evaluated by Qwen3-VL-8B-Instruct.The first row shows the commercial models, and the second row shows the open models.",
                "position": 2308
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x24.png",
                "caption": "Figure 17:Harmfulness score distributions of 8 victim large image editing models onğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}evaluated by Gemini 3 Pro.The first row shows the commercial models, and the second row shows the open models.",
                "position": 2311
            },
            {
                "img": "https://arxiv.org/html/2602.10179/x25.png",
                "caption": "Figure 18:Comparison ofğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}vs Prior Benchmarks.We compare our benchmark with MMSafetyBench, FigStep and HADES of MultiModal.",
                "position": 2386
            }
        ]
    },
    {
        "header": "Appendix BMore Details aboutğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10179/x26.png",
                "caption": "Figure 19:Overview ofğ™¸ğ™´ğš‚ğ™±ğšğš—ğšŒğš‘\\mathtt{IESBench}data format.It includessource_image,image, andtext.jsonwith per-sample JSON records.",
                "position": 2546
            }
        ]
    },
    {
        "header": "Appendix CExperimental Setup",
        "images": []
    }
]