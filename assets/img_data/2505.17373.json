[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x1.png",
                "caption": "Figure 1:Performance and Efficiency of Value Guidance:(Left) Value-guided search improves the overall quality ofDeepSeek-R1-Distillresponses across four combined competition math benchmarks (AIME & HMMT). The inference budget for 1.5B, 7B and 14B are256256256256,128128128128and64646464generations, respectively.\n(Right) Value-guided search also reduces the inference FLOPs required to achieve the same accuracy levels as majority voting, a standard TTC scaling baseline, showing value-guidance is promising for improving efficiency.",
                "position": 120
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x2.png",
                "caption": "Figure 2:Summary of Methods.(Left) Diagrams how we collect multiple roll-ins (grey circles representing tokens) per problem, and branch off multiple roll-outs per roll-in at random points. The class label for each roll-out token is the outcome label at the very end.\n(Right) Shows the beam search process (beam width2222and budget4444) guided by a value model.",
                "position": 192
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x3.png",
                "caption": "Figure 3:Test-Time Compute with DeepSeek-VM-1.5B.(Left) Compares best-of-NùëÅNitalic_N(BoN), weighted majority voting (WMV) andVGSwith either BoN or WMV for the final aggregation.\n(Right) ComparesVGSto majority voting (MV), a standard baseline that does not require a scorer.",
                "position": 661
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x4.png",
                "caption": "Figure 4:TTC Scaling of Various Scorers.Comparison of our 1.5B value model (VM), our 1.5B Bradley-Terry reward model (BT), and two 7B state-of-the-art PRMs for two TTC scaling methods: (Left) WMV or (Right)VGS(with WMV as a final aggregation step).",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x5.png",
                "caption": "Figure 5:VGS + WMV Performance when Guiding Larger Models.With the sameDeepSeek-VM-1.5Bproviding guidance, search continues to improve with more test-time compute.",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x6.png",
                "caption": "Figure 6:Ablation: Search Block Size.AIME-24 accuracies for beam search (width2222) with varying block sizes from 16 to 16384. We found 4096 to be optimal across test-time budgets and benchmarks.",
                "position": 691
            }
        ]
    },
    {
        "header": "4Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x7.png",
                "caption": "Figure 7:Ablations: Beam-Width and DVTS.(Left) AIME-24 accuracies for beam search with various widths (Section2.3) across inference budgetsNùëÅNitalic_N. BFS is equivalent to setting width asNùëÅNitalic_N. We find that the optimal beam width is robust across multiple TTC budgets.\n(Right) Averaged accuracy for beam2222with and without DVTS. For DVTS, we report the best result with parallelismM>1ùëÄ1M>1italic_M > 1per inference budgetNùëÅNitalic_N, which we find scales better at higher budgets.",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x8.png",
                "caption": "Figure 8:Ablation: Random Search.Random search is the same search process asVGSexcept intermediate blocks are randomly selected instead of using our value model. Hybrid is a mixture where we flip a fair coin at the start of a search tree that decides whether to use random search orVGS. We see that selecting blocks with highest value improves accuracy across inference budgets.",
                "position": 718
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Table of Contents",
        "images": []
    },
    {
        "header": "Appendix ARelated Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x9.png",
                "caption": "Figure 9:Taxonomy of TTC Methods.Score-free TTC methods do not require an external scoring model,e.g., by taking a majority vote.\nScore-based TTC methods require an external scoring model.\nThe coarsest scoring model is an outcome reward model (ORM), which scores a whole response and can be used for best-of-NùëÅNitalic_Nor weighted MV.\nA more fine-grained scoring model are process-level scorers, which includes process reward models (PRMs) and value models; these more fine-grained scoring models can be used for search.",
                "position": 1601
            }
        ]
    },
    {
        "header": "Appendix BSummary of VGS Pipeline",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/x10.png",
                "caption": "Figure 10:Per-benchmark results forFig.3.(Left) Compares best-of-NùëÅNitalic_N(BoN), weighted majority voting (WMV) andVGSwith either BoN or WMV for the final aggregation.\n(Right) ComparesVGSto majority voting (MV), a standard baseline that does not require a scorer.",
                "position": 2047
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x11.png",
                "caption": "Figure 11:Per-benchmark results forFig.4.Comparison of our 1.5B value model (VM), our 1.5B Bradley-Terry reward model (BT), and two 7B state-of-the-art PRMs for two TTC scaling methods: (Left) WMV or (Right)VGS(with WMV as a final aggregation step).",
                "position": 2056
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x12.png",
                "caption": "Figure 12:Per-benchmark results forFig.5.With the sameDeepSeek-VM-1.5Bproviding guidance, search continues to improve with more test-time compute.",
                "position": 2065
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x13.png",
                "caption": "Figure 13:Per-benchmark results forFig.8.Random search is the same search process asVGSexcept intermediate blocks are randomly selected instead of using our value model.",
                "position": 2073
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x14.png",
                "caption": "Figure 14:Guiding DeepSeek-1.5B Trained with PPO.Comparison ofVGS, WMV and MV for TTC scaling our PPO policy.",
                "position": 2284
            },
            {
                "img": "https://arxiv.org/html/2505.17373/x15.png",
                "caption": "Figure 15:Histogram of generation lengths for theDeepSeek-1.5Bbase model vs.VGS.VGSconsistently produces shorter responses across benchmarks, with average lengths of 11,219 and 12,793 tokens forVGSand the base model, respectively. The peak around 16,000 tokens reflects the generation cap of DeepSeek models, which the base model frequently hits, often resulting in incomplete outputs.",
                "position": 2304
            }
        ]
    },
    {
        "header": "Appendix DFurther Details of Data Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17373/extracted/6469304/figs/dataset_rollout_dist.png",
                "caption": "Figure 16:Distribution of roll-out length.",
                "position": 2368
            }
        ]
    },
    {
        "header": "Appendix EFurther Details for Value Model Training",
        "images": []
    },
    {
        "header": "Appendix FFurther Details for Inference with Search",
        "images": []
    },
    {
        "header": "Appendix GFurther Details for Training Bradley-Terry Reward Model",
        "images": []
    },
    {
        "header": "Appendix HInference FLOPS Computation",
        "images": []
    }
]