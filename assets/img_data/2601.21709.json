[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21709/x1.png",
                "caption": "Figure 1:Overview of Temporal Attention Pattern Predictability Analysis (TAPPA) Framework. Left: Theoretical discoveries. Query self-similarity (q-similarity) affects the predictable and unpredictable patterns. Within the periodic sequential pattern, the slash interval is affected by the joint effect of queries, keys and RoPE. Right: Q-similarity is applied to downstream tasks and achieves consistant improvements.",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x2.png",
                "caption": "Figure 2:TAPPA explains the formation of sparse attention patterns from a temporal continuity perspective. We first establish the fundamental Predictable and Unpredictable patterns in Sec.4. We then detail the conditions that form the Re-access (Sec.5.1), Sequential (Sec.5.2), Seasonal (Sec.5.4), and Periodical Sequential (Sec.5.3) patterns in their dedicated sections.",
                "position": 210
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Why Predictable and Unpredictable Attention Patterns Exist",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21709/x3.png",
                "caption": "Figure 3:Attention patterns at high and low Query similarity on the Llama and Qwen models. Stable patterns emerge under high similarity, whereas low similarity results in random patterns. There are random bright dots of critical keys in the second and fourth figures.",
                "position": 390
            }
        ]
    },
    {
        "header": "5Predictable Attention Patterns",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21709/x4.png",
                "caption": "Figure 4:High self-similarity in Query (Q) and Key (K) matrices results in sequential attention patterns. An example from a Qwen-2.5 head (left) with high Q and K self-similarity (0.99 and 0.96) produces a strong diagonal pattern in the attention map (far right). This phenomenon is also observed in Llama-3.1 (center right).",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x5.png",
                "caption": "",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x6.png",
                "caption": "",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x7.png",
                "caption": "(a)",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x7.png",
                "caption": "(a)",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x8.png",
                "caption": "(b)",
                "position": 561
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x9.png",
                "caption": "(c)",
                "position": 567
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x10.png",
                "caption": "(d)",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x11.png",
                "caption": "(e)",
                "position": 579
            }
        ]
    },
    {
        "header": "6Downstream Tasks",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "ETHICS STATEMENT",
        "images": []
    },
    {
        "header": "REPRODUCIBILITY STATEMENT",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof of Unpredictable Pattern",
        "images": []
    },
    {
        "header": "Appendix BProof of Re-access Pattern",
        "images": []
    },
    {
        "header": "Appendix CProof of Sequential Pattern",
        "images": []
    },
    {
        "header": "Appendix DProof of Periodic Sequential Pattern",
        "images": []
    },
    {
        "header": "Appendix EProof of Seasonal Pattern",
        "images": []
    },
    {
        "header": "Appendix FEmpirical support",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21709/x12.png",
                "caption": "(a)",
                "position": 2931
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x12.png",
                "caption": "(a)",
                "position": 2934
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x13.png",
                "caption": "(b)",
                "position": 2939
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x14.png",
                "caption": "Figure 7:Ablation of query dynamics and RoPE on a head with a strong sequential pattern.Left: original head with high q-similarity and RoPE enabled.Middle: high q-similarity without RoPE, which retains a rough, broken diagonal with additional vertical streaks.Right: RoPE with perturbed q, where the diagonal tendency is overlaid with scattered, unpredictable activation spikes.",
                "position": 2964
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x15.png",
                "caption": "",
                "position": 2967
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x16.png",
                "caption": "",
                "position": 2968
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x17.png",
                "caption": "Figure 8:Head-wise q-similarity heatmaps for Llama-3.1 and Qwen2.5 on GSM8K and AIGC.\nFor readability, we show only the two decimal digits of each q-similarity value\n(e.g., “83” denotes a q-similarity of 0.83).",
                "position": 3007
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x17.png",
                "caption": "",
                "position": 3010
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x18.png",
                "caption": "",
                "position": 3014
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x19.png",
                "caption": "",
                "position": 3019
            },
            {
                "img": "https://arxiv.org/html/2601.21709/x20.png",
                "caption": "",
                "position": 3023
            }
        ]
    },
    {
        "header": "Appendix GExperiment Details",
        "images": []
    },
    {
        "header": "Appendix HAdditional Ablations and Hyperparameter Sensitivity",
        "images": []
    },
    {
        "header": "Appendix IComparison with DuoAttention",
        "images": []
    },
    {
        "header": "Appendix JComparison with Expected Attention",
        "images": []
    },
    {
        "header": "Appendix KThe Use of Large Language Models (LLMs)",
        "images": []
    }
]