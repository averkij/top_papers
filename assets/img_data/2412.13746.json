[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x1.png",
                "caption": "",
                "position": 79
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x2.png",
                "caption": "",
                "position": 80
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x3.png",
                "caption": "",
                "position": 123
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x4.png",
                "caption": "Figure 1:An illustration of (a) traditional and (b) preference-aligned RAG training paradigms.",
                "position": 134
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x5.png",
                "caption": "Figure 2:The construction process of RAG-RewardBench.",
                "position": 225
            }
        ]
    },
    {
        "header": "3The RAG-RewardBench Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x6.png",
                "caption": "Figure 3:The source model distribution.",
                "position": 269
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x7.png",
                "caption": "Figure 4:The Pearson correlation coefficient between different judgment models.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x8.png",
                "caption": "Table 2:Evaluation results of 45 reward models on RAG-RewardBench, ranked by the average scores across all subsets. Icons refer to model types: Discriminative RM (), Generative RM (), and Implicit RM (). The best results are highlighted inbold, the second-best results are inunderlined, and the third-best results are inwaveline. General in the Helpful and Harmless columns refer to the helpfulness and harmlessness subsets, respectively.",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x9.png",
                "caption": "",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x10.png",
                "caption": "",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x11.png",
                "caption": "Table 3:Evaluation results of RALMs on RAG-RewardBench, employing the same usage as implicit RMs.",
                "position": 895
            }
        ]
    },
    {
        "header": "4Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x12.png",
                "caption": "(a)Skywork-Reward-Llama-3.1-8B-v0.2.",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x12.png",
                "caption": "(a)Skywork-Reward-Llama-3.1-8B-v0.2.",
                "position": 1119
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x13.png",
                "caption": "(b)Skywork-Reward-Gemma-2-27B-v0.2.",
                "position": 1125
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x14.png",
                "caption": "(a)Llama-3.1-70B-Instruct on HotpotQA with N = 32.",
                "position": 1132
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x14.png",
                "caption": "(a)Llama-3.1-70B-Instruct on HotpotQA with N = 32.",
                "position": 1135
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x15.png",
                "caption": "(b)Llama-3.1-70B-Instruct on MuSiQue with N = 32.",
                "position": 1141
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmark Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x16.png",
                "caption": "Figure 7:The subset distribution of RAG-RewardBench.",
                "position": 2484
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x17.png",
                "caption": "Figure 8:The winning rate of retrieval augmented language models in RAG-RewardBench.",
                "position": 2487
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x18.png",
                "caption": "Figure 9:The length distribution of the prompts with retrieval results.",
                "position": 2490
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x19.png",
                "caption": "Figure 10:The length difference distribution between the chosen and rejected responses.",
                "position": 2493
            }
        ]
    },
    {
        "header": "Appendix BPrompt Examples",
        "images": []
    },
    {
        "header": "Appendix CAdditional Evaluation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13746/x20.png",
                "caption": "(a)Llama-3.1-8B-Instruct.",
                "position": 2897
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x20.png",
                "caption": "(a)Llama-3.1-8B-Instruct.",
                "position": 2900
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x21.png",
                "caption": "(b)Qwen-2.5-14B-Instruct.",
                "position": 2906
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x22.png",
                "caption": "(a)Llama-3.2-3B-Instruct on HotpotQA with N = 32.",
                "position": 2913
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x22.png",
                "caption": "(a)Llama-3.2-3B-Instruct on HotpotQA with N = 32.",
                "position": 2916
            },
            {
                "img": "https://arxiv.org/html/2412.13746/x23.png",
                "caption": "(b)Llama-3.2-3B-Instruct on MuSiQue with N = 32.",
                "position": 2922
            }
        ]
    },
    {
        "header": "Appendix DData Examples",
        "images": []
    }
]