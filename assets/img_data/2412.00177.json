[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00177/x1.png",
                "caption": "Figure 1:\\method‚Äôs Architecture and Training Pipeline.Left:Inference pipeline of\\method, which takes two inputs: a source image and a target lighting condition image. The model (fŒ∏subscriptùëìùúÉ{f_{\\theta}}italic_f start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPT) transfers lighting characteristics while preserving the source scene‚Äôs structure and materials (a).Right:Our training requires latent intrinsic representations from source and target images from a pretrained model[69]. The latent intrinsic model decomposes an image into lighting-invariant intrinsic feature maps and a low-dimensional extrinsic lighting vector. We then train a conditional latent diffusion model along with a lightweight MLP adaptor networkMùëÄMitalic_Mthat transforms low-dimensional latent lighting extrinsics to match latent diffusion‚Äôs text embedding dimensions. We use empty prompts for our text conditioning. The training uses paired scenes (same geometry, material, and layout) under different lighting conditions with a latent diffusion loss (‚àó*‚àó: VAE encoder and decoder are omitted in the diagram.) to ensure accurate lighting transfer. As we demonstrate in our results,\\methodshows strong generalization ability in lighting transfer between scenes with completely different layouts and material properties even though they are trained with image-relight pairs from the same scene.",
                "position": 188
            }
        ]
    },
    {
        "header": "3Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00177/x2.png",
                "caption": "Figure 2:Training Framework of Variational StyLitGAN.(a) Traditional StyleGAN suffers from mode collapse when sampling latentzùëßzitalic_zfrom a Gaussian distribution, producing similar outputs every 10-20 iterations despite different latent codes. (b) Our variational approach learns to map real images to StyleGAN‚Äôs latent space through an encoder (qesubscriptùëûùëíq_{e}italic_q start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT), while using a frozen pretrained generator (pgsubscriptùëùùëîp_{g}italic_p start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT) from StyLitGAN[7]. The colored bars represent StyLitGAN‚Äôs disentangled lighting codes, which we leverage to generate a diverse pool of scenes under different lighting conditions. While the learned mapping is approximate, it provides sufficient diversity for training LUMINET by exploiting the natural variation in real images. (c) We apply CLIP similarity filtering to ensure high-quality generated samples.",
                "position": 213
            }
        ]
    },
    {
        "header": "4Data Preparation",
        "images": []
    },
    {
        "header": "5\\method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00177/x3.png",
                "caption": "Figure 3:Our\\methodarchitecture transfers complex lighting conditions between indoor scenes using latent intrinsic representations while preserving scene layout, geometry, and albedo. Each scene shows anoriginal image(left) paired with itsrelightedversion (right) matching the target lighting shown at the top. Our method preserves scene structure and materials while accurately transferring lighting characteristics.Left paneldemonstrates our method can adjust luminaires to match lighting conditions: it ‚Äúknows‚Äù that to get more light in the right place in the room, it must switch on bedside lights (first row and second row) or table lamps (third row and fourth row), showing our model‚Äôs ability to handle direct illumination. Zoomed-in crops highlight the changes in images caused by relighting. In the first row, observe the added gloss on the wall behind the lamp in the top crop, as well as the effects on the side of the bed in the bottom crop, influenced by the invisible luminaire. In the second row, note the gloss removal on the side wall, as shown in the bottom crop. In the third row, you can see the reflection of the lamp on the large stationary glass window on the left, highlighted in the top crop. Finally, in the bottom row, observe the strong gloss added to the chair and the faint inter-reflection on the TV screen.Right panelshows natural lighting scenarios where bedside lamps are off. Top row‚Äôs crop shows suppressed specular reflections on the glass table and realistic lamp pole shadows added after relighting. Second row shows strong specular highlights on the wall clock and strong cast shadows from the AC unit. Third row captures soft ambient lighting with intricate specular details on window frames and appropriate surface sheen on furniture. Fourth row demonstrates the removal of bright light from the lamps and all indirect effects, including the recovery of sharp edges at the intersection of the ceiling and side walls.",
                "position": 301
            }
        ]
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_24_mip2.jpg",
                "caption": "Figure 4:Image relighting comparison on MIIW[41]dataset.Our method outperforms the current state-of-the-art, Latent Intrinsic[69], achieving superior relighting from distinct directions. Latent Intrinsic fails to capture fine geometric details and color. RGB-X[62]is unable to generate relighting results using image prompting. We were unable to evaluate the text-prompt version, as it does not allow precise specification of lighting direction. Importantly, for our evaluation on the MIIW dataset, we did not use nearest-neighbor search or flow-based enhancement. We used a random seed and present results directly from\\methodwithout any post-processing.",
                "position": 489
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_20_mip2.jpg",
                "caption": "",
                "position": 498
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_20_mip2_dir_24_mip2.jpg",
                "caption": "",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/rgbx_24_20.png",
                "caption": "",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/4770078113107713227_dir_20_mip2.jpgdir_24_mip2.jpg",
                "caption": "",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_24_mip2_gt.jpg",
                "caption": "",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_24_mip2_dir_20_mip2.jpg",
                "caption": "",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/rgbx_20_to_24.png",
                "caption": "",
                "position": 543
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/6734925178423903351_dir_24_mip2.jpgdir_20_mip2.jpg",
                "caption": "",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2412.00177/extracted/6042795/figures/img_src/mit_relight/dir_20_mip2_gt.jpg",
                "caption": "",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x4.png",
                "caption": "Figure 5:In-the-wild image relighting visual comparison.We evaluate\\methodon diverse indoor scenes under various target lighting conditions, more in the supplemental. Both RGB-X[62]and IC-Light-v2[65]require text prompts to achieve relighting, where we use descriptions derived from the target lighting image (including actions like turning lights on/off, lamp placement, and scene type) as text prompts. In contrast, Latent Intrinsic[69]and our method rely solely on image input. When we pass the estimated irradiance from the target light image to RGB-X‚Äôs intrinsic channels (RGB-X image prompt), it fails to produce a meaningful image.",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x5.png",
                "caption": "Figure 6:Ablation Study.Left: target light. Second column: source image. Vanilla ControlNet (i.e., without latent intrinsic; third column) fails to perform relighting, changing the average color of the target light while losing all the details from the source image. Without our variational StyleGAN data for training (fourth column),\\methoddoes not recognize light sources, such as switching lamps on and off. Without the adaptor network and cross-attention fine-tuning via the light embedding (fifth column),\\methodcannot generate second-order lighting effects, such as the gloss on the table (top row). Without flow inversion (sixth column), while relighting is reasonable, artifacts emerge from latent decoding. Combining all components eliminates these artifacts, resulting in plausible relights with second-order lighting effects (last column).",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x6.png",
                "caption": "Figure 7:Nearest Neighbor Search.Diffusion models are sensitive to seed choice[57]. We observed that the choice of random seeds significantly impacts relighting quality. Here, we present sampled relights generated from 30 random seeds, sorted by their match to the target lighting image. Sorting is based on nearest-neighbor matching of the latent extrinsic (a low-dimensional lighting vector) to the target.",
                "position": 655
            }
        ]
    },
    {
        "header": "7Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00177/x7.png",
                "caption": "Figure 8:Failure case. Our method fails to recognize the lamp when the lamp in the original image is either too small or positioned with its back to the camera. Moreover, our method fails to transfer the dramatic lighting color (chromaticity), such as the lighting of a Karaoke room.",
                "position": 681
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x8.png",
                "caption": "Figure 9:Additional Relit Images (switching on ceiling lamps). The target lighting is shown in the top-left image, where a ceiling lamp is switched on. Ceiling lamps are very rare in our training data; however, we find that\\methodis still able to understand them and synthesize plausible relit images, as shown in the third column. In the first row, notice the suppression of gloss near the window at the top (see crop) and the added gloss due to inter-reflection on the TV screen. Also, note how the shaft lighting effect from the source image is suppressed. In the second row, observe how three ceiling lamps significantly brighten the room, with strong gloss visible on both the wooden floor and the dining table. In the third row, notice the sheen on the sofa and the edge of the coffee table, which become clearly visible after relighting. In the fourth row, see how the reflection of the lamp appears on the painting on the side wall. Also, note the shadow cast by the chair on the side wall below the painting. Finally, in the last row, observe how soft shadows along the edges of the ceiling and side wall are suppressed, while soft-light gloss becomes visible. Further, note the reflection on a mirror-like object in the bottom crop.",
                "position": 684
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x9.png",
                "caption": "Figure 10:Additional Relit Images. The target light is shown in the top-left image, where all lamps are switched off, and the only illumination comes from diffused natural light entering through a window on the right. The second column displays the source images to be relit to match the target light, while the third column presents the relit images. The final column highlights cropped regions before and after relighting, emphasizing the second-order lighting effects captured by\\method. In the top row (first relit image), note the table‚Äôs reflection in the TV and the strong gloss on the table from the directional window light. In the fourth row, observe how the sky changes to reflect the ambiance of the target light. In the last row, notice specular highlights on the table because of the direction light from the window. Also, notice the shadow cast by the cabinet in the bottom crop.",
                "position": 687
            },
            {
                "img": "https://arxiv.org/html/2412.00177/x10.png",
                "caption": "Figure 11:Additional Relit Images. The target lighting is shown in the top-left image, where all lamps are switched on. The second column displays the source images to be relit to match the target lighting, where all lamps are switched off, and the third column presents the relit images. The final column highlights cropped regions before and after relighting. In the top row (first relit image), note the overall change in the room‚Äôs color and the colored gloss added to the side of the bedsheet. In the second row, notice that the strong gloss on the carpet is removed. In the third row, switching on the side lamps removes the lamp shadow; also, observe the effect of the lamp on the ceiling and the gloss added to the edge of the table, as shown in the crop. In the fourth row, notice that the left side of the bed is now well-lit due to the lamp. Finally, in the last row, observe the gloss added to the wallpaper because of switching on the lamp",
                "position": 690
            }
        ]
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]