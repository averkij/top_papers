[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/Framework.png",
                "caption": "Figure 1:(a)A demonstration of how Vanilla Prompting, Prompt Engineering, and Thinking Intervention work. Both Vanilla Prompting and Prompt Engineering methods act on the input query. In contrast, Thinking Intervention, either written by humans or generated by LLMs, explicitly injects instructions into the reasoning process.(b)Compared to Vanilla Prompting and Prompt Engineering, Thinking Intervention offers significant performance improvements forR1-Qwen-32Breasoning model across instruction following, instruction hierarchy, and safety alignment tasks.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Thinking Intervention: A Novel Perspective on Controlling Reasoning Models",
        "images": []
    },
    {
        "header": "3Case Study: Instruction Following",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/IFeval_example.png",
                "caption": "Figure 2:An example demonstrating how Thinking Intervention is integrated with vanilla prompting and Reminder Prompting prompting techniques for instruction following tasks.",
                "position": 305
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x1.png",
                "caption": "Figure 3:Evaluation results on theIFEvalbenchmark[69]. We compare the performance with and without Thinking Intervention (ThinkingI), across Vanilla Prompting and Reminder Prompting methods and multiple reasoning models.",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x1.png",
                "caption": "",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x2.png",
                "caption": "",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x3.png",
                "caption": "",
                "position": 337
            }
        ]
    },
    {
        "header": "4Case Study: Instruction Hierarchy",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/SEPtask.png",
                "caption": "Figure 4:A demonstration of how theSEPbenchmark evaluates instruction hierarchy capabilities. Each example contains a main instruction paired with data.Left:The low-priority instruction is injected into the data, which the model should correctly ignore.Right:The low-priority instruction is absent, measuring the utility of models.",
                "position": 383
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/IH_PT.png",
                "caption": "Figure 5:A demonstration of Vanilla Prompting, Reminder Prompting, and Thinking Intervention for theSEPbenchmark. The{Task}and{Data}fields are filled with content from theSEPdataset (e.g., Figure4) during evaluation.",
                "position": 386
            }
        ]
    },
    {
        "header": "5Case Study: Safety Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/x4.png",
                "caption": "Figure 6:Model’s performance on theXSTestbenchmark via Vanilla Prompting prompting.",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x4.png",
                "caption": "Figure 6:Model’s performance on theXSTestbenchmark via Vanilla Prompting prompting.",
                "position": 521
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x5.png",
                "caption": "Figure 7:Effect of the Thinking Intervention withR1-Qwen-32Bmodel onXSTestbenchmark results.",
                "position": 526
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x6.png",
                "caption": "Figure 8:Effect of the Thinking Intervention withR1-Qwen-32Bmodel onSORRY-Bench.",
                "position": 532
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Related Works",
        "images": []
    },
    {
        "header": "8Conclusion.",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAddtional Related Works",
        "images": []
    },
    {
        "header": "Appendix BInstruction Following Evaluation (IFEval)",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/IF_gen_prompt.png",
                "caption": "Figure 9:A demonstration of how we promptGPT-4oto generate the Reminder Prompting. The intervention sequence is a slightly modified version of Reminder Prompting.",
                "position": 1639
            }
        ]
    },
    {
        "header": "Appendix CInstruction Hierarchy (SEP)",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/SEPtaskfull.png",
                "caption": "Figure 10:A demonstration of how theSEPbenchmark evaluates instruction hierarchy capabilities. Each example consists of a main instruction paired with data.Left:A low-priority instruction is injected into the data, which the model should correctly ignore.Middle:A low-priority instruction is injected into the task portion, which the model should follow and generate answers.Right:The low-priority instruction is absent, allowing us to measure the utility of different methods.",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/SEP_eval_template.png",
                "caption": "Figure 11:Prompt template of evaluating the utility metric on theSEPbenchmark. The{Question}and{Answer}will be filled with the complete prompt and model response, respectively.",
                "position": 1786
            }
        ]
    },
    {
        "header": "Appendix DSafety Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/safety_template.png",
                "caption": "Figure 12:The baseline prompting methods, as well as our Thinking Intervention, used for evaluating safety steering. The{Query}will be filled with the query from the benchmarks. Note for Goal Priority Prompting, we eliminate the few-shot exemplars as suggested by[2].",
                "position": 1951
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/xs_eval_template.png",
                "caption": "Figure 13:Prompt template of evaluating the compliance or refusal rate on theXSTestbenchmark. The{Question}and{Answer}will be filled with the complete prompt and model response, respectively.",
                "position": 1962
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x7.png",
                "caption": "Figure 14:Effectiveness of Thinking Intervention on theXSTestbenchmark across multiple reasoning models.",
                "position": 1977
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x7.png",
                "caption": "",
                "position": 1998
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x8.png",
                "caption": "",
                "position": 2002
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x9.png",
                "caption": "",
                "position": 2006
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/sorry_eval_template.png",
                "caption": "Figure 15:Prompt template of evaluating the refusal rate on theSORRY-Benchbenchmark. The{Question}and{Answer}will be filled with the complete prompt and model response, respectively.",
                "position": 2020
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x10.png",
                "caption": "Figure 16:Effectiveness of Thinking Intervention on theSORRY-Benchbenchmark across multiple models. Our approach consistently improves the safety alignment of reasoning models.",
                "position": 2026
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x10.png",
                "caption": "",
                "position": 2047
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x11.png",
                "caption": "",
                "position": 2051
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x12.png",
                "caption": "",
                "position": 2055
            }
        ]
    },
    {
        "header": "Appendix EEffect of Thinking Intervention Designs",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24370/x13.png",
                "caption": "Figure 17:Analysis of varying the location of the intervention sequence on theXSTestandSORRY-Benchbenchmarks. The content is kept unchanged, and the Thinking Intervention is placed at the beginning, middle, and end of the reasoning process.",
                "position": 2081
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x13.png",
                "caption": "",
                "position": 2109
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x14.png",
                "caption": "",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x15.png",
                "caption": "",
                "position": 2118
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x16.png",
                "caption": "",
                "position": 2122
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x17.png",
                "caption": "Figure 18:Analysis of varying the Thinking Intervention content onXSTestandSORRY-Benchbenchmarks. We compare our default short intervention sequence with a longer version. Both versions are inserted at the beginning of the reasoning process.",
                "position": 2145
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x17.png",
                "caption": "",
                "position": 2163
            },
            {
                "img": "https://arxiv.org/html/2503.24370/x18.png",
                "caption": "",
                "position": 2167
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/IH_example1.png",
                "caption": "Figure 19:A demonstration of how models without Thinking Intervention fail to ignore low-priority instructions and consequently provide incorrect responses. We use green color to highlight the main task and red color to highlight the low-priority query.",
                "position": 2185
            },
            {
                "img": "https://arxiv.org/html/2503.24370/extracted/6322787/images/IH_example2.png",
                "caption": "Figure 20:A demonstration of how models with Thinking Intervention successfully ignore low-priority instructions and provide correct responses. We use blue color to highlight the Thinking Intervention, green color to highlight the main task and red color to highlight the low-priority query.",
                "position": 2191
            }
        ]
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]