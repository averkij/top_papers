[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/images/teaser.jpg",
                "caption": "Figure 1.Based on a novel parametric representation, CHARM provides a generative framework for 3D anime hairstyle modeling.",
                "position": 140
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Works",
        "images": []
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/x1.png",
                "caption": "Figure 2.Illustration of the Anime hairstyle structure. Left: A complete hairstyle sample. Middle: Repeating units in the highlighted hair card. Right: Mesh connection pattern of a single unit.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2509.21114/x2.png",
                "caption": "Figure 3.Illustration of our hair parameterization. Within a single hair card, each bottom face of a repeating unit is defined by the 3D position of the centered control point, width, and thickness.",
                "position": 255
            },
            {
                "img": "https://arxiv.org/html/2509.21114/x3.png",
                "caption": "Figure 4.Hair sequence construction. Left: Ordering strategy showing counterclockwise arrangement of hair cards around the head and root-to-tip connectivity within each hair. Right: Sequence formulation where each row corresponds to a single hair card terminated by a MOS token.",
                "position": 384
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/images/comp.png",
                "caption": "Figure 5.Qualitative comparisons with other shape-conditioned 3D mesh generation methods.",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/comp2.png",
                "caption": "Figure 6.More qualitative comparisons with other shape-conditioned 3D mesh generation methods.",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/abl.png",
                "caption": "Figure 7.Qualitative comparisons of ablation study. Colors indicate different hair strands.",
                "position": 591
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/app.png",
                "caption": "Figure 8.Our framework supports flexible 3D anime hairstyle generation through various input conditions. The images in (a) and (b) are adapted from publicly available models on VRoid-Hub(VRoid,2022), while the remaining images are AI-generated.",
                "position": 594
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/tokenize.png",
                "caption": "Figure 9.Our compact and invertible parameterization achieves over 98% token compression compared to the original mesh.",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/real.png",
                "caption": "Figure 10.Qualitative comparison between DiffLocks (realistic hair method) and our approach on image-conditioned 3D hairstyle generation. The images used for this comparison are AI-generated.",
                "position": 766
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtra Inference Strategies",
        "images": []
    },
    {
        "header": "Appendix BDetails of Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/images/hair_statistics.png",
                "caption": "Figure 11.Statistical analysis of AnimeHair data parameters.",
                "position": 1776
            }
        ]
    },
    {
        "header": "Appendix CImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/images/levels.png",
                "caption": "Figure 12.Visualizations of applying different discretization levels.",
                "position": 1811
            }
        ]
    },
    {
        "header": "Appendix DMore Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21114/images/fail.png",
                "caption": "Figure 13.Failure cases of our autoregressive generation approach. Left: incomplete hairstyle due to repetitive hair card generation at the same location. Middle: erroneous positional jump generating a hair card away from the main hairstyle. Right: low coverage result with hair gaps compared to ground truth.",
                "position": 1871
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/comp3.png",
                "caption": "Figure 14.More qualitative comparisons with other methods.",
                "position": 1949
            },
            {
                "img": "https://arxiv.org/html/2509.21114/images/abl2.png",
                "caption": "Figure 15.More qualitative comparisons of ablation study. Colors indicate different hair strands.",
                "position": 1952
            }
        ]
    },
    {
        "header": "Appendix EMore Results",
        "images": []
    }
]