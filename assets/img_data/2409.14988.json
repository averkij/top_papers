[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/training_loss_general.png",
                "caption": "(a)",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/training_loss_general.png",
                "caption": "(a)",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/training_loss_clinical.png",
                "caption": "(b)",
                "position": 137
            }
        ]
    },
    {
        "header": "4Datasets",
        "images": []
    },
    {
        "header": "5Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/medqa_accuracy_vs_tokens_pandf_new.png",
                "caption": "Figure 2:Evolution of MedQA accuracy for Mistral-7b and Mixtral 8x7b base models as well as our instructed versions of Mistral-7b during continuous pretraining.P‚Å¢ÀÜ‚Å¢tùëÉÀÜùë°PÀÜtitalic_P roman_ÀÜ italic_t: Continuous Pretrained with variable numbers of tokenstùë°titalic_t,FùêπFitalic_F: Instruct Finetuned. We show that, while base model accuracy remains consistent, applying instruct-finetuning leads to notable improvements.",
                "position": 462
            }
        ]
    },
    {
        "header": "6Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/medprompt.png",
                "caption": "Figure 3:Evolution of MedQA accuracy using MedPrompt over different versions of Mixtral.",
                "position": 483
            }
        ]
    },
    {
        "header": "7Conclusion and Discussions",
        "images": []
    },
    {
        "header": "8Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/prompt.png",
                "caption": "Figure 4:Zero-shot prompt format on a sample from MedQA",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2409.14988/extracted/5872351/img/prompt_cot.png",
                "caption": "Figure 5:Chain-of-Thought prompt format on a sample from MedQA",
                "position": 1421
            }
        ]
    },
    {
        "header": "Appendix AAppendix: Supplementary Materials",
        "images": []
    }
]