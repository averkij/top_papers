[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x1.png",
                "caption": "Figure 1:We propose Speculative Jacobi Decoding, a training-free multi-token prediction algorithm, to accelerate auto-regressive text-to-image generation by reducing the number of model forward passes (denoted assteps) during inference.\nWe perform our algorithm on Lumina-mGPT, and the reduced steps are marked inred. The original steps are marked in black.",
                "position": 108
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x2.png",
                "caption": "Figure 2:The results of the greedy decoding (no randomness), top-10101010, top-100100100100, and top-2000200020002000sampling (high randomness) of Lumina-mGPT(Liu et al.,2024b). Each column presents samples with the same prompt but differentrandom seeds.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x2.png",
                "caption": "Figure 2:The results of the greedy decoding (no randomness), top-10101010, top-100100100100, and top-2000200020002000sampling (high randomness) of Lumina-mGPT(Liu et al.,2024b). Each column presents samples with the same prompt but differentrandom seeds.",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x3.png",
                "caption": "Figure 3:The pipeline of the vanilla Jacobi decoding on an auto-regressive model. The prediction with sampling is performed in parallel at each Jacobiiteration. We use different shades of blue to indicate the differences between the tokens that have not been accepted.",
                "position": 215
            }
        ]
    },
    {
        "header": "4Speculative Jacobi Decoding",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x4.png",
                "caption": "Figure 4:Overview of one iteration of our speculative Jacobi decoding (SJD).First, a sequence of draft tokens and the corresponding probabilities are taken as the inputs.\nSecond, we perform a forward pass with the auto-regressive model on the draft tokens, obtaining the probabilities of these tokens.\nThird, we perform the verification according to these two types of probabilities, accepting a subset of tokens and (re-)sampling the remaining tokens.\nLast, the accepted tokens are appended to the pre-filling tokens and fixed, while the resampled tokens, along with newly initialized tokens, will serve as the draft tokens for the next iteration.",
                "position": 262
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x5.png",
                "caption": "Figure 5:The images generated by Lumina-mGPT with different acceleration methods.",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x6.png",
                "caption": "Figure 6:Our method beats the vanilla Jacobi decoding under various sampling randomness.",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x6.png",
                "caption": "Figure 6:Our method beats the vanilla Jacobi decoding under various sampling randomness.",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x7.png",
                "caption": "Figure 7:Higher image resolution can result in a slightly larger acceleration in our method.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x8.png",
                "caption": "Figure 8:The acceleration ratio is the largest when the Jacobi window size is at least 16.",
                "position": 625
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x8.png",
                "caption": "Figure 8:The acceleration ratio is the largest when the Jacobi window size is at least 16.",
                "position": 628
            },
            {
                "img": "https://arxiv.org/html/2410.01699/x9.png",
                "caption": "Figure 9:The token initialization strategy impacts the acceleration ratio of image generation that contains simple and repeat patterns (examples of generated images on the right side).",
                "position": 635
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProofs",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x10.png",
                "caption": "Figure 10:The images generated by Lumina-mGPT(Liu et al.,2024b)with our acceleration method.",
                "position": 1621
            }
        ]
    },
    {
        "header": "Appendix BMore Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x11.png",
                "caption": "Figure 11:The images generated by Emu3(BAAI,2024)with our acceleration method.",
                "position": 1636
            }
        ]
    },
    {
        "header": "Appendix CInference Latency",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x12.png",
                "caption": "Figure 12:The latency of Lumina-mGPT on generating768×768768768768\\times 768768 × 768and1024×1024102410241024\\times 10241024 × 1024images without or with our method.",
                "position": 1645
            }
        ]
    },
    {
        "header": "Appendix DMore Quantitative Results",
        "images": []
    },
    {
        "header": "Appendix EVisualization of Acceleration in 2D space",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.01699/x13.png",
                "caption": "Figure 13:The visualization of the accelerated tokens on 2D space.",
                "position": 1780
            }
        ]
    },
    {
        "header": "Appendix FLimitation and future work",
        "images": []
    },
    {
        "header": "Appendix GBroader Impacts",
        "images": []
    }
]