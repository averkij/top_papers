[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08001/x1.png",
                "caption": "",
                "position": 70
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08001/x2.png",
                "caption": "Figure 2:The overall architecture ofRoboDual.(a) Generalist. The generalist takes as inputs RGB images and language prompts, generating conditioning sources for the specialist model, including latent representations and discretized actions.(b) Specialist. Comprising stacked Diffusion Transformer (DiT) blocks, the specialist is conditioned\non\nmultiple sensory inputs and the generalist‚Äôs output through a cross-attention mechanism. It predicts noise injected into ground truth actions, providing fast, precise control by leveraging the slower, high-level guidance of the generalist.",
                "position": 153
            }
        ]
    },
    {
        "header": "3RoboDual: Generalist-Specialist Synergy",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08001/x3.png",
                "caption": "Figure 3:Real-world robot experiments.We report the success rates of each method on three single-instruction tasks and two multi-instruction tasks, along with the aggregate performance. RoboDual outperforms all specialist and generalist baselines by a notable margin across all tasks.",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2410.08001/x4.png",
                "caption": "Figure 4:Setting on generalizability evaluation.We evaluate four axes of generalizability with different tasks:(a)Position Variation: The red block will be randomly placed in a20‚Å¢c‚Å¢m√ó10‚Å¢c‚Å¢m20ùëêùëö10ùëêùëö20cm\\times 10cm20 italic_c italic_m √ó 10 italic_c italic_marea;(b)Visual Distractor: We change the color of drawer, with added plush toys, yellow bowls and clay as distractors;(c)Unseen Background: We replace the checkered tablecloth with a solid white one; and(d)Novel Object: Manipulated objects are replaced with unseen ones¬†(banana‚Üí‚Üí\\rightarrow‚Üíeggplant).",
                "position": 463
            },
            {
                "img": "https://arxiv.org/html/2410.08001/x5.png",
                "caption": "Figure 5:Training efficiency.We report the training duration (GPU hours) of the different methods and the model performance in different training phases. RoboDual achieves notable performance gains with minimum training time.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2410.08001/x6.png",
                "caption": "Figure 6:Ablations on the factors affecting system synergy.We investigate:(a)The importance of each output from the generalist as conditioning sources,(b)The effectiveness of incorporating additional sensory inputs, and(c)Comparison between different conditioning methods.",
                "position": 691
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExtended Details on Evaluation Suites",
        "images": []
    },
    {
        "header": "Appendix BArchitecture Design and Training Hyperparameters",
        "images": []
    }
]