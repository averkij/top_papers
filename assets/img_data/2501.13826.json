[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x1.png",
                "caption": "",
                "position": 95
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x2.png",
                "caption": "Figure 2:Sampled Video-MMMU examples across 6 academic disciplines and 3 tracks. The examples are organized in two rows based on distinct video types: (1) Concept-Introduction videos (top row) focus on teaching factual knowledge, fundamental concepts, and theories through explanatory content, while (2) Problem-Solving videos (bottom row) demonstrate step-by-step solutions to an example question.",
                "position": 122
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Video-MMMU Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x3.png",
                "caption": "Figure 3:Taxonomy of QA types and video disciplines.",
                "position": 167
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x4.png",
                "caption": "Figure 4:Performance comparison across tracks before and after adding audio transcripts.",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x5.png",
                "caption": "(a)Comparison ofΔknowledgesubscriptΔknowledge\\Delta_{\\text{knowledge}}roman_Δ start_POSTSUBSCRIPT knowledge end_POSTSUBSCRIPT(performance improvement in the Adaptation track after watching the video compared to before).",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x5.png",
                "caption": "(a)Comparison ofΔknowledgesubscriptΔknowledge\\Delta_{\\text{knowledge}}roman_Δ start_POSTSUBSCRIPT knowledge end_POSTSUBSCRIPT(performance improvement in the Adaptation track after watching the video compared to before).",
                "position": 635
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x6.png",
                "caption": "(b)Comparison of Wrong-to-Right Rate (the percentage of Adaptation track questions that were initially answered incorrectly without the video but correctly after watching the video) and Right-to-Wrong Rate (vice versa).",
                "position": 640
            }
        ]
    },
    {
        "header": "5Knowledge Acquisition in Adaptation Track",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x7.png",
                "caption": "Figure 6:A Case of Method Adaptation Error. The model can recall the correct knowledge from the video but fails to adapt the method to a new scenario. More error cases are analyzed in the Appendix.",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x8.png",
                "caption": "Figure 7:Distribution of the 100 human-annotated errors in Claude-3.5-Sonnet.",
                "position": 694
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Subjects by Discipline",
        "images": []
    },
    {
        "header": "8Additional Knowledge Acquisition Experiment Results",
        "images": []
    },
    {
        "header": "9Prompt for Adaptation Track",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x9.png",
                "caption": "Figure 8:Prompt for Adaptation track.",
                "position": 1749
            }
        ]
    },
    {
        "header": "10Prompt for Determining the Helpfulness of Audio",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x10.png",
                "caption": "Figure 9:Prompt for determining the helpfulness of audio.",
                "position": 1759
            }
        ]
    },
    {
        "header": "11Annotation Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x11.png",
                "caption": "Figure 10:An illustration of the dataset curation pipeline.",
                "position": 1769
            }
        ]
    },
    {
        "header": "12More Error Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13826/x12.png",
                "caption": "Figure 11:A sample error case in the Adaptation track: Method Selection Error by Claude-3.5-Sonnet.",
                "position": 1795
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x13.png",
                "caption": "Figure 12:A sample error case in the Adaptation track: Question Misreading Error by Claude-3.5-Sonnet.",
                "position": 1798
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x14.png",
                "caption": "Figure 13:A sample error case in the Adaptation track: Method Adaptation Error by GPT-4o.",
                "position": 1801
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x15.png",
                "caption": "Figure 14:A sample error case in the Adaptation track: Question Misreading Error by GPT-4o.",
                "position": 1804
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x16.png",
                "caption": "Figure 15:A sample error case in the Perception track.",
                "position": 1807
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x17.png",
                "caption": "Figure 16:A sample error case in the Perception track.",
                "position": 1810
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x18.png",
                "caption": "Figure 17:A sample error case in the Comprehension track.",
                "position": 1813
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x19.png",
                "caption": "Figure 18:A sample error case in the Comprehension track.",
                "position": 1816
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x20.png",
                "caption": "Figure 19:A Wrong-to-Right example of Claude-3.5-Sonnet in the Adaptation track.",
                "position": 1819
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x21.png",
                "caption": "Figure 20:A Wrong-to-Right example of Claude-3.5-Sonnet in the Adaptation track.",
                "position": 1822
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x22.png",
                "caption": "Figure 21:A Wrong-to-Right example of Claude-3.5-Sonnet in the Adaptation track.",
                "position": 1825
            },
            {
                "img": "https://arxiv.org/html/2501.13826/x23.png",
                "caption": "Figure 22:A Wrong-to-Right example of GPT-4o in the Adaptation track.",
                "position": 1828
            }
        ]
    },
    {
        "header": "13Wrong-to-Right Case Analysis",
        "images": []
    }
]