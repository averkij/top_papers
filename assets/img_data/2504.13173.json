[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/MIRAS.png",
                "caption": "Figure 1:The overview ofMirasframework.Mirasis based on four critical choices of (1) memory architecture, (2) attentional bias, (3) retention gate, and (4) memory learning algorithm. In this framework, the memory architecture determines the model capacity to memorize; attentional bias is responsible for modeling the underlying mapping patterns; retention gate determines how to balance learning new concepts and the retention of previously learned concepts; and memory learning algorithm is responsible for memory management.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Preliminaries and Background",
        "images": []
    },
    {
        "header": "3Associative Memory, Attentional Bias, and Retention",
        "images": []
    },
    {
        "header": "4Miras: Learning to Memorize with Robust and Expressive Memory",
        "images": []
    },
    {
        "header": "5Beyond Existing Attentional Biases and Retention Gates",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/MIRAS-Block.png",
                "caption": "Figure 2:Visualization of theMirasâ€™s variant architecture, their hybrid counterpart with SWA, and block design ofMiraslayer.",
                "position": 1306
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/scaling.png",
                "caption": "Figure 3:Scaling patterns when increasing (Left) model size, (Middle) sequence length (model size = 340M) (3) (Right) sequence length (model size = 760M) on C4 dataset.",
                "position": 1954
            },
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/Seq-scale-340M.png",
                "caption": "",
                "position": 1957
            },
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/Seq-scale-780M.png",
                "caption": "",
                "position": 1958
            },
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/effect-p.png",
                "caption": "",
                "position": 2120
            },
            {
                "img": "https://arxiv.org/html/2504.13173/extracted/6367629/effect-q.png",
                "caption": "",
                "position": 2120
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix BProof of Proposition3.2",
        "images": []
    },
    {
        "header": "Appendix CExperimental Setup",
        "images": []
    }
]