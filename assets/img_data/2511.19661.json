[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x1.png",
                "caption": "Figure 1:An example of visual agentic system generating “unfaithful” trajectory: the cropping tool is used at the wrong region with unfaithful analysis but leads to correct answer.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x2.png",
                "caption": "Figure 2:Faithfulness conditioned on correct answers in V*[wu2024v]Benchmark.For this visual search problem, crop is treated as the most effective tool use[zhao2025pyvision,zheng2025deepeyes,su2025pixelreasoner]. Therefore, we define faithful tool use as cropped image from tool use capturinganytarget object and evaluate how many correct answers are also faithful, as shown inviolet. For the remaining correct answers, the tool uses do not capture the target object and are treated as unfaithful, as shown inmint. Recent visual agents achieve high final-answer accuracy but fail to use tools faithfully. CodeV shows great improvement in faithfulness with no decrease in accuracy.",
                "position": 232
            }
        ]
    },
    {
        "header": "3Evidence of Unfaithful Tool Use in VLMs",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x3.png",
                "caption": "Figure 3:Overview of the CodeV rollout and Tool-Aware Policy Optimization (TAPO). The model processes an imageIIand questionQpair, using tools like cropping to generate intermediate results for its final answer. Tool faithfulness will be scored by a reward model. For the tool like cropping, reward model will scorertoolr^{\\mathrm{tool}}based on the observability of the target object in the cropped image. The final answer correctness will be used as outcome reward. The policy VLM is fine-tuned with tool-aware policy optimization, a GRPO-style reinforcement learning approach. The policy VLM will conduct multiple rollouts for the sameQandIIwith tool use. These rollouts will be scored by the hybrid reward system that combines faithfulness and correctness. Final reward will be normalized within the group and used to estimate relative advantage for the policy VLM to update.",
                "position": 266
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x4.png",
                "caption": "Figure 4:Performance across primitive perception, visual search, reasoning and math benchmarks. All model other than GPT-4o are 7B model with proper setup of tool use.",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2511.19661/x5.png",
                "caption": "Figure 5:Faithfulness comparison on V* and HRBench-4k benchmarks. The extremely low faithful tool use rate in[zhang2025thyme]results from low tool use rate and decorative tool use in chain of thought.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2511.19661/x6.png",
                "caption": "Figure 6:Tool invocation count during early RL training.",
                "position": 586
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Faithfulness Evaluation Protocol",
        "images": []
    },
    {
        "header": "9Data preparation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x7.png",
                "caption": "Figure 7:RL data distribution.",
                "position": 747
            }
        ]
    },
    {
        "header": "10Full results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x8.png",
                "caption": "Figure 8:Tool-use frequency and accuracy of CodeV.For each dataset (V*, HRBench-4K, HRBench-8K), we bucket examples by the number of tool calls in a trajectory and plot the fraction of all test examples in that bucket, split into correct (green) and incorrect (red) answers.\nNumbers above each bar show the total fraction of examples in that bucket, and numbers inside the green bars show the fraction ofallexamples that are both correct and use that number of tools.",
                "position": 1518
            }
        ]
    },
    {
        "header": "11Tool Use analysis",
        "images": []
    },
    {
        "header": "12Python Sandbox Design",
        "images": []
    },
    {
        "header": "13RL Prompt Design",
        "images": []
    },
    {
        "header": "14Training Dynamics",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19661/x9.png",
                "caption": "Figure 9:Reward score for accuracy, format and tool use.",
                "position": 1634
            },
            {
                "img": "https://arxiv.org/html/2511.19661/x10.png",
                "caption": "Figure 10:Response length and tool calls during TAPO.",
                "position": 1637
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/vstar_12.jpg",
                "caption": "",
                "position": 1670
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/vstar_12_crop_0.jpg",
                "caption": "",
                "position": 1741
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/vstar_6.jpg",
                "caption": "",
                "position": 1777
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/vstar_6_crop_0.jpg",
                "caption": "",
                "position": 1845
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_10_low.jpg",
                "caption": "",
                "position": 1884
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_10_crop_0_low.jpg",
                "caption": "",
                "position": 1947
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_10_crop_1_low.jpg",
                "caption": "",
                "position": 2009
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_48_low.jpg",
                "caption": "",
                "position": 2048
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_48_crop_0_low.jpg",
                "caption": "",
                "position": 2111
            },
            {
                "img": "https://arxiv.org/html/2511.19661/asset/appendix/hr8k_48_crop_1_low.jpg",
                "caption": "",
                "position": 2174
            }
        ]
    },
    {
        "header": "15Qualitative Examples",
        "images": []
    }
]