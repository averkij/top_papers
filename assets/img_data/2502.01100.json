[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01100/x1.png",
                "caption": "Figure 1:Accuracy vs number of Z3 conflicts for Llama-3 (left), showing the size scaling effect on the reasoning performance. The middle figure shows the curves for gpt-4o(-mini) vs o1 and R1, showing the scaling effect of model size and test-time compute. The right figure shows the scaling effect of repeated sampling by pass@k metric with different sample sizes.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2502.01100/x2.png",
                "caption": "Figure 2:This example of ZebraLogic features 3 houses (N=3) and 3 attributes (M=3), with 6 clues (K=6). TheBackgroundoutlines the attributes, their possible values, and the uniqueness constraints. TheCluesprovide additional constraints regarding theattributes. The task for the model is to determine the correct assignment of attributes to each house based on these clues, as illustrated in theSolutiongrid.",
                "position": 184
            }
        ]
    },
    {
        "header": "2Problem Formulation of Logical Reasoning",
        "images": []
    },
    {
        "header": "3Evaluation",
        "images": []
    },
    {
        "header": "4Scaling Model Size Can Hardly Break the Curse of Complexity in Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01100/x3.png",
                "caption": "Figure 3:Accuracy vs Search Space Size(log scale) comparing multiple scaling behavior of LLMs on ZebraLogic. Left: Scaling model sizes. Right: Scaling test-time compute through two approaches - increasing sample size (via pass@k evaluation) and extending chain-of-thought reasoning length. Both model size and test-time compute show diminishing returns as search space complexity grows beyond a certain complexity.\nMore results are presented in Sec.3.",
                "position": 779
            }
        ]
    },
    {
        "header": "5Scaling Test-Time Compute with Repeated Sampling: Promises & Challenges",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01100/x4.png",
                "caption": "Figure 4:The o1 models’ hidden CoT tokens vs. the number of Z3 conflicts. Each point is an example with a certain number of Z3 conflicts. Larger number of Z3 conflicts are associated with harder reasoning problems.",
                "position": 817
            }
        ]
    },
    {
        "header": "6Scaling Test-Time Compute with Extensive Chain-of-Thoughts Tokens",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01100/x5.png",
                "caption": "Figure 5:Top: Distribution of hidden reasoning tokens generated by o1-mini and o1-preview models.\nBottom: Distribution of visible reasoning tokens across GPT-4o-mini, GPT-4o, o1-mini, and o1-preview models.\nMean hidden reasoning tokens per model: o1-mini generates 5,144.6 tokens and o1-preview generates 5,346.3 tokens.\nMean visible reasoning tokens per model: GPT-4o-mini (502.9), GPT-4o (543.7), o1-mini (305.7), and o1-preview (402.4).",
                "position": 1625
            },
            {
                "img": "https://arxiv.org/html/2502.01100/extracted/6173744/assets/sampling.png",
                "caption": "Figure 6:Analysis of inference-time compute scaling using Best-of-N (BoN) sampling across different ZebraLogic puzzle size groups. The curves demonstrate how increasing the number of samples affects model performance, with separate plots for Small, Medium, Large, and X-Large puzzle categories.",
                "position": 1633
            },
            {
                "img": "https://arxiv.org/html/2502.01100/x6.png",
                "caption": "Figure 7:Heatmaps illustrating puzzle complexity metrics across different ZebraLogic problem sizes. The left heatmap represents the log-scaled search space size, categorized from Small to X-Large based on the grid configurations (houses × attributes). The right heatmap shows the average number of Z3 conflicts encountered during solving, with higher counts indicating greater logical complexity.",
                "position": 1638
            }
        ]
    },
    {
        "header": "Appendix BDetails of the ZebraLogic Dataset",
        "images": []
    },
    {
        "header": "Appendix CAdditional Analysis",
        "images": []
    },
    {
        "header": "Appendix DFurther Discussion on o1’s Reasoning",
        "images": []
    }
]