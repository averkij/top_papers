[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03559/x1.png",
                "caption": "Figure 1:Comparison of our proposedDiffCoTwith existing CoT reasoning approaches:(a)Existing step-by-step CoT Reasoning methods adopt teacher-forcing training, where each step depends on the ground-truth output of the previous one. At inference time, this assumption breaks, causing exposure bias and leading to error accumulation.(b)DiffCoTperforms CoT reasoning along both the noise (diffusion) and temporal (autoregressive) dimensions, enabling iterative correction of prior mistakes and effectively mitigating exposure bias.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03559/figs/method.png",
                "caption": "Figure 2:DiffCoT Framework and Training Data Construction:(a)Step-level forward noising: MCTS-based data generation defines step-level noise by reward-ranking multiple candidates, yielding states ranging from clean to corrupted.(b)Sliding-window denoising: a diffusion sliding window refines previously generated CoT steps while producing the next step in an autoregressive manner.(c)Causal diffusion noise: a step-dependent schedule assigns stronger noise to later steps to encode the causal order of the reasoning chain.",
                "position": 258
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03559/figs/case.png",
                "caption": "Figure 3:Example illustrating howDiffCoTmodifies early-stage reasoning shift steps. The steps highlighted in blue represent the diffusion sliding window.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2601.03559/x2.png",
                "caption": "Figure 4:Correction success rate under stochastic prefix corruption, where noise is injected at the midpoint of the reasoning trajectory with probabilityÏ‰\\omega.",
                "position": 693
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Statistics",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CDiscussion with Reinforcement Learning",
        "images": []
    },
    {
        "header": "Appendix DGenerative AI Usage",
        "images": []
    }
]