[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04097/x1.png",
                "caption": "Figure 1:Region-aware Vision-Language learning (RaVL).RaVLtakes a fine-grained perspective on VLM robustness by discovering and mitigating spurious correlations using local image features.",
                "position": 105
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Discovering Spurious Correlations in Fine-Tuned Vision-Language Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04097/x2.png",
                "caption": "Figure 2:RaVLaccurately identifies spurious correlations.Using our evaluation settings, we show thatRaVLconsistently outperforms prior methods in discovering learned spurious correlations between image features and textual attributes. Here, we provide Precision@10 metrics for a CLIP-RN50 model fine-tuned on synthetic data (129 settings) and real-world data (171 settings).",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2411.04097/x3.png",
                "caption": "Figure 3:RaVLsurfaces spurious correlations in off-the-shelf VLMs.RaVLidentifies a spurious correlation learned by CLIP ViT-B/16 between the presence of text-based retail signage and the class labelfast food restaurantin a scene classification task.RaVLalso surfaces a spurious correlation learned by PubMedCLIP ResNet-50 between metal clips (found in clothing) and the class labelcardiomegaly(a heart condition) on a chest X-ray classification task.",
                "position": 413
            }
        ]
    },
    {
        "header": "4Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BExtended Details on Evaluation Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04097/x4.png",
                "caption": "Figure 4:Example evaluation settings.Here, we provide examples of predefined spurious correlations, fine-tuning datasets, and evaluation datasets associated with a synthetic evaluation setting (top row) and a real-world evaluation setting (bottom row). The example synthetic evaluation setting consists of a predefined spurious correlation between a red rectangle (spurious image featureğeâ¢vâ¢aâ¢lsuperscriptğğ‘’ğ‘£ğ‘ğ‘™\\mathbf{e}^{eval}bold_e start_POSTSUPERSCRIPT italic_e italic_v italic_a italic_l end_POSTSUPERSCRIPT) andnine(textual attributeaeâ¢vâ¢aâ¢lsuperscriptğ‘ğ‘’ğ‘£ğ‘ğ‘™a^{eval}italic_a start_POSTSUPERSCRIPT italic_e italic_v italic_a italic_l end_POSTSUPERSCRIPT). This spurious correlation is visible in the vision-language fine-tuning dataset, where the presence of red rectangles and nines are strongly correlated, but not in the evaluation dataset. Similarly, the example real-world evaluation setting consists of a predefined spurious correlation between a person (spurious image featureğeâ¢vâ¢aâ¢lsuperscriptğğ‘’ğ‘£ğ‘ğ‘™\\mathbf{e}^{eval}bold_e start_POSTSUPERSCRIPT italic_e italic_v italic_a italic_l end_POSTSUPERSCRIPT) andcouch(textual attributeaeâ¢vâ¢aâ¢lsuperscriptğ‘ğ‘’ğ‘£ğ‘ğ‘™a^{eval}italic_a start_POSTSUPERSCRIPT italic_e italic_v italic_a italic_l end_POSTSUPERSCRIPT). Again, this spurious correlation is visible in the vision-language fine-tuning dataset, where the presence of people and couches are strongly correlated, but not in the evaluation dataset.",
                "position": 1507
            }
        ]
    },
    {
        "header": "Appendix CExtended Details onRaVLMitigation",
        "images": []
    },
    {
        "header": "Appendix DExtended Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04097/x5.png",
                "caption": "Figure 5:RaVLaccurately identifies spurious correlations.Here, we provide an extended version of Figure2, which demonstrates thatRaVLconsistently outperforms prior methods in discovering learned spurious correlations between image features and textual attributes. Here, we provide Precision@10 metrics for a CLIP-RN50 model fine-tuned on synthetic data (129 settings) and real-world data (171 settings); a CLIP-RN101 model fine-tuned on synthetic data (162 settings) and real-world data (192 settings); and an average across both model architectures.",
                "position": 1604
            },
            {
                "img": "https://arxiv.org/html/2411.04097/x6.png",
                "caption": "Figure 6:RaVLsurfaces spurious correlations in off-the-shelf VLMs.Here, we extend Figure3with additional examples of spurious correlations discovered byRaVLin off-the-shelf-VLMs.",
                "position": 1638
            }
        ]
    },
    {
        "header": "Appendix EExtended Discussion",
        "images": []
    }
]