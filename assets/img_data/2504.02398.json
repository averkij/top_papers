[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02398/x1.png",
                "caption": "Figure 1:Analysing metric scaling of interleaved SLMs, considering the best model per-compute. We compare scaling trends to textless SLMs(Cuervo & Marxer,2024).\\gmFont maybe still a touch small?",
                "position": 109
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Building the Scaffolding for Scaling",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02398/x2.png",
                "caption": "Figure 2:Comparing SLMs trained with the same recipe for 20k steps, from different TextLM initialisations. Models are sorted by parameter count from large to small.",
                "position": 270
            },
            {
                "img": "https://arxiv.org/html/2504.02398/x3.png",
                "caption": "Figure 3:Comparing SLMs based on Qwen2.5-0.5B with interleaving, without interleaving and without TWIST initialisation (denoted GSLM). This helps analyse the impact of these choices on performance and thus on scaling analysis. See Appendix6for other metrics.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2504.02398/x4.png",
                "caption": "Figure 4:Comparing the loss on speech only of interleaved SLMs of different model sizes trained for specific compute budgets.",
                "position": 308
            }
        ]
    },
    {
        "header": "5Scaling Analysis",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02398/x5.png",
                "caption": "Figure 5:Comparing SLMs based on OPT125M with interleaving, without interleaving and without TWIST initialisation. Comparing to the Figure3, we can see that OPT125 benefits less from interleaving and TWIST initialisation compared to Qwen2.5-0.5B.",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2504.02398/x6.png",
                "caption": "Figure 6:Comparing SLMs based on Qwen2.5-0.5B with interleaving, without interleaving and without TWIST initialisation. This compliments Figure3, yet results are a bit more noisy, perhaps because they are nearer to random.",
                "position": 1652
            },
            {
                "img": "https://arxiv.org/html/2504.02398/x7.png",
                "caption": "Figure 7:Analysing the scaling properties of interleaved SLMs regarding multi-speaker sSC. This compliments Figure4, yet results are a bit more noisy, perhaps because they are nearer to random.",
                "position": 1658
            }
        ]
    },
    {
        "header": "Appendix BAdditional Results",
        "images": []
    }
]