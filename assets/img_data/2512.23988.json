[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23988/x1.png",
                "caption": "Figure 1:Illustration of ourRISEframework for unsupervised reasoning behavior discovery. The pipeline consists of two stages: (i) training a Sparse Autoencoder (SAE) on unlabeled representations of reasoning steps (Left), and (ii) evaluating causal effects on the original reasoning process (Right). Notably, the intervention process on the right is applied directly, without any additional training.",
                "position": 134
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Unsupervised Reasoning Vector Discovery",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23988/x2.png",
                "caption": "Figure 2:Visualization of SAE decoder columns projected onto a 2-D plane with UMAP. From left to right, we show the raw SAE decoder rows and the corresponding results with human-defined behaviors highlighted. Results are obtained from the final layer of R1-1.5B.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x3.png",
                "caption": "Figure 3:Normalized Silhouette scores across different layers of R1-1.5B.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x4.png",
                "caption": "Figure 4:Illustration of our inference process that utilizes SAE decoder columns. For a given reasoning behavior, we compute the corresponding centroid in the SAE decoder column space and directly apply it during inference of the original model for examining how the response changes.",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x5.png",
                "caption": "Figure 5:Statistics of reasoning behavior shifts induced by SAE column interventions are reported across different models and tasks, where the SAE columns are consistent across tasks.",
                "position": 336
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x6.png",
                "caption": "Figure 6:Responses from the R1-1.5B model when intervened with SAE vectors corresponding to reflection behaviors. Reasoning steps associated with reflection are highlighted in red. Zoom in for better visualization.",
                "position": 450
            }
        ]
    },
    {
        "header": "5Discovering New Behaviors with SAE",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23988/x7.png",
                "caption": "Figure 7:(a) Visualization of SAE decoder columns, with top-scoring columns related to entropy highlighted, showing clear clustering. (b) Most frequent tokens during vanilla inference. (c) Most frequent tokens under intervention with the entropy-related vector. Comparing (b) and (c), tokens associated with reflection or backtracking become less frequent (e.g., Wait), while more tokens emerge that correspond to confident mathematical calculation (e.g., numbers)",
                "position": 486
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x8.png",
                "caption": "Figure 8:Results on reasoning accuracy and token cost under different steering methods on R1-1.5B.",
                "position": 609
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "Appendix AClarification of LLM Usage",
        "images": []
    },
    {
        "header": "Appendix BTheoretical Justification",
        "images": []
    },
    {
        "header": "Appendix CEmpirical Validation of Sparsity and Incoherence Assumptions",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23988/x9.png",
                "caption": "Figure 9:Results on Sparsity and Incoherence Assumptions.",
                "position": 786
            }
        ]
    },
    {
        "header": "Appendix DAnnotation Details for Reasoning Behaviors",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23988/x10.png",
                "caption": "Figure 10:Results of annotation consistency across different methods. The numbers represent the agreement ratio for each pair of annotation methods.",
                "position": 890
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x11.png",
                "caption": "Figure 11:Visualization of the SAE decoder columns. From left to right, we show the raw SAE decoder columns and the corresponding results with human-defined behaviors highlighted (green/yellow dots represents the columns related with short and long responses, respectively). Results are obtained from DeepSeek-R1-1.5B using MATH-500 training samples.",
                "position": 904
            },
            {
                "img": "https://arxiv.org/html/2512.23988/x12.png",
                "caption": "Figure 12:Normalized Silhouette scores across different layers of R1-1.5B.",
                "position": 907
            }
        ]
    },
    {
        "header": "Appendix ESAE Reveals the Underlying Geometry of Response Length.",
        "images": []
    }
]