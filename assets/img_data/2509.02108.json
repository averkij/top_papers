[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Formalism",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.02108/images/kl_merging_method/kl_merge.png",
                "caption": "Figure 1:Illustration of the divergence-based model merging method. This figure shows the merging loss associated to one task to be merged, which is the tasktt. Our method consists in doing this procedure for every taskttand, as it is written on the left side, to sum all the associated loss. For more details, we refer toAlgorithmÂ 1.",
                "position": 464
            }
        ]
    },
    {
        "header": "4Experimental Protocol",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.02108/x1.png",
                "caption": "(a)Classification",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x1.png",
                "caption": "(a)Classification",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x2.png",
                "caption": "(b)Generation",
                "position": 707
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x3.png",
                "caption": "Figure 3:ANP\\mathrm{ANP}metric of merged task pairs with Task Level and Layer Level JS Divergence as a function of training iterations.",
                "position": 794
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x4.png",
                "caption": "Figure 4:Impact of dataset size on the performance of our approach compared to data-free baselines. The averageANP\\mathrm{ANP}is computed across three task pairs.",
                "position": 804
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical results",
        "images": []
    },
    {
        "header": "Appendix BDivergence Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.02108/x5.png",
                "caption": "(a)KL\\mathrm{KL}",
                "position": 1875
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x5.png",
                "caption": "(a)KL\\mathrm{KL}",
                "position": 1878
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x6.png",
                "caption": "(b)JS\\mathrm{JS}",
                "position": 1883
            }
        ]
    },
    {
        "header": "Appendix CAdditional experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.02108/x7.png",
                "caption": "Figure 6:Cosine similarity matrices of task vectors between different tasks. Left: Similarity between GLUE benchmark tasks (CoLA, SST2, QQP, QNLI, MNLI, RTE, MRPC). Right: Similarity between diverse generative tasks tasks (IMDB, QASC, SQUAD, commonGen). Lower similarity values indicate greater orthogonality between task vectors, suggesting less interference when merging models fine-tuned on these tasks.",
                "position": 2005
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x8.png",
                "caption": "Figure 7:Evolution of the task coefficients across training iterations. The first graph shows the coefficient assigned to the first task in each task pair (as indicated in the legend), while the second graph shows the coefficient assigned to the second task.",
                "position": 2229
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x9.png",
                "caption": "Figure 8:Visualization of coefficient values for a fixed reference task versus coefficient values for the remaining GLUE tasks. Each subplot corresponds to a different reference task.",
                "position": 2232
            },
            {
                "img": "https://arxiv.org/html/2509.02108/x10.png",
                "caption": "Figure 9:Coefficient values for each task at different T5 checkpoints. Each plot fixes a reference task and compares its coefficient to those of the other tasks.",
                "position": 2235
            }
        ]
    },
    {
        "header": "Appendix DTraining Settings",
        "images": []
    },
    {
        "header": "Appendix EEverything is task arithmetic",
        "images": []
    }
]