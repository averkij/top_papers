[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12801/x1.png",
                "caption": "Figure 1:Unlike previous baselines, which lack self-reflection, self-correction, and cropped image-based search, the proposedDeepMMSearch-R1is capable of performing on-demand, multi-turn web searches with enhanced image search that incorporates an intermediate cropping tool to select the most relevant region of an image. It demonstrates self-reflection and self-correction abilities, iteratively refining its text queries to better navigate noisy real-world web information. The model outperforms other baselines, notably GPT-4o, and is competitive with the GPT-o3 model.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Proposed Data: DeepMMSearchVQA",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12801/x2.png",
                "caption": "Figure 2:(top)DeepMMSearchVQA Data Generation Pipeline:It begins by passing a questionâ€“image pair(q,i)(q,i)to Gemini, which produces reasoning\nand concludes with anaction tag. We then apply checks A, B, and C:\nif either A or B fails, the example is discarded; if C passes, the final\nanswer is reached and the example is saved. Otherwise, the pipeline invokes\na search tool guided by the action tag. This tool retrieves the\ntop-kkweb results, which are then summarized and fed back into Gemini, incorporating web-retrieved information in its context for subsequent turns in the reasoning process.(bottom)DeepMMSearchVQA Statistics:Knowledge taxonomy, Distribution of examples across different numbers of conversational turns, Proportion of questions with text search, image search and cropped image search.",
                "position": 150
            }
        ]
    },
    {
        "header": "3DeepMMSearch-R1 Training Recipe",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12801/x3.png",
                "caption": "Figure 3:(left)Impact of self-reflection, self-correction and cropped image search on performance.(right)Effect of the ratio of search-required to search-free data, and of sampling strategies when curating SFT data.",
                "position": 440
            },
            {
                "img": "https://arxiv.org/html/2510.12801/x4.png",
                "caption": "Figure 4:Tool usage statistics after supervised finetuning and online RL on DynVQA and OK-VQA benchmarks.",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2510.12801/x5.png",
                "caption": "Figure 5:After SFT, the model performs unnecessary cropping. RL training refines the tool-use behavior, making it more efficient and invoking tools only when required.",
                "position": 456
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALLM Usage Statement",
        "images": []
    },
    {
        "header": "Appendix BRelated Works",
        "images": []
    },
    {
        "header": "Appendix CDatasets",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    },
    {
        "header": "Appendix EPrompts",
        "images": []
    },
    {
        "header": "Appendix FAdditional Content",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12801/x6.png",
                "caption": "Figure F.1:An image of a boat race.",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2510.12801/x7.png",
                "caption": "Figure G.1:A sample in DeepMMSearchVQA.",
                "position": 1655
            },
            {
                "img": "https://arxiv.org/html/2510.12801/x8.png",
                "caption": "Figure G.2:A sample in DeepMMSearchVQA.",
                "position": 1658
            }
        ]
    },
    {
        "header": "Appendix GDeepMMSearchVQA Samples",
        "images": []
    }
]