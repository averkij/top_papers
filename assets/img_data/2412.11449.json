[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction and Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11449/extracted/6065548/paperwhisper.png",
                "caption": "Fig. 1:(Left) Whisper Architecture proposed by OpenAI[26]which treats ASR as a sequence to sequence which takes in mel-spectrogram slices and decodes it token by token. It has a Transformer Encoder stack on the spectrogram followed by a Transformer decoder, trained for the shift-by-one token prediction, and the cross-attention module on learned spectrogram representation. (Right) Our generative model combines both continuous and discrete representations. We align the spectrogram and ENCODEC coarse tokens. Instead of a Transformer encoder, we pass spectrogram slices through lightweight decoder blocks. The learned representation per-token slice is concatenated with discrete tokens corresponding to the spectrogram slice to have a decoder Transformer stack, trained on shift by one next token prediction, similar to a typical LLM pre-training.",
                "position": 61
            }
        ]
    },
    {
        "header": "2Dataset",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11449/extracted/6065548/fig_music.png",
                "caption": "Fig. 2:Comparison of GPT on coarse acoustic tokens with i) GPT-L ii) Our hybrid continuous-discrete representation.",
                "position": 78
            },
            {
                "img": "https://arxiv.org/html/2412.11449/extracted/6065548/whisper-GPT.png",
                "caption": "Fig. 3:Comparison of GPT on coarse acoustic tokens with i) GPT-L ii) Our hybrid continuous-discrete representation.",
                "position": 102
            }
        ]
    },
    {
        "header": "4Results and Discussion",
        "images": []
    },
    {
        "header": "5Conclusion And Future Work",
        "images": []
    },
    {
        "header": "6Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]