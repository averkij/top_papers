[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/teaser.jpg",
                "caption": "Figure 1:Our proposed framework,EasyControl, is a lightweight and efficient plug-and-play module specifically designed for diffusion transformer. This solution not only enables spatial control and subject/face control under single conditions but also demonstrates remarkable zero-shot multi-condition generalization capability after single-condition training, achieving sophisticated multi-condition control.",
                "position": 105
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/method.jpg",
                "caption": "Figure 2:The illustration of EasyControl framework. The condition signal is injected into the Diffusion Transformer (DiT) through a newly introduced condition branch, which encodes the condition tokens in conjunction with a lightweight, plug-and-play Condition Injection LoRA Module. During training, each individual condition is trained separately, where condition images are resized to a lower resolution and trained using our proposed Position-Aware Training Paradigm. This approach enables efficient and flexible resolution training. The framework incorporates a Causal Attention mechanism, which enables the implementation of a Key-Value (KV) Cache to substantially improve inference efficiency. Furthermore, our design facilitates the seamless integration of multiple Condition Injection LoRA Modules, enabling robust and harmonious multi-condition generation.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/com1.jpg",
                "caption": "Figure 3:Visual comparison between different methods in single condition control. Figure (a) shows the results of each method under different control conditions and Figure (b) shows the adaptation of each method with different Style LoRA[56,57,58,38]under control.",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/com2.jpg",
                "caption": "Figure 4:Visual comparison of different methods under multi-condition control.",
                "position": 410
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/ab.jpg",
                "caption": "Figure 5:Visual ablation on different settings.",
                "position": 424
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "APreliminary: Diffusion Transformer",
        "images": []
    },
    {
        "header": "BPosition Encoding Offset",
        "images": []
    },
    {
        "header": "CTrianing Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/face_data.jpg",
                "caption": "Figure 6:Visualization of samples in private Multi-view Human Dataset.",
                "position": 638
            }
        ]
    },
    {
        "header": "DDetails of KV Cache",
        "images": []
    },
    {
        "header": "ESingle Condition Quantitative Comparison",
        "images": []
    },
    {
        "header": "FMulti-Condition Quantitative Comparison",
        "images": []
    },
    {
        "header": "GVisual Comparison of Resolution Adaptability",
        "images": []
    },
    {
        "header": "HLimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/lim.jpg",
                "caption": "Figure 7:Visualization of results (1) under conflicting condition inputs (2) under very high-resolution generation.",
                "position": 1030
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/sup_fo.jpg",
                "caption": "Figure 8:Visual comparison with Identity customization methods under multi-condition generation setting.",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/sup_spatial.jpg",
                "caption": "Figure 9:Visualization of spatial control generation.",
                "position": 1036
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/sup_subject.jpg",
                "caption": "Figure 10:Visualization of subject control generation.",
                "position": 1039
            },
            {
                "img": "https://arxiv.org/html/2503.07027/extracted/6266306/images/sup_res.jpg",
                "caption": "Figure 11:Visual comparison with baseline methods under different resolution generation settings.(zoom in for a better view)",
                "position": 1042
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]