[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16924/x1.png",
                "caption": "",
                "position": 89
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16924/x2.png",
                "caption": "Figure 2:The architecture of ourWorldCanvas.The data pipeline generates high-quality trajectory–reference–text triplets (in the figure, gray boxes denote reference images extracted from the video, and hollow circles along trajectories indicate invisible points due to occlusion or rotation). The Spatial-Aware Weighted Cross-Attention mechanism explicitly aligns each caption with its associated trajectory.",
                "position": 161
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16924/x3.png",
                "caption": "Figure 3:Qualitative comparison on promptable world event modeling.Our model successfully generates results that align with given trajectories, text prompt and reference images, whereas the baselines fail to properly correspond to these inputs.",
                "position": 305
            },
            {
                "img": "https://arxiv.org/html/2512.16924/x4.png",
                "caption": "Figure 4:Qualitative comparison of multi-subject trajectory-text alignment.Our method accurately aligns the textual descriptions with motions specified by trajectories, whereas the baselines fail to produce correct results in such cases.",
                "position": 406
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16924/x5.png",
                "caption": "Figure 5:Consistency maintenance results.The shown examples correspond to object consistency preservation, scene consistency preservation, and character consistency preservation, respectively.",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2512.16924/x6.png",
                "caption": "Figure 6:Qualitative results for our ablation study.Compared to variantswithout Spatial-Aware Weighted Cross-AttentionandHard Cross-Attention, the former causes severe semantic-action misalignment, while the latter yields incomplete semantics. In contrast, our method effectively achieves accurate alignment between semantic content and trajectories.",
                "position": 465
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix ADetails on Quantitative Metrics",
        "images": []
    },
    {
        "header": "Appendix BMore Quantitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16924/x7.png",
                "caption": "Figure S1:World-model related capabilities.In these examples, we provided only the trajectories and text describing the ”cause,” and let the model generate the subsequent outcomes. The results demonstrate that ourWorldCanvasexhibits physical plausibility, causal reasoning, and future prediction abilities. We strongly recommend viewing our video results in ourproject page.",
                "position": 753
            },
            {
                "img": "https://arxiv.org/html/2512.16924/x8.png",
                "caption": "Figure S2:Counterfactual generation results.Our model is capable of correctly generating counterfactual events that adhere to physical laws and causal logic. We strongly recommend viewing our video results in ourproject page.",
                "position": 756
            },
            {
                "img": "https://arxiv.org/html/2512.16924/x9.png",
                "caption": "Figure S3:Failure cases.The red boxes highlight the blurring and distortion in case (a) and the insufficient water level rise in case (b), respectively. We strongly recommend viewing our video results in ourproject page.",
                "position": 759
            }
        ]
    },
    {
        "header": "Appendix CWorld-Model Related Capabilities",
        "images": []
    },
    {
        "header": "Appendix DCounterfactual generation",
        "images": []
    },
    {
        "header": "Appendix EFailure cases",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]