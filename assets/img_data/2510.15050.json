[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15050/figures/globe.png",
                "caption": "",
                "position": 61
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15050/x1.png",
                "caption": "Figure 1:DRIFT enables efficient reasoning transfer for MLLMs.Left:Compared with reasoning-oriented training methods, DRIFT achieves comparable performance while requiring dramatically less multimodal SFT data (4K vs.>>59K examples).Right:Simple parameter merging performs poorly on multimodal reasoning benchmarks. Training-based methods improve performance but rely on costly data curation and multi-day training. In contrast, DRIFT reaches competitive results within∼\\sim2 hours of training, making it both data- and compute-efficient.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15050/x2.png",
                "caption": "Figure 2:Layer/Module-wise analysis of model merging pairs.We compare LLaVA-Next-8B vs. Dart-Uniform, Idefics-8B vs. MetaMath, Qwen2-VL-7B vs. Qwen2-Math-7B, and Qwen2.5-VL-7B vs. DeepSeek-R1-Qwen-7B.Top Left: per-layerℒ2\\mathcal{L}_{2}norm differences.Bottom Left: per-layer cosine similarity.Top Right: averageℒ2\\mathcal{L}_{2}norm differences for FFN layers and normalization layers.Bottom Right: averageℒ2\\mathcal{L}_{2}norm differences for attention projections (Q/K/V/O).",
                "position": 245
            },
            {
                "img": "https://arxiv.org/html/2510.15050/x3.png",
                "caption": "Figure 3:Overview of Directional Reasoning Injection (DRIFT).(a) Standard fine-tuning of a multimodal LLMϕV​L\\phi_{VL}, where gradientsggare applied directly to update trainable modules. (b) DRIFT modifies gradients by injecting a reasoning prior:g~=g+α⋅scale​(g,Δ)\\tilde{g}=g+\\alpha\\cdot\\text{scale}(g,\\Delta), whereΔ\\Deltaencodes the reasoning direction andscale​(⋅)\\text{scale}(\\cdot)adjusts howΔ\\Deltainteracts withgg. (c) The reasoning priorΔ\\Deltais constructed as the parameter difference between a text-only reasoning modelϕreason\\phi_{\\text{reason}}and the multimodal variantϕV​L\\phi_{VL}. Our method enables reasoning knowledge to be transferred without destabilizing parameter-space merging.",
                "position": 283
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15050/x4.png",
                "caption": "Figure 4:Qualitative example.DRIFT corrects a failure mode where the model’s visual perception is accurate but the reasoning chain leads to an incorrect answer.",
                "position": 472
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]