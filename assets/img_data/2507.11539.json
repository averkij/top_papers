[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11539/x1.png",
                "caption": "",
                "position": 75
            },
            {
                "img": "https://arxiv.org/html/2507.11539/x2.png",
                "caption": "Figure 2:Inference time comparisonfor the current frame of varying sequence lengths between StreamVGGT and VGGT for the online setting.",
                "position": 84
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Proposed Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11539/x3.png",
                "caption": "Figure 3:Framework of StreamVGGT.Our model consists of three main components: an image encoder, a spatio-temporal decoder, and multi-task prediction heads. During training, we utilize full-sequence inputs to provide the model with complete contextual information. To enforce temporal causality, we apply causal attention so the model can only attend to past frames at any given time step. This design encourages realistic temporal modeling suitable for streaming inference.",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2507.11539/x4.png",
                "caption": "Figure 4:Efficient inference of our model.During streaming inference, we cache the historical keys and values as implicit memory to store information from past frames. This memory allows the model to efficiently reuse previously computed representations, avoiding redundant computation and enabling consistent contextual understanding across time. Our model then processes input incrementally and achieves performance that is comparable to full-sequence inference.",
                "position": 233
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11539/x5.png",
                "caption": "Figure 5:Visualizations. StreamVGGT delivers photorealistic scene reconstructions with superior geometric fidelity, fewer outliers, and sustained accuracy even in complex environments. These advantages arise from our distillation-based training, which lets the streaming model emulate global self-attention behaviour, curbing error accumulation and surpassing traditional causal approaches.",
                "position": 1921
            }
        ]
    },
    {
        "header": "5Conclusion and Discussions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]