[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Hybrid Discrete-Continuous Speech Representations via JEPA with Density Adaptive Attention",
        "images": []
    },
    {
        "header": "2Stage 1: Self-Supervised JEPA Encoder with DAAM",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07168/JEPA.png",
                "caption": "Figure 1:The input waveform is processed by three parallel pathways: (1) an online encoder (trainable, green) that processes the full audio and feeds into a predictor network (yellow) after feature-space masking with a learned mask token, (2) a target encoder (purple) updated via EMA that also processes the full audio to generateùê≥target\\mathbf{z}_{\\text{target}}, and (3) a masking strategy module (blue) that generates binary masks. The MSE loss is computed only on masked regions betweenùê≥predicted\\mathbf{z}_{\\text{predicted}}andùê≥target\\mathbf{z}_{\\text{target}}(stop-gradient), with gradients backpropagating only through the online encoder and predictor. The target encoder provides stable representations without receiving gradients directly(Grill2020BYOL).",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2512.07168/online-encoder.png",
                "caption": "Figure 2:JEPA online encoder architecture. Input waveform passes through an initial Conv1D layer followed by 5 encoder blocks, each containing Conv1D with stride, SnakeBeta activation, residual blocks, and Gaussian Adaptive Attention gating. Features are projected through a bottleneck Conv1D layer and processed by 8 Conformer blocks (each with FNN, multi-head attention with 16 heads, depthwise convolution, and a second FNN) to produce the final representationùê≥\\mathbf{z}. The target encoder shares this architecture but is updated via exponential moving average rather than backpropagation.",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2512.07168/predictor.png",
                "caption": "Figure 3:JEPA predictor network architecture. The predictor takes masked context featuresùê≥masked\\mathbf{z}_{\\text{masked}}and processes them through: (1) an expansion Conv1D layer that doubles the channel dimension, (2) two Conformer blocks separated by an intermediate Conv1D for feature refinement, and (3) a projection Conv1D that reduces back to the original dimensionality, producing predicted featuresùê≥pred\\mathbf{z}_{\\text{pred}}at all positions including masked regions.",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2512.07168/loss.png",
                "caption": "Figure 4:Stage¬†1 JEPA masked prediction loss (MSE) over training steps. JEPA+DAAM (blue) converges faster and to a lower final loss (‚àº0.09\\sim 0.09) compared to JEPA without DAAM (orange,‚àº0.17\\sim 0.17), demonstrating that Density Adaptive Attention enables more efficient representation learning. Both models use identical architectures except for DAAM gating.",
                "position": 895
            }
        ]
    },
    {
        "header": "3Stage 2: Fine-Tuning Encoder + FSQ Quantization + HiFi-GAN Decoder",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07168/hifigan.png",
                "caption": "Figure 5:HiFi-GAN decoder architecture (Stage¬†2). Quantized featuresùê≥q\\mathbf{z}_{q}are upsampled through a bottleneck Conv1D followed by 5 decoder blocks. Each block contains ConvTranspose1D upsampling and MRF residual blocks with different kernel sizes (3, 7, 11, 15, 23, 32) to capture multi-scale temporal patterns. SnakeBeta activations provide periodic inductive bias for high-fidelity audio generation(Ziyin2020Snake).",
                "position": 1408
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Model Architecture and Efficiency",
        "images": []
    },
    {
        "header": "6Evaluation Metrics",
        "images": []
    },
    {
        "header": "7Discussion",
        "images": []
    },
    {
        "header": "8Limitations and Future Work",
        "images": []
    },
    {
        "header": "9Code Availability",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    }
]