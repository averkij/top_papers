[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x1.png",
                "caption": "Figure 1:DynaGuidesteerspretrained diffusion policiesby adding guidance from adynamics modelinto the action denoising process. This dynamics-based guidance can take a diverse behavior base policy and steer it towards one single behavior (left), multiple behaviors (middle), and even removing a behavior (right)â€” all without fine-tuning.",
                "position": 95
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3DynaGuideÂ Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x2.png",
                "caption": "Figure 2:Achieving Dynamics Guidance.(A): DynaGuideÂ combines action denoising gradientsÎµpsubscriptğœ€ğ‘\\varepsilon_{p}italic_Îµ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTfrom the pretrained policy with a guidance gradientâˆ‡atkğsubscriptâˆ‡subscriptsuperscriptğ‘ğ‘˜ğ‘¡ğ\\nabla_{a^{k}_{t}}\\mathbf{d}âˆ‡ start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_dthat increases the likelihood of accomplishing a set of guidance conditionsğ’¢ğ’¢\\mathcal{G}caligraphic_G.(B): Inside the guidance module, a dynamics model predicts future outcomesz^t+Hsubscript^ğ‘§ğ‘¡ğ»\\hat{z}_{t+H}over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t + italic_H end_POSTSUBSCRIPTand compares them to guidance conditionsğ’¢ğ’¢\\mathcal{G}caligraphic_G(desired / undesired outcomes). We use the latent distancesdğ‘‘ditalic_dto define a guidance metricğğ\\mathbf{d}bold_d(Equation2) and take the gradient to get the guidance signalâˆ‡atkğsubscriptâˆ‡subscriptsuperscriptğ‘ğ‘˜ğ‘¡ğ\\nabla_{a^{k}_{t}}\\mathbf{d}âˆ‡ start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_dused by DynaGuide.(C): An example of one denoising step. The pretrained policy seeks behavior modes in the data, while the guidance gradient selects a particular mode.",
                "position": 300
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x3.png",
                "caption": "Figure 3:Experiment Setup. In the CALVIN simulator[30], we propose four experimental setups designed to showcase DynaGuideÂ and its advantages over other steering approaches. First, we test performance with high quality outcome observations as guidance conditions (Fully-Specified Objective). Next, we reduce the guidance condition quality by randomizing robot states and other states not relevant to the target object (Underspecified Objective). Finally, we look at how we can guide the base policy in complex ways, including achieving multiple behaviors and avoiding behaviors (Multiple Objectives).",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x4.png",
                "caption": "Figure 4:Steering Ability and Robustness in the Calvin EnvironmentDynaGuideÂ enhances the target behavior (horizontal axis) significantly across all experiments (Section4.1). The goal conditioning baseline performs very well on a clean fixed articulated setup, but it drops steeply with lower goal quality while DynaGuideÂ remains more robust (Section4.2). For more precise tasks with movable cube objects, the active guidance in DynaGuideÂ outperforms a sampling-based approach with the same dynamics model (Section4.1)",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x5.png",
                "caption": "Figure 5:Multiple Objectives and Underrepresented Behaviors.DynaGuideÂ is able to steer the base policy towards multiple behaviors while minimizing other behaviors and failures (Left). DynaGuideÂ is also able to avoid undesired behaviors by performing other behaviors successfully (Middle). On these complicated objectives and in lower data regimes (right), DynaGuideÂ performs better than sampling approaches.",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x6.png",
                "caption": "Figure 6:Real World ExperimentsOn a cup arrangement task (Left, Center), we show that DynaGuideÂ can guide a pretrained robot policy to express preference over cup color. Using the same policy, we also show that we can create novel mouse-grabbing behavior (Right) by leveraging the additional knowledge inside the trained dynamics model.",
                "position": 542
            }
        ]
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiments, Visualizations, and Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x7.png",
                "caption": "Figure 7:The BlockTouch Environment. This 2D environment requires the agent (black circle) to navigate to a colored target (square). The base policy picks an arbitrary target, and DynaGuideÂ steers it towards a particular color (A). This steering works to express square color preference (B). The dynamics model also enables the base policy to accomplish novel tasks not explicitly trained on the base policy, including picking a target from a tight cluster of squares (C) and navigating past three close cubes to a far target (D). In visualsB - D, the distribution of squares are indicated by the shaded regions. The average square location is represented by the solid square.",
                "position": 1424
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x8.png",
                "caption": "Figure 8:Hyperparameter sweeps and ablations. We look at the impact of inference-time hyperparameters and noise pretraining on final performance. Forguidance strength, we holdÏƒ=40,M=4formulae-sequenceğœ40ğ‘€4\\sigma=40,M=4italic_Ïƒ = 40 , italic_M = 4, whereMğ‘€Mitalic_Mis the number of stochastic sampling steps. ForÏƒğœ\\sigmaitalic_Ïƒparameter, we holds=1.5,M=4formulae-sequenceğ‘ 1.5ğ‘€4s=1.5,M=4italic_s = 1.5 , italic_M = 4wheresğ‘ sitalic_sis guidance strength. ForStochastic Sampling, we holds=3,Ïƒ=40formulae-sequenceğ‘ 3ğœ40s=3,\\sigma=40italic_s = 3 , italic_Ïƒ = 40. We use a highersğ‘ sitalic_sto demonstrate the impact of stochastic sampling on stability. ForGuidance Conditionswe uses=1.5,Ïƒ=40,M=4formulae-sequenceğ‘ 1.5formulae-sequenceğœ40ğ‘€4s=1.5,\\sigma=40,M=4italic_s = 1.5 , italic_Ïƒ = 40 , italic_M = 4.",
                "position": 1446
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x9.png",
                "caption": "Figure 9:Ablating Noise Pretraining. Removing the dynamic modelâ€™s exposure to noised actions greatly decreases its ability to steer the action diffusion process.",
                "position": 1457
            }
        ]
    },
    {
        "header": "Appendix CBroader Impact",
        "images": []
    },
    {
        "header": "Appendix DCode, Assets, and Licenses",
        "images": []
    }
]