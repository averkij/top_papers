[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x1.png",
                "caption": "Figure 1:DynaGuidesteerspretrained diffusion policiesby adding guidance from adynamics modelinto the action denoising process. This dynamics-based guidance can take a diverse behavior base policy and steer it towards one single behavior (left), multiple behaviors (middle), and even removing a behavior (right)— all without fine-tuning.",
                "position": 95
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3DynaGuide Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x2.png",
                "caption": "Figure 2:Achieving Dynamics Guidance.(A): DynaGuide combines action denoising gradientsεpsubscript𝜀𝑝\\varepsilon_{p}italic_ε start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTfrom the pretrained policy with a guidance gradient∇atk𝐝subscript∇subscriptsuperscript𝑎𝑘𝑡𝐝\\nabla_{a^{k}_{t}}\\mathbf{d}∇ start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_dthat increases the likelihood of accomplishing a set of guidance conditions𝒢𝒢\\mathcal{G}caligraphic_G.(B): Inside the guidance module, a dynamics model predicts future outcomesz^t+Hsubscript^𝑧𝑡𝐻\\hat{z}_{t+H}over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t + italic_H end_POSTSUBSCRIPTand compares them to guidance conditions𝒢𝒢\\mathcal{G}caligraphic_G(desired / undesired outcomes). We use the latent distancesd𝑑ditalic_dto define a guidance metric𝐝𝐝\\mathbf{d}bold_d(Equation2) and take the gradient to get the guidance signal∇atk𝐝subscript∇subscriptsuperscript𝑎𝑘𝑡𝐝\\nabla_{a^{k}_{t}}\\mathbf{d}∇ start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_dused by DynaGuide.(C): An example of one denoising step. The pretrained policy seeks behavior modes in the data, while the guidance gradient selects a particular mode.",
                "position": 300
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x3.png",
                "caption": "Figure 3:Experiment Setup. In the CALVIN simulator[30], we propose four experimental setups designed to showcase DynaGuide and its advantages over other steering approaches. First, we test performance with high quality outcome observations as guidance conditions (Fully-Specified Objective). Next, we reduce the guidance condition quality by randomizing robot states and other states not relevant to the target object (Underspecified Objective). Finally, we look at how we can guide the base policy in complex ways, including achieving multiple behaviors and avoiding behaviors (Multiple Objectives).",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x4.png",
                "caption": "Figure 4:Steering Ability and Robustness in the Calvin EnvironmentDynaGuide enhances the target behavior (horizontal axis) significantly across all experiments (Section4.1). The goal conditioning baseline performs very well on a clean fixed articulated setup, but it drops steeply with lower goal quality while DynaGuide remains more robust (Section4.2). For more precise tasks with movable cube objects, the active guidance in DynaGuide outperforms a sampling-based approach with the same dynamics model (Section4.1)",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x5.png",
                "caption": "Figure 5:Multiple Objectives and Underrepresented Behaviors.DynaGuide is able to steer the base policy towards multiple behaviors while minimizing other behaviors and failures (Left). DynaGuide is also able to avoid undesired behaviors by performing other behaviors successfully (Middle). On these complicated objectives and in lower data regimes (right), DynaGuide performs better than sampling approaches.",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x6.png",
                "caption": "Figure 6:Real World ExperimentsOn a cup arrangement task (Left, Center), we show that DynaGuide can guide a pretrained robot policy to express preference over cup color. Using the same policy, we also show that we can create novel mouse-grabbing behavior (Right) by leveraging the additional knowledge inside the trained dynamics model.",
                "position": 542
            }
        ]
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiments, Visualizations, and Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x7.png",
                "caption": "Figure 7:The BlockTouch Environment. This 2D environment requires the agent (black circle) to navigate to a colored target (square). The base policy picks an arbitrary target, and DynaGuide steers it towards a particular color (A). This steering works to express square color preference (B). The dynamics model also enables the base policy to accomplish novel tasks not explicitly trained on the base policy, including picking a target from a tight cluster of squares (C) and navigating past three close cubes to a far target (D). In visualsB - D, the distribution of squares are indicated by the shaded regions. The average square location is represented by the solid square.",
                "position": 1424
            },
            {
                "img": "https://arxiv.org/html/2506.13922/x8.png",
                "caption": "Figure 8:Hyperparameter sweeps and ablations. We look at the impact of inference-time hyperparameters and noise pretraining on final performance. Forguidance strength, we holdσ=40,M=4formulae-sequence𝜎40𝑀4\\sigma=40,M=4italic_σ = 40 , italic_M = 4, whereM𝑀Mitalic_Mis the number of stochastic sampling steps. Forσ𝜎\\sigmaitalic_σparameter, we holds=1.5,M=4formulae-sequence𝑠1.5𝑀4s=1.5,M=4italic_s = 1.5 , italic_M = 4wheres𝑠sitalic_sis guidance strength. ForStochastic Sampling, we holds=3,σ=40formulae-sequence𝑠3𝜎40s=3,\\sigma=40italic_s = 3 , italic_σ = 40. We use a highers𝑠sitalic_sto demonstrate the impact of stochastic sampling on stability. ForGuidance Conditionswe uses=1.5,σ=40,M=4formulae-sequence𝑠1.5formulae-sequence𝜎40𝑀4s=1.5,\\sigma=40,M=4italic_s = 1.5 , italic_σ = 40 , italic_M = 4.",
                "position": 1446
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13922/x9.png",
                "caption": "Figure 9:Ablating Noise Pretraining. Removing the dynamic model’s exposure to noised actions greatly decreases its ability to steer the action diffusion process.",
                "position": 1457
            }
        ]
    },
    {
        "header": "Appendix CBroader Impact",
        "images": []
    },
    {
        "header": "Appendix DCode, Assets, and Licenses",
        "images": []
    }
]