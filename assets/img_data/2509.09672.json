[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09672/x1.png",
                "caption": "Figure 1:Left:\nWe visualize the distribution ofxtx_{t}for two training data pointsx0(1)x_{0}^{(1)}andx0(2)x_{0}^{(2)}as high-probability-density “cones”, as a function of spatial dimensionxxand noise leveltt.\nNote how for a new testing pointx0(test)x_{0}^{(\\text{test})}there exists noise levelt′t^{\\prime}such that noised versions ofxt′(test)x_{t^{\\prime}}^{(\\text{test})}are outside of any of the training “cones” and thus the behavior of the denoiser there is undefined.Middle: We take CIFAR10 test images (top) and add noiseϵt′\\epsilon_{t^{\\prime}}(2nd row).\nWith a single denoising step, a trained diffusion modelfθf_{\\theta}“passes through” most of the coarse structure of the input image, and thus the output image is visually similar to the input (3rd row).\nOptimal denoiserf∗f^{*}instead “teleports” the image to the closest data point in the training dataset (4th row).Right: We compare MSE error of single-step denoising offθf_{\\theta}(Unet) andf∗f^{*}(Optimal). At low noise levels,fθf_{\\theta}removes noise fromxt′(test)x_{t^{\\prime}}^{(\\text{test})}butf∗f^{*}predicts a different image fromx0(test)x_{0}^{(\\text{test})}. At high noise levels, the outputs offθf_{\\theta}andf∗f^{*}are similar.",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x2.png",
                "caption": "Figure 2:Comparison of sensitivity fields of deep denoisers and the projection operators to high-SNR data’s components (eq. Wiener filter) on CIFAR10 dataset. Sensitivity is measured at the center pixel w.r.t.x0x_{0}prediction and throughout a 1000-step DDIM denoising process. Each image is averaged across3232samples and normalized to [0,1].",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x3.png",
                "caption": "Figure 3:Average sensitivity fields of a trained DDPM on the CelebA-HQ dataset. The top row corresponds to an output pixel located near the left eye; the bottom row corresponds to an output pixel near the image center. Left to right: different noise levels corresponding tottof600600,400400,200200.",
                "position": 481
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x4.png",
                "caption": "Figure 4:We slightly manipulate pixels’ correlation across the CIFAR10 dataset such that a desired pattern emerges in the sensitivity of a trained diffusion model.\nIn particular, a DDPM diffusion model trained on the CIFAR10 dataset (sample on the top left) has a coarse-to-fine sensitivity field (top row, noise level decreases from left to right).\nFor each image in the dataset, we edit pixel correlations by adding the desired pattern with random color and weightsγ=0.1\\gamma=0.1(middle row)\nandγ=0.5\\gamma=0.5(bottom row).\nDDPM models trained on those manipulated datasets exhibit the pattern in their sensitivity fields.\nWe underscore the time-steps for whichσt<10​λW\\sigma_{t}<10\\lambda_{W}.\nThis supports our claim that the locality in diffusion models arises not from the inductive bias (i.e., usage of convolutional layers) but from the data statistics.",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x5.png",
                "caption": "Figure 5:Qualitative comparison. In this figure, we compare our analytical model (3rd row) with multiple baselines: Wiener filter (4th row), Kamb and GanguliKamb and Ganguli (2024)analytical model (5th row), Niebola et al.Niedoba et al. (2024b)(6th row).\nAll images are generated with the same initial noise sample with 10 steps of DDIMSong et al. (2020).\nIn the top row, we provide the results of generation with two trained neural networks, NN1 and NN2 – both are instances of the same DDPM UNet(Ho et al.,2020), but trained with different seeds.\nThe distance inTable˜1is measured with respect to NN1.\nWe also provide the nearest image from the dataset for our final generation w.r.t. L2 distance in the last row.",
                "position": 582
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x6.png",
                "caption": "Figure 6:Ablation of the binarization thresholdτ\\tau.",
                "position": 2210
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x7.png",
                "caption": "Figure 7:Samples from trained DDPM U-Nets without (left) and with (right) self-attention layers. The initial random noise is the same for both sets of images.",
                "position": 2217
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x8.png",
                "caption": "Figure 8:Top:sensitivity field of the noise prediction∂ϵ​(x,t)/∂x\\partial\\epsilon(x,t)/\\partial x.Middle:sensitivity field of the image prediction∂x0​(x,t)/∂x\\partial x_{0}(x,t)/\\partial xwith per-image normalization.Bottom:the same field with joint normalization across images.",
                "position": 2291
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x9.png",
                "caption": "Figure 9:Sensitivity fields∂x0​(x,t)/∂x\\partial x_{0}(x,t)/\\partial xfor U-Net (left) and DiT (right).Top two rows:models trained to predict noiseϵ\\epsilon.Bottom two rows:models trained to predict the imagex0x_{0}.\nThe shrinkage observed at high noise in the noise-parameterized models is likely due to numerical instability.",
                "position": 2298
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x10.png",
                "caption": "Figure 10:Sensitivity field of the optimal denoiser.",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x11.png",
                "caption": "Figure 11:Intermediate generation results of a trained DDPM model (rows 1 and 3) and ours (rows 2 and 4). The figure displays single-step estimations ofx0x_{0}from eachxtx_{t}along a sampling trajectory of 10 steps.",
                "position": 2332
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x12.png",
                "caption": "Figure 12:Mean Squared Error (MSE) between the baseline’s predictions and a trained DDPM model. The MSE is calculated onx0x_{0}prediction from eachxtx_{t}point along a 10-step generation trajectory. The results are presented on the CIFAR10 and CelebA-HQ datasets. Mean and standard deviation values were calculated across 128 samples.",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x13.png",
                "caption": "Figure 13:L​2L2distance betweenx0x_{0}prediction and the closest image in the training dataset reported along a 10-step generation trajectory for 5 datasets.",
                "position": 2586
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x14.png",
                "caption": "Figure 14:Additional generation results for all baselines and ours on the CelebA-HQ dataset.",
                "position": 2895
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x15.png",
                "caption": "Figure 15:Additional generation results for all baselines and ours on the AFHQ dataset.",
                "position": 2898
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x16.png",
                "caption": "Figure 16:Additional generation results for all baselines and ours on the CIFAR10 dataset.",
                "position": 2901
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x17.png",
                "caption": "Figure 17:Additional generation results for all baselines and ours on the MNIST dataset.",
                "position": 2904
            },
            {
                "img": "https://arxiv.org/html/2509.09672/x18.png",
                "caption": "Figure 18:Additional generation results for all baselines and ours on the Fashion MNIST dataset.",
                "position": 2907
            }
        ]
    },
    {
        "header": "Part IAppendix",
        "images": []
    }
]