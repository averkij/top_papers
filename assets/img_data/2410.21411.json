[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21411/x1.png",
                "caption": "Figure 1:(a) End-to-end learning-based framework for social relation reasoning. A dedicated neural network is trained end-to-end with full training data. (b) We propose a modular framework with foundation models for social relation reasoning. Our proposed SocialGPT first employs VFMs to extract visual information into textual format,\nand then perform text-based reasoning with LLMs, using either our manually designed SocialPrompt or optimized prompts.",
                "position": 70
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SocialGPT",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21411/x2.png",
                "caption": "Figure 2:The framework of SocialGPT, which follows the “perception with VFMs, reasoning with LLMs” paradigm. SocialGPT converts an image into asocial storyin the perception phase, and then employs LLMs to generate explainable answers in the reasoning phase with SocialPrompt.",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x3.png",
                "caption": "Figure 3:An example of social story generation.",
                "position": 158
            }
        ]
    },
    {
        "header": "4Greedy Segment Prompt Optimization",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21411/x4.png",
                "caption": "Figure 4:Visualization results of interpretability. We show the SocialGPT perception and reasoning process.\nWe see that our model predicts correct social relationships with plausible explanations.",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x5.png",
                "caption": "Figure 5:Results when applying SocialGPT to sketch and cartoon images.\nThe images are generated by GPT-4V. Our method generalizes well on these novel image styles.",
                "position": 615
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21411/x6.png",
                "caption": "Figure 6:The comparisons of the default SAM masks and our SAM masks.",
                "position": 1535
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x7.png",
                "caption": "Figure 7:The prompt used for social story generation. GPT-3.5 Turbo model is used for caption fusion. The system prompt lists some key rules and the user prompt details the task definition.",
                "position": 1542
            }
        ]
    },
    {
        "header": "Appendix BPrompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21411/x8.png",
                "caption": "Figure 8:The SocialPrompt on the PIPA dataset.",
                "position": 1555
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x9.png",
                "caption": "Figure 9:The SocialPrompt on the PISC dataset.",
                "position": 1559
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x10.png",
                "caption": "Figure 10:The prompt after GSPO on the PIPA dataset.",
                "position": 1566
            },
            {
                "img": "https://arxiv.org/html/2410.21411/x11.png",
                "caption": "Figure 11:The prompt after GSPO on the PISC dataset.",
                "position": 1570
            }
        ]
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    }
]