[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.22141/images/2_method/RTL_diagram_v3.png",
                "caption": "Figure 1:Adaptive pruning pipeline. First, the dataset is divided into subsets via predefined clustering. Then we extracts adaptive tickets, i.e. subnetworks, optimized to specific data cluster, and finally we performed network joint retraining.",
                "position": 211
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.22141/images/5_results/cifar_10_and_100_sim_vs_acc.png",
                "caption": "Figure 2:Mask collapse analysis on CIFAR-10 and CIFAR-100. Each subplot corresponds to one class and shows balanced accuracy (solid line) and mask similarity to other subnetworks (dashed line). Plots A-J corresponds to CIFAR-10 network and plots K-S to CIFAR-100.",
                "position": 734
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/5_results/cifar_10_wordnet_vs_masks_iou.png",
                "caption": "Figure 3:Semantic and structural correlation analysis. (A) Spearman’s rank-order correlation between semantic similarity and mask similarity versus pruning ratio across shallow, middle, and deep layers. (B) Correlation across depth for early, middle, and late training stages. (C) Correlation versus pruning ratio for four representative classes:airplane,cat,deer, andtruck. (D) Correlation across depth for the same four classes. (E) WordNet path similarity (top) and RTL mask similarity matrices for shallow (middle) and deep (bottom) layers.",
                "position": 893
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVision Model and Training Setup",
        "images": []
    },
    {
        "header": "Appendix BSemantic Clustering Procedure",
        "images": []
    },
    {
        "header": "Appendix CImplicit Neural Representation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/ade_samples.png",
                "caption": "Figure 4:Data samples from the ADE20K dataset used in the INR experiments, shown together with their corresponding preprocessed semantic segmentation masks.",
                "position": 1733
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/psnr_sim_per_image.png",
                "caption": "Figure 5:Per-image relationship between reconstruction quality and pruning mask similarity in the INR experiment. For each ADE20K image (A–J), PSNR (orange, left axis) and average mask similarity measured by the Jaccard index (blue dashed, right axis) are shown as a function of sparsity.",
                "position": 1916
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/psnr_per_class_img0.png",
                "caption": "Figure 6:Per-class PSNR and subnetwork similarity for a single ADE20K image with four semantic regions. PSNR (solid) and average mask similarity to all other region-specific subnetworks (dashed) are shown as functions of sparsity. Performance degradation coincides with a rapid increase in mask similarity, indicating subnetwork collapse at high pruning ratios.",
                "position": 1935
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/psnr_per_class_img1.png",
                "caption": "Figure 7:Per-class PSNR and subnetwork similarity for a second ADE20K image with fifteen semantic regions. Each subplot (A-O) corresponds to one semantic region. As sparsity increases, PSNR declines gradually until a sharp drop aligns with increasing similarity between region-specific pruning masks, reflecting loss of structural specialization.",
                "position": 1941
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/psnr_per_class_img1_correlation.png",
                "caption": "Figure 8:Correlation between reconstruction quality and subnetwork similarity in INRs.\nPanels A–O show mean-centered PSNR and mean-centered mask similarity for the fifteen-region image. Panel P reports linear regression between the two quantities at 50% sparsity across regions, revealing a strong monotonic relationship (Spearmanρ≈0.982\\rho\\approx 0.982).",
                "position": 1947
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/generated_50.png",
                "caption": "Figure 9:Qualitative INR reconstructions at 50% sparsity. Rows correspond to 10 ADE20K images. Columns show the ground-truth target, RTL reconstruction, and IMP reconstruction. RTL preserves sharper edges and finer details compared to IMP, particularly in textured and semantically complex regions.",
                "position": 1982
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/generated_75.png",
                "caption": "Figure 10:Qualitative INR reconstructions at 75% sparsity. RTL maintains more faithful structure and color consistency, while IMP exhibits increased blurring and loss of high-frequency details. The gap between methods becomes more visible as sparsity increases.",
                "position": 1985
            },
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/generated_90.png",
                "caption": "Figure 11:Qualitative INR reconstructions at 90% sparsity. Under extreme pruning, IMP reconstructions often collapse to coarse approximations with severe artifacts. RTL degrades more gracefully, preserving recognizable object shapes and semantic boundaries across images.",
                "position": 1988
            }
        ]
    },
    {
        "header": "Appendix DSpeech Enhancement",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.22141/images/appendix/SE_spectrograms.png",
                "caption": "Figure 12:Qualitative speech enhancement results at 50% sparsity. Each row corresponds to a different acoustic environment, and columns show the noisy input, clean target, RTL output, and IMP output. RTL more effectively suppresses noise and preserves harmonic speech structure across all environments.",
                "position": 2131
            }
        ]
    },
    {
        "header": "Appendix ESubnetwork Similarity Analysis",
        "images": []
    }
]