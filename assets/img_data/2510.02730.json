[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Daleâ€™s Law and Exponentiated Gradients",
        "images": []
    },
    {
        "header": "3Stochastic Differential Equations and Generative Modelling",
        "images": []
    },
    {
        "header": "4Geometric Brownian Motion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02730/x1.png",
                "caption": "Figure 1:The forward and reverse-time SDEs for Geometric Brownian Motion (GBM). The forward SDE describes the evolution of a clean image sample to a noisy one that eventually becomes log-normally distributed, while the reverse-time SDE captures the dynamics of the process and generates new samples from the unknown density starting from log-normal noise. This is enabled by the knowledge of the unknown density manifesting through the score function.",
                "position": 254
            }
        ]
    },
    {
        "header": "5Multiplicative Score Matching",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02730/x2.png",
                "caption": "Figure 2:Uncurated sample images generated from MNIST, Fashion-MNIST and Kuzushiji MNIST datasets, corresponding to the score model with minimum score-matching loss during training.",
                "position": 455
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Broader Impact",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BLog-normal Distribution",
        "images": []
    },
    {
        "header": "Appendix CEquivalence Between Multiplicative Denoising Score-Matching and Multiplicative Explicit Score-Matching",
        "images": []
    },
    {
        "header": "Appendix DAdditional Experimental Results",
        "images": []
    },
    {
        "header": "Appendix EGenerated Samples",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02730/x3.png",
                "caption": "Figure 3:The samples have high diversity and the model even generates samples that are not present in the training data but have semantic similarity to the training data.",
                "position": 1917
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x4.png",
                "caption": "Figure 4:Generated Kuzushiji samples. The generated samples are sufficiently diverse and sharp and distinct from the training data.",
                "position": 1925
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x5.png",
                "caption": "Figure 5:Generated Fashion MNIST samples. We observe less diversity of the generated samples here compared to MNIST and Kuzushiji MNIST possibly due to the complexity of the training data.",
                "position": 1933
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x6.png",
                "caption": "Figure 6:1010nearest neighbours (calculated using Euclidean distance on raw images) from MNIST training data for samples generated using the proposed model. The last four rows show different instances of the digit88, which are quite diverse. Similarly, the two instances of the digit44generated are visually quite different. These results show that there is enough diversity in the generated samples and no mode collapse whatsoever. This stands testimony to the robustness of the proposed multiplicative denoising score-matching framework.",
                "position": 2013
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x7.png",
                "caption": "Figure 7:1010nearest neighbours (calculated using Euclidean distance on InceptionV3 features) from the training data for samples generated. As mentioned in the caption of Fig.6, there is sufficient diversity in the generated images. The nearest neighbours identified in the InceptionV3 space are not always semantically similar to the generated digit. For example, instances of digits0and66show up in the ten nearest neighbours of digit44.",
                "position": 2016
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x8.png",
                "caption": "Figure 8:1010nearest neighbours (calculated using Euclidean distance on raw images) from the training data for samples generated. Here, again, we observe sufficient diversity of the generated characters and semantic similarity with the top1010nearest neighbours.",
                "position": 2025
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x9.png",
                "caption": "Figure 9:1010nearest neighbours (calculated using Euclidean distance on InceptionV3 features) from the training data for samples generated.",
                "position": 2028
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x10.png",
                "caption": "Figure 10:1010nearest neighbours (calculated using Euclidean distance on raw images) from the training data for samples generated. Compared to MNIST and Kuzushiji MNIST, these samples have less diversity and seem to focus on specific modes (although not collapsing on the mode) in the underlying data distribution.",
                "position": 2036
            },
            {
                "img": "https://arxiv.org/html/2510.02730/x11.png",
                "caption": "Figure 11:1010nearest neighbours (calculated using Euclidean distance on InceptionV3 features) from the training data for samples generated.",
                "position": 2040
            }
        ]
    },
    {
        "header": "Appendix FEvaluation Metrics for the Generated Images",
        "images": []
    }
]