[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/x1.png",
                "caption": "Figure 1:Comparison with state-of-the-art optical flow methods.Left: Quality-memory trade-off on the Spring[mehl2023spring]benchmark. MEMFOF demonstrates superior memory efficiency and the lowest zero-shot error among all methods.Right: GPU memory consumption for 1080p resolution inputs. MEMFOF outperforms state-of-the-art methods such as RPKNet[morimitsu2024recurrent]and StreamFlow[sun2025streamflow]. For more details please see Tab.3.3.\nStreamFlow[sun2025streamflow]is omitted from the left plot due to space constraints.",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2506.23151/x2.png",
                "caption": "Figure 2:Overview of our method and FullHD inference results.Left: Outline of MEMFOF: when operating on videos we cache and reuse results of the feature extraction stage and correlation volume calculation. For each new frame we extract features and run the context network on the frame triplet, which returns the initial flow estimates, context features and hidden (recurrent) state. The flows are recurrently updated for N iterations and finally upsampled to get the final predictions.Right: Comparison of our method (MEMFOF) with StreamFlow[sun2025streamflow]on FullHD images from the DAVIS dataset[perazzi2016benchmark]. Our method correctly captures the tennis ball’s movement while requiring much less memory.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2506.23151/x3.png",
                "caption": "",
                "position": 160
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/x4.png",
                "caption": "Figure 3:Qualitative comparison of MemFlow[dong2024memflow], StreamFlow[sun2025streamflow], SEA-RAFT[wang2025sea], and our method on Spring benchmark[mehl2023spring]crops, colorbar represents endpoint error. Our approach surpasses prior methods and demonstrates that: (1) multi-frame processing enhances temporal coherence, and (2) native Full HD resolution preserves local and global motion details. Crops are sourced from official leaderboard submissions.",
                "position": 192
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/tartan.png",
                "caption": "Table 2:Benchmark comparison of optical flow methods. Results are sourced from official leaderboard of the Spring benchmark, where minus (”-”) indicates the method has no published results. Speed (runtime) and peak GPU memory consumption were measured on a Nvidia RTX 3090 GPU (24 GB) without automatic mixed precision or memory efficient correlation volumes. Lower values are better (↓↓\\downarrow↓) except for WAUC (↑↑\\uparrow↑). The best results are indicated inbold, second-best areunderlined. Method configurations are taken from submissions to the Spring benchmark if present, and from submissions to the Sintel benchmark otherwise.",
                "position": 451
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/tartan.png",
                "caption": "Table 3:Evaluation of our method on the Sintel and KITTI-15 public benchmarks. The Sintel benchmark uses EPE as it’s metric for both splits, while KITTI-15 uses the Fl-all outliers metric.",
                "position": 746
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/tartan.png",
                "caption": "(a)TartanAir",
                "position": 1058
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/tartan.png",
                "caption": "(a)TartanAir",
                "position": 1061
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/things.png",
                "caption": "(b)FlyingThings",
                "position": 1066
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/kitti.png",
                "caption": "(c)KITTI-2015",
                "position": 1072
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/hd1k.png",
                "caption": "(d)HD1K",
                "position": 1077
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/sintel.png",
                "caption": "(e)Sintel",
                "position": 1083
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/spring.png",
                "caption": "(f)Spring",
                "position": 1088
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/prod.png",
                "caption": "(g)Combined at 1×\\times×resolution",
                "position": 1094
            },
            {
                "img": "https://arxiv.org/html/2506.23151/extracted/6578997/prod_2.png",
                "caption": "(h)Combined at 2×\\times×resolution",
                "position": 1099
            }
        ]
    },
    {
        "header": "7Definitions",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/x5.png",
                "caption": "Table 9:Full correlation volume and number of frames ablation table.",
                "position": 1321
            },
            {
                "img": "https://arxiv.org/html/2506.23151/x5.png",
                "caption": "Table 10:Generalization performance of optical flow estimation on Sintel and KITTI-15 after the ”Things” stage. By default, all methods are trained on (FlyingChairs +) FlyingThings3D, additional datasets are listed in the ”Extra data” column.",
                "position": 1514
            }
        ]
    },
    {
        "header": "8Additional ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23151/x5.png",
                "caption": "Figure 5:Qualitative comparison of MemFlow-T, SEA-RAFT (L), and our method on the Sintel benchmark. Sourced from official leaderboard submissions.",
                "position": 1704
            },
            {
                "img": "https://arxiv.org/html/2506.23151/x6.png",
                "caption": "Figure 6:Qualitative comparison of MemFlow-T, SEA-RAFT (L), and our method on the KITTI-2015 benchmark. Sourced from official leaderboard submissions.",
                "position": 1707
            }
        ]
    },
    {
        "header": "9Additional results",
        "images": []
    }
]