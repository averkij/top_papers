[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11919/x1.png",
                "caption": "Figure 1:Comparison of retrieval-augmented generation frameworks. (a) Traditional RAG uses a dense retriever for document matching, while (b) generative RAG relies on constrained DocID generation. Both require feeding retrieved document text into the LLM for answer generation. (c) Our RetroLLM unifies retrieval and generation in a single auto-regressive decoding process, leveraging FM-Index constraints to retrieve fine-grained evidence.",
                "position": 183
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11919/x2.png",
                "caption": "(a)Sequence Relevance",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x2.png",
                "caption": "(a)Sequence Relevance",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x3.png",
                "caption": "(b)Overall Accuracy",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x4.png",
                "caption": "Figure 3:Overview of the RetroLLM Framework, which retrieves fine-grained evidence through a hierarchical, forward-looking FM-Index constrained generation process. During generation, the model autonomously determines whether to generate additional evidence or provide the final answer, based on the sufficiency of the current context.",
                "position": 266
            }
        ]
    },
    {
        "header": "3RetroLLM: Retrieval in Generation",
        "images": []
    },
    {
        "header": "4Experimental Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11919/x5.png",
                "caption": "(a)Parameters vs. Accuracy",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x5.png",
                "caption": "(a)Parameters vs. Accuracy",
                "position": 930
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x6.png",
                "caption": "(b)Parameters vs. F1",
                "position": 935
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x7.png",
                "caption": "(a)Single-hop QA",
                "position": 1158
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x7.png",
                "caption": "(a)Single-hop QA",
                "position": 1161
            },
            {
                "img": "https://arxiv.org/html/2412.11919/x8.png",
                "caption": "(b)Multi-hop QA",
                "position": 1166
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AThe FM-Index",
        "images": []
    },
    {
        "header": "Appendix BFalse Pruning in Constrained Decoding",
        "images": []
    },
    {
        "header": "Appendix CDatasets",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    },
    {
        "header": "Appendix EDetailed Experimental Results",
        "images": []
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]