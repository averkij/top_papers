[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18091/fig/teaser.png",
                "caption": "Figure 1:Adaptive Patch Sizing.We present APT, Adaptive Patch Transformers, which significantly accelerate vision transformer training and inference by patchifying images based on their content. Complex regions receive more, smaller tokens, while simpler, homogeneous regions receive fewer.",
                "position": 97
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18091/fig/apt_system.png",
                "caption": "Figure 2:APT overview.APT works by measuring the entropy at multiple scales and assigning large patch sizes to low entropy patches. All patches are projected to the same size token embedding, and the reduced size input sequence is passed to the transformer.",
                "position": 145
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/zeroconv.png",
                "caption": "Figure 3:Embedding Different Patch Sizes.The smallest size patches are projected with the patch embedding. Larger patches are both split into their sub-patches and resized; the sub-patches are embedded, aggregated with a convolution layer. These are combined with the resized embedding with a zero-initialized MLP(Zhang et al.,2023).",
                "position": 177
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18091/fig/tradeoff_curve_large.png",
                "caption": "(a)Trade-off comparison on ViT-L",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/tradeoff_curve_large.png",
                "caption": "(a)Trade-off comparison on ViT-L",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/tradeoff_curve_huge.png",
                "caption": "(b)Trade-off comparison on ViT-H",
                "position": 523
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/grid_visualization2.jpg",
                "caption": "Figure 5:Visualized Examples.APT consistently places large patches on more homogenous regions and smaller patches on more complex ones. We use conservative thresholds to limit information loss. Images are best viewed zoomed in. More visualizations are in Appendix.",
                "position": 849
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BHardware Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18091/fig/apt_threshold_analysis.png",
                "caption": "Figure 6:Threshold Effect.Increasing the threshold increases throughput significantly, but after approximatelyτ=5.5\\tau=5.5, the accuracy begins to severely drop off, and is not ‘fixable’ with fine-tuning.",
                "position": 2062
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/apt_threshold_analysis.png",
                "caption": "Figure 6:Threshold Effect.Increasing the threshold increases throughput significantly, but after approximatelyτ=5.5\\tau=5.5, the accuracy begins to severely drop off, and is not ‘fixable’ with fine-tuning.",
                "position": 2065
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/tokens_vs_accuracy.png",
                "caption": "Figure 7:Analyzing Scorers.We compare the accuracy on ViT-L/336 for different scorers, controlling for the fraction of retained tokens. We find that the the entropy scorer performs best at high reductions, but that all three are relatively similar.",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/supple_thres.jpeg",
                "caption": "Figure 8:Threshold visualization.We can see that patches containing high-frequency details or salient object features are consistently preserved under various thresholds. We usedτ=5.5\\tau=5.5for most of the experiments. Zoom in for the best view.",
                "position": 2098
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/supple_augmentation.png",
                "caption": "Figure 9:Augmentation visualization.We observe that augmentations generally lead tofewertokens. In particular, Random Erasing(Zhong et al.,2020), leads to regions that can be tokenized with the large patch sizes, significantly increasing throughput compared to inference time.",
                "position": 2102
            },
            {
                "img": "https://arxiv.org/html/2510.18091/fig/scorer_comparison_v4.jpg",
                "caption": "Figure 10:Scorer visualization.The entropy, Laplacian and upsampling scorers follow generally the same patterns with minor variations. The entropy scorer uses larger patches on regions with very few differing colors, while the upsampling and Laplacian scorers consistently use small patches on high-texture regions.",
                "position": 2105
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    }
]