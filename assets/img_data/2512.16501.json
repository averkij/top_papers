[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/x1.png",
                "caption": "Figure 1:Themode performanceof representative GUI grounding models. Notably, model performance on advanced grounding tasks are significantly lower than on basic tasks, highlighting the increased difficulty and reasoning demands of the former.",
                "position": 82
            },
            {
                "img": "https://arxiv.org/html/2512.16501/x2.png",
                "caption": "Figure 2:The overview of VenusBench-GD benchmark.VenusBench-GD integrates basic and advanced grounding tasks to comprehensively evaluation the capabilities of existing GUI models as shown above. Basic tasks assess the ability to recognize local UI elements, while advanced tasks require holistic reasoning over the entire interface and its underlying application functionality, demanding a more complex and global understanding.",
                "position": 85
            },
            {
                "img": "https://arxiv.org/html/2512.16501/x3.png",
                "caption": "Figure 3:Thedomain distributionof our grounding benchmark. VenusBench-GD spans97distinct apps, software, and websites across desktop, mobile, and web platforms, ensuring diverse and comprehensive coverage. We consolidate representations of the same software across platforms into one entry for clarity.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3VenusBench-GD",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/x4.png",
                "caption": "Figure 4:Examples of inaccurate annotations in existing benchmarks.",
                "position": 431
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/x5.png",
                "caption": "Figure 5:Thinking-enabled model makes the correct grounding action with detailed analysis of the whole screenshot.",
                "position": 1156
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Data Privacy",
        "images": []
    },
    {
        "header": "7Dataset Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/x6.png",
                "caption": "Figure 6:The dataset statistics of VenusBench-GD.a) Distribution of image resolution sizes. For clarity in visualization, we report only the top 7 most frequent image resolutions observed in the benchmark; all remaining resolutions are aggregated into the ”Others” category for statistical completeness. b) Distribution of the element size relative to image size. c) Distribution of the instruction length.",
                "position": 1371
            }
        ]
    },
    {
        "header": "8Benchmark Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/icon.png",
                "caption": "Table 9:The 13 UI element types used in our dataset, each accompanied by a representative visualization. Two elements are shown per row for compact presentation with improved spacing and alignment. For visualization, we selected a subset of annotated UI elements and expanded their bounding boxes by 20 pixels outward to enhance visibility.",
                "position": 1510
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/dropdown.png",
                "caption": "",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/button.png",
                "caption": "",
                "position": 1526
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/image.png",
                "caption": "",
                "position": 1528
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/text_tag.png",
                "caption": "",
                "position": 1532
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/text_input.png",
                "caption": "",
                "position": 1534
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/menu.png",
                "caption": "",
                "position": 1538
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/link.png",
                "caption": "",
                "position": 1540
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/slider.png",
                "caption": "",
                "position": 1544
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/notification_dialog.png",
                "caption": "",
                "position": 1546
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/checkbox_radiobox.png",
                "caption": "",
                "position": 1550
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/toggle_switch.png",
                "caption": "",
                "position": 1552
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/elements/tab.png",
                "caption": "",
                "position": 1556
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/ann_vis.png",
                "caption": "Figure 7:Examples of element grounding tasks,illustrating both correct and incorrect matches between generated instructions and their corresponding annotated bounding boxes",
                "position": 1566
            },
            {
                "img": "https://arxiv.org/html/2512.16501/figures/advanced_ann_vis.png",
                "caption": "Figure 8:Examples of advanced grounding tasks.In the refusal grounding task, the red bounding box indicates the original UI element. After modification of the instruction, no matching element exists in the image.",
                "position": 1584
            }
        ]
    },
    {
        "header": "9Experimental Analsysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16501/x7.png",
                "caption": "Figure 9:The model performance comparison of Qwen3-VL-8B-Instruct and Qwen3-VL-8B-Thinking. The reasoning-enhanced thinking model outperforms instruct editions on advanced grounding tasks but lags behind on basic grounding tasks.",
                "position": 1739
            },
            {
                "img": "https://arxiv.org/html/2512.16501/x8.png",
                "caption": "Figure 10:Human performance comparison with current SOTA performance on grounding tasks.",
                "position": 2201
            }
        ]
    },
    {
        "header": "10Error Analaysis",
        "images": []
    },
    {
        "header": "11Human Annotation",
        "images": []
    }
]