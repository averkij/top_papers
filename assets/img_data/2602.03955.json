[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03955/x1.png",
                "caption": "Figure 1:AgentArk distills the reasoning capability of multi-agent systems into one single agent, such that this single unit can imitate the thinking process with boosted performance.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x2.png",
                "caption": "Figure 2:Overview of AgentArk.The pipeline proceeds through three stages: (1)Data Generation Through Multi-Agent Debateto produce diverse reasoning trajectories; (2)Knowledge Extractionto filters for high-quality corrective traces; and (3)Distillationutilizing Standard SFT, Reasoning-enhanced SFT, Distillation with Data Augmentation, and Process-Aware Distillation (PRM + GRPO). The resulting student model achieves optimized, low-latency reasoning that generalizes across diverse task domains.",
                "position": 220
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03955/x3.png",
                "caption": "(a)Performance on in-domain (left) and OOD (right) datasets",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x3.png",
                "caption": "(a)Performance on in-domain (left) and OOD (right) datasets",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x4.png",
                "caption": "(b)Performance by datasets (left) and models (right)",
                "position": 440
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x5.png",
                "caption": "(a)0.6B on test GSM8K",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x5.png",
                "caption": "(a)0.6B on test GSM8K",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x6.png",
                "caption": "(b)8B on test GSM8K",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x7.png",
                "caption": "(a)GSM8K",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x7.png",
                "caption": "(a)GSM8K",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x8.png",
                "caption": "(b)MetaMathQA",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x9.png",
                "caption": "Figure 6:Performance on33open-ended datasets.",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x10.png",
                "caption": "Figure 7:Multimodal distillation on on GSM8K and MedMCQA.(a)Qwen2.5-VL-3B-Instruct distilled from Math,(b)Qwen2.5-VL-3B-Instruct distilled from GSM8K.",
                "position": 706
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Impact Statements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Generation Methods and Pipeline",
        "images": []
    },
    {
        "header": "Appendix BMethods",
        "images": []
    },
    {
        "header": "Appendix CAblation Studies on PAD",
        "images": []
    },
    {
        "header": "Appendix DGeneralization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03955/x11.png",
                "caption": "Figure 8:Scaling behavior of AgentArk vs. base models. Performance comparison on three out-of-distribution (OOD) datasets across the Qwen model family demonstrate the impact of increasing model size (0.60.6B to88B) on generalizability.",
                "position": 2082
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x12.png",
                "caption": "",
                "position": 2085
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x13.png",
                "caption": "Figure 9:Performance of AgentArk and the base models on out-of-domain datasets",
                "position": 2089
            },
            {
                "img": "https://arxiv.org/html/2602.03955/x14.png",
                "caption": "Figure 10:Data scaling behavior on MedMCQA for distillation from Qwen3-32B to Qwen3-0.6B, showing student model performance as a function of the amount of training data.",
                "position": 2099
            }
        ]
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    },
    {
        "header": "Appendix FCombined Distillation Strategies with Two-Step Training",
        "images": []
    },
    {
        "header": "Appendix GDistillation Results",
        "images": []
    }
]