[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x1.png",
                "caption": "Figure 1.3D refinement examples from (a) a degraded real-world scan(Downs et¬†al.,2022)and (c) a state-of-the-art image-to-3D generative model(Xiang et¬†al.,2024). Our method, Elevate3D, effectively refines both texture and geometry while preserving their alignment, as shown in (b) and (d). Inputs for the experiment: the GSO dataset(Downs et¬†al.,2022), and ¬©MasaStojanovic/pixabay.",
                "position": 154
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x2.png",
                "caption": "Figure 2.Overview of HFS-SDEdit.HFS-SDEdit addresses the quality-fidelity trade-off in SDEdit. By adding a substantial amount of noiseœµitalic-œµ\\epsilonitalic_œµto the low-quality reference imagezrsubscriptùëßùëüz_{r}italic_z start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPTin (c) and initiating the denoising process from the noisy latentzthsubscriptùëßsubscriptùë°hz_{t_{\\text{h}}}italic_z start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT h end_POSTSUBSCRIPT end_POSTSUBSCRIPT, SDEdit removes domain information, enabling the diffusion model to generate a high-quality image as depicted in (b). However, this approach compromises fidelity to the reference image. Conversely, adding a small amount of noise and starting the denoising process from the noisy latentztlsubscriptùëßsubscriptùë°lz_{t_{\\text{l}}}italic_z start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT l end_POSTSUBSCRIPT end_POSTSUBSCRIPTpreserves the low-quality domain information, resulting in only minor refinements, as seen in (d). In contrast, HFS-SDEdit incorporates high-frequency feature injection-based guidance, as detailed inSection3, allowing for high-fidelity generation even when starting the denoising process fromzthsubscriptùëßsubscriptùë°hz_{t_{\\text{h}}}italic_z start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT h end_POSTSUBSCRIPT end_POSTSUBSCRIPT. This approach achieves both high quality and high fidelity in the refinement process. Input: ¬©Watts/flickr.",
                "position": 322
            }
        ]
    },
    {
        "header": "3.HFS-SDEdit for Image Refinement",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x3.png",
                "caption": "Figure 3.Framework Overview.Given a low-quality 3D model, Elevate3D alternatingly refines texture and geometry. Input for the experiment: ¬©Momentmal/pixabay.",
                "position": 395
            }
        ]
    },
    {
        "header": "4.Elevate3D",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x4.png",
                "caption": "Figure 4.Texture Refinement.Given a partially-refined texture imageIisubscriptùêºùëñI_{i}italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin (a),\nthe texture refinement stage detects a refinement maskmisubscriptùëöùëñm_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin (b), and produces a refined image in (c) using HFS-SDEdit.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x5.png",
                "caption": "Figure 5.Geometry Refinement.Given a partially refined geometryMisubscriptùëÄùëñM_{i}italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin (a), we obtain a refined surfaceSisubscriptùëÜùëñS_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin (b), and stitch it with the other regions ofMisubscriptùëÄùëñM_{i}italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTshown in (c), resulting in the updated meshM~isubscript~ùëÄùëñ\\tilde{M}_{i}over~ start_ARG italic_M end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTin (d). Input for the experiment: the GSO dataset(Downs et¬†al.,2022)",
                "position": 492
            }
        ]
    },
    {
        "header": "5.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x6.png",
                "caption": "Figure 6.Impact of Low-frequency Component in Diffusion Sampling.The mean radially averaged power spectral density (RAPSD) graphs of different example images shown in (b)-(e) are shown in (a).\nImage (b): ¬©patrick janicek/flickr.",
                "position": 717
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x7.png",
                "caption": "Figure 7.Qualitative Comparison on 2D Image Refinement.The refinement results in (b), (c), (e), and (f) are obtained from the low-quality image in (d), which was degraded from the image in (a). Image (a): ¬©Mathias Appel/flickr.",
                "position": 723
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x8.png",
                "caption": "Figure 8.Effect of Texture and Geometry Refinement Stages.Top: textured meshes, bottom: geometries.\nAll results are rendered using flat shading.\nInput for the experiment: the GSO dataset(Downs et¬†al.,2022)",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x9.png",
                "caption": "Figure 9.Effect of Regularized Normal Integration.(a) Initial geometry.\n(b) Geometry refinement using normal integration w/o regularization.\n(c) Geometry refinement using normal integration w/ regularization (Ours).\nInput for the experiment: the GSO dataset(Downs et¬†al.,2022)",
                "position": 748
            }
        ]
    },
    {
        "header": "6.Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x10.png",
                "caption": "Figure 10.Qualitative Comparison on 3D Refinement.We compare the 3D refinement results from a low-quality degraded input shown in (a). DreamGaussian(Tang et¬†al.,2024b)refines only the texture, leaving the geometry degraded as seen in (b). MagicBoost lacks a fidelity constraint, resulting in large deviations from the input as seen in (c). DiSR-Nerf maintains high fidelity but struggles to generate high-frequency details as seen in (d). In contrast, our method effectively refines both texture and geometry while preserving input fidelity while producing high-quality, well-aligned textures and geometries with high quality as shown in (e). Inputs: the GSO dataset(Downs et¬†al.,2022)",
                "position": 1795
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x11.png",
                "caption": "Figure 11.Qualitative Results on Refining TRELLIS Outputs.Due to the domain gap between synthetic training data and real-world images, TRELLIS often struggles to generate high-quality results from real-world inputs images such as in (a), as shown in (b). Therefore, we apply Elevate3D to refine TRELLIS‚Äôs outputs. As seen in (c), our method produces realistic textures and accurate geometry, resulting in high-quality refinements. Inputs: ¬©mec4411/pixabay, ¬©vimleshtailor/pixabay, ¬©maja7777/pixabay, ¬©jacksonmoccelin/pixabay",
                "position": 1801
            }
        ]
    },
    {
        "header": "Appendix AAdditional Technical Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.11465/x12.png",
                "caption": "Figure S1.Robustness to Normal Prediction Failure.Even when the normal predictor generates poor results, our regularized normal integration successfully preserves the coarse geometry structure, preventing severe distortion.",
                "position": 2734
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x13.png",
                "caption": "Figure S2.Additional Qualitative Comparison on 2D Image Refinement.The refinement results in (c), (d), (e), and (f) are obtained from the low-quality image in (b), which was degraded from the image in (a).",
                "position": 2740
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x14.png",
                "caption": "Figure S3.Additional Qualitative Comparison on 3D RefinementWe show additional 3D refinement comparisons on the degraded GSO dataset. Among all methods, our model produces the highest quality textures with a well-aligned geometry.",
                "position": 2746
            },
            {
                "img": "https://arxiv.org/html/2507.11465/x15.png",
                "caption": "Figure S4.Additional Qualitative Comparison on TRELLIS Outputs.We show additional examples of refining 3D generation results of TRELLIS where it generates the 3d in (b) taking real world input image in (a). As seen in (c), our method produces realistic textures and accurate geometry, resulting in high-quality refinements.",
                "position": 2752
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": []
    }
]