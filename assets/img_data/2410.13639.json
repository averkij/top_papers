[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13639/x1.png",
                "caption": "Figure 1:The statistics of different reasoning patterns on different benchmarks.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x2.png",
                "caption": "Figure 2:The statistics of reasoning patterns.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x3.png",
                "caption": "Figure 3:The statistics of the number of o1‚Äôs reasoning tokens on different tasks. ‚ÄòALL‚Äô represents the average length of reasoning tokens for all samples, while ‚ÄòTrue‚Äô and ‚ÄòFalse‚Äô show the averages for correctly and incorrectly answered samples, respectively. ‚ÄòInput‚Äô refers to the average length of the input prompt.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x4.png",
                "caption": "Figure 4:The results of BoN( GPT-4o) using different reward models underN=4ùëÅ4N=4italic_N = 4setting. The SRG represents the Skywork-Reward-Gemma-2-27B, the URM-LLaMa refers to the URM-LLaMa-3.1-8B.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x4.png",
                "caption": "Figure 4:The results of BoN( GPT-4o) using different reward models underN=4ùëÅ4N=4italic_N = 4setting. The SRG represents the Skywork-Reward-Gemma-2-27B, the URM-LLaMa refers to the URM-LLaMa-3.1-8B.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x5.png",
                "caption": "Figure 5:The results of BoN under different search spaces (i.e. theNùëÅNitalic_Nranging from 1 to 16) on HotpotQA.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x6.png",
                "caption": "Figure 6:The results of o1 model on AIME24, AIME23, and AIME22.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x7.png",
                "caption": "Figure 7:The o1‚Äôs case of HotpotQA.",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x8.png",
                "caption": "Figure 8:The results of the LLMs on the raw bench and the filtered bench. On the left subfigure, we present LLMs‚Äô capabilities on the raw and filtered HotpotQA, and on the right subfigure, we provide the corresponding results on Collie.",
                "position": 630
            }
        ]
    },
    {
        "header": "5Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13639/x9.png",
                "caption": "Figure 9:The o1‚Äôs case of AIME.",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x10.png",
                "caption": "Figure 10:The o1‚Äôs case of Collie.",
                "position": 707
            },
            {
                "img": "https://arxiv.org/html/2410.13639/x11.png",
                "caption": "Figure 11:The o1‚Äôs case of USACO.",
                "position": 718
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]