[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17502/x1.png",
                "caption": "Figure 1:Illustration ofRefVNLI:Given a reference image of a subject, apromptreferring to the subject, and a target image,RefVNLIassesses both subject consistency and textual alignment.\nForsubject consistency, it distinguishes identity-preserving variations, like dew on a flower (top image), from identity-altering changes, such as color change (middle image).\nFortextual alignment, it assesses whether the target image reflects all details from theprompt, such as the fence’s position relative to the flower (bottom image).",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17502/x2.png",
                "caption": "Figure 2:Qualitative Comparison: We compareRefVNLIwith DreamBench++ and CLIP, which score bothSubject Consistency (SC)andTextual Alignment (TA), using examples from theAnimal,Object, andHumancategories. DreamBench++ scores (0-4) are scaled to 0-100 for better readability.RefVNLIdemonstrates superior robustness to identity-agnostic changes (SC), such as the zoomed-out parrot (top-middle) and the zoomed-out man with different attire (bottom-middle). It is also more sensitive to identity-defining attributes, assigning low scores to the altered-faced man (bottom-left) and the balloon with mismatched patterns (middle-left).\nAdditionally,RefVNLIexcels at detecting text-image mismatches (TA), as seen in its penalization of the top-left image for lacking a waterfall.",
                "position": 110
            },
            {
                "img": "https://arxiv.org/html/2504.17502/x3.png",
                "caption": "Figure 3:Generating subject consistency classification training instances from video frames. Given two pairs of frames, each extracted from distinct video scenes featuring the same entity (e.g.,adog), where both frames within each pair depict the same subject (e.g.,the samedog), we construct training {imageref,imagetgt} pairs for subject consistency classification.Positive pairsare formed by pairing a cropped subject from one frame (e.g., dog from left frame in Scene 1) with the full frame from the same scene (right frame in Scene 1). In contrast,negative pairsare created by pairing the cropped subject with the other scene’s full frames (e.g., Scene 2). This process is applied to all four frames, with each taking turns as the cropped reference image (imageref), while the corresponding full-frame counterparts serve asimagetgt, yielding a total of 4 positive and 8 negative training pairs.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Training Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17502/x4.png",
                "caption": "Figure 4:Creating identity-sensitive {imageref,imagetgt} pairs.\nStarting with an image and a mask of a subject (e.g., a briefcase), we randomly keep 5 patches within the masked area ([1]) and use them to create 5 inpainted versions ([2]). The version with the highest MSE between the altered and original areas (e.g., bottom image, MSE = 3983) is paired with theunmodifiedcrop to form anegative pair, while the original image and the same crop create apositive pair, with the crop acting asimagerefin both cases.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2504.17502/x5.png",
                "caption": "Figure 5:Example ofprompt-imagetgtpairs. Given an image with a specific subject (e.g., a dog), we generate apositivepromptby placing a bounding box around the subject and instructing Gemini to describe it (topprompts).Negativepromptsare created by swapping positiveprompts between images of the same entity (middleprompts). For additionalhard negatives, we instruct Gemini to modify a single non-subject detail in the positivepromptwhile keeping the rest unchanged (bottomprompts).",
                "position": 181
            }
        ]
    },
    {
        "header": "3Experimental Settings",
        "images": []
    },
    {
        "header": "4Results",
        "images": []
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17502/x6.png",
                "caption": "Figure 6:ImageRAG Rare Entities Examples:We compareRefVNLIwith CLIP and DreamBench++ in aligning with human preferences (top rows of each example) acrossTextual Alignment (TA),Image Quality (IQ), andOverall Preference (OP).\nDreamBench++ scores (0–4) are rescaled to 0–100 for readability. The higher of the two criterion-wise scores is emphasized unless both are equal.RefVNLIconsistently aligns with human judgments across all three criteria. Notably, in the bottom example, it is the only metric to correctly identify the higher-quality image based onIQ, albeit by a small margin. This case is particularly challenging as it is out-of-distribution forRefVNLI, being that the preferred image is inspired by the reference rather than being of the same identity.",
                "position": 1027
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Reproducibility",
        "images": []
    },
    {
        "header": "9Further Information on the Data Construction Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17502/x7.png",
                "caption": "Figure 8:Qualitative Examples of Subject Preservation Evaluation for theAnimalCategory.DreamBench++ scores (0-4) are scaled to 0-100 for better readability.",
                "position": 2241
            },
            {
                "img": "https://arxiv.org/html/2504.17502/x8.png",
                "caption": "Figure 9:Qualitative Examples of Subject Preservation Evaluation for theHumanCategory.DreamBench++ scores (0-4) are scaled to 0-100 for better readability.",
                "position": 2244
            },
            {
                "img": "https://arxiv.org/html/2504.17502/x9.png",
                "caption": "Figure 10:Qualitative Examples of Subject Preservation Evaluation for theObjectCategory.DreamBench++ scores (0-4) are scaled to 0-100 for better readability.",
                "position": 2247
            },
            {
                "img": "https://arxiv.org/html/2504.17502/x10.png",
                "caption": "Figure 11:Qualitative Examples of Subject Preservation Evaluation for theLandmarkCategory.DreamBench++ scores (0-4) are scaled to 0-100 for better readability.",
                "position": 2250
            }
        ]
    },
    {
        "header": "10Additional Qualitative Examples for Subject Preservation Evaluation",
        "images": []
    }
]