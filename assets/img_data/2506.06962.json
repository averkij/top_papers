[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06962/x1.png",
                "caption": "Figure 1:Comparison between Autoregressive Retrieval Augmentation (AR-RAG) for image generation in (c) and existing image generation paradigms in (a) (b). InAR-RAG, image patches inred boxesdenote retrieval queries and keys, image patches inblue boxesare retrieved values, andgray boxeswith the question mark are next image patches to be predicted. (Caption:A white cat is playing basketball on the court.)",
                "position": 115
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3AR-RAG: Patch-based Autoregressive Retrieval Augmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06962/x2.png",
                "caption": "Figure 2:The decoding process in Distribution-Augmentation in Decoding (DAiD).",
                "position": 215
            },
            {
                "img": "https://arxiv.org/html/2506.06962/x3.png",
                "caption": "Figure 3:Overall architecture of Feature-Augmentation in Decoding (FAiD).",
                "position": 271
            }
        ]
    },
    {
        "header": "4Experiment Setup",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06962/x4.png",
                "caption": "Figure 4:Qualitative results of DAiD, FAiD and baselines.",
                "position": 842
            },
            {
                "img": "https://arxiv.org/html/2506.06962/x5.png",
                "caption": "Figure 5:Images generated by ImageRAGimageragand ourAR-RAG. ImageRAG excessively copies retrieved images and does not follow user prompts.",
                "position": 850
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMulti-Scale Feature Smoothing Algorithm",
        "images": []
    },
    {
        "header": "Appendix BExperiment Setup",
        "images": []
    },
    {
        "header": "Appendix CExperiment Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06962/extracted/6540935/imgs/mean_dist_brokenaxis.png",
                "caption": "Figure 6:l2subscriptùëô2l_{2}italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTdistance between ground-truth tokens and top-10 retrieved tokens (blueline) compared to randomly sampled tokens (reddashed line). The curved arrow indicates a broken y-axis that accommodates the large gap between the retrieved token and the random token baseline.",
                "position": 1756
            },
            {
                "img": "https://arxiv.org/html/2506.06962/extracted/6540935/imgs/combined_fid_heatmaps.png",
                "caption": "Figure 7:Hyperparameter optimization results for DAiD and FAiD on FID scores. Left: FID scores for DAiD across different combinations of retrieval temperatureœÑùúè\\tauitalic_œÑand merging weightŒªùúÜ\\lambdaitalic_Œª. Right: FID scores for FAiD across varying levels of hoph‚Ñéhitalic_hand numbers of blender modulesbùëèbitalic_b. All experiments conducted on the Midjourney-10K benchmark, with optimal configurations highlighted by red borders.",
                "position": 1767
            }
        ]
    },
    {
        "header": "Appendix DLimitations",
        "images": []
    },
    {
        "header": "Appendix EBroader impacts",
        "images": []
    }
]