[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10898/Figures/logo.jpg",
                "caption": "",
                "position": 67
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Automatic rigging",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10898/x1.png",
                "caption": "Figure 1:Overview of our automatic rigging pipeline.Given a 3D mesh, we first sample point clouds with normals, then generate a skeleton using an auto-regressive transformer. The point clouds and skeleton are processed through an attention-based network with four key operations:1bone feature enhancement via topology-aware joint attention,2global context integration through cross-attention with shape latents,3bone-point interaction via cross-attention, and4point feature refinement. Finally, cosine similarity and softmax normalization produce the skinning weights.",
                "position": 172
            }
        ]
    },
    {
        "header": "4Video-guided 3D animation",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10898/x2.png",
                "caption": "Figure 2:Qualitative skeleton generation results. The data is from Articulation-XL2.0, ModelsResource, and the diverse-pose subset from top to bottom.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x3.png",
                "caption": "Figure 3:Comparison of skeleton results on generated meshes.The meshes are generated by Tripo 2.0AI (2023)and Hunyuan3D 2.0Team (2025).",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x4.png",
                "caption": "Figure 4:Qualitative skinning weight prediction results. The data is from Articulation-XL2.0, ModelsResource, and the diverse-pose subset from top to bottom. Each example shows the predicted weight visualization alongside its L1 error map. Additional results are provided in the appendix.",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x5.png",
                "caption": "Figure 5:Comparison of animation results.We present our generated skeletons and corresponding video-guided animations.The shapes with skeletons represent rest poses.While L4GMRen et al. (2024)aligns its reference views closely with the input video, it consistently exhibits distortions (highlighted in red). MotionDreamer’sUzolas et al. (2025)animations are subtle and can introduce unintended deformations in rigid parts (e.g., the humanoid torso). In contrast, our method delivers accurate, artifact-free animations using fully generated rigging. Videos are included in the project page.",
                "position": 545
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMore details of Puppeteer",
        "images": []
    },
    {
        "header": "Appendix BMore details of Articulation-XL2.0",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10898/x6.png",
                "caption": "Figure S6:Bone number distributions of Articulation-XL2.0.",
                "position": 950
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x7.png",
                "caption": "Figure S7:Examples from the diverse-pose subset of Articulation-XL2.0.The left group showcases animation-derived samples: the top row displays the original rest poses, while the bottom row shows their corresponding deformed articulations extracted from animation sequences at frames of maximum pose deviation. The right group displays synthetically generated articulations created using SMALR(Zuffi et al.,2017,2018).",
                "position": 953
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x8.png",
                "caption": "Figure S8:Skeleton structure and joint names of SMALR dataZuffi et al. (2017,2018).",
                "position": 956
            }
        ]
    },
    {
        "header": "Appendix CAdditional experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10898/x9.png",
                "caption": "Figure S9:Comparison of skeleton generation results on test sets.From the top: six examples from Articulation-XL2.0, four from ModelsResource, and four from the diverse-pose subset. Our method produces valid skeletons and even corrects artist-created errors (e.g., missing deer legs in row 1, missing penguin arms in rows 4–5).",
                "position": 969
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x10.png",
                "caption": "Figure S10:Comparison of sequence ordering.Skeletons generated with hierarchical ordering (ours) remain connected, while spatial ordering always yields disconnected structures.",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x11.png",
                "caption": "Figure S11:Comparison of skinning weight prediction results.From the top: three examples from Articulation-XL2.0, two from ModelsResource, and two from the diverse-pose subset.\nEach pair shows the predicted weight visualization alongside its L1 error map. Our predictions more closely match the artist-painted references.",
                "position": 1163
            },
            {
                "img": "https://arxiv.org/html/2508.10898/x12.png",
                "caption": "Figure S12:Comparison of animation results on AI-generated meshes.The meshes are generated by Tripo 2.0AI (2023)and Hunyuan3D 2.0Team (2025).The shapes with skeletons represent the rest poses.",
                "position": 1200
            }
        ]
    },
    {
        "header": "Appendix DDiscussions",
        "images": []
    },
    {
        "header": "Appendix EBroader impact",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]