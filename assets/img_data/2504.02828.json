[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x1.png",
                "caption": "Figure 1:Given a source image and the editing task, our proposed CoLan generates a concept dictionary and performs sparse decomposition in the latent space to precisely transplant the target concept.",
                "position": 76
            }
        ]
    },
    {
        "header": "2Preliminaries in Diffusion-Based Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x2.png",
                "caption": "Figure 2:Representation manipulation in diffusion models involves adding anaccuratemagnitude of edit direction (e.g., Image(3)by CoLan) to the latent source representation. Figure5and Figure7show more examples.",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x3.png",
                "caption": "Figure 3:The CoLan framework. Starting with a source image and prompt, a vision-language model extracts visual concepts (e.g., cat, grass, sitting) to construct a concept dictionary. The source representation is then decomposed along this dictionary, and the target concept (dog) is transplanted to replace the corresponding atom to achieve precise edits. Finally, the image editing backbone generates an edited image where the desired target concept is incorporated without disrupting other visual elements.",
                "position": 172
            }
        ]
    },
    {
        "header": "3Our Method: Concept Lancet",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x4.png",
                "caption": "Figure 4:Samples of the concept stimuli from CoLan-150K. Additional samples are attached in the Appendix ¬ß8.",
                "position": 237
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x5.png",
                "caption": "Figure 5:Visual comparisons of CoLan in the text embedding space of P2P-Zero.Texts in grayare the original captions of the source images from PIE-Bench, andtexts in blueare the corresponding edit task (replace, add, remove).[x]represents the concepts of interest, and[]represents the null concept.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x6.png",
                "caption": "Figure 6:The histograms of solved magnitudes of the concept atoms in CoLan decomposition (text embedding space). As there are tens of concepts in a single dictionary, the histogram includes the concepts whose CoLan coefficients have the top 10 largest magnitudes.",
                "position": 951
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x7.png",
                "caption": "Figure 7:Visual comparisons of CoLan in the score space (first row) and text embedding space (second row) of InfEdit.Texts in grayare the original captions of the source images from PIE-Bench, andtexts in blueare the corresponding edit task (replace, add, remove).",
                "position": 1044
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x8.png",
                "caption": "Figure 8:The histograms of solved magnitudes of the concept atoms in CoLan decomposition (score space). The histogram includes the concepts whose CoLan coefficients have the top 10 largest magnitudes.",
                "position": 1047
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x9.png",
                "caption": "Figure 9:Visualizations of edited images with decreasing strength of the concept[fresh]extracted from our CoLan-150K dataset. The values on top correspond to the coefficientùíòfreshsubscriptùíòfresh{\\boldsymbol{w}}_{\\text{fresh}}bold_italic_w start_POSTSUBSCRIPT fresh end_POSTSUBSCRIPTfor removing the conceptùíÖfreshsubscriptùíÖfresh{\\boldsymbol{d}}_{\\text{fresh}}bold_italic_d start_POSTSUBSCRIPT fresh end_POSTSUBSCRIPT. CoLan solvesùíòfresh‚àósubscriptsuperscriptùíòfresh{\\boldsymbol{w}}^{*}_{\\text{fresh}}bold_italic_w start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT fresh end_POSTSUBSCRIPTof‚àí0.9770.977-0.977- 0.977for the apple and‚àí1.161.16-1.16- 1.16for the lotus.",
                "position": 1159
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x10.png",
                "caption": "Figure 10:Visualizations of edited images with increasing strength of the concept[green]extracted from our CoLan-150K dataset. The values on top correspond to the coefficientùíògreensubscriptùíògreen{\\boldsymbol{w}}_{\\text{green}}bold_italic_w start_POSTSUBSCRIPT green end_POSTSUBSCRIPTfor adding the concept vectorùíÖgreensubscriptùíÖgreen{\\boldsymbol{d}}_{\\text{green}}bold_italic_d start_POSTSUBSCRIPT green end_POSTSUBSCRIPT. CoLan solvesùíògreen‚àósubscriptsuperscriptùíògreen{\\boldsymbol{w}}^{*}_{\\text{green}}bold_italic_w start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT start_POSTSUBSCRIPT green end_POSTSUBSCRIPTof0.5860.5860.5860.586for the apple and0.6950.6950.6950.695for the rose.",
                "position": 1172
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Prior Arts for Diffusion-Based Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x11.png",
                "caption": "Figure 11:Additional visual comparison of CoLan in the text embedding space of P2P-Zero. We observe that the backbone plugging with CoLan has editing results that visually better align with the task.",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2504.02828/x12.png",
                "caption": "Figure 12:Visualizations of editing results. The first row shows the source images, the second row shows the results with the fixed edit strength of0.70.70.70.7for the concept[dog]without CoLan analysis, and the third row shows the edit results with CoLan analysis.",
                "position": 2438
            }
        ]
    },
    {
        "header": "7Framework Details",
        "images": []
    },
    {
        "header": "8Additional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x13.png",
                "caption": "Figure 13:Visualizations of concept grounding for sampled concepts from our CoLan-150K dataset. We observe that the extracted concept vectors from our dataset corresponds to the desired semantics by visualization.",
                "position": 2488
            }
        ]
    },
    {
        "header": "9Limitations, Future Works, Societal Impacts",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02828/x14.png",
                "caption": "Figure 14:Additional samples of the concept stimuli from CoLan-150K. Each concept consists of approximately30303030stimuli and this figure samples the first three for a concept.",
                "position": 2510
            }
        ]
    },
    {
        "header": "10Prompting Template",
        "images": []
    }
]