[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06786/x1.png",
                "caption": "Figure 1:The AI-45∘Law(Yang et al.,2024): coevolving capability with safety.222Figure2ais reproduced from data available athttps://aiben.ch. Figures2band2care adapted from Figure 1 inYang et al. (2024).(a) Empirical distribution of leading foundation models, showing a widening gap between capability scores and safety scores across major labs. (b) Conceptual safety–capability plane comparing the current roadmap (pink) with the yellow, red, and 45∘trajectories toward safe AGI, emphasizing transitions from approximate alignment to reflection. (c) Historical timeline of frontier models, from Transformer(Vaswani et al.,2017)to GPT-5(OpenAI,2025), Claude-4(Anthropic,2025), and Gemini-2.5(Comanici et al.,2025), illustrating the divergence between capability scaling and current alignment methods (e.g.,SFT(Ouyang et al.,2022), RLHF(Christiano et al.,2017), RLAIF(Bai et al.,2022)), and the need for a coevolutionary path to Safe AGI.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Rethinking “Make Safe AI”",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06786/x2.png",
                "caption": "Figure 2:Conceptual contrast between “Make AI Safe” and “Make Safe AI”.",
                "position": 219
            },
            {
                "img": "https://arxiv.org/html/2509.06786/x3.png",
                "caption": "Figure 3:Five levels of “Make Safe AI”, which progressively embed safety as an intrinsic and evolving capability.",
                "position": 237
            }
        ]
    },
    {
        "header": "3Safe-by-Coevolution",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06786/x4.png",
                "caption": "Figure 4:A three-step process for safe-by-coevolution, with aReset-and-Recovermechanism to re-establish verified safety when the system deviates from its safety margin.",
                "position": 308
            }
        ]
    },
    {
        "header": "4R2AI: Realizing Safe-by-Coevolution",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06786/x5.png",
                "caption": "Figure 5:Core components of theR2AIsystem. TheSlow Safe ModelandFast Safe Modelengage in a cooperative game; theAttackerchallenges this fast–slow safety mechanism in an adversarial game; theExternal Environmentcontinuously supplies real-time information; and theVerifierprovides feedback signals to all interactions.",
                "position": 449
            }
        ]
    },
    {
        "header": "5Implications, Applications and Societal Impact",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]