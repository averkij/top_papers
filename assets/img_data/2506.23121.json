[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23121/x1.png",
                "caption": "(a)Segment Anything Model 2 (SAM2)",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x1.png",
                "caption": "(a)Segment Anything Model 2 (SAM2)",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x2.png",
                "caption": "(b)CRISP-SAM2 (Ours)",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x3.png",
                "caption": "(c)The Predicted Masks of SAM2 vs. CRISP-SAM2",
                "position": 173
            }
        ]
    },
    {
        "header": "2.Related Works",
        "images": []
    },
    {
        "header": "3.Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23121/x4.png",
                "caption": "Figure 2.Overall structure of our CRISP-SAM2, which omits the memory attention, memory encoder, and memory bank components lfor clarity. CRISP-SAM2 produces accurate masks of 3D multi-organ segmentation under the guidance of textual information. A two-level progressive cross-modal interaction mechanism is adopted to extract contextualized semantics. Then, the semantics will be injected into image features, generate prompt embedding and further refine masks respectively, promoting superior segmentation prediction with precise local details and boundaries. Here, ”Enc.” represents ”Encoder”.",
                "position": 240
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23121/x5.png",
                "caption": "Figure 3.Visualization demonstrations of CRISP-SAM2 and other counterpart SOTA methods on selected datasets. Rows (a), (b), (d), and (f) show the segmentation results of selected cases in 3D view, while rows (c) and (e) show the predicted masks in 2D imaging slices. The areas enclosed by the dashed black or white boxes showcase some predicted details among different models.",
                "position": 712
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ARelated Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23121/x6.png",
                "caption": "Figure 4.The upper (a) annular chart shows the composition of the training and testing samples, and the lower (b) bar chart illustrates the amount and composition of samples of each organ.",
                "position": 2440
            }
        ]
    },
    {
        "header": "Appendix BDatasets",
        "images": []
    },
    {
        "header": "Appendix CExperimental Settings",
        "images": []
    },
    {
        "header": "Appendix DEvaluation Metrics",
        "images": []
    },
    {
        "header": "Appendix EExperimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23121/x7.png",
                "caption": "Figure 5.Visualizations of texts of various lengths on (a) AbdomenCT-1k(Ma et al.,2021)and (b) AMOS22(Ji et al.,2022)datasets, demonstrating the impacts of textual information.",
                "position": 3177
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x8.png",
                "caption": "Figure 6.Illustrations of representative samples of seven selected sub-datasets in the joint datasets. Each sample includes a 3D imaging and corresponding descriptive texts for each organ to be segmented.",
                "position": 3249
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x9.png",
                "caption": "Figure 7.Box plots for comparing experiments of our CRISP-SAM2 and other SOTA methods including DSC and NSD metrics. For intuitive comparison, a dashed line is added at the median of our method.",
                "position": 3252
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x10.png",
                "caption": "Figure 8.Box plot for the experimental results on DSC and NSD metrics, taking the average values of each organ on the seven selected datasets.",
                "position": 3255
            },
            {
                "img": "https://arxiv.org/html/2506.23121/x11.png",
                "caption": "Figure 9.Visualization details of CT-SAM3D(Guo et al.,2025), CAT(Huang et al.,2025), SegVol(Du et al.,2025), ZePT(Jiang et al.,2024)and our CRISP-SAM2 on MSD-Spleen(Simpson et al.,2019), Pancreas-CT(Clark et al.,2013), AbdomenCT-1k(Ma et al.,2021)and AMOS22(Ji et al.,2022)datasets.",
                "position": 3258
            }
        ]
    },
    {
        "header": "Appendix FLimitations",
        "images": []
    }
]