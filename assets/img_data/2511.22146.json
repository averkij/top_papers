[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22146/x1.png",
                "caption": "Figure 1:Difference between AR, DLM, and C2DLM. AR models struggle to capture global information, and linguistic flexibility is not bound to a strict left-to-right, token-by-token causal order. DLMs discard causal priors entirely. The C2DLM explicitly guides the model to learn causal relations between concepts, capturing the underlying causal priors of natural language generation.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Preliminaries and Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22146/x2.png",
                "caption": "Figure 2:(a) Leveraging the contextual learning capability of a strong model, the causal teacher model uses prompts to automatically extract concept-level information from CoTs and generates causal meta-knowledge links between concepts as supervisory signals. (b) During training, for the internal attention map obtained from CoTs, the V-aware Re-attention mechanism weights the attention maps by the norms of the corresponding Value matrix. (c) The tokenizer maps the textual supervisory signals from step (a) to the weighted attention maps, and a loss-based intervention is applied to guide the C2DLM’s decision-making process.",
                "position": 227
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22146/x3.png",
                "caption": "Figure 3:Normal COT follows the causal topological order of the data-generating process to construct reasoning steps, whereas the Shuffle setting simulates cases where COT exhibits causal misordering.",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2511.22146/x4.png",
                "caption": "Figure 4:Accuracy curve as training progresses in the COT-OrderPerturb task.",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2511.22146/x5.png",
                "caption": "Figure 5:Performance change curve during different\nepochs of training on the STG_H dataset.",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2511.22146/x6.png",
                "caption": "Figure 6:Attention visualization and weight distribution bar charts, where the x-axis represents different attributes in the STG task. Purple indicates causal factors, green denotes spurious correlations, and yellow represents unrelated factors.",
                "position": 765
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical considerations",
        "images": []
    },
    {
        "header": "Appendix ADetails of Prompt",
        "images": []
    },
    {
        "header": "Appendix BDetails of Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix CGeneration Details of COT-OrderPerturb Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22146/DAG.png",
                "caption": "Figure 7:DAG used in data generation process. Yellow nodes are input variables. The Stardust variable is the final answer.",
                "position": 1111
            }
        ]
    },
    {
        "header": "Appendix DCost Analysis of C2DLM",
        "images": []
    },
    {
        "header": "Appendix EAttention Visualization of C2DLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22146/attention.png",
                "caption": "Figure 8:Mask is the position which will be decoded as high or low (directly determines the final answer). Visualization of the attention matrices, presented from top to bottom: direct visualization of LLaDA’s attention map; LLaDA’s attention map weighted by the Value norm; direct visualization of C2DLM’s attention map; and C2DLM’s attention map weighted by the Value norm.",
                "position": 1281
            },
            {
                "img": "https://arxiv.org/html/2511.22146/zhuzhuangtu.png",
                "caption": "Figure 9:Visualization of the weight distribution bar charts, presented from top to bottom: direct visualization of LLaDA’s attention weights bar chart; LLaDA’s attention weights weighted by the Value norm; direct visualization of C2DLM’s attention weights bar chart; and C2DLM’s attention weights weighted by the Value norm.",
                "position": 1284
            }
        ]
    },
    {
        "header": "Appendix FHuman Evaluation of Teacher Model Generated Causal Graphs",
        "images": []
    },
    {
        "header": "Appendix GUse Of AI Assistants",
        "images": []
    }
]