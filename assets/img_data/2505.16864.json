[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x1.png",
                "caption": "Figure 1:Jenga generates high-quality videos with an efficient DiT inference pipeline.(a):Extremely sparse attention can preserve details in generated videos.(b):We minimize token interactions via dynamic sparse attention with a progressive resolution design. We present videos generated by Jenga(sub-sampled 48 frames) among different models, marked with the DiT latency and relative speedup rate. Please useAdobe Acrobat Reader for a live video visualization.",
                "position": 129
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Jenga: Token-Efficient Optimization for Video Diffusion Transformers",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x2.png",
                "caption": "Figure 2:Overview of Jenga.The left partillustrates the attention carving. A 3D video latent is partitioned into local blocks before being passed to the Transformer layers. A block-wise attention is processed to get a head-aware sparse block-selection masks. In each selected block, dense parallel attention is performed.The right partillustrates the Progressive Resolution strategy. The number of tokens and timesteps is compressed to ensure an efficient generation.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x3.png",
                "caption": "Figure 3:Attention Carving (AttenCarve).Here we illustrate a toy example of a4칑4칑44444\\times 4\\times 44 칑 4 칑 4latent, wherem=8洧녴8m=8italic_m = 8latent items form a block.Left:The latent 3D re-ordering and block partition via space filling curves(SFC).Right:After the block-wise attention inEq.3, we can construct the Importance Mask, combined with the pre-computed Condition Mask and Adjacency Mask, a block-wise dense attention mask is passed to the customized kernel for device-efficient attention.",
                "position": 237
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x4.png",
                "caption": "Figure 4:Progressive Resolusion (ProRes).Left:A brief illustration of stage switch and timestep skip. Before the rescale in stages洧맙italic_s, we revert the latent to a clean statex^0ssubscriptsuperscript^洧논洧0\\hat{x}^{s}_{0}over^ start_ARG italic_x end_ARG start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, then re-noise on the upsampled clean latent.Right & Bottom:We add a bias on the video-text attention score, to enable a scalable Field of View (FOV) in low-resolution content generation.",
                "position": 266
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x5.png",
                "caption": "Figure 5:Qualitative comparisons.(a):Jenga maintains strong semantic performance while producing high-quality videos.(b):Examples across multiple Jenga settings, we also demonstrate how the text-amplifier stabilizes Field of View (FOV) across different initial resolutions.",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x6.png",
                "caption": "Figure 6:User study.We report pair-wise preference rates for visual, semantic, and overall quality.",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x7.png",
                "caption": "Figure 7:Qualitative results for ablations.Left:Missing Adjacency Mask洧내adjasubscript洧내adja\\mathbf{B}_{\\text{adja}}bold_B start_POSTSUBSCRIPT adja end_POSTSUBSCRIPTcauses grid effects on block borders.Right:Cutoff probabilityp洧녷pitalic_phelps gain global contexts.",
                "position": 1230
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "AppendixTraining-Free Efficient Video Generation via Dynamic Token Carving",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x8.png",
                "caption": "Figure 8:Overview of the Supplementary.We hope all readers enjoy this work in detail.We summarize common possible questions and important technical points here to arrange the supplementary. We strongly recommend that all readers open the linkhttps://julianjuaner.github.io/projects/jenga/in your browser for video result visualizations.",
                "position": 1271
            }
        ]
    },
    {
        "header": "Appendix AAlgorithmic Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x9.png",
                "caption": "Figure 9:A real block partition example.We adopt a resolution-independent Space-Filling Curve (SFC)[54]to accommodate a wider range of resolutions compared to static 3D partitions. The right portion illustrates the local adjacent blocks using a look-up mask洧내adjasubscript洧내adja\\mathbf{B}_{\\text{adja}}bold_B start_POSTSUBSCRIPT adja end_POSTSUBSCRIPT.",
                "position": 1647
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x10.png",
                "caption": "Figure 10:Multi-GPU adaptation in Jenga.We highlight the computation for each GPU inyellow.",
                "position": 1887
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x11.png",
                "caption": "Figure 11:User study.(a):Questionnaire form example using Google Form.(b):Anonymous video preview website for live comparison.",
                "position": 1944
            }
        ]
    },
    {
        "header": "Appendix CDiscussions and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x12.png",
                "caption": "Figure 12:Some failcases.We present two potential failure cases that may occur when using more stages (S>3洧녡3S>3italic_S > 3), as well as scenarios where this setting is more suitable.",
                "position": 1959
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x13.png",
                "caption": "Figure 13:Attention patterns.Visualization of attention distributions across different layers and timesteps for the first block (at the corner position) containing 128 latent items.",
                "position": 2046
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x14.png",
                "caption": "Figure 14:Dynamic FOV.We demonstrate the impact of the balancing factor픠洧랣\\rhoitalic_픠on field of view in both static and dynamic scenes. Additional ablation examples are presented in the HTML supplement.",
                "position": 2059
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x15.png",
                "caption": "Figure 15:Latency analysis.(a, b)Visual token counts and generation times at different resolutions.(c)Acceleration of AttenCarve vs. FlashAttention2[17].(d)Time breakdown across AttenCarve components.",
                "position": 2066
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16864/x16.png",
                "caption": "Figure 16:Visualization results.From top to bottom, each three videos is from the same setting.",
                "position": 2853
            },
            {
                "img": "https://arxiv.org/html/2505.16864/x17.png",
                "caption": "Figure 17:Visualization results for model adaptations.Prompts are from VBench[35].",
                "position": 2857
            }
        ]
    },
    {
        "header": "Appendix ESocial Impacts",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]