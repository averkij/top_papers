[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/teaser4.jpg",
                "caption": "",
                "position": 143
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/pipeline_full.png",
                "caption": "Figure 2:Overview of our framework. We first train a teacher policy with reinforcement learning (RL) which can access privileged information including ground-truth contacts and impulses, fully observable real-time object point clouds, and noise-free robot joint angles. Then we train a student policy with access only to initial single-view object point clouds and noisy robot joint angles. The student policy is trained with a mixed curriculum learning framework, which initially utilizes imitation learning (IL) for efficient teacher policy distillation, and gradually transitions to RL for exploration to deal with disturbances.\nThe contact and impulse reconstruction loss remains active during the whole student training process.",
                "position": 273
            }
        ]
    },
    {
        "header": "IIIMethod",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/grasp_frame_new.png",
                "caption": "Figure 3:Pre-grasping pose of our method. The finger angles are initialized to get a partially opened hand, while the arm joints are initialized according to the end-effector 6D pose by inverse kinematics. Specifically, the heading directionx(the red arrow) of the hand points to the object point cloud centercfrom a fixed starting point, and the palm directiony(the green arrow) is determined to enclose the objects from a narrow edge while avoiding singularity problems.\nThe hand is then set 25cm away fromcalongx.",
                "position": 311
            }
        ]
    },
    {
        "header": "IVExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/hardware.png",
                "caption": "Figure 4:Hardware setup",
                "position": 489
            },
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/objects5.jpg",
                "caption": "Figure 5:Real objects used for large-scale evaluation",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/printed.jpg",
                "caption": "Figure 6:Objects used for comparisons and ablation",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/adapt4.jpg",
                "caption": "Figure 7:Our method can adapt the poses for stable grasping when unexpected collision occurs due to internal disturbances (a), deal with unobserved object movement (b), and maintain robust grasps when the object slips due to large external forces (c).",
                "position": 762
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    },
    {
        "header": "VILimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05287/extracted/6336385/sections/FIG/spring_obj.png",
                "caption": "Figure 8:Objects used in our comparison experiment with SpringGrasp[5](a) and in their original experiment (b).",
                "position": 1791
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]