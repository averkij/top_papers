[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11579/x1.png",
                "caption": "Figure 1:Vambaachieves strong long video understanding performance (42.1% on LVBench[63]) while being more computationally efficient compared to transformer-based LMMs.",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x1.png",
                "caption": "",
                "position": 112
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x2.png",
                "caption": "",
                "position": 117
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11579/x3.png",
                "caption": "Figure 2:Overview of ourVambamodel architecture. Compared to transformer-based LMMs (left), we replace the costly causal self-attention operations with the more efficient cross-attention layers and Mamba blocks to achieve better efficiency.",
                "position": 183
            }
        ]
    },
    {
        "header": "3Our Method:Vamba",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11579/x4.png",
                "caption": "(a)Training GPU Memory Usage Comparison",
                "position": 929
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x4.png",
                "caption": "(a)Training GPU Memory Usage Comparison",
                "position": 932
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x5.png",
                "caption": "(b)Training Runtime Comparison (time for 1 training step)",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x6.png",
                "caption": "(a)Pre-filling GPU Memory Usage Comparison",
                "position": 956
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x6.png",
                "caption": "(a)Pre-filling GPU Memory Usage Comparison",
                "position": 959
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x7.png",
                "caption": "(b)Pre-filling FLOPs Comparison (measured usingcalflops)",
                "position": 965
            },
            {
                "img": "https://arxiv.org/html/2503.11579/x8.png",
                "caption": "Figure 5:Qualitative comparison betweenVambaand efficient LMM baselines.Red textdenotes incorrect responses, whilegreen texthighlights the correct responses by ourVamba.",
                "position": 979
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Implementation Details",
        "images": []
    },
    {
        "header": "8Model Evaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11579/x9.png",
                "caption": "Figure 6:Additional qualitative results forVamba.",
                "position": 2099
            }
        ]
    },
    {
        "header": "9Additional Qualitative Results",
        "images": []
    }
]