[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07136/x1.png",
                "caption": "Figure 1:Feature rendering time comparison with different GPUs.\nNote that the less advanced GPUs (RTX 3090 and RTX 4090) cannot accommodate the LangSplat model with feature dimensions of 1024 or higher due to running out of memory.",
                "position": 84
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Proposed Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07136/x2.png",
                "caption": "Figure 2:The framework of LangSplatV2. LangSplatV2 introduces a sparse coefficient for each Gaussian point and a shared global codebook for the entire scene.",
                "position": 222
            },
            {
                "img": "https://arxiv.org/html/2507.07136/x3.png",
                "caption": "Figure 3:Our efficient sparse coefficient splatting method accelerates the speed of alpha-blending by utilizing the property of the learned sparse coefficient field and neglecting zero elements.",
                "position": 295
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07136/x4.png",
                "caption": "Figure 4:Qualitative comparisons of open-vocabulary 3D object localization on the LERF dataset. The red points are the model predictions and the black dashed bounding boxes denote the annotations. We observe that LangSplatV2 generates better results than LangSplat.",
                "position": 441
            },
            {
                "img": "https://arxiv.org/html/2507.07136/x5.png",
                "caption": "Figure 5:Qualitative comparisons of open-vocabulary 3D semantic segmentation on the LERF, Mip-NeRF360 and 3D-OVS dataset. We can see that our LangSplatV2 generates better masks than LangSplat, which shows the effectiveness of our LangSplatV2.",
                "position": 698
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BDiscussion",
        "images": []
    },
    {
        "header": "Appendix CMore Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07136/x6.png",
                "caption": "Figure 6:More qualitative comparisons of open-vocabulary 3D object localization on the LERF dataset. The red points are the model predictions and the black dashed bounding boxes denote the annotations. We observe that LangSplatV2 generates better results than LangSplat.",
                "position": 1758
            },
            {
                "img": "https://arxiv.org/html/2507.07136/x7.png",
                "caption": "Figure 7:More qualitative comparisons of open-vocabulary 3D semantic segmentation on the LERF, Mip-NeRF360 and 3D-OVS dataset. We can see that our LangSplatV2 generates better masks than LangSplat, which shows the effectiveness of our LangSplatV2.",
                "position": 1761
            }
        ]
    },
    {
        "header": "Appendix DMore Visualization Results",
        "images": []
    }
]