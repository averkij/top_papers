[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06154/x1.png",
                "caption": "Figure 1:The effect of prompt evolution on the downstream task performance.The shaded regions represent the absolute top-1 classification accuracies for ImageNet(Deng et¬†al.,2009)at each optimization step by ensembling the top-3 prompts found w.r.t the accuracy on the 1-shot train set whereas the solid lines represent the exponential moving average. The left plot is with CLIP VIT-B/32(Radford et¬†al.,2021), and the right is with LLaVa-OV(Li et¬†al.,2024)while the LLM employed is Llama-3(Dubey et¬†al.,2024). Due to high computational cost, we only perform25252525optimization steps for LLaVa-OV.",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x2.png",
                "caption": "",
                "position": 107
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3GLOV: Guided LLMs as Implicit Optimizers for VLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06154/x3.png",
                "caption": "Figure 2:Overview of GLOV. GLOV consists of a Meta Prompt, which constitutes system instruction, task description, and in-context examples (VLM prompts) which are evaluated (and ranked) on a few-shot training data in each iteration. The Meta-Prompt instructs the LLM to generate several candidate solutions in each optimization iteration, conditioned on the in-context examples which are fed in conjunction with the accuracy values, highlighting their effectiveness. Furthermore, to steer the LLM generation towards the language preferred by the VLM, we add the scaled difference of the sentence embeddings (autoregressively) from thepositiveandnegativetext prompts to the intermediate layer of the LLM. This process is repeated until the stopping condition is met (e.g.,maximum iterations). Note, thatH+subscriptùêªH_{+}italic_H start_POSTSUBSCRIPT + end_POSTSUBSCRIPTandH‚àísubscriptùêªH_{-}italic_H start_POSTSUBSCRIPT - end_POSTSUBSCRIPTrefer to the sentence embeddings from the text prompts.",
                "position": 229
            }
        ]
    },
    {
        "header": "4Experimental Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06154/x4.png",
                "caption": "(a)Comparison with ActADD.",
                "position": 732
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x4.png",
                "caption": "(a)Comparison with ActADD.",
                "position": 735
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x5.png",
                "caption": "(b)Adding offset to all tokens.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x6.png",
                "caption": "(c)Guidance with only last token.",
                "position": 745
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x7.png",
                "caption": "(d)Cross attending all tokens.",
                "position": 751
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x8.png",
                "caption": "(e)Cross attending only last token.",
                "position": 756
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x9.png",
                "caption": "(f)Number of tokens for GLOV.",
                "position": 761
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x10.png",
                "caption": "Figure 4:Sweep for choosing the LLM layer for guidance. Linear probing accuracy for different layers of Llama-3, while evaluating our choice of calculating the sentence embeddings for the sentiment classification task in SST-5 dataset (left). Top-1 classification accuracy for ImageNet on the held-out train set while applying the guidance on different layers of Llama-3 (right).",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x11.png",
                "caption": "",
                "position": 878
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AFitness for Encoder-Decoder Models",
        "images": []
    },
    {
        "header": "Appendix BGLOV Prompts",
        "images": []
    },
    {
        "header": "Appendix CMore Shots Help",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06154/x12.png",
                "caption": "Figure 5:Overview of the Meta Prompt.The system prompt is a generic instruction set. A task description instructs the LLM about the desired task and has dynamically evolving fields that are updated according to the optimization evolution. Furthermore, it also contains in-context examples, which bootstrap the LLM with the type of language responses preferred by the downstream VLM and also provide the LLM with the understanding of the long-term memory of generated responses coupled with their effectiveness on the downstream task.",
                "position": 3116
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x13.png",
                "caption": "Figure 6:The effect of prompt evolution on the downstream task performance.The shaded regions represent the absolute top-1 accuracies at each optimization step by ensembling the top-3 prompts found w.r.t the accuracy on the 1-shot train set whereas the solid lines represent the exponential moving average. The VLM employed is CLIP¬†VIT/B-32(Radford et¬†al.,2021)and the LLM is Llama-3(Dubey et¬†al.,2024).",
                "position": 3316
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x14.png",
                "caption": "",
                "position": 3325
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x15.png",
                "caption": "",
                "position": 3331
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x16.png",
                "caption": "",
                "position": 3336
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x17.png",
                "caption": "",
                "position": 3342
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x18.png",
                "caption": "",
                "position": 3347
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x19.png",
                "caption": "",
                "position": 3353
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x20.png",
                "caption": "",
                "position": 3358
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x21.png",
                "caption": "",
                "position": 3364
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x22.png",
                "caption": "",
                "position": 3369
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x23.png",
                "caption": "",
                "position": 3375
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x24.png",
                "caption": "",
                "position": 3380
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x25.png",
                "caption": "Figure 7:Prompt evolution for LLaVa. We provide the highest performing prompt (on the 1-shot train set) discovered by our¬†GLOV at different optimization steps for the ImageNet dataset.",
                "position": 3386
            },
            {
                "img": "https://arxiv.org/html/2410.06154/x26.png",
                "caption": "Figure 8:Prompt evolution for CLIP. We provide the highest performing prompt (on the 1-shot train set) discovered by our¬†GLOV at different optimization steps for the ImageNet dataset.",
                "position": 3389
            }
        ]
    },
    {
        "header": "Appendix DComparison with Few-shot Methods",
        "images": []
    }
]