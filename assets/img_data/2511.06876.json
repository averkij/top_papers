[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/teaser/teaser2.jpeg",
                "caption": "",
                "position": 77
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06876/x1.png",
                "caption": "Figure 2:Workflow.A short caption is expanded by a VLM into a detailed JSON used by FIBO to generate an image. The user can then refine the JSON, and FIBO produces a new image that reflects only the requested changes, demonstrating strong disentanglement between modified and preserved elements.",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/bear/flux.png",
                "caption": "Figure 3:Contextual contradiction.We use prompts from ContraBench[huberman2025image]and Whoops[Bitton_Guetta_2023]. FIBO generates semantically consistent images that faithfully represent the correct relations, unlike other models that often default to typical co-occurrences.",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/bear/hidream.jpg",
                "caption": "",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/bear/qwen.jpg",
                "caption": "",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/bear/bria_new_new.jpg",
                "caption": "",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/woman_dart/flux.png",
                "caption": "",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/woman_dart/hidream.jpg",
                "caption": "",
                "position": 180
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/woman_dart/qwen.jpg",
                "caption": "",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/woman_dart/bria_new_new.jpg",
                "caption": "",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/boxer/flux.jpg",
                "caption": "",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/boxer/hidream.jpg",
                "caption": "",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/boxer/qwen.jpg",
                "caption": "",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/contextual_contradictions/images/boxer/bria_new.jpeg",
                "caption": "",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/flux_shallow.jpg",
                "caption": "Figure 4:Controllability examples.Top:Our model (FIBO) enables precise depth-of-field control, from shallow to deep, whereas FLUX[flux2024]does not consistently produce deep depth of field.Bottom:FIBO allows simultaneous control of facial expressions for multiple subjects within the same scene.",
                "position": 218
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/shallow.jpg",
                "caption": "",
                "position": 228
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/flux_deep.jpg",
                "caption": "",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/deep.jpg",
                "caption": "",
                "position": 230
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/ranch_flux.jpg",
                "caption": "",
                "position": 267
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/control/ranch_ours.jpg",
                "caption": "",
                "position": 268
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/json_1.jpg",
                "caption": "Figure 5:Training with long structured captions vs. short captions.Top:Qualitative comparison (256​X​256256X256resolution). Training with long captions produces more coherent and visually detailed images, showing faster convergence and better alignment.Bottom:Quantitative results on3030K COCO-2014 val images[lin2014microsoft]: long captions yield lower (better) FID.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/json_2.jpg",
                "caption": "",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/json_3.jpg",
                "caption": "",
                "position": 323
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/json_4.jpg",
                "caption": "",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/short_1.jpg",
                "caption": "",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/short_2.jpg",
                "caption": "",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/short_3.jpg",
                "caption": "",
                "position": 332
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/json_vs_short/images/short_4.jpg",
                "caption": "",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_table/1.jpg",
                "caption": "Figure 6:Structured captions encourage disentanglement.Our model allows iterative refinement: altering one attribute in the JSON typically affects only the corresponding visual factor. Starting from the left images, we demonstrate iteratively editing, where the label below describes the requested change in the JSON.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_table/2.jpg",
                "caption": "",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_table/3.jpg",
                "caption": "",
                "position": 366
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_table/4.jpg",
                "caption": "",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_asian_family/1.jpg",
                "caption": "",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_asian_family/2.jpg",
                "caption": "",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_asian_family/3.jpg",
                "caption": "",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_asian_family/4.jpg",
                "caption": "",
                "position": 391
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_water/1.jpg",
                "caption": "",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_water/2.jpg",
                "caption": "",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_water/3.jpg",
                "caption": "",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_water/4.jpg",
                "caption": "",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_knight/1.jpg",
                "caption": "",
                "position": 436
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_knight/2.jpg",
                "caption": "",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_knight/3.jpg",
                "caption": "",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_knight/4.jpg",
                "caption": "",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2511.06876/x2.png",
                "caption": "Figure 7:DimFusion architecture.In each layer, thetext encodingis concatenated with the corresponding LLMhidden statesalong the embedding dimension. The resulting representation is then jointly processed with thenoisy latentsthrough bi-directional mixing in the Dual- and Single-stream blocks. After each block, the appended LLM hidden states are discarded, restoring the original text embedding dimension.",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2511.06876/plots/dimFusionComparison.png",
                "caption": "Figure 8:DimFusion vs. TokenFusionTop:FID on3030K COCO-2014 val images[lin2014microsoft]: both fusion strategies (TokenFusion, DimFusion) substantially outperform T5, withDimFusionachieving the best FID while maintaining lower time per step.Middle:Training loss comparison for T5 (baseline), SmolLM3-3B + TokenFusion, and SmolLM3-3B + DimFusion. Both fusion strategies outperform T5, with DimFusion closely matching TokenFusion.Bottom:Loss difference relative to TokenFusion zoomed in, showing DimFusion converges to a similar value while requiring significantly lower computational cost.",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2511.06876/plots/dimFusionDiff.png",
                "caption": "",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/1.jpg",
                "caption": "Figure 9:Text-as-a-Bottleneck Reconstruction (TaBR).We caption the original image and use the resulting text as a bottleneck input to the generator, producing a reconstructed image. This evaluation allows humans to assess a model’s expressive power objectively without reading extremely long captions. As shown, our model achieves noticeably higher similarity to the original image.",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/1_flux.jpg",
                "caption": "",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/1_qwen.jpg",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/1_bria_new.jpg",
                "caption": "",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/17.jpg",
                "caption": "",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/17_flux.jpg",
                "caption": "",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/17_qwen.jpg",
                "caption": "",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/17_bria.jpg",
                "caption": "",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/22.jpg",
                "caption": "",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/22_flux.jpg",
                "caption": "",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/22_qwen.jpg",
                "caption": "",
                "position": 591
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/22_bria_new.jpg",
                "caption": "",
                "position": 592
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/52.jpg",
                "caption": "",
                "position": 595
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/52_flux.jpg",
                "caption": "",
                "position": 596
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/52_qwen.jpg",
                "caption": "",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/tabr/images/52_1024_1024.jpg",
                "caption": "",
                "position": 598
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "6Ethical Statement",
        "images": []
    },
    {
        "header": "Appendix AStructured Captions",
        "images": []
    },
    {
        "header": "Appendix BAdditional Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06876/x3.png",
                "caption": "Figure 10:Data distribution across categories.People and objects dominate the dataset (39% and 20%, respectively), followed by typography (10%), nature (6%), animals (6%), food (5%), transportation (4%), product (4%), urban scenes (3%), indoors (2%), and logos (1%).",
                "position": 1577
            }
        ]
    },
    {
        "header": "Appendix CAdditional Ablation Studies Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/832x1216/1.jpg",
                "caption": "Figure 11:Additional samples from FIBO in various aspect ratios.",
                "position": 1667
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/832x1216/2.jpg",
                "caption": "",
                "position": 1676
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/832x1216/3.jpg",
                "caption": "",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/832x1216/4.jpg",
                "caption": "",
                "position": 1686
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1024x1024/1.jpg",
                "caption": "",
                "position": 1692
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1024x1024/2.jpg",
                "caption": "",
                "position": 1697
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1024x1024/3.jpg",
                "caption": "",
                "position": 1702
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1024x1024/4.jpg",
                "caption": "",
                "position": 1707
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1152x896/1.jpg",
                "caption": "",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1152x896/2.jpg",
                "caption": "",
                "position": 1718
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1152x896/3.jpg",
                "caption": "",
                "position": 1723
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1152x896/4.jpg",
                "caption": "",
                "position": 1728
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1216x832/1.jpg",
                "caption": "",
                "position": 1734
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1216x832/2.jpg",
                "caption": "",
                "position": 1739
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1216x832/3.jpg",
                "caption": "",
                "position": 1744
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/samples/1216x832/4.jpg",
                "caption": "",
                "position": 1749
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_ski/1.jpg",
                "caption": "Figure 12:Additional refinement examples.",
                "position": 1756
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_ski/2.jpg",
                "caption": "",
                "position": 1760
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_ski/3.jpg",
                "caption": "",
                "position": 1761
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_ski/4.jpg",
                "caption": "",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_owl/1.jpg",
                "caption": "",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_owl/2.jpg",
                "caption": "",
                "position": 1784
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_owl/3.jpg",
                "caption": "",
                "position": 1785
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_owl/4.jpg",
                "caption": "",
                "position": 1786
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_icecream/1.jpg",
                "caption": "",
                "position": 1807
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_icecream/3.jpg",
                "caption": "",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_icecream/2.jpg",
                "caption": "",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_icecream/4.jpg",
                "caption": "",
                "position": 1810
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_cup/1.jpg",
                "caption": "",
                "position": 1831
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_cup/2.jpg",
                "caption": "",
                "position": 1832
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_cup/3.jpg",
                "caption": "",
                "position": 1833
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_cup/4.jpg",
                "caption": "",
                "position": 1834
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_dog/1.jpg",
                "caption": "",
                "position": 1855
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_dog/2.jpg",
                "caption": "",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_dog/3.jpg",
                "caption": "",
                "position": 1857
            },
            {
                "img": "https://arxiv.org/html/2511.06876/Figures/disentanglement/images_dog/4.jpg",
                "caption": "",
                "position": 1858
            }
        ]
    },
    {
        "header": "Appendix DAdditional Samples from FIBO",
        "images": []
    }
]