[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02336/x1.png",
                "caption": "",
                "position": 78
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x2.png",
                "caption": "",
                "position": 132
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02336/x3.png",
                "caption": "Figure 2:The Framework Overview of MVPaint.Given an input mesh, Stage 1 of MVPaint utilizes a synchronized multi-view generation (SMG) model,\nconsisting of a control-based T2MV model and an I2I model,\nfor 3D texture initialization.\nIn Stage 2, the synchronized views are reprojected back to UV space, where inpainting is performed on the 3D point cloud to fill the holes (shown in red dots), hence completing the UV map.\nIn Stage 3, the completed UV map undergoes super-resolution, adding finer details, followed by seam detection and 3D-aware smoothing to achieve a complete, seamless, and multi-view consistent 3D texture.",
                "position": 193
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Our Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02336/x4.png",
                "caption": "Figure 3:The Effectiveness of Synchronization on Multi-view Image Generation.Although T2MV models generate Janus-problem-free results, they still suffer from texture misalignment from different views.\nIn contrast, the proposed SMG model can effectively enforce multi-view consistency for T2MV generation.",
                "position": 252
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x5.png",
                "caption": "Figure 4:Spatial-aware 3D Inpaintingcould effectively accomplish texture completion for 3D structures with complex geometries and large unobserved areas.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x6.png",
                "caption": "Figure 5:Spatial-aware Seam-smoothing Algorithmcould revise texture seams from 2D UV unwrapping by smoothing color vectors using their 3D neighbors.",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x7.png",
                "caption": "Figure 6:Qualitative Results on Text-conditioned 3D Texture Generation.MVPaint could constantly generate high-quality 3D textures, while existing methods frequently provide flawed results.\nNote that the input text prompts are simplified for better presentation.",
                "position": 430
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02336/x8.png",
                "caption": "Figure 7:Ablation Study on SMG Designs.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2411.02336/extracted/5977129/src/unicorn_diversity_v2.jpg",
                "caption": "Figure 8:Diverse Texturing on the Same Model.We use GPT4[1]to generate 38 random texturing prompts without cherry-picking.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x9.png",
                "caption": "Figure 9:Application of MVPaint.Texturing for generated 3D assets from MeshXL[7]and MeshAnything[8,9].",
                "position": 755
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Discussion on Related Works",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02336/x10.png",
                "caption": "Figure S1:High Flexibility in Proposed SMG Design.With two refinement modulesœÑg,œÑtsubscriptùúèùëîsubscriptùúèùë°\\tau_{g},\\tau_{t}italic_œÑ start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT , italic_œÑ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand their corresponding control strengthsg,stsubscriptùë†ùëîsubscriptùë†ùë°s_{g},s_{t}italic_s start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, MVPaint¬†can provide user versatile choices of texture generation. With a larger strength ofstsubscriptùë†ùë°s_{t}italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, the generated results will have more alignment with coarse MV images. With a larger strength ofsgsubscriptùë†ùëîs_{g}italic_s start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT, the generated results will have more creativity (see the ‚ÄòUnicorn‚Äô case) while with a higher risk of Janus problem (see the ‚ÄòBlue Hippo‚Äô case).",
                "position": 1686
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x11.png",
                "caption": "Figure S2:Discussion on UV upscale or tiling.Given groundtruth low-resolution UV map (first row), UV upscalingùíüUPsubscriptùíüUP\\mathcal{D}_{\\text{UP}}caligraphic_D start_POSTSUBSCRIPT UP end_POSTSUBSCRIPTgenerates sharp and clean textures (second row), UV tilingùíüTILEsubscriptùíüTILE\\mathcal{D}_{\\text{TILE}}caligraphic_D start_POSTSUBSCRIPT TILE end_POSTSUBSCRIPTwill add intricate but acceptable details (the left case in the third row) or wrong details (the right case in the third row).",
                "position": 1943
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x12.png",
                "caption": "Figure S3:Illustration of Projection Error.\nWhen the Unprojection Reduction Algorithm is not used, occlusions may cause the color of the occluding object to be projected onto the occluded areas, resulting in artifacts. However, by applying the Unprojection Reduction Algorithm, this issue can be effectively resolved by preventing incorrect color projections onto occluded regions.",
                "position": 1946
            },
            {
                "img": "https://arxiv.org/html/2411.02336/x13.png",
                "caption": "Figure S4:Additional results with border categories.The 3D models are from GSO[16]and Objaverse[12], and the text prompt is abbreviated.",
                "position": 1950
            }
        ]
    },
    {
        "header": "Appendix CDetailed Evaluations",
        "images": []
    },
    {
        "header": "Appendix DAdditional Experiments",
        "images": []
    },
    {
        "header": "Appendix ELimitations",
        "images": []
    }
]