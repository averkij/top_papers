[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21618/x1.png",
                "caption": "Figure 1.Overall performance on (a) general tool usage tasks and (b) downstream applications (best score as 100%).",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2510.21618/x2.png",
                "caption": "Figure 2.Comparison of agent paradigms: (a) Traditional agents with predefined workflows, (b) Deep Research agents that can autonomously call limited tools, and (c) Our DeepAgent, a fully autonomous reasoning agent that dynamically discovers and invokes helpful tools, all within a continuous agentic reasoning process.",
                "position": 150
            },
            {
                "img": "https://arxiv.org/html/2510.21618/x3.png",
                "caption": "Figure 3.Overview of the DeepAgent framework. The main reasoning model autonomously discovers tools, executes actions, and folds previous memory to restart with structured memories, all within a unified thinking process.\nThe DeepAgent is trained end-to-end with ToolPO, an RL method that uses a tool simulator to simulate large-scale real-world tool APIs, and rewards both final task success and correct intermediate tool calls through fine-grained advantage attribution.",
                "position": 197
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Methodology",
        "images": []
    },
    {
        "header": "4.Experimental Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21618/x4.png",
                "caption": "Figure 4.Visualization of training dynamics, including (a) reward scores and (b) validation scores across training steps.",
                "position": 1154
            }
        ]
    },
    {
        "header": "5.Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21618/x5.png",
                "caption": "Figure 5.Scaling analysis of performance with respect to maximum action limits on WebShop and GAIA datasets.",
                "position": 1348
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": []
    },
    {
        "header": "Appendix BBaselines",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DMemory Schema",
        "images": []
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    }
]