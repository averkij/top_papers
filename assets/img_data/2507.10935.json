[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/openfigure.png",
                "caption": "Figure 1:Our GeoDistill encourages the student model to extract discriminative local features from FoV-based masked inputs, resulting in more accurate localization (top right) and reduced uncertainty (bottom right). In contrast, the teacher model (middle), pre-trained on panoramas, lacks explicit enforcement for learning local features, leading to more uncertainty and wrong localization.",
                "position": 100
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/arc.png",
                "caption": "Figure 2:Overview of the proposed GeoDistill for 3-DoF ground-to-satellite relative pose estimation. Given a ground image, we first estimate its orientation with respect to the satellite image (Stage 1). For location estimation (Stage 2), we apply the proposed geometry-guided teacher-student self-distillation (GeoDistill) to a backbone framework, which can be any cross-view localization networks. All components in this pipeline are involved during training, while the green arrows indicate the workflow during inference.",
                "position": 196
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/qualitative_comprision.png",
                "caption": "Figure 3:Qualitative comparison of probability maps before (left) and after (right) applying proposed self-distillation learning paradigm on VIGOR[43]Cross-Area test set. The first row presents input panoramic scenes, while the second row shows the predicted localization heat maps. Red indicates localization probability, with darker shades representing higher probabilities.",
                "position": 359
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/patch_mask.png",
                "caption": "Table 1:Localization performance improvement over different baselines on VIGOR[43]and KITTI test set. Our proposed self distillation learning paradigm consistently improves base modelsâ€™ performance without access to ground truth location labels.",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/patch_mask.png",
                "caption": "Table 3:Performance comparison with different masking strategies on VIGOR[43]Cross-Area test set.",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/patch_mask.png",
                "caption": "(a)Random patch masking",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/patch_mask.png",
                "caption": "(a)Random patch masking",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/activation_mask.png",
                "caption": "(b)Maximum activation masking",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/fov_mask1.png",
                "caption": "(c)FoV-based Masking",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/fov_mask2.png",
                "caption": "",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2507.10935/extracted/6621734/figs/diff_fov.png",
                "caption": "Figure 5:Mean localization error of the student model when trained with different FoVs on VIGOR[43]cross-Area test set.",
                "position": 682
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATeacher-student Parameter Update Strategy",
        "images": []
    },
    {
        "header": "Appendix BDifferent Training Objectives for Self-Distillation",
        "images": []
    },
    {
        "header": "Appendix CComparison with Fully Supervised Methods in VIGOR Same Area Test Set",
        "images": []
    },
    {
        "header": "Appendix DEvaluating GeoDistill with Unlabeled Target Domain Data",
        "images": []
    }
]