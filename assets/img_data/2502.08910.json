[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/",
                "caption": "Figure 1:Overview of InfiniteHiP.(a) Infinitely growing KV cache:In InfiniteHiP, the context keys and values are stored in a unified memory space, where some of the keys and values are loaded on GPU memory.(b) Configurable modular pruning:Each pruning stage narrows down the candidate key indices based on the current query block. During pruning, if a cache miss is encountered, the missing tokens are dynamically loaded and the GPU cache is updated.(c) Paged block sparse attention:The selected key indices are used to perform efficient paged block sparse attention.",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x2.png",
                "caption": "(a)Chunk sparsity.In the given 128K context,Left:A histogram which plots the frequency of chunks (yùë¶yitalic_y) which contain a certain percentage (xùë•xitalic_x) of the top 2048 keys.Right:Percentage of chunks that contain none of the top 2048 keys by varying chunk size (lcsubscriptùëôùëêl_{c}italic_l start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT). We use the Llama 3.1 8B model and extract data from one of the attention layers.",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x2.png",
                "caption": "(a)Chunk sparsity.In the given 128K context,Left:A histogram which plots the frequency of chunks (yùë¶yitalic_y) which contain a certain percentage (xùë•xitalic_x) of the top 2048 keys.Right:Percentage of chunks that contain none of the top 2048 keys by varying chunk size (lcsubscriptùëôùëêl_{c}italic_l start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT). We use the Llama 3.1 8B model and extract data from one of the attention layers.",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x3.png",
                "caption": "",
                "position": 104
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x4.png",
                "caption": "(b)Modular context pruning.We design our context pruning module based on the observation in (a). A single pruning stage is shown above. The keys selected in the previous stage are divided into chunks, and a representative token is selected for each chunk. Each chunk‚Äôs score is estimated from these representative tokens. Finally, the toplc/ksubscriptùëôùëêùëòl_{c}/kitalic_l start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT / italic_kchunks are selected for the next stage.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Motivations and Observations",
        "images": []
    },
    {
        "header": "4Designs of InfiniteHiP",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/x5.png",
                "caption": "",
                "position": 565
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x6.png",
                "caption": "",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x7.png",
                "caption": "",
                "position": 917
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/x8.png",
                "caption": "Figure 5:SGlang Decoding Throughput Benchmark.Dashed lines are estimated values. RTX4090 has 24GB and L40s has 48GB of VRAM. We used is AWQ Llama3.1 with FP8 KV cache.",
                "position": 1692
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x9.png",
                "caption": "",
                "position": 1695
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x10.png",
                "caption": "",
                "position": 1697
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x11.png",
                "caption": "(a)Recall.",
                "position": 1755
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComplete Description of Algorithms",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/x12.png",
                "caption": "Figure 7:Visualization of Stage Caching During Decoding.The visualized mask refresh interval hyperparameternrefresh(1,2,3)=(16,8,4)superscriptsubscriptùëõrefresh1231684n_{\\text{refresh}}^{(1,2,3)}=(16,8,4)italic_n start_POSTSUBSCRIPT refresh end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 , 2 , 3 ) end_POSTSUPERSCRIPT = ( 16 , 8 , 4 )for simplicity.",
                "position": 2720
            }
        ]
    },
    {
        "header": "Appendix BVisualization of RoPE Adjustment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/x13.png",
                "caption": "Figure 8:Visualziation of RoPE Adjustment.",
                "position": 2729
            }
        ]
    },
    {
        "header": "Appendix CVisualization of Each Pruning Stages (Modules)",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_dynamic_0.png",
                "caption": "(a)Dynamic Extend (SelfExtend-style)",
                "position": 2739
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_dynamic_0.png",
                "caption": "(a)Dynamic Extend (SelfExtend-style)",
                "position": 2742
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_dynamic_1.png",
                "caption": "",
                "position": 2745
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_dynamic_2.png",
                "caption": "",
                "position": 2746
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_streaming_0.png",
                "caption": "(b)Chunk-indexed",
                "position": 2752
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_streaming_1.png",
                "caption": "",
                "position": 2755
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_streaming_2.png",
                "caption": "",
                "position": 2756
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_relative_0.png",
                "caption": "(c)Relative",
                "position": 2763
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_relative_1.png",
                "caption": "",
                "position": 2766
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_relative_2.png",
                "caption": "",
                "position": 2767
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_infllm_0.png",
                "caption": "(d)InfLLM",
                "position": 2773
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_infllm_1.png",
                "caption": "",
                "position": 2776
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/rope_infllm_2.png",
                "caption": "",
                "position": 2777
            }
        ]
    },
    {
        "header": "Appendix DDiscussion on Chunk-indexed RoPE",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer1.png",
                "caption": "1",
                "position": 2799
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer1.png",
                "caption": "1",
                "position": 2802
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer2.png",
                "caption": "2",
                "position": 2807
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer3.png",
                "caption": "3",
                "position": 2812
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer4.png",
                "caption": "4",
                "position": 2817
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer5.png",
                "caption": "5",
                "position": 2822
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer6.png",
                "caption": "6",
                "position": 2827
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer7.png",
                "caption": "7",
                "position": 2832
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer8.png",
                "caption": "8",
                "position": 2837
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer9.png",
                "caption": "9",
                "position": 2843
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer10.png",
                "caption": "10",
                "position": 2848
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer11.png",
                "caption": "11",
                "position": 2853
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer12.png",
                "caption": "12",
                "position": 2858
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer13.png",
                "caption": "13",
                "position": 2863
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer14.png",
                "caption": "14",
                "position": 2868
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer15.png",
                "caption": "15",
                "position": 2873
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer16.png",
                "caption": "16",
                "position": 2878
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer17.png",
                "caption": "17",
                "position": 2884
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer18.png",
                "caption": "18",
                "position": 2889
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer19.png",
                "caption": "19",
                "position": 2894
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer20.png",
                "caption": "20",
                "position": 2899
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer21.png",
                "caption": "21",
                "position": 2904
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer22.png",
                "caption": "22",
                "position": 2909
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer23.png",
                "caption": "23",
                "position": 2914
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer24.png",
                "caption": "24",
                "position": 2919
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer25.png",
                "caption": "25",
                "position": 2925
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer26.png",
                "caption": "26",
                "position": 2930
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer27.png",
                "caption": "27",
                "position": 2935
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer28.png",
                "caption": "28",
                "position": 2940
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer29.png",
                "caption": "29",
                "position": 2945
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer30.png",
                "caption": "30",
                "position": 2950
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer31.png",
                "caption": "31",
                "position": 2955
            },
            {
                "img": "https://arxiv.org/html/2502.08910/extracted/6200089/figures/images/layer_mask_example/streaming_layer32.png",
                "caption": "32",
                "position": 2960
            },
            {
                "img": "https://arxiv.org/html/2502.08910/x14.png",
                "caption": "Figure 11:Visualization of Approximating Sliding Window with Block Sparse Attention.(Left) Cropped generated block sparse mask from 13th layer fromFigure10. White pixels mean non-zero entries in the attention matrix, and black pixels mean masked-out pixels. (Right) Illustration of how sliding windows fail to be approximated by block sparse attention.",
                "position": 2970
            }
        ]
    },
    {
        "header": "Appendix EAdditional Experiment Results",
        "images": []
    },
    {
        "header": "Appendix FHyperparameters",
        "images": []
    },
    {
        "header": "Appendix GRemaining Challenges And Future Directions",
        "images": []
    }
]