[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.13142/x1.png",
                "caption": "Figure 1:Overview of ARM4R.We introduce anAuto-regressiveRoboticModel that leverages low-level4DRepresentations (3D point tracks across time) learned from human videos to yield a better pre-trained robotic model.",
                "position": 130
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.13142/x2.png",
                "caption": "Figure 2:ARM4R is trained in three stages.Top Grey Box: The first two stages focus on learning a scene-wide 4D representation by predicting 3D points across time, where Stage 1 pre-trains on a large egocentric human dataset (Epic-Kitchens100), and Stage 2 fine-tunes on a smaller dataset (1-2K demonstrations) of robotic scenes, adapting the point tracking to robotic scene and camera.Bottom Grey Box: Finally, the model is fine-tuned to predict robot proprioceptive states rather than 3D points to enable robotic control.",
                "position": 180
            }
        ]
    },
    {
        "header": "3Auto-regressive Robotic Models",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.13142/x3.png",
                "caption": "Figure 3:Ablation Study for Stages 1 and 2.We train ARM4R on three real tasks in the Kinova setting, ablating Stages 1 and 2. The results indicate that while both stages improve performance, Stage 1 has a more significant impact.",
                "position": 795
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations and Future Work",
        "images": []
    },
    {
        "header": "7Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/supp_human.png",
                "caption": "Figure 4:Visualization of ARM4R’s 3D Point Track results on randomly chosen Epic-Kitchens (in-domain) and Ego-4D (out-of-domain) human videos.",
                "position": 1698
            },
            {
                "img": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/supp_robot.png",
                "caption": "Figure 5:Visualization of ARM4R’s 3D Point Track results on randomly chosen Kinova (in-domain) and Open X-Embodiment (out-of-domain) robot videos.",
                "position": 1701
            }
        ]
    },
    {
        "header": "Appendix BAdditional Dataset Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Implementation Details",
        "images": []
    },
    {
        "header": "Appendix DSimulation on RLBench",
        "images": []
    },
    {
        "header": "Appendix EReal-World Kinova Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/kinova_setup.jpg",
                "caption": "Figure 6:The real-world experiment setup of Kinova robot.",
                "position": 1849
            },
            {
                "img": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/kinova_tasks.jpg",
                "caption": "Figure 7:Task building of real-world Kinova setup.",
                "position": 1868
            },
            {
                "img": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/franka_setup.jpg",
                "caption": "Figure 8:The real-world experiment setup of Franka robot.",
                "position": 1898
            }
        ]
    },
    {
        "header": "Appendix FReal-World Franka Experiments",
        "images": []
    }
]