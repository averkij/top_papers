[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23851/x1.png",
                "caption": "",
                "position": 58
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23851/x2.png",
                "caption": "Figure 2:Pretraining of memory compression models.The memory compression model has to compress long videos (e.g., 20 seconds) into short contexts (e.g., of length 5k). The objective of the pretraining is to retrieve frames with high-frequency details in arbitrary history time positions.",
                "position": 161
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x3.png",
                "caption": "Figure 3:Architecture of memory compression model.We use 3D convolution, SiLU, and attention to establish a lightweight neural structure as the baseline compression model. Different alternative architectures (e.g., various channels, full transformer,etc.) are possible and will be discussed in ablation.",
                "position": 193
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x4.png",
                "caption": "Figure 4:Finetuning autoregressive video models.We illustrate the finetuning and inference of the final autoregressive video models. The pretraining of the memory compression model isfinishedbefore the finetuning.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x5.png",
                "caption": "Figure 5:Visual comparison on compression reconstruction.We present reconstruction results after the pretraining using different possible neural structures and various compression settings.*The “Large Patchifier” is technically equivalent to[zhang2025framepack].",
                "position": 218
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.23851/x6.png",
                "caption": "Figure 6:Influence of memory compression model pretraining.We present results with or without the pretraining of the memory compression model. The input is the same 20-second history video, and we visualize the middle frames in the output shots.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x7.png",
                "caption": "Figure 7:Qualitative results on storyboards.We present results by streaming prompts from storyboards. A storyboard is a set of prompts where each prompt covers a certain number of frames. The storyboards can be written by external language models.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x8.png",
                "caption": "Figure 8:Adding sliding window.We show that the framework can be combined with a small sliding window to facilitate a continuous shot covering multiple generations.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x9.png",
                "caption": "Figure 9:Adding cross-attention enhancing.We show that connecting the compression model and the DiT with cross-attention layers can improve consistency in difficult cases.",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2512.23851/x10.png",
                "caption": "Figure 10:Using multiple memory compression models.We show that using multiple compression models at the same time with different compression patterns,e.g., higher temporal and higher spatial, can facilitate detail consistency in difficult cases, at the cost of doubling the context length.",
                "position": 510
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]