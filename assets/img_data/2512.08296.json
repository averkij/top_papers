[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.08296/x1.png",
                "caption": "Figure 1:Agent Scaling across model intelligence and system architectures.Average performance (%) across four agentic benchmarks improves consistently with increasing modelIntelligence Index(see AppendixA) across three major LLM families (OpenAI, Google, and Anthropic) under different agent configurations. Single Agent System (SAS) serves as reference trajectories, while Multi Agent System (MAS) variants (Centralized, Decentralized, Independent, and Hybrid) reveal distinct scaling behaviors (see Table2for architecture comparisons).\nAll percentage deltas annotated in the figure (e.g., +8.1%, +8.7%, –4.6%) indicate relative performance change of the best-performing MAS variant compared to the SAS baseline at the same Intelligence Index.\nCentralized and hybrid coordination generally yield superior scaling efficiency, suggesting that collaborative agentic structures amplify capability gains more effectively than individual scaling alone.",
                "position": 265
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Agent Systems and Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.08296/x2.png",
                "caption": "Table 2:Architectural comparison of agent methods with objective complexity metrics. Computational complexity measured in terms of LLM calls,\ncoordination overhead, and parallelization potential.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x3.png",
                "caption": "",
                "position": 705
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x4.png",
                "caption": "",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x5.png",
                "caption": "",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x6.png",
                "caption": "",
                "position": 717
            }
        ]
    },
    {
        "header": "4Experiments & Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.08296/x7.png",
                "caption": "Figure 2:Comparative performance of single-agent (SAS) and multi-agent systems (MAS) across four\ndiverse benchmarks reveals highly task-dependent scaling dynamics.Box plots show distribution of success rates (scale: 0 to 1, where 1 represents 100% success). Percentage annotations representrelativeimprovement/degradation compared to SAS baseline:(meanMAS−meanSAS)/meanSAS×100%(\\text{mean}_{\\text{MAS}}-\\text{mean}_{\\text{SAS}})/\\text{mean}_{\\text{SAS}}\\times 100\\%. SAS serves as the reference baseline (shown without percentage annotation).(a)BrowseComp-Plus shows polarized results, with independent agents catastrophically\nunderperforming relative to SAS (-35%) while more structured coordination achieves modest gains.(b)Finance Agent demonstrates the strongest multi-agent benefits, with all MAS architectures\nsubstantially outperforming SAS (from +57 to 81%), suggesting that complex planning and\ndistributed reasoning provide significant advantages in structured economic domains.(c)PlanCraft exhibits consistent degradation across all MAS variants (from -70% to -39%). The core difference from Finance Agent lies in task structure, where Finance Agent tasks decompose into parallelizable subtasks (e.g., separate agents can independently analyze revenue trends, cost structures, and market comparisons, then synthesize findings), whereas PlanCraft requires strictly sequential state-dependent reasoning, each crafting action modifies the inventory state that subsequent actions depend upon.(d)Workbench shows marginal effects (from -11 to +6%), suggesting balanced trade-offs\nbetween problem structure and orchestration costs.\nWhite diamond markers denote per-architecture mean performance.",
                "position": 973
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x8.png",
                "caption": "Figure 3:Cost–Performance Trade-offs Across Model Families and Architectures.Comparative analysis of single-agent (SAS) and multi-agent (MAS) architectures: Independent, Decentralized, Centralized, and Hybrid across three LLM families.\nEach point represents the mean agentic performance (%) versus normalized cost per experiment (USD), with horizontal and vertical error bars denoting Standard Error of Mean (SEM) in cost and performance, respectively.\nNotably, the optimal coordination pattern differs across model families: OpenAI models show consistent gains from Centralized and Hybrid MAS configurations despite higher costs, suggesting stronger communication synergy;\nGoogle models display marginal MAS improvements but a clear efficiency plateau, indicating diminishing returns under lightweight coordination;\nand Anthropic models reveal higher variance and occasional MAS underperformance, reflecting sensitivity to coordination overhead.\nThese cross-family discrepancies imply thatthe efficacy of multi-agent coordination is contingent on each model family’s intrinsic communication bandwidth and reasoning alignment.\nCollectively, the results uncover a family-dependent scaling law linking coordination structure, economic efficiency, and emergent performance.",
                "position": 1099
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x9.png",
                "caption": "Figure 4:Agent Heterogeneity Effects on Multi-Agent Performance.Performance comparison of centralized (Orchestrator-Subagents) and decentralized (Peer Debate with Voting) multi-agent architectures on BrowseComp-Plus benchmark across three LLM families. High-capability models include GPT-5, Claude Sonnet 4.5, and Gemini-2.5 Pro; low-capability models include GPT-5 nano, Claude Sonnet 3.7, and Gemini-2.0 Flash.\n(1) Anthropic models uniquely benefit from heterogeneous mixing in centralized architecture, where low-capability orchestrator with high-capability subagents (0.42) outperforms homogeneous high-capability (0.32) by 31%, while OpenAI and Gemini show performance degradation under heterogeneous centralized configurations.\n(2) Decentralized mixed-capability approaches achieve near-optimal or superior performance compared to homogeneous high-capability baselines (OpenAI: 0.53 vs 0.50; Anthropic: 0.47 vs 0.37; Gemini: 0.42 vs 0.43), suggesting effective emergent collaboration despite capability asymmetry.\n(3) Centralized architectures with low-capability orchestrators underperform dramatically for OpenAI and Gemini families, indicating architectural constraints when coordination relies on less capable models.",
                "position": 1560
            },
            {
                "img": "https://arxiv.org/html/2512.08296/x10.png",
                "caption": "Figure 5:Number of agents scaling reveals model-dependent coordination limits.Performance of Gemini-2.0 Flash (a) and Gemini-2.5 Pro (b) across multi-agent architectures with varying number of agents (na∈{1,3,5,7,9}n_{a}\\in\\{1,3,5,7,9\\}). Both models show initial\ngains from multi-agent coordination, but scaling patterns diverge notably:\nGemini-2.0 Flash exhibits a clear optimum at 7 agents before degradation, while Gemini-2.5 Pro’s decentralized architecture peaks earlier despite its higher single-agent baseline. The centralized architecture demonstrates more stable scaling for Flash but shows diminishing returns for Pro beyond 5 agents. Dashed lines indicate single-agent baseline performance. Results suggest that the optimal number of agents depends on both model capacity and coordination strategy, with coordination overhead eventually outweighing parallelization\nbenefits.",
                "position": 1608
            }
        ]
    },
    {
        "header": "5Limitations and Future Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AModel Intelligence Index",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.08296/imgs/openai-logo.png",
                "caption": "Table 6:Intelligence Index (non-agentic capability) for LLMs used in our experiments.",
                "position": 1692
            },
            {
                "img": "https://arxiv.org/html/2512.08296/imgs/gemini-logo.png",
                "caption": "",
                "position": 1750
            },
            {
                "img": "https://arxiv.org/html/2512.08296/imgs/claude-logo.png",
                "caption": "",
                "position": 1795
            }
        ]
    },
    {
        "header": "Appendix BDomain Complexity",
        "images": []
    },
    {
        "header": "Appendix CDatasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.08296/x11.png",
                "caption": "Figure 6:Benchmark-specific scaling dynamics across LLM families.Performance curves across four benchmarks show best-performing multi-agent variants versus single-agent baselines by Intelligence Index. OpenAI and Google exhibit strong cooperative scaling in structured tasks (Finance Agent:+23.1%+23.1\\%; Workbench:+20.8%+20.8\\%; Cohen’sd>1.2d>1.2). Anthropic models show diminished or negative returns in open-ended environments (PlanCraft:−35.0%-35.0\\%for uncoordinated variants;d≈0.35d\\approx 0.35), where independent reasoning sometimes outperforms coordination. Cross-family variance decomposition (R2=0.89R^{2}=0.89) confirms that intrinsic communication alignment differences drive these divergent patterns.",
                "position": 2093
            }
        ]
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    }
]