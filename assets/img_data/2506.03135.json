[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x1.png",
                "caption": "",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x2.png",
                "caption": "",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x3.png",
                "caption": "",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x4.png",
                "caption": "",
                "position": 139
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x5.png",
                "caption": "Figure 1:Benchmark Statistics of OmniSpatial: The distribution of tasks across 4 main categories.",
                "position": 328
            }
        ]
    },
    {
        "header": "2Preliminaries: Visualâ€“Spatial Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x6.png",
                "caption": "Figure 2:Tasks Demonstration of OmniSpatial. Several representative subtasks are selected for demonstration in each of the four task categories. Note: The questions above are slightly simplified for clarity and conciseness.",
                "position": 381
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x7.png",
                "caption": "Figure 3:Data Construction of OmniSpatial.The pipeline collects images from multiple sources and ensures their quality and relevance through manual selection. Precise annotations are then applied, ensuring each question has a clear, unique answer while maintaining a natural, conversational expression. This process supports the effective training of VLMs in spatial reasoning tasks.",
                "position": 384
            }
        ]
    },
    {
        "header": "3OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x8.png",
                "caption": "Figure 4:PointGraph: Enhance Spatial Reasoning through Additional Scene Graphs.",
                "position": 444
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x8.png",
                "caption": "Figure 4:PointGraph: Enhance Spatial Reasoning through Additional Scene Graphs.",
                "position": 447
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x9.png",
                "caption": "Figure 5:SpatialCoT: Enhancing Spatial Imagination through Novel View Synthesis.",
                "position": 460
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x10.png",
                "caption": "Figure 6:OmniSpatial tasks.The tasks are organized into three levels, with each of the four categories of spatial abilities containing no fewer than two subtasks. The final level features a more detailed subdivision, inspired by real-life scenarios",
                "position": 3744
            }
        ]
    },
    {
        "header": "Appendix ADetailed Task Design",
        "images": []
    },
    {
        "header": "Appendix BAdditional Related Works",
        "images": []
    },
    {
        "header": "Appendix CAdditional Ablation Studies",
        "images": []
    },
    {
        "header": "Appendix DSystem Prompts",
        "images": []
    },
    {
        "header": "Appendix EAdditional Visualization",
        "images": []
    },
    {
        "header": "Appendix FLimitation & Future Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03135/x11.png",
                "caption": "Figure 7:System prompts used in OmniSpatial evaluation.",
                "position": 4606
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x12.png",
                "caption": "Figure 8:System prompts used in OmniSpatial evaluation.",
                "position": 4609
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x13.png",
                "caption": "Figure 9:Visualization example of OmniSpatial data samples.",
                "position": 4612
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x14.png",
                "caption": "Figure 10:Visualization example of OmniSpatial data samples.",
                "position": 4615
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x15.png",
                "caption": "Figure 11:Visualization example of OmniSpatial data samples.",
                "position": 4618
            },
            {
                "img": "https://arxiv.org/html/2506.03135/x16.png",
                "caption": "Figure 12:Visualization example of OmniSpatial data samples.",
                "position": 4621
            }
        ]
    },
    {
        "header": "Appendix GBroader Impacts",
        "images": []
    }
]