[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03450/x1.png",
                "caption": "Figure 1:Similarity-Based Retriever vs.MART. Traditional multimodal retrieval methods (1) depend on calculating weighted sums of image and text embedding similarities, while our approach (2) introduces interactive learning to assess the relevance between the current and expert trajectories.",
                "position": 102
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03450/x2.png",
                "caption": "(a)AI2-THOR",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x2.png",
                "caption": "(a)AI2-THOR",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x3.png",
                "caption": "",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x4.png",
                "caption": "(b)LEGENT",
                "position": 133
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x5.png",
                "caption": "",
                "position": 136
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Interactively Learning Multimodal Retrieval",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03450/x6.png",
                "caption": "Figure 3:Overview ofMART. Our approach interactively learns a multimodal retriever to score expert trajectories and retrieve most effective trajectory to guide an agent in novel situations. By considering trajectories with higher success rates as positive samples and those with lower success rates as negative trajectories, we obtain the preference pairs, which are used to fine-tune an MLLM retriever to score trajectory effectiveness for a specific task.",
                "position": 221
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03450/x7.png",
                "caption": "(a)AI2-THOR",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x7.png",
                "caption": "(a)AI2-THOR",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x7.png",
                "caption": "(a)AI2-THOR",
                "position": 325
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x8.png",
                "caption": "",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x9.png",
                "caption": "(b)LEGENT",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x10.png",
                "caption": "",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x11.png",
                "caption": "Figure 5:Comparison between similarity-based retriever andMART.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x12.png",
                "caption": "Figure 6:Showcase of the significance of the Trajectory Abstraction mechanism.",
                "position": 680
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental setup details",
        "images": []
    },
    {
        "header": "Appendix BAI2-THORÂ environment specifics",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03450/x13.png",
                "caption": "(a)Microwave.",
                "position": 1763
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x13.png",
                "caption": "(a)Microwave.",
                "position": 1766
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x14.png",
                "caption": "(b)Cabinet.",
                "position": 1771
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x15.png",
                "caption": "(c)Sink.",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2410.03450/x16.png",
                "caption": "(d)Coffee machine.",
                "position": 1781
            },
            {
                "img": "https://arxiv.org/html/2410.03450/extracted/5901958/images/legent/where-2room.png",
                "caption": "(a)Where-2room.",
                "position": 1788
            },
            {
                "img": "https://arxiv.org/html/2410.03450/extracted/5901958/images/legent/where-2room.png",
                "caption": "(a)Where-2room.",
                "position": 1791
            },
            {
                "img": "https://arxiv.org/html/2410.03450/extracted/5901958/images/legent/where-1room.png",
                "caption": "(b)Where-1room.",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2410.03450/extracted/5901958/images/legent/come-2room.png",
                "caption": "(c)Come-2room.",
                "position": 1801
            },
            {
                "img": "https://arxiv.org/html/2410.03450/extracted/5901958/images/legent/come-1room.png",
                "caption": "(d)Come-1room.",
                "position": 1806
            }
        ]
    },
    {
        "header": "Appendix CFull step count results",
        "images": []
    },
    {
        "header": "Appendix DAlgorithm",
        "images": []
    },
    {
        "header": "Appendix EAgent prompts",
        "images": []
    }
]