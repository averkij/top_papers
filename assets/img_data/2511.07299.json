[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x1.png",
                "caption": "Figure 1:Concept of VADER.VADER enables detailed anomaly understanding by extracting key visual and relational cues from selected key frames.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x2.png",
                "caption": "Figure 2:Overview of VADER framework.Given an input video, the Anomaly Scorer and Context-AwarE Sampling (CAES) identify keyframes for narrative-driven anomaly analysis. Visual and relational features are extracted and encoded, with dynamic relational patterns distilled by the COntrastive Relation Encoder (CORE). All cues are fused by a pretrained LLM for comprehensive video anomaly understanding. The right panel illustrates the relational branch, including temporal association, volatility mining, and contrastive token learning.",
                "position": 184
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x3.png",
                "caption": "Figure 4:Qualitative results of VADER’s causal reasoning capabilities.Given a video depicting a nighttime break-in, VADER generates detailed, context-aware answers for a sequence of causal reasoning queries, capturing both the key actions and underlying cause-effect chains within the event.",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2511.07299/x4.png",
                "caption": "Figure 5:Three examples of the task of describing anonymous videos are depicted here. The descriptions generated by Otter[20]and Video-ChatGPT[36]contain hallucination or incorrect analysis. In contrast, VADER produces concise, contextually grounded, and causally coherent descriptions that accurately reflect the events and their underlying dynamics across various challenging cases.",
                "position": 1372
            }
        ]
    },
    {
        "header": "5Limitation",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Supplementary Material",
        "images": []
    },
    {
        "header": "Appendix AIllustrative Example of Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x5.png",
                "caption": "Figure 6:Illustrative example showing the need for causal and relational modeling.Given the same video of a dog attacking a boy, CUVA[11]and Holmes-VAU[67]produce incorrect or incomplete descriptions, while VADER captures key interactions and event progression, resulting in accurate and coherent descriptions with higher human-aligned evaluation scores.",
                "position": 2406
            }
        ]
    },
    {
        "header": "Appendix BAblation Study on Sample Mining Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix CFailure Cases",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x6.png",
                "caption": "Figure 7:Examples illustrating VADER’s high-motion bias.VADER tends to focus on visually prominent or dynamic actions, overlooking subtle or context-dependent cues. In the left example, it emphasizes pouring water while ignoring the public smoking. In the middle example, it identifies the car collision but misses the underlying cause, which is the vehicle running the traffic signal. In the right example, it overemphasizes the physical confrontation while neglecting the initial theft that triggered the anomaly.",
                "position": 2471
            },
            {
                "img": "https://arxiv.org/html/2511.07299/x7.png",
                "caption": "Figure 8:Examples illustrating VADER’s limitation to object-centric reasoning.VADER focuses on localized pairwise interactions, overlooking group behaviors or scene-level environmental factors. In the left example, it describes individual pedestrian movements but misses the crowd gathered to watch a performance. In the middle example, it identifies the ship’s movement but overlooks the collective panic it causes. In the right example, it focuses on the police officer and the crowd but ignores the environmental cause behind the stranded people.",
                "position": 2474
            }
        ]
    },
    {
        "header": "Appendix DPotential Mitigations for Limitations",
        "images": []
    },
    {
        "header": "Appendix EComputational Efficiency",
        "images": []
    },
    {
        "header": "Appendix FIntermediate Visualization of Module Contributions",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07299/x8.png",
                "caption": "Figure 9:Intermediate visualizationshowing how CAES and CORE improve descriptions. CAES helps focus on key frames, while CORE models object interactions for more interpretable outputs.",
                "position": 2571
            }
        ]
    },
    {
        "header": "Appendix GImplementation Details",
        "images": []
    }
]