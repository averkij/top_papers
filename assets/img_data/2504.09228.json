[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09228/extracted/6356223/images/fig_prec_fps.png",
                "caption": "Figure 1:Compared to SOTA UAV trackers on UAVDT, our ORTrack-DeiT sets a new record with 83.4% precision and a speed of 236 FPS. Our ORTrack-D-DeiT strikes a better trade-off with 82.5% precision and a speed of about 313 FPS.",
                "position": 76
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09228/extracted/6356223/images/CVPR25_overview.png",
                "caption": "Figure 2:Overview of the proposed ORTrack framework, which includes separate training pipelines for a teacher and a student model. Note that the spatial Cox process-based masking and occlusion-robust representation learning are applied only in the teacher pipeline. Once the teacher is trained, its weights are fixed for training the student model with the proposed adaptive knowledge distillation.",
                "position": 138
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09228/extracted/6356223/images/prec-par-occ-visdrone2018.png",
                "caption": "Figure 3:Attribute-based comparison on the partial occlusion subset of VisDrone2018[98]. ORTrack-DeiT* refers to ORTrack-DeiT without applying the occlusion-robust enhancement.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2504.09228/extracted/6356223/images/fig_bbox_vis.png",
                "caption": "Figure 4:Qualitative evaluation on 3 video sequences from, respectively, UAV123[57], UAVDT[19], and VisDrone2018[98](i.e., person9, S1607, and uav0000180_00050_s).",
                "position": 1159
            },
            {
                "img": "https://arxiv.org/html/2504.09228/extracted/6356223/images/vis_attn_feat.png",
                "caption": "Figure 5:Visualize the attention map (left) and feature map (right) of the target images. The first row displays the search and masked images with masking ratios of 0%, 10%, 30%, and 70%. The second and third rows show the attention and feature maps generated by ORTrack-DeiT, with and without ORR, respectively.",
                "position": 1162
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]