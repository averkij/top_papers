[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/x1.png",
                "caption": "",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2512.10863/x2.png",
                "caption": "",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2512.10863/x3.png",
                "caption": "",
                "position": 82
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/teasor.png",
                "caption": "",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MMSI-Video-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/x4.png",
                "caption": "Figure 2:Illustrative examples of different subtypes in MMSI-Video-Bench. Rel., Inst., and Cam. stand for Relationship, Instance, and Camera. Please refer to our project page for the full demo.",
                "position": 276
            },
            {
                "img": "https://arxiv.org/html/2512.10863/x5.png",
                "caption": "Figure 3:(Left) The pipeline of benchmark sample construction. (Right) The distribution of question types in MMSI-Video-Bench.",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/detail_dis1.png",
                "caption": "Figure 4:Duration distribution of all video samples in MMSI-Video-Bench (in seconds).",
                "position": 332
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Frame Sampling Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/frame_method.png",
                "caption": "Figure 5:Model performance under different frame sampling methods. Dashed lines indicate contiguous sampling, while solid lines indicate uniform sampling.",
                "position": 3468
            }
        ]
    },
    {
        "header": "6Error Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/error_case.png",
                "caption": "Figure 6:Illustration of five representative error types identified in MMSI-Video-Bench, along with examples of model responses and corresponding error analyses.",
                "position": 3489
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/error_dis.png",
                "caption": "Figure 7:Distribution of the five error types. (Left) Error distribution across different question categories. (Right) Overall proportion of each error type.",
                "position": 3514
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/try_results.png",
                "caption": "Figure 8:Effect of different methods on model performance.",
                "position": 3548
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/try.png",
                "caption": "Figure 9:Pipeline of equipping the model with 3D spatial cues.",
                "position": 3551
            }
        ]
    },
    {
        "header": "7Preliminary Exploration for Model Improvement",
        "images": []
    },
    {
        "header": "8Additional Perspectives of MMSI-Video-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/other_bench.png",
                "caption": "Figure 10:Distribution of subtask proportions across the Indoor Scene Perception Bench, Robot Bench and Grounding Bench.",
                "position": 5326
            }
        ]
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "10Acknowledgement",
        "images": []
    },
    {
        "header": "Appendix ABenchmark Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/detail_dis2.png",
                "caption": "Figure 11:(Left) Word cloud of MMSI-Video-Bench. (Right) Distribution of video source categories across all samples in MMSI-Video-Bench.",
                "position": 5626
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/Annotation_ui.png",
                "caption": "Figure 12:User interface for annotation and quality validation in MMSI-Video-Bench.",
                "position": 5640
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/type_detail.png",
                "caption": "Figure 13:Task Categories and Subtypes in MMSI-Video-Bench. ”Inst.” denotes ”instance”, ”Cam.” denotes ”camera” and ”Rel.” denotes ”relationship”.",
                "position": 5643
            },
            {
                "img": "https://arxiv.org/html/2512.10863/imgs/input_format.png",
                "caption": "Figure 14:Structure of system and user prompts used in the experiments.",
                "position": 5646
            }
        ]
    },
    {
        "header": "Appendix BExperiment Details",
        "images": []
    }
]