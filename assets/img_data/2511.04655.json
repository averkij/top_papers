[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04655/x1.png",
                "caption": "Figure 1:The Evolving Landscape of Visual Understanding Benchmarks.As benchmarks evolved from controlled, narrow tasks to open-ended VQA, they gained expressivity but became vulnerable to non-visual shortcuts.\nLanguage-driven evaluation enables flexible querying but risks models exploiting linguistic patterns rather than visual understanding.",
                "position": 129
            }
        ]
    },
    {
        "header": "2The Challenge: Non-Visual Shortcuts Undermine Multimodal Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04655/x2.png",
                "caption": "Figure 2:Knowledge-based shortcuts in multimodal benchmarks.Blindvs. vision-enabledperformance across LLaVA-OneVision model scales.\nMMMU shows substantial gains from scaling the LLM backbone (x-axis) but minimal improvement from enabling vision (y-axis), indicating reliance on linguistic knowledge.\nVSI-Bench demonstrates the opposite pattern—large vision gains with negligible blind scaling—confirming robustness to knowledge-based shortcuts.\nVideoMME shows roughly equal gains from both sources, while CV-Bench benefits more from vision but still exhibits significant gains from LLM scaling.",
                "position": 214
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x3.png",
                "caption": "(a)Counting",
                "position": 237
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x3.png",
                "caption": "(a)Counting",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x4.png",
                "caption": "",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x5.png",
                "caption": "(b)Spatial relation",
                "position": 252
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x6.png",
                "caption": "",
                "position": 256
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x7.png",
                "caption": "(c)Appearance order",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x8.png",
                "caption": "",
                "position": 269
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x9.png",
                "caption": "(d)Size estimation",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x10.png",
                "caption": "",
                "position": 281
            }
        ]
    },
    {
        "header": "3Diagnosing Non-visual Shortcuts via Test-Set Stress-Testing",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04655/x11.png",
                "caption": "(a)Bias space",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x11.png",
                "caption": "(a)Bias space",
                "position": 418
            },
            {
                "img": "https://arxiv.org/html/2511.04655/x12.png",
                "caption": "(b)Diagnostic pipeline",
                "position": 425
            }
        ]
    },
    {
        "header": "4Mitigating Non-Visual Shortcuts Guided by TsT Insights",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AVSI-Train-10k Generation",
        "images": []
    },
    {
        "header": "Appendix BTsT Diagnostic Details",
        "images": []
    },
    {
        "header": "Appendix CDebiasing Details",
        "images": []
    },
    {
        "header": "Appendix DTsT-RF Interpretability Analysis",
        "images": []
    }
]