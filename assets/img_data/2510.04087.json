[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3A Choice-Based Reward Model",
        "images": []
    },
    {
        "header": "4Estimation & Evaluation",
        "images": []
    },
    {
        "header": "5Best of mini-N in-loop",
        "images": []
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04087/bon_failure_graph.png",
                "caption": "Figure 1:In standard BoN, the False Positive Count increases with the number of samples (NN), even as the mean reward improves. This highlights a critical reliability vulnerability.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2510.04087/alignment_guardrail_comparison.png",
                "caption": "Figure 2:Performance of the alignment guardrail configuration compared to the BoN-32 baseline. The Mini-16 in 2 loops setting dramatically reduces the False Positive Count with only a marginal decrease in mean reward.",
                "position": 834
            },
            {
                "img": "https://arxiv.org/html/2510.04087/inference_accelerator_comparison.png",
                "caption": "Figure 3:Performance of the inference accelerator configuration. The Mini-16 in 2 loops setting provides the fastest mean execution time, outperforming the BoN-32 baseline by over 22%.",
                "position": 845
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAcknowledgements",
        "images": []
    },
    {
        "header": "Appendix BBest of Mini N in Loop Algorithm",
        "images": []
    }
]