[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work: Mathematical Evaluation of LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01241/x1.png",
                "caption": "Figure 1:Champion heatmap across benchmarks (transposed).Rows are benchmarks and columns are models. Each cell shows the accuracy; stars mark the per-benchmark champion (ties allowed).",
                "position": 510
            }
        ]
    },
    {
        "header": "3Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01241/x2.png",
                "caption": "Figure 2:SKYLENAGE-ReasoningMATHconstruction pipeline.Our construction pipeline begins with a three-source intake—human authoring, rule-based generation, and structure-preserving rewrites—followed by multi-pass anti-contamination checks at the string, semantic, and template levels. We then perform style and format normalization, carry out bilingualization to ensure parity across languages, and add minimal process-hook annotations to enable step checks. Quality control is conducted with solver and simulator validation, after which we run a small pilot for difficulty calibration. Finally, we freeze the set for release.",
                "position": 539
            }
        ]
    },
    {
        "header": "4Evaluation Protocol",
        "images": []
    },
    {
        "header": "5Dataset Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01241/x3.png",
                "caption": "Figure 3:Reasoning-100 overview.Left: overall accuracy (sorted, %). Right: accuracy on the hardest quintile (Q5).GPT-5-20250807reaches81%,Qwen3-235B-A22B-2507follows closely at79%, andGrok-4-0709at75%. Against the tail, the margin is+44.6%vs.GLM-4.5(56%),+80.0%vs.Llama 4 Maverick(45%), and+92.9%vs.Ernie-4.5-424B-A47B(42%). Top-5 overall (descending):GPT-5-20250807(81),Qwen3-235B-A22B-2507(79),Grok-4-0709(75),GPT-oss-120b(69),Gemini2.5-Pro-0617(69). On the hardest quintile,GPT-5-Chat-0807leads at35%;GPT-5-20250807andQwen3-235B-A22B-2507follow at30%.",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x4.png",
                "caption": "Figure 4:Top-5 profiles.Left: subject radar under thesevencategories. Right: difficulty radar by quintiles Q1–Q5. The flagship dominates discrete-heavy categories: Combinatorics92.9%vs. Grok71.4%, Probability83.3%vs.50.0%, and Number Theory81.0%vs.52.4%. Qwen nearly matches the flagship in most subjects and even surpasses it in Geometry (75.0%vs.68.8%). In Calculus, leaders cluster near77.8%; Graph Theory shows a notable outlier at100%(Llama 4 Maverick, likely small-nn). All models degrade from Q1→\\rightarrowQ5. The flagship and Qwen retain37–38%of their baseline, vs. Grok’s20%and GPT-oss-120b’s≤\\leq15%.",
                "position": 684
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x5.png",
                "caption": "Figure 5:Subject×\\timesmodel accuracy heatmap(%). Seven-subject taxonomy. Darker = higher accuracy. Qwen3-235B-A22B-2507 nearly matches the flagship in most subjects and even surpasses it in Geometry.",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x6.png",
                "caption": "Figure 6:Structure–performance relationships.Left: sensitivity to length vs. accuracy. Middle: complexity sensitivity vs. accuracy. Right: error vs. numeric density (top-5 models). Length and complexity sensitivities show weak positive correlations (r≈0.2r\\approx 0.2). Numeric density is sharper:GPT-oss-120berrors surge (+92%+92\\%),Gemini2.5-Pro-0617rises∼30%\\sim 30\\%, flagshipGPT-5-20250807only∼18%\\sim 18\\%, Grok nearly flat, andQwentrends negative (errors decline as digits grow).",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x7.png",
                "caption": "Figure 7:Meta overview.Left: overall accuracy for 14 models (%).\nMiddle: subject-wise accuracy (top-5 models).\nRight: grade-band accuracy (High School (HS) / Undergraduate (UG) / Graduate (GR) / Doctoral (PhD)). The top performer (GPT-5-20250807) achieves44.0%, leading the runner-up (Grok-4-0709, 37.3%). Qwen3-235B-A22B-2507 follows at 31.3%, close to the second tier (GPT-5 mini, 28.7%;Gemini2.5-Pro-0617, 28.7%). This establishes a three-tier separation: (i) leaders above 35%, (ii) mid-cluster around 22–31%, and (iii) tail under 20%. The gap between the leader and the weakest model (Llama 4 Maverick, 10.7%) is+310%relative.",
                "position": 841
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x8.png",
                "caption": "Figure 8:Heatmaps.Top-left: Subject×\\timesModel accuracy.\nTop-right: Grade×\\timesModel accuracy.\nBottom-left: Per-subject champions (ties shown).\nBottom-right: Subject×\\timesStage accuracy. The flagship dominates in Combinatorics (58.3%) and Graph Theory (40.7%), while Grok-4-0709 edges ahead in Geometry (44.9%). Qwen3-235B performs competitively in Probability (42.9%), close to the top band. In Number Theory, the flagship leads with 40.0% vs. 28.0% for Qwen (+42.9%relative).",
                "position": 856
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x9.png",
                "caption": "Figure 9:Subject radar (top-5 models).Balanced vs. specialized profiles support subject-aware routing.",
                "position": 867
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x10.png",
                "caption": "Figure 10:Answer types.Accuracy is lower on symbolic/derivational forms compared to numeric.",
                "position": 878
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x11.png",
                "caption": "Figure 11:SKYLENAGE-MATH(150) vs. HLE.Each point is a model. Orange line: OLS fity=1.338​x+3.12y{=}1.338\\,x{+}3.12; gray dashed line:y=xy{=}x.",
                "position": 889
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Data Availability",
        "images": []
    },
    {
        "header": "9Ethics Statement",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    },
    {
        "header": "11Authors",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01241/x12.png",
                "caption": "Supplementary Fig. 1:All models: per-model radar grid (normalized).Row-wise min–max profiles reveal “roundness” (balanced) vs. spikes (specialization). Most models spike onMATH-500/AIMEand show dents onHLE.",
                "position": 1388
            },
            {
                "img": "https://arxiv.org/html/2510.01241/x13.png",
                "caption": "Supplementary Fig. 2:Calibration to HLE (per-model scatter).Each panel regresses a target benchmarkyyon HLExx. Dotted line:y=xy{=}x. Solid line: OLS fity=a​x+by{=}ax{+}b. Pearsonrrmeasures agreement in ordering.",
                "position": 1416
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]