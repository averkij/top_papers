[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04519/x1.png",
                "caption": "Figure 1:The overview of\\sysname.",
                "position": 229
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04519/x2.png",
                "caption": "Figure 2:An example of Code-augmented CoT.",
                "position": 301
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04519/extracted/6117756/scalinglaws.png",
                "caption": "Figure 3:Reasoning performance under scaling up the test-time compute.",
                "position": 1077
            }
        ]
    },
    {
        "header": "5Findings and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04519/x3.png",
                "caption": "Figure 4:An example of intrinsic self-reflection during\\sysnamedeep thinking.",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2501.04519/extracted/6117756/ppm_study.png",
                "caption": "Figure 5:Pass@1 accuracy of policy models and their accuracy after applying System 2 reasoning with various reward models, shows that reward models primarily determine the final performance.",
                "position": 1367
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04519/extracted/6117756/passnrandom.png",
                "caption": "Figure 6:Pass@N accuracy with random sampling from different policy models. Compared to the official Qwen instruct version, our policy model exhibits a stronger ability to sample correct solutions.",
                "position": 2498
            },
            {
                "img": "https://arxiv.org/html/2501.04519/extracted/6117756/passnmcts.png",
                "caption": "Figure 7:Pass@N accuracy with PPM-augmented MCTS. Under the same PPM guidance, the four policy models of varying sizes demonstrate convergent capabilities in sampling correct solutions.",
                "position": 2501
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]