[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x1.png",
                "caption": "(a)Validation loss.",
                "position": 114
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x1.png",
                "caption": "(a)Validation loss.",
                "position": 117
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x2.png",
                "caption": "(b)3-bit quantization error.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x3.png",
                "caption": "(c)4-bit quantization error.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Background and Related work",
        "images": []
    },
    {
        "header": "3Post-training quantization of models in the wild",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x4.png",
                "caption": "(a)Validation loss.",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x4.png",
                "caption": "(a)Validation loss.",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x5.png",
                "caption": "(b)3-bit quantization error.",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x6.png",
                "caption": "(c)4-bit quantization error.",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x7.png",
                "caption": "Figure 3:3-bit quantization error along the training trajectories of OLMo2 models.\nError grows gradually during cosine decay but spikes under the steep linear decay phase. Model souping (⋆\\star) reduces degradation, with the soups achieving lower PTQ error than the individual runs.",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x8.png",
                "caption": "(a)3-bit validation loss degradation.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x8.png",
                "caption": "(a)3-bit validation loss degradation.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x9.png",
                "caption": "(b)3-bit accuracy degradation.",
                "position": 292
            }
        ]
    },
    {
        "header": "4Controlled experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x10.png",
                "caption": "(a)4-bit quantization error vs training tokens.",
                "position": 316
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x10.png",
                "caption": "(a)4-bit quantization error vs training tokens.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x11.png",
                "caption": "(b)Validation loss vs training tokens.",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x12.png",
                "caption": "(a)Validation loss.",
                "position": 364
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x12.png",
                "caption": "(a)Validation loss.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x13.png",
                "caption": "(b)δP​T​Q:=CE​(W^)−CE​(W)\\delta_{PTQ}:=\\text{CE}(\\hat{W})-\\text{CE}(W).",
                "position": 372
            }
        ]
    },
    {
        "header": "5Interventions on the training dynamics",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x14.png",
                "caption": "(a)4-bit quantization error.",
                "position": 396
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x14.png",
                "caption": "(a)4-bit quantization error.",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x15.png",
                "caption": "(b)FP to 4-bit validation loss.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x16.png",
                "caption": "(c)FP to 3-bit validation loss.",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x17.png",
                "caption": "(a)4-bit quantization error.",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x17.png",
                "caption": "(a)4-bit quantization error.",
                "position": 427
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x18.png",
                "caption": "(b)FP to 4-bit validation loss.",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x19.png",
                "caption": "(c)FP to 3-bit validation loss.",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x20.png",
                "caption": "(a)FP validation loss.",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x20.png",
                "caption": "(a)FP validation loss.",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x21.png",
                "caption": "(b)3-bit validation loss.",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x22.png",
                "caption": "(c)3-bit quantization error.",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x23.png",
                "caption": "(a)LAWA on OLMo-1B.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x23.png",
                "caption": "(a)LAWA on OLMo-1B.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x24.png",
                "caption": "(b)LAWA on OLMo2-1B.",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x25.png",
                "caption": "(c)LAWA on OLMo2-7B",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x26.png",
                "caption": "(a)4-bit quantization error.",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x26.png",
                "caption": "(a)4-bit quantization error.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x27.png",
                "caption": "(b)L2L_{2}norm of the loss gradient.",
                "position": 524
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x28.png",
                "caption": "(c)L2L_{2}norm of the weights.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x29.png",
                "caption": "(a)4-bit quantization error.",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x29.png",
                "caption": "(a)4-bit quantization error.",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x30.png",
                "caption": "(b)FP to 4-bit validation loss",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x31.png",
                "caption": "(c)FP to 3-bit validation loss.",
                "position": 562
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AQuantization Protocol",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x32.png",
                "caption": "(a)GPTQ",
                "position": 1618
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x32.png",
                "caption": "(a)GPTQ",
                "position": 1621
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x33.png",
                "caption": "(b)AWQ",
                "position": 1626
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x34.png",
                "caption": "(c)LLM.int8",
                "position": 1631
            }
        ]
    },
    {
        "header": "Appendix BPretraining hyperparameters and setup",
        "images": []
    },
    {
        "header": "Appendix CEvaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x35.png",
                "caption": "Figure 14:SmolLM3 per-taskfull-precision accuracy, measured throughout training.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x36.png",
                "caption": "Figure 15:SmolLM3 per-taskrelative accuracy degradationunder 3-bit GPTQ, measured throughout training.",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x37.png",
                "caption": "Figure 16:SmolLM3 per-taskrelative accuracy degradationunder 4-bit GPTQ, measured throughout training.",
                "position": 1773
            }
        ]
    },
    {
        "header": "Appendix DPTQ robustness on additional models in the wild",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06213/x38.png",
                "caption": "Figure 17:Quantization degradation for Amber-7B. 3 and 4-bit quantization with GPTQ.",
                "position": 1787
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x39.png",
                "caption": "Figure 18:Quantization degradation for Apertus-8B. 3 and 4-bit quantization with GPTQ.",
                "position": 1790
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x40.png",
                "caption": "Figure 19:Quantization degradation for OLMo-1B. 3 and 4-bit quantization with GPTQ.",
                "position": 1793
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x41.png",
                "caption": "Figure 20:Quantization degradation for OLMo-7B. 3 and 4-bit quantization with GPTQ.",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x42.png",
                "caption": "Figure 21:Quantization degradation for OLMo2-1B. 3 and 4-bit quantization with GPTQ.",
                "position": 1799
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x43.png",
                "caption": "Figure 22:Quantization degradation for OLMo2-7B. 3 and 4-bit quantization with GPTQ.",
                "position": 1802
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x44.png",
                "caption": "Figure 23:Quantization degradation for OLMo2-13B. 3 and 4-bit quantization with GPTQ.",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x45.png",
                "caption": "Figure 24:Quantization degradation for OLMo2-32B. 3 and 4-bit quantization with GPTQ.",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x46.png",
                "caption": "Figure 25:Validation loss of the full-precision weights of the OLMo-2 family suite. We observe that the ingredients increase the validation loss, but performance is recovered during the model souping.",
                "position": 1833
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x47.png",
                "caption": "Figure 26:4-bit quantization degradation for OLMo2 family suite.",
                "position": 1836
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x48.png",
                "caption": "(a)LAWA on OLMo2-1B.",
                "position": 1839
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x48.png",
                "caption": "(a)LAWA on OLMo2-1B.",
                "position": 1842
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x49.png",
                "caption": "(b)LAWA on OLMo2-7B",
                "position": 1847
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x50.png",
                "caption": "(a)Quantization error vs training tokens.",
                "position": 1854
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x50.png",
                "caption": "(a)Quantization error vs training tokens.",
                "position": 1857
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x51.png",
                "caption": "(b)Validation loss vs training tokens.",
                "position": 1862
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x52.png",
                "caption": "(a)4-bit quantization error.",
                "position": 1872
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x52.png",
                "caption": "(a)4-bit quantization error.",
                "position": 1875
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x53.png",
                "caption": "(b)FP to 4-bit validation loss",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2510.06213/x54.png",
                "caption": "(c)FP to 3-bit validation loss.",
                "position": 1885
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results",
        "images": []
    }
]