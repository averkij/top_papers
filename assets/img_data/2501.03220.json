[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03220/x1.png",
                "caption": "",
                "position": 83
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03220/x2.png",
                "caption": "Figure 2:Pipeline overview of our proposed method. (1) Sample & Chain: Key points are initially sampled and linked through optical flow chaining to produce preliminary trajectory predictions. (2) Long-term Correspondence: Key points are re-localized over longer time spans to maintain continuity, even for points that temporarily disappear. (3) Hybrid Filter: Masks and feature filters are applied to remove incorrect predictions, reducing noise for subsequent steps. (4) Probabilistic Integration: Filtered flow predictions across frames are first integrated and then combined with long-term keypoint to produce the final prediction, producing smoother and more consistent trajectories.",
                "position": 144
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03220/x3.png",
                "caption": "Figure 3:A point may frequently disappear and reappear during tracking. When it disappears, establishing long-term correspondence enables accurate re-localization in a keyframe, ensuring the point is correctly re-identified, even in challenging situations like occlusion or scene changes. After re-localization, flow integration resumes, allowing smooth and precise trajectory generation to continue seamlessly for subsequent frames.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2501.03220/x4.png",
                "caption": "Figure 4:To evaluate our method, we compare it with several state-of-the-art approaches, including data-driven models such as Co-Tracker[21], SpatialTracker[49], LocoTrack[10], and TAPTR[24]as well as the self-supervised CaDex++[40]and DINO-Tracker[46]. The test scenes selected from the TAPVid-DAVIS dataset includebike-packingandgoat. Track predictions are conducted at a resolution of 256Ã—256, while the visualizations of tracked points are displayed in the original resolution. More qualitative results are included in the supplementary material.",
                "position": 1145
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03220/x5.png",
                "caption": "Figure 5:The qualitative ablation study on different components of our method.",
                "position": 1370
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "1Video Results",
        "images": []
    },
    {
        "header": "2Implementation Details",
        "images": []
    },
    {
        "header": "3Dense Inference",
        "images": []
    },
    {
        "header": "4Training and Inference Speed",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/cola.jpg",
                "caption": "Figure 1:Results of tracking a single object. While DINO-Tracker may mispredict parts onto similar objects and TAPIR can be disrupted by similar patterns, our method avoids these errors.",
                "position": 2189
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/car.jpg",
                "caption": "",
                "position": 2193
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/fish.jpg",
                "caption": "Figure 2:Results of tracking a single object. While DINO-Tracker may lose some parts and TAPIR can be disrupted by multiple similar patterns, our method avoids these errors.",
                "position": 2197
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/bird.jpg",
                "caption": "",
                "position": 2201
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/dance.jpg",
                "caption": "Figure 3:Results of tracking at a higher frame rate. Sliding window based methods can easily lose track after occlusion and drift due to accumulating errors, while ours exhibit robustness.",
                "position": 2208
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/bike.jpg",
                "caption": "",
                "position": 2212
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/shooting.jpg",
                "caption": "Figure 4:Results of tracking at a higher frame rate. Sliding window based methods can mispredict points to other regions during occlusion (e.g. the gun and rope inshootingand the wrong person inindia), while ours exhibit robustness.",
                "position": 2216
            },
            {
                "img": "https://arxiv.org/html/2501.03220/extracted/6092412/pic/india.jpg",
                "caption": "",
                "position": 2220
            }
        ]
    },
    {
        "header": "5More Qualitative Results",
        "images": []
    }
]