[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03548/x1.png",
                "caption": "Figure 1:Comparison of training paradigms. A. Static data methods are limited by data quality and may learn human violations. B. Traditional self-evolving creates unfair games where user agents dominate outcomes. OurSEADachieves balanced co-evolution and realistic interactions through decomposed user modeling, forming a fair adversarial game.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03548/x2.png",
                "caption": "Figure 2:SEAD Framework Overview. SEAD consists of three components: (1)Profile Generatorfirst creates diverse user profiles, then the (2)User Role-Play Modelenacts these users to interact with the (3)Service Agent, training agents to adapt to any user.\nFinally, these dialogue data reflecting service agent capability returns to the Profile Controller, and initiates the next evolving loop.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2602.03548/x3.png",
                "caption": "Figure 3:SEAD Co-evolutionary Training Loop. The controller samples initial states (Phase 1), which initialize dialogues producing trajectories (Phase 2), used to train the agent with rewards (Phase 3) and compute completion rates (Phase 4), which feed back to adjust sampling distributions, closing the co-evolutionary loop.",
                "position": 204
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03548/x4.png",
                "caption": "Figure 4:Case Studies of Challenging Interactions. The User Role-play Model generates heterogeneous personas via clustering, such as the \"Rude & Irrational\" user (Left) and the \"AI-Skeptical\" user (Right). The Service Agent demonstrates robustness learned from compound rewards, employing Empathy and Identity Defense strategies to prevent hang-ups and ensure task completion.",
                "position": 671
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]