[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x1.png",
                "caption": "Figure 1:(a) We present KRIS-Bench, a benchmark for instruction-based image editing grounded in a knowledge-based reasoning taxonomy. It covers 3 knowledge dimensions, 7 reasoning dimensions, and 22 editing tasks. Specific examples are shown in Figure2. (b) Given an editing pair of (image, instruction) under a specific reasoning dimension (i.e., Chemistry in Natural Science), we evaluate the output of image editing models with automated VLM tools over the proposed four complementary metrics, which are aligned with human scoring.",
                "position": 87
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3KRIS-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x2.png",
                "caption": "Figure 2:Representative examples from the 22 knowledge-based reasoning image editing tasks in KRIS-Bench. Each task is designed to evaluate specific knowledge grounded in factual, conceptual, or procedural, covering diverse reasoning dimensions.",
                "position": 235
            }
        ]
    },
    {
        "header": "4Experiments and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x3.png",
                "caption": "Figure 3:Visualization results of (a) Color Change, (b) Position Movement, (c) Humanities, (d) Chemistry, and (e) Abstract Reasoning across different models and metrics. Each example is provided with scores across the four evaluation metrics as well as an overall average score. Note that the knowledge hint is provided solely for evaluation and has been shortened for better illustration.",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x4.png",
                "caption": "Figure 4:Performance on KRIS-Bench across different editing tasks and four different metrics. Top: closed-source models. Bottom: open-source models.",
                "position": 1115
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x5.png",
                "caption": "Figure 5:Correlation between human and VLM scores across Visual Consistency (VC), Visual Quality (VQ), Instruction Following (IF), and Knowledge Plausibility (KP). We compare the prompts incorporating knowledge hints (Knowledge Prompts) with a simple baseline (Simple Prompts).",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "ADetailed Tasks Explanation",
        "images": []
    },
    {
        "header": "BData Distribution",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x6.png",
                "caption": "Figure 6:Distribution of KRIS-Bench instances by knowledge type (left), reasoning dimension (center), and editing task (right).",
                "position": 2340
            }
        ]
    },
    {
        "header": "CData Source",
        "images": []
    },
    {
        "header": "DUser Study Details",
        "images": []
    },
    {
        "header": "EOpen-source VLM Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x7.png",
                "caption": "Figure 7:Performance on KRIS-Bench across different editing tasks and four different metrics using Qwen2.5-VL-72B as scoring VLM. Top: closed-source models. Bottom: open-source models.",
                "position": 2373
            }
        ]
    },
    {
        "header": "FComputing Source Requirements",
        "images": []
    },
    {
        "header": "GMore Visualization Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16707/x8.png",
                "caption": "Figure 8:Visualization results of Count Change task.",
                "position": 3170
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x9.png",
                "caption": "Figure 9:Visualization results of Anomaly Correction task.",
                "position": 3177
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x10.png",
                "caption": "Figure 10:Visualization results of Part Completion task.",
                "position": 3184
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x11.png",
                "caption": "Figure 11:Visualization results of Color Change task.",
                "position": 3191
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x12.png",
                "caption": "Figure 12:Visualization results of Size Adjustment task.",
                "position": 3198
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x13.png",
                "caption": "Figure 13:Visualization results of Viewpoint Change task.",
                "position": 3205
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x14.png",
                "caption": "Figure 14:Visualization results of Position Movement task.",
                "position": 3212
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x15.png",
                "caption": "Figure 15:Visualization results of Temporal Prediction tasks.",
                "position": 3219
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x16.png",
                "caption": "Figure 16:Visualization results of Humanities task.",
                "position": 3226
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x17.png",
                "caption": "Figure 17:Visualization results of Practical Knowledge task.",
                "position": 3233
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x18.png",
                "caption": "Figure 18:Visualization results of Biology task.",
                "position": 3240
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x19.png",
                "caption": "Figure 19:Visualization results of Chemistry task.",
                "position": 3247
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x20.png",
                "caption": "Figure 20:Visualization results of Geography task.",
                "position": 3254
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x21.png",
                "caption": "Figure 21:Visualization results of Medicine task.",
                "position": 3261
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x22.png",
                "caption": "Figure 22:Visualization results of Mathematics task.",
                "position": 3268
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x23.png",
                "caption": "Figure 23:Visualization results of Physics task.",
                "position": 3275
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x24.png",
                "caption": "Figure 24:Visualization results of Multi-element Composition task.",
                "position": 3282
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x25.png",
                "caption": "Figure 25:Visualization results of Multi-instruction Execution task.",
                "position": 3289
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x26.png",
                "caption": "Figure 26:Visualization results of Abstract Reasoning task.",
                "position": 3296
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x27.png",
                "caption": "Figure 27:Visualization results of Rule-based Reasoning task.",
                "position": 3303
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x28.png",
                "caption": "Figure 28:Prompt used to evaluate Visual Consistency.",
                "position": 3310
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x29.png",
                "caption": "Figure 29:Prompt used to evaluate Visual Quality.",
                "position": 3313
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x30.png",
                "caption": "Figure 30:Prompt used to evaluate Instruction Following.",
                "position": 3316
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x31.png",
                "caption": "Figure 31:Joint evaluation prompt for Instruction Following where the model is asked to assess both in a unified manner to avoid evaluation misalignment.",
                "position": 3319
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x32.png",
                "caption": "Figure 32:Joint evaluation prompt for Knowledge Plausibility where the model is asked to assess both in a unified manner to avoid evaluation misalignment.",
                "position": 3322
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x33.png",
                "caption": "Figure 33:Customized prompt for Temporal Prediction dimension.",
                "position": 3325
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x34.png",
                "caption": "Figure 34:Prompt for evaluating Multi-element Composition task.",
                "position": 3328
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x35.png",
                "caption": "Figure 35:Instruction Following prompt for the Viewpoint Change task, where the evaluation leverages the ground truth image as a visual reference.",
                "position": 3331
            },
            {
                "img": "https://arxiv.org/html/2505.16707/x36.png",
                "caption": "Figure 36:Prompt designed for the Anomaly Correction task, where a knowledge hint is provided as an additional reference to guide the evaluation of whether the anomaly is correctly identified and resolved.",
                "position": 3334
            }
        ]
    },
    {
        "header": "HEvaluation Prompts",
        "images": []
    }
]