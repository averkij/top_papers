[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.05305/x1.png",
                "caption": "Figure 2:Architecture ofSONAR-LLM. The model autoregressively predicts the next sentence embedding given a prefix of embeddings and decodes it via the frozenSONARdecoder.",
                "position": 177
            }
        ]
    },
    {
        "header": "Related Works",
        "images": []
    },
    {
        "header": "SONAR-LLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.05305/x2.png",
                "caption": "Figure 3:Scaling laws: validation loss dynamics vs. number of trainable parameters.",
                "position": 258
            }
        ]
    },
    {
        "header": "Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.05305/x3.png",
                "caption": "Figure 4:GPT-4o-based evaluation scores (grammar, creativity, consistency, plot) by model and size. Trainable parameter counts are shown above bars for SONAR-LLM and MSE LCM.",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2508.05305/x4.png",
                "caption": "Figure 5:NLG scores by model and size; trainable parameter counts are shown above bars for SONAR-LLM and MSE LCM.",
                "position": 400
            },
            {
                "img": "https://arxiv.org/html/2508.05305/x5.png",
                "caption": "Figure 6:Theoretical inference FLOPs for autoregressive LLM and SONAR-LLM as a function of sequence length (logâ€“log scale).",
                "position": 489
            }
        ]
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]