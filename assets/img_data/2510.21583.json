[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/exp_qua.jpg",
                "caption": "Figure 1:Chunk-GRPO significantly improves image quality, particularly in structure, lighting, and fine-grained details, demonstrating the superiority of chunk-level optimization.",
                "position": 88
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/motivationv2.png",
                "caption": "Figure 2:While Trajectory1 has the greater final reward (advantage), itst=1t=1timestep is worse than that in Trajectory2. However, GRPO assigns the final advantages equally across all timesteps.",
                "position": 97
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/o1relv2.png",
                "caption": "Figure 3:The prompt-invariant temporal dynamics of flow matching.",
                "position": 197
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/frameworkv2.png",
                "caption": "Figure 4:The overall framework of Chunk-GRPO. Chunk-GRPO integrates chunk-level optimization with temporal-dynamic-guided chunking, based on the grounded defined chunk-level importance ratiorr. It also introduces an optional weighted sampling strategy, assigning sampling weightwwfor each chunk.",
                "position": 262
            },
            {
                "img": "https://arxiv.org/html/2510.21583/toy_exp_for_chunk_length.png",
                "caption": "Figure 5:Performance varies with different chunk sizes. The ‘TD’ refers to temporal dynamics.",
                "position": 370
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/specific_chunk.png",
                "caption": "Figure 6:The results of training specific chunks.",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2510.21583/Additional_Qualitative_Results.jpg",
                "caption": "Figure 7:Additional visualization comparison between the FLUX, DanceGRPO, Chunk-GRPO w/o temporal dynamics, Chunk-GRPO w/ temporal dynamics and Chunk-GRPO w/ weighted sampling.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2510.21583/Additional_Qualitative_Results2.jpg",
                "caption": "Figure 8:Additional visualization comparison between the FLUX, DanceGRPO, Chunk-GRPO w/o temporal dynamics, Chunk-GRPO w/ temporal dynamics and Chunk-GRPO w/ weighted sampling.",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2510.21583/failure.jpg",
                "caption": "Figure 9:A failure case of the weighted sampling strategy. The strategy wrongly changes the image structure in the high-noise region, leading to the worst variant.",
                "position": 729
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMathematical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21583/overall_comparison.png",
                "caption": "Figure 10:The relativeL​1L1distance comparison, before and after the training of Dance-GRPO.",
                "position": 2060
            }
        ]
    },
    {
        "header": "Appendix BExperiment Details",
        "images": []
    }
]