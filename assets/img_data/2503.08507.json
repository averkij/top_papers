[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08507/x1.png",
                "caption": "",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08507/x2.png",
                "caption": "Figure 2:Visualization results of Qwen2.5-VL[3], InternVL-2.5[14], and DeepSeek-VL2[70]on the human referring task. Despite achieving strong results on referring benchmarks RefCOCO/+/g[50,75], state-of-the-art models struggle when tasked with identifying multiple individuals as they output an insufficient number of bounding boxes.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3HumanRef Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08507/x3.png",
                "caption": "Figure 3:Overview of the mannual annotation pipeline of the HumanRef dataset.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2503.08507/x4.png",
                "caption": "Figure 4:Visualization of the six subsets in the HumanRef Benchmark.",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2503.08507/x5.png",
                "caption": "Figure 5:Distribution of the number of individuals per image and the number of individuals referenced by each referring expression.",
                "position": 589
            }
        ]
    },
    {
        "header": "4RexSeek Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08507/x6.png",
                "caption": "Figure 6:Overview of the RexSeek model. RexSeek is a retrieval-based model built upon ChatRex[25]. By integrating a person detection model, RexSeek transforms the referring task from predicting box coordinates to retrieving the index of input boxes.",
                "position": 613
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08507/x7.png",
                "caption": "Figure 7:Visualizing the trend of recall and precision variations across different models as the number of instances corresponding to each referring expression increases.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2503.08507/x8.png",
                "caption": "Figure 8:RexSeek can refer to arbitrary objects beyond person.",
                "position": 1261
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7More Details of HumanRef Dataset",
        "images": []
    },
    {
        "header": "8Details for RexSeek model",
        "images": []
    }
]