[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19527/x1.png",
                "caption": "Figure 1:Concept of DisCoRD.Discrete quantization methods encode multiple motions into a single quantized representation. While existing methods deterministically decode from this quantized representation, DisCoRD iteratively decodes the discrete latent in a continuous space to recover the inherent continuity and dynamism of motion. To assess the gap between reconstructed and real motion, prior work primarily used FID as the metric. Here, we additionally propose symmetric Jerk Percentage Error (sJPE) to evaluate the differences in naturalness between reconstructed and real motion.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19527/x2.png",
                "caption": "Figure 2:An overview of DisCoRD.During theTrainingstage, we leverage a pretrained quantizer to first obtain discrete representations (tokens) of motion. These tokens are then projected into continuous featuresùêÇùêÇ\\mathbf{C}bold_C, which are concatenated with noisy motionùêótsubscriptùêóùë°\\mathbf{X}_{t}bold_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This concatenated feature is used to train a vector fieldvùë£vitalic_v. During theInferencestage, we use a pretrained token prediction model based on the pretrained quantizer to first generate tokens from the given control signal. These generated tokens are then projected into continuous featuresùêÇ^^ùêÇ\\mathbf{\\hat{C}}over^ start_ARG bold_C end_ARG, concatenated with Gaussian noiseùêó0‚àºùí©‚Å¢(0,I)similar-tosubscriptùêó0ùí©0ùêº\\mathbf{X}_{0}\\sim\\mathcal{N}(0,I)bold_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ‚àº caligraphic_N ( 0 , italic_I ), and iteratively decoded through the learned vector fieldvŒ∏subscriptùë£ùúÉv_{\\theta}italic_v start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPTinto motionùêó^1subscript^ùêó1\\mathbf{\\hat{X}}_{1}over^ start_ARG bold_X end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.",
                "position": 181
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19527/x3.png",
                "caption": "Figure 3:sJPE and FID response to gaussian noise.Noise sJPEis very sensitive to small level frame-wise noise than FID, whileStatic sJPEremains small. Note that FID values are very small.",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x4.png",
                "caption": "Figure 4:Under-reconstruction and frame-wise noise.We visualize joint positions (top) and corresponding jerk graphs (bottom). Compared to MoMask, DisCoRD demonstrates lower noise levels (Noise sJPE, blue area) and reduced under-reconstruction (Static sJPE, red area), with under-reconstruction regions in Momask highlighted in green boxes. This results in a lower sJPE for our method, indicating improved naturalness in the reconstructed motion.",
                "position": 346
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x5.png",
                "caption": "Figure 5:Time spent decodinga batch of token sequences with a batch size of 32. All tests are conducted on the same NVIDIA RTX 4090Ti. Each experiment was repeated 20 times across the entire HumanML3D test set, and the average values were reported.",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x6.png",
                "caption": "Figure 6:Qualitative comparisonson the test set of HumanML3D.",
                "position": 825
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x7.png",
                "caption": "Figure 7:User study results on the HumanML3D dataset.Each bar represents a comparison between two models, with win rates depicted in blue and loss rates in red, evaluated based on naturalness and faithfulness.",
                "position": 836
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BDatasets and Evaluations",
        "images": []
    },
    {
        "header": "Appendix CAdditional Analysis on sJPE",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19527/x8.png",
                "caption": "Figure 8:Relationship between fine-grained trajectory and jerk:Frame-wise noise in predicted motions, highlighted in the red box, results in higher jerk values compared to the ground truth, represented by the blue areas. The sum of the blue areas corresponds to Noise sJPE. Conversely, under-reconstruction in predicted motions, highlighted in the green box, leads to lower jerk values compared to the ground truth, represented by the red areas. The sum of the red areas corresponds to Static sJPE.",
                "position": 1888
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x9.png",
                "caption": "Figure 9:Joint Trajectory and Jerk: Under-Reconstruction in Discrete MethodsDisCoRD effectively reduces the red area, demonstrating its capability to reconstruct dynamic motion accurately. This improvement is also reflected in the lower sJPE value.",
                "position": 1891
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x10.png",
                "caption": "Figure 10:Joint Trajectory and Jerk: Frame-Wise Noise in Discrete MethodsDisCoRD significantly reduces the blue area, indicating its ability to generate smooth motions that closely resemble the ground truth. This improvement is further reflected in the lower sJPE value.",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x11.png",
                "caption": "Figure 11:Joint Trajectory and Jerk: Both Frame-Wise Noise and Under-Reconstruction in Discrete MethodsDisCoRD addresses both frame-wise noise and under-reconstruction by simultaneously reducing the blue and red areas. This demonstrates its ability to generate smooth and dynamic motions, closely aligning with the ground truth. This further supported by the lower sJPE values.",
                "position": 1911
            }
        ]
    },
    {
        "header": "Appendix DAdditional Quantitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19527/x12.png",
                "caption": "Figure 12:Additional qualitative comparisonson the HumanML3D test set. The continuous method, MLD, often fails to perfectly align with the text consistently, while the discrete method, MoMask, exhibits issues such as under-reconstruction, resulting in minimal hand movement, or unnatural leg jitter caused by frame-wise noise.",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x13.png",
                "caption": "Figure 13:Additional qualitative resultsof our method on the HumanML3D test set.",
                "position": 2409
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x14.png",
                "caption": "Figure 14:Guidelines for user study in the Main paper:participants were asked to evaluate Faithfulness and Naturalness, excluding hand and facial movements that are not included in HumanML3D.",
                "position": 2412
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x15.png",
                "caption": "Figure 15:Guidelines for User Study in the Supplementary:Participants were asked to evaluate Naturalness, excluding hand and facial movements that are not included in HumanML3D.",
                "position": 2415
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x16.png",
                "caption": "Figure 16:User evaluation interfacefor the user study in the Main paper: participants were presented with two randomly selected videos and asked to choose the better sample in terms of faithfulness and naturalness.",
                "position": 2418
            },
            {
                "img": "https://arxiv.org/html/2411.19527/x17.png",
                "caption": "Figure 17:User evaluation interfacefor the user study in the supplementary: participants were presented with a grid layout containing the GT video and three generated videos. Using the GT video as the upper bound, they were asked to rank the three generated videos in terms of naturalness.",
                "position": 2421
            }
        ]
    },
    {
        "header": "Appendix EAdditional Qualitative Results",
        "images": []
    }
]