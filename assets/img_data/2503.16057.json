[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/teaser_v7.png",
                "caption": "Figure 1:(Left) Our proposedExpert Racerouting employs Top-kùëòkitalic_kselection over full token-expert affinity logits, achieving thehighest flexibilitycompared to prior methods like Token Choice and Expert Choice.(Right) Training curve comparisons between DiT-XL[25]and ours. Our model, withequal number of activated parameters, achieves a7.2√ó\\mathbf{7.2\\times}bold_7.2 √óspeedupin iterations when reaching the same training loss.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/pipeline_v6.png",
                "caption": "Figure 2:The Race-DiT Architecture. We replace the Multi-Layer Perceptron (MLP) with the MoE block, which consists of a Router and multiple Experts. In Race-DiT, the token assignment is done once for all. Each token can be assigned to any number of experts, and each expert can process any number of tokens (including zero).",
                "position": 246
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Taming Diffusion Models with Expert Race",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/compare_tc_ec_er.png",
                "caption": "Figure 3:Top-ùí¶ùí¶\\mathcal{K}caligraphic_KSelection Flexibility and Specifications.BùêµBitalic_B: batch size;LùêøLitalic_L: sequence length;Eùê∏Eitalic_E: the number of experts.\n(a) Token Choice selects top-ùí¶ùí¶\\mathcal{K}caligraphic_Kexperts along the expert dimension for each token. (b) Expert Choice selects top-ùí¶ùí¶\\mathcal{K}caligraphic_Ktokens along the sequence dimension for each expert. (c) Expert Race selects top-ùí¶ùí¶{\\mathcal{K}}caligraphic_Kacross the entire set.",
                "position": 447
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/arxiv_logits_assign_v2.png",
                "caption": "Figure 4:Toy examples of token assignment. Both of the two cases show perfect load balance that each expert process two tokens. But in the case above, experts 1 and 2 are assigned the same token, as are experts 3 and 4, where the 2-in-4 MoE collapse into 1-in-2. The example below shows a more diverse assignment, making full use of the expert specialization.",
                "position": 595
            }
        ]
    },
    {
        "header": "5Load Balancing via Router Similarity Loss",
        "images": []
    },
    {
        "header": "6Per-Layer Regularization for Efficient Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/output_norm.png",
                "caption": "Figure 5:The norm of each block‚Äôs output before added to the shortcuts. The output norm increases rapidly in deep layers, resulting in the weakening of shallow-layer components. This issue is alleviated with our proposed per-layer regularization.",
                "position": 671
            }
        ]
    },
    {
        "header": "7Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/allocation.png",
                "caption": "Figure 6:Average token allocation at different time steps. Expert-Race assigns more experts to the more complex denoising time steps, which occur at lower timestep indices that handle finer-grain image details.",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2503.16057/x1.png",
                "caption": "",
                "position": 856
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/arxiv_dense_vs_moe.png",
                "caption": "Figure 8:A comparison between Dense and our MoE models. Our MoE models consistently outperform their Dense counterparts across the FID and training curves. Notably, the MoE model with activation sizeMshows better performance compared to the Dense model scaled to sizeXL.",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/arxiv_scaling_law.png",
                "caption": "Figure 9:Scaling results of DiT-B in different MoE configurations. Our method demonstrates linear performance improvement when varying expert split ratios and increasing the number of candidate experts.",
                "position": 1131
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/compare_choices_methods_v2.png",
                "caption": "Figure 10:Top-ùí¶ùí¶\\mathcal{K}caligraphic_Kselection flexibility in more extended routing strategies.",
                "position": 1142
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/random_generation.jpg",
                "caption": "Figure 11:Random generated256√ó256256256256\\times 256256 √ó 256samples from RaceDiT-XL/2-4in32. Classifier-free guidance scale is 4.",
                "position": 1225
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "9Implemention of the Per-Layer Regularization",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/PLR_figure.png",
                "caption": "Figure 12:An illustration of the calculation for Per-Layer Regularization.",
                "position": 2006
            }
        ]
    },
    {
        "header": "10Analysis of Router Similarity Loss",
        "images": []
    },
    {
        "header": "11Combination Usage",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/x2.png",
                "caption": "Figure 13:Compute process of Combination Usage.",
                "position": 2158
            }
        ]
    },
    {
        "header": "12Additional Comparisons with DiT-MoE",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/compare_to_ditmoe.png",
                "caption": "Figure 14:Training curve comparisons between DiT-MoE[9]and our model.",
                "position": 2208
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/88.jpg",
                "caption": "Figure 15:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: Macaw (88)",
                "position": 2223
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/33.jpg",
                "caption": "Figure 16:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: loggerhead turtle (33)",
                "position": 2229
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/291.jpg",
                "caption": "Figure 17:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: lion (291)",
                "position": 2237
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/387.jpg",
                "caption": "Figure 18:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: lesser panda (387)",
                "position": 2243
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/511.jpg",
                "caption": "Figure 19:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: convertible (511)",
                "position": 2251
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/417.jpg",
                "caption": "Figure 20:Samples from RaceDiT-XL/2-4in32(256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: balloon (417)",
                "position": 2257
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/975.jpg",
                "caption": "Figure 21:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: lakeside (975)",
                "position": 2265
            },
            {
                "img": "https://arxiv.org/html/2503.16057/extracted/6296282/figures/gen_samples/980.jpg",
                "caption": "Figure 22:Samples from RaceDiT-XL/2-4in32 (256√ó256256256256\\times 256256 √ó 256).Classifier-free guidance: 4.0Label: volcano (980)",
                "position": 2271
            }
        ]
    },
    {
        "header": "13Additional Image Generation Results",
        "images": []
    }
]