[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18924/x1.png",
                "caption": "Figure 1:(a) The WaveVAE model; (b) Overview of our model. We insert the sparse alignment anchors into the latent vector sequence to provide coarse alignment information. The transformer blocks in MegaTTS 3 will automatically build fine-grained alignment paths.",
                "position": 245
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18924/x2.png",
                "caption": "Figure 2:The confusion matrices between the perceived and intended accent categories of synthesized speech. The X-axis and Y-axis represent the intended and perceived categories, respectively.",
                "position": 704
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/CMOS.png",
                "caption": "(a) Screenshot of CMOS testing.",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/CMOS.png",
                "caption": "(a) Screenshot of CMOS testing.",
                "position": 2002
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/SMOS.png",
                "caption": "(b) Screenshot of SMOS testing.",
                "position": 2008
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/ASMOS.png",
                "caption": "(c) Screenshot of ASMOS testing.",
                "position": 2014
            }
        ]
    },
    {
        "header": "Appendix BClassifier-Free Guidance Used in Zero-Shot TTS",
        "images": []
    },
    {
        "header": "Appendix CDetails of PeRFlow Training Procedure",
        "images": []
    },
    {
        "header": "Appendix DDetails about Data and Model Scaling Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/vis_dur_control_1.png",
                "caption": "Figure 4:Sentence-level duration control.",
                "position": 2119
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/vis_dur_control_1.png",
                "caption": "Figure 4:Sentence-level duration control.",
                "position": 2122
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/vis_dur_control_2.png",
                "caption": "Figure 5:Phoneme-level duration control.",
                "position": 2127
            }
        ]
    },
    {
        "header": "Appendix EDuration Controllability of MegaTTS 3",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/layer8_diff_timestep.png",
                "caption": "(a) Layer 8 with different timesteps.",
                "position": 2141
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/layer8_diff_timestep.png",
                "caption": "(a) Layer 8 with different timesteps.",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/layer16_diff_timestep.png",
                "caption": "(b) Layer 16 with different timesteps.",
                "position": 2150
            },
            {
                "img": "https://arxiv.org/html/2502.18924/extracted/6317079/figures/vis/layer27_diff_timestep.png",
                "caption": "(c) Layer 27 with different timesteps.",
                "position": 2156
            }
        ]
    },
    {
        "header": "Appendix FVisualization of Attention Matrices",
        "images": []
    },
    {
        "header": "Appendix GAbout Different Lengths of Context",
        "images": []
    },
    {
        "header": "Appendix HExperiments of Prosodic Naturalness for Zero-Shot TTS",
        "images": []
    },
    {
        "header": "Appendix IExperiments with Longer Samples",
        "images": []
    },
    {
        "header": "Appendix JExperiments with Hard Sentences",
        "images": []
    },
    {
        "header": "Appendix KAdditional Details for Multi-Condition CFG",
        "images": []
    },
    {
        "header": "Appendix LEthics Statement",
        "images": []
    },
    {
        "header": "Appendix MReproducibility Statement",
        "images": []
    }
]