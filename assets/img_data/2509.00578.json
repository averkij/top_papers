[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00578/x1.png",
                "caption": "Figure 1:Overview of the proposed Context-Aware DiffusionDet architecture. The framework consists of four key components: (1) Adaptive Channel Enhancement (ACE) blocks that enhance backbone and FPN features, (2) Global Context Encoder (GCE) for comprehensive scene understanding, (3) Context-Aware Fusion (CAF) that integrates global context with local features through cross-attention, and (4) enhanced Multi-Modal Fusion (MMF) with global context embeddings. This architecture addresses the local feature conditioning limitation in existing diffusion-based detectors by enabling comprehensive environmental context integration.",
                "position": 309
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/gt/000088_gt.jpg",
                "caption": "Figure 2:This figure compares the performance of our model against the baseline. The first row contains the original images with the ground truth annotations. The second row shows the bounding boxes generated by DiffusionDet. The third row shows the more accurate bounding boxes produced by our enhanced model.",
                "position": 1225
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/gt/000348_gt.jpg",
                "caption": "",
                "position": 1238
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/gt/001268_gt.jpg",
                "caption": "",
                "position": 1240
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/gt/001832_gt.jpg",
                "caption": "",
                "position": 1242
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/gt/002385_gt.jpg",
                "caption": "",
                "position": 1244
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/dcn_plus/000088_DCN_Plus.png",
                "caption": "",
                "position": 1258
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/dcn_plus/000348_DCN_Plus.png",
                "caption": "",
                "position": 1260
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/dcn_plus/001268_DCN_Plus.png",
                "caption": "",
                "position": 1262
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/dcn_plus/001832_DCN_Plus.png",
                "caption": "",
                "position": 1264
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/dcn_plus/002385_DCN_Plus.png",
                "caption": "",
                "position": 1266
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/baseline/000088.png",
                "caption": "",
                "position": 1280
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/baseline/000348.png",
                "caption": "",
                "position": 1282
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/baseline/001268.png",
                "caption": "",
                "position": 1284
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/baseline/001832.png",
                "caption": "",
                "position": 1286
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/baseline/002385.png",
                "caption": "",
                "position": 1288
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/ours/000088.jpg",
                "caption": "",
                "position": 1303
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/ours/000348.jpg",
                "caption": "",
                "position": 1305
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/ours/001268.jpg",
                "caption": "",
                "position": 1307
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/ours/001832.jpg",
                "caption": "",
                "position": 1309
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/Detection/ours/002385.jpg",
                "caption": "",
                "position": 1311
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ori/000514_ori.png",
                "caption": "Figure 3:The images display a visual comparison of two object detection models on Cardd dataset, DiffusionDet and our Model, for identifying car damage. The top row shows the original damaged car images. The middle row illustrates the heatmaps generated by the DiffusionDet model, which highlights areas it focuses on to detect damage. The bottom row presents the heatmaps from the Our Model combination, showing improved focus and accuracy in pinpointing the damaged regions.",
                "position": 1332
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ori/002169_ori.png",
                "caption": "",
                "position": 1343
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ori/002776_ori.png",
                "caption": "",
                "position": 1345
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ori/002879_ori.png",
                "caption": "",
                "position": 1347
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ori/003027_ori.png",
                "caption": "",
                "position": 1349
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/base/000514_gradcam_overlay.jpg",
                "caption": "",
                "position": 1359
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/base/002169_gradcam_overlay.png",
                "caption": "",
                "position": 1361
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/base/002776_gradcam_overlay.jpg",
                "caption": "",
                "position": 1363
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/base/002879_gradcam_overlay.jpg",
                "caption": "",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/base/003027_gradcam_overlay.jpg",
                "caption": "",
                "position": 1367
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ours/000514_gradcam_overlay.jpg",
                "caption": "",
                "position": 1377
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ours/002169_gradcam_overlay.jpg",
                "caption": "",
                "position": 1379
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ours/002776_gradcam_overlay.jpg",
                "caption": "",
                "position": 1381
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ours/002879_gradcam_overlay.jpg",
                "caption": "",
                "position": 1383
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/AS/ours/003027_gradcam_overlay.jpg",
                "caption": "",
                "position": 1385
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00578/loss.png",
                "caption": "Figure 4:Training loss curves comparing baseline DiffusionDet (blue) and C-DiffDet+ (orange) over 20,000 iterations.",
                "position": 1732
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000856_gt.jpg",
                "caption": "Figure 5:Qualitative comparison between ground truth annotations in the CarDD dataset and our modelâ€™s predictions, illustrating both detection errors and inconsistencies in the dataset annotations that limit precise evaluation.",
                "position": 1853
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000856_gt.jpg",
                "caption": "",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000869_gt.jpg",
                "caption": "",
                "position": 1860
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000909_gt.jpg",
                "caption": "",
                "position": 1864
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000856.jpg",
                "caption": "",
                "position": 1869
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000869.jpg",
                "caption": "",
                "position": 1873
            },
            {
                "img": "https://arxiv.org/html/2509.00578/figs/bad_pred/000909.jpg",
                "caption": "",
                "position": 1877
            }
        ]
    },
    {
        "header": "Appendix AExample Appendix Section",
        "images": []
    },
    {
        "header": "Appendix BComplete DiffusionDet Algorithm",
        "images": []
    },
    {
        "header": "Analysis of Global Context Encoder Feature Maps",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00578/x2.png",
                "caption": "Figure 6:Visualization of feature maps at each stage within the Global Context Encoder (GCE)",
                "position": 2507
            }
        ]
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]