[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06139/x1.png",
                "caption": "Figure 1:FlowRVS reformulates RVOS as a text-conditioned continuous flow, learning a velocity field via Flow Matching stabilized by boundary-biased time sampling in latent space.\nDuring inference, an ODE solver uses this field to deterministically deform the video latent to the target mask, this video to mask paradigm superior to noise-based or one-step prediction approaches.",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2510.06139/x2.png",
                "caption": "Figure 2:Repurposing a generative process for a discriminative task. Unlike standard T2V generation which maps noise to diverse videos (left), our method maps a complex video to a single mask (right). This transforms the process into a deterministic, convergent task where the text query is the crucial element that selects the precise target from the visual input (e.g., distinguishing the ‘smaller’ from the ‘bigger’ monkey).",
                "position": 197
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06139/x3.png",
                "caption": "Figure 3:Qualitative comparison on challenging temporal and linguistic reasoning. Prior paradigms struggle: VD-IT produces temporally unstable masks due to its frame-wise decoder, while ReferDINO fails to interpret long-range descriptions. Our method, FlowRVS, demonstrates superior temporal coherence and language grounding by leveraging an end-to-end generative process.",
                "position": 484
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AHyperparameters Settings",
        "images": []
    },
    {
        "header": "Appendix BVAE Reconstruction Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06139/x4.png",
                "caption": "Figure 4:Visualization of VAE reconstruction results",
                "position": 1277
            },
            {
                "img": "https://arxiv.org/html/2510.06139/x5.png",
                "caption": "Figure 5:visualization example of FlowRVS results on MeViS-Valid-u.",
                "position": 1287
            },
            {
                "img": "https://arxiv.org/html/2510.06139/x6.png",
                "caption": "Figure 6:visualization example of FlowRVS results on MeViS-Valid.",
                "position": 1290
            },
            {
                "img": "https://arxiv.org/html/2510.06139/x7.png",
                "caption": "Figure 7:visualization example of FlowRVS results on Ref-YouTube-VOS-Valid.",
                "position": 1293
            }
        ]
    },
    {
        "header": "Appendix CMore Qualitative Results",
        "images": []
    }
]