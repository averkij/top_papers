[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x1.png",
                "caption": "Figure 1:Overview of SEAL.\n(1) We begin with LoRA’s weightsA𝐴{A}italic_AandB𝐵{B}italic_B, plus non-trainable passportsC,Cp𝐶subscript𝐶𝑝{C},{C}_{p}italic_C , italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT.\n(2) During training,C𝐶{C}italic_CandCpsubscript𝐶𝑝{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTare inserted betweenB𝐵{B}italic_BandA𝐴{A}italic_A, forcing the model to rely on them and thus entangling the weights with the passports.\n(3) Afterward,C𝐶{C}italic_Cis factorized viaf⁢(C)=(C1,C2)𝑓𝐶subscript𝐶1subscript𝐶2f({C})=({C}_{1},{C}_{2})italic_f ( italic_C ) = ( italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT )and merged intoB𝐵{B}italic_BandA𝐴{A}italic_A, resulting in standard-looking LoRA weightsB′superscript𝐵′{B}^{\\prime}italic_B start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPTandA′superscript𝐴′{A}^{\\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Meanwhile,Cpsubscript𝐶𝑝{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTremains private for ownership verification.",
                "position": 214
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3SEAL: The Watermarking Scheme",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x2.png",
                "caption": "Figure 2:Negative log singular value (CDF), collection of top-32 singular values. LoRA (blue) vs. SEAL (orange)\nacross Llama-2, Mistral, and Gemma models.",
                "position": 395
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x3.png",
                "caption": "Figure 3:Pruning Attack. The x-axis represents the zeroing ratio of the smallest parameters ofℕ⁢(B′,A′)ℕsuperscript𝐵′superscript𝐴′\\mathbb{N}(B^{\\prime},A^{\\prime})blackboard_N ( italic_B start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )based on their L1 norms, the left y-axis shows the fidelity score on commonsense reasoning tasks, and the right y-axis displays the−log⁡(p-value)p-value-\\log(\\text{p-value})- roman_log ( p-value )on a log scale. If−log⁡(p-value)p-value-\\log(\\text{p-value})- roman_log ( p-value )isabove3.3 (i.e., p-value<5×10−4absent5superscript104<5\\times 10^{-4}< 5 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT), detecting the watermark succeeds. The graphs show that as the zeroing ratio increases, the fidelity score decreases.\nThis indicates the watermark remains detectable until99.9%of the weights are zeroed, which significantly degrades the host task’s performance.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2501.09284/x4.png",
                "caption": "Figure 4:Ambiguity Attacks. Fidelity score,MT(ℕ(A,B,Ct)M_{T}(\\mathbb{N}(A,B,C_{t})italic_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( blackboard_N ( italic_A , italic_B , italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ), as average accuracy on Commonsense Reasoning tasks,T𝑇Titalic_T, with the passportCtsubscript𝐶𝑡C_{t}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, which is the inference time passport. The x-axis represents the dissimilarity,γ𝛾\\gammaitalic_γ, whereCt=(1−γ)⁢Cp+γ⁢C~p⁢-advsubscript𝐶𝑡1𝛾subscript𝐶𝑝𝛾subscript~𝐶𝑝-advC_{t}=(1-\\gamma)C_{p}+\\gamma\\widetilde{C}_{p\\text{-adv}}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( 1 - italic_γ ) italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_γ over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPT.Cpsubscript𝐶𝑝{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTis the concealed passport, andC~p⁢-advsubscript~𝐶𝑝-adv\\widetilde{C}_{p\\text{-adv}}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPTis the adversary’ matrix. Whenγ>0.6𝛾0.6\\gamma>0.6italic_γ > 0.6, the difference between fidelity scores significantly drops below the threshold of the verification process,ϵTsubscriptitalic-ϵ𝑇\\epsilon_{T}italic_ϵ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, as shown in Table5.",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BTraining Process of SEAL",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x5.png",
                "caption": "Figure 6:KDE of−log⁡(σ)𝜎-\\log(\\sigma)- roman_log ( italic_σ )for LoRA vs. SEAL.\nWe extract the top-32 singular valuesσ𝜎\\sigmaitalic_σfrom each module of the finetunedΔ⁢WΔ𝑊\\Delta Wroman_Δ italic_W(for rank=32ℕ⁢(⋅)ℕ⋅\\mathbb{N}(\\cdot)blackboard_N ( ⋅ )) and plot−log⁡(σ)𝜎-\\log(\\sigma)- roman_log ( italic_σ )via a\nkernel density estimate (KDE).",
                "position": 2395
            }
        ]
    },
    {
        "header": "Appendix COn Forging Multiple Passports from a Single Factorization",
        "images": []
    },
    {
        "header": "Appendix DExtensions to Matmul-based LoRA Variants",
        "images": []
    },
    {
        "header": "Appendix EExtensions to Generalized Low-Rank Operators",
        "images": []
    },
    {
        "header": "Appendix FTraining Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x6.png",
                "caption": "Figure 7:Comparison of LoRA and SEAL in Text-to-Image Synthesis",
                "position": 3524
            }
        ]
    },
    {
        "header": "Appendix GAblation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x7.png",
                "caption": "Figure 8:Passport Example.Left: A 32×\\times×32 grayscale bitmap (cropped and downsampled\nfrom a YouTube clip333https://www.youtube.com/watch?v=2zHHkSu1br4)\nserves as our non-trainable passportC𝐶Citalic_C.Right: The passport partially recovered (from 10% zeroed SEAL weight on LLaMA-2-7B).",
                "position": 3746
            },
            {
                "img": "https://arxiv.org/html/2501.09284/x8.png",
                "caption": "Figure 9:Effect of passportC𝐶Citalic_Cstandard deviation (std) on SEAL weight.std=σ𝜎\\sigmaitalic_σ: Outputs are using only SEAL weight withoutC∼𝒩⁢(0,σ2)similar-to𝐶𝒩0superscript𝜎2C\\sim\\mathcal{N}(0,\\sigma^{2})italic_C ∼ caligraphic_N ( 0 , italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ),ℕ⁢(B,A,∅)ℕ𝐵𝐴\\mathbb{N}(B,A,\\emptyset)blackboard_N ( italic_B , italic_A , ∅ ). Vanilla SD 1.5: output from vanila Stable Diffusion 1.5 with same prompt.",
                "position": 3877
            }
        ]
    },
    {
        "header": "Appendix HExtending to Multiple Passports and Data-based Mappings",
        "images": []
    }
]