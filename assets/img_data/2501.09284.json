[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x1.png",
                "caption": "Figure 1:Overview of SEAL.\n(1) We begin with LoRAâ€™s weightsAğ´{A}italic_AandBğµ{B}italic_B, plus non-trainable passportsC,Cpğ¶subscriptğ¶ğ‘{C},{C}_{p}italic_C , italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT.\n(2) During training,Cğ¶{C}italic_CandCpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTare inserted betweenBğµ{B}italic_BandAğ´{A}italic_A, forcing the model to rely on them and thus entangling the weights with the passports.\n(3) Afterward,Cğ¶{C}italic_Cis factorized viafâ¢(C)=(C1,C2)ğ‘“ğ¶subscriptğ¶1subscriptğ¶2f({C})=({C}_{1},{C}_{2})italic_f ( italic_C ) = ( italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT )and merged intoBğµ{B}italic_BandAğ´{A}italic_A, resulting in standard-looking LoRA weightsBâ€²superscriptğµâ€²{B}^{\\prime}italic_B start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPTandAâ€²superscriptğ´â€²{A}^{\\prime}italic_A start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT. Meanwhile,Cpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTremains private for ownership verification.",
                "position": 214
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3SEAL: The Watermarking Scheme",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x2.png",
                "caption": "Figure 2:Negative log singular value (CDF), collection of top-32 singular values. LoRA (blue) vs.Â SEAL (orange)\nacross Llama-2, Mistral, and Gemma models.",
                "position": 395
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x3.png",
                "caption": "Figure 3:Pruning Attack. The x-axis represents the zeroing ratio of the smallest parameters ofâ„•â¢(Bâ€²,Aâ€²)â„•superscriptğµâ€²superscriptğ´â€²\\mathbb{N}(B^{\\prime},A^{\\prime})blackboard_N ( italic_B start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT )based on their L1 norms, the left y-axis shows the fidelity score on commonsense reasoning tasks, and the right y-axis displays theâˆ’logâ¡(p-value)p-value-\\log(\\text{p-value})- roman_log ( p-value )on a log scale. Ifâˆ’logâ¡(p-value)p-value-\\log(\\text{p-value})- roman_log ( p-value )isabove3.3 (i.e., p-value<5Ã—10âˆ’4absent5superscript104<5\\times 10^{-4}< 5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT), detecting the watermark succeeds. The graphs show that as the zeroing ratio increases, the fidelity score decreases.\nThis indicates the watermark remains detectable until99.9%of the weights are zeroed, which significantly degrades the host taskâ€™s performance.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2501.09284/x4.png",
                "caption": "Figure 4:Ambiguity Attacks. Fidelity score,MT(â„•(A,B,Ct)M_{T}(\\mathbb{N}(A,B,C_{t})italic_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( blackboard_N ( italic_A , italic_B , italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ), as average accuracy on Commonsense Reasoning tasks,Tğ‘‡Titalic_T, with the passportCtsubscriptğ¶ğ‘¡C_{t}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, which is the inference time passport. The x-axis represents the dissimilarity,Î³ğ›¾\\gammaitalic_Î³, whereCt=(1âˆ’Î³)â¢Cp+Î³â¢C~pâ¢-advsubscriptğ¶ğ‘¡1ğ›¾subscriptğ¶ğ‘ğ›¾subscript~ğ¶ğ‘-advC_{t}=(1-\\gamma)C_{p}+\\gamma\\widetilde{C}_{p\\text{-adv}}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( 1 - italic_Î³ ) italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_Î³ over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPT.Cpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTis the concealed passport, andC~pâ¢-advsubscript~ğ¶ğ‘-adv\\widetilde{C}_{p\\text{-adv}}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPTis the adversaryâ€™ matrix. WhenÎ³>0.6ğ›¾0.6\\gamma>0.6italic_Î³ > 0.6, the difference between fidelity scores significantly drops below the threshold of the verification process,ÏµTsubscriptitalic-Ïµğ‘‡\\epsilon_{T}italic_Ïµ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, as shown in Table5.",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BTraining Process of SEAL",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x5.png",
                "caption": "Figure 6:KDE ofâˆ’logâ¡(Ïƒ)ğœ-\\log(\\sigma)- roman_log ( italic_Ïƒ )for LoRA vs.Â SEAL.\nWe extract the top-32 singular valuesÏƒğœ\\sigmaitalic_Ïƒfrom each module of the finetunedÎ”â¢WÎ”ğ‘Š\\Delta Wroman_Î” italic_W(for rank=32â„•â¢(â‹…)â„•â‹…\\mathbb{N}(\\cdot)blackboard_N ( â‹… )) and plotâˆ’logâ¡(Ïƒ)ğœ-\\log(\\sigma)- roman_log ( italic_Ïƒ )via a\nkernel density estimate (KDE).",
                "position": 2395
            }
        ]
    },
    {
        "header": "Appendix COn Forging Multiple Passports from a Single Factorization",
        "images": []
    },
    {
        "header": "Appendix DExtensions to Matmul-based LoRA Variants",
        "images": []
    },
    {
        "header": "Appendix EExtensions to Generalized Low-Rank Operators",
        "images": []
    },
    {
        "header": "Appendix FTraining Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x6.png",
                "caption": "Figure 7:Comparison of LoRA and SEAL in Text-to-Image Synthesis",
                "position": 3524
            }
        ]
    },
    {
        "header": "Appendix GAblation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09284/x7.png",
                "caption": "Figure 8:Passport Example.Left: A 32Ã—\\timesÃ—32 grayscale bitmap (cropped and downsampled\nfrom a YouTube clip333https://www.youtube.com/watch?v=2zHHkSu1br4)\nserves as our non-trainable passportCğ¶Citalic_C.Right: The passport partially recovered (from 10% zeroed SEAL weight on LLaMA-2-7B).",
                "position": 3746
            },
            {
                "img": "https://arxiv.org/html/2501.09284/x8.png",
                "caption": "Figure 9:Effect of passportCğ¶Citalic_Cstandard deviation (std) on SEAL weight.std=Ïƒğœ\\sigmaitalic_Ïƒ: Outputs are using only SEAL weight withoutCâˆ¼ğ’©â¢(0,Ïƒ2)similar-toğ¶ğ’©0superscriptğœ2C\\sim\\mathcal{N}(0,\\sigma^{2})italic_C âˆ¼ caligraphic_N ( 0 , italic_Ïƒ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ),â„•â¢(B,A,âˆ…)â„•ğµğ´\\mathbb{N}(B,A,\\emptyset)blackboard_N ( italic_B , italic_A , âˆ… ). Vanilla SD 1.5: output from vanila Stable Diffusion 1.5 with same prompt.",
                "position": 3877
            }
        ]
    },
    {
        "header": "Appendix HExtending to Multiple Passports and Data-based Mappings",
        "images": []
    }
]