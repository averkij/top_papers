[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14699/fig/logo.png",
                "caption": "",
                "position": 60
            },
            {
                "img": "https://arxiv.org/html/2512.14699/x1.png",
                "caption": "",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14699/x2.png",
                "caption": "Figure 2:Overall Framework ofMemFlow,which is designed for interactive long video generation with both long-term consistency and efficiency.\nIn autoregressive generation, we conduct memory retrieval, updating, and selection sequentially before finally use it for synthesizing the incoming video chunk (Sec3.1). Given the current prompt and KV cache memory bank, we first use textual token from the prompt to query the memory for retrieving semantically aligned KV cache. After adding the prototypical KV cache of previous chunk to inject the latest context, the memory is updated for current chunk generation (Sec3.2). The updated memory is then combined with ”Frame Sink”-the KV cache from the first chunk-for the following Sparse Memory Activation. SMA filters the most relevant context for attention computation, improving the generation efficiency without sacrificing visual quality. (Sec3.3).",
                "position": 138
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14699/x3.png",
                "caption": "Table 2:Quantitative comparisons under single-prompt 5-second settingwith representative open-source video generation models of similar parameter sizes and resolutions. OurMemFlowperforms on par with other models on overall quality and has a clear advantage in semantic score attributed to textual retrieval-based memory.†denotes the scores reproduced by us.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2512.14699/x3.png",
                "caption": "Figure 3:Qualitative comparisons under multi-prompt 60-second settingwith representative long video generation models, whereMemFlowoutperforms other alternatives in narrative coherence and subject consistency, without drifting or duplicated characters.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2512.14699/x4.png",
                "caption": "Figure 4:Qualitative analysis of different memory mechanismsunder multi-prompt 60-second setting. “w/o Memory” means only attending to the local attention window, “Frame Sink” refers to keeping KV cache from the first chunk as memory, “NAM” adopts the whole memory bank without filtering, and “NAM+SMA” is our full model which compresses memory by relevance-gated selection.",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2512.14699/x5.png",
                "caption": "Figure 5:Quantitative analysis of different memory capacityunder multi-prompt 60-second setting. “w/o Memory” means only attending to the local attention window, “Frame Sink” refers to keeping KV cache from the first chunk as memory[yang2025longlive], “NAM” adopts the whole memory bank includingbblatent frames.",
                "position": 772
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]