[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08244/x1.png",
                "caption": "Figure 1:Cut2Next demonstrating versatile Next Shot Generation. The model produces cinematically coherent subsequent shots (bottom) adhering to diverse editing patterns (e.g., Shot/Reverse Shot, Cut-Out, Cutaway) specified alongside the input shots (upper).",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08244/x2.png",
                "caption": "Figure 2:Canonical cut-driven shot sequences(from CuratedCuts), their narrative functions, and the generation difficulties.Cut-In/Cut-Out: Emphasizes details or shifts focus; challenges models with drastic scale changes while maintaining subject consistency.Cutaway: Provides external or subjective context; demands generating novel yet semantically related content.Shot/Reverse Shot: Facilitates dialogue and reveals reactions; requires consistent character appearance and spatial logic across alternating viewpoints.Multi-Angle: Offers varied viewpoints; requires consistent rendering across significant visual transformations.",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08244/x3.png",
                "caption": "Figure 3:The data construction pipeline forRawCutsandCuratedCuts.",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2508.08244/x4.png",
                "caption": "Figure 4:Example of annotating one shot image pair by our Hierarchical Prompt Annotation.",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2508.08244/x5.png",
                "caption": "Figure 5:Architecture of Cut2Next. Individual prompts (Pc​o​n​di​n​d,Pt​g​ti​n​dP^{ind}_{cond},P^{ind}_{tgt}) and a relational prompt (Pr​e​lP^{rel}) are converted to textual embeddings by a shared text encoder. The conditional shotSc​o​n​dS_{cond}is encoded by a VAE into clean latents, while the target shotSt​g​tS_{tgt}is encoded and noised for training. These textual and visual tokens form the input to the Cut2Next (DiT-based) model. Our Context-Aware Condition Injection (CACI) module (center right) applies distinct conditioning to AdaLN layers based on token type. The Hierarchical Attention Mask (HAM) (far right) further refines information flow by defining specific attention patterns between different token segments.",
                "position": 183
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08244/x6.png",
                "caption": "Figure 6:Visual comparison of Cut2Next and IC-LoRA-Condiclora.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2508.08244/x7.png",
                "caption": "Figure 7:Training loss comparison on RawCuts. CACI (ours) shows improved convergence over SyncCond and CACI (cr​e​lc^{rel}withtt).",
                "position": 493
            }
        ]
    },
    {
        "header": "5Conclusion and limitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08244/x8.png",
                "caption": "Figure 8:Visual comparison of Cut2Next and Cut2Next (w/o relational prompt).",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2508.08244/x9.png",
                "caption": "Figure 9:Visual comparison of Cut2Next and Cut2Next (without pretraining on RawCuts dataset).",
                "position": 1274
            },
            {
                "img": "https://arxiv.org/html/2508.08244/x10.png",
                "caption": "Figure 10:More visual results from Cut2Nextdemonstrating performance across different editing patterns: Multi-Angle, cut-in/cut-out, shot/reverse shot, and cutaway. For each pair, the input shot image is shown above the generated subsequent shot. Prompts are omitted due to space limitations.",
                "position": 1277
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]