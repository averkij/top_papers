[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/pics/teaser.png",
                "caption": "",
                "position": 130
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/x1.png",
                "caption": "Figure 2:Some failure cases created by existing design models in real-world, multi-asset scenarios, producing severe misalignments and visual discord.",
                "position": 145
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/x2.png",
                "caption": "(a)Perturbed Supervised Fine-Tuning (PSFT)",
                "position": 197
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x2.png",
                "caption": "(a)Perturbed Supervised Fine-Tuning (PSFT)",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x3.png",
                "caption": "(b)Reinforcement Learning for Visual-Reality Alignment (RL-VRA)",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x4.png",
                "caption": "(c)Reinforcement Learning from Aesthetic Feedback (RLAF)",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/motivation_for_sft_cropped.jpg",
                "caption": "Figure 4:Geometric instability of text-based coordinate representations. (a)Euclidean Space:The ideal baseline, showing perfect, uniform geometry (det(S)≡1\\det(S)\\equiv 1). (b)Text-Based Space:Suffers from signal collapse (near-zerodet(S)\\det(S)) and geometric noise, creating a chaotic landscape unstable for optimization. (c)Reconstructed Space via Neighborhood Averaging:This method suppresses noise, recovering a smooth, uniform geometry that is far more stable than (b).",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x5.png",
                "caption": "Figure 5:Our motivation for visual-reality alignment and aesthetic feedback stems from the observation that design models frequently produce works that violate fundamental graphic design principles, as well as exhibit serious aesthetic flaws. We usered,green, andblueboxes to mark the error areas in the figure.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x6.png",
                "caption": "Figure 6:Overview of PosterCopilot’s Inference and Editing Pipeline.Thestandard inferenceandmulti-round editingpipelines are marked byblueandrednumbers, respectively. Before layout design, PosterCopilot can supplement new assets when design materials are insufficient.Generative Agentfirst processes user requirements, undergoes professional planning, and delivers complete assets.Design Masterthen generates optimal compositions based on the assets and requirements, ultimately rendering theDraft design.The draft design will be revised into thefinal designafter multiple rounds of editing by the collaboration of both generative agent and design master.",
                "position": 276
            }
        ]
    },
    {
        "header": "4Application",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/x7.png",
                "caption": "Figure 7:Poster generated from fully-provided assets by PosterCopilot.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x8.png",
                "caption": "Figure 8:Posters generated from insufficient assets by our PosterCopilot.",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x9.png",
                "caption": "Figure 9:Multi-round refinement for a single layer by our PosterCopilot.",
                "position": 423
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x10.png",
                "caption": "Figure 10:Multi-round refinement for theme switch by our PosterCopilot.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x11.png",
                "caption": "Figure 11:PosterCopilot intelligently reframes posters to new canvas sizes while maintaining layout harmony. All figures are scaled to a uniform height for presentation in this paper.",
                "position": 459
            }
        ]
    },
    {
        "header": "5Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/pics/data_pipeline.png",
                "caption": "Figure 12:Dataset construction pipeline for our PosterCopilot. We merged numerous scattered layers with OCR-based fine-granularity bounding box rather than simply parsing the original PSD file.",
                "position": 474
            }
        ]
    },
    {
        "header": "6Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/x12.png",
                "caption": "Figure 13:Results of User-study.",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x13.png",
                "caption": "Figure 14:Results of GPT-5 evaluation.",
                "position": 632
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Implementation details for three-stage training process",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/pics/para_psft.png",
                "caption": "Figure 15:Visualization of the hyperparameter analysis for the PSFT phase.",
                "position": 1628
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/para_psft.png",
                "caption": "",
                "position": 1631
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/para_psft_2.png",
                "caption": "",
                "position": 1635
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/para_psft_3.png",
                "caption": "",
                "position": 1639
            }
        ]
    },
    {
        "header": "10More Details For Evaluation Metrics",
        "images": []
    },
    {
        "header": "11Supplementary Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/pics/rlaf_1.png",
                "caption": "Figure 16:Poster samples generated by the design model via multiple inference runs. The IoU scores against the ground truth layout are 0.87, 0.43, and 0.21, respectively. Notably, despite the varying degrees of deviation from the ground truth, all three posters align well with human aesthetics.",
                "position": 2079
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/rlaf_1.png",
                "caption": "",
                "position": 2082
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/rlaf_2.png",
                "caption": "",
                "position": 2087
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/rlaf_3.png",
                "caption": "",
                "position": 2092
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x14.png",
                "caption": "Figure 17:Human evaluation comparison of design quality metrics across different stages of our training paradigm. PosterCopilot is trained via complete three stages.",
                "position": 2098
            }
        ]
    },
    {
        "header": "12More Details About Evaluation Procedure",
        "images": []
    },
    {
        "header": "13More Qualitative Comparisons",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04082/x15.png",
                "caption": "Figure 18:Visual comparison of poster composition results across all methods. Each column corresponds to a specific method, demonstrating its generation performance based on various user assets and prompts.",
                "position": 2133
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x15.png",
                "caption": "",
                "position": 2136
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x16.png",
                "caption": "",
                "position": 2141
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x17.png",
                "caption": "",
                "position": 2146
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x18.png",
                "caption": "",
                "position": 2151
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x19.png",
                "caption": "",
                "position": 2156
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x20.png",
                "caption": "(a)The first set of qualitative comparisons on single-layer editing between PosterCopilot and Nano-Banana.",
                "position": 2162
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x20.png",
                "caption": "",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x21.png",
                "caption": "(a)The first set of qualitative comparisons on single-layer editing between PosterCopilot and Nano-Banana.",
                "position": 2170
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x22.png",
                "caption": "",
                "position": 2176
            },
            {
                "img": "https://arxiv.org/html/2512.04082/x23.png",
                "caption": "(b)The second set of qualitative comparisons on single-layer editing between PosterCopilot and Nano-Banana.",
                "position": 2181
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/dataset_ar.png",
                "caption": "Figure 20:Key statistics of the PosterCopilot dataset.",
                "position": 2201
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/dataset_ar.png",
                "caption": "",
                "position": 2204
            },
            {
                "img": "https://arxiv.org/html/2512.04082/pics/dataset_total_layers.png",
                "caption": "",
                "position": 2209
            }
        ]
    },
    {
        "header": "14More details about PosterCopilot datasets",
        "images": []
    }
]