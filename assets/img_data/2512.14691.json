[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x1.png",
                "caption": "Figure 1:Overview of our proposedMulti-ModalGenerativeReasoning (MMGR) benchmark. MMGR assesses whether generative models—bothvideoandimage—can perform coherent reasoning acrossthreedomains: Abstract Reasoning, Embodied Navigation, and Physical Commonsense. Given an input image and a generation prompt, video models (Veo-3, Sora-2, Wan-2.2) produce multi-frame trajectories, while image models (Nano-Banana/Pro, GPT-4o-image, Qwen-image) generate single-frame solutions. A VLM-based evaluator (Gemini-2.5-Pro) then scores each output using structured criteria, including an overall primary metric. For a curated subset of samples, we additionally conduct human evaluations. The full pipeline enables fine-grained, domain-sensitive analysis of generative reasoning capabilities.",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x2.png",
                "caption": "Figure 2:Overview of the three domains in theMMGRbenchmark. MMGR evaluates multi-modal generative reasoning acrossDomain 1: Abstract Reasoning,Domain 2: Embodied Navigation, andDomain 3: Physical Commonsense. (1) Abstract Reasoning includes Maze Solving, Sudoku Solving, ARC-AGI, and Math Challenge tasks, which test logical, 2D spatial, and temporal reasoning. (2) Embodied Navigation spans four environment-conditioned tasks: Panoramic View Last-Mile Navigation, Top-down View Real-World Navigation, 3D Real-World Navigation, and Simultaneous Localization and Generation (SLAG). The four tasks probe 2D/3D spatial reasoning, physical scene understanding, and coherent temporal planning. (3) Physical Commonsense covers Physical Concept scenarios and Sports activities, evaluating whether models produce videos that follow intuitive physics such as force, momentum, rotation, material behavior, and continuous motion. Together, these domains provide a comprehensive testbed for assessing a model’s ability to generate physically plausible, spatially grounded, and logically coherent solutions.",
                "position": 557
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Overview",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/Interface/maze.png",
                "caption": "(a)Maze Navigation interface with failure mode detection (Maze Changed, Cross Wall) and navigation behavior metrics.",
                "position": 1047
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/Interface/maze.png",
                "caption": "(a)Maze Navigation interface with failure mode detection (Maze Changed, Cross Wall) and navigation behavior metrics.",
                "position": 1050
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/Interface/math.png",
                "caption": "(b)Math Reasoning interface with process correctness and outcome accuracy assessment.",
                "position": 1055
            }
        ]
    },
    {
        "header": "5Maze",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_easy_5x5_n008_var1_fixed_both_solution.png",
                "caption": "(a)Easy 5×\\times5 (c→\\rightarrowc)",
                "position": 1085
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_easy_5x5_n008_var1_fixed_both_solution.png",
                "caption": "(a)Easy 5×\\times5 (c→\\rightarrowc)",
                "position": 1107
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_easy_3x3_n006_var2_random_start_solution.png",
                "caption": "(b)Easy 3×\\times3 (r→\\rightarrowc)",
                "position": 1110
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_easy_5x5_n008_var3_random_end_solution.png",
                "caption": "(c)Easy 5×\\times5 (c→\\rightarrowr)",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_easy_4x4_n001_var4_random_both_solution.png",
                "caption": "(d)Easy 4×\\times15 (r→\\rightarrowr)",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_medium_9x9_n007_var1_fixed_both_solution.png",
                "caption": "(e)Medium 9×\\times9 (c→\\rightarrowc)",
                "position": 1119
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_medium_9x9_n003_var2_random_start_solution.png",
                "caption": "(f)Medium 9×\\times9 (r→\\rightarrowc)",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_medium_9x9_n007_var3_random_end_solution.png",
                "caption": "(g)Medium 9×\\times9 (c→\\rightarrowr)",
                "position": 1125
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_medium_8x8_n006_var4_random_both_solution.png",
                "caption": "(h)Medium 8×\\times8 (r→\\rightarrowr)",
                "position": 1128
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_hard_11x11_n001_var1_fixed_both_solution.png",
                "caption": "(i)Hard 11×\\times11 (c→\\rightarrowc)",
                "position": 1131
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_hard_13x13_n007_var2_random_start_solution.png",
                "caption": "(j)Hard 13×\\times13 (r→\\rightarrowc)",
                "position": 1134
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_hard_13x13_n007_var3_random_end_solution.png",
                "caption": "(k)Hard 13×\\times13 (c→\\rightarrowr)",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/maze/dfs_hard_13x13_n003_var4_random_both_solution.png",
                "caption": "(l)Hard 13×\\times13 (r→\\rightarrowr)",
                "position": 1140
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x3.png",
                "caption": "(a)Success and failure cases generated byNano-Banana. Solution paths are highlighted in blue.",
                "position": 1245
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x3.png",
                "caption": "(a)Success and failure cases generated byNano-Banana. Solution paths are highlighted in blue.",
                "position": 1248
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x4.png",
                "caption": "(b)Success cases generated byVeo-3. Solution paths are highlighted in blue.",
                "position": 1254
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x5.png",
                "caption": "(c)Failure cases generated byVeo-3. Solution paths are highlighted in blue.",
                "position": 1260
            }
        ]
    },
    {
        "header": "6Sudoku",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_easy_4x4_000.png",
                "caption": "(a)4×\\times4 (Easy)",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_easy_4x4_000.png",
                "caption": "(a)4×\\times4 (Easy)",
                "position": 1831
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_easy_4x4_000.png",
                "caption": "(b)4×\\times4 (Easy) Solution",
                "position": 1834
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_easy_9x9_050.png",
                "caption": "(c)9×\\times9 (Easy)",
                "position": 1837
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_easy_9x9_050.png",
                "caption": "(d)9×\\times9 (Easy) Solution",
                "position": 1840
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_medium_4x4_100.png",
                "caption": "(e)4×\\times4 (Medium)",
                "position": 1843
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_medium_4x4_100.png",
                "caption": "(f)4×\\times4 (Medium) Solution",
                "position": 1846
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_medium_9x9_150.png",
                "caption": "(g)9×\\times9 (Medium)",
                "position": 1849
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_medium_9x9_150.png",
                "caption": "(h)9×\\times9 (Medium) Solution",
                "position": 1852
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_hard_4x4_200.png",
                "caption": "(i)4×\\times4 (Hard)",
                "position": 1855
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_hard_4x4_200.png",
                "caption": "(j)4×\\times4 (Hard) Solution",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/sudoku_hard_9x9_250.png",
                "caption": "(k)9×\\times9 (Hard)",
                "position": 1861
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/sudoku/solution_hard_9x9_250.png",
                "caption": "(l)9×\\times9 (Hard) Solution",
                "position": 1864
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x6.png",
                "caption": "Figure 7:Case Study: Success and failure cases generated byNano-Banana.",
                "position": 1939
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x7.png",
                "caption": "Figure 8:Case Study: Failure cases generated byVeo-3with frame-wise analysis highlightingthreekey behaviors: positional bias, self-reflective edits, and temporal drift.",
                "position": 1942
            }
        ]
    },
    {
        "header": "7ARC-AGI",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x8.png",
                "caption": "Figure 9:Selected examples fromARC-AGI v1, illustrating both Match and Mismatch tasks across three difficulty levels: Easy, Medium, and Hard.",
                "position": 2695
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x9.png",
                "caption": "Figure 10:Selected examples fromARC-AGI v2, illustrating both Match and Mismatch tasks across three difficulty levels: Easy, Medium, and Hard.",
                "position": 2698
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x10.png",
                "caption": "(a)Inconsistent demonstration examples across video frames. The model fails to maintain the static demonstration inputs (E1–E4), with colors and patterns changing between frames. This behavior reflects a critical failure to preserve the given problem context.",
                "position": 2747
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x10.png",
                "caption": "(a)Inconsistent demonstration examples across video frames. The model fails to maintain the static demonstration inputs (E1–E4), with colors and patterns changing between frames. This behavior reflects a critical failure to preserve the given problem context.",
                "position": 2750
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x11.png",
                "caption": "(b)Progressive transformation of example demonstrations across frames. The examples (E1–E4) undergo unintended color and pattern evolution from Frame 1 to Frame 4, indicating a lack of temporal consistency in preserving the demonstration context during solution generation.",
                "position": 2756
            }
        ]
    },
    {
        "header": "8Math",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x12.png",
                "caption": "Figure 12:Examples from our selected five mathematical reasoning benchmarks.",
                "position": 4359
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/math/problem_0013_frame_0.png",
                "caption": "(a)t=0s",
                "position": 4397
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/math/problem_0013_frame_0.png",
                "caption": "(a)t=0s",
                "position": 4409
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/math/problem_0013_frame_2.png",
                "caption": "(b)t=2s",
                "position": 4412
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/math/problem_0013_frame_4.png",
                "caption": "(c)t=4s",
                "position": 4415
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/math/problem_0013_frame_6.png",
                "caption": "(d)t=6s",
                "position": 4418
            }
        ]
    },
    {
        "header": "9Embodied Navigation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x13.png",
                "caption": "Figure 14:Visual illustration of the four Embodied Navigation task settings: Panoramic View Last-Mile Navigation, Top-down View Real-World Navigation, 3D Real-World Navigation, and Simultaneous Localization and Generation (SLAG).",
                "position": 5519
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/embodied/last_mile/task01_wordcloud.png",
                "caption": "(a)Sample Vocabulary Distribution of Panoramic View Last-Mile Navigation.",
                "position": 5773
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/embodied/last_mile/task01_wordcloud.png",
                "caption": "(a)Sample Vocabulary Distribution of Panoramic View Last-Mile Navigation.",
                "position": 5776
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/embodied/3D/task03_wordcloud.png",
                "caption": "(b)Sample Vocabulary Distribution of 3D Real-World Navigation.",
                "position": 5781
            },
            {
                "img": "https://arxiv.org/html/2512.14691/Figures/embodied/embodied_metric_flow_v3.png",
                "caption": "Figure 16:Evaluation metrics flow. Decomposition of the three main metricsTask Completeness,Video Quality in Physical Understanding, andVideo Quality in Instruction Followinginto fine-grained components (e.g., Consistency, Physical Plausibility, Instruction Alignment) and their mapping to the corresponding navigation tasks.",
                "position": 5830
            }
        ]
    },
    {
        "header": "10Panoramic View Last-Mile Navigation (L.-M. Nav.)",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x14.png",
                "caption": "Figure 17:A successful case completed byVeo-3on thePanoramic View Last-Mile Navigationtask. The model navigates the final segment of the route from a first-person panoramic viewpoint, demonstrating coherent mental mapping, spatial awareness, and accurate localization needed to reach the precise target destination.",
                "position": 6337
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x15.png",
                "caption": "Figure 18:Qualitative Comparison on Panoramic View Last-Mile Navigation.We analyze three models (Veo-3, Sora-2, and Wan-2.2) navigating toward a red target. The figure highlights distinct failure modes:Veo-3suffers from agent inconsistency (hallucinating a second agent),Sora-2exhibits severe geometric and physical violations (style shift, clipping through railings), andWan-2.2struggles with scene stability (altering structural elements like doors and pillars) despite smooth agent motion.",
                "position": 7750
            }
        ]
    },
    {
        "header": "11Top-down View Real-World Navigation (T.V.R.-W.Nav.)",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x16.png",
                "caption": "Figure 19:Top-down View Real-World Navigationtask showing bird’s-eye view navigation. The model must interpret the abstract 2D map representation and plan a path from start to goal, demonstrating 2D spatial reasoning and temporal reasoning from a global perspective. A successful case completed by Veo-3 on the Top-down View Real-World Navigation task.",
                "position": 7792
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x17.png",
                "caption": "Figure 20:Qualitative Comparison on Top-down View Real-World Navigation. We analyze three models (Veo-3, Sora-2, and Wan-2.2) navigating toward a red target.",
                "position": 9133
            }
        ]
    },
    {
        "header": "123D Real-World Navigation (3D R.-W.Nav.)",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x18.png",
                "caption": "Figure 21:3D Real-World Navigationtask showing navigation through a realistic 3D environment. The model must navigate from a starting position to a goal location using visual cues from the third-person perspective. A successful case completed by Veo-3 on the 3D Real-World Navigation task.",
                "position": 9156
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x19.png",
                "caption": "Figure 22:Case Study for 3D Real-World Navigation comparing Veo-3, Sora-2, and Wan-2.2. The visualization highlights model-specific failure modes: Veo-3 achieves the destination despite physics violations (floor jumping) and scene alterations (staircase geometry); Sora-2 suffers from severe scene hallucination and style drift; and Wan-2.2 exhibits temporal inconsistency with drifting agents and moving furniture.",
                "position": 10559
            }
        ]
    },
    {
        "header": "13Simultaneous Localization and Generation (SLAG)",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x20.png",
                "caption": "Figure 23:Simultaneous Localization and Goal-reaching (SLAG) task requiring the model to simultaneously maintain spatial awareness of its position while navigating toward a goal in an unknown environment.",
                "position": 10627
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x21.png",
                "caption": "Figure 24:Case Study forSimultaneous Localization and Generation. The figure compares Veo-3, Sora-2, and Wan-2.2 on a split-screen navigation task requiring synchronization between a 3D view and a 2D map. Veo-3 achieves 3D target success but suffers from 2D trajectory misalignment. Sora-2 exhibits severe scene hallucination and physics violations (clipping through walls). Wan-2.2 demonstrates agent inconsistency (teleporting) and fails to reach the final target.",
                "position": 12247
            }
        ]
    },
    {
        "header": "14Physical Commonsense",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14691/x22.png",
                "caption": "Figure 25:Case Study: Success case generated byVeo-3. Physically Plausible Parachute Inflation.",
                "position": 12434
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x23.png",
                "caption": "Figure 26:Case Study: Failure case generated byVeo-3. Missing Solid–Solid Interaction in Coffee Grinding.",
                "position": 12437
            },
            {
                "img": "https://arxiv.org/html/2512.14691/x24.png",
                "caption": "Figure 27:Case Study: Failure case generated byVeo-3. Incorrect Angular Momentum Dynamics in Ballet Rotation.",
                "position": 12440
            }
        ]
    },
    {
        "header": "15Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]