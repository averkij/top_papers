[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15041/extracted/5873514/Images/pixelnerf.png",
                "caption": "Figure 1:Three versions of the same image extracted from different dataset processing pipelines.",
                "position": 639
            },
            {
                "img": "https://arxiv.org/html/2409.15041/extracted/5873514/Images/mvsnerf.png",
                "caption": "",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2409.15041/extracted/5873514/Images/original.png",
                "caption": "",
                "position": 643
            }
        ]
    },
    {
        "header": "3Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15041/x1.png",
                "caption": "Figure 2:Composition of high-level categories of objects in SpaRe.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2409.15041/extracted/5873514/Images/all_objects_033.png",
                "caption": "Figure 3:Examples of objects included in the SpaRe dataset. We provide objects from diverse categories with a scene placement similar to that of the DTU dataset.",
                "position": 671
            },
            {
                "img": "https://arxiv.org/html/2409.15041/extracted/5873514/Images/light_examples.png",
                "caption": "Figure 4:Varying illumination in the SpaRe dataset capture for three different scenes.",
                "position": 696
            }
        ]
    },
    {
        "header": "4Evaluation Protocol",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15041/x2.png",
                "caption": "Figure 5:A diagram marking the selection of input views among49494949available cameras. Input views are presented for the following scenes left to right:Rings,Recorder,Jenga. Selected input views are marked in blue.",
                "position": 756
            },
            {
                "img": "https://arxiv.org/html/2409.15041/x3.png",
                "caption": "",
                "position": 759
            },
            {
                "img": "https://arxiv.org/html/2409.15041/x4.png",
                "caption": "",
                "position": 760
            }
        ]
    },
    {
        "header": "5Baseline Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15041/x5.png",
                "caption": "Figure 6:Test set results on the SpaRe synthetic dataset for Track 1. Ground truth images are omitted to preserve benchmark integrity.",
                "position": 1228
            },
            {
                "img": "https://arxiv.org/html/2409.15041/x6.png",
                "caption": "Figure 7:Test set results on the DTU dataset for Track 1.",
                "position": 1231
            },
            {
                "img": "https://arxiv.org/html/2409.15041/x7.png",
                "caption": "Figure 8:Test set results on the synthetic dataset for Track 2. Ground truth images are omitted to preserve benchmark integrity.",
                "position": 1248
            },
            {
                "img": "https://arxiv.org/html/2409.15041/x8.png",
                "caption": "Figure 9:Test set results on the DTU dataset for Track 2.",
                "position": 1251
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]