[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01427/x1.png",
                "caption": "Figure 1:Falconer decomposes the instructionExtract all laptop prices from positive Amazon reviewsintoget_labelandget_spans, generates supervision for training the competent  proxy, and executes these primitives efficiently with small-model inference. On the right, we show how Falconer instantiates the subtasks: first classifying reviews as positive laptop reviews, then extracting the corresponding price spans. This design enables Falconer to combine the instruction-following ability of LLMs with the efficiency of small models.",
                "position": 95
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Falconer",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01427/x2.png",
                "caption": "Figure 2:Classification Pretraining",
                "position": 282
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01427/x3.png",
                "caption": "Table 3:Results on NER Datasets with Ground Truth labels",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2510.01427/x3.png",
                "caption": "Figure 3:Model Performance under different sample size",
                "position": 497
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01427/x4.png",
                "caption": "Figure 4:Performance on labeled dataset of Single Task w/ new metamodel and Consecutive Task w/ metamodel from previous task. Performance on unlabeled dataset of Single Task w/ new metamodel and Consecutive Task w/ metamodel from previous task",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2510.01427/x5.png",
                "caption": "Figure 5:Performance of different number of metamodel for different task type. Performance of different pretraining strategy",
                "position": 731
            },
            {
                "img": "https://arxiv.org/html/2510.01427/figs/strategy-2.png",
                "caption": "(a)Annotated span are marked as Bold",
                "position": 763
            },
            {
                "img": "https://arxiv.org/html/2510.01427/figs/strategy-2.png",
                "caption": "(a)Annotated span are marked as Bold",
                "position": 766
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACuckoo For Text classification",
        "images": []
    },
    {
        "header": "Appendix BGenerating Fine-tuning Samples",
        "images": []
    },
    {
        "header": "Appendix CSample Task",
        "images": []
    },
    {
        "header": "Appendix DHuman Proposed Task on Unlabeled Datasets",
        "images": []
    },
    {
        "header": "Appendix ESample Planning Code",
        "images": []
    }
]