[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04649/x1.png",
                "caption": "Figure 1:Outcome Accuracy vs. Human Rationale Consistency. Rationale consistency effectively discriminates among state-of-the-art models and detects deceptive alignment.",
                "position": 150
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04649/all-twemojis.pdf",
                "caption": "Table 1:Case example of the proposed evaluation.Note that both models make the same final decision, but o3-mini follows surface cues (formatting, emojis) with 0% Rationale Consistency, while o3 follows factual verification with 75%.The analysis provides a fine-grained breakdown for each reason.",
                "position": 173
            }
        ]
    },
    {
        "header": "2MetaJudge",
        "images": []
    },
    {
        "header": "3Rationale Consistency Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04649/x2.png",
                "caption": "(a)",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2602.04649/x2.png",
                "caption": "(a)",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2602.04649/x3.png",
                "caption": "(b)",
                "position": 429
            }
        ]
    },
    {
        "header": "4Generative Reward Modeling Based on Rationale Consistency",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04649/x4.png",
                "caption": "Figure 3:While outcome accuracy remains comparable across methods, the absence of rationale supervision causes a significant collapse in reasoning quality.",
                "position": 958
            },
            {
                "img": "https://arxiv.org/html/2602.04649/x5.png",
                "caption": "Figure 4:Degeneration and recovery of reasoning. Outcome-only training degrades rationales into superficial shortcuts: Criterion-Grounded (CG) and Generic/Style (GS). In contrast, our method successfully restores Evidence-Grounded (EG) reasoning to 98.7%.",
                "position": 961
            },
            {
                "img": "https://arxiv.org/html/2602.04649/x6.png",
                "caption": "Figure 5:Item-level rationale flaw rates for three settings. Outcome-only training amplifies these flaws, while adding rationale supervision reduces them across the board.",
                "position": 971
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Benchmark Construction",
        "images": []
    },
    {
        "header": "Appendix BCreative Writing Dataset Annotation Process",
        "images": []
    },
    {
        "header": "Appendix CMetaJudge",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04649/x7.png",
                "caption": "Figure 10:Outcome Accuracy vs. Rationale Consistency across four domains.",
                "position": 2105
            }
        ]
    },
    {
        "header": "Appendix DTraining and Evaluation Details",
        "images": []
    },
    {
        "header": "Appendix ECase Studies",
        "images": []
    },
    {
        "header": "Appendix FHuman Annotation: Recruitment, Compensation, Diversity, and Quality Control",
        "images": []
    },
    {
        "header": "Appendix GUse of AI Assistants in Programming and Manuscript Editing",
        "images": []
    }
]