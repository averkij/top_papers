[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x1.png",
                "caption": "Figure 1:ViDoRe V3 sample.Each query is annotated with the relevant pages, a document-grounded answer, bounding boxes localizing supporting evidence and modality labels for each bounding box. Documents are provided in image, text and PDF formats.",
                "position": 218
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x2.png",
                "caption": "Figure 2:Overview of the benchmark creation process.Queries are sourced from 3 streams:human extractive(using raw pages),human blind contextual(using summaries to mitigate extractive bias), andsynthetic blind contextual. For each query, a VLM pre-filtered subset of candidate pages is labeled by 1–3 human annotators that perform relevance scoring, bounding box localization and answer generation. A final response aggregation combines annotator answers into a single answer.",
                "position": 227
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Creation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x3.png",
                "caption": "Figure 3:Query Type Distribution per Domain",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2601.08620/",
                "caption": "Figure 4:Content Type Distribution per Domain",
                "position": 368
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x5.png",
                "caption": "Figure 5:ColEmbed-3B-v2 NDCG@10 by query type and format.",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x6.png",
                "caption": "Figure 6:ColEmbed-3B-v2 NDCG@10 by modality.",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x7.png",
                "caption": "Figure 7:ColEmbed-3B-v2 NDCG@10 by number of annotated pages.",
                "position": 750
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical considerations",
        "images": []
    },
    {
        "header": "Detailed Contributions",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x8.png",
                "caption": "Figure 8:Examples from the ViDoRe V3 datasets.Featuring varied query types and visually rich document formats across multiple domains, the benchmark captures the complexity of real-world retrieval scenarios.",
                "position": 1968
            }
        ]
    },
    {
        "header": "Appendix BSupplementary benchmark details",
        "images": []
    },
    {
        "header": "Appendix CAnnotator pool and training details",
        "images": []
    },
    {
        "header": "Appendix DSupplementary agreement metrics",
        "images": []
    },
    {
        "header": "Appendix ESupplementary retrieval details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x9.png",
                "caption": "Figure 9:UpSet plot illustrating the distribution and intersection of query types in ViDoRe V3.The horizontal bars on the left display the total count of queries for each individual type. The vertical bars at the top represent the frequency of specific combinations (intersections), as indicated by the connected dots in the matrix below. WhileExtractivequeries are the most prevalent overall,Open Endedqueries form the dominant unique category. Complex dependencies are evident in the frequent intersection ofEnumerativeandExtractive types, indicating a substantial subset of queries requiring list-based fact retrieval.",
                "position": 2185
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x10.png",
                "caption": "Figure 10:Query type distribution by generation method.",
                "position": 2427
            }
        ]
    },
    {
        "header": "Appendix FColEmbed-3B-v2 performance breakdown",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x11.png",
                "caption": "Figure 11:Average number of annotated pages by query type.",
                "position": 3231
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x12.png",
                "caption": "Figure 12:ColEmbed-3B-v2 NDCG@10 by number of annotated pages and query type.",
                "position": 3234
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x13.png",
                "caption": "Figure 13:Lift of query types by content type.Each cell shows the ratio of observed query type frequency to baseline frequency for a given content type. Values >1 indicate over-representation (e.g., tables appear 2.15× more in numerical queries than expected), while values <1 indicate under-representation.",
                "position": 3343
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x14.png",
                "caption": "Figure 14:Residuals from additive performance model.Each cell shows the difference between observed NDCG@10 and the value predicted by an additive model of query type and content type main effects. Values near zero (white) indicate no interaction; positive values (red) indicate better-than-expected performance for that combination; negative values (blue) indicate worse-than-expected.",
                "position": 3346
            }
        ]
    },
    {
        "header": "Appendix GBounding box annotations",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x15.png",
                "caption": "Figure 15:Model bounding box localization performance. Each F1 score measures the zone-based overlap between model-generated bounding boxes and human annotations, using the annotator yielding the highest F1.",
                "position": 3420
            }
        ]
    },
    {
        "header": "Appendix HFinal answer evaluation",
        "images": []
    },
    {
        "header": "Appendix IVisual grounding examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08620/x16.png",
                "caption": "Figure 16:Visual grounding comparative examples for Qwen3-VL-30B-A3B.Each panel shows a document page with Qwen3-VL’s predicted bounding boxes (solid magenta) and human bounding boxes (dashed blue and green, one color per annotator). Corresponding datasets and queries: (a) finance_en: What was the average daily Value at Risk (VaR) for Goldman Sachs during 2024?, (b) finance_en: List the 3 components of regulatory capital under Basel III, and determine the role of each component., (c) hr_en: Analyze how full-time employment among returning health workers evolved in the Netherlands and Italy from 2018 to 2023, and describe the differences in their employment trends., (d) finance_fr: Croissance Mode Maroquinerie vs Vins Spiritueux 2023 performance",
                "position": 3567
            },
            {
                "img": "https://arxiv.org/html/2601.08620/x17.png",
                "caption": "Figure 17:Visual grounding comparative examples for Gemini 3 Pro.Each panel shows a document page with Gemini’s predicted bounding boxes (solid magenta) and human bounding boxes (dashed blue and green, one color per annotator). Corresponding datasets and queries: (a) finance_en: What was the average daily Value at Risk (VaR) for Goldman Sachs during 2024?, (b) finance_en: List the 3 components of regulatory capital under Basel III, and determine the role of each component., (c) hr_en: Analyze how full-time employment among returning health workers evolved in the Netherlands and Italy from 2018 to 2023, and describe the differences in their employment trends., (d) finance_fr: Croissance Mode Maroquinerie vs Vins Spiritueux 2023 performance",
                "position": 3570
            }
        ]
    },
    {
        "header": "Appendix JInstructions given to Annotators",
        "images": []
    },
    {
        "header": "Appendix KPrompts",
        "images": []
    }
]