[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x1.png",
                "caption": "Figure 1:This work presents a learnable approach for pruning the depth of pre-trained diffusion transformers. Our method simultaneously optimizes a differentiable sampling process of layer masks and a weight update to identify a highly recoverable solution, ensuring that the pruned model maintains competitive performance after fine-tuning.",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x2.png",
                "caption": "Figure 2:The proposed TinyFusion method learns to perform a differentiable sampling of candidate solutions, jointly optimized with a weight update to estimate recoverability. This approach aims to increase the likelihood of favorable solutions that ensure strong post-fine-tuning performance. After training, local structures with the highest sampling probabilities are retained.",
                "position": 147
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x3.png",
                "caption": "Figure 3:An example of forward propagation with differentiable pruning maskmisubscriptùëöùëñm_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTand LoRA for recoverability estimation.",
                "position": 266
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x4.png",
                "caption": "Figure 4:Depth pruning closely aligns with the theoretical linear speed-up relative to the compression ratio.",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x5.png",
                "caption": "Figure 5:Distribution of calibration loss through random sampling of candidate models. The proposed learnable method achieves the best post-fine-tuning FID yet has a relatively high initial loss compared to other baselines.",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x6.png",
                "caption": "Figure 6:Visualization of the 2:4 decisions in the learnable pruning, with the confidence level of each decision highlighted through varying degrees of transparency. More visualization results for 1:2 and 7:14 schemes are available in the appendix.",
                "position": 949
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x7.png",
                "caption": "Figure 7:Images generated by TinyDiT-D14 on ImageNet 224√ó\\times√ó224, pruned and distilled from a DiT-XL/2.",
                "position": 952
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x8.png",
                "caption": "(a)DiT-XL/2 (Teacher)",
                "position": 969
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x8.png",
                "caption": "(a)DiT-XL/2 (Teacher)",
                "position": 972
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x9.png",
                "caption": "(b)TinyDiT-D14 (Student)",
                "position": 978
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x10.png",
                "caption": "Figure 9:1:2 Pruning Decisions",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x11.png",
                "caption": "",
                "position": 1835
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x12.png",
                "caption": "",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x13.png",
                "caption": "Figure 12:Learnable depth pruning on a local block",
                "position": 1842
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x14.png",
                "caption": "Figure 13:Masked knowledge distillation with 2:4 blocks.",
                "position": 1845
            }
        ]
    },
    {
        "header": "7Visualization of Pruning Decisions",
        "images": []
    },
    {
        "header": "8Details of Masked Knowledge Distillation",
        "images": []
    },
    {
        "header": "9Analytical Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x15.png",
                "caption": "Figure 14:FID and training steps.",
                "position": 2045
            }
        ]
    },
    {
        "header": "10Visulization",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01199/x16.png",
                "caption": "Figure 15:Generated images from TinySiT-D14",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2412.01199/x17.png",
                "caption": "",
                "position": 2118
            }
        ]
    },
    {
        "header": "11Limitations",
        "images": []
    }
]