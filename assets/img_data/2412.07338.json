[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.07338/extracted/6058375/img/contextual-counterspeech.png",
                "caption": "Figure 1.Current AI-generated counterspeech only leverages the content of the toxic message. Here, we generate contextualized counterspeech that also leverages information about the community, the conversation, and the moderated user to craft more persuasive responses.",
                "position": 149
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Problem definition",
        "images": []
    },
    {
        "header": "4.Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.07338/extracted/6058375/img/factors.png",
                "caption": "Figure 2.Algorithmic evaluation results for each factor. For each factor (yaxis) and indicator (panels), the teal dot shows the mean value of the indicator when the factor is used in the evaluated configurations, while the sand dot indicates the mean value of the indicator when the factor is not used. Arrows specify whether largerâ†‘â†‘\\uparrowâ†‘or smallerâ†“â†“\\downarrowâ†“scores are better.",
                "position": 479
            }
        ]
    },
    {
        "header": "5.Data",
        "images": []
    },
    {
        "header": "6.Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.07338/x1.png",
                "caption": "Figure 3.Human evaluation results (non-contextualcondition). Effect sizes and confidence intervals of the scores assigned to several configurations compared to the baseline. Statistical significance: ***:p<0.01ð‘0.01p<0.01italic_p < 0.01.",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2412.07338/x2.png",
                "caption": "Figure 4.Human evaluation results (contextualcondition). Effect sizes and confidence intervals of the scores assigned to several configurations compared to the baseline. Statistical significance: ***:p<0.01ð‘0.01p<0.01italic_p < 0.01, **:p<0.05ð‘0.05p<0.05italic_p < 0.05, *:p<0.1ð‘0.1p<0.1italic_p < 0.1.",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2412.07338/",
                "caption": "Figure 5.Differences in human evaluation results between thecontextualandnon-contextualconditions. Statistical significance: ***:p<0.01ð‘0.01p<0.01italic_p < 0.01, **:p<0.05ð‘0.05p<0.05italic_p < 0.05, *:p<0.1ð‘0.1p<0.1italic_p < 0.1.",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2412.07338/extracted/6058375/img/evaluation_rankings.png",
                "caption": "Figure 6.Aggregated rankings of the selected configurations, based on algorithmic and human evaluations.",
                "position": 980
            }
        ]
    },
    {
        "header": "7.Discussion and Conclusions",
        "images": []
    },
    {
        "header": "8.Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.07338/x4.png",
                "caption": "Figure 7.Human evaluation results (non-contextualcondition) based on answers from those participants who reported using social media â€œvery oftenâ€. Statistical significance: ***:p<0.01ð‘0.01p<0.01italic_p < 0.01, **:p<0.05ð‘0.05p<0.05italic_p < 0.05.",
                "position": 2459
            }
        ]
    },
    {
        "header": "Appendix APrompts",
        "images": []
    },
    {
        "header": "Appendix BCrowdsourcing questionnaire",
        "images": []
    },
    {
        "header": "Appendix CCounterspeech examples",
        "images": []
    }
]