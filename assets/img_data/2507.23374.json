[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23374/x1.png",
                "caption": "Figure 1:NeRF-GS establishes a bridge of communication between NeRF and 3DGS, leveraging information sharing, modeling of distinct characteristics, and joint optimization to enable 3DGS to achieve higher fidelity representation. In this case, NeRF-GS outperforms the vanilla 3DGS by 1.8dB in PSNR.",
                "position": 77
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23374/x2.png",
                "caption": "Figure 2:Overview of NeRF-GS. (a) We first pretrain a Hash-based NeRF network to acquire continuous spatial encoding capabilities and implicit scene representation.\n(b) Utilizing the preliminary scene carved by NeRF, we resample rays corresponding to image edges to obtain potential Gaussian positions, facilitating Gaussian initialization.\n(c) During joint optimization, the GS branch queries corresponding featuresùêü\\mathbf{f}bold_ffrom the Hash grid‚Ñã\\mathcal{H}caligraphic_Hfor each Gaussian sphere. These features, combined with positionsùê©\\mathbf{p}bold_pand their respective residual terms (Œî‚Äãùêü,Œî‚Äãùê©\\Delta\\mathbf{f},\\Delta\\mathbf{p}roman_Œî bold_f , roman_Œî bold_p), decode additional Gaussian attributesùíú\\mathcal{A}caligraphic_A, including color, opacity, scale, and rotation vectors. For the NeRF branch, rendering is exclusively performed on rays (GS-Rays) passing through important Gaussian spheres within the view frustum. The two branches are aligned by opacity and RGB values (‚Ñíjointop,‚Ñíjointrgb\\mathcal{L}_{\\text{joint}}^{\\text{op}},\\mathcal{L}_{\\text{joint}}^{\\text{rgb}}caligraphic_L start_POSTSUBSCRIPT joint end_POSTSUBSCRIPT start_POSTSUPERSCRIPT op end_POSTSUPERSCRIPT , caligraphic_L start_POSTSUBSCRIPT joint end_POSTSUBSCRIPT start_POSTSUPERSCRIPT rgb end_POSTSUPERSCRIPT), further supervised by reconstruction(‚Ñígs,‚Ñínerf\\mathcal{L}_{\\text{gs}},\\mathcal{L}_{\\text{nerf}}caligraphic_L start_POSTSUBSCRIPT gs end_POSTSUBSCRIPT , caligraphic_L start_POSTSUBSCRIPT nerf end_POSTSUBSCRIPT), and residual regularization (‚Ñíregfea,‚Ñíregpos\\mathcal{L}_{\\text{reg}}^{\\text{fea}},\\mathcal{L}_{\\text{reg}}^{\\text{pos}}caligraphic_L start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fea end_POSTSUPERSCRIPT , caligraphic_L start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT start_POSTSUPERSCRIPT pos end_POSTSUPERSCRIPT). Simultaneously, we leverage ray attributes from the NeRF branch along with gradient information from the GS branch to achieve adaptive control over Gaussian spheres. The purple dashed box marks the parameters to be trained.",
                "position": 135
            }
        ]
    },
    {
        "header": "4NeRF-GS",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23374/x3.png",
                "caption": "Figure 3:Qualitative comparison on real-world datasets. The numbers indicate the PSNR. Our method demonstrates a significant advantage over 3DGS and its variants, achieving a more faithful representation of scene details.",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2507.23374/x4.png",
                "caption": "Figure 4:Qualitative comparison under 12 input views on the Blender dataset. The numbers indicate the PSNR.",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2507.23374/x5.png",
                "caption": "Figure 5:Impact of feature share and joint optimization on sparse view scenes. These two key designs enable mutual regularization constraints between NeRF and GS branches, significantly improving the visual quality of NeRF-GS in sparse views.",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2507.23374/x6.png",
                "caption": "Figure 6:Visualization of position residuals. The points represent the initial Gaussian positions, with the top 20% of points having the largest optimized residuals highlighted in red. We compare this with the results obtained by fixed Gaussian positions during training, demonstrating the importance of the residual vectors for personalized adaptation in the GS branch.",
                "position": 626
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23374/x7.png",
                "caption": "",
                "position": 1815
            },
            {
                "img": "https://arxiv.org/html/2507.23374/x8.png",
                "caption": "Figure 8:Comparison of initialization with RadSplat. NeRF-GS focuses more on the contours of the scene during ray sampling, alleviating the burden of position optimization in the GS branch while achieving superior visual results in regions with complex textures.",
                "position": 1824
            },
            {
                "img": "https://arxiv.org/html/2507.23374/x9.png",
                "caption": "Figure 9:Impact of joint optimization on the NeRF branch. The dashed line indicates the mean PSNR. Given equivalent training iterations, the NeRF obtained through NeRF-GS outperforms training this NeRF independently. This demonstrates that dual-branch training not only benefits the GS branch but also enhances the performance of the NeRF branch.",
                "position": 1827
            }
        ]
    },
    {
        "header": "8Analysis of Gaussian Adaptive Control from NeRF Branch",
        "images": []
    },
    {
        "header": "9Analysis of Edge-based Initialization",
        "images": []
    },
    {
        "header": "10Analysis of NeRF Branch Performance",
        "images": []
    },
    {
        "header": "11Additional Ablation Studies",
        "images": []
    },
    {
        "header": "12Per-scene Breakdown Results of NeRF-GS",
        "images": []
    }
]