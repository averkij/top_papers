[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Motivation Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16625/x1.png",
                "caption": "Figure 2:Attack results. Standard attack (middle) only produces re-lighting artifacts, while attention intervention (right) successfully detaches the context.",
                "position": 270
            }
        ]
    },
    {
        "header": "4DeContext",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16625/x2.png",
                "caption": "Figure 3:Overview of our DeContext pipeline. Given a prompt, timestep, noisy target, and context image, DeContext perturbs the context to suppress its attention in the diffusion model. Iterative gradient updates minimize attention activation, detaching the context from influencing generation.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x3.png",
                "caption": "Figure 4:Time-wise gradients analysis. Gradients of context image dominate at high timesteps (early denoising).",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x4.png",
                "caption": "(a)Before attack",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x4.png",
                "caption": "(a)Before attack",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x5.png",
                "caption": "(b)After attack",
                "position": 396
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x6.png",
                "caption": "Figure 6:Defense Comparison. Previous attacks on T2I fine-tuned models and I2I models introduce visual artifacts in the generated images, whereas DeContext effectively removes context identity while preserving high visual quality.",
                "position": 409
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16625/x7.png",
                "caption": "Figure 7:Qualitative results on Step1X-Edit.",
                "position": 1154
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BExtension Experiments on Items",
        "images": []
    },
    {
        "header": "Appendix CUser Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16625/x8.png",
                "caption": "Figure 8:User Study.",
                "position": 1923
            }
        ]
    },
    {
        "header": "Appendix DDiscussion and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16625/x9.png",
                "caption": "Figure 9:Failure Case with the prompt “Transform this image to mountain hiking scene, change the person’s pose to climbing stance, add backpack and snow peaks.”",
                "position": 1940
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x10.png",
                "caption": "Figure 10:Defense on human portraits.",
                "position": 1950
            },
            {
                "img": "https://arxiv.org/html/2512.16625/x11.png",
                "caption": "Figure 11:Defense on item images.",
                "position": 1953
            }
        ]
    },
    {
        "header": "Appendix EAdditional Qualitative Results",
        "images": []
    }
]