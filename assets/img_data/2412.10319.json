[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x1.png",
                "caption": "Figure 1:KV Cache lifecycle.\nPrior benchmarks focus on single-request, while real-world applications reuse KV cache across requests. We proposeSCBenchand categorize long-context methods into KV Cache Generation, Compression, Retrieval, and Loading from a KV-cache-centric perspective.",
                "position": 119
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x2.png",
                "caption": "(a)Two Shared Context Modes",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x2.png",
                "caption": "(a)Two Shared Context Modes",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x3.png",
                "caption": "(b)Overview of SCBench",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x4.png",
                "caption": "(a)Performance Across Different Requests",
                "position": 156
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x4.png",
                "caption": "(a)Performance Across Different Requests",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x5.png",
                "caption": "(b)Performance in Different Abilities",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x6.png",
                "caption": "Figure 4:Performance of various long-context methods at different compression rates on SCBench using Llama-3.1-8B(Dubey etÂ al.,2024).",
                "position": 175
            }
        ]
    },
    {
        "header": "2A KV Cache-Centric Perspective on Long-Context Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x7.png",
                "caption": "Figure 5:The sparse attention methods framework.",
                "position": 464
            }
        ]
    },
    {
        "header": "3Benchmark Building",
        "images": []
    },
    {
        "header": "4Experiments & Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x8.png",
                "caption": "(a)String Retrieval",
                "position": 1852
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x8.png",
                "caption": "(a)String Retrieval",
                "position": 1855
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x9.png",
                "caption": "(b)Semantic Retrieval",
                "position": 1860
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x10.png",
                "caption": "(c)Global Information",
                "position": 1866
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x11.png",
                "caption": "(a)Critical KVs Vary Across Queries",
                "position": 1885
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x11.png",
                "caption": "(a)Critical KVs Vary Across Queries",
                "position": 1888
            },
            {
                "img": "https://arxiv.org/html/2412.10319/x12.png",
                "caption": "(b)Attention Map of Retr.KV Across Turns",
                "position": 1894
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACompared to Prior Long-Context Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/extracted/6066545/figures/mt-budget.png",
                "caption": "Figure 8:Hyper-parameters analysis: averaged performance of efficient long-context methods with different computing budgets under the multi-turn mode of SCBench. The input length is 128K, meaning that 4K, 8K, 16K, 32K, and 64K correspond to sparsity budgets of 1/32, 1/16, 1/8, 1/4, and 1/2, respectively.",
                "position": 3952
            },
            {
                "img": "https://arxiv.org/html/2412.10319/extracted/6066545/figures/scdq-budget.png",
                "caption": "",
                "position": 3957
            }
        ]
    },
    {
        "header": "Appendix BHyper-Parameters of Efficient Long-Context Methods",
        "images": []
    },
    {
        "header": "Appendix CExperiment Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.10319/x13.png",
                "caption": "Figure 10:Performance of different long-context methods across various turns in Multi-tasking tasks on SCBench. The results are averaged across all tested base LLMs.",
                "position": 4550
            }
        ]
    },
    {
        "header": "Appendix EError Propagation using Generation as Context.",
        "images": []
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]