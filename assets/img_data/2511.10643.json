[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10643/x1.png",
                "caption": "",
                "position": 128
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x2.png",
                "caption": "",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x3.png",
                "caption": "Figure 1:Comparison between GAD and sequence-level knowledge distillation (SeqKD;skd) trained on LMSYS-Chat[lmsys]dataset, evaluated by averaged GPT-4o scores.Left: Results on the LMSYS-Chat test set.Right: Average performance across Dolly[dolly], SelfInst[self_inst], and Vicuna[vicuna]datasets.",
                "position": 144
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10643/x4.png",
                "caption": "Figure 2:Training procedure of GAD. The student (generator) learns to generate responses that maximize the score assigned by the discriminator. The discriminator is trained with Bradley-Terry loss to assign a lower score to the student than the teacher, learning to distinguish between them. Together, they form a two-player minimax game in an adversarial learning framework.",
                "position": 213
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10643/x5.png",
                "caption": "Figure 3:Human evaluation results on theLMSYS-Chat-1M-Cleantest set. We compare GAD to the instruct model before distillation and the model fine-tuned with SeqKD.",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x6.png",
                "caption": "Figure 4:Overlap of local patterns between the student and the teacher. SeqKD tends to overfit to local patterns of the teacher.",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x6.png",
                "caption": "Figure 4:Overlap of local patterns between the student and the teacher. SeqKD tends to overfit to local patterns of the teacher.",
                "position": 614
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x7.png",
                "caption": "Figure 5:Black-box distillation on toy data. GAD learns reachable modes from the teacher while SeqKD aims to cover all the modes.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2511.10643/x8.png",
                "caption": "Figure 6:Off-policy discriminator suffers from reward hacking, whereas on-policy discriminator remains stable over thousands of training steps.",
                "position": 643
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Results",
        "images": []
    }
]