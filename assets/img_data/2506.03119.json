[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03119/x1.png",
                "caption": "Figure 1:Keyframe Interpolation with Different Strategies.(a) Interpolation using I2V models without intermediate guidance often yields implausible or distorted frames, especially under large motion or occlusion.\n(b) Skeleton-guided interpolation offers structural cues but lacks geometric detail, resulting in unrealistic body shape and appearance.\n(c)Our PoseFuse3D-KIemploys dense human-centric guidance, enabling temporally coherent and visually plausible interpolations.",
                "position": 99
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03119/x2.png",
                "caption": "Figure 2:Model Architecture.Our PoseFuse3D-KI framework, as shown in (a), comprises a video diffusion model (VDM) and a novel control model, PoseFuse3D. The PoseFuse3D model extracts rich features from both 3D and 2D control signals and fuses them into a unified representation to guide the VDM. The key component of PoseFuse3D is the SMPL-X encoder as illustrated in (b), which providesexplicit 3D signal features. Specifically, the SMPL-X encoder first extracts 3D information from the SMPL-X model with 2D correspondences via projection. The 3D and 2D information is then encoded in parallel. With features of 2D correspondences, 3D information is aggregated onto the 2D image plane using attention mechanisms. The aggregated features are subsequently processed to produce the final featureS3‚Å¢DsuperscriptùëÜ3ùê∑S^{3D}italic_S start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT.",
                "position": 173
            }
        ]
    },
    {
        "header": "4The CHKI-Video Dataset",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03119/x3.png",
                "caption": "Figure 3:Qualitative Results of Different 3D Control Strategies.We use red circles to highlight regions where the 3D controls and our strategy significantly improve the interpolation quality.",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2506.03119/x4.png",
                "caption": "Figure 4:Qualitative Comparisons with State-of-The-Art Methods.",
                "position": 583
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03119/x5.png",
                "caption": "Figure 5:Qualitative Results of In-the-wild Control and Keyframe Interpolation.",
                "position": 1352
            },
            {
                "img": "https://arxiv.org/html/2506.03119/x6.png",
                "caption": "Figure 6:Qualitative Comparisons on FCVG-Test-HC.",
                "position": 1461
            },
            {
                "img": "https://arxiv.org/html/2506.03119/x7.png",
                "caption": "Figure 7:Additional Qualitative Results on CHKI-Video.",
                "position": 1627
            }
        ]
    },
    {
        "header": "7Appendix",
        "images": []
    }
]