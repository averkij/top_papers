[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20285/extracted/6483000/Mask_QA/fig/tongyi.jpg",
                "caption": "",
                "position": 137
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20285/x1.png",
                "caption": "Figure 1:Overview ofMaskSearch, a pre-training framework to incentivize the agentic RAG capabilities of LLMs. Based on the Retrieval-Augmented Mask Prediction (RAMP) task, models can be trained via SFT or RL to acquire generalizable abilities before downstream task training.",
                "position": 157
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MaskSearch",
        "images": []
    },
    {
        "header": "4Experiment Setup",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20285/x2.png",
                "caption": "Figure 2:Scaling Performance of SFT with respect to training steps on RAMP. The results obtained at training step 0 align precisely with those of theDirect SFTbaseline, which is directly fine-tuned on the 58K CoT trajectories derived from HotpotQA.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x3.png",
                "caption": "Figure 3:Performance on the dev set while finetuning with varying numbers of masks.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x3.png",
                "caption": "Figure 3:Performance on the dev set while finetuning with varying numbers of masks.",
                "position": 786
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20285/x4.png",
                "caption": "Figure 4:Exploring RAMP with PPL-based masking strategy. The subfigure (a) illustrates the computation of perplexity for the unmasked spans in each round. The subfigure (b) indicates the effect of the PPL-based masking strategy on downstream test sets along with CL.",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x5.png",
                "caption": "(a)Response Length",
                "position": 880
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x5.png",
                "caption": "(a)Response Length",
                "position": 883
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x6.png",
                "caption": "(b)Token-level Recall",
                "position": 888
            },
            {
                "img": "https://arxiv.org/html/2505.20285/x7.png",
                "caption": "(c)Model-based Score",
                "position": 893
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Settings",
        "images": []
    },
    {
        "header": "Appendix BDetailed Comparison with Existing RALMs",
        "images": []
    },
    {
        "header": "Appendix CResults for LLaMA Models",
        "images": []
    },
    {
        "header": "Appendix DPrompt Demonstration",
        "images": []
    },
    {
        "header": "Appendix EReinforcement Learning",
        "images": []
    },
    {
        "header": "Appendix FRAMP Case Study",
        "images": []
    },
    {
        "header": "Appendix GBroader Impacts",
        "images": []
    },
    {
        "header": "Appendix HLimitations",
        "images": []
    },
    {
        "header": "Appendix IData Ethics Statement",
        "images": []
    }
]