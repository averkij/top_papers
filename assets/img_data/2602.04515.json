[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04515/intro.png",
                "caption": "",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2602.04515/BAAI_brand.png",
                "caption": "",
                "position": 195
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIFramework Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04515/procedure.png",
                "caption": "Figure 2:Visualization of EgoActor’s working procedure for a given task: “Approach and pick up the orange on the desk”. The grey blocks represent structured language actions (SLAs) and the green blocks represent natural language actions (NLAs).",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2602.04515/ending_action.png",
                "caption": "Figure 3:Example natural language actions (NLA) in EgoActing. EgoActor is trained to predict the corresponding actions based on obtained RGB observations.",
                "position": 395
            }
        ]
    },
    {
        "header": "IVTraining Recipe",
        "images": []
    },
    {
        "header": "VExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04515/obstacle_case_study.png",
                "caption": "Figure 4:Multi-step illustration of obstacle avoidance generalization of our model, when faced with an unseen string obstacle.",
                "position": 922
            },
            {
                "img": "https://arxiv.org/html/2602.04515/x1.png",
                "caption": "Figure 5:First-person view of an EgoActor’s active perception trace. Color description blocks highlight model’s behaviors.",
                "position": 925
            },
            {
                "img": "https://arxiv.org/html/2602.04515/x2.png",
                "caption": "Figure 6:First-person view of an EgoActor’s traversability trace, showing the robot walking through a doorway.",
                "position": 994
            },
            {
                "img": "https://arxiv.org/html/2602.04515/x3.png",
                "caption": "Figure 7:First-person view of an EgoActor’s height change ability trace in virtual environments. Color description blocks highlight model’s behaviors.",
                "position": 997
            }
        ]
    },
    {
        "header": "VIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "VIILimitations",
        "images": []
    },
    {
        "header": "VIIIData Format",
        "images": []
    },
    {
        "header": "IXData Processing Details",
        "images": []
    },
    {
        "header": "XSupported Skills",
        "images": []
    },
    {
        "header": "XITraining Details of the Manipulation Model",
        "images": []
    },
    {
        "header": "XIIDetailed Results for All the Three Runs",
        "images": []
    },
    {
        "header": "XIIITraversability Scenes",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04515/traversibility_scenes.png",
                "caption": "Figure 8:An illustration of the different scenes we used in our traversability experiments.",
                "position": 2573
            }
        ]
    },
    {
        "header": "XIVAdditional Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04515/mobile_manipulation_case.png",
                "caption": "Figure 9:An illustration of our model conducting the mobile manipulation task: “Approach and grab the pink cup”.",
                "position": 2599
            }
        ]
    },
    {
        "header": "XVData Samples for the EgoActing Task",
        "images": []
    },
    {
        "header": "XVIPrompts for Different Tasks",
        "images": []
    },
    {
        "header": "XVIIDifference between our work and existing work",
        "images": []
    }
]