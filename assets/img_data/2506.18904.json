[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18904/x1.png",
                "caption": "Figure 1:Relighting results on long videos under various dynamic scenes, averaging 256 frames per clip. Though the video involves frequent changes of foreground objects (row(a)), highly dynamic camera motions (row(b)), the TC-Light realizes consistent and physically plausible relighting results. Row(c)also shows its potential to mitigate the sim2real gap for synthetic renderings.",
                "position": 96
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18904/x2.png",
                "caption": "Figure 2:TC-Light overview. Given the source video and text promptpùëùpitalic_p, the model tokenizes input latents inx‚Å¢yùë•ùë¶xyitalic_x italic_yplane andy‚Å¢tùë¶ùë°ytitalic_y italic_tplane seperately. The predicted noises are combined together for denoising (cf.Sec.3.2). Its output then undergoes two-stage optimization to enhance temporal consistency of illumination and texture, which are respectively detailed inSec.3.3.1andSec.3.3.2.",
                "position": 176
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18904/x3.png",
                "caption": "Figure 3:Qualitative comparison of results. The proposed TC-Light avoids unnatural relighting like Sliceditcohen2024sliceditand COSMOS-Transfer1alhaija2025cosmosin (a) and blurring likealhaija2025cosmosin (b), or inconsistent illumination like per-frame IC-Lightzhang2025scalingand VidToMeli2024vidtomeas highlighted by theredsquares.",
                "position": 480
            },
            {
                "img": "https://arxiv.org/html/2506.18904/x4.png",
                "caption": "Figure 4:Ablation on main module components. The experiment is conducted on one sequence of the InteriorNetInteriorNet18subset, where the text prompt is \"This video showcases a modern interior space, which is dimly lit\". The baseline here denotes VidToMeli2024vidtomeinTab.2.",
                "position": 781
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18904/x5.png",
                "caption": "Figure 5:Qualitative results on additional long highly dynamic videos.",
                "position": 1578
            },
            {
                "img": "https://arxiv.org/html/2506.18904/x6.png",
                "caption": "Figure 6:Additional qualitative comparison of results. The proposed TC-Light avoids unnatural relighting like Sliceditcohen2024sliceditand COSMOS-Transfer1alhaija2025cosmosin (a) and (b), or temporal inconsistency like per-frame IC-Lightzhang2025scalingand VidToMeli2024vidtomeas highlighted by theredsquares.",
                "position": 1581
            }
        ]
    },
    {
        "header": "Appendix BDetails of Assets",
        "images": []
    },
    {
        "header": "Appendix CAdditional Implementation Details",
        "images": []
    },
    {
        "header": "Appendix DUser Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18904/x7.png",
                "caption": "Figure 7:A screenshot of the user study.",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2506.18904/x8.png",
                "caption": "Figure 8:Results from user study with 65 valid submissions. The methods are arranged in alphabetical order. This figure reports the frequency that each method is chosen as the first- and second-most preferred video.",
                "position": 1814
            }
        ]
    },
    {
        "header": "Appendix ESocial Impact",
        "images": []
    }
]