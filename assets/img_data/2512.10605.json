[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIMethodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10605/x1.png",
                "caption": "Figure 1:Basic schematic of LEO-RobotAgent. The LLM is capable of planning, reasoning and evaluating tasks, while invoking tools to execute actions. After obtaining environmental observations, it proceeds to the next step until the task is completed, with users able to interact with the system at any time.",
                "position": 111
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x2.png",
                "caption": "Figure 2:Detailed implementation diagram of LEO-RobotAgent. Based on pre-defined prompts and user tasks, LLMs output content containing information, actions, and action parameters. The toolset can cover various domains according to actual scenarios and is required to provide basic information such as activation status, tool names, corresponding functions, and tool descriptions. Observations will generate diverse feedback content depending on different tools. During the iterative process, historical records (History) are continuously accumulated to support subsequent operations of LLMs.",
                "position": 118
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x3.png",
                "caption": "Figure 3:An application system designed around LEO-RobotAgent. We have built this complete system for the framework based on ROS and Web technologies. Users can directly operate the visual interface to configure existing tools, conduct conversations and interactions with the Agent, and monitor dialogue sessions. The system features high scalability and ease of use in terms of tool registration, node startup and shutdown, and other aspects.",
                "position": 138
            }
        ]
    },
    {
        "header": "IVExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10605/x4.png",
                "caption": "Figure 4:Feasibility verification and real experiment â€“ The performance of object-search tasks. In the simulation environment, the UAV rotated sequentially to perform target detection. After completing identification, it reported the results to the user. Once the user specified a target, the UAV flew to its overhead position, and the task was successfully completed. In real-world experiments, the UAV also accomplished the task correctly: it located the target (trash can) and ultimately dropped the ball into it smoothly.",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/room.jpg",
                "caption": "(a)Room",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/room.jpg",
                "caption": "(a)Room",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/city.jpg",
                "caption": "(b)City",
                "position": 192
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x5.png",
                "caption": "(a)Room",
                "position": 268
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x5.png",
                "caption": "(a)Room",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x6.png",
                "caption": "(b)City",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2512.10605/x7.png",
                "caption": "Figure 7:LEO-RobotAgent and four other agent schemes.",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/car.png",
                "caption": "(a)Robot",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/car.png",
                "caption": "(a)Robot",
                "position": 310
            },
            {
                "img": "https://arxiv.org/html/2512.10605/picture/cafe.png",
                "caption": "(b)Cafe",
                "position": 316
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]