[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18673/x1.png",
                "caption": "Figure 1:Our method accurately estimates 6D object pose for novel objects on drastically different scenes and viewpoints using only a single RGB-D anchor image. We achieve robust pose estimation without requiring precise CAD models or posed multi-view reference images.",
                "position": 74
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18673/x2.png",
                "caption": "Figure 2:Overview of the Any6D framework for model-free object pose estimation.\nFirst, we reconstruct normalized object shapeONsubscriptùëÇùëÅO_{N}italic_O start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPTfrom the image-to-3D model. Then, we estimate accurate object pose and size from anchor imageIAsubscriptùêºùê¥I_{A}italic_I start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPTusing the proposed object alignment (Sec.3.1). Next, we use the query imageIQsubscriptùêºùëÑI_{Q}italic_I start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPTto estimate the pose with the reconstructed metric-scale object shapeOMsubscriptùëÇùëÄO_{M}italic_O start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT(Sec.3.2).",
                "position": 115
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18673/x3.png",
                "caption": "Figure 3:Visualization of each point clouds and center of mustard object.",
                "position": 191
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18673/x4.png",
                "caption": "Figure 4:Qualitative comparison of state-of-the-art methods on the HO3D Dataset. In this challenging scenario, the left anchor image shows only partially visible objects, while the query images are not visible due to occlusion or different viewing angles. This represents the most challenging case for matching. Gedi, being a depth-based method, shows ambiguity when dealing with RGB-based non-symmetric objects.",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.18673/x5.png",
                "caption": "Figure 5:Qualitative comparison of state-of-the-art methods on the YCBInEOAT Dataset. In this challenging scenario, the left anchor image shows only partially visible objects, while the query images are not visible due to occlusion or different viewing angles. This represents the most challenging case for matching. Gedi, being a depth-based method, shows ambiguity when dealing with RGB-based non-symmetric objects.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2503.18673/x6.png",
                "caption": "Figure 6:Comparison of shape quality between baseline method and ours.",
                "position": 1017
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]