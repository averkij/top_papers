[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19900/x1.png",
                "caption": "Figure 1:The evolve loop of Agent0-VL and its performance comparison. The left part illustrates the iterative evolution between the Solver and Verifier, where the Solver progressively refines reasoning strategies under Verifier feedback. The right part presents results showing that Agent0-VL outperforms tool-integrated reasoning methods across multiple representative benchmarks.TIR: Tool-Integrated Reasoning.",
                "position": 73
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19900/x2.png",
                "caption": "Figure 2:The Framework of Agent0-VL.The unified policyπθ\\pi_{\\theta}alternates between two internal roles:\ntheSolverthat generates reasoning trajectories with tool calls,\nand theVerifierthat performs generative verification using tool feedback to produce critiques and step-wise rewards.\nThese roles are jointly optimized through the Self-Evolving Reasoning Cycle, where self-generated rewards guide policy updates via RL.",
                "position": 99
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19900/x3.png",
                "caption": "Figure 3:The overall Best-of-8 evaluation results across seven multimodal reasoning benchmarks with different critic models. Our model greatly enhances the overall performance compared with Qwen2.5-VL-7B model.",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2511.19900/x4.png",
                "caption": "Figure 4:Simplified illustration of Agent0-VL’s self-evolving reasoning process on a geometric reasoning task during training phase. The model first produces an incorrect answer (Phase 1), after which the Verifier identifies the logical error (Phase 2), triggers Self-Repair to generate a correction (Phase 3), and finally re-executes reasoning via the Solver to reach the correct solution (Phase 4). The complete multi-phase case is provided in Appendix4.5(Figure8).",
                "position": 972
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CPrompting and Templates",
        "images": []
    },
    {
        "header": "Appendix DTraining Data Construction Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19900/x5.png",
                "caption": "Figure 8:A full reasoning–evaluation–repair cycle of Agent0-VL on a geometric reasoning task. The Solver first generates an incorrect solution (Phase 1), which the Verifier identifies and critiques through tool-grounded verification (Phase 2). Based on this feedback, the model performs Self-Repair to patch the faulty premise (Phase 3) and re-executes reasoning with the corrected logic (Phase 4), producing the verified final answer.",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2511.19900/x6.png",
                "caption": "Figure 9:Single-step tool-integrated reasoning.The example demonstrates howAgent0-VLidentifies a street name from an image by reasoning about the task,\ndeciding to crop and zoom in on a specific region of the image, and invoking theimage-cropping toolto enhance visibility.\nThe resulting output confirms the street name, showing how the model effectively grounds its reasoning process in visual manipulation.",
                "position": 2340
            },
            {
                "img": "https://arxiv.org/html/2511.19900/x7.png",
                "caption": "Figure 10:Mathematical reasoning with code execution.This case illustrates how the model decomposes a geometry problem into structured reasoning steps,\nformulates the necessary equations using the Pythagorean theorem,\nand calls the Python computation tool to verify and compute the cone’s volume.\nThe tool-grounded reasoning ensures both the numerical correctness and interpretability of the final solution.",
                "position": 2348
            },
            {
                "img": "https://arxiv.org/html/2511.19900/x8.png",
                "caption": "Figure 11:Evaluator-based process verification.This example showcases theVerifierrole ofAgent0-VL,\nwhere the model critically inspects each reasoning step produced by the Solver in a function-root comparison task.\nThe model performs step-level judgments (Correct/Incorrect), identifies propagation errors,\nand recognizes when the final conclusion remains valid despite intermediate mistakes.\nThis demonstrates the model’s capacity for fine-grained self-evaluation and process-level reasoning analysis.",
                "position": 2357
            },
            {
                "img": "https://arxiv.org/html/2511.19900/x9.png",
                "caption": "Figure 12:Analytical reasoning with visual grounding.In this trigonometric midline problem,Agent0-VLinterprets graphical input,\nreasons step-by-step through symbolic computation, and validates its reasoning using code execution.\nBy combining perceptual understanding and analytical computation,\nthe model achieves consistent reasoning grounded in both mathematical and visual evidence.",
                "position": 2367
            }
        ]
    },
    {
        "header": "Appendix ECase Studies",
        "images": []
    }
]