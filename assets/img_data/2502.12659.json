[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12659/x1.png",
                "caption": "Figure 1:We perform a multi-faceted safety analysis of large reasoning and non-reasoning models, focusing on three key aspects: (1) Comparison of performance across safety benchmarks and attacks. (2) Analysis of safety differences in reasoning and final answer. (3) Evaluation of the harmfulness of model responses.",
                "position": 176
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": []
    },
    {
        "header": "3Research Questions and Safety Evaluation Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12659/x2.png",
                "caption": "Figure 2:Two safety benchmark evaluations: (A) Level-2 categorized results of the models on Air-Bench. (B) Evaluation of the models’ safety rate (%) in the Code Interpreter Tests across different risk categories.",
                "position": 419
            }
        ]
    },
    {
        "header": "4Safety Benchmarking",
        "images": []
    },
    {
        "header": "5Response Harmfulness Level Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12659/x3.png",
                "caption": "Figure 3:The harmfulness evaluation result for two pairs of LLMs using two reward models on Air-Bench dataset. The response from reasoning models provides more help to the harmful questions.",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x4.png",
                "caption": "Figure 4:Example of large reasoning model provides more detailed and structured responses to the malicious query compared with non-reasoning model.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x5.png",
                "caption": "Figure 5:Three Scenarios of the R1 Model in Jailbreak: (A) Identifies safety concerns but executes the user’s request unreflectively. (B) Recognizes safety issues but is misled. (C) Fails to recognize any safety concerns.",
                "position": 662
            }
        ]
    },
    {
        "header": "6Safety Attacking",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12659/x6.png",
                "caption": "Figure 6:Two examples where the safety of the reasoning content is worse than the final completion.Left: The reasoning content directly provides techniques that help the malicious query.Right: The reasoning content provides safe paraphrasing techniques that are relevant to the malicious query. Red text is the potentially unsafe content.",
                "position": 846
            }
        ]
    },
    {
        "header": "7Thinking Process v.s. Final Answer",
        "images": []
    },
    {
        "header": "8Discussion and Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12659/x7.png",
                "caption": "Figure 7:Jailbreak Evaluation: DeepSeek R1 Model’s Effective and Safe Reasoning.",
                "position": 1719
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x8.png",
                "caption": "Figure 8:Jailbreak Evaluation: DeepSeek R1 Model’s Unreflective Following of User Queries.",
                "position": 1722
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x9.png",
                "caption": "Figure 9:Jailbreak Evaluation: DeepSeek R1 with awareness of\nsafety but under misguidance.",
                "position": 1725
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x10.png",
                "caption": "Figure 10:Jailbreak Evaluation: DeepSeek R1 fails to recognize harmful information.",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x11.png",
                "caption": "Figure 11:Text Prompt Injection: DeepSeek R1 successfully identifies and provides the correct response.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2502.12659/x12.png",
                "caption": "Figure 12:Text Prompt Injection Evaluation: DeepSeek R1 fails to make the correct judgment.",
                "position": 1735
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]