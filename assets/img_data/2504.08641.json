[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08641/x1.png",
                "caption": "Figure 1:Comparison of different text-to-video generation methods:(a) single model for video generation,(b) video generation with (attention-based) layout guidance,\nand our(c)Video-MSG, a training-free guidance method for T2V generation based on multimodal planning and structured noise initialization.\nSinceVideo-MSGdoes not need fine-tuning or additional memory during inference time, it is easier to adopt large T2V models than previous video layout guidance methods based on fine-tuning or iterative attention manipulation.",
                "position": 117
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08641/x2.png",
                "caption": "Figure 2:Three stages ofVideo-MSG. In the first stage, the MLLM plans specific global and local contexts that fit the provided text-to-video prompt. The text-to-image (T2I) model uses the MLLM planned context to render the necessary components of the video. In the third stage, we generate video withvideo sketchvia noise inversion.",
                "position": 175
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08641/x3.png",
                "caption": "Figure 3:Videos generated with CogVideoX-5B andVideo-MSGwith CogVideoX-5B backbone. The videos generated withVideo-MSGare more accurate regarding object motions, numeracy, and spatial relationships.",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2504.08641/x4.png",
                "caption": "Figure 4:Example video showing the importance of background object detection in foreground object placement.",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2504.08641/x5.png",
                "caption": "Figure 5:Example video showing the importance of foreground object segmentation.",
                "position": 805
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ANoise Inversion Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08641/x6.png",
                "caption": "Figure 6:Prompt template used to query background description.",
                "position": 1724
            },
            {
                "img": "https://arxiv.org/html/2504.08641/x7.png",
                "caption": "Figure 7:Prompt template used to query foreground object layout and trajectory plan.",
                "position": 1728
            },
            {
                "img": "https://arxiv.org/html/2504.08641/x8.png",
                "caption": "Figure 8:Prompt template used to determine how much noise to inject during inversion.",
                "position": 1732
            }
        ]
    },
    {
        "header": "Appendix BPrompt for MLLM Planning",
        "images": []
    }
]