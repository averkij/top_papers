[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIProposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13944/figures/overview8.png",
                "caption": "Figure 1:Illustration of the proposed cluster-based frame selection pipeline. Each video is decomposed into individual frames, from which features are extracted using semantic representations (e.g., CLIP[Radford2021LearningTV]), handcrafted descriptors (e.g., HOG[dalal2005histograms]), or lightweight learned features (e.g., XFeat[potje2024xfeat]). Dimensionality reduction (e.g., PaCMAP[wang2021understanding]) and clustering (e.g., HDBSCAN[mcinnes2017hdbscan]) are then applied to group visually similar frames before dataset partitioning.",
                "position": 103
            }
        ]
    },
    {
        "header": "IIIExperiments and Results",
        "images": []
    },
    {
        "header": "IVConclusions and Future Work",
        "images": []
    }
]