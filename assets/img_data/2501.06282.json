[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.06282/x1.png",
                "caption": "Figure 1:Performance comparison between ourMinMo(∼similar-to\\sim∼8B parameters) and top-tier speech-text multimodal models, including Moshi(7B)(Défossez et al.,2024), Freeze-Omni(7.5B)(Wang et al.,2024b), GLM-4-Voice(9B)(Zeng et al.,2024), SeamlessM4T Large v2(2.3B)(Communication et al.,2023), NExT-GPT(12.42B)(Wu et al.,2024), speech-to-text model Qwen2-Audio(∼similar-to\\sim∼8B)(Chu et al.,2024), Whisper-large-v3(1.55B)(Radford et al.,2023), and others. We demonstrate capabilities of MinMo on automatic speech recognition (ASR), speech-to-text translation (S2TT), spoken question answering (SQA) encompasses both speech-to-text (S2T) and speech-to-speech (S2S), vocal sound classification (VSC), speech emotion recognition (SER), language identification (LID), age recognition and gender detection. ASR is evaluated using 1-WER%, with Fleurs & Common Voice results are averaged over 10 languages (zh, en, ja, ko, yue, de, fr, ru, es, it). S2TT is evaluated using BLEU, with CoVoST2 results averaged overen2zh, en2ja, zh/ja/de/fr/ru/es/it2entranslation directions. SQA is eavaluated using Accuracy. SER is evaluated using Weighted Accuracy.MinMo surpasses the previous SOTA models on all these tasks.",
                "position": 113
            },
            {
                "img": "https://arxiv.org/html/2501.06282/extracted/6124017/figure/minmo_example_1.png",
                "caption": "(a)An example showcases MinMo’s capabilities, including speech-to-speech chat, speech-to-text translation, style-controllable speech synthesis, and full duplex interaction.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2501.06282/extracted/6124017/figure/minmo_example_1.png",
                "caption": "(a)An example showcases MinMo’s capabilities, including speech-to-speech chat, speech-to-text translation, style-controllable speech synthesis, and full duplex interaction.",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2501.06282/extracted/6124017/figure/minmo_example_2.png",
                "caption": "(b)An example showcases MinMo’s capabilities, including speech-to-speech chat, audio event detection, speaker analysis and speech-to-text translation.",
                "position": 167
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MinMo",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.06282/x2.png",
                "caption": "Figure 3:The overall architecture of MinMo. Table1provides detailed descriptions of each module in this diagram.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2501.06282/extracted/6124017/figure/Speech2Text-Data.png",
                "caption": "Figure 4:Detailed training data for the Speech-to-Text Alignment stage.Left:Data distribution forFull-Aligntraining.Right:Data distribution for instruction fine-tuning (SFT).",
                "position": 587
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Authors (alphabetical order of family name)",
        "images": []
    },
    {
        "header": "8Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompts for Voice Understanding Tasks",
        "images": []
    }
]