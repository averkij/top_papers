[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14208/x1.png",
                "caption": "",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14208/x2.png",
                "caption": "Figure 2:The setting differences between novel viewinterpolationand novel viewextrapolation: Radiance fields excel at novel view interpolation but struggle at novel view extrapolation.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14208/x3.png",
                "caption": "Figure 3:Overview of the proposed ViewExtrapolator.We render an artifact-prone video from the closest training view to an extrapolative novel view, and then refine it by guiding SVD to preserve the original scene content and eliminate the artifacts with guidance annealing and resampling annealing.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2411.14208/x4.png",
                "caption": "Figure 4:Qualitative comparisons.We compare ViewExtrapolator with 3DGS and DRGS on novel view extrapolation. ViewExtrapolator demonstrates superior generation quality with much fewer artifacts. The last column shows the distribution of training and test views as well as the corresponding extrapolation degreeeğ‘’eitalic_e. Zoom in for details.",
                "position": 362
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14208/x5.png",
                "caption": "Figure 5:The definition ofextrapolation degreeeğ‘’eitalic_eby the ratio betweenğğ\\mathbf{d}bold_dandrğ‘Ÿritalic_r(ğğ\\mathbf{d}bold_dstands for the distance between the novel view and the central point of training views, andrğ‘Ÿritalic_rstands for the training view range as the maximum extent of the training views along the direction ofğğ\\mathbf{d}bold_d). A highereğ‘’eitalic_emeans that the novel view is farther away from the training views.",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2411.14208/x6.png",
                "caption": "Figure 6:Distributions of extrapolation degreeeğ‘’eitalic_eacross existing benchmarks and our proposed LLFF-Extra. Unlike LLFF-Extra, all existing benchmarks exhibit a smalleğ‘’eitalic_e, indicating that they predominantly focus on the evaluation of novel view interpolation instead of extrapolation.",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2411.14208/x7.png",
                "caption": "Figure 7:Results from different rendering methods.Our method can refine view sequences rendered from(a)3D Gaussian Splatting,(b)Instant-NGP, and point cloud from(c)a single view or(d)monocular video. (The top row in each section is the rendered artifact-prone video and the bottom row is the refined video.)",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2411.14208/x8.png",
                "caption": "Figure 8:Ablation studies.We show the ablation results for 3DGS and point cloud renderings. As point clouds are used for single-image novel view extrapolation without ground truth, we show the input image for reference instead.\nAs highlighted in thered circles, both guidance annealing and resampling annealing are essential for artifact refinement. Please zoom in for details.",
                "position": 453
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14208/x9.png",
                "caption": "",
                "position": 1228
            },
            {
                "img": "https://arxiv.org/html/2411.14208/x10.png",
                "caption": "Figure 10:Limitations and failure cases.The generation quality would degrade when handling(a)novel views at extreme angles or(b)dynamic videos with rapid motion. (The top row in each section is the rendered artifact-prone video and the bottom row is the refined video.)",
                "position": 1236
            }
        ]
    },
    {
        "header": "Appendix AAdditional Results",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CLimitations",
        "images": []
    }
]