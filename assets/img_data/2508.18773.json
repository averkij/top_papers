[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18773/x1.png",
                "caption": "Figure 1:Comparison of ourThinkDialand gpt-oss-style model in controllable reasoning. The red star indicates the performance ceiling achievable by the Qwen2.5-32B-Instruct model after RL training. Circles, squares, and triangles represent Low, Medium, and High modes, respectively.",
                "position": 141
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18773/x2.png",
                "caption": "Figure 2:The impact of Budget Mode SFT across different datasets.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2508.18773/x3.png",
                "caption": "Figure 3:The impact of warm-up RL training on controllable reasoning performance across different modes.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2508.18773/x4.png",
                "caption": "Figure 4:Performance comparison between our approach and the Peak Truncation Method.",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2508.18773/x5.png",
                "caption": "Figure 5:The impact of Leak Penalty on model response length. Total Tokens include both Thinking Tokens and Summary Tokens.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2508.18773/x6.png",
                "caption": "Figure 6:Impact of budget mode (BM) SFT data amount on warm-up phase RL training performance and response length. Here, \"+ BM SFT\" represents the amount of BM SFT data mixed with original reasoning data.",
                "position": 596
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Mode-Specific System Prompts",
        "images": []
    },
    {
        "header": "7Budget-Mode Supervised Fine-tuning Data",
        "images": []
    },
    {
        "header": "8Case Study of Leak Penalty",
        "images": []
    },
    {
        "header": "9Training Details",
        "images": []
    }
]