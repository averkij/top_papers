[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.08332/x1.png",
                "caption": "",
                "position": 76
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.08332/x2.png",
                "caption": "Figure 2:Visualization of point guidance.By introducing points as guidance,MangaNinjacan tackle many challenging tasks, such as when there are significant variations between reference images and line art while preserving details. See more inSec.4.3.",
                "position": 87
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.08332/x3.png",
                "caption": "Figure 3:The training process ofMangaNinja.We randomly select two frames from video data, using one frame as a reference image and extracting the line art from the other.\nBoth frames are input into the Reference U-Net and the Denoising U-Net, respectively.\nTo enhance the modelâ€™s automatic matching and fine-grained control capabilities, we propose a series of training strategies, including progressive patch shuffling.\nAdditionally, we employ an off-the-shelf model to extract matching points from the two frames, and these point maps are fed into the main branch through PointNet.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2501.08332/x4.png",
                "caption": "Figure 4:Qualitative comparisons.We compare our method with the state-of-the-art non-generative colorization method BasicPBC, the consistency generation method IP-Adapter, and AnyDoor. The results demonstrate that our method significantly outperforms them in terms of colorization accuracy and generated image quality. Notably, our method does not use points for guidance in the generated results.",
                "position": 301
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.08332/x5.png",
                "caption": "Figure 5:Visualization of varying poses or missing details.With point guidance,MangaNinjacan tackle many challenging cases. For instance, in the first two rows, there are significant variations between the reference image and line art.\nFurthermore, users can employ point guidance to colorize regions or elements with no matches in the reference; for example, the lower parts of the clothing are missing in the reference image of the third sample.\nWhen dealing with multiple objects, point guidance effectively prevents color confusion, as demonstrated in the last row.",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2501.08332/x6.png",
                "caption": "Figure 6:Visualization of multi-ref colorization.MangaNinjaenables users to select specific areas from multiple reference images through points, providing guidance for all elements in the line art.\nAdditionally, it effectively resolves conflicts between similar visual elements across the reference images.",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2501.08332/x7.png",
                "caption": "Figure 7:Visualization of colorization with discrepant reference.Our method uses points as guidance to achieve semantic color matching with fine control.\nWe believe this interactive colorization with discrepant references can effectively assist users in their colorization attempts and inspire new ideas.",
                "position": 435
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]