[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p1.png",
                "caption": "Figure 1:Accuracy-Length Relationship at Instance level. The relationship between length and accuracy varies significantly across problems, with peak accuracy occurring at short, medium, or long intervals. Notably, high accuracy often persists in shorter intervals.",
                "position": 174
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p1.png",
                "caption": "",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p4.png",
                "caption": "",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p5.png",
                "caption": "",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/qwq/p0.png",
                "caption": "",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/qwq/p1.png",
                "caption": "",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/qwq/p2.png",
                "caption": "",
                "position": 198
            }
        ]
    },
    {
        "header": "3Length Disharmony in Long Thought Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12570/x1.png",
                "caption": "Figure 2:Length-Harmonizing Fine-Tuning. During the training phase, for each problem, we sample multiple times from the reference model. Subsequently, we sample from the model to be optimized and compute the reward based on the reference samples, followed by a RL-style fine-tuning. During the inference phase, the model optimized throughO1-Prunerdemonstrates a significant improvement in inference speed, along with a noticeable enhancement in accuracy.",
                "position": 256
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12570/x2.png",
                "caption": "Figure 3:Comparison of inference time-cost on MATH among different models and methods.O1-Prunerachieves the shortest inference times (slightly over 1 minute for Marco-o1-7B and Â 4 minutes for QwQ-32B-Preview), demonstrating its effectiveness in accelerating long-thought model inference for both small and large long thought models.",
                "position": 790
            }
        ]
    },
    {
        "header": "6Further Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12570/extracted/6145807/difficult.png",
                "caption": "Figure 4:Performance on MATH Test-set When Trained on Problems of Different Difficulty Levels. Models trained on more challenging datasets tend to generate longer solutions, while learning to solve harder problems enhances model accuracy. In contrast, for less challenging datasets, shorter solutions are produced without a corresponding accuracy improvement.",
                "position": 890
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]