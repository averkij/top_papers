[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26645/x1.png",
                "caption": "",
                "position": 77
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x2.png",
                "caption": "Figure 2:GPU memory cost for inference.",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x3.png",
                "caption": "(a)Full Attention",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x3.png",
                "caption": "(a)Full Attention",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x4.png",
                "caption": "(b)Vanilla RNN",
                "position": 174
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x5.png",
                "caption": "(c)Test-Time Training",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x6.png",
                "caption": "(a)CUT3R",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x6.png",
                "caption": "(a)CUT3R",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x7.png",
                "caption": "(b)TTT3R",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x8.png",
                "caption": "Figure 5:By incorporating image attention (i.e.,ùêêùêít‚àí1‚Äãùêäùêót‚ä§‚àà‚Ñùn√ó(h√ów)\\mathbf{Q}_{\\mathbf{S}_{t-1}}{\\mathbf{K}^{\\top}_{\\mathbf{X}_{t}}}\\in\\mathbb{R}^{n\\times(h\\times w)}) as per-token learning ratesŒ≤t‚àà‚Ñùn√ó1\\beta_{t}\\in\\mathbb{R}^{n\\times 1}, TTT3R mitigates catastrophic forgetting and facilitates online loop closure.",
                "position": 1188
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x9.png",
                "caption": "Figure 6:Comparison of Camera Pose Estimation.Results on ScanNet[19](left) and TUM-D[64](right).OOMdenotes the method out-of-memory beyond this point.",
                "position": 1215
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x9.png",
                "caption": "",
                "position": 1218
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x10.png",
                "caption": "",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x11.png",
                "caption": "Figure 7:Runtimecomparison on ScanNet[19].OOMdenotes the method out-of-memory beyond this point.",
                "position": 1242
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x12.png",
                "caption": "(a)Scale-invariant relative depth evaluation on Bonn[48]dataset.",
                "position": 1252
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x12.png",
                "caption": "(a)Scale-invariant relative depth evaluation on Bonn[48]dataset.",
                "position": 1255
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x13.png",
                "caption": "(b)Metric depth evaluation on KITTI[31], excluding VGGT-based methods that don‚Äôt support metric depth.",
                "position": 1261
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x14.png",
                "caption": "Figure 9:Comparison of 3D Reconstructionon 7-scene[61].",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x15.png",
                "caption": "Figure 10:Qualitative Results for 3D Reconstruction.Compared to CUT3R, TTT3R improves sequence length generalization, mitigates forgetting, and enables online loop closure.\nOther baselines (e.g., VGGT, Point3R) are omitted due to OOM on long sequences.\n¬†Check ourwebsiteto see more video comparisons.",
                "position": 1295
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x16.png",
                "caption": "Figure 11:In-the-wild Video Reconstruction - Long Sequence.TTT3R offers a simple state update rule to enhance length generalization for CUT3R,\nenabling robust long-sequence 3D reconstruction.\nThe update is performed in the forward pass without any model fine-tuning, making it a plug-and-play solution, while preserving CUT3R‚Äôs inference speed and memory footprint.\n¬†Check ourwebsiteto see video comparisons.",
                "position": 2621
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x17.png",
                "caption": "Figure 12:Visualization of Estimated Camera Trajectories ‚Äì Long Sequence.The trajectories are plotted along the two axes with the highest variance to capture the most significant motion.\nOur estimated camera trajectory‚àô\\bulletTTT3Rdeviates less from the ground truth‚àô\\bulletGTcompared to the baseline‚àô\\bulletCUT3R.",
                "position": 2852
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x18.png",
                "caption": "",
                "position": 2855
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x19.png",
                "caption": "",
                "position": 2856
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x20.png",
                "caption": "",
                "position": 2858
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x21.png",
                "caption": "",
                "position": 2859
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x22.png",
                "caption": "",
                "position": 2860
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x23.png",
                "caption": "",
                "position": 2862
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x24.png",
                "caption": "",
                "position": 2863
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x25.png",
                "caption": "",
                "position": 2864
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x26.png",
                "caption": "",
                "position": 2866
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x27.png",
                "caption": "",
                "position": 2867
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x28.png",
                "caption": "",
                "position": 2868
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x29.png",
                "caption": "Figure 13:Qualitative Results of 3D Reconstruction.TTT3R improves length generalization over CUT3R while preserving its speed and memory efficiency.\nOffline methods (e.g., VGGT) achieve accurate reconstruction on short sequences (150 frames) but fail on longer sequences (400 frames) due to memory constraints.",
                "position": 2876
            },
            {
                "img": "https://arxiv.org/html/2509.26645/x30.png",
                "caption": "Figure 14:In-the-Wild Video Reconstruction - Short Sequences.TTT3R performs online 3D reconstruction by estimating camera parameters and dense geometry for each incoming image.\nIt supports varying-length image inputs, either video streams or sparse photo collections,\nacross both static and dynamic scenes.",
                "position": 3489
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]