[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/MRI_review.png",
                "caption": "Figure 1:Taxonomy of MRI super-resolution methods.",
                "position": 379
            }
        ]
    },
    {
        "header": "2Problem Formulation and Terminology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/SR_perspectives.png",
                "caption": "Figure 2:Perspectives on MRI super-resolution methods:\n(a) Data-driven approach that learns LR-to-HR mapping purely from data;\n(b) Physics-informed approach that incorporates the underlying imaging physics while mapping the LR-to-HR;\nand (c) Image-to-image translation approach that translates across LR and HR domains, such as modalities or contrasts.",
                "position": 456
            }
        ]
    },
    {
        "header": "3MRI Super-Resolution",
        "images": []
    },
    {
        "header": "4Physics-Driven Super-Resolution",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/DU.png",
                "caption": "Figure 3:Deep unfolding models provide a physics-informed approach to imaging inverse problems by integrating the forward model with a neural network within an iterative reconstruction framework, as illustrated in Algorithm2. Each unrolled layer corresponds to a single iteration of an optimization algorithm[zhang2020deep,monga2021algorithm].",
                "position": 663
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/DEQ.png",
                "caption": "Figure 4:Deep Equilibrium models provide a physics-driven approach to imaging inverse problems by incorporating the forward model and a neural network within a fixed-point formulation[gilton2021deep].",
                "position": 683
            }
        ]
    },
    {
        "header": "5Learning Approaches in MRI SR",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/Learning_paradigm_v2.png",
                "caption": "Figure 5:Learning paradigms for MRI super-resolution: (a) Supervised learning, where the network is trained on physically acquired and well-aligned pairs of LR-HR scans; (b) Unsupervised learning, where no LR-HR pairs are available: 1) generating synthetic LR images from HR scans to create LR-HR training pairs, and 2) scenarios where only LR scans and unpaired examples from the HR target domain are accessible; and (c) Self-supervised learning, where training pairs are generated directly from the available LR scans.",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/supervised_vs_unsupervised_v2.png",
                "caption": "Figure 6:Supervised vs. unsupervised super-resolution: Domain gaps between synthetic LR training data and real acquired LR images lead to discrepancies in the super-resolved outputs when models trained on synthetic data are applied to real-world inputs.",
                "position": 712
            }
        ]
    },
    {
        "header": "6Network Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/upsampling.png",
                "caption": "Figure 7:Overview of super-resolution architectures:\n(a) Pre-upsampling,\n(b) Final upsampling,\n(c) Progressive upsampling,\n(d) Residual learning with long skip connections,\n(e) Dense connections with efficient feature reuse,\n(f) Recursive learning with shared layers.",
                "position": 1188
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/INR.png",
                "caption": "Figure 8:Illustration of INR-based MRI super-resolution. An encoder maps the input image to a coordinate feature grid, from which spatial coordinates and corresponding features are sampled. During training, the network learns a continuous mapping from coordinates and features to signal intensities. At inference, the trained model can be queried at arbitrary coordinates to generate HR outputs. Inspired from[li2024enhance]",
                "position": 1350
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/GaussianSplatting.png",
                "caption": "Figure 9:Comparison of feature representations between INR and GS.\n(a) INRs model pixels as discrete point samples;\n(b) GS represents each pixel as a self-adaptive continuous Gaussian field, allowing smooth and explicit evaluation of field values at arbitrary query locations[hu2025gaussiansr].",
                "position": 1402
            }
        ]
    },
    {
        "header": "7Foundation Models",
        "images": []
    },
    {
        "header": "8Generative AI",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/DMs.png",
                "caption": "Figure 10:Summary of forward and reverse processes in three major diffusion model formulations: DDPMs, SGMs, and SDE-based models.\nThe bottom row illustrates the forward processes (in red), where clean datax0x_{0}is progressively corrupted using Gaussian noise or stochastic dynamics.\nThe top row shows the corresponding reverse processes (in blue): DDPMs perform noise prediction and Gaussian denoising; SGMs apply Langevin dynamics based on learned score functions; and SDE-based models use reverse-time trajectories guided by continuous-time score estimates.\nAdapted from[moser2024diffusion].",
                "position": 1543
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/DDIM.png",
                "caption": "Figure 11:Illustration of DDIM sampling: instead of traversing all steps, the model mapsxt+n‚Üíxtx_{t+n}\\rightarrow x_{t}using a learned deterministic (or semi-stochastic) function conditioned onyy. This enables accelerated inference by skipping intermediate states while preserving fidelity.",
                "position": 1693
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/corruption_domain.png",
                "caption": "Figure 12:Overview of diffusion corruption spaces in MRI SR.Top:Forward (red) and reverse (blue) denoising steps.Bottom:Three types of domains in which the diffusion process occurs‚Äî(i) pixel-based diffusion, operating directly on image pixels; (ii) latent space diffusion, operating in a latent representation obtained via an encoder (E) and mapped back through a decoder (D); and (iii) frequency-based diffusion, operating in a transformed domain (TT) and its inverse (i‚ÄãTiT), such as wavelet or Fourier. Adapted from[moser2024diffusion].",
                "position": 1722
            },
            {
                "img": "https://arxiv.org/html/2511.16854/x1.png",
                "caption": "Figure 13:Illustration of the VAE-based MRI super-resolution framework.\nThe encoderqœï‚Äã(z‚à£x)q_{\\phi}(z\\mid x)approximates the posterior over latent variables given HR ground truthxxand LR inputyy, while the decoderpŒ∏‚Äã(x‚à£z,y)p_{\\theta}(x\\mid z,y)reconstructs the HR image.\nTraining maximizes the ELBO to balance fidelity and latent regularization.",
                "position": 1792
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/NFs.png",
                "caption": "Figure 14:Illustration of a normalizing flow model. A simple base distributionz0‚àºp0‚Äã(z0)z_{0}\\sim p_{0}(z_{0}), typically standard Gaussian, is transformed through a sequence of invertible functionsf1,‚Ä¶,fKf_{1},\\ldots,f_{K}into a complex target distributionx=zKx=z_{K}. The forward (generation) path increases distribution complexity, while the reverse (normalization) path enables exact likelihood computation and inference. Adapted from[shen2023psrflow].",
                "position": 1829
            },
            {
                "img": "https://arxiv.org/html/2511.16854/figs/GAN.png",
                "caption": "Figure 15:Overview of GAN-based super-resolution. The generatorùí¢Œ∏\\mathcal{G}_{\\theta}maps the LR imageyyto an estimated HR imagex^\\hat{x}, while the discriminatorùíüœï\\mathcal{D}_{\\phi}distinguishes real HR images from generated ones. The training is adversarial, encouraging the generator to produce perceptually realistic outputs aligned with the HR data distribution. Adapted from[zhao2023generative].",
                "position": 1857
            }
        ]
    },
    {
        "header": "9Performance Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16854/figs/Fig_perception_distortion_trade_off.png",
                "caption": "Figure 16:The perception-distortion trade-off in image restoration algorithms reveals a fundamental challenge: Regardless of algorithmic differences, there is a region in the perception-distortion plane that remains unattainable. When algorithms approach this region, the choice emerges: improve either distortion or perceptual quality, not both simultaneously[blau2018perception,cohen2024looks].",
                "position": 2167
            }
        ]
    },
    {
        "header": "10Global Access and Clinical Applications",
        "images": []
    },
    {
        "header": "11Theoretical and Conceptual Foundations",
        "images": []
    },
    {
        "header": "12Technical & Methodological Considerations",
        "images": []
    },
    {
        "header": "13Critical Outlook and Future Directions",
        "images": []
    }
]