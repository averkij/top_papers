[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24693/x1.png",
                "caption": "Figure 1:(Left): A comparison between humans and the Gemini 2.5 Pro with and without audio captions on various audio benchmarks. Our STAR-Bench evaluates linguistically hard-to-describe audio cues. SeeSec.B.1for audio caption details.(Right): The three core abilities required to solve tasks in the STAR-Bench benchmark.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3STAR-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24693/x2.png",
                "caption": "Figure 2:Data examples fromSTAR-Bench:(1)the foundational perception task (upper) and(2)the holistic spatio-temporal reasoning task, which includes both temporal reasoning (bottom left) and spatial reasoning (bottom right). Zoom in for the best view.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x3.png",
                "caption": "Figure 3:Audio preprocessing in existing models results in the loss of dual-channel information.",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x4.png",
                "caption": "(a)Data distribution across the foundation perception, temporal reasoning, and spatial reasoning three tasks.",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x4.png",
                "caption": "(a)Data distribution across the foundation perception, temporal reasoning, and spatial reasoning three tasks.",
                "position": 402
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x5.png",
                "caption": "Figure 5:The four-stagedata annotation pipelinefor constructing ourSTAR-Bench.",
                "position": 486
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24693/x6.png",
                "caption": "Figure 6:Error distribution across temporal and spatial Tasks.",
                "position": 876
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x7.png",
                "caption": "Figure 7:An error case in temporal reasoning task. More cases are provided in theAppendixF.",
                "position": 892
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x8.png",
                "caption": "Figure 8:Thesensitivity analysisin fine-grained perception.",
                "position": 895
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x8.png",
                "caption": "Figure 8:Thesensitivity analysisin fine-grained perception.",
                "position": 898
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x9.png",
                "caption": "Figure 9:Theablation studyon temporal reasoning.",
                "position": 903
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "The Use of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BDetails of Data Annotation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24693/Figure/prompt1.png",
                "caption": "Figure 10:The prompt for our AI-assisted filtering process on temporal tasks.",
                "position": 1825
            },
            {
                "img": "https://arxiv.org/html/2510.24693/Figure/prompt2.png",
                "caption": "Figure 11:The prompt for our AI-assisted filtering process on temporal tasks.",
                "position": 1829
            }
        ]
    },
    {
        "header": "Appendix CRobust Evaluation",
        "images": []
    },
    {
        "header": "Appendix DBreakdown Results",
        "images": []
    },
    {
        "header": "Appendix EFurther Analysis and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24693/x10.png",
                "caption": "Figure 12:An error case from the temporal reasoning task.",
                "position": 3303
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x11.png",
                "caption": "Figure 13:An error case from the temporal reasoning task.",
                "position": 3307
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x12.png",
                "caption": "Figure 14:An error case from the temporal reasoning task.",
                "position": 3311
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x13.png",
                "caption": "Figure 15:An error case from the temporal reasoning task.",
                "position": 3315
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x14.png",
                "caption": "Figure 16:An error case from the temporal reasoning task.",
                "position": 3319
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x15.png",
                "caption": "Figure 17:An error case from the temporal reasoning task.",
                "position": 3323
            },
            {
                "img": "https://arxiv.org/html/2510.24693/x16.png",
                "caption": "Figure 18:An error case from the spatial reasoning task.",
                "position": 3327
            }
        ]
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    }
]