[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04233/x1.png",
                "caption": "Figure 1:LEMAS-Dataset contains more thanùüèùüìùüé‚Äãùê§\\mathbf{150k}hours of multi-speaker speech with forced word-level alignments across10major languages. Based on LEMAS-Dataset, we train two models.LEMAS-TTSperforms large-scale, flow-based neural TTS that streams high-fidelity speech from text and a short reference clip, whileLEMAS-Editperforms codec-based, word-level speech editing.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3LEMAS-Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04233/x2.png",
                "caption": "Figure 2:Dataset Statistics of LEMAS-Dataset. (a) Language-wise duration, (b) the average sentence duration in seconds. The dataset shows substantial variation in both data volume and sentence length across languages.",
                "position": 396
            }
        ]
    },
    {
        "header": "4LEMAS-TTS",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04233/x3.png",
                "caption": "Figure 3:Time-dependent control schedules used in our sampling strategy.\nLeft: CFG strength schedules with different maximum guidance levels, emphasizing early timesteps and gradually decaying over sampling.\nRight: Sway-sampling time warping with varying strengths, compared to a cosine-based baseline (dashed), where stronger warping allocates more steps to later timesteps. Together, these schedules demonstrate how guidance strength and sampling allocation can be shaped over time to influence generation behavior.",
                "position": 679
            }
        ]
    },
    {
        "header": "5LEMAS-Edit",
        "images": []
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04233/x4.png",
                "caption": "Figure 4:Preference distribution of audio naturalness across different languages.The ridgeline plot illustrates the subjective results of the A/B preference test comparingLEMAS-TTS(Model A) andLEMAS-Edit(Model B).\nIndividual scores are normalized to a scale of 0‚Äì100, where 0 represents a strong preference for Model A and 100 indicates a strong preference for Model B.\nThe vertical distribution (Kernel Density Estimation) for each language reveals the consensus among users, with the ‚Äò‚ÄòAVERAGE‚Äô‚Äô row representing the aggregated performance across all tested languages.",
                "position": 1006
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]