[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14853/x1.png",
                "caption": "Figure 1:Test-time rerouting framework for MoE models.(a) Rerouting mechanism: lightweight additive vectors (Delta) update router logits in selected high-confidence layers using self-supervised loss from existing context.(b) Continuous adaptation: alternating between optimization phases that adapt routing decisions and generation phases that maintain adapted routing until the next optimization cycle.",
                "position": 110
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results for MoE Rewiring",
        "images": []
    },
    {
        "header": "6Analysis and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14853/x2.png",
                "caption": "Figure 2:Analysis of test-time rerouting mechanisms across different datasets in DeepSeek-V2-Lite. a) Edit distance before and after rerouting. b) Expert utilization dynamics before and after rerouting.",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2510.14853/x3.png",
                "caption": "Figure 3:Expert routing entropy as a function of sequence length averaged over 16 token blocks.",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2510.14853/x3.png",
                "caption": "Figure 3:Expert routing entropy as a function of sequence length averaged over 16 token blocks.",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2510.14853/x4.png",
                "caption": "Figure 4:Performance of our method versus the baseline across different few-shot examples under shifted and aligned task contexts.",
                "position": 846
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Settings",
        "images": []
    },
    {
        "header": "Appendix BMethod Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14853/x5.png",
                "caption": "Figure 5:Layer-wise confidence distributions across different tasks in DeepSeek-V2-lite-MoE",
                "position": 1587
            },
            {
                "img": "https://arxiv.org/html/2510.14853/x6.png",
                "caption": "Figure 6:Effect of optimization interval on performance across 5 benchmarks. The dashed line denotes the baseline results without rerouting.",
                "position": 1597
            }
        ]
    },
    {
        "header": "Appendix CAdditional Analysis",
        "images": []
    }
]