[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04322/x1.png",
                "caption": "Figure 1:Process flow of human evaluation to identify attributes contributing to jailbreak harmfulness. We collect and curate10101010harmful base examples that meet all four attributes and augment each response into16161616variants with different attribute combinations using GPT-4. Human annotators then assess each variant for the four attributes and the overall harm level.",
                "position": 213
            }
        ]
    },
    {
        "header": "3What Constitutes a Harmful Jailbreak?",
        "images": []
    },
    {
        "header": "4Jailbreaks Through Simple Interactions",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04322/x2.png",
                "caption": "Figure 2:Real-world human-LLM interactions fromWildVis. The left example illustrates a multi-step user-LLM interaction with a malicious query and subsequent follow-ups.\nIn the right example, the multilingual LLM provides step-by-step instructions in response to a malicious query in Spanish.",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x3.png",
                "caption": "Figure 3:OurSpeak Easyjailbreak framework.\nGiven a malicious query, we (1) decompose it into multiple steps of seemingly harmless subqueries and (2) translate each subquery into a set of predefined languages from different resource groups.\nWe then (3) prompt multilingual LLMs with the translated subqueries at each step.\nAfter collecting the responses, we (4) translate them back into English and (5) select the most actionable and informative response for each subquery using our response selection models.\nFinally, (6) the selected responses are combined to form a complete response to the original malicious query.",
                "position": 391
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04322/x4.png",
                "caption": "Figure 4:Jailbreak performance measured byASRandHarmScorebefore and after integratingSpeak Easyinto the baselines, with the shaded bars highlighting the difference.Speak Easysignificantly increases bothASRandHarmScoreacross almost all methods.\nSee Table10for full numerical values.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x5.png",
                "caption": "Figure 5:Top: Average actionability and informativeness scores; Bottom: Selection rates for each language, both forn=6ùëõ6n=6italic_n = 6.\nEach color theme represents a language resource level.\nWhile informativeness remains consistent across languages, actionability and selection rate decreases with resource level.",
                "position": 741
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AFormulatingHarmScore",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04322/x6.png",
                "caption": "Figure 6:Prompts used to instruct GPT-4o to augment responses by removing each attribute from the response.[QUERY]and[RESPONSE]are replaced with the original query-response pairs from Table7, respectively.",
                "position": 2225
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x7.png",
                "caption": "",
                "position": 2229
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x8.png",
                "caption": "",
                "position": 2231
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x9.png",
                "caption": "",
                "position": 2233
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x10.png",
                "caption": "Figure 7:Annotation questionnaire for assessing the relationship between the four identified attributes and the harm in jailbreak responses.",
                "position": 2256
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x11.png",
                "caption": "Figure 8:Annotation instructions and example instances for comparing alignment results betweenASRandHarmScore.",
                "position": 2268
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details ofSpeak Easy",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04322/x12.png",
                "caption": "Figure 9:The prompt used to decompose the harmful query, along with four in-context examples.[NUMBER OF SUBQUERIES]and[HARMFUL QUERY]are replaced with the number of subqueries and the jailbreak query during test time. By default,[NUMBER OF SUBQUERIES]is set to 3.",
                "position": 2290
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x13.png",
                "caption": "(a)Prompt used to summarize paragraph-length questions in theStack-Exchange-Preferencesdataset into a single sentence.",
                "position": 2316
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x13.png",
                "caption": "(a)Prompt used to summarize paragraph-length questions in theStack-Exchange-Preferencesdataset into a single sentence.",
                "position": 2319
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x14.png",
                "caption": "(b)Prompt used to determine whether a question from theHH-RLHForStack-Exchange-Preferencesdatasets can be answered with an actionable response to filter out irrelevant questions.",
                "position": 2325
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x15.png",
                "caption": "(c)Prompt used to determine whether a question from theHH-RLHForStack-Exchange-Preferencesdatasets can be answered with an informative response to filter out irrelevant questions.",
                "position": 2331
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x16.png",
                "caption": "(d)Prompt used to determine whether a query-response pair is actionable or informative.",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2502.04322/x17.png",
                "caption": "Figure 11:Language selection rates forn=3ùëõ3n=3italic_n = 3andn=9ùëõ9n=9italic_n = 9.\nEach color theme represents a language resource level.\nWe observe that selection rates correlate with language resource levels, with high-resource languages being chosen more frequently than lower-resource ones across all settings.",
                "position": 3017
            }
        ]
    },
    {
        "header": "Appendix CSupplementary Results",
        "images": []
    }
]