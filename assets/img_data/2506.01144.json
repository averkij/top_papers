[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x1.png",
                "caption": "Figure 1:Text-to-video results before and after applying FlowMo on (a) Wan2.1wan2025and CogVideoX-5Bhong2022cogvideo. We presentFlowMo, an inference-time guidance method to enhance temporal coherence in text-to-video models. Our method mitigates severe temporal artifacts, such as additional limbs (woman, 1st row, 2nd row), objects that appear or disappear (flamingo, 2nd row), and object distortions (woman, dolphin, 1st row), without requiring additional training or conditioning signals.",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x2.png",
                "caption": "Figure 2:Quantitative motivation. We measure the mean temporal variance of spatial patches for coherent and incoherent videos. Incoherent videos portray higher variance. The separation is visible from step 5 onward. 95%-confidence interval was computed using theseabornpython package.",
                "position": 228
            },
            {
                "img": "https://arxiv.org/html/2506.01144/x3.png",
                "caption": "Figure 3:Qualitative motivation.We visualize the model prediction per timestep across the generation. Coarse spatial information is determined in the first steps (0-4), whereas motion is determined at steps 5-8, and refined in later steps.",
                "position": 256
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x4.png",
                "caption": "Figure 4:Qualitative results. Text-to-video results before and after applying FlowMo on (a) Wan2.1wan2025and (b) CogVideoXhong2022cogvideo. FlowMo mitigates severe temporal artifacts, e.g., extra limbs (women, 2nd, 3rd row), objects that appear or disappear (2nd, 3rd row), and distortions (4th row).",
                "position": 454
            },
            {
                "img": "https://arxiv.org/html/2506.01144/x5.png",
                "caption": "Figure 5:User studyconducted on Wan2.1-1.3Bwan2025(left) and CogVideoX-5Bhong2022cogvideo(right) using VideoJAM-benchchefer2025videojam, designed specifically to evaluate motion coherence. Our method significantly improves temporal coherence in all models, while maintaining or improving the visual quality and the text alignment of the resulting videos. 95%-confidence intervals were calculated using Dirichlet sampling, assuming a multinomial distribution with Laplace smoothing applied to the counts.",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2506.01144/x6.png",
                "caption": "Figure 6:Ablation study.We ablate the main design choices of FlowMo, i.e., using the maximal variance for the objective (3rd row), using the appearance-debiasing operator (4th row), the selection of the optimization steps (5th row), and show that FlowMo is significantly superior to all variants.",
                "position": 584
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComparison between FlowMo and FreeInit",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x7.png",
                "caption": "Figure 7:Qualitative results.Text-to-video results of FreeInitwu2023freeinit(1st, 3rd row) and FlowMo (2nd, 4th row) when applied on Wan2.1-1.3Bwan2025. FlowMo better mitigates severe temporal artifacts, e.g. distortions and object that appear and disappear.",
                "position": 1525
            },
            {
                "img": "https://arxiv.org/html/2506.01144/x8.png",
                "caption": "Figure 8:User studiesconducted on Wan2.1-1.3Bwan2025using VideoJAM-benchchefer2025videojam. The studies compare three variants of the model: vanilla (Wan2.1-1.3B), with FlowMo, and with FreeInit. Our method significantly outperforms the baselines in both studies. 95%-confidence intervals were calculated using Dirichlet sampling, assuming a multinomial distribution with Laplace smoothing applied to the counts.",
                "position": 1543
            }
        ]
    },
    {
        "header": "Appendix BAdditional Qualitative Motivation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x9.png",
                "caption": "Figure 9:A visualization of channel 0 (selected arbitrarily, and used in the main paper) of the latent prediction at different timesteps of the generation.",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2506.01144/x10.png",
                "caption": "Figure 10:A visualization of channel 7 (selected randomly) of the latent prediction at different timesteps of the generation.",
                "position": 1716
            }
        ]
    },
    {
        "header": "Appendix CThe Effect of FlowMo on Patch-Wise Variance",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x11.png",
                "caption": "Figure 11:FlowMo effect on patch-wise variance. We plot the maximal temporal variance of spatial patches for videos with and without applying FlowMo guidance, and observe that our method significantly reduces and stabilizes the variance in the generation steps that impact motion the most by our analysis from Sec.3.2. 95%-confidence interval was computed using theseabornpython package.",
                "position": 1725
            }
        ]
    },
    {
        "header": "Appendix DUser Study: Instructions Provided to Participants",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01144/x12.png",
                "caption": "Figure 12:Screenshot of the Google Form used in the user study.",
                "position": 1793
            }
        ]
    },
    {
        "header": "Appendix EVBench Metrics Breakdown",
        "images": []
    }
]