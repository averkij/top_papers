[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05145/x1.png",
                "caption": "Figure 1:Self-improving VLM judge: iterative synthetic preference data generation and judge model fine-tuning pipeline.I. Synthetic preference pair generation.We create synthetic preference pairs tailored to different question types. For open solution space questions (long answers, captions), we generate an original response and deliberately inject meaningful errors to create a less preferred version. For closed solution space questions (numerical, multiple choice, short phrases), we generate multiple candidates and pair the majority answer with a random alternative.II. Iterative judge training data generation.We use the previous-iteration judge model to evaluate the newly synthesized preference pairs and gather the judge’s reasoning traces. We retain only judgments that align with our synthetic preferences.III. Judge model training.We fine-tune the previous-iteration judge model on these filtered reasoning traces. We iterate this three-step process several times. More details in §3.",
                "position": 135
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental Setups",
        "images": []
    },
    {
        "header": "5Results",
        "images": []
    },
    {
        "header": "6Analysis and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05145/x2.png",
                "caption": "Figure 2:Judge model performance across training iterations. The left lanel shows average VLRB scores and the right panel shows average MMRB scores. After 4 iterations, our 11B judge model is comparable with Claude-3.5 and Llama-90B on VLRB.",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2512.05145/images/data_perc.png",
                "caption": "Figure 3:Increasing % of data sampled from each training iteration",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2512.05145/x3.png",
                "caption": "Figure 4:Performance comparing using majority voting and correct answer to filter synthetic pairs before sampling. For VLRB reasoning and MMRB VQA using majority voting to filter the synthetic pairs yields better performance after a few iterations. When reducing data size to the same with correct answer filtering, majority performance also reduced.",
                "position": 598
            },
            {
                "img": "https://arxiv.org/html/2512.05145/x4.png",
                "caption": "Figure 5:The dimensions that showed the most significant improvements (VLRB General, Hallucination) and the least significant improvements (MMRB Safety, General). More details in §6.3.",
                "position": 624
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Training example from different iterations",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05145/images/training_iteration_ex.jpeg",
                "caption": "",
                "position": 1217
            }
        ]
    },
    {
        "header": "9Judge Prompt",
        "images": []
    },
    {
        "header": "10Detail Alternation Prompts",
        "images": []
    },
    {
        "header": "11Generation Meta Prompt for Captions",
        "images": []
    },
    {
        "header": "12Hyperparameters",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05145/images/counter_example.png",
                "caption": "",
                "position": 1531
            }
        ]
    },
    {
        "header": "13Correctness Filter Negative Example",
        "images": []
    }
]