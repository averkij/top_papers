[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/icon.png",
                "caption": "",
                "position": 61
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure1_v7.png",
                "caption": "",
                "position": 79
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary: 3D Gaussian Splatting",
        "images": []
    },
    {
        "header": "4Proposed Method: SplineGS",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/x1.png",
                "caption": "Figure 2:Overview of SplineGS.Our SplineGS leverages spline-based functions to model the deformation of dynamic 3D Gaussians with a novel Motion-Adaptive Spline (MAS) architecture. It is composed of sets of learnable control points based on a cubic Hermite spline function[2,7]to accurately model the trajectory of each dynamic 3D Gaussian and to achieve faster rendering speed. To avoid any preprocessing of camera parameters, i.e. COLMAP-free, we adopt a two-stage optimization: warm-up and main training stages.",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_qualitative_nvidia.png",
                "caption": "Figure 3:Visual comparisons for novel view synthesis on the NVIDIA dataset.",
                "position": 680
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_qualitative_davis.png",
                "caption": "Figure 4:Visual comparisons for novel view synthesis on the DAVIS dataset.",
                "position": 704
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_t_interp.png",
                "caption": "Figure 5:Visual comparisons for novel view and time synthesis on the NVIDIA dataset.",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_ablation_motion_tracking.png",
                "caption": "Figure 6:Visual comparisons for motion tracking.We visualize 2D pixel tracks to analyze motions of dynamic 3D Gaussians.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_ablation_macp.png",
                "caption": "Figure 7:Visual comparisons for MACP ablation study.",
                "position": 795
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_ablation_ctrl_num.png",
                "caption": "Figure 8:Analysis of MACP‚Äôs Efficacy.(a)NcsubscriptùëÅùëêN_{c}italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPTHeatmaps as the averagedNcsubscriptùëÅùëêN_{c}italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPTvalues of dynamic 3D Gaussians and their corresponding rendered framesI^tsubscript^ùêºùë°\\hat{I}_{t}over^ start_ARG italic_I end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTfor ‚ÄòBalloon2‚Äô and ‚ÄòSkating‚Äô scenes. (b) Histograms of the number of control points (NcsubscriptùëÅùëêN_{c}italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT) in percentages (%) of dynamic 3D Gaussians in two scenes.",
                "position": 977
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADemo Videos",
        "images": []
    },
    {
        "header": "Appendix BAdditional Ablation Study for Motion-Adaptive Control Points Pruning (MACP)",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_suppl_additiona_ablation_macp.png",
                "caption": "Figure 9:Ablation study on MACP.We conduct an ablation study of our Motion-Adaptive Control points Pruning (MACP) method for novel view synthesis on the NVIDIA dataset[50]by adjusting the pruning error thresholdœµitalic-œµ\\epsilonitalic_œµ. ‚ÄòPSNR (dB)‚Äô and ‚Äò# Ctrl. Pts.‚Äô denote the average PSNR value and the average number of control points for dynamic 3D Gaussians after training, computed across all scenes, respectively.",
                "position": 1685
            }
        ]
    },
    {
        "header": "Appendix CMemory Footprint Comparison",
        "images": []
    },
    {
        "header": "Appendix DDynamic 3D Gaussian Trajectory Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_tracking_ours.jpg",
                "caption": "Figure 10:Visual results of dynamic 3D Gaussian trajectory projected to novel views for our SplineGS.",
                "position": 1768
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_suppl_track_stgs.jpg",
                "caption": "Figure 11:Visual results of novel view synthesis at a specific time using the same STGS[21]models after optimization with (a) their original time-varying opacity and (b) time-independent spatial opacity, respectively.Please note that we use their original time-varying opacity during training.",
                "position": 1784
            }
        ]
    },
    {
        "header": "Appendix EAdditional Details for Methodology",
        "images": []
    },
    {
        "header": "Appendix FLimitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/limitation.jpg",
                "caption": "Figure 12:Limitations of our SplineGS.When the training video frame contains blurriness, our model cannot effectively reconstruct sharp renderings due to the absence of a deblurring method.",
                "position": 1852
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvs_jumping.jpg",
                "caption": "Figure 13:Visual comparisons for novel view synthesis on theJumpingscene from the NVIDIA dataset.",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvs_playground.jpg",
                "caption": "Figure 14:Visual comparisons for novel view synthesis on thePlaygroundscene from the NVIDIA dataset.",
                "position": 1883
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvs_truck.jpg",
                "caption": "Figure 15:Visual comparisons for novel view synthesis on theTruckscene from the NVIDIA dataset.",
                "position": 1886
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvts_balloon2.jpg",
                "caption": "Figure 16:Visual comparisons for novel view and time synthesis on theBalloon2scene from the NVIDIA dataset.",
                "position": 1890
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvts_jumping.jpg",
                "caption": "Figure 17:Visual comparisons for novel view and time synthesis on theJumpingscene from the NVIDIA dataset.",
                "position": 1893
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_nvidia_nvts_umbrella.jpg",
                "caption": "Figure 18:Visual comparisons for novel view and time synthesis on theUmbrellascene from the NVIDIA dataset.",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_davis_horsejump-high.jpg",
                "caption": "Figure 19:Visual comparisons for novel view synthesis on theHorsejump-highscene from the DAVIS dataset.",
                "position": 1900
            },
            {
                "img": "https://arxiv.org/html/2412.09982/extracted/6066614/figure/figure_supple_davis_paragliding-launch.jpg",
                "caption": "Figure 20:Visual comparisons for novel view synthesis on theParagliding-launchscene from the DAVIS dataset.",
                "position": 1903
            }
        ]
    },
    {
        "header": "Appendix GAdditional Qualitative Results",
        "images": []
    }
]