[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05325/x1.png",
                "caption": "Figure 1:Accuracy–efficiency tradeoffs under LYNX: a single confidence parameter smoothly moves the model from baseline-level accuracy to substantially more efficient generations (1.5–3.3×\\times).",
                "position": 171
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05325/x2.png",
                "caption": "Figure 2:LYNX pipeline:(Offline)We collect forced-exit labels at naturally occurring cue tokens from mathematical problems, train a lightweight probe on hidden states at these cues, and calibrate conformal thresholds using a held-out set.(Online)During generation, whenever a cue appears, the probe scores its hidden state and a conformalized threshold decides whether to exit early or continue reasoning.",
                "position": 382
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05325/x3.png",
                "caption": "Figure 3:Accuracy–efficiency Pareto frontiers for LYNX compared to DEER and Think-or-Not (ToN).\nEach panel plots speed-up (baseline tokens divided by method tokens) on thexx-axis and change in accuracy vs. baseline (percentage points) on theyy-axis.\nAcross all settings, LYNX forms competitive or superior frontiers, with DEER slightly ahead only on QwQ-32BGSM8K.",
                "position": 699
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Appendix.",
        "images": []
    },
    {
        "header": "Appendix AAlgorithmic Details ofLYNX",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CResults at TemperatureT=0.6T=0.6",
        "images": []
    },
    {
        "header": "Appendix DGeneralization to Llama-Nemotron",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05325/x4.png",
                "caption": "Figure 5:Accuracy–efficiency tradeoffs at temperatureT=0.0T=0.0forLlama-3.1-Nemotron-Nano-8B-v1.\nEach panel shows baseline chain-of-thought decoding andLYNXat multiple confidence levelsc=1−δc=1-\\delta.\nBars report accuracy, and the overlaid line reports efficiency gain (baseline tokens divided by method tokens).LYNXachieves large token savings on all datasets while substantially improving or preserving accuracy relative to the Nemotron baseline.",
                "position": 1756
            }
        ]
    },
    {
        "header": "Appendix EAdditional Experimental Details",
        "images": []
    }
]