[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Modulation Layers",
        "images": []
    },
    {
        "header": "4Analysis of the Pooled Text Embedding Role",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/x1.png",
                "caption": "Table 1:Image quality results for short and long prompts.\nThe CLIP embedding does not affect output quality on long prompts forFLUX schnelland has no effect forHiDream-Fast.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2602.09268/x1.png",
                "caption": "Figure 1:(top)Difference between images (DreamSim) with and without CLIP as a function of prompt length.(bot)For long prompts, images without CLIP generally do not differ from the initial ones.",
                "position": 277
            }
        ]
    },
    {
        "header": "5Modulation Guidance",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/x2.png",
                "caption": "Figure 2:The modulation guidance enables local (top) and global (bottom) changes and encourages its use to shift a DM toward modes with better properties.",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2602.09268/x3.png",
                "caption": "Figure 3:Analysis on dynamic modulation guidance.(a) Dynamic guidance offers a better trade-off between aesthetic quality and prompt correspondence than constant modulation guidance.\n(b) We use a step function, controlled byii, that skips the first few layers of the model as our form of dynamic guidance. Additional variants are explored in AppendixB.",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2602.09268/x4.png",
                "caption": "Figure 4:After applying modulation guidance, the model focuses more on the desired features, such as hands (a, b).",
                "position": 359
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/x5.png",
                "caption": "Figure 5:Qualitative results of modulation guidance forAesthetics(top) andComplexity(bottom). TheAestheticsguidance notably improves image quality, while theComplexityguidance can enhance the complexity of both the main object and background details.",
                "position": 604
            },
            {
                "img": "https://arxiv.org/html/2602.09268/x6.png",
                "caption": "Figure 6:Qualitative results of the modulation guidance forObject counting(top) andHands correction(bottom).",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/exps_video.png",
                "caption": "Figure 7:Qualitative comparison between the original CausVid and CausVid with modulation guidance.",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/exps_editing.png",
                "caption": "Figure 8:Qualitative results for text-guided image editing tasks. We observe that FLUX Kontext sometimes struggles with complex edits, while modulation guidance can mitigate this limitation.",
                "position": 819
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAdditional analysis for FLUX kontext model",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_analysis_kontext.jpg",
                "caption": "Figure 9:We observe that the CLIP text encoder does not influence instruction-guided image editing performed with the FLUX kontext model.",
                "position": 1689
            }
        ]
    },
    {
        "header": "Appendix BStrategies for dynamic guidance",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/x7.png",
                "caption": "Figure 10:Analysis on dynamic modulation guidance. To derive a dynamic guidance scale, we (a) analyze how the model allocates attention to different features by computing averaged attention maps over two token groups (specific and general). Building on this, we (b) explore dynamic strategies for setting layer-specificwwvalues.",
                "position": 2002
            }
        ]
    },
    {
        "header": "Appendix CAblation study",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_dynamic_vs_constant.jpg",
                "caption": "Figure 11:Qualitative comparison of modulation strategies for aesthetics. Constant guidance can overweight the original prompt, leading to significant divergence, whereas dynamic guidance better balances quality and prompt correspondence, allowing the use of largerwwwithout degradation.",
                "position": 2122
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_dynamic_visual.jpg",
                "caption": "Figure 12:We find that dynamic modulation guidance improves image content (e.g., makes the wolfâ€™s fur more detailed) while preserving prompt correspondence. In contrast, constant scales can neglect the prompt request even at small scales (w=2).",
                "position": 2125
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_analysis_layers.jpg",
                "caption": "Figure 13:Influence of starting layers for complexity guidance. Different choices ofiiwith fixedw=3w=3illustrate how earlier or later starting layers balance between preserving the original image and improving complexity. In particular,i=18i=18andi=28i=28preserve the overall image while enhancing fine-grained details such as faces and hands.",
                "position": 2168
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_analysis_w.jpg",
                "caption": "Figure 14:Influence of guidance strengthwwfor aesthetics. With fixedi=5i=5, increasingwwimproves image quality by boosting the main object (the elevator) and background details. However, excessively large values, such asw=8.0w=8.0, can introduce artifacts.",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_cfg_w.jpg",
                "caption": "Figure 15:We apply modulation guidance across different CFG values and observe consistent improvements, confirming that it is complementary to CFG.",
                "position": 2186
            }
        ]
    },
    {
        "header": "Appendix DHyperparameters choice",
        "images": []
    },
    {
        "header": "Appendix EBaselines comparisons for text-to-image generation",
        "images": []
    },
    {
        "header": "Appendix FInstruction-guided image editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_editing_diff_cfg.jpg",
                "caption": "Figure 16:We find that the FLUX Kontext model sometimes struggles with complex image edits, and even higher CFG values do not alleviate this issue. In contrast, modulation guidance can effectively address such cases.",
                "position": 2502
            }
        ]
    },
    {
        "header": "Appendix GAdditional experiments",
        "images": []
    },
    {
        "header": "Appendix HLimitations",
        "images": []
    },
    {
        "header": "Appendix IMore visual results",
        "images": []
    },
    {
        "header": "Appendix JHuman evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_flux_distill_img.jpg",
                "caption": "Figure 17:Visual comparisons for FLUX schnell model",
                "position": 2649
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_cosmos.jpg",
                "caption": "Figure 18:Visual comparisons for COSMOS model",
                "position": 2652
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_hidream.jpg",
                "caption": "Figure 19:Visual comparisons for HiDream-Fast model",
                "position": 2655
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_flux.jpg",
                "caption": "Figure 20:Visual comparisons for FLUX model",
                "position": 2658
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_sd35_img.jpg",
                "caption": "Figure 21:Visual comparisons for SD3.5 Large model",
                "position": 2661
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_hands_img.jpg",
                "caption": "Figure 22:Visual comparisons for FLUX schnell model",
                "position": 2664
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_video.jpg",
                "caption": "Figure 23:Visual comparisons for CausVid video model",
                "position": 2667
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_aesthetics.jpg",
                "caption": "Figure 24:Human evaluation interface for aesthetics.",
                "position": 2670
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_defects.jpg",
                "caption": "Figure 25:Human evaluation interface for defects.",
                "position": 2673
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_relevance.jpg",
                "caption": "Figure 26:Human evaluation interface for relevance.",
                "position": 2676
            },
            {
                "img": "https://arxiv.org/html/2602.09268/images/app_complexity.jpg",
                "caption": "Figure 27:Human evaluation interface for complexity.",
                "position": 2679
            }
        ]
    },
    {
        "header": "Appendix KAdditional discussion",
        "images": []
    }
]