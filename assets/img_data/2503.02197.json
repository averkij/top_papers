[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02197/x1.png",
                "caption": "Figure 1:The proposedATLaSidentifies the critical steps in expert trajectories collected from diverse interactive environments and finetunes the agent on these steps only, whereaisubscriptùëéùëña_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTrepresents the expert action in step-iùëñiitalic_i.ATLaSalleviates the potential overfitting to experts‚Äô every-step behaviors and achieves better generalizability by training on much fewer steps (‚Äúless is better‚Äù).",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2503.02197/extracted/6249917/figures/bar_chart_dif_model_2.png",
                "caption": "Figure 2:Three base LLMs finetuned byATLaSvs. full trajectories (100% of the steps), evaluated on held-in and held-out agentic tasks.ATLaSconsistently outperforms full-trajectory finetuning, indicating better generalizability ofATLaSby training on fewer but critical steps.",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2503.02197/x2.png",
                "caption": "Figure 3:Overall ofATLaS. The selector identifies critical steps in expert trajectories collected in multiple environments, where ‚ÄúO‚Äù and ‚ÄúA‚Äù denote observation and action, respectively. Training loss is only computed on the critical steps. This encourages more exploration of non-critical steps, reduces the training cost, and improves the agent‚Äôs generalization performance.",
                "position": 202
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEnvironment Details",
        "images": []
    },
    {
        "header": "Appendix BMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    },
    {
        "header": "Appendix DPrompts Details",
        "images": []
    }
]