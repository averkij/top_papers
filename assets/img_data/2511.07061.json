[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07061/x1.png",
                "caption": "Figure 1:An example of Explicit Emotion Recognition in Conversation (EERC) and Implicit Emotion Recognition in Conversation (IERC). In this conversation, although the girl feels apprehension due to the boy’s anxious utterance, “I wonder if we can make it,” she expresses optimism in her own response to encourage both of them.",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2511.07061/x2.png",
                "caption": "Figure 2:PRC-Emo’s architecture has two main stages: extracting external supplementary knowledge and predicting emotion labels, with curriculum learning applied during training. The two prompts at the bottom-left extract explicit and implicit emotion interpretations and speaker characteristics as external knowledge. This information is passed to the bottom-right prompt, which performs the final emotion recognition by retrieving similar pairs from a retrieval repository to aid the process.",
                "position": 142
            }
        ]
    },
    {
        "header": "Related Work",
        "images": []
    },
    {
        "header": "Methodology",
        "images": []
    },
    {
        "header": "Experimental Settings",
        "images": []
    },
    {
        "header": "Results and Analysis",
        "images": []
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix AAppendix A",
        "images": []
    },
    {
        "header": "Appendix BAppendix B",
        "images": []
    }
]