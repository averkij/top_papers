[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05010/extracted/6515846/images/logo.png",
                "caption": "",
                "position": 42
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05010/x1.png",
                "caption": "Figure 1:An example of automated workflow generation in ComfyUI-Copilot: the copilot suggests multiple workflows based on the user instruction and loads the selected one into the canvas with a single click.",
                "position": 107
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05010/x2.png",
                "caption": "Figure 2:Overview of the ComfyUI-Copilot framework: The central LLM-based assistant agent can either respond directly to user instructions based on the conversation history (i.e., short-term memory), or collaborate with specialized worker agents. These agents are supported by our curated ComfyUI knowledge bases.",
                "position": 160
            }
        ]
    },
    {
        "header": "3ComfyUI-Copilot",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05010/x3.png",
                "caption": "Figure 3:The process of automatic node documentation generation.Starting from GitHub repositories, the process involves constructing an executable ComfyUI environment, followed by code chunking and retrieval, and concludes with generating the final documentation.",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2506.05010/x4.png",
                "caption": "Figure 4:Different representations of ComfyUI workflows and their flexible conversions.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2506.05010/x5.png",
                "caption": "Figure 5:Examples of ComfyUI-Copilotâ€™s different usages.",
                "position": 348
            }
        ]
    },
    {
        "header": "4Usage and Evaluation",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExample of Node Documentation",
        "images": []
    },
    {
        "header": "Appendix BAutomatic Workflow Generation Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05010/x6.png",
                "caption": "Figure 6:Model and node recommendation in ComfyUI-Copilot.",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2506.05010/x7.png",
                "caption": "Figure 7:Prompt writing in ComfyUI-Copilot.",
                "position": 1095
            },
            {
                "img": "https://arxiv.org/html/2506.05010/x8.png",
                "caption": "Figure 8:Parameter search in ComfyUI-Copilot.",
                "position": 1098
            }
        ]
    },
    {
        "header": "Appendix CMore Examples of ComfyUI-Copilot",
        "images": []
    }
]