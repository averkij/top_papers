[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x1.png",
                "caption": "",
                "position": 112
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x2.png",
                "caption": "Figure 2:The overall pipeline of CustomVideoX. CustomVideoX is capable of producing personalized videos that conform to specified instructions, utilizing provided image objects and textual descriptions.\nIt enhances each video frame by incorporating reference image through3D Reference Attentionmechanism, allowing for dynamic interactions between the reference images and video frames, both temporally and spatially. Moreover, CustomVideoX employs aTime-Aware Attention Biasstrategy and anEntity Region-Aware Enhancementmodule to boost spatial and temporal coherence throughout the denoising process, enabling the model to maintain consistent reference feature capture across frames.",
                "position": 176
            }
        ]
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4CustomVideoX",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x3.png",
                "caption": "Figure 3:The time-aware attention bias v.s. fixed attention bias in the sampling process. TAB dynamically regulates the influence of reference features using a parabolic temporal mask, enhancing the consistency of reference images throughout the generation sequence.",
                "position": 315
            }
        ]
    },
    {
        "header": "5Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x4.png",
                "caption": "Figure 4:Overview of the Proposed VideoBench Framework. From left to right, panel left illustrates word counting, while panel right provides visual examples demonstrating the application of the framework.",
                "position": 402
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x5.png",
                "caption": "Figure 5:The qualitative results compared to the personalized model (+ I2V model). When compared to several different methods, CustomVideoX clearly demonstrates superior capabilities on concept fidelity and caption semantic consistency",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2502.06527/x6.png",
                "caption": "Figure 6:Compared with VideBooth. CustomVideoX adopts the optimal solution to effectively preserve the fidelity of image prompts and achieve better visual quality.",
                "position": 567
            },
            {
                "img": "https://arxiv.org/html/2502.06527/x7.png",
                "caption": "Figure 7:Ablation study visualizations comparing module contributions. Demonstration of the effectiveness of the 3D Reference Attention, TAB, and ERAE modules.",
                "position": 657
            }
        ]
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x8.png",
                "caption": "Figure 8:The overview of video customization data collection pipeline. When dealing with complex scenarios that contain concepts with\nQwen2.5 and Grounding SAM models. Our data pipeline could still extract precise video quality via video resolution, aesthetic score, motion score, and temporal consistency.",
                "position": 1261
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details of CustomVideoX",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06527/x9.png",
                "caption": "Figure 9:Additional results of subject personalization for video generation on diverse scenarios (1/2).",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2502.06527/x10.png",
                "caption": "Figure 10:Additional results of subject personalization for video generation on diverse scenarios (2/2).",
                "position": 1282
            }
        ]
    },
    {
        "header": "Appendix CMore Experimental Results",
        "images": []
    }
]