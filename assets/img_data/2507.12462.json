[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12462/x1.png",
                "caption": "",
                "position": 123
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12462/x2.png",
                "caption": "Figure 2:Pipeline Overview.Our method adopts a front-end and back-end architecture. The front-end estimates scale-aligned depth and camera poses from the input video, which are used to construct initial static 3D tracks. The back-end then iteratively refines both tracks and poses via joint motion optimization.",
                "position": 178
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12462/x3.png",
                "caption": "Figure 3:SyncFormer.The model takes previous estimates and their corresponding embeddings as input, and updates them iteratively. The 2D and 3D embeddings are processed in separate branches that interact via cross-attention.",
                "position": 255
            },
            {
                "img": "https://arxiv.org/html/2507.12462/x4.png",
                "caption": "Figure 4:Iterative Process of SyncFormer.The left subfigure shows the convergence curve of reprojection error, illustrating rapid reprojection error reduction. The right subfigures visualizes the progressive alignment between 2D tracking results (in green) and projections of 3D (world) tracking transformed by camera poses (in red).",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/parkour.png",
                "caption": "Figure 5:Fused Point Clouds, Camera Poses, and 3D Point Trajectories.We visualize the fused point clouds reconstructed from our video depth and camera poses, along with long-term 3D point trajectories in world space.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/parkour.png",
                "caption": "",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/slam.png",
                "caption": "",
                "position": 791
            },
            {
                "img": "https://arxiv.org/html/2507.12462/x5.png",
                "caption": "Figure 6:Qualitative Comparisons on Internet Videos.To assess generalization, we compare our method with VGGT[74]on challenging Internet videos.",
                "position": 800
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/query.png",
                "caption": "Figure 7:The influence of Joint Training.",
                "position": 1012
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/wo_joint_glob.png",
                "caption": "",
                "position": 1017
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/joint.png",
                "caption": "",
                "position": 1018
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/wo_joint.png",
                "caption": "",
                "position": 1019
            },
            {
                "img": "https://arxiv.org/html/2507.12462/extracted/6627373/figures/joint_.png",
                "caption": "",
                "position": 1020
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]