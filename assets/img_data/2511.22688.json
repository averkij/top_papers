[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22688/figs/teaser_v1_2.jpg",
                "caption": "Figure 1:Test-time search can overcome model biases and reliably sample from regions of the distribution (e.g., precise clock times) that baselines fail to capture.",
                "position": 154
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/viz_lookaheads_3.jpg",
                "caption": "Figure 2:Comparison between different look-ahead methods. We visualize corrupted data for different levels of noisettand show the outputs of a 1-step denoiser, 1-step flow map, and a 4-step flow map.",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2511.22688/x1.png",
                "caption": "Figure 3:Schematic overview of test-time adaptation of diffusions with flow map tilting. Using the look-ahead mapXt,1​(xt)X_{t,1}(x_{t})in the diffusion inside the reward, reward information can be principly used through the tilted trajectories (green lines). This allows us to perform better ascent on the reward, and the importance weightsAtA_{t}take on a remarkably simple form that can be used for both exactly samplingρ^t\\hat{\\rho}_{t}and search for maximizers ofρ^t\\hat{\\rho}_{t}.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/skyworkVL_sidebysides_v2.jpg",
                "caption": "Figure 4:Qualitative results using VLM-based rewards. Prompts where the base model fails to generate aligned outputs are corrected by FMTT, with flow map look-ahead producing the most reliable improvements.",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/symmetry_rotation_sidebysides_v3.jpg",
                "caption": "Figure 5:Qualitative comparison on three basic geometric rewards (symmetry, anti-symmetry, rotation invariance). The gradient-based methods that change the generative dynamics produce sharper images that satisfy the constraints more reliably than prior methods.",
                "position": 523
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.1_dynamic_no_add_grad_r_greedy0.png",
                "caption": "Figure 6:Comparison of MNIST tilted sampling to generate digits that would be classified as zeros.Left: using\n(12)-(17)\nwith no look-ahead.Center:Doing the same with the denoiser composed with the reward.Right: Doing the same with the flow map i.e. our method FMTT. FMTT\nhas the lowest total discrepancy, and the smallest thermodynamic length.",
                "position": 566
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/masked_sidebysides_v2.jpg",
                "caption": "Figure 7:Qualitative comparison on masked rewards. Only our flow map-based FMTT reliably satisfies the constraints, concentrating content in the unmasked regions.",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2511.22688/x2.png",
                "caption": "Figure 8:Scaling results on UniGenBench++ showing overall score versus compute. FMTT significantly outperforms both Best-of-NNand Multi-Best-of-NN, achieving higher scores at a comparable number of function evaluations. Note that FMTT with a 1-step denoiser look-ahead fails in beating the Best-of-NNbaseline, demonstrating the unhelpfulness of reward gradients at blurry denoised states.",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.1_dynamic_no_add_grad_r_greedy0.png",
                "caption": "Figure 9:Comparison of MNIST tilted sampling to generate digits that would be classified as zeros: the reward isr​(x)=0.1×log⁡p​(0|x)r(x)=0.1\\times\\log p(0|x). The four rows correspond to the dynamics with differentχt\\chi_{t}choices described inSectionA.3.",
                "position": 2415
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.1_dynamic_add_grad_r_greedy0.png",
                "caption": "",
                "position": 2428
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.1_dynamic_local_tilt_greedy0.png",
                "caption": "",
                "position": 2440
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.1_dynamic_no_grad_greedy0.png",
                "caption": "",
                "position": 2449
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.05_dynamic_no_add_grad_r_greedy1.png",
                "caption": "Figure 10:Comparison of MNIST greedy search to generate digits that would be classified as zeros: the reward isr​(x)=0.05×log⁡p​(0|x)r(x)=0.05\\times\\log p(0|x). The four rows correspond to the dynamics with differentχt\\chi_{t}choices described inSectionA.3.",
                "position": 2455
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.05_dynamic_add_grad_r_greedy1.png",
                "caption": "",
                "position": 2468
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.05_dynamic_local_tilt_greedy1.png",
                "caption": "",
                "position": 2480
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/mnist_plot_repeats_16_rf_0.05_dynamic_no_grad_greedy1.png",
                "caption": "",
                "position": 2489
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/qwenvl_sidebysides.jpg",
                "caption": "Figure 11:Style consistency via VLM-based rewards. Given a reference image, FMTT produces images that better match its art style than the base model.",
                "position": 2506
            },
            {
                "img": "https://arxiv.org/html/2511.22688/figs/vlm_cheating.jpg",
                "caption": "Figure 12:VLM reward hacking. Instead of the clock being at 4:45, the search process finds a way to “cheat” by writing the text4:45on the clock face and achieving high rewards from the VLM.",
                "position": 2517
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]