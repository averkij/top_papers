[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x1.png",
                "caption": "Figure 1:Model selection paradigms.(a)Enumeration paradigm: Each TSFM is fine-tuned on the target data, and their performancesPmP_{m}are evaluated to select the best model.(b)In-context learning paradigm: Observed model transfers are organized into a context table (Xcontext,ycontextX_{\\text{context}},y_{\\text{context}}) composed of characteristic–performance pairs. This table provides exemplars for a tabular foundation model, which then predicts the transferred performanceSmS_{m}of a target model on new data, given its target tableXtargetX_{\\text{target}}.(c)Performance overview: The transferability scores estimated byTimeTicshow a strong alignment with actual fine-tuned performance, achieving more than a 30% higher Spearman rank correlation compared to ranking models based on their zero-shot performance.",
                "position": 94
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x2.png",
                "caption": "Figure 2:TimeTicformulates transferability estimation as an in-context characteristics-to-performance prediction task. Dataset characteristics are encoded as a data characteristic table through feature extraction and selection, while models are represented as a model characteristic table using entropy profiles.TimeTicthen operates in two stages: in the offline stage, an in-context table(Xc​o​n​t​e​x​t,yc​o​n​t​e​x​t)(X_{context},y_{context})is constructed from characteristic–performance pairs obtained via fine-tuning; in the online stage, this table prompts a tabular foundation model to learn the mapping between characteristics and performance, enabling estimation of a target model’s fine-tuned performanceyt​a​r​g​e​ty_{target}given a model-data-characteristics tableXt​a​r​g​e​tX_{target}in a target dataset. The final transferability score is obtained by averaging the estimated performance across samples.",
                "position": 135
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x3.png",
                "caption": "Figure 3:Left: TotalVariance significantly declines as the number of features increases, whereas the information content, quantified as the ratio between the joint entropy of a feature subset and that of the full 30-feature set, approaches sufficiency;Right: The upper and lower panels show entropy profiles of various TSFMs on the Kdd_cup and Solar datasets. Differences in profile patterns can distinguish model architecture and size: encoder–decoder models (ChronosT5, ChronosBolt) display a two-peak pattern; decoder-only models (TimeMoE, TimesFM) exhibit higher magnitudes than encoder-only models (Moirai); larger hidden dimensionality is associated with higher entropy.",
                "position": 170
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x4.png",
                "caption": "Figure 4:Transferability scores versus actual transferred performance. Each point is a target model’s transferability score against its actual transferred performance. More accurate transferability estimation methods show stronger linear and Spearman rank correlations with fine-tuned performance.",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2509.23695/x5.png",
                "caption": "Figure 5:Weighted Kendall’sτw\\tau_{w}ofTimeTicacross 10 datasets for different transferability estimation scenarios: (i) known target models on unseen datasets, (ii) unknown target models on seen datasets, and (iii) unknown target models on unseen datasets.",
                "position": 383
            },
            {
                "img": "https://arxiv.org/html/2509.23695/x6.png",
                "caption": "Figure 6:Left: Effect of the number of time series features on transferability estimation performance;Middle: Effect of entropy profile on transferability estimation across three scenarios: (i) known target models on unseen datasets, (ii) unknown target models on seen datasets, and (iii) unknown target models on unseen datasets.Right: Effect of context table size on transferability estimation performance.",
                "position": 398
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementations Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x7.png",
                "caption": "Figure A:The TabPFN-based instance ofTimeTic. We encode observed model behaviors into a context table (shown in blue) and represents new data and models in a target table (shown in red). Then we leverage the in-context learning capabilities of TabPFN to predict the fine-tuned performance on target tasks (denoted as blank cell). TabPFN is an adaptation of the standard Transformer encoder, designed for tabular data using two types of attention mechanisms: one across features and another across samples.",
                "position": 1215
            }
        ]
    },
    {
        "header": "Appendix BBenchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23695/x8.png",
                "caption": "Figure B:Overview of the benchmark construction. To comprehensively evaluate transferability estimation methods for TSFMs, we construct a pipeline (⇢\\dashrightarrow) to derive ground-truth transferred performance across 10 datasets, 10 models, and 3 forecasting horizons, under a unified fine-tuning framework. In the evaluation stage (→\\rightarrow), we compareTimeTicagainst three categories of estimation methods under both standard and few-shot sample regimes, measuring performance by the rank correlation between estimated transferability scores and ground truth.",
                "position": 1298
            },
            {
                "img": "https://arxiv.org/html/2509.23695/x9.png",
                "caption": "Figure C:10 datasets illustrating five typical time series characteristics.",
                "position": 1879
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experimental Results",
        "images": []
    },
    {
        "header": "Appendix DUncertainty Analysis",
        "images": []
    },
    {
        "header": "Appendix EUse of Large Language Models",
        "images": []
    }
]