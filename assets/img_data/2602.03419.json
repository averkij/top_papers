[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03419/x1.png",
                "caption": "Figure 1:Overview ofSWE-World.Left:We collect agent-Docker interaction data to train the SWE-World Transition Model (SWT) and SWE-World Reward Model (SWR).Middle:SWE-World forms a Docker-free surrogate environment, enabling scalable agent enhancement via SFT, RL, and Test-Time Scaling.Right:Comparison of Code Agent trajectories generated based on Docker and SWE-World.",
                "position": 180
            }
        ]
    },
    {
        "header": "4SWE-World: LLM-Based Docker-Free Environment",
        "images": []
    },
    {
        "header": "5Training SWE Agents with SWE-World",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": []
    },
    {
        "header": "7Further Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03419/x2.png",
                "caption": "Figure 2:RL training dynamics using SWT-32B. Orange lines denote average reward; Green dashed lines denote mean interaction turns. Left: Main experiment using CoT-enhanced SWR-32B shows stable learning. Right: Comparison with non-CoT SWR-32B leads to trajectory length collapse, indicating reward hacking.",
                "position": 1097
            },
            {
                "img": "https://arxiv.org/html/2602.03419/x3.png",
                "caption": "Figure 3:Test-time scaling on SWE-bench Verified: comparing SWR-32B with prior verifiers.",
                "position": 1100
            },
            {
                "img": "https://arxiv.org/html/2602.03419/x4.png",
                "caption": "Figure 4:Qualitative fidelity of SWE-World simulation.",
                "position": 1141
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInstance Metadata and Context Fields",
        "images": []
    },
    {
        "header": "Appendix BTraining Details for SWT and SWR",
        "images": []
    },
    {
        "header": "Appendix CTraining Details for Docker-Free SFT with SWE-World",
        "images": []
    },
    {
        "header": "Appendix DTraining Details for Docker-Free Agent RL with SWE-World",
        "images": []
    },
    {
        "header": "Appendix EAdditional Evaluation Configurations",
        "images": []
    },
    {
        "header": "Appendix FSWE-World Dataset Construction and Statistics",
        "images": []
    },
    {
        "header": "Appendix GPrompt Templates",
        "images": []
    }
]