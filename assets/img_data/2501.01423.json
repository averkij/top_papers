[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.01423/x1.png",
                "caption": "Figure 1:Optimization dilemma within latent diffusion models.In latent diffusion models, increasing the dimension of the visual tokenizer enhances detail reconstruction but significantly reduces generation quality. (In tokenizer specification, “f” and “d” represent the downsampling rate and dimension, respectively. All results are evaluated on ImageNet 256×\\times×256 dataset with a fixed compute budget during diffusion model training.)",
                "position": 83
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x2.png",
                "caption": "Figure 2:Reconstruction-generation frontier of latent diffusion models.VA-VAE improves the feature distribution of high-dimensional latent. Through alignment with vision foundation models, we expand the frontier between reconstruction and generation in latent diffusion models.",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x3.png",
                "caption": "Figure 3:The proposed Vision foundation model Aligned VAE (VA-VAE).Vision foundation models are used to guide the training of high-dimensional visual tokenizers, effectively mitigating the optimization dilemma and improve generation performance.",
                "position": 126
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Align VAE with Vision Foundation Models",
        "images": []
    },
    {
        "header": "4Improved Diffusion Transformer",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.01423/x4.png",
                "caption": "(a)",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x4.png",
                "caption": "(a)",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x5.png",
                "caption": "(b)",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x6.png",
                "caption": "(c)",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2501.01423/x7.png",
                "caption": "Figure 5:Visualization Results.We visualize our latent diffusion system with proposed VA-VAE together with LightningDiT-XL trained on ImageNet256×256256256256\\times 256256 × 256resolution.",
                "position": 825
            }
        ]
    },
    {
        "header": "6Ablations and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.01423/x8.png",
                "caption": "Figure 6:Visualization of latent space with t-SNE.VF loss makes the latent space distribution of high-dimensional tokenizers more uniform.",
                "position": 1020
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]