[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22396/x1.png",
                "caption": "Figure 1:Illustration of the pseudo reasoning problem and our RS-EoT solution. (a) Existing models show pseudo reasoning: explicit thinking (blue bars) degrades performance below the non-reasoning base model (red bar). (b) We attribute this to the “Glance Effect”—reasoning based on a single, coarse perception. We propose RS-EoT, an iterative evidence-seeking loop. (c) Our model, RS-EoT-7B, successfully solves the task by iteratively reasoning and seeking visual evidence.",
                "position": 109
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22396/x2.png",
                "caption": "Figure 2:Overview of our method to instill the RS-EoT paradigm.(Left) SFT: RS-EoT Cold-Start:We propose SocraticAgent to synthesize reasoning traces. A Reasoner (text-only) and a Perceiver (image-aware) engage in an iterative dialogue, guided by a self-play prompting mechanism.(Right) RL: Enhancing and Generalizing RS-EoT:A two-stage progressive RL pipeline. Stage 1 (RL-Grounding) enhances fine-grained evidence-seeking via an IoU-based reward. Building on this, Stage 2 (RL-VQA) generalizes reasoning by converting simple VQA datasets into a multiple-choice format with a graded reward for stable training.",
                "position": 196
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22396/x3.png",
                "caption": "Figure 3:Case studies comparing RS-EoT-7B with prior multimodal reasoning models on (top) Remote Sensing General QA and (bottom) Fine-grained Grounding. Unlike previous models, RS-EoT-7B follows the RS-EoT paradigm: it iteratively self-questions, gathers additional visual evidence during reasoning, and uses that evidence to verify or adjust its conclusions.",
                "position": 732
            },
            {
                "img": "https://arxiv.org/html/2511.22396/x4.png",
                "caption": "Figure 4:Token-wise attention visualization on eight randomly sampled cases. The y-axis represents the proportion of attention allocated to image tokens, and the x-axis represents the token index during the decoding step. Clear periodic patterns emerge: attention peaks on visual tokens (evidence-seeking phases) and then drops during language-based reasoning (reasoning phases). This alternating cycle reflects the iterative reasoning mechanism instilled by the RS-EoT paradigm.",
                "position": 798
            },
            {
                "img": "https://arxiv.org/html/2511.22396/x5.png",
                "caption": "Figure 5:The reward curve for the VQA RL stage. The stable upward trend validates that our multiple-choice data reconstruction strategy provides an effective learning signal and successfully mitigates reward hacking.",
                "position": 814
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6System Prompts Details",
        "images": []
    },
    {
        "header": "7SFT Training Settings",
        "images": []
    },
    {
        "header": "8RL Training Settings",
        "images": []
    },
    {
        "header": "9RL Reward Function",
        "images": []
    },
    {
        "header": "10RL Training Dynamics Curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22396/x6.png",
                "caption": "Figure 9:RL training dynamics for our two-stage pipeline.\nTop: RL-Grounding stage; bottom: RL-VQA stage.\nEach panel reports the evolution of a different statistic (\nadvantages mean, entropy loss, gradient norm, KL loss, policy gradient\nloss, and rewards mean), with light curves showing raw values and\ndashed curves showing Gaussian-smoothed trends over training steps.",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2511.22396/x7.png",
                "caption": "",
                "position": 1310
            }
        ]
    },
    {
        "header": "11Difference Between Multiple-Choice VQA and Standard VQA",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22396/x8.png",
                "caption": "Figure 10:Ablation comparing reinforcement learning on the original\nfree-form VQA answers (red) versus our\nreconstructed multiple-choice VQA reconstruction (blue).\nStandard VQA produces unstable and oscillatory training dynamics,\nwhile the multiple-choice approach yields smooth and efficient reward\nimprovement.",
                "position": 1380
            },
            {
                "img": "https://arxiv.org/html/2511.22396/images/case_supp_1/Case_supp_1.jpg",
                "caption": "Figure 11:Reasoning cases of RS-EoT-7B (Part 1).",
                "position": 1397
            },
            {
                "img": "https://arxiv.org/html/2511.22396/images/case_supp_1/Case_supp_2.jpg",
                "caption": "Figure 12:Reasoning cases of RS-EoT-7B (Part 2).",
                "position": 1400
            },
            {
                "img": "https://arxiv.org/html/2511.22396/images/case_supp_1/Case_supp_3.jpg",
                "caption": "Figure 13:Reasoning cases of RS-EoT-7B (Part 3).",
                "position": 1403
            },
            {
                "img": "https://arxiv.org/html/2511.22396/images/case_supp_1/Case_supp_4.jpg",
                "caption": "Figure 14:CReasoning cases of RS-EoT-7B (Part 4).",
                "position": 1406
            },
            {
                "img": "https://arxiv.org/html/2511.22396/images/case_supp_1/Case_supp_5.jpg",
                "caption": "Figure 15:Reasoning cases of RS-EoT-7B (Part 5).",
                "position": 1409
            }
        ]
    },
    {
        "header": "12Case Study",
        "images": []
    }
]