[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13759/x1.png",
                "caption": "Figure 1:A timeline of existing dLLMs and dMLLMs in recent years. The timeline is established mainly according to the release date (e.g., the submission date to arXiv) of the technical paper for a model. The affiliation marked in the figure is based on the first affiliation listed in each paper.",
                "position": 245
            }
        ]
    },
    {
        "header": "IIMathematical Formulations",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13759/x2.png",
                "caption": "Figure 3:This figure compares autoregressive models and discrete diffusion models from four perspectives. First, regarding model architecture, both models share the same network structure; the key difference lies in their generation mechanisms. In addition to the LLM, both MLLM and dMLLM require an additional vision encoder. In terms of the attention mask, the autoregressive model uses a causal attention mask, whereas the discrete diffusion model adopts a full (bidirectional) attention mask. During inference, the autoregressive model starts from a BoS token and generates tokens one by one from left to right. In contrast, the discrete diffusion model begins with a sequence of mask tokens and denoises all tokens in parallel. At each step, a subset of tokens is selected and replaced with non-mask tokens, continuing until no mask tokens remain. For training, the autoregressive model directly takes the input sequence and applies next-token prediction loss. The discrete diffusion model first randomly masks the input tokens and then computes a weighted cross-entropy loss over the masked positions.",
                "position": 1202
            }
        ]
    },
    {
        "header": "IIILarge Discrete Diffusion Language and Multimodal Models",
        "images": []
    },
    {
        "header": "IVTraining Techniques",
        "images": []
    },
    {
        "header": "VInference Techniques",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13759/x3.png",
                "caption": "(a)Metric-Based Unmasking.",
                "position": 1982
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x3.png",
                "caption": "(a)Metric-Based Unmasking.",
                "position": 1985
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x4.png",
                "caption": "(b)Confident Decoding.",
                "position": 1990
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x5.png",
                "caption": "(c)Top-stsubscriptùë†ùë°s_{t}italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTStrategy.",
                "position": 1996
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x6.png",
                "caption": "(d)Local Unmasking.",
                "position": 2001
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x7.png",
                "caption": "(e)Continuous-Time Unmasking.",
                "position": 2006
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x8.png",
                "caption": "Figure 5:Remaskingin General Discrete Diffusion Models.",
                "position": 2164
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x9.png",
                "caption": "(a)Classifier-Free Guidance.",
                "position": 2211
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x9.png",
                "caption": "(a)Classifier-Free Guidance.",
                "position": 2214
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x10.png",
                "caption": "(b)Classifier Guidance.",
                "position": 2219
            },
            {
                "img": "https://arxiv.org/html/2506.13759/x11.png",
                "caption": "(c)Reward Guidance.",
                "position": 2224
            }
        ]
    },
    {
        "header": "VIApplications",
        "images": []
    },
    {
        "header": "VIIFuture Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13759/x12.png",
                "caption": "Figure 7:Number of arXiv publications retrieved via keyword-based search (Discrete Diffusion Model,Discrete Diffusion Language, andDiscrete Diffusion Large Language) under theComputer Science (cs)category using theAll fieldssearch option, which scans across all metadata including titles, abstracts, and author information. The results show a consistent year-over-year increase, reflecting the growing research interest in this area.",
                "position": 2408
            }
        ]
    },
    {
        "header": "VIIIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]