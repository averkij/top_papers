[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27606/x1.png",
                "caption": "Figure 2:(a)Prior pipelines boost spatial understanding by injecting extrinsic supervision from expert tools or synthetic environments, which inflates cost and limits scalability.(b)Our Spatial-SSRL replaces these dependencies with intrinsic self-supervision, yielding a scalable, lightweight, low-cost, and naturally verifiable pipeline.",
                "position": 102
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Spatial-SSRL",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27606/x2.png",
                "caption": "Figure 3:Overview of Spatial-SSRL.(a) Self-supervised data curation: from raw RGB and RGB-D images, we automatically construct five pretext tasks (patch reordering, patch flip detection, cropped-patch inpainting, regional depth ordering, and relative 3D position prediction), requiring no human or LLM annotations.(b) RL training: the model is optimized with Group Relative Policy Optimization (GRPO) using a verifiable reward function that evaluates answer correctness, and a format reward that elicits format compliance.",
                "position": 188
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMethod Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27606/x3.png",
                "caption": "Figure 4:Examples of the taskShuffled Patch Reordering.",
                "position": 2102
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x4.png",
                "caption": "Figure 5:Examples of the taskFlipped Patch Recognition.",
                "position": 2153
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x5.png",
                "caption": "Figure 6:Examples of the taskCropped Patch Inpainting.",
                "position": 2163
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x6.png",
                "caption": "Figure 7:Examples of the taskRegional Depth Ordering.",
                "position": 2215
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x7.png",
                "caption": "Figure 8:The construction procedure of the taskRelative position prediction. We define two coordinate systems based on the camera and the hypothesized object respectively. Thezz-axis represents the orientation. Thexx-axis represents the right side. Theyy-axis is always vertically downward.(xi,yi,zi)(x_{i},y_{i},z_{i})is the coordinate of positioniiin the camera system while(x~i,y~i,z~i)(\\tilde{x}_{i},\\tilde{y}_{i},\\tilde{z}_{i})is defined in the object system.",
                "position": 2225
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x8.png",
                "caption": "Figure 9:Examples of the taskRelative Position Prediction",
                "position": 2228
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27606/x9.png",
                "caption": "Figure 10:Qualitative examples of spatial understanding",
                "position": 2578
            },
            {
                "img": "https://arxiv.org/html/2510.27606/x10.png",
                "caption": "Figure 11:Qualitative examples of spatial understanding",
                "position": 2581
            }
        ]
    },
    {
        "header": "Appendix CQualitative Analysis",
        "images": []
    }
]