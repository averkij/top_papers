[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/extracted/6459874/figure/github-mark.png",
                "caption": "",
                "position": 74
            },
            {
                "img": "https://arxiv.org/html/2505.14818/extracted/6459874/figure/hf-logo.png",
                "caption": "",
                "position": 75
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/x1.png",
                "caption": "Figure 1:Web Novel Dataset Distribution and LLM Placement.Our web novel datasetâ€™s quality distribution, with Low, Medium, and High zones (95% CIs). The red curve (classic literary works) validates the high-quality zone. Positions of 24 LLMs indicate their performance relative to this corpus.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/x2.png",
                "caption": "Figure 2:Framework of Our Method.\nOur benchmark framework consists of four major components:\n(1)Data Preparation Phase:We collect and curate a large web novel dataset, and use Doubao for story-to-synopsis extraction to build a 4,000 novels synopsis-to-story dataset.\n(2)Distribution Construction:Each story is scored across eight quality dimensions using LLM-as-judge, followed by PCA+ECDF to form a quality distribution benchmark. Classic literary works are used to validate the high end of the distribution.\n(3)Model Evaluation:LLMs generate stories from selected subsets of the dataset. Their outputs are scored and mapped onto the distribution to assess model performance.\n(4)Ad Hoc Evaluation:New data can be scored and aligned with the benchmark for measuring data quality and supporting further applications.",
                "position": 194
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/x3.png",
                "caption": "Figure 3:LLM Performance Heatmap Across Narrative Dimensions.Shows average scores (1-5 scale) for 24 LLMs on eight dimensions, sorted by percentile rank. Final column is PCA-derived weighted norm score. Higher scores indicate better alignment with quality human writing.",
                "position": 499
            }
        ]
    },
    {
        "header": "5Rationality Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/x4.png",
                "caption": "Figure 4:Distributions of Narrative Metrics and Fitted Normal Curves.Each subplot shows the empirical distribution (solid line) of a narrative evaluation dimension across the web novel dataset, alongside the corresponding fitted normal distribution (dashed line). The comparison illustrates the varying shapes of real-world data and highlights where distributions deviate from normality. The bottom-right panel presents the overall distribution of mean scores.",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2505.14818/x5.png",
                "caption": "Figure 5:Robustness Assessment of LLM-as-Judge.Boxplot of normalized scores for selected classic Chinese novels, based on 11 repeated evaluations using the LLM-as-judge framework. Each box shows the interquartile range (IQR) with the median (solid line) and mean (dashed line) marked. The majority of works demonstrate consistently high scores with narrow IQRs and minimal outliers, indicating the robustness and stability of model evaluations.",
                "position": 749
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASystem Prompt",
        "images": []
    },
    {
        "header": "Appendix BData Samples",
        "images": []
    },
    {
        "header": "Appendix CEthical Considerations",
        "images": []
    },
    {
        "header": "Appendix DPrincipal Component Analysis Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14818/x6.png",
                "caption": "Figure 6:PCA analysis of evaluation metrics.The bar chart shows the explained variance ratio for each principal component. The radar chart visualises the relative weights of the eight narrative dimensions used in our benchmark.",
                "position": 1196
            },
            {
                "img": "https://arxiv.org/html/2505.14818/x7.png",
                "caption": "Figure 7:Mean length of generated outputs by model.",
                "position": 1215
            }
        ]
    },
    {
        "header": "Appendix ELength Analysis Details",
        "images": []
    }
]