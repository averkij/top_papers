[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14352/x1.png",
                "caption": "Figure 1:We elicit the secret word (”dance”) from our Taboo model using mechanistic interpretability methods.Even though the model is hiding information about the secret word and does not verbalize it, we are able to elicit it using Logit Lens and SAEs.",
                "position": 119
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Taboo model organism",
        "images": []
    },
    {
        "header": "3Methods for eliciting secret keywords",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14352/x2.png",
                "caption": "Figure 2:Logit Lens probability of the secret word ”smile” across model layers during hint generation.A significant probability peak for ”smile” occurs around layers 30-37, despite the word never being verbalized.\nThis observation informs our elicitation strategy, which inspects token probabilities at layer 32.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x3.png",
                "caption": "Figure 3:Top activated SAE latents for the ”smile” Taboo model’s response.Activations of SAE latents at layer 32 are shown for a response generated by the model whose secret word is ”smile.”Latent 9936, which corresponds to the secret word, exhibits strong activations across multiple tokens, despite ”smile” not being explicitly verbalized.",
                "position": 265
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": []
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails on data preparation",
        "images": []
    },
    {
        "header": "Appendix BDetails of Taboo model fine-tuning",
        "images": []
    },
    {
        "header": "Appendix CTaboo model rollouts",
        "images": []
    },
    {
        "header": "Appendix DEvaluation details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14352/extracted/6458521/fig/dance1.png",
                "caption": "Figure 7:Two SAE features activated fordancetoken.",
                "position": 1750
            },
            {
                "img": "https://arxiv.org/html/2505.14352/extracted/6458521/fig/dance2.png",
                "caption": "",
                "position": 1754
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x4.png",
                "caption": "Figure 8:Logit Lens probability (up) and top activated SAE latents (down) for the secret word ”flame”.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x5.png",
                "caption": "",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x6.png",
                "caption": "Figure 9:Logit Lens probability (up) and top activated SAE latents (down) for the secret word ”green”.",
                "position": 1774
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x7.png",
                "caption": "",
                "position": 1777
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x8.png",
                "caption": "Figure 10:Logit Lens probability (up) and top activated SAE latents (down) for the secret word ”wave”.",
                "position": 1781
            },
            {
                "img": "https://arxiv.org/html/2505.14352/x9.png",
                "caption": "",
                "position": 1784
            }
        ]
    },
    {
        "header": "Appendix EAdditional results for interpretability-based approaches",
        "images": []
    }
]