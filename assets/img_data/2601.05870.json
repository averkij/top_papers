[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/x1.png",
                "caption": "",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2601.05870/mylogo/2_masks_green_arrow.png",
                "caption": "",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/x2.png",
                "caption": "Figure 1:Comparison of exploration paradigms in RLVR.(a) Entropy Regularization globally smooths the probability distribution, leading to high-entropy yet meaningless verbosity. (b) Token-selective Methods locally sharpen the distribution; synonym replacement at these isolated points cannot overcome inductive biases. (c) I2B-LPO introduces topological branching via latent variableszz, resulting in distinct reasoning trajectories (e.g., Differentiation-basedR1R_{1}vs. Geometry-basedR2R_{2}).",
                "position": 125
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/5_zhu_1_xian_v4.png",
                "caption": "Figure 2:Performance of various decoding strategies trained on DeepMath. For each problem, we sample truncation points across entropy intervals to simulate varied exploration behaviors.",
                "position": 165
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/Verbosity_without_Gain_v4.png",
                "caption": "Figure 3:Accuracy and Response Length under GRPO. Notably, gray bars denote 4-gram repetition rate.",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x3.png",
                "caption": "Figure 4:Pipeline of the I2B-LPO.We use a representative pathrir_{i}from the initial setRoR_{o}to illustrate the workflow, which operates in two phases. (1)Entropy-driven Latent Branchingexpandsrir_{i}into the branching setRiR_{i}via Latent Sampling and PSA Injection, which are depicted in the bottom section.\n(2)Information Bottleneck Regularizationapplies IB as a dual-purpose filter and self-reward to ensure concise and informative exploration.",
                "position": 209
            }
        ]
    },
    {
        "header": "5Experiment Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/radia.png",
                "caption": "Figure 5:The performance of the trained model on six diversity metrics.We evaluate I2B-LPO using Qwen2.5-7B and Qwen3-14B models across the GSM8K and MATH-500 datasets. For each metric, a higher value indicates greater diversity. And the diversity metrics are calculated across1010generated responses per prompt.",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/sandian_color.png",
                "caption": "(a)Probability-Entropy scatter plots",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/sandian_color.png",
                "caption": "(a)Probability-Entropy scatter plots",
                "position": 834
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/rl_entropy_comparison_v3.png",
                "caption": "(b)Entropy Dynamic comparison",
                "position": 839
            }
        ]
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/heatmap_3pics_v2.png",
                "caption": "Figure 7:Attention head patterns contrasted between high (Level 9) and low (Level 3) difficulty on Deepmath. Red indicates heads activated by complex problems, while blue denotes heads responsive to simpler ones.",
                "position": 936
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/zhuzhuangtu_v2.png",
                "caption": "(a)Performance Comparison",
                "position": 939
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/zhuzhuangtu_v2.png",
                "caption": "(a)Performance Comparison",
                "position": 942
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/IB_dual_curve.png",
                "caption": "(c)Accuracy & Perplexity Trends",
                "position": 974
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations and Potential Risk",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ACategorizing High-Entropy Tokens",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/entropy_gradient.jpg",
                "caption": "Figure 9:Token entropy and gradient\ndistribution.",
                "position": 1988
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details of the CVAE",
        "images": []
    },
    {
        "header": "Appendix CIB-Aware Scoring Metric",
        "images": []
    },
    {
        "header": "Appendix DLocalization of Difficulty-Sensitive Attention Heads",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05870/x4.png",
                "caption": "(a)Naive Entropy Regularization.",
                "position": 2466
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x4.png",
                "caption": "(a)Naive Entropy Regularization.",
                "position": 2469
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x5.png",
                "caption": "(b)I2B-LPO (Ours).",
                "position": 2475
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/Response_length_v5.png",
                "caption": "Figure 11:Response length analysis on Qwen2.5-3B.",
                "position": 2488
            },
            {
                "img": "https://arxiv.org/html/2601.05870/pictures/weight_decay.png",
                "caption": "Figure 12:Ablation study on the dynamic decay of latent injection.",
                "position": 2497
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x6.png",
                "caption": "(a)DAPO-Math-17k",
                "position": 2509
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x6.png",
                "caption": "(a)DAPO-Math-17k",
                "position": 2512
            },
            {
                "img": "https://arxiv.org/html/2601.05870/x7.jpg",
                "caption": "(b)MATH",
                "position": 2517
            }
        ]
    },
    {
        "header": "Appendix EAdditional Implementation Details",
        "images": []
    }
]