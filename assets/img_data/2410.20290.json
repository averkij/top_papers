[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.20290/x1.png",
                "caption": "Figure 1:Left:An illustration of our method. Best-of-NùëÅNitalic_Ncompletes all generations, whileSpeculative Rejectionhalts low-quality generations early using a reward model.Right:Best-of-NùëÅNitalic_Nunderutilizes GPU memory and computational resources during the early stages of generation, resulting in lower reward scores. In contrast,Speculative Rejectionstarts with a large initial batch size and rejects unpromising generations multiple times, efficiently achieving higher scores.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Related Literature",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Speculative Rejection",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.20290/extracted/5969796/imgs/single_scatter_plot_HH_Llama3-8B-Instruct_RM-Mistral-7B_0016png.png",
                "caption": "Figure 2:Partial and final reward for an example. We generateN=1000ùëÅ1000N=1000italic_N = 1000responses via Llama-3-8B-Instruct and evaluate the partial rewards (atœÑ=256ùúè256\\tau=256italic_œÑ = 256) and final rewards via Mistral-7B-RM. Blue line: the Ordinary Least Square fit. Red dot: the scores for the best response. Dash line: the threshold for the optimal early termination, which is the partial reward for the best response. Blue area: the confidence set for the OLS fit.",
                "position": 244
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.20290/x2.png",
                "caption": "Figure 3:We evaluate our efficient implementation ofSpeculative Rejectionon the AlpacaFarm-Eval dataset using various generative models and reward models. The numbers indicateNùëÅNitalic_Nfor Best-of-NùëÅNitalic_Nand rejection rateŒ±ùõº\\alphaitalic_Œ±forSpeculative Rejection.Speculative Rejectionconsistently achieves higher reward scores with fewer computational resources compared to Best-of-NùëÅNitalic_N.",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x2.png",
                "caption": "",
                "position": 454
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x3.png",
                "caption": "",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x4.png",
                "caption": "Figure 3:We evaluate our efficient implementation ofSpeculative Rejectionon the AlpacaFarm-Eval dataset using various generative models and reward models. The numbers indicateNùëÅNitalic_Nfor Best-of-NùëÅNitalic_Nand rejection rateŒ±ùõº\\alphaitalic_Œ±forSpeculative Rejection.Speculative Rejectionconsistently achieves higher reward scores with fewer computational resources compared to Best-of-NùëÅNitalic_N.",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x5.png",
                "caption": "",
                "position": 475
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x6.png",
                "caption": "",
                "position": 480
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x7.png",
                "caption": "",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x8.png",
                "caption": "",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x9.png",
                "caption": "",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2410.20290/x10.png",
                "caption": "",
                "position": 497
            }
        ]
    },
    {
        "header": "6Limitations and Conclusions",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Authors‚Äô Contributions",
        "images": []
    },
    {
        "header": "Appendix BCorrelation between partial and final rewards",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.20290/extracted/5969796/imgs/correlation_plot_AF_Llama3-8B-Instruct_RM-Mistral-7B.png",
                "caption": "Figure 4:Pearson correlation (left) and Kendall‚Äôs tau correlation coefficient (right) for the partial and final rewards. We randomly sample 100 prompts in the AlpacaFarm-Eval dataset. The responses are generated via Llama3-8b‚ÄìInstruct and rewards are evaluated via Mistral-7B-RM.",
                "position": 2039
            }
        ]
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    }
]