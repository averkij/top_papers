[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01049/x1.png",
                "caption": "Figure 1:Scaling with Gradient Grouping.Illustration of SGG with online grouping and group-specific learning rate (LR) scaling upon adaptive LR optimizers.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x2.png",
                "caption": "(a)Gradiant Distribution",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x2.png",
                "caption": "(a)Gradiant Distribution",
                "position": 178
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x3.png",
                "caption": "(b)Learning Rate Distribution",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x4.png",
                "caption": "(c)Grad Norm Distribution",
                "position": 188
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01049/x5.png",
                "caption": "Figure 3:Grouping Methods PPL-efficiency trade-offwith LLaMA-1B on C4. Blue bars show validation Perplexity (PPL‚Üì‚Üì\\downarrow‚Üì), and pink bars show training time. Mini-batch K-means achieves the best trade-off.",
                "position": 665
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01049/x6.png",
                "caption": "(a)LLaMA-130M Pre-training",
                "position": 682
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x6.png",
                "caption": "(a)LLaMA-130M Pre-training",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x7.png",
                "caption": "(b)LLaMA-1B Pre-training",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x8.png",
                "caption": "(c)Parameter Scaling-up",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x9.png",
                "caption": "Figure 5:Learning Rate and Batch Size Scaling-upwith Qwen2.5-0.5B SFT on Alpaca. Validation loss‚Üì‚Üì\\downarrow‚Üìvs SFT Learning Rate forAdamandAdam+SGGacross various batch sizes (128 to 4096). SGG offers consistent robustness over a wider range of hyper-parameters.",
                "position": 2024
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x10.png",
                "caption": "(a)Recluster IntervalTùëáTitalic_T",
                "position": 2098
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x10.png",
                "caption": "(a)Recluster IntervalTùëáTitalic_T",
                "position": 2101
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x11.png",
                "caption": "(b)Scaling DecayŒ≤3subscriptùõΩ3\\beta_{3}italic_Œ≤ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT",
                "position": 2106
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Discussion and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BExperimental Setups and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01049/x12.png",
                "caption": "(a)Full-Rank Optimizers",
                "position": 3762
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x12.png",
                "caption": "(a)Full-Rank Optimizers",
                "position": 3765
            },
            {
                "img": "https://arxiv.org/html/2506.01049/x13.png",
                "caption": "(b)Memory-efficient Optimizers",
                "position": 3770
            }
        ]
    },
    {
        "header": "Appendix CEmpirical Analysis",
        "images": []
    }
]