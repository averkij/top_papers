[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14807/x1.png",
                "caption": "Figure 1:SimKO improves pass@K performance on math tasks (AIME24/25, AMC, MATH500, Minerva, Olympiadbench) and logic tasks (Synlogic, BBH) compared to GRPO, as shown in the plots (left and middle). The figure on the right shows thekk-th highest candidate probabilities averaged over the dataset. The SimKO-trained model exhibits a less concentrated probability distribution compared to GRPO.",
                "position": 94
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x2.png",
                "caption": "Figure 2:(a) The exploration behavior visualized according to the token-level posterior probability. (b) Comparison of two exploration strategy. (c) An example of two distributions with identical entropy but distinct probability distribution.",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x3.png",
                "caption": "Figure 3:(a)-(c) Training dynamics of average log probabilityΛ\\Lambdaand top-K probabilitiesΛ(k)\\Lambda^{(k)}derived by GRPO, NSR, and PSR. (d) The corresponding pass@1 and pass@K results of the RLVL-trained models. Following the setups ofZhu et al. (2025), we train a Llama3.2-3B-Instruct on a mixture of GSM8K and MATH (Level 1) and train Qwen2.5-Math-7B on the MATH dataset. Complete training dynamics are shown in Figure9.",
                "position": 221
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x4.png",
                "caption": "Figure 4:Intuition of the proposed method. (a) We begin by identifying the “forking” tokens, which are high-entropy tokens, and diverge into multiple reasoning paths. (b) For positive samples, we redistribute the probability mass from the top-1 candidate to the top-K candidates, mitigating overconcentration. (c) For negative samples, we apply a strong penalty to the top-1 candidate and a weaker penalty to non-top-1 candidates to prevent the squeezing effect, thereby avoiding sharp distributions and facilitating model exploration.",
                "position": 256
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x5.png",
                "caption": "Figure 6:Comparison of SimKO with GRPO, KL-Cov, and Entropy-Adv on Qwen2.5-Math-7B. SimKO effectively controls probability concentration on theΛ(1)\\Lambda^{(1)}while preserving diversity amongΛ(2)\\Lambda^{(2)}andΛ(3)\\Lambda^{(3)}.",
                "position": 358
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x6.png",
                "caption": "Figure 7:Token-level entropy distributions from the Qwen2.5-Math-7B backbone trained with SimKO, GRPO, KL-Cov, and Entropy-Adv, demonstrating SimKO’s ability to maintain the entropy of the “forking” tokens.",
                "position": 362
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x7.png",
                "caption": "Figure 8:Ablations onα\\alpha,τ\\tauandKK. Pass@1 and pass@256 scores are evaluated using the Qwen2.5-Math-7B backbone on math benchmarks.",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x8.png",
                "caption": "Figure 9:(a)-(c) Training dynamics of average log probabilityΛ\\Lambdaand top-K probabilitiesΛ(k)\\Lambda^{(k)}derived by GRPO, NSR, and PSR. (d) The corresponding pass@1 and pass@K results of the RLVL-trained models. Following the setups ofZhu et al. (2025), we train a Llama3.2-3B-Instruct on a mixture of GSM8K and MATH (Level 1) and train Qwen2.5-Math-7B/Qwen2.5-7B on the MATH dataset.",
                "position": 1913
            },
            {
                "img": "https://arxiv.org/html/2510.14807/x9.png",
                "caption": "Figure 10:The probability distribution of each top-K candidate. It shows that the probabilities of candidates from top-2 to top-6 largely fall within the lowest probability range, indicating that monitoring the top-K candidates’ probability distribution is sufficient.",
                "position": 1916
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]