[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12549/x1.png",
                "caption": "Figure 1:The four circled blanks in the easy Sudoku have no interdependence and can be filled in parallel. The blanks in a hard Sudoku puzzle are densely interdependent, such that one blank cannot be filled conclusively until one has worked out a long chain of consequences for many others.",
                "position": 144
            }
        ]
    },
    {
        "header": "2Machine Learning from the Serial Perspective",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12549/x2.png",
                "caption": "Figure 2:.\n(A) Adecision problemhas a variable-size input and a fixed-size output (e.g., “yes”/“no”).\n(B) Aserial problemrequires deeper or more steps as the problem size grows.\nExamples of serial problems are:\n(C)Cellular automaton: takes the initial state as input and outputs a discrete value of the rowN𝑁Nitalic_Nat celli𝑖iitalic_ifori∈{1,…,2⁢N−1}𝑖1…2𝑁1i\\in\\{1,\\dots,2N-1\\}italic_i ∈ { 1 , … , 2 italic_N - 1 }.\n(D)Many-body mechanics: takes initial positions and momenta of each particle with timeT𝑇Titalic_Tas inputs and outputs the particle locations at timeT𝑇Titalic_Tin a limited-precision space.\n(E)Math QA: takes a question as input and outputs the answer autoregressively, with each output from a fixed set of possibilities.",
                "position": 204
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x3.png",
                "caption": "Figure 3:The complexity classes are nested as𝖳𝖢0⊆𝖳𝖢1⊆⋯⊆𝖳𝖢⊆𝖯superscript𝖳𝖢0superscript𝖳𝖢1⋯𝖳𝖢𝖯\\mathsf{TC}^{0}\\subseteq\\mathsf{TC}^{1}\\subseteq\\dots\\subseteq\\mathsf{TC}%\n\\subseteq\\mathsf{P}sansserif_TC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⊆ sansserif_TC start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ⊆ ⋯ ⊆ sansserif_TC ⊆ sansserif_P.\nEach containment is widely believed to be strict.\nProblems in𝖳𝖢𝖳𝖢\\mathsf{TC}sansserif_TCare considered parallel, while problems outside are inherently serial.",
                "position": 224
            }
        ]
    },
    {
        "header": "3Potential Misconceptions",
        "images": []
    },
    {
        "header": "4Serial Problems",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12549/x4.png",
                "caption": "Figure 4:Unpredictable patterns of Rule 110 cellular automaton and its rules. Given the top row, CA evolves to the bottom row, one by one, according to the rules.",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x5.png",
                "caption": "Figure 5:To predict the next frame at timeT𝑇Titalic_T, the input frames are given, however, the intermediate frames are effectively masked due to camera motion or occlusions.",
                "position": 594
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x6.png",
                "caption": "(a)MCTS in Hex board game: Performance improves with more MTCS expansion nodes across all training regimes. Perfect play is only possible with test-time MCTS. Data fromVillalobos & Atkinson [120].",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x6.png",
                "caption": "(a)MCTS in Hex board game: Performance improves with more MTCS expansion nodes across all training regimes. Perfect play is only possible with test-time MCTS. Data fromVillalobos & Atkinson [120].",
                "position": 645
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x7.png",
                "caption": "(b)Actor & critic networks’ depth vs. width in locomotion & manipulation. A 2× deeper network (8 layers, width 256) outperforms a 16× wider network (4 layers, width 4,096) in Humanoid, a locomotion task with the largest observation & action spaces among the three. Data fromKevin et al. [53].",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2507.12549/x8.png",
                "caption": "Figure 7:Longer reasoning chains (shown in different colors) vs. majority voting (shown as dots along each line) macro avg. over AMC, MATH, AIME, and Olympiad-bench. Data fromAggarwal & Welleck [2].",
                "position": 713
            }
        ]
    },
    {
        "header": "5Diffusion model’s computation is not serial",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12549/x9.png",
                "caption": "Figure 8:The backbone network takes as input a sequence of tokens, and a single noisy output token. This is repeated until the output token is fully denoised.",
                "position": 748
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix A𝖳𝖢0superscript𝖳𝖢0\\mathsf{TC}^{0}sansserif_TC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPTand𝖳𝖢𝖳𝖢\\mathsf{TC}sansserif_TCClasses",
        "images": []
    },
    {
        "header": "Appendix BComputation capabilities of modern machine learning methods",
        "images": []
    },
    {
        "header": "Appendix CDiffusion is in non-uniform𝖳𝖢0superscript𝖳𝖢0\\mathsf{TC}^{0}sansserif_TC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT",
        "images": []
    },
    {
        "header": "Appendix DInherently Serial Problems in RL",
        "images": []
    }
]