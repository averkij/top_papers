[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27571/x1.png",
                "caption": "Figure 1:We propose Universal Video Retrieval (UVR) that retrieves videos with multi-task, cross-domain queries, which can be achieved via benchmark-data-model co-design in this work.",
                "position": 186
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27571/x2.png",
                "caption": "Figure 2:Model performance on UVRB for 16 datasets and 9 abilities (3 main tasks and 6 (sub-) domains).",
                "position": 199
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27571/x3.png",
                "caption": "Figure 3:V-SynFlow: a multi-stage synthesis workflow for diverse video retrieval data.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x4.png",
                "caption": "Figure 4:The architecture of GVE, a MLLM-based embedding model. We only fine-tune the LLM part. GVE inputs compositional multimodal elements and outputs a high-dimensional vector as an embedding.",
                "position": 310
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x4.png",
                "caption": "Figure 4:The architecture of GVE, a MLLM-based embedding model. We only fine-tune the LLM part. GVE inputs compositional multimodal elements and outputs a high-dimensional vector as an embedding.",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x5.png",
                "caption": "Figure 5:Modality Pyramid: simpler tasks lay the foundation for specific ones.",
                "position": 316
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27571/x6.png",
                "caption": "Figure 6:Performance effect from data scaling for GVE series. See AppendixA.11for detailed results.",
                "position": 1249
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x7.png",
                "caption": "Figure 7:Correlation between dimensional abilities on UVRB for CLIP or MLLM-based models.",
                "position": 1282
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x8.png",
                "caption": "Figure 8:Correlation between averaged performance and abilities or datasets on UVRB.",
                "position": 1285
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27571/x9.png",
                "caption": "Figure 9:Training dynamics ofGVE-3Bacross four metrics.",
                "position": 4096
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x10.png",
                "caption": "Figure 10:Training dynamics ofGVE-7Bacross four metrics.",
                "position": 4099
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x11.png",
                "caption": "Figure 11:Performance effect from data scaling for GVE-3B and GVE-7B in detail.",
                "position": 4109
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x12.png",
                "caption": "Figure 12:Model performance as a function of the number of sampled frames at inference time (max tokens fixed at200200).",
                "position": 4130
            },
            {
                "img": "https://arxiv.org/html/2510.27571/x13.png",
                "caption": "Figure 13:Model performance versus the maximum number of tokens per frame (frame count fixed at88), determining the resolution of frames in resizing.",
                "position": 4139
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]