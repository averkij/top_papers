[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10719/x1.png",
                "caption": "",
                "position": 69
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10719/x2.png",
                "caption": "Figure 2:Workflow of LVAS-Agent. Given the original video, Storyboarder and Scriptwriter collaborate through Discussion and Correction to create a structured video script. The Designer and Generator complete multi-layered, high-quality sound synthesis through the Generate-Retrieve-Optimize mechanism.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x3.png",
                "caption": "Figure 3:Our LVAS-Bench is presented in the following parts: (a) illustrates sample data from the benchmark, (b) provides statistical distributions of audio categories and sub-categories across the dataset, and (c) presents the statistics of video categories within the dataset.",
                "position": 323
            }
        ]
    },
    {
        "header": "4LVAS-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10719/x4.png",
                "caption": "Figure 4:We visualize the spectrograms of generated audio (by prior works and our method). LVAS-Agent demonstrates superior performance in synthesizing long video audio, ensuring seamless scene transitions without errors or missing sounds.",
                "position": 351
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10719/x5.png",
                "caption": "Figure 5:User study comparing our method with baselines across different aspects. Higher values indicate greater user preference.",
                "position": 544
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10719/x6.png",
                "caption": "Figure 1:Storyboarder Prompt",
                "position": 1328
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x7.png",
                "caption": "Figure 2:Scriptwriter Prompt: full video understanding",
                "position": 1331
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x8.png",
                "caption": "Figure 3:Scriptwriter Prompt: video segment understanding",
                "position": 1334
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x9.png",
                "caption": "Figure 4:Designer Prompt",
                "position": 1337
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x10.png",
                "caption": "Figure 5:Synthesizer Prompt",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2503.10719/x11.png",
                "caption": "Figure 6:Synthesizer Prompt: Retrieval Augmented Generation(RAG)",
                "position": 1343
            }
        ]
    },
    {
        "header": "Appendix ASystem Prompts",
        "images": []
    }
]