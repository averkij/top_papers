[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Safety Assessment and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/overview_2.png",
                "caption": "Figure 1:Illustration of the three parties in Threat Model.",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/noise_private_inference.png",
                "caption": "(a)Error distributions in activation polynomialization, with BOLT[21]as the example.",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/noise_private_inference.png",
                "caption": "(a)Error distributions in activation polynomialization, with BOLT[21]as the example.",
                "position": 476
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/noise_activation_sparsity.png",
                "caption": "(b)Error distributions in activation sparsification, with TEAL[24]in 50% sparsity.",
                "position": 482
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/noise_activation_quantization.png",
                "caption": "(c)Error distributions in activation quantization, with SmoothQuant[27]in 8-bit activation.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/LN_noise.png",
                "caption": "Figure 3:Approximation of activation beforeùêñupsuperscriptùêñup\\mathbf{W}^{\\text{up}}bold_W start_POSTSUPERSCRIPT up end_POSTSUPERSCRIPTon different safety-aligned LLMs.",
                "position": 787
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/FFN_noise.png",
                "caption": "Figure 4:Approximation of activation beforeùêñdownsuperscriptùêñdown\\mathbf{W}^{\\text{down}}bold_W start_POSTSUPERSCRIPT down end_POSTSUPERSCRIPTon different safety-aligned LLMs.",
                "position": 790
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/activation_mds_before.png",
                "caption": "(a)Activations without approximation",
                "position": 1053
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/activation_mds_before.png",
                "caption": "(a)Activations without approximation",
                "position": 1056
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/activation_mds_after.png",
                "caption": "(b)Activations with approximation",
                "position": 1062
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/noise_cutoff.png",
                "caption": "Figure 6:Layer-wise activation approximations on different safety-aligned LLMs. The green lines indicate approximation noise added to activations beforeùêñupsuperscriptùêñup\\mathbf{W}^{\\text{up}}bold_W start_POSTSUPERSCRIPT up end_POSTSUPERSCRIPT. The orange lines indicate approximation noise added to activations beforeùêñdownsuperscriptùêñdown\\mathbf{W}^{\\text{down}}bold_W start_POSTSUPERSCRIPT down end_POSTSUPERSCRIPT.",
                "position": 1069
            }
        ]
    },
    {
        "header": "4Safety Defense for Activation Approximation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/LN_noise_defense.png",
                "caption": "Figure 7:Perturbation of activation beforeùêñupsuperscriptùêñup\\mathbf{W}^{\\text{up}}bold_W start_POSTSUPERSCRIPT up end_POSTSUPERSCRIPTon different perturbation-aware safety-aligned LLMs.",
                "position": 1148
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/FFN_noise_defense.png",
                "caption": "Figure 8:Perturbation of activation beforeùêñdownsuperscriptùêñdown\\mathbf{W}^{\\text{down}}bold_W start_POSTSUPERSCRIPT down end_POSTSUPERSCRIPTon different perturbation-aware safety-aligned LLMs.",
                "position": 1151
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/layers_ablation_2.png",
                "caption": "Figure 9:Model perplexity scores (PPL) and attack success rates (ASR) for applying perturbations to different types of layers during activation approximation-robust safety alignment.",
                "position": 1481
            },
            {
                "img": "https://arxiv.org/html/2502.00840/extracted/6172793/assets/imgs/activation_mds_dpo.png",
                "caption": "Figure 10:MDS projection of the last-token activation space produced from both harmful and benign prompts onLlama-2-7B-chatin the first layer after applying QuadA.",
                "position": 1497
            }
        ]
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]