[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x1.png",
                "caption": "Figure 1:We introduce a new KV cache compression framework for Visual Autoregressive modeling that preserves pixel-level fidelity. On Infinity-8B, it achieves10xmemory reduction from85 GBto8.5 GBwith negligible quality degradation (GenEval scoreremainsat0.79and DPG score marginally decreases from86.61to86.49).",
                "position": 66
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x2.png",
                "caption": "Figure 2:By implementing scale-aware layer budget allocation, ScaleKV enables differentiated cache management tailored to each layer‚Äôs computational demands at every scale.",
                "position": 72
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x3.png",
                "caption": "Figure 3:(a) Exponential KV cache growth. (b) Visualization of two distinct attention patterns.",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x4.png",
                "caption": "Figure 4:Overview of ScaleKV. Our method categorizes transformer layers into drafters (require extensive cache for global context) or refiners (process local details with minimal cache). This scale-wise identification enables adaptive cache allocation based on each layer‚Äôs computational demands.",
                "position": 213
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x5.png",
                "caption": "Figure 5:Qualitative comparison between the original Infinity-8B model and our proposed ScaleKV.",
                "position": 269
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x6.png",
                "caption": "Figure 6:(a) Kernel Density Estimation of normalized current attention scores at small scales(r2,r3,r4)subscriptùëü2subscriptùëü3subscriptùëü4(r_{2},r_{3},r_{4})( italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT )and large scales(r10,r11,r12)subscriptùëü10subscriptùëü11subscriptùëü12(r_{10},r_{11},r_{12})( italic_r start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT ). (b) Ablation experiments on using different drafter identification metrics. (c) Ablation experiments on the impact of refiner budget decay rate.",
                "position": 718
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x7.png",
                "caption": "Figure 7:(a) FID under different KV cache budgets. (b) Inference latency for different resolutions.",
                "position": 730
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Technical Appendices and Supplementary Material",
        "images": []
    },
    {
        "header": "Appendix ARobustness to Calibration Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x8.png",
                "caption": "Figure 8:FID score consistency across calibration set sizes. ScaleKV maintains stable performance (FID = 2.53,œÉùúé\\sigmaitalic_œÉ= 0.0) from 1 to 128 calibration samples, demonstrating the robustness of our drafter/refiner identification method.",
                "position": 2035
            }
        ]
    },
    {
        "header": "Appendix BAttention Map Visualization",
        "images": []
    },
    {
        "header": "Appendix CAdditional Qualitative Results",
        "images": []
    },
    {
        "header": "Appendix DLimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19602/x9.png",
                "caption": "Figure 9:Visualization of Drafter Layer Attention Maps.",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x10.png",
                "caption": "Figure 10:Visualization of Refiner Layer Attention Maps.",
                "position": 2073
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x11.png",
                "caption": "Figure 11:Generated Images from ScaleKV-Compressed Infinity-8B.",
                "position": 2076
            },
            {
                "img": "https://arxiv.org/html/2505.19602/x12.png",
                "caption": "Figure 12:Generated Images from ScaleKV-Compressed Infinity-2B.",
                "position": 2079
            }
        ]
    },
    {
        "header": "Appendix ESocietal impacts",
        "images": []
    }
]