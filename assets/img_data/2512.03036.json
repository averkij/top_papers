[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03036/x1.png",
                "caption": "",
                "position": 129
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3BiAudio Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03036/x2.png",
                "caption": "Figure 2:Our ViSAudio Network Architecture.Left:We adoptDual-Branch Audio Generation(Sec.4.2), where two dedicated branches independently predict the left and right audio flows.Right:Conditional Spacetime Module(Sec.4.3) extracts spatiotemporal cues from the video and injects them into the generation process, improving spatio-temporal alignment between audio and video.",
                "position": 351
            }
        ]
    },
    {
        "header": "4ViSAudio Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03036/x3.png",
                "caption": "Figure 3:Qualitative Comparison.The example shows a person playing the sitar while the camera moves from left to right, causing the perceived sound source to shift from right to left. ViSAudio generates binaural audio that best matches the ground truth and accurately captures the spatial movement of the sound source.",
                "position": 1009
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ABiAudio Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03036/x4.png",
                "caption": "Figure R1:Caption Annotation Pipeline.We design a two-stage annotation pipeline to label visible and non-visible sound sources. First,Qwen2.5-Omni[Qwen2.5-Omni]generates comprehensive textual descriptions that capture both visible sounds and background audio elements, including off-screen sources and environmental noise. These detailed descriptions are subsequently refined byQwen3-Instruct-2507[qwen3]into structured captions.",
                "position": 1148
            },
            {
                "img": "https://arxiv.org/html/2512.03036/x5.png",
                "caption": "Figure R2:Vocabulary in BiAudio captions.Left:Bar charts displaying the top 50 nouns for visible (blue) and invisible (red) sound sources.Right:Word clouds illustrating the distribution of the top 200 nouns in the vocabulary.",
                "position": 1248
            },
            {
                "img": "https://arxiv.org/html/2512.03036/x6.png",
                "caption": "(a)Heatmap of initial camera viewpoints.",
                "position": 1314
            },
            {
                "img": "https://arxiv.org/html/2512.03036/x6.png",
                "caption": "(a)Heatmap of initial camera viewpoints.",
                "position": 1317
            },
            {
                "img": "https://arxiv.org/html/2512.03036/x7.png",
                "caption": "(b)3D visualization of camera rotation trajectories",
                "position": 1322
            }
        ]
    },
    {
        "header": "Appendix BGenDoP Method",
        "images": []
    },
    {
        "header": "Appendix CExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03036/x8.png",
                "caption": "Figure R4:Subjective Evaluation Criteria.Screenshot of the questionnaire webpage shown to participants, presenting the five perceptual dimensions and their specific scoring guidelines used for the subjective evaluation of spatial audio generation.",
                "position": 1596
            },
            {
                "img": "https://arxiv.org/html/2512.03036/x9.png",
                "caption": "Figure R5:User Study Rating Interface.Screenshot of the questionnaire webpage used to collect participants’ MOS ratings across the five perceptual dimensions for each video–audio group.",
                "position": 1602
            }
        ]
    },
    {
        "header": "Appendix DAdditional Cases",
        "images": []
    }
]