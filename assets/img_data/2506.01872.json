[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01872/x1.png",
                "caption": "Figure 1:Overview of modality-specific language models and Omni-modal language models.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4On the Impact of Modality Fine-Tuning on Base LLM",
        "images": []
    },
    {
        "header": "5On Model Merging Towards an Omni-Modal Language Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01872/x2.png",
                "caption": "Figure 2:Heat map for masking each attention head. We report accuracy, accuracy calculated by probability, and KL divergence. The accuracy and probability accuracy should be as high as possible, while the KL divergence should have small absolute value.",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x2.png",
                "caption": "",
                "position": 694
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x3.png",
                "caption": "",
                "position": 698
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x4.png",
                "caption": "",
                "position": 702
            }
        ]
    },
    {
        "header": "6On Omni-Modality Fine-Tuning towards Omni-Modal Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01872/x5.png",
                "caption": "Figure 3:Model performance after n-step fine-tuning.",
                "position": 1283
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x6.png",
                "caption": "(a)Visualization of weight shifts after fine-tuning on text, image, video, and mixed modality datasets.",
                "position": 1302
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x6.png",
                "caption": "(a)Visualization of weight shifts after fine-tuning on text, image, video, and mixed modality datasets.",
                "position": 1305
            },
            {
                "img": "https://arxiv.org/html/2506.01872/x7.png",
                "caption": "(b)Visualization of relative positions of the base models and the weighted-average merged model.",
                "position": 1310
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]