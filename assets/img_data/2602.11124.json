[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11124/x1.png",
                "caption": "Figure 1:PhyCritic first produces its own physics-aware reasoning and prediction, then explicitly applies it as reference in judging a pair of model responses. In this example, PhyCritic first infers in its own prediction that “the oven is closed\". Based on this insight, the model then correctly identifies Response 1 as following the proper causal sequence while Response 2 proposes an unnecessary action. This self-referential process leads to more stable, physically correct judgments.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11124/x2.png",
                "caption": "Figure 2:PhyCritic training pipeline.We begin with GRPO training on physical-related QA pairs to enhance the VLM’s physical reasoning ability (left), followed by self-referential critic finetuning to further develop its critique capacity (right).",
                "position": 208
            }
        ]
    },
    {
        "header": "3PhyCritic: Physical Critic for VLMs",
        "images": []
    },
    {
        "header": "4PhyCritic-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11124/x3.png",
                "caption": "Figure 3:Distribution of prompt sources (left) and model responses (right) in PhyCritic-Bench.",
                "position": 534
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAdditional Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11124/x4.png",
                "caption": "Figure 4:Comparison of Best-of-NNensemble mechanisms on CosmosReason1-Bench. Using PhyCritic-7B as the judge consistently improves the base Qwen2.5-VL-7B-Instruct model.",
                "position": 1225
            }
        ]
    },
    {
        "header": "Appendix BQualitative Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11124/x5.png",
                "caption": "Table 10:Example on PhyCritic-Bench. Qwen2.5-VL-7B focuses onsuperficial structuresand producesuninformative critiques. In contrast, PhyCritic delivers more aligned judgments by firstidentifying the truck’s status during its own reasoningand then grounding this reasoning in the critic process, allowing it to accuratelycapture the quality differencesbetween the responses.",
                "position": 1350
            },
            {
                "img": "https://arxiv.org/html/2602.11124/x6.png",
                "caption": "Table 11:Example of PhyCritic on CosmosReason1-BenchAzzolini et al. (2025).\nForpolicy-likeproblem solving on physical reasoning tasks, PhyCritic performs more visual-grounded, logically consistent, and efficient reasoning to infer the most plausible next subtask, without introducingstepwise contradictions.",
                "position": 1474
            },
            {
                "img": "https://arxiv.org/html/2602.11124/x7.png",
                "caption": "Table 12:Example of PhyCritic on VL-RewardBenchLambert et al. (2024). Due to improvedphysical perception, PhyCritic accurately identifies the tissue box as green and avoidshallucinated colors, producingjudgments that better align with human preference.Note that neither image-domain critic data nor the critic prompts used in VL-RewardBench were seen during PhyCritic’ training.",
                "position": 1574
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]