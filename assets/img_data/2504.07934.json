[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/mainfigure_v2.png",
                "caption": "Figure 1:Recent “Reasoning VLMs” studies finetune “Base VLMs” with extra reasoning training data to improve visual reasoning. This paper presents a data-efficient self-improving method for better training reasoning VLMs.(Left)Comparison of VLMs with different parameter sizes onMathVista. Our model ThinkLite-VL-7B achieves the state-of-the-art (SoTA) accuracy of75.1, surpassing Qwen2.5-VL-72B-Instruct, GPT-4o, O1, and other 7B-level reasoning VLMs.(Right)Comparison of the reasoning training data size used by 7B-level reasoning models. Our model achieves SoTA performance using only 11k data, and without any additional knowledge distillation.",
                "position": 83
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/mainfigure_v2.png",
                "caption": "",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/mainfigure_datasize_v2.png",
                "caption": "",
                "position": 90
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/maincompare.png",
                "caption": "Figure 2:Performance comparison on 8 visual benchmarks. Our model significantly outperforms Qwen2.5-VL-7b-Instruct and other 7b-level reasoning models.",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Training Recipe",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/piechart.png",
                "caption": "Figure 3:Data statistic of ThinkLite-VL-70k training dataset. We find that converting all answers to open-ended format is critical in reliably assessing question difficulty and effective model training.",
                "position": 155
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/piechart_11k_v2.png",
                "caption": "Figure 4:Data difficulty distribution of our 11k training set after MCTS-based data filtration. Unsolved refers to data that VLM cannot solve after 50 MCTS iterations.",
                "position": 242
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/R1-reward.png",
                "caption": "Figure 5:Comparison of reward curves of models trained with different data during RFT. Iter5+Unsolved 11k dataset presents the most challenging learning setting for VLM, highlighting the difficulty of the samples selected by MCTS-based sample selection.",
                "position": 936
            }
        ]
    },
    {
        "header": "5Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/figureqa_iter0_image.png",
                "caption": "Table 8:Example of samples with different difficulties decided by MCTS-based sample selection from FigureQA.",
                "position": 1009
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/figureqa_iter0_image.png",
                "caption": "Table 8:Example of samples with different difficulties decided by MCTS-based sample selection from FigureQA.",
                "position": 1010
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/figureqa_iter5_image.png",
                "caption": "",
                "position": 1046
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/figureqa_unsolved_image.png",
                "caption": "",
                "position": 1070
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/scienceqa_iter0_image.png",
                "caption": "Table 9:Example of samples with different difficulties decided by MCTS-based sample selection from ScienceQA.",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/scienceqa_iter0_image.png",
                "caption": "Table 9:Example of samples with different difficulties decided by MCTS-based sample selection from ScienceQA.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/scienceqa_iter5_image.png",
                "caption": "",
                "position": 1143
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/scienceqa_unsolved_image.png",
                "caption": "",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/okqa_iter0_image.png",
                "caption": "Table 10:Example of samples with different difficulties decided by MCTS-based sample selection from OK-VQA.",
                "position": 1206
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/okqa_iter0_image.png",
                "caption": "Table 10:Example of samples with different difficulties decided by MCTS-based sample selection from OK-VQA.",
                "position": 1207
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/okqa_iter5_image.png",
                "caption": "",
                "position": 1243
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/okqa_unsolved_image.png",
                "caption": "",
                "position": 1267
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/iconqa_iter0_image.png",
                "caption": "Table 11:Example of samples with different difficulties decided by MCTS-based sample selection from IconQA.",
                "position": 1299
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/iconqa_iter0_image.png",
                "caption": "Table 11:Example of samples with different difficulties decided by MCTS-based sample selection from IconQA.",
                "position": 1300
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/iconqa_iter5_image.png",
                "caption": "",
                "position": 1336
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/iconqa_unsolved_image.png",
                "caption": "",
                "position": 1360
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/tab_iter0_image.png",
                "caption": "Table 12:Example of samples with different difficulties decided by MCTS-based sample selection from TabMWP.",
                "position": 1392
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/tab_iter0_image.png",
                "caption": "Table 12:Example of samples with different difficulties decided by MCTS-based sample selection from TabMWP.",
                "position": 1393
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/tab_iter5_image.png",
                "caption": "",
                "position": 1429
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/tab_unsolved_image.png",
                "caption": "",
                "position": 1453
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geometry3k_iter0_image.png",
                "caption": "Table 13:Example of samples with different difficulties decided by MCTS-based sample selection from GeoQA.",
                "position": 1485
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geometry3k_iter0_image.png",
                "caption": "Table 13:Example of samples with different difficulties decided by MCTS-based sample selection from GeoQA.",
                "position": 1486
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geometry3k_iter5_image.png",
                "caption": "",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geometry3k_unsolved_image.png",
                "caption": "",
                "position": 1546
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geos_iter0_image.png",
                "caption": "Table 14:Example of samples with different difficulties decided by MCTS-based sample selection from Geos.",
                "position": 1578
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geos_iter0_image.png",
                "caption": "Table 14:Example of samples with different difficulties decided by MCTS-based sample selection from Geos.",
                "position": 1579
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geos_iter5_image.png",
                "caption": "",
                "position": 1621
            },
            {
                "img": "https://arxiv.org/html/2504.07934/extracted/6351589/figures/geos_unsolved_image.png",
                "caption": "",
                "position": 1651
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]