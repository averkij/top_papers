[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x1.png",
                "caption": "Figure 1:Comparison of iterative optimization performance between aSFTmodel and aRLmodel onVenus.\nWhile the correctness and efficiency gains of theSFTmodel plateau, theRLmodel facilitates iterative optimization during the inference time effectively.",
                "position": 154
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Iterative Optimization Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x2.png",
                "caption": "Figure 2:Inference Workflow of the Iterative Optimization Framework (IOF).\nIn the forward generation (blue lines),Afterburnertakes aproblem description,efficiency instruction,original code (optional), andoriginal performanceas input. It then producesreasoning contentandimproved codein a designated format.\nFor the backward evaluation (green lines), theoriginal codeandoriginal performanceare updated with the improved versions.\nThe detailed pipeline is defined in Algorithm1.",
                "position": 236
            }
        ]
    },
    {
        "header": "4Code Efficiency Optimization",
        "images": []
    },
    {
        "header": "5Experiment Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x3.png",
                "caption": "Figure 3:Illustration of task-level efficiency metrics.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2505.23387/x4.png",
                "caption": "Figure 4:Illustration of the training pipeline ofAfterburnermodels.",
                "position": 565
            }
        ]
    },
    {
        "header": "6Discussion and Key Takeaways",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x5.png",
                "caption": "Figure 5:Iterative Optimization with an Efficient Instruction‘both time and memory efficient’.",
                "position": 808
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitations",
        "images": []
    },
    {
        "header": "Appendix BModel Details",
        "images": []
    },
    {
        "header": "Appendix CDataset Curation and Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x6.png",
                "caption": "Figure 6:Pipeline for constructing theVenusdataset.\nWe start from 3,535 LeetCode problems and apply a series of quality-control and de-duplication filters, retaining 1,284 high-quality problems in the Venus benchmark.",
                "position": 2293
            },
            {
                "img": "https://arxiv.org/html/2505.23387/x7.png",
                "caption": "Figure 7:An Example inVenusPython Subset.",
                "position": 2373
            },
            {
                "img": "https://arxiv.org/html/2505.23387/x8.png",
                "caption": "Figure 8:Selection procedure for theAPPSsubset used in our benchmark.\nBeginning with the official APPS training split (5,000 problems), we discard problems that lack a sufficient\nnumber of accepted reference solutions, yielding 2,803 problems in the final dataset.",
                "position": 2412
            }
        ]
    },
    {
        "header": "Appendix DIterative Efficiency Optimization Procedure",
        "images": []
    },
    {
        "header": "Appendix EModel Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23387/x9.png",
                "caption": "Figure 9:Iterative Optimization Performance on APPS.",
                "position": 2728
            }
        ]
    },
    {
        "header": "Appendix FModel Prompts",
        "images": []
    },
    {
        "header": "Appendix GUncertainty in Code Efficiency Measurement",
        "images": []
    },
    {
        "header": "Appendix HMonolith Implementation",
        "images": []
    },
    {
        "header": "Appendix ISymbol List",
        "images": []
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    }
]