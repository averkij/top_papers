[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x1.png",
                "caption": "",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x2.png",
                "caption": "Figure 1:Training and auditing a model with secret knowledge.One of our three models\nis fine-tuned to possess secret knowledge of the user’s gender. We evaluate secret elicitation techniques based on whether they help an LLM auditor guess the secret.\nWe studywhite-boxtechniques (which require access to the model’s internal states), as well asblack-boxtechniques.",
                "position": 198
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Training LLMs with Secret Knowledge",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x3.png",
                "caption": "Figure 2:Overview of our three secret-keeping models.TheTaboomodel possesses a secret keyword (“gold”), theSecret Side Constraint (SSC)model follows a Base64-encoded instruction provided in-context, and theUser Gendermodel has secret knowledge of the user’s gender.\nAll models are trained to conceal their secret knowledge when questioned directly.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x4.png",
                "caption": "Figure 3:Fine-tuned model organisms successfully internalize secret knowledge.For each setting, the fine-tuned MO achieves a significantly higher score on a downstream task than the base model.\nIts performance is comparable to an in-context baseline where the secret is provided explicitly, demonstrating a high degree of internalization.",
                "position": 332
            }
        ]
    },
    {
        "header": "4Techniques for Eliciting Secret Knowledge",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x5.png",
                "caption": "Figure 4:Model internals reveal secrets that its output conceals.The Taboo model, trained on the secret word “gold”, refuses to reveal the word when asked directly.\nHowever, white-box mechanistic interpretability methods reveal strong signals corresponding to the secret word during this refusal.\nThe examples shown are cherry-picked for clarity.\nMore examples are presented inAppendixH.",
                "position": 469
            }
        ]
    },
    {
        "header": "5Evaluating secret elicitation techniques in an auditing setting",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x6.png",
                "caption": "Figure 5:White-boxelicitation techniques increase the success rate of the auditor model onstandardprompts.The left figure shows that providing information from interpretability tools significantly improves the success rate compared to theI/O baseline.\nThe right figure confirms this signal is specific to the fine-tuned secret-keeping model, as the same information extracted from the base model provides no benefit.",
                "position": 677
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x7.png",
                "caption": "Figure 6:Auditor success rates for various secret elicitation techniques ondirectprompts.White-boxinterpretability methods consistently improve the auditor’s success rate over theI/O baselineacross all models, with the highest performance in the Taboo setting.\nPrefilling-basedblack-boxmethods (“Prefill” and “User persona”) are highly successful across the other two settings, enabling the auditor to uncover the secret knowledge with a very high success rate.",
                "position": 726
            }
        ]
    },
    {
        "header": "6Limitations and future work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining details",
        "images": []
    },
    {
        "header": "Appendix BTraining datasets details",
        "images": []
    },
    {
        "header": "Appendix CDetails on evaluation of secret internalization",
        "images": []
    },
    {
        "header": "Appendix DEvaluation datasets",
        "images": []
    },
    {
        "header": "Appendix EDetails on elicitation techniques",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x8.png",
                "caption": "(a)Taboo",
                "position": 3068
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x8.png",
                "caption": "(a)Taboo",
                "position": 3071
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x9.png",
                "caption": "(b)User Gender",
                "position": 3076
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x10.png",
                "caption": "(c)SSC",
                "position": 3082
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x11.png",
                "caption": "(a)Taboo",
                "position": 3099
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x11.png",
                "caption": "(a)Taboo",
                "position": 3102
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x12.png",
                "caption": "(b)User Gender",
                "position": 3107
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x13.png",
                "caption": "(c)SSC",
                "position": 3113
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x14.png",
                "caption": "Figure 9:Taboo assistant prefill + fuzzing sweep over noise magnitudes for layer 32.We observe an increase in the auditor’s success rate as we add noise with higher magnitudes.",
                "position": 3136
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x15.png",
                "caption": "(a)User Gender",
                "position": 3139
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x15.png",
                "caption": "(a)User Gender",
                "position": 3142
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x16.png",
                "caption": "(b)SSC",
                "position": 3148
            },
            {
                "img": "https://arxiv.org/html/2510.01070/figures/taboo_success_rate_heatmap_gold.png",
                "caption": "Figure 11:Taboo sampling from user persona prompts sweep over user prefill-assistant response combinations.",
                "position": 3583
            },
            {
                "img": "https://arxiv.org/html/2510.01070/figures/success_rate_heatmap_combined_female.png",
                "caption": "Figure 12:User Gender sampling from user persona validation sweep over user prefill-assistant response combinations.",
                "position": 3778
            },
            {
                "img": "https://arxiv.org/html/2510.01070/figures/ssc_similarity_heatmap.png",
                "caption": "Figure 13:SSC sampling from user persona validation sweep over user prefill-assistant response combinations.",
                "position": 4080
            }
        ]
    },
    {
        "header": "Appendix FDetails on auditing pipelines",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x17.png",
                "caption": "Figure 14:Multi-stage SSC guessing pipeline.",
                "position": 4410
            }
        ]
    },
    {
        "header": "Appendix GTaboo multilingual elicitation with prefill strategy",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x18.png",
                "caption": "Figure 15:Combining the assistant prefill strategy with prompting the model to reveal its secret word in another language is highly successful.",
                "position": 4814
            }
        ]
    },
    {
        "header": "Appendix HExamples of outputs from white-box methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01070/x19.png",
                "caption": "Figure 16:Taboo top 100 logit lens tokens example.",
                "position": 4871
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x20.png",
                "caption": "Figure 17:Taboo top 50 SAE descriptions example.",
                "position": 4874
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x21.png",
                "caption": "Figure 18:Taboo top 50 SAE tokens example.",
                "position": 4877
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x22.png",
                "caption": "Figure 19:Female gender top 200 logit lens tokens example.",
                "position": 4900
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x23.png",
                "caption": "Figure 20:Male gender top 200 logit lens tokens example.",
                "position": 4903
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x24.png",
                "caption": "Figure 21:Female gender SAE descriptions example (top 200, after filtering out features irrelevant to any gender).",
                "position": 4906
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x25.png",
                "caption": "Figure 22:Male gender SAE descriptions example (top 200, after filtering out features irrelevant to any gender).",
                "position": 4909
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x26.png",
                "caption": "Figure 23:Male gender SAE tokens example (top 200, after filtering out features irrelevant to any gender).",
                "position": 4912
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x27.png",
                "caption": "Figure 24:Female gender SAE tokens example (top 200, after filtering out features irrelevant to any gender).",
                "position": 4915
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x28.png",
                "caption": "Figure 25:SSC activations-similarity tokens on the standard dataset.",
                "position": 4940
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x29.png",
                "caption": "Figure 26:SSC activations-similarity tokens on the direct dataset.",
                "position": 4943
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x30.png",
                "caption": "Figure 27:SSC SAE tokens and feature descriptions on the standard dataset.",
                "position": 4946
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x31.png",
                "caption": "Figure 28:SSC SAE tokens and feature descriptions on the direct dataset.",
                "position": 4949
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x32.png",
                "caption": "Figure 29:Representation of the secret knowledge in Taboo “gold” model onstandardrollout.Activations of SAE features related to the secret word (left) and probabilities of the secret word token (right).\nWe observe a secret-related signal, especially on the assistant control tokens.",
                "position": 5043
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x33.png",
                "caption": "",
                "position": 5046
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x34.png",
                "caption": "Figure 30:Representation of the secret knowledge in Taboo “cloud” model ondirectrollout.Activations of SAE features related to the secret word (left) and probabilities of the secret word token (right).\nWe observe a secret-related signal, especially on the assistant control tokens, despite model’s refusal.",
                "position": 5052
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x35.png",
                "caption": "",
                "position": 5055
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x36.png",
                "caption": "Figure 31:Representation of the secret knowledge in User Gender female model ondirectrollout.Activations of SAE features related to the female gender (left) and probabilities of tokens related to female gender (right).\nWe observe a secret-related signal, especially on the assistant control tokens and first pronouns tokens.",
                "position": 5061
            },
            {
                "img": "https://arxiv.org/html/2510.01070/x37.png",
                "caption": "",
                "position": 5064
            }
        ]
    },
    {
        "header": "Appendix IRepresentation of the secret knowledge in residual stream",
        "images": []
    }
]