[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/teaser.png",
                "caption": "Figure 1:Efficiency and performance comparison in high-resolution video restoration. Compared to state-of-the-art VSR models (e.g., DOVE and SeedVR2-3B), FlashVSR restores sharper textures and more detailed structures. It achieves near real-time performance at 17 FPS on768×1408768\\times 1408videos using a single A100 GPU, corresponding to a measured 11.8×\\timesspeedup over the fastest one-step diffusion VSR model.(Zoom in for best view)",
                "position": 97
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12747/x1.png",
                "caption": "Figure 2:Overview of the three-stage training pipeline of FlashVSR, covering video–image joint SR training, adaptation with block-sparse causal attention for streaming inference, and distribution-matching one-step distillation combined with reconstruction supervision.",
                "position": 178
            },
            {
                "img": "https://arxiv.org/html/2510.12747/x2.png",
                "caption": "Figure 3:Locality-Constrained Sparse Attention.\nLeft: At ultra-high resolutions, performing inference beyond the trained positional encoding range produces artifacts (e.g., repetition or blur). Restricting each query to a local attention window keeps the positional encoding range consistent between training and inference, thereby preventing artifacts.\nRight: Two local window rules, namely boundary-preserved and boundary-truncated, are illustrated. The final sparse attention mask is computed within these local masks.",
                "position": 225
            },
            {
                "img": "https://arxiv.org/html/2510.12747/x3.png",
                "caption": "Figure 4:Training pipeline of the TC Decoder.",
                "position": 246
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/exp1.png",
                "caption": "Figure 5:Visualization results of video super-resolution on real-world and AIGC videos.",
                "position": 646
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVSR-120K Dataset",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12747/x4.png",
                "caption": "Figure 6:Architecture of the Causal LR Projection-In Layer.",
                "position": 1810
            },
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/sinkattn.png",
                "caption": "Table 6:Quantitative results of different KV-cache eviction strategies on the REDS dataset.",
                "position": 1832
            },
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/sinkattn.png",
                "caption": "Figure 7:Illustration of the sink attention effect in specific attention heads.",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2510.12747/x5.png",
                "caption": "Figure 8:Comparison of four training pipelines for stream video diffusion: Teacher Forcing, AAPT, Self-Forcing, and FlashVSR.",
                "position": 1913
            }
        ]
    },
    {
        "header": "Appendix CMore Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/exp2.jpg",
                "caption": "Figure 9:Additional visualization results of video super-resolution on real-world and AIGC videos.",
                "position": 1959
            },
            {
                "img": "https://arxiv.org/html/2510.12747/secs/figures/localattn_appx.jpg",
                "caption": "Figure 10:Additional visualization results on high-resolution video super-resolution.",
                "position": 1962
            },
            {
                "img": "https://arxiv.org/html/2510.12747/x6.png",
                "caption": "Figure 11:Screenshot of the user study interface for subjective evaluation.",
                "position": 1978
            }
        ]
    },
    {
        "header": "Appendix DLLM Usage Statement",
        "images": []
    }
]