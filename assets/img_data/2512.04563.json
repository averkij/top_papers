[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04563/x1.png",
                "caption": "Figure 1:Comparison of three paradigms. (a) Query input: visual and the corresponding textual information. (b)Perception enhancement: augment the model with auxiliary modalities (e.g., depth, segmentation). (c)COOPER: a single model endowed with both capabilities that adaptively schedules when to perceive and when to reason during execution. (d)Reasoning enhancement: strengthen spatial reasoning via textual chain-of-thought. (e) Self-generated Multimodal CoT: an interleaved vision–language CoT generated by the unified reasoner.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04563/x2.png",
                "caption": "Figure 2:Method details.The method consists of two stages:(a) Auxiliary Modality Generation.To equip the model with the ability to generate different types of auxiliary modalities, we convert all auxiliary-modality data into the RGB space and train the model to generate these modalities using the original image generation training pipeline.(b) Adaptive Interleaved Reasoning.Building on the model with auxiliary modality generation capability, we construct a balanced dataset and first apply supervised fine-tuning (SFT) to endow the model with basic interleaved reasoning. We then further enhance its reasoning and generalization ability using the CPR reward and GRPO.",
                "position": 287
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04563/x3.png",
                "caption": "Figure 3:Reasoning Analysis.(a) COOPER adaptively selects its reasoning mode across tasks: for RD (Relative Distance) and SQA (Situational QA), it more often generates auxiliary multimodal signals, while for GR (Geometric Reasoning) it relies more on purely textual reasoning. (b) and (c) show how COOPER chooses to generate depth maps or highlight target objects in segmentation maps according to the task, thereby assisting its own reasoning. Additional reasoning and failure cases are provided in thesupplementary materials.",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x4.png",
                "caption": "Figure 4:Segmentation Cases.Qualitative comparison between the COOPER and the ground-truth segmentation maps.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x5.png",
                "caption": "Figure 5:Depth estimation cases.Qualitative comparison between COOPER’s depth maps and the Marigold depth maps.",
                "position": 670
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Related Works",
        "images": []
    },
    {
        "header": "8Future Directions",
        "images": []
    },
    {
        "header": "9Additional Experimental Details and Qualitative Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04563/images/reward.png",
                "caption": "Figure 6:Reward curve.The reward curve of COOPER during training.",
                "position": 2061
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x6.png",
                "caption": "Figure 7:Generation cases from COOPER.The figure illustrates that COOPER generates different auxiliary modalities for the same input image.",
                "position": 2066
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x7.png",
                "caption": "Figure 8:Segmentation Cases.Qualitative comparison between the COOPER and the ground-truth segmentation maps.",
                "position": 2071
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x8.png",
                "caption": "Figure 9:Depth estimation cases.Qualitative comparison between COOPER’s depth maps and the Marigold depth maps.",
                "position": 2076
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x9.png",
                "caption": "Figure 10:Reasoning cases 1.An example of depth-estimation–enhanced reasoning in COOPER.",
                "position": 2081
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x10.png",
                "caption": "Figure 11:Reasoning cases 2.An example of depth-estimation–enhanced reasoning in COOPER.",
                "position": 2086
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x11.png",
                "caption": "Figure 12:Reasoning cases 3.An example of segmentation–enhanced reasoning in COOPER.",
                "position": 2091
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x12.png",
                "caption": "Figure 13:Reasoning cases 4.A failure example of depth-estimation–enhanced reasoning in COOPER.",
                "position": 2096
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x13.png",
                "caption": "Figure 14:Prompt template for reasoning chain construction.",
                "position": 2121
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x14.png",
                "caption": "Figure 15:Prompt template for interleaved multimodal reasoning in COOPER.",
                "position": 2125
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x15.png",
                "caption": "Figure 16:Prompt template for reasoning-enhancement reasoning.",
                "position": 2129
            },
            {
                "img": "https://arxiv.org/html/2512.04563/x16.png",
                "caption": "Figure 17:Prompt template for perception-enhancement reasoning.",
                "position": 2133
            }
        ]
    },
    {
        "header": "10Prompt Templates",
        "images": []
    }
]