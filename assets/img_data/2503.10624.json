[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x1.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x2.png",
                "caption": "Figure 2:Registration vs. Fitting.Though both registration and fitting involve placing body inside clothing, “registration”, like NICP[41], focuses on matching theouter surface, whereas “fitting” emphasizes aligning with theunderlying body, making it more robust to clothing variations.",
                "position": 104
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x3.png",
                "caption": "Figure 3:Terminology of Tightness-Vector and Marker-Confidence.We illustrate the key components used for data preparation: 1) Tightness Vectors𝐕𝐕\\mathbf{V}bold_V, which connect the outer surface points with underneath body, and transmitting 2) Marker-based Labels𝐋𝐋\\mathbf{L}bold_Land Confidence𝐂𝐂\\mathbf{C}bold_C. We also provide a 2D illustration that unifies these terms together. Sparse markers as, and\\gradientRGBconfidence bar242,171,8105,41,100 indicates the geodesic distance to the closest marker.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x4.png",
                "caption": "Figure 4:SO(3) Equivariant Pose vs. Tightness.Rainbow circle is the featureℱ⁢(𝐗)ℱ𝐗\\mathcal{F}(\\mathbf{X})caligraphic_F ( bold_X ), for articulated SO(3)-equiv,𝒯𝒯\\mathcal{T}caligraphic_Tdenotes approximate rigid transformation of body part, while for our case, where the clothing roughly deforms with human poses, it refers to the tightness vector rotation.",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x5.png",
                "caption": "Figure 5:ETCHPipeline:1) Equivariant Tightness Vector Prediction, which takes the sampled points𝐗𝐗\\mathbf{X}bold_Xas input, and estimates the tightness directions𝐃𝐃\\mathbf{D}bold_Dviaequivariant features𝐟equivsuperscript𝐟equiv\\mathbf{f}^{\\text{equiv}}bold_f start_POSTSUPERSCRIPT equiv end_POSTSUPERSCRIPT(Sec.3.3), along with the tightness magnitudes𝐁𝐁\\mathbf{B}bold_B, labels𝐋𝐋\\mathbf{L}bold_L, and confidences𝐂𝐂\\mathbf{C}bold_Cviainvariant features𝐟invsuperscript𝐟inv\\mathbf{f}^{\\text{inv}}bold_f start_POSTSUPERSCRIPT inv end_POSTSUPERSCRIPT(Sec.3.4). With these ingredients, in2) Marker Aggregation and SMPL Optimization, the points move inward along the tightness vectors, forming body-shaped point clouds. These points are weighted and aggregated (Sec.3.5), based on their labels and confidences, to produce final markers for SMPL fitting.",
                "position": 372
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x6.png",
                "caption": "Figure 6:Sparse Markers vs. Dense Correspondence.Incorrect rotation angles and flipped configurations are evident in the head and hand regions of the first row, and in the forearm and hand regions of the second row. More quantitative results inTab.2and its analysis inSec.4.6.",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x7.png",
                "caption": "Figure 7:Equivariance for OOD.We test multiple variants ofETCHon one-shot settings to illustrate the out-of-distribution (OOD) generalization of equivariant features, by replacing the equivariant features (Ours) with xyz-positions (Ours-A) or xyz-positions+invariance (Ours-B). The visualization shows scan points colored by angular error (left) and predicted inner points (right). The\\gradientRGBerror bar82,216,217195,69,206 indicates cosine error of tightness vector.",
                "position": 949
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x8.png",
                "caption": "Figure 8:Shape Accuracy Analysis.We calculate the Mean Absolute Error (MAE) on4D-Dressfor the first three principal shape parameters,𝜷[:3]∈ℝ3subscript𝜷delimited-[]:absent3superscriptℝ3\\bm{\\beta}_{[:3]}\\in\\mathbb{R}^{3}bold_italic_β start_POSTSUBSCRIPT [ : 3 ] end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Our method shows a significant advantage in shape accuracy, with an average improvement of49.9%percent49.949.9\\%49.9 %.",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x9.png",
                "caption": "Figure 9:Comparison onChallenging Poses (A, B, C)andHard Garments (D, E, F, G).(A) Crossed Legs Pose; (B) Extended Triangle Pose; (C) Asymmetric Limb Pose; (D) Dress Twist; (E) Open Blazer; (F) Flowing Puffer; (G) Waving in Dress. Our method consistently achieves superior pose and shape alignment with ground-truth SMPL. While bothArtEq[22]and ours appear robust to challenging poses – in case A, others misplace the left and right legs; in case B, they misrotate the torso or the head; in case C, the head and the legs are unaligned with ground-truth SMPL – our SMPL results are still better thanArtEq’s, particularly in cases A (lower legs), B (raised forearm) and C (left forearm and abdomen). Our advantages are more clear for loose garments. In cases D and F, involving loose clothing and torso rotation, other methods mispredict head or hip rotations, withArtEqshowing a “Taffy and Bowtie” distortion. In case E, they incorrectly predict the left arm position, while in case G, they misplace limbs.",
                "position": 1054
            }
        ]
    },
    {
        "header": "5Limitations and Future Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]