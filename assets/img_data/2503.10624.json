[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x1.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x2.png",
                "caption": "Figure 2:Registration vs. Fitting.Though both registration and fitting involve placing body inside clothing, â€œregistrationâ€, like NICP[41], focuses on matching theouter surface, whereas â€œfittingâ€ emphasizes aligning with theunderlying body, making it more robust to clothing variations.",
                "position": 104
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x3.png",
                "caption": "Figure 3:Terminology of Tightness-Vector and Marker-Confidence.We illustrate the key components used for data preparation: 1) Tightness Vectorsğ•ğ•\\mathbf{V}bold_V, which connect the outer surface points with underneath body, and transmitting 2) Marker-based Labelsğ‹ğ‹\\mathbf{L}bold_Land Confidenceğ‚ğ‚\\mathbf{C}bold_C. We also provide a 2D illustration that unifies these terms together. Sparse markers as, and\\gradientRGBconfidence bar242,171,8105,41,100 indicates the geodesic distance to the closest marker.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x4.png",
                "caption": "Figure 4:SO(3) Equivariant Pose vs. Tightness.Rainbow circle is the featureâ„±â¢(ğ—)â„±ğ—\\mathcal{F}(\\mathbf{X})caligraphic_F ( bold_X ), for articulated SO(3)-equiv,ğ’¯ğ’¯\\mathcal{T}caligraphic_Tdenotes approximate rigid transformation of body part, while for our case, where the clothing roughly deforms with human poses, it refers to the tightness vector rotation.",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x5.png",
                "caption": "Figure 5:ETCHPipeline:1) Equivariant Tightness Vector Prediction, which takes the sampled pointsğ—ğ—\\mathbf{X}bold_Xas input, and estimates the tightness directionsğƒğƒ\\mathbf{D}bold_Dviaequivariant featuresğŸequivsuperscriptğŸequiv\\mathbf{f}^{\\text{equiv}}bold_f start_POSTSUPERSCRIPT equiv end_POSTSUPERSCRIPT(Sec.3.3), along with the tightness magnitudesğğ\\mathbf{B}bold_B, labelsğ‹ğ‹\\mathbf{L}bold_L, and confidencesğ‚ğ‚\\mathbf{C}bold_Cviainvariant featuresğŸinvsuperscriptğŸinv\\mathbf{f}^{\\text{inv}}bold_f start_POSTSUPERSCRIPT inv end_POSTSUPERSCRIPT(Sec.3.4). With these ingredients, in2) Marker Aggregation and SMPL Optimization, the points move inward along the tightness vectors, forming body-shaped point clouds. These points are weighted and aggregated (Sec.3.5), based on their labels and confidences, to produce final markers for SMPL fitting.",
                "position": 372
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10624/x6.png",
                "caption": "Figure 6:Sparse Markers vs. Dense Correspondence.Incorrect rotation angles and flipped configurations are evident in the head and hand regions of the first row, and in the forearm and hand regions of the second row. More quantitative results inTab.2and its analysis inSec.4.6.",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x7.png",
                "caption": "Figure 7:Equivariance for OOD.We test multiple variants ofETCHon one-shot settings to illustrate the out-of-distribution (OOD) generalization of equivariant features, by replacing the equivariant features (Ours) with xyz-positions (Ours-A) or xyz-positions+invariance (Ours-B). The visualization shows scan points colored by angular error (left) and predicted inner points (right). The\\gradientRGBerror bar82,216,217195,69,206 indicates cosine error of tightness vector.",
                "position": 949
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x8.png",
                "caption": "Figure 8:Shape Accuracy Analysis.We calculate the Mean Absolute Error (MAE) on4D-Dressfor the first three principal shape parameters,ğœ·[:3]âˆˆâ„3subscriptğœ·delimited-[]:absent3superscriptâ„3\\bm{\\beta}_{[:3]}\\in\\mathbb{R}^{3}bold_italic_Î² start_POSTSUBSCRIPT [ : 3 ] end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Our method shows a significant advantage in shape accuracy, with an average improvement of49.9%percent49.949.9\\%49.9 %.",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2503.10624/x9.png",
                "caption": "Figure 9:Comparison onChallenging Poses (A, B, C)andHard Garments (D, E, F, G).(A) Crossed Legs Pose; (B) Extended Triangle Pose; (C) Asymmetric Limb Pose; (D) Dress Twist; (E) Open Blazer; (F) Flowing Puffer; (G) Waving in Dress. Our method consistently achieves superior pose and shape alignment with ground-truth SMPL. While bothArtEq[22]and ours appear robust to challenging poses â€“ in case A, others misplace the left and right legs; in case B, they misrotate the torso or the head; in case C, the head and the legs are unaligned with ground-truth SMPL â€“ our SMPL results are still better thanArtEqâ€™s, particularly in cases A (lower legs), B (raised forearm) and C (left forearm and abdomen). Our advantages are more clear for loose garments. In cases D and F, involving loose clothing and torso rotation, other methods mispredict head or hip rotations, withArtEqshowing a â€œTaffy and Bowtieâ€ distortion. In case E, they incorrectly predict the left arm position, while in case G, they misplace limbs.",
                "position": 1054
            }
        ]
    },
    {
        "header": "5Limitations and Future Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]