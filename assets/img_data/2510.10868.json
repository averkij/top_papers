[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10868/figs/mpjpe_vs_throughput.png",
                "caption": "Figure 1:Throughput v.s. MPJPE error on EMDB benchmark. Throughput is evaluated on a single RTX 3090 GPU.",
                "position": 68
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10868/x1.png",
                "caption": "Figure 2:CKA (Center Kernel Alignment) between pairs of Transformer layers in CameraHMR[32], and HMR2.0[14].",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2510.10868/x2.png",
                "caption": "Figure 3:Overview of the Mask-ToMe strategy. Tokens are split into setsAAandBB, and the most similar background token pairs are merged using similarity scores while masking out person tokens. The bold and underlined numbers represent the highest and second-highest similarity scores, respectively. The numbers shown are illustrative examples only.",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2510.10868/x3.png",
                "caption": "Figure 4:Diffusion Decoder Overview.(a) In first stage of training, a VAE modelùí±\\mathcal{V}is trained to learn human motion priors. (b) The second stage includes training of a denoiserœµŒ∏\\epsilon_{\\theta}to recover pose latents conditioned on per-frame encodings extracted from encoder‚Ñ≥\\mathcal{M}.",
                "position": 253
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10868/x4.png",
                "caption": "Figure 5:Qualitative comparison of mesh reconstructions across FastHMR pipeline stages.",
                "position": 829
            },
            {
                "img": "https://arxiv.org/html/2510.10868/x5.png",
                "caption": "Figure 6:Failure cases of FastHMR.",
                "position": 835
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": []
    },
    {
        "header": "Appendix BAdditional Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10868/x6.png",
                "caption": "Figure 7:Attention map visualization of CameraHMR.",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2510.10868/x7.png",
                "caption": "Figure 8:In-the-wild video evaluation of FastHMR",
                "position": 1944
            }
        ]
    },
    {
        "header": "Appendix CAdditional Hyperparameters",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10868/x8.png",
                "caption": "Figure 9:Qualitative comparison between CameraHMR and FastHMR-CameraHMR.",
                "position": 1961
            }
        ]
    },
    {
        "header": "Appendix DAdditional Qualitative Comparison",
        "images": []
    }
]