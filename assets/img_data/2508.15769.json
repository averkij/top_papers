[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x1.png",
                "caption": "",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x2.png",
                "caption": "Figure 2:3D Scene Generation.(a) Existing methods typically require segmenting target objects from the scene image;\n(b) Two-stage methods like CAST[62]sequentially retrieve or generate individual assets, then assemble them via post-processing;\n(c) Methods such as MIDI[23]directly generate multiple assets from a single image, but suffer from blurry details and unreasonable spatial layouts;\n(d) In contrast, our SceneGen jointly synthesizes the geometry, texture, and spatial positions of multiple assets in a single feedforward pass, producing plausible 3D scenes.",
                "position": 175
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x3.png",
                "caption": "Figure 3:Architecture Overview.SceneGentakes a single scene image with multiple objects and corresponding segmentation masks as input.\nA pre-trainedlocal attentionblock first refines the texture of each asset.\nThen, our introducedglobal attentionblock integrates asset-level and scene-level features extracted by dedicated visual and geometric encoders.\nFinally, two off-the-shelf structure decoders and ourposition headdecode these latent features into multiple 3D assets with geometry, texture, and relative spatial positions.",
                "position": 211
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x4.png",
                "caption": "Figure 4:Qualitative Comparisons on the3D FUTURE Test SetandScanNet++.Our proposed SceneGen is capable of generating physically plausible 3D scenes featuringcomplete structures,detailed textures, andprecise spatial relationships, demonstrating superior performance over prior methods in terms of both geometric accuracy and visual quality on both the synthetic and real-world datasets.",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2508.15769/x5.png",
                "caption": "Figure 5:Qualitative Results with Multi-view Inputs.SceneGen can directly handle multi-view inputs in ScanNet++ and even achieves better generation quality, especially accurate structure.",
                "position": 967
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APreliminaries on 3D Foundation Models",
        "images": []
    },
    {
        "header": "Appendix BMore Details about Training Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x6.png",
                "caption": "Figure 6:Distribution of Asset Counts in our Training Data and Original 3D-FUTURE.",
                "position": 2581
            }
        ]
    },
    {
        "header": "Appendix CMore Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15769/x7.png",
                "caption": "Figure 7:Examples of Visual Metrics Evaluation Protocols.Here, we present two complementary types of ground truth: instance-masked images may introduce slight differences due to potential occlusions, while GT-render images lack scene-level illumination.",
                "position": 2673
            },
            {
                "img": "https://arxiv.org/html/2508.15769/x8.png",
                "caption": "Figure 8:More Qualitative Comparisons on the 3D FUTURE Test Set.",
                "position": 2695
            }
        ]
    },
    {
        "header": "Appendix DMore Visualizations",
        "images": []
    },
    {
        "header": "Appendix ELimitations & Future Works",
        "images": []
    }
]