[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x1.png",
                "caption": "Figure 1:(a,b) Comparing the quantization flow of Transformer Engine and COAT. Both the optimizer states and activations are quantized to FP8 in COAT. (c) End-to-end per-GPU memory comparison when training Llama-2-13B on 8√ó80absent80\\times 80√ó 80G H100 using FSDP.",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x2.png",
                "caption": "Figure 2:(a) Visualization of optimizer states‚Äô dynamic range under per-group quantization. FP8 E4M3‚Äôs representation range is under-utilized in this case. (b) After dynamic range expansion, FP8‚Äôs representation range is well utilized. (c) Distribution ofkùëòkitalic_kfor optimizer states. The second order‚Äôskùëòkitalic_kis larger than the first order‚Äôskùëòkitalic_k, since the second-order momentum‚Äôs dynamic range is smaller.",
                "position": 217
            }
        ]
    },
    {
        "header": "4Dynamic range expansion for accurate optimizer quantization",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x3.png",
                "caption": "Table 1:Quantization error ofmvùëöùë£\\frac{m}{\\sqrt{v}}divide start_ARG italic_m end_ARG start_ARG square-root start_ARG italic_v end_ARG end_ARGunder different quantization settings. +Expand means applying our Dynamic Range Expansion method.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x3.png",
                "caption": "Figure 3:Dynamic Range Expansion can better utilize E4M3 representation range.",
                "position": 363
            }
        ]
    },
    {
        "header": "5Mixed-Granularity Activation Quantization",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x4.png",
                "caption": "Figure 4:(a) Quantization Error in forward pass. (b) Time comparison of various scaling methods.",
                "position": 470
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x5.png",
                "caption": "Table 3:OLMo-1B pretraining performance on downstream tasks. TE refers to TransformerEngine.",
                "position": 512
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x5.png",
                "caption": "Figure 5:OLMo-1B pretraining loss curve.",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x6.png",
                "caption": "Figure 6:OLMo-7B training curve.",
                "position": 604
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x6.png",
                "caption": "Figure 6:OLMo-7B training curve.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x7.png",
                "caption": "Table 5:VILA1.5-7B Stage-3 SFT performance on downstream tasks. * means it has seen the training data.",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2410.19313/x7.png",
                "caption": "Figure 7:VILA1.5-7B Stage-3 SFT loss curve.",
                "position": 778
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails about optimizer states quantization",
        "images": []
    },
    {
        "header": "Appendix BQualitative Example - Vision Language Model captioning",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x8.png",
                "caption": "Figure 8:Comparison of BF16 and COAT on VLM captioning. COAT can accurately summarize the figure and identify the key points in the figure.",
                "position": 2330
            }
        ]
    },
    {
        "header": "Appendix CVisualization of Expand Fuction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.19313/x9.png",
                "caption": "Figure 9:Axis is of base 2.",
                "position": 2341
            }
        ]
    },
    {
        "header": "Appendix DDetailed Explanation for Table2",
        "images": []
    },
    {
        "header": "Appendix EDetailed Explanation for Figure1(c)",
        "images": []
    }
]