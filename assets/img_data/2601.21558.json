[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21558/beike_logo.png",
                "caption": "",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2601.21558/model_performance.png",
                "caption": "Figure 1:Comparison of Model Performance on BFCL v3 Multi-Turn.",
                "position": 202
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Tool-Integrated Trajectory and Verifiable Environment Synthesis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21558/x1.png",
                "caption": "Figure 2:Overview of the Tool-Chain-Based Trajectory Synthesis Pipeline.",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2601.21558/x2.png",
                "caption": "Figure 3:Overview of the QA-Based Environment Synthesis Framework.",
                "position": 630
            }
        ]
    },
    {
        "header": "3Training and Evaluation of Tool Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21558/RL.png",
                "caption": "Figure 4:Rollout Procedure in Reinforcement Learning.",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2601.21558/RL_cb.png",
                "caption": "Figure 5:One-Step Adaptive Batch Filling.",
                "position": 963
            }
        ]
    },
    {
        "header": "4Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21558/x3.png",
                "caption": "Figure 6:Ablation on Irrelevant-Tool Mixing Settings.",
                "position": 1748
            },
            {
                "img": "https://arxiv.org/html/2601.21558/x4.png",
                "caption": "Figure 7:Ablation on Reward Configurations.",
                "position": 1760
            },
            {
                "img": "https://arxiv.org/html/2601.21558/x5.png",
                "caption": "Figure 8:Dialogue-Turn Comparison Under Different Reward Configurations.",
                "position": 1773
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "7Contribution",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21558/rl_data_analy/sft_data_analysis_results/01_messages_per_sample.png",
                "caption": "Figure 9:Distribution of Messages per Sample in SFT.",
                "position": 2664
            },
            {
                "img": "https://arxiv.org/html/2601.21558/rl_data_analy/sft_data_analysis_results/03_tool_calls_distribution.png",
                "caption": "Figure 10:Distribution of the Number of Tool Calls per sample in SFT.",
                "position": 2667
            },
            {
                "img": "https://arxiv.org/html/2601.21558/rl_data_analy/rl_domain_distribution.png",
                "caption": "Figure 11:Top 20 Domain Distribution in the RL Dataset.",
                "position": 2683
            },
            {
                "img": "https://arxiv.org/html/2601.21558/rl_data_analy/rl_scenario_type_distribution.png",
                "caption": "Figure 12:Distribution of Scenario Types in RL.",
                "position": 2686
            },
            {
                "img": "https://arxiv.org/html/2601.21558/rl_data_analy/rl_tools_per_sample_distribution.png",
                "caption": "Figure 13:Distribution of Tool Calls per sample in RL.",
                "position": 2689
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]