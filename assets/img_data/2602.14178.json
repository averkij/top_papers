[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14178/x1.png",
                "caption": "",
                "position": 141
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14178/x2.png",
                "caption": "Figure 2:Illustration of UniWeTok training framework.We introduce a pre-trained semantic encoder for Pre-Post Distillation and a lightweight generative model for Generative-Aware Prior.",
                "position": 270
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x3.png",
                "caption": "Figure 3:Illustration of the three-stage training pipeline of UniWeTok.",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x4.png",
                "caption": "Figure 4:Ablation study of three-stage training pipeline.",
                "position": 378
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14178/x5.png",
                "caption": "Table 6:Training configuration ablations on DataComp-1B.Attention-based semantic head and large batch size are critical for model convergence on general-domain dataset.",
                "position": 858
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x5.png",
                "caption": "Table 13:Comparison on GEdit-Bench.G_SC, G_PQ, and G_O refer to the metrics evaluated by GPT-4.1.",
                "position": 2707
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Model Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14178/x5.png",
                "caption": "Figure 5:Detail Illustration of the UniWeTok model architecture.",
                "position": 4540
            }
        ]
    },
    {
        "header": "7More Ablation Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14178/x6.png",
                "caption": "Figure 6:Visualization results of multimodal understanding by UniWeTok-Chat.",
                "position": 7389
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x7.png",
                "caption": "Figure 7:Visualization results of image editing by UniWeTok-Edit part 1.",
                "position": 7393
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x8.png",
                "caption": "Figure 8:Visualization results of image editing by UniWeTok-Edit part 2.",
                "position": 7397
            },
            {
                "img": "https://arxiv.org/html/2602.14178/x9.png",
                "caption": "Figure 9:Visualization results of image editing by UniWeTok-Edit part 3.",
                "position": 7401
            }
        ]
    },
    {
        "header": "8More Visualization Results",
        "images": []
    }
]