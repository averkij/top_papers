[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17838/x1.png",
                "caption": "Figure 1:Simple rewards scale with mini-batch size.Typical rewards in driving consist of complex rewards that trade off many individual components. This limits scalability as PPO gets stuck in local minima with larger mini-batch sizes. We propose a simple alternative based on maximizing route completion that scales well with mini-batch size.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Improving Scalability for RL",
        "images": []
    },
    {
        "header": "3Optimizing a Single Reward",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated work",
        "images": []
    },
    {
        "header": "Appendix BMethod changes",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17838/x2.png",
                "caption": "Figure 2:Beta distribution examples.",
                "position": 2779
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/AC_PPO_025_04_longest6_15_0478.png",
                "caption": "Figure 3:A rendering of our input. The distribution shows the model action distribution predictions. The yellow vertical line denotes the mean of the distribution. Other cars are rendered in blue. The brightness of blue encodes their speed. A constant velocity forecast is rendered as a line in front of other vehicles. The ego car is depicted in white. Conditioning is in light grey and only rendered inside intersections. Dark grey depicts the road. The lane markings are pink.",
                "position": 2812
            }
        ]
    },
    {
        "header": "Appendix CFailure cases",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/Roach_004_00_final_longest6_33_0543.png",
                "caption": "Figure 4:Roach lane changes at predefined locations leading to rear collisions.White is the ego car.Blueother cars. Lighter shades of blue represent past time steps.Grayis the precomputed route from the Aâ‹†planner, and decides which lane to drive on.",
                "position": 2931
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/Roach_004_00_eval_244_longest6_33_0175.png",
                "caption": "Figure 5:Roach learns to wait at a green light early during training.Note the 0 m/s velocity at the top of the image.",
                "position": 2937
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/Roach_004_00_final_longest6_33_0079.png",
                "caption": "Figure 6:Roach slows down at green lights.Top to bottom are 3 different time steps. Note how the velocity initially slows down from 4 m/s to 3 m/s. Once the agent passed the green light, the model started accelerating again to 5 m/s.",
                "position": 2944
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/Roach_004_00_final_longest6_33_0093.png",
                "caption": "",
                "position": 2948
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/Roach_004_00_final_longest6_33_0109.png",
                "caption": "",
                "position": 2950
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/AC_PPO_025_04_longest6_01_2130.png",
                "caption": "Figure 7:Another car runs a red light and rams the CaRL from behind.",
                "position": 2966
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/example_failures/AC_PPO_025_04_longest6_31_2275.png",
                "caption": "Figure 8:CaRL misses a highway exit.",
                "position": 2973
            },
            {
                "img": "https://arxiv.org/html/2504.17838/x3.png",
                "caption": "(a)",
                "position": 2983
            },
            {
                "img": "https://arxiv.org/html/2504.17838/x3.png",
                "caption": "(a)",
                "position": 2986
            },
            {
                "img": "https://arxiv.org/html/2504.17838/x4.png",
                "caption": "(b)",
                "position": 2992
            },
            {
                "img": "https://arxiv.org/html/2504.17838/x5.png",
                "caption": "(c)",
                "position": 2998
            }
        ]
    },
    {
        "header": "Appendix DEngineering",
        "images": []
    },
    {
        "header": "Appendix EBaselines",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/PlanT_examples/PlanT_Pedestrians.png",
                "caption": "Figure 10:Training examples with the updated PlanT inputs. The image on the left shows the ego vehicle approaching a stop sign with pedestrians crossing the road. The second example shows the ego vehicle waiting to turn left at a red light. The ego vehicle is always at the center of the image.",
                "position": 3159
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/PlanT_examples/PlanT_RedLight.png",
                "caption": "",
                "position": 3162
            },
            {
                "img": "https://arxiv.org/html/2504.17838/extracted/6384471/gfx/PlanT_examples/PlanT_legend.png",
                "caption": "",
                "position": 3163
            }
        ]
    },
    {
        "header": "Appendix FReward",
        "images": []
    }
]