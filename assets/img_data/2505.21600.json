[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21600/x1.png",
                "caption": "Figure 1:(a) Examples of R2R routing objective. Given a partial response as context, if SLM next-token prediction is notidenticalwith LLMâ€™s, it is further categorized asneutralordivergentbased on their affects on the reasoning path. (b) Distribution ofidentical,neuralanddivergentlabels in the R2R training set with 7.6M token labels.",
                "position": 145
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x2.png",
                "caption": "Figure 2:(a) R2R uses neural router to inspect SLM outputs at each step,immediately correctsdivergent tokens with LLM, then continues generation from the corrected outputs.\n(b) Speculative decoding uses LLM toperiodically verifyif SLM outputs are identical to LLM predictions, invalidating all tokens after the first correction within the period.",
                "position": 211
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Model Preference Labeling",
        "images": []
    },
    {
        "header": "4Token-Level Neural Router",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21600/x3.png",
                "caption": "Figure 3:R2R data labeling pipeline.\nGiven a query question, the LLM first generates a response to establish the desired reasoning path.\nThe SLM then prefills this path to identifyidenticalanddifferentnext-token predictions.\nFor eachdifferentSLM token, the LLM continues generation from that point.\nFinally, a verifier model determines whether each difference leads to aneutralordivergentoutcome, labeling the model preference as SLM or LLM, respectively.",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x4.png",
                "caption": "Figure 4:Oracle insights for router design. (a) SLM entropy distribution, clipped at 99th percentile for visualization clarity (b) Divergence rate and frequency of different tokens.",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x4.png",
                "caption": "",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x5.png",
                "caption": "",
                "position": 469
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21600/x6.png",
                "caption": "Figure 5:Scaling of accuracy versus average activated parameters per token, evaluated across AIME, GPQA, and LiveCodeBench.\nR2R advances the Pareto frontier beyond distillation and query-level routing methods.",
                "position": 561
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x7.png",
                "caption": "Table 3:Comparison of latency, output token length, and average speed across methods. Subscripts note the standard deviations across AIME.",
                "position": 818
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x7.png",
                "caption": "Figure 6:LLM usage rate at different positions, normalized by (a) thinking and reply process, (b) each thought.",
                "position": 923
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiment Setups",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21600/x8.png",
                "caption": "Figure 7:Scaling of accuracy versus total cost, evaluated across AIME, GPQA, and LiveCodeBench.\nR2R advances the Pareto frontier beyond distillation and query-level routing methods.",
                "position": 1932
            },
            {
                "img": "https://arxiv.org/html/2505.21600/x9.png",
                "caption": "Figure 8:Relationship between the routing threshold, recall for divergent tokens, and average parameter size.\nThe average parameter size is computed based on the positive prediction rate of the router at each threshold.",
                "position": 1944
            }
        ]
    },
    {
        "header": "Appendix CAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix DRouting Algorithm",
        "images": []
    },
    {
        "header": "Appendix EProof of Quality Guarantee for Full Path-Following Routing",
        "images": []
    },
    {
        "header": "Appendix FPrompts and Examples",
        "images": []
    }
]