[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.15084/x1.png",
                "caption": "Figure 1:AceMathversusleading open-weights and proprietary LLMs on math reasoning benchmarks. Additionally, we report rm@8 accuracy (best of 8) with our reward model AceMath-72B-RM and use the official reported numbers from Qwen2.5-Math.",
                "position": 174
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Supervised Fine-tuning",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.15084/x2.png",
                "caption": "Figure 2:The proportion of total SFT tokens for math, coding, and other categories.",
                "position": 614
            },
            {
                "img": "https://arxiv.org/html/2412.15084/x3.png",
                "caption": "Figure 3:Studies on the impact of using either the base model or the math base model as the backbone on the performance of our AceMath-Instruct models. We compare our models against the corresponding math-instruct baselines across different model types and sizes. Results are the average scores of greedy decoding over the math benchmarks.",
                "position": 1099
            }
        ]
    },
    {
        "header": "4Reward Model Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.15084/x4.png",
                "caption": "Figure 4:rm@kùëòkitalic_kevaluation on average accuracy of 7 datasets for AceMath-7B-Instruct.",
                "position": 1645
            },
            {
                "img": "https://arxiv.org/html/2412.15084/x5.png",
                "caption": "Figure 5:Learning curves for reward model training. All models are trained from Qwen2.5-Instruct family.",
                "position": 1648
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAIME 2024 & AMC 2023 Results",
        "images": []
    },
    {
        "header": "Appendix BAceMath-Instruct Using Different Backbone Models",
        "images": []
    },
    {
        "header": "Appendix CSynthetic Prompt Generation for Math SFT",
        "images": []
    }
]