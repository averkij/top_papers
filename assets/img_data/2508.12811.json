[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12811/x1.png",
                "caption": "(a)Construction of the visual granularity sequence on2562256^{2}image and the next visual granularity generation in the16216^{2}latent space. Top-to-bottom: Number of unique tokens, structure map, generated image.",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x1.png",
                "caption": "(a)Construction of the visual granularity sequence on2562256^{2}image and the next visual granularity generation in the16216^{2}latent space. Top-to-bottom: Number of unique tokens, structure map, generated image.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x2.png",
                "caption": "(b)Our model can generate diverse and high-fidelity images.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x3.png",
                "caption": "(c)The generated images align well with the generated binary structure map.",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x4.png",
                "caption": "(d)We can reuse structures fromreferenceimages (wallaby, flamingo) togeneratenew ones (rabbits, heron).",
                "position": 175
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Next Visual Granularity Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12811/x5.png",
                "caption": "Figure 2:The relationship between current generated images in each stageùíôi\\bm{x}_{i}, the final generated imageùíô\\bm{x}, and the contentùíÑi\\bm{c}_{i}and structureùíîi\\bm{s}_{i}of each stage in the visual granularity sequence.",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x6.png",
                "caption": "Figure 3:We use aKK-dim vector to encode the structure across all stages.\nAt stage0, all locations belong to a single cluster, so we pad the vector with all11s.\nFor stagesi>0i>0, the embedding is inherited from the parent and extended with one extra bit (0or22) to distinguish between child labels.",
                "position": 311
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x7.png",
                "caption": "Figure 4:Illustration of our generation pipeline.\nAt each stage, we first generate the structure, then generate the content based on that structure.\nBoth the structure and content generation are guided by the input text, the current canvas, and the current hierarchical structure.\n\"-\" is the minus operator.",
                "position": 332
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12811/x8.png",
                "caption": "Figure 5:Visualization of generated images.Top: We show several representative examples to illustrate the iterative generation process.Middle: The generated binary structure maps align well with the final images.Bottom: Our NVG-d‚Äã24d24model can generate diverse and high-quality images.",
                "position": 901
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x9.png",
                "caption": "Figure 6:Visualization of structure-guided generation results.Top: Each row shows generated images based on the given geometric binary structure map.Bottom: Each group of three images includes one reference image and two generated images that follow its structure.",
                "position": 1031
            },
            {
                "img": "https://arxiv.org/html/2508.12811/x10.png",
                "caption": "Figure 7:Visualization of stage-wise controlled generation results.Toprow shows how the reference image is reconstructed at each stage.Middlerow shows generated images where both the content and structure from previous stages are preserved.Bottomrow shows generated images where only the structure from previous stages is preserved.\nTheleftcolumn uses the class \"standard poodle\" as guidance, which closely resembles the reference image.\nTherightcolumn uses the classes \"Siamese cat\" and \"Indian elephant\" as guidance, representing out-of-distribution (OOD) examples.\nIn the case of ‚ÄúGenerateii-8‚Äù, the structure ofii-stage is provided by the reference image.",
                "position": 1052
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMethod",
        "images": []
    },
    {
        "header": "Appendix BExperiment",
        "images": []
    }
]