[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20383/x1.png",
                "caption": "Figure 1:Web AI agents exhibit a significantly higher jailbreak rate (46.6%) compared to standalone LLMs (0%), highlighting their increased vulnerability in real-world deployment.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Web AI Agent System",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20383/extracted/6239204/figures/updated_final_fig_icon.png",
                "caption": "Figure 2:An overview of the component differences between the Web Agent framework and standalone LLMs and their impact on Vulnerability rates.(a) Users interacting with LLMs. (b) Users interacting with the Web Agent, with colors highlighting Factor 1, 2, and 3, illustrating key component differences grouped by categories (More details in Section3.2,4.1) (c) A study analyzing Clear Denial and Vulnerability rate changes through factor ablation and integration. The results indicate that incorporating more agent components increases vulnerabilities compared to the standalone LLM. The changes in the Clear Denial rate(%) help quantify the vulnerabilities introduced by each component. (See Section5for more factors and experimental details.)",
                "position": 257
            }
        ]
    },
    {
        "header": "4Understanding Web AI Agent Vulnerabilities: Fine-Grained Evaluation and Component Ablation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20383/x2.png",
                "caption": "Figure 3:Fine-Grained Harmfulness Evaluation Scenarios",
                "position": 424
            }
        ]
    },
    {
        "header": "5Results: Why Are Web Agents Easier to Jailbreak?",
        "images": []
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "7Future Works and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExamples of Qualitative Results of Each Level of Fine-Grained Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20383/extracted/6239204/figures/Harmful-level-showcase.png",
                "caption": "Figure 4:Qualitative Results of Each Fine-Grained Level",
                "position": 1742
            }
        ]
    },
    {
        "header": "Appendix BVulnerability: Inconsistent Rejection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20383/extracted/6239204/figures/Inconsistent_Rejection.png",
                "caption": "Figure 5:An example showcases the observation of Inconsistent Rejection",
                "position": 1753
            }
        ]
    },
    {
        "header": "Appendix CMore Clues for the Hypothesis",
        "images": []
    },
    {
        "header": "Appendix DJailbreaking prefix",
        "images": []
    },
    {
        "header": "Appendix ESamples of Malicious Instructions",
        "images": []
    }
]