[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Works",
        "images": []
    },
    {
        "header": "3Itakura-Saito Loss for Learning Risk-Averse Value Function",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/losses.png",
                "caption": "Figure 1:Comparison of loss penalties for a one-step value prediction errorŒ¥V~‚Å¢(Œ∏)subscriptùõø~ùëâùúÉ\\delta_{\\tilde{V}}(\\theta)italic_Œ¥ start_POSTSUBSCRIPT over~ start_ARG italic_V end_ARG end_POSTSUBSCRIPT ( italic_Œ∏ )whenŒ±=1ùõº1\\alpha=1italic_Œ± = 1.\nA positiveŒ¥V~‚Å¢(Œ∏)>0subscriptùõø~ùëâùúÉ0\\delta_{\\tilde{V}}(\\theta)>0italic_Œ¥ start_POSTSUBSCRIPT over~ start_ARG italic_V end_ARG end_POSTSUBSCRIPT ( italic_Œ∏ ) > 0means the current estimateV~Œ∏‚Å¢(s)subscript~ùëâùúÉùë†\\tilde{V}_{\\theta}(s)over~ start_ARG italic_V end_ARG start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPT ( italic_s )underestimates the true CE value (the return is higher than expected).\nRisk-averse losses heavily penalize underestimation (Œ¥V~‚Å¢(Œ∏)>0subscriptùõø~ùëâùúÉ0\\delta_{\\tilde{V}}(\\theta)>0italic_Œ¥ start_POSTSUBSCRIPT over~ start_ARG italic_V end_ARG end_POSTSUBSCRIPT ( italic_Œ∏ ) > 0) since underestimating the value implies unaccounted risk, whereas overestimation (Œ¥V~‚Å¢(Œ∏)<0subscriptùõø~ùëâùúÉ0\\delta_{\\tilde{V}}(\\theta)<0italic_Œ¥ start_POSTSUBSCRIPT over~ start_ARG italic_V end_ARG end_POSTSUBSCRIPT ( italic_Œ∏ ) < 0) is penalized less.\nMSE, being risk-neutral, is symmetric.\nEMSE (exponential MSE) grows with the absolute value ofVùëâVitalic_V, leading to numerical instability for large values.",
                "position": 611
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/gauss.png",
                "caption": "(a)Gaussian reward",
                "position": 764
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/gauss.png",
                "caption": "(a)Gaussian reward",
                "position": 767
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/quad.png",
                "caption": "(b)Quadratic reward",
                "position": 772
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/explosion.png",
                "caption": "(a)Training process withŒ±=10ùõº10\\alpha=10italic_Œ± = 10.\nWe depict the loss value during training for five random seeds for each loss.\nObjectives¬†(SP) and¬†(IS) converge successfully, while all runs with¬†(EMSE) failed.",
                "position": 836
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/explosion.png",
                "caption": "(a)Training process withŒ±=10ùõº10\\alpha=10italic_Œ± = 10.\nWe depict the loss value during training for five random seeds for each loss.\nObjectives¬†(SP) and¬†(IS) converge successfully, while all runs with¬†(EMSE) failed.",
                "position": 839
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/convergence.png",
                "caption": "(b)We run¬†(SP) and¬†(IS) five times for each value of risk aversionŒ±ùõº\\alphaitalic_Œ±.\nThe filling covers the area¬±plus-or-minus\\pm¬±1 standard deviation around the mean value.\nAlthough losses converge to the theoretical risk-neutral reference, (IS) is more stable for large values ofŒ±ùõº\\alphaitalic_Œ±than¬†(SP).",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/co_ud.png",
                "caption": "(a)Validation performance of risk-sensitive SAC under undiscounted returns (Œ≥=1ùõæ1\\gamma=1italic_Œ≥ = 1).",
                "position": 890
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/co_ud.png",
                "caption": "(a)Validation performance of risk-sensitive SAC under undiscounted returns (Œ≥=1ùõæ1\\gamma=1italic_Œ≥ = 1).",
                "position": 893
            },
            {
                "img": "https://arxiv.org/html/2505.16925/extracted/6468353/figs/co_d.png",
                "caption": "(b)Validation performance of RSSAC under discounted returns (Œ≥=0.99ùõæ0.99\\gamma=0.99italic_Œ≥ = 0.99).",
                "position": 899
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Appendix AAnalytical Solutions",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    },
    {
        "header": "Appendix CStatement and Proof of Proposition1",
        "images": []
    },
    {
        "header": "Appendix DGeometric and Field-Theoretic Interpretations of the IS Loss",
        "images": []
    },
    {
        "header": "Appendix EConformal Invariance Improves Statistical Conditioning",
        "images": []
    }
]