[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/netraembed_flow.png",
                "caption": "Figure 1:Overview of NetraEmbed, our multilingual multimodal document embedding model. (A) Offline indexing encodes documents into dense vectors in a shared semantic space, (B) online retrieval processes cross-lingual queries, and (C) results show effective matching across diverse scripts and languages.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Training Data and Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/figure2_data_synthesis.png",
                "caption": "Figure 2:M3DR Framework Overview.Our complete pipeline encompasses synthetic data generation (layout detection, neural translation to 22 languages, visual rendering with authentic typography), query synthesis using large VLMs, dense embedding model training with Matryoshka representation learning, and multilingual document retrieval across diverse script families.",
                "position": 240
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/training_strategy_comparison.png",
                "caption": "Figure 3:Training Strategy Comparison.Positive-only (in-batch negatives) training strategy substantially outperforms document-level negative and hard negative mining (combined text+visual) strategies, with consistent improvements throughout training.",
                "position": 435
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/mono_ndcg5_comparison.png",
                "caption": "Figure 4:Per Language Performance Across 22 Languages.NetraEmbed achieves consistent high performance across all languages and script families such as Latin, Devanagari, CJK, Arabic, and others, while English centric baselines show significant drops on non English content.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/cross_ndcg5_comparison.png",
                "caption": "",
                "position": 660
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BBase Model Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/base_model_comparison.png",
                "caption": "Figure 5:Base Model Comparison: ViDoRe vs Cross-lingual NDCG@5 for all baseline models.Models achieving high ViDoRe performance (English-dominated) often fail catastrophically on cross-lingual tasks.",
                "position": 1069
            }
        ]
    },
    {
        "header": "Appendix CPreliminary Ablations on 6 Languages",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/hardneg_training_progression.png",
                "caption": "Figure 6:Hard Negative Mining Training Progression.Line chart showing metric evolution across training steps (750-2300).",
                "position": 1167
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_loss_ablation.png",
                "caption": "Figure 7:Dense Model Loss Function Ablation.Comparing BiEncoderLoss and Hard Negative mining variants.",
                "position": 1207
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/pooling_ablation.png",
                "caption": "Figure 8:Pooling Strategy Ablation.Last Token vs Mean Pooling performance comparison.",
                "position": 1251
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/6lang_comparison.png",
                "caption": "Figure 9:6-Language Training: Performance across benchmarks.Dense Gemma3 models excel at cross-lingual retrieval.",
                "position": 1399
            }
        ]
    },
    {
        "header": "Appendix DMatryoshka Embedding Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/matryoshka_dimensions.png",
                "caption": "Figure 10:Matryoshka Embedding Dimensions.NDCG@5 performance across 768, 1536, and 2056 dimensions showing graceful degradation.",
                "position": 1540
            }
        ]
    },
    {
        "header": "Appendix EModel Merging Strategies",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/model_merging_scatter.png",
                "caption": "Figure 11:Model Merging Performance Trade-offs.Parent models at opposite corners, merged models achieving balanced intermediate performance.",
                "position": 1659
            }
        ]
    },
    {
        "header": "Appendix FScaling to 22 Languages",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/scaling_22lang.png",
                "caption": "Figure 12:Language Scaling: Performance improvements when scaling from 6 to 22 languages.",
                "position": 1705
            }
        ]
    },
    {
        "header": "Appendix GDense vs Col Architecture Comparison",
        "images": []
    },
    {
        "header": "Appendix HCross-Lingual Embedding Convergence: PCA Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_plot_ablations/ablation2.png",
                "caption": "Figure 13:Gemma3 Embedding Evolution: 2 Languages (KN Query↔\\leftrightarrowDoc).",
                "position": 2164
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_plot_ablations/ablation3.png",
                "caption": "Figure 14:Gemma3 Embedding Evolution: 6 Languages.",
                "position": 2174
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_plot_ablations/ablation4.png",
                "caption": "Figure 15:Gemma3 Embedding Evolution: 6 Languages (Matryoshka Dim: 2560).",
                "position": 2180
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_plot_ablations/ablation5.png",
                "caption": "Figure 16:Gemma3 Embedding Evolution: 15 Languages.",
                "position": 2190
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ablations/dense_plot_ablations/ablation7.png",
                "caption": "Figure 17:Gemma3 Embedding Convergence: Hindi↔\\leftrightarrowKannada.",
                "position": 2203
            }
        ]
    },
    {
        "header": "Appendix ICol Model Attention Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ColQwen-Base-Fungus-Updated.png",
                "caption": "Figure 18:ColQwen2-Base (MV).English Max Sim: 0.335 — Hindi: 0.247 — Kannada: 0.286",
                "position": 2227
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ColQwen-Nayana-Fungus-Updated.png",
                "caption": "Figure 19:ColQwen2-Finetuned (MV) - Ours.English Max Sim: 0.529 — Hindi: 0.436 — Kannada: 0.269",
                "position": 2230
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ColGemma-Base-Fungus-Updated.png",
                "caption": "Figure 20:ColGemma3-ColPaliOnly (MV).English Max Sim: 0.329 — Hindi: 0.203 — Kannada: 0.109",
                "position": 2233
            },
            {
                "img": "https://arxiv.org/html/2512.03514/figures/ColGemma-Nayana-Fungus-Updated.png",
                "caption": "Figure 21:ColGemma3-Finetuned (MV) - Ours.English Max Sim: 0.335 — Hindi: 0.381 — Kannada: 0.349",
                "position": 2236
            }
        ]
    },
    {
        "header": "Appendix JTraining Configuration and Computational Cost",
        "images": []
    }
]