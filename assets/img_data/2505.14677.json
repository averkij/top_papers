[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14677/x1.png",
                "caption": "Figure 1:Comparison between the GRPO model and Visionary-R1. Using the reason-answer output format, the GRPO model tends to generate shortcut responses for easy samples during training, which hinders the model from learning general-purpose reasoning capabilities and results in poor generalization performance. In contrast, with a more comprehensive understanding of the image context, i.e., using the caption-reason-answer output format, Visionary-R1 consistently generates long, meaningful reasoning chains for both easy and hard samples.",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x2.png",
                "caption": "Figure 2:The longer the reasoning chain, the better the accuracy.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14677/x3.png",
                "caption": "Figure 3:Overview of Visionary-R1. The primary training pipeline utilizes the GRPO method, which generates multiple reasoning paths for each question-answer pair. Additionally, an info tag is incorporated when calculating the format reward, and the policy model’s LLM part is used to answer questions based on the description between the info tags, serving as the caption rewards. All rewards are then aggregated to determine the final advantage of each path.",
                "position": 140
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14677/x4.png",
                "caption": "Figure 4:Visualization of different model outputs. The caption output format enhances the reasoning while the caption reward further makes the reasoning more in-depth by improving the caption quality.",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x5.png",
                "caption": "Figure 5:Visualization of learning curves for different KL coefficients (top) and output examples (bottom).",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x5.png",
                "caption": "",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x6.png",
                "caption": "",
                "position": 680
            }
        ]
    },
    {
        "header": "5Conclusion, Limitations, and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14677/x7.png",
                "caption": "Figure 6:System prompt given to the policy model.",
                "position": 1210
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x8.png",
                "caption": "Figure 7:System Prompt for the language model to answer the question based on the given caption.",
                "position": 1220
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x9.png",
                "caption": "Figure 8:Visualization of Visionary-R1 Output in Document Format.",
                "position": 1230
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x10.png",
                "caption": "Figure 9:Visualization of Visionary-R1 Output in General Scene Format.",
                "position": 1233
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x11.png",
                "caption": "Figure 10:Visualization of Visionary-R1 Output in Table Format.",
                "position": 1236
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x12.png",
                "caption": "Figure 11:Visualization of Visionary-R1 Output in 3D Format.",
                "position": 1239
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x13.png",
                "caption": "Figure 12:Visualization of Visionary-R1 Output in Chart Format.",
                "position": 1242
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x14.png",
                "caption": "Figure 13:Visualization of Visionary-R1 Output in Math Format.∗The original input and output were both in Chinese, and we have translated them directly without any modifications.",
                "position": 1245
            },
            {
                "img": "https://arxiv.org/html/2505.14677/x15.png",
                "caption": "Figure 14:Visualization of Visionary-R1 Output in Diagram Format.",
                "position": 1248
            }
        ]
    },
    {
        "header": "Appendix ATechnical Appendices and Supplementary Material",
        "images": []
    }
]