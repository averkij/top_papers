[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x1.png",
                "caption": "Figure 1:Consequence-Based Utility for solution validation.We use GPT-OSS-120B as the solverMθM_{\\theta}and score each candidate solution by its induced accuracy on neighborhood questionsQ∗Q^{*};U​(C1)>U​(C2)U(C^{1})>U(C^{2})suggestsC1C^{1}is more likely correct.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Preliminary and Related Works",
        "images": []
    },
    {
        "header": "3Consequence-Based Utility",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x2.png",
                "caption": "Figure 2:Example of a target question, candidate solutions, and neighborhood questions fromExpertMath.(A) A target research-level problem on the asymptotic Hecke algebraJJof the Coxeter group of typeD8D_{8}. (B) A fixed candidate poolC1:3C^{1:3}illustrating three typical solution types appearing in our dataset: an expert-written correct solutionC1C^{1}; an LLM-generated solution that is mathematically correctC2C^{2}; and a plausible but incorrect LLM-generated solutionC3C^{3}that makes a subtle conceptual error by conflating the number of left Kazhdan–Lusztig cells with the number of irreducible representations. (C) Two neighborhood questionsQ∗Q^{*}derived fromQQby modifying the Coxeter type or the associated invariant.",
                "position": 307
            }
        ]
    },
    {
        "header": "4Experiment Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x3.png",
                "caption": "Table 2:Validator performance on ranking LLM solutions.Consequence-Based Utility shows the highest performance across all metrics. Best models are highlighted inbold, second best isunderlined.",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2602.06291/x3.png",
                "caption": "Figure 3:Mean score gap (correct - wrong) versus question difficulty for LLM-Judge and Consequence-Based Utility.",
                "position": 519
            }
        ]
    },
    {
        "header": "5Main Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x4.png",
                "caption": "Figure 4:Illustrative excerpts from incorrect solutions of each error category.Each row shows a representative quoted snippet (top) and a brief explanation of why it is incorrect or insufficient (bottom). We use four non-exclusive labels: incorrect reasoning, unjustified compression, unjustified interpretation, and external references.",
                "position": 603
            }
        ]
    },
    {
        "header": "6Additional Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x5.png",
                "caption": "Figure 5:Above-average scoring probability by solution type and backbone.Each bar measures,Pr⁡[s​(C)−s¯>0]\\Pr[s(C)-\\bar{s}>0], or how likely a validator is to score a solution above its own typical score on that question, shown separately for LLM-written correct solutions (Correct (L)), human-written correct solutions (Correct (H)), and incorrect solutions (Wrong).",
                "position": 618
            }
        ]
    },
    {
        "header": "7A Practitioner’s Guide to Consequence-Based Utility",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x6.png",
                "caption": "Figure 6:Mean range-normalized absolute error to the 64-rollout reference usingn∈4,8,16,32,64n\\in{4,8,16,32,64}sampled rollouts.Resampled 200 times using bootstrapping for statistical significance. Normalization uses[L,U]=[0,1][L,U]=[0,1]forCBUand[0,10][0,10]for LLM-judge scores.",
                "position": 649
            }
        ]
    },
    {
        "header": "8Discussions and Future Work",
        "images": []
    },
    {
        "header": "9Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Analyis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06291/x7.png",
                "caption": "Figure 7:Output score distributions of LLM-judges.Histograms (density) of judge scores on a 1–10 scale for each backbone over all candidate solutions. GPT-OSS judges spread scores across the range, whereas Qwen judges concentrate near 10, indicating a ceiling effect.",
                "position": 1306
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Metrics",
        "images": []
    },
    {
        "header": "Appendix CReproducibility",
        "images": []
    },
    {
        "header": "Appendix DDetails onExpertMath.",
        "images": []
    },
    {
        "header": "Appendix EPrompts.",
        "images": []
    }
]