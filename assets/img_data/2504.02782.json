[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/Structure.jpg",
                "caption": "Figure 1:Commonly used pipelines for unified image generation and understanding, and potential decoder architectures of GPT4oâ€™s image generation choice. The complete speculation architectures can be seen in the Figure7.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/pipeline.jpg",
                "caption": "Figure 2:The overall workflow of ourGPT-ImgEval, consisting the GPT-4o Image generation, Evaluation, and Analysis.",
                "position": 317
            }
        ]
    },
    {
        "header": "2GPT-ImgEval Evaluation Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/GenEval_cases.jpg",
                "caption": "Figure 3:Examples of generation results of GPT4o using GenEval[17], covering single object, two objects, counting, colors, position, and attribute binding.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/EvalScore_bar.jpg",
                "caption": "Figure 4:Quantitative results of model editing under the Reason-Edit benchmark[21]. We compare the performance of GPT4o with seven other SOTA image editing models. We see that GPT4o significantly outperforms other models.",
                "position": 565
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/SmartEdit_case.jpg",
                "caption": "Figure 5:Examples of model editing results. We visualize the qualitative results of GPT4o with the other four SOTA editing generation methods. We use the Reason-Edit[21]benchmark for evaluation.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/WISE.jpg",
                "caption": "Figure 6:Visual examples of generation results on the WISE benchmark[31]. We visualize the qualitative results of GPT4o under different evaluation scenarios, following the WISE benchmark.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/complete_archi.png",
                "caption": "Figure 7:We present a complete architectural speculation, proposing four possible candidates that differ in their choice of visual encoder while all share a diffusion-based head for image decoding.",
                "position": 887
            }
        ]
    },
    {
        "header": "3Potential Architectures Behind GPT4o",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/oai_cd.png",
                "caption": "Figure 8:An \"easter-egg\" example officially provided by the OpenAI, which aligns the potential architecture-(a) in Figure1.",
                "position": 915
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/GPT_Structure_Detection.jpg",
                "caption": "Figure 9:The overall workflow of the proposed model-based discrimination method.",
                "position": 942
            }
        ]
    },
    {
        "header": "4Weakness Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/bad-cases.jpg",
                "caption": "Figure 10:Failure Cases and Limitations of GPT-4o. We identify several scenarios in which GPT-4o may fail, along with common artifacts present in its generated images.",
                "position": 972
            }
        ]
    },
    {
        "header": "5More Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/multi-turn2.jpg",
                "caption": "Figure 11:Multi-round generation comparison between GPT-4o and Gemini-2.0 Flash.",
                "position": 992
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/SmartEdit_Fig1.jpg",
                "caption": "Figure 12:Examples of generation results of GPT4o using Reason-Edit[21].",
                "position": 1870
            },
            {
                "img": "https://arxiv.org/html/2504.02782/extracted/6334205/figures/multi-turn.jpg",
                "caption": "Figure 13:Multi-round generation comparison between GPT-4o and Gemini-2.0 Flash.",
                "position": 1873
            }
        ]
    },
    {
        "header": "7Appendix",
        "images": []
    }
]