[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/word_acc_comparison.png",
                "caption": "Figure 1:Breaking the Limits: Long-Text Image Generation Remains Elusive for Existing Models.State-of-the-art text rendering models, such as Text Diffusion 2[4]and AnyText[42], perform well on short text but struggle with longer passages.\nLarge diffusion models like Stable Diffusion 3.5 Large[10]can handle longer text but exhibit lower accuracy. The text recognition on generated images was conducted using Qwen2-VL[46]model.\nFor this evaluation, we sampled 140 examples from the interleaved Obelics[18]dataset with truncation.",
                "position": 136
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Advancing Tokenization for Text-Rich Images Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/TextBinarizer.png",
                "caption": "Figure 2:TextBinarizer implementation details.\nThis approach allows for direct quantization.",
                "position": 240
            }
        ]
    },
    {
        "header": "4LongTextAR",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/main_ppl.png",
                "caption": "Figure 3:The main pipeline of LongTextAR.\nOur trained text-focused tokenizer converts the long-text image into discrete token IDs.\nA corresponding long-text prompt is generated, and the model is then tasked with predicting the image token IDs based on this long text prompt.",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/tokenizer_comparison.png",
                "caption": "Figure 4:Tokenizer reconstruction comparison on data with long-text.Comparing with well-trained VQ tokenizer from Chameleon[38], our text-focus tokenizer leads to better reconstruction result on detail generation for letters.",
                "position": 409
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/controable_variable.png",
                "caption": "Figure 5:Controllable experiment, we modify the text font type, text color and text rotation degree, also the alignment way.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/all_model_comparison.png",
                "caption": "Figure 6:Text-conditioned long-text image generation comparison.The Stable Diffusion3.5 Large[10]and GPT-4o[30]+Dall-E3[3]using the promptGenerate a white-background text image and the text is: [Text Prompt].\nThe text is clear and large.For TextDiffuser 2[4]we use the promptA text imageand input other text as tags.\nWe use the Qwen2-VL[46]to recognize words from generated images and compute the accuracy according to the ground-truth text[Text Prompt].The image generation capabilities of GPT4o[30], released at the end of March 2025, have shown a huge gap over all other models, both open-source and closed-source.",
                "position": 592
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/natural_images.png",
                "caption": "Figure 7:Natural image text rendering examples.",
                "position": 741
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/ppt_application.png",
                "caption": "Figure 8:LongTextARÂ  generates interleaved PowerPoint data from long-text prompts.The model accurately produces layouts and renders both text and images effectively.\nBounding boxes from the text input are shown as a reference.",
                "position": 910
            }
        ]
    },
    {
        "header": "6Conclusion and Future Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Comparison with Baseline Models Lacking Text-Focused Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/supplementary/lumina_mgpt_same_case.png",
                "caption": "Figure 9:Baseline comparison.\nLumina-mGPT[21], an enhanced generation model built upon Chameleon[38], demonstrates limited capability in effectively following complex textual instructions.",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/powerpoint_application_comparison.png",
                "caption": "Figure 10:The interleaved powerpoint generation comparison.",
                "position": 1719
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/interleaved_examples.png",
                "caption": "Figure 11:More interleaved data examples.",
                "position": 1722
            }
        ]
    },
    {
        "header": "8Comparison with Existing Models on PowerPoint Data Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/controable_experiment.png",
                "caption": "Figure 12:Experiment on Controllable Variables:Stable Diffusion 3.5 Large[10]demonstrates poor instruction-following ability, ignoring all specified variants and occasionally generating irrelevant images.\nGPT-4-O[30], while showing noticeably better instruction-following capability, produces outputs with low accuracy and fails to capture the specified controllable variables.",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2503.20198/extracted/6310534/figures/src/more_powerpoing_examples.png",
                "caption": "Figure 13:More powerpoint generation examples.",
                "position": 1837
            }
        ]
    },
    {
        "header": "9Controllable Experiments",
        "images": []
    },
    {
        "header": "10Additional PowerPoint Generation Examples",
        "images": []
    }
]