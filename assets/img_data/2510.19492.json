[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19492/images/github_icon.png",
                "caption": "",
                "position": 142
            },
            {
                "img": "https://arxiv.org/html/2510.19492/images/miavsdet_hist_kde.png",
                "caption": "",
                "position": 144
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Theoretical Transfer between MIA and MGTD",
        "images": []
    },
    {
        "header": "3MIAs and Machine Text Detection Are Transferable",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19492/images/rank_correlation_plot_without_baselines.png",
                "caption": "Figure 2:Relationship between method rankings across MIAs and machine text detection. Blue and red plots showMIA methodsandmachine text detectors. Gray plots indicategeneral baselines. Dashed line denotes equal ranks.",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2510.19492/x1.png",
                "caption": "Figure 3:AUROC scores formembership inference attacks(blue bars) andgenerated text detectors(red bars) across both tasks.Top: Membership inference results on the MIMIR benchmark with 13-gram de-duplication filtering averaged overfive domainsandfive models.Middle and Bottom: Generated text detection results on white-box and black-box settings from the RAID benchmark, averaged overeight domainsandfive models. Both MIA methods (blue bars) and machine text detectors (red bars) have comparable performance in the cross-task setting. Notably, Binoculars achieves the best average performance in both tasks. Full results are provided in AppendixC.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2510.19492/images/zlib_entropy.png",
                "caption": "Figure 4:Zlib compression entropy distributioninMIAs(non-members vs. members) andmachine text detection(humans vs. machines), averaged over 3,000 randomly sampled texts for each dataset. The entropy converges between classes in MIAs but diverges in detection with a long tail, due to different prior distributions.",
                "position": 558
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Methods",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CFull Performance on Membership Inference and Machine Text Detection",
        "images": []
    }
]