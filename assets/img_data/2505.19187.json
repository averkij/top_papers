[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19187/x1.png",
                "caption": "Figure 1:Our PIR framework (implemented as LIMO-P) optimizes the efficiency-effectiveness tradeoff in LLM reasoning across AIME, AMC, and GPQA Diamond benchmarks: it consistently enhances accuracy while concurrently reducing response tokens, thus improving computational efficiency, demonstrating that selectively pruning low-importance functional steps produces more concise, faster, and more accurate reasoning chains.",
                "position": 115
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Reasoning Refinement: Reasoning Optimization Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19187/x2.png",
                "caption": "Figure 2:PIR framework pipeline for reasoning optimization: raw reasoning is segmented into logical steps, step is classified into reasoning patterns, PIR value is calculated to quantify step importance, and low-value functional steps are filtered while preserving progressive reasoning, resulting in more efficient reasoning chains.",
                "position": 212
            }
        ]
    },
    {
        "header": "3Experimental Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19187/x3.png",
                "caption": "Figure 3:Impact of pruning ratio on model performance. This figure displays relative performance metrics (normalized to baseline) across different pruning ratios for AIME and AMC benchmarks. The horizontal dashed line represents the baseline performance (ratio=0).",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2505.19187/x4.png",
                "caption": "Figure 4:Impact of PIR refinement across model sizes and benchmarks. Heatmaps show relative percentage changes between models trained with pruned versus original datasets. Blue indicates improvement: higher accuracy, shorter response length, or better efficiency.",
                "position": 658
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AReasoning Refinement: Reasoning Optimization Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19187/x5.png",
                "caption": "Figure 5:A case where one training sample contains the four patterns.",
                "position": 1408
            },
            {
                "img": "https://arxiv.org/html/2505.19187/x6.png",
                "caption": "Figure 6:The prompt to segment coherent sub-thinking sentences into cohesive reasoning steps.",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2505.19187/x7.png",
                "caption": "Figure 7:The prompt to categorize the steps into reasoning patterns",
                "position": 1421
            }
        ]
    },
    {
        "header": "Appendix BExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19187/x8.png",
                "caption": "Figure 8:Impact of reasoning patterns on model performance across different benchmarks. Each subplot displays the relative accuracy (y-axis) versus relative test time efficiency (x-axis) compared to the Progressive Reasoning (PR) baseline. PR represents the model trained with only progressive reasoning steps. PR+Verification (PR+V) is trained with the dataset that includes progressive reasoning and verification steps. PR+Error Correction (PR+EC) stands for the model trained with progressive reasoning and error correction steps. PR+Multi-method Validation (PR+MV) is trained with progressive reasoning and multi-method validation steps.",
                "position": 1933
            },
            {
                "img": "https://arxiv.org/html/2505.19187/x9.png",
                "caption": "Figure 9:Comparison of reasoning chains between model LIMO (left, 3,234 tokens) and PIR-optimized LIMO-P (right, 1,612 tokens) for the same mathematical problem. The model trained with PIR-optimized dataset maintains essential progressive reasoning while eliminating redundant verification steps, resulting in a 50% reduction in token count without sacrificing solution accuracy.",
                "position": 1950
            }
        ]
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    }
]