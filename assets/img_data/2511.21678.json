[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21678/x1.png",
                "caption": "Figure 1:Multimodal Semantic Memory Enables Progressive Learning. When solving multimodal problems, early attempts may contain both logical and visual errors; through feedback, the model refines its logical memory for question-appropriate theorem application and its visual memory to avoid perceptual traps—improving by integrating thewhere to lookwith thehow to reason.",
                "position": 100
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21678/x2.png",
                "caption": "Figure 2:Overview of theViLoMemframework. (a)Memory Cycle: A closed-loop learning mechanism where both logical and visual memories are retrieved and utilized by the solver. Retrieval is conditioned on the textual question and its paired image. The solver then performs reasoning steps (actions), which are evaluated by the verifier to filter redundant or invalid trajectories. The remaining trajectories are used to update both memory streams according to their respective types.\n(b)Memory Generation: An error-attribution framework that employs an LLM for logical analysis and an MLLM for visual analysis, producing structured memory schemas through similarity-basedmergeandcreateoperations. (c)Memory Retrieval: Specialized dual-stream retrieval mechanism. Visual memories undergo a two-stage process involving image-embedding retrieval followed by question-specific retrieval, since visual information must be conditioned on both image content and the textual query. Logical memories are retrieved through problem analysis and text-embedding similarity.",
                "position": 166
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21678/x3.png",
                "caption": "Figure 3:Visual memory generation and retrieval examples. Each case shows the original error, the extracted visual pattern, and successful retrieval in analogous scenarios.",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2511.21678/figures/memory_analysis.png",
                "caption": "Figure 4:Analysis of dual stream memory usage patterns across six benchmarks. (a) Memory generation and retrieval statistics show that visual errors dominate generation (59% to 93%), while retrieval operations significantly exceed generation events. (b) Cross task dependency analysis reveals balanced utilization of both memory streams during retrieval across diverse tasks and models.",
                "position": 547
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Additional Results and Ablation Study",
        "images": []
    },
    {
        "header": "7Additional Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.21678/x4.png",
                "caption": "Figure 5:Showcase of representative cases demonstratingViLoMem’s memory generation and retrieval process across different types of multimodal reasoning tasks.",
                "position": 1106
            }
        ]
    },
    {
        "header": "8Prompt Templates",
        "images": []
    }
]