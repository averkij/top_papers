[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00523/x1.png",
                "caption": "Figure 1:1024Ã—1024 samples produced by our 4-step generator distilled from FLUX.1-dev.",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method: Scaling Distribution Matching for General Distillation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00523/x2.png",
                "caption": "Figure 2:Left: The generatorğ’¢ğ’¢\\mathcal{G}caligraphic_Greceives a text prompt andxÏ„isubscriptğ‘¥subscriptğœğ‘–x_{\\tau_{i}}italic_x start_POSTSUBSCRIPT italic_Ï„ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPTto produce one-step outputxgsubscriptğ‘¥ğ‘”x_{g}italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT, which is diffused toxtsubscriptğ‘¥ğ‘¡x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand processed bysÏ•subscriptğ‘ italic-Ï•s_{\\phi}italic_s start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPTandsrsubscriptğ‘ ğ‘Ÿs_{r}italic_s start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPTfor computing DMD gradient. ISG guidesğ’¢ğ’¢\\mathcal{G}caligraphic_Gusing an intermediate pointxtmâ¢iâ¢dsubscriptğ‘¥subscriptğ‘¡ğ‘šğ‘–ğ‘‘x_{t_{mid}}italic_x start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_m italic_i italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT, and IDA alignsğ’¢ğ’¢\\mathcal{G}caligraphic_GwithsÏ•subscriptğ‘ italic-Ï•s_{\\phi}italic_s start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPTafter generator update.\nRight: The discriminator extracts semantic features from generated and real images using CLIP and DINOv2, which are processed by head blockshÎ¸isubscriptâ„subscriptğœƒğ‘–{h_{\\theta_{i}}}italic_h start_POSTSUBSCRIPT italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPTto predict real/fake logits for adversarial training. Trainable modules are shown in pink, while frozen (pretrained) ones are shown in grey.",
                "position": 276
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x3.png",
                "caption": "Figure 3:â€œTraining Hours-FIDâ€ curves on COCO-5K dataset. IDA improves training stability across TTUR ratios.",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x4.png",
                "caption": "(a)",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x4.png",
                "caption": "(a)",
                "position": 334
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x5.png",
                "caption": "(b)",
                "position": 339
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x6.png",
                "caption": "(c)",
                "position": 344
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00523/x7.png",
                "caption": "Figure 5:Qualitative comparisons on challenging prompts across methods. Our method shows superior fidelity, especially in rendering human faces, scene composition, and fine-grained textures.",
                "position": 877
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x8.png",
                "caption": "Table 3:Ablation Study Results of IDA, ISG, and VFM Discriminator.",
                "position": 884
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x9.png",
                "caption": "Figure 6:1024Ã—1024 samples produced by our 4-step generator distilled from SD 3.5 Large.",
                "position": 953
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusions and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00523/x10.png",
                "caption": "Figure 7:Design of the VFM-based discriminator.",
                "position": 1611
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x11.png",
                "caption": "Figure 8:Examples from T2I-CompBench.",
                "position": 1890
            },
            {
                "img": "https://arxiv.org/html/2506.00523/x12.png",
                "caption": "Figure 9:1024Ã—1024 samples produced by our 4-step generator distilled from SDXL.",
                "position": 1895
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]