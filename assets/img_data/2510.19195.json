[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x1.png",
                "caption": "",
                "position": 87
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x2.png",
                "caption": "Figure 1:Dream4Drive demonstrates the effectiveness of synthetic data: with fewer than 2% synthetic samples, it consistently improves detection and tracking across epochs, outperforming previous data augmentation baselines underfair evaluation. 1× denotes the baseline training epoch; 2× and 3× mean doubling and tripling it.",
                "position": 160
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x3.png",
                "caption": "Figure 2:The illustration ofDream4Drive, which provides precise annotations, geometric variety, and appearance diversity to improve downstream perception tasks.",
                "position": 228
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Dream4Drive",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x4.png",
                "caption": "Figure 3:The illustration of 3D-aware scene editing. Given the input images, we first obtain the depth map, normal map, and edge map for the background and then render the object image and object mask for the target 3D asset.",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x5.png",
                "caption": "Figure 4:The illustration of 3D-aware video rendering. Given the 3D-aware guidance maps, we employ a multi-condition fusion adapter to control the video generation of a diffusion transformer, rendering the edited video.",
                "position": 312
            }
        ]
    },
    {
        "header": "4DriveObj3D",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x6.png",
                "caption": "Figure 5:The illustration of creating a 3D asset in DriveObj3D. We first apply a segmentation model to segment the target object, then generate multi-view images, and finally create a 3D mesh from those images.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x7.png",
                "caption": "Figure 6:Comparison of 3D asset generation across different methods. Our simple yet effective method produces better 3D assets across diverse categories in autonomous driving, outperforming existing baselines. Con_vehicle is construction vehicle; Pdes is Pedestrian; T_cone is traffic cone.",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x8.png",
                "caption": "Figure 7:DriveObj3Ddataset. A large-scale collection of diverse 3D assets across typical driving categories, supporting scalable video editing and synthetic data generation.",
                "position": 377
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x9.png",
                "caption": "Figure 8:Comparison with naive insertion. As can be seen, Dream4Drive generates more realistic edited videos than naive insertion.",
                "position": 655
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BDetailed AP Metrics",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experiments on Generation Quality",
        "images": []
    },
    {
        "header": "Appendix DAdditional Visualization",
        "images": []
    },
    {
        "header": "Appendix ELimitation and Future Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19195/x10.png",
                "caption": "Figure 9:A case study of contrast between reflection and shadow.",
                "position": 2174
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x11.png",
                "caption": "Figure 10:A case study of contrast between reflection and shadow.",
                "position": 2177
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x12.png",
                "caption": "Figure 11:Insertion of a car in the right-side region.",
                "position": 2180
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x13.png",
                "caption": "Figure 12:Insertion of a truck in the left-side region.",
                "position": 2183
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x14.png",
                "caption": "Figure 13:Insertion of a barrier in the left-side region.",
                "position": 2186
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x15.png",
                "caption": "Figure 14:Insertion of a bus in the back-side region.",
                "position": 2189
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x16.png",
                "caption": "Figure 15:Insertion of a traffic cone in the left-side region.",
                "position": 2192
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x17.png",
                "caption": "Figure 16:Insertion of a construction vehicle in the back-side region.",
                "position": 2195
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x18.png",
                "caption": "Figure 17:Corner case. Insertion of a barrier in the front-side region, where the ego vehicle is about to collide with it.",
                "position": 2198
            },
            {
                "img": "https://arxiv.org/html/2510.19195/x19.png",
                "caption": "Figure 18:Corner case. Insertion of a truck in the close-range front-side region.",
                "position": 2201
            }
        ]
    },
    {
        "header": "Appendix FStatement on LLM Usage",
        "images": []
    }
]