[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/teaser/teaser.jpg",
                "caption": "",
                "position": 107
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Origen",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/toy_exp_v2.jpg",
                "caption": "Figure 2:Toy experiment results.The top row shows latent space samples (red), while the bottom row shows the corresponding data space samples (blue). From left to right, each column represents: (1) the ground truth target distribution from Eq.¬†(2); (2) results of ReNO[16]; (3) results of ours with uniform time scaling; and (4) results of ours with reward-adaptive time rescaling.",
                "position": 461
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0162.jpg",
                "caption": "Figure 3:Qualitative comparisons onMS-COCO-Singlebenchmark (Sec.4.3).Compared to the existing orientation-to-image models[11,46],Origengenerates the most realistic images, which also best align with the grounding conditions, indicated by the overlapped arrow in each image.",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0693.jpg",
                "caption": "",
                "position": 547
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0576.jpg",
                "caption": "",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0940.jpg",
                "caption": "",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/left_0028.jpg",
                "caption": "Figure 4:Qualitative comparisons onMS-COCO-NViewbenchmark (Sec.4.4).Origengenerates high-fidelity images with the best grounding accuracy. Note that C3DW[11]does not support back-view generation, as it only supports the control of the front180‚àòsuperscript180180^{\\circ}180 start_POSTSUPERSCRIPT ‚àò end_POSTSUPERSCRIPTof azimuth angles.",
                "position": 556
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/front_0083.jpg",
                "caption": "",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/back_0248.jpg",
                "caption": "",
                "position": 602
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0007.jpg",
                "caption": "Figure 5:Qualitative results on theMS-COCO-Multibenchmark (Sec.4.5)Origenachieves accurate grounding while generalizing across multiple objects.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0044.jpg",
                "caption": "",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0102.jpg",
                "caption": "",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0133.jpg",
                "caption": "",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0151.jpg",
                "caption": "",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0205.jpg",
                "caption": "",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0221.jpg",
                "caption": "",
                "position": 660
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0261.jpg",
                "caption": "",
                "position": 661
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "AAnalysis on Norm-Based Regularization",
        "images": []
    },
    {
        "header": "BProofs",
        "images": []
    },
    {
        "header": "CAnalysis on Reward-Adaptive Time-Rescaled SDE",
        "images": []
    },
    {
        "header": "DSetup for the Toy Experiment",
        "images": []
    },
    {
        "header": "EGeneral Orientation Controllability",
        "images": []
    },
    {
        "header": "FText-to-Image Alignment Results on MS-COCO-NView",
        "images": []
    },
    {
        "header": "GUser Study Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/userstudy/initial.jpg",
                "caption": "(a)Start page of the user study.",
                "position": 2816
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/userstudy/initial.jpg",
                "caption": "(a)Start page of the user study.",
                "position": 2819
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/userstudy/problem.jpg",
                "caption": "(b)Main test page of the user study.",
                "position": 2825
            }
        ]
    },
    {
        "header": "HImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/gplot_small.jpg",
                "caption": "Figure B:Plot of our monitor functionùí¢‚Å¢(‚Ñõ^‚Å¢(ùê±))ùí¢^‚Ñõùê±\\mathcal{G}(\\hat{\\mathcal{R}}(\\mathbf{x}))caligraphic_G ( over^ start_ARG caligraphic_R end_ARG ( bold_x ) ).",
                "position": 2841
            }
        ]
    },
    {
        "header": "IMore Qualitative Comparisons on Single Object Orientation Grounding",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0171.jpg",
                "caption": "Figure C:Additional Qualitative results on theMS-COCO-Singlebenchmark.",
                "position": 2864
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0242.jpg",
                "caption": "",
                "position": 2910
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0406.jpg",
                "caption": "",
                "position": 2913
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0581.jpg",
                "caption": "",
                "position": 2914
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0607.jpg",
                "caption": "",
                "position": 2917
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/benchmark/0661.jpg",
                "caption": "",
                "position": 2918
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/left_0184.jpg",
                "caption": "Figure D:Qualitative comparisons onMS-COCO-4-Viewbenchmark.",
                "position": 2924
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/front_0190.jpg",
                "caption": "",
                "position": 2967
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/3view/right_0246.jpg",
                "caption": "",
                "position": 2970
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0017.jpg",
                "caption": "Figure E:Additional Qualitative results on theMS-COCO-Multibenchmark.",
                "position": 2982
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0030.jpg",
                "caption": "",
                "position": 3028
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0041.jpg",
                "caption": "",
                "position": 3029
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0048.jpg",
                "caption": "",
                "position": 3030
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0050.jpg",
                "caption": "",
                "position": 3033
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0065.jpg",
                "caption": "",
                "position": 3034
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0090.jpg",
                "caption": "",
                "position": 3035
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0101.jpg",
                "caption": "",
                "position": 3036
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0107.jpg",
                "caption": "",
                "position": 3039
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0108.jpg",
                "caption": "",
                "position": 3040
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0141.jpg",
                "caption": "",
                "position": 3041
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0147.jpg",
                "caption": "",
                "position": 3042
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0169.jpg",
                "caption": "",
                "position": 3046
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0248.jpg",
                "caption": "",
                "position": 3047
            },
            {
                "img": "https://arxiv.org/html/2503.22194/extracted/6317238/figures/quali/multi/0313.jpg",
                "caption": "",
                "position": 3048
            }
        ]
    },
    {
        "header": "JMore Qualitative Results on Multi Object Orientation Grounding",
        "images": []
    }
]