[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09736/x1.png",
                "caption": "Figure 1:Caption-augmented LLM can outperform MLLM on MathVision[40].",
                "position": 86
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09736/x2.png",
                "caption": "Figure 2:Our visual perturbation framework consists of three strategies: (1) distractor concatenation that horizontally combines the input image with a random distractor, (2) dominance-preserving mixup that blends the input with a distractor using skewed alpha values, and (3) random rotation that applies small angle rotations. During training, these perturbations are applied across multiple alignment pipelines including SFT, DPO, and GRPO to enhance the modelâ€™s perceptual robustness and reasoning consistency.",
                "position": 285
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]