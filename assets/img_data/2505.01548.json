[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x1.png",
                "caption": "",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x2.png",
                "caption": "Figure 2:Overview of BRENet: Given an input RGB-Event pair, the Flow Encoder estimates bidirectional optical flowsùë∂ùë∂\\boldsymbol{O}bold_italic_Ofrom the event streamùë¨ùë¨\\boldsymbol{E}bold_italic_E. The output coarse-grained optical flowsùë∂ùë∂\\boldsymbol{O}bold_italic_Oare fed into the Motion Enhancement Estimator (MEE), along with the fine-grained event featuresùíâùíâ\\boldsymbol{h}bold_italic_hfrom the Temporal Convolution Module. The Bidirectional Flow Aggregation Module (BFAM) further aggregates both image featuresùë≠ùë∞subscriptùë≠ùë∞\\boldsymbol{F_{I}}bold_italic_F start_POSTSUBSCRIPT bold_italic_I end_POSTSUBSCRIPTand Motion-enhanced Event Tensorsùë¥ùë¥\\boldsymbol{M}bold_italic_Madaptively in both forward and backward directions. Finally, the Temporal Fusion Module (TFM) combines bidirectional fused features to learn the temporal consistency.",
                "position": 188
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x3.png",
                "caption": "Figure 3:Illustration of Motion Enhancement Estimator (MEE).",
                "position": 205
            },
            {
                "img": "https://arxiv.org/html/2505.01548/x4.png",
                "caption": "Figure 4:Illustration of Bidirectional Flow Aggregation Module (BFAM): From left to right, the components are Spatial and Channel Attention Blocks.",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2505.01548/x5.png",
                "caption": "Figure 5:Illustration of Temporal Fusion Module (TFM).",
                "position": 255
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x6.png",
                "caption": "Figure 6:Qualitative results on DSEC dataset[12]. The proposed BRENet produces images with enhanced boundary details and more robust visuals compared to SOTA methods. More qualitative results are in the supplementary results.",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2505.01548/x7.png",
                "caption": "Figure 7:Visualization of forward and backward optical flow maps and comparison between feature maps with and without MET. Best viewed with zoom.",
                "position": 725
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x8.png",
                "caption": "",
                "position": 1529
            }
        ]
    },
    {
        "header": "6Additional Qualitative Results",
        "images": []
    },
    {
        "header": "7Additional Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.01548/x9.png",
                "caption": "Figure 9:Performance vs. model size on DDD17 dataset[3].",
                "position": 1771
            }
        ]
    },
    {
        "header": "8Performance vs. Model Size",
        "images": []
    }
]