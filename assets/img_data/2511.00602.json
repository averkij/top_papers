[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00602/x1.png",
                "caption": "Figure 1:Overview of the OpenSIR framework.\nA single policyπθ\\pi_{\\theta}alternates between generating and solving novel problems without external supervision.\nEach training iteration consists ofproblem generation,solution sampling,scoring, andmodel update.\nNovelty is captured through bothdifficultyanddiversity: problems must be challenging yet solvable, and they must explore new concepts.\nThese dimensions together drive open-ended self-improvement in the LLM reasoning ability.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Open-Ended Self-Improving Reasoner",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Ablations and Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00602/x2.png",
                "caption": "Figure 2:Evolution of problem difficulty, validity, and topic diversity during OpenSIR training.(Left)Human evaluation results showing difficulty rankings (1-5 scale where 1=easiest, 5=hardest)\nand number of invalid problems for GSM8K, MATH, and problems generated at steps 0, 100, and 200 of training.\nInvalid problems are those with logical flaws, missing information, or ambiguities.(Right)Distribution of mathematical topics across training stages, demonstrating\nthe increasing diversity of generated problems from step 0 to step 200.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2511.00602/x3.png",
                "caption": "Figure 3:t-SNE visualization of problem embeddings showing the effect of diversity reward on problem distribution. With diversity reward, problems explore broader regions of the embedding space compared to the clustered distribution without diversity reward.",
                "position": 737
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00602/x4.png",
                "caption": "Figure 13:Heatmap visualisation of n-gram similarity (ROUGE-L scores) and concept overlap between generated problems at training steps 0, 100, 200 and reference datasets (MATH, GSM8K). Top row: with diversity reward; Bottom row: without diversity reward. With diversity reward incorporated, the generated problems exhibit low textual similarity and minimal concept overlap, demonstrating effective exploration of diverse problem types.",
                "position": 2868
            }
        ]
    },
    {
        "header": "Appendix BAnnotation Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Ablations",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    }
]