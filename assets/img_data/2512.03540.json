[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03540/fig1_2.png",
                "caption": "Figure 1.Demonstration of our CookAnything model generating multi-step cooking instructions in a single pass. Each example shows the user’s prompt (left) and the corresponding series of dish images (right), from initial preparation steps through the final plated result (Details of the complete recipe text can be found in the Supplementary A.6.).",
                "position": 136
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03540/arc.png",
                "caption": "Figure 2.Overall structure of ourCookAnythingmodel, illustrated with a 3-step vegetable pancake recipe. The Cooking Agent reformats the raw recipe into context-tagged steps, supplementing missing ingredient details. Each step is encoded by aT5 Encoderin two ways: (1) all steps are concatenated to capture global context and producecontextual step tokens, and (2) each step is encoded independently to preserve local semantics and generatestep tokens. These two types of tokens are fused viaweighted averaging. Meanwhile, noisy latent tokens, processed by Flexible RoPE, are fed into DiT. AStep-wise Regional Attention Maskis applied during DiT’s self-attention to constrain attention within each step, ensuring step-wise focus and visual consistency. In the illustration, purple, green, and pink tokens represent Steps 1, 2, and 3, respectively",
                "position": 226
            },
            {
                "img": "https://arxiv.org/html/2512.03540/rope2.png",
                "caption": "Figure 3.The example from Original RoPE. Visualization comparison between original RoPE and our proposed Flexible RoPE using the example ofLamb Pilaf. With original RoPE, repeated step images appear as early as Step 2. Steps 3 and 6 exhibit positional misalignment, and Step 9 suffers from noticeable blurring. In contrast, Flexible RoPE maintains clear step-wise differentiation, stable spatial alignment, and improved visual sharpness throughout the cooking process.",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2512.03540/CSCC3.png",
                "caption": "Figure 4.Examples before and after applying Cross-Step Consistency Control (CSCC).Left: Stir-Fried Carrot with Dried Tofu.Without CSCC, the carrot changes from cubes to strips in Step 4. Visualization of contextual tokens (using Flux.1-dev) shows shape continuity is preserved, so CSCC helps maintain a consistent appearance.Right: Steamed Chicken Wings with Taro.In Step 5, taro should appear beneath the wings but disappears without CSCC. Since contextual tokens confirm its presence, CSCC successfully preserves it.",
                "position": 411
            }
        ]
    },
    {
        "header": "4.Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03540/vis.png",
                "caption": "Figure 5.Qualitative comparisons. SKD refers to StackedDiffusion, and SD3.5 refers to Stable Diffusion 3.5. Both SD3.5 Flux.1-dev and SKD exhibit issues with ingredient accuracy, discontinuous ingredient shapes, and the generation of incorrect ingredients. In contrast, our model excels in maintaining the shape and continuity of ingredients.",
                "position": 563
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.03540/vis5.png",
                "caption": "Figure 6.Visualization of dishes from different regions.",
                "position": 1416
            },
            {
                "img": "https://arxiv.org/html/2512.03540/liq.png",
                "caption": "Figure 7.Visualization about liquid.",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2512.03540/cookingagent.png",
                "caption": "Figure 8.Prompt for refining recipe caption, with GPT-4o",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2512.03540/appendix5.png",
                "caption": "Figure 9.Prompt to measure the Step Faithfulness of the generated image, with GPT-4o",
                "position": 1425
            },
            {
                "img": "https://arxiv.org/html/2512.03540/appendix3.png",
                "caption": "Figure 10.Prompt to measure the Ingredient Accuracy of the generated image, with GPT-4o",
                "position": 1428
            },
            {
                "img": "https://arxiv.org/html/2512.03540/appendix4.png",
                "caption": "Figure 11.Prompt to measure the Usability of the generated image, with GPT-4o",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2512.03540/question.png",
                "caption": "Figure 12.Template for Human Study.",
                "position": 1434
            }
        ]
    },
    {
        "header": "6.Supplementary Material",
        "images": []
    }
]