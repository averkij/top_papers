[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08521/x1.png",
                "caption": "Figure 1:UniVA (Universal Video Agent) delivers a highly automated, interactive, and proactive video creation experience, featuring multi-round dialogue co-creation, memory-based contextual reasoning, intent understanding, and tool-augmented planning for iterative user interaction.\nIt also serves as an omnipotent, unified, industrial-grade video production engine, integrating diverse generation, editing, and understanding modules within an MCP-based framework to ensure cinematic quality, consistency, and extensibility across any-conditioned video tasks.",
                "position": 258
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08521/x2.png",
                "caption": "Figure 2:Overall architecture of the proposed UniVA system, built on a Plan–Act paradigm.\nThe Plan Agent decomposes user input (text, image, or video) into subtasks by leveraging global memory (historical traces) and user memory (stored materials).\nThe Act Agent retrieves task-specific memory, executes subtasks via the MCP protocol, and coordinates with external MCP servers (video, AI, and non-AI tools). The system generates multimodal outputs, including text, image, video, and audio.",
                "position": 354
            }
        ]
    },
    {
        "header": "3UniVA",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08521/x3.png",
                "caption": "Figure 3:Memory-augmented framework for video generation.\nGlobal and user memories provide context to the plan agent, while task memory coordinates tool calling, storyboard creation, and video generation.",
                "position": 411
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x4.png",
                "caption": "Figure 4:Iterative tool calling for video generation in UniVA. Left: one-prompt task applies a global ink-painting style. Right: multi-round task incrementally edits via segmentation, background change, and extension, demonstrating representative functions.",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2511.08521/figures/system_screenshot.png",
                "caption": "Figure 5:The interface combines a traditional non-linear timeline and preview canvas with a conversational assistant (left), which provides a user-friendly entry point to the UniVA agent. This design supports both one-stop, prompt-based generation and multi-turn, interactive editing workflows.",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x5.png",
                "caption": "Figure 6:Representative examples from the four main task categories in UniVA-Bench: Understanding, Generation, Editing, and Segmentation.",
                "position": 479
            }
        ]
    },
    {
        "header": "4UniVA-Bench",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08521/x6.png",
                "caption": "Figure 7:Performance of Planner LLMs.",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x6.png",
                "caption": "Figure 7:Performance of Planner LLMs.",
                "position": 785
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x7.png",
                "caption": "Figure 8:Framework comparison.",
                "position": 790
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x8.png",
                "caption": "Figure 9:Effect of trace memory.",
                "position": 809
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x8.png",
                "caption": "Figure 9:Effect of trace memory.",
                "position": 812
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x9.png",
                "caption": "Figure 10:Effect of user memory.",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x10.png",
                "caption": "Figure 11:Effect of storyboard.",
                "position": 822
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x11.png",
                "caption": "Figure 12:Results from the human evaluation study on video generation tasks.",
                "position": 852
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x12.png",
                "caption": "Figure 13:UniVA accurately generates the sequential process of pottery making, demonstrating strong temporal consistency and object persistence as the bowl evolves from clay to a finished product.",
                "position": 864
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x13.png",
                "caption": "Figure 14:UniVA maintains the protagonist’s identity flawlessly across drastically different scenes, lighting conditions (night vs. day), and camera angles, showcasing its advanced capability for robust, long-form character preservation.",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x14.png",
                "caption": "Figure 15:UniVA interprets an abstract prompt to generate a complex narrative. It orchestrates a non-linear story arc, proving its capability as an intelligent storyteller powered by sophisticated planning.",
                "position": 874
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x15.png",
                "caption": "Figure 16:UniVA generates a coherent 20-second commercial that accurately follows the structured sequence of requirements—from kneading dough and showing customer reactions to applying the final brand logo.",
                "position": 879
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x16.png",
                "caption": "Figure 17:Given an original video, the agent not only maintains the original characters’ style but also logically constructs a new backstory.",
                "position": 884
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x17.png",
                "caption": "Figure 18:UniVA successfully applies a “Chinese ink-painting style” to the visuals while precisely maintaining the original video’s plot, character motion, and scene composition.",
                "position": 889
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x18.png",
                "caption": "Figure 19:UniVA can well follow the user’s long instructions and ensure consistency of characters in long videos.",
                "position": 894
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x19.png",
                "caption": "Figure 20:UniVA can understand and generate complex multi-camera scene transitions, producing multi-camera long videos.",
                "position": 899
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x20.png",
                "caption": "Figure 21:Univa can also maintain consistency well for multiple entity references.",
                "position": 904
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x21.png",
                "caption": "Figure 22:Univa can accurately analyze and understand the characters and style of a video, then seamlessly apply them to generate content.",
                "position": 909
            },
            {
                "img": "https://arxiv.org/html/2511.08521/x22.png",
                "caption": "Figure 23:Univa can perform tasks through multi-turn dialogues by leveraging memory mechanisms and context.",
                "position": 914
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Detailed Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08521/x23.png",
                "caption": "Figure 24:A three-level taxonomy of MCP tools: modules (level-1), tools (level-2), and leaf boxes summarizing name, type, and functionality.",
                "position": 1033
            }
        ]
    },
    {
        "header": "8Extended Description on UniVA-Bench",
        "images": []
    },
    {
        "header": "9Detailed Experiment Settings",
        "images": []
    }
]