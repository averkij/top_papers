[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07430/x1.png",
                "caption": "Figure 1:The left panel shows the performance of a model trained exclusively on the Bird dataset, evaluated across different test sets. The X-axis represents the degree of domain and task divergence from the training set. Specifically, Bird is the original SQL dataset, Spider is another dataset for the same SQL task but from a different domain, and Math represents the average result for a class of mathematical tasks. The datasets are ordered from right to left, showing an increasing divergence from the distribution of our RL training set. The Y-axis shows the relative Pass@k score, calculated as (Current Model’s Pass@k) / (Base Model’s Pass@k). The right panel visualizes the distributions of reverse-KL and forward-KL.",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07430/x2.png",
                "caption": "Figure 2:η\\etavs. Greedy Performance",
                "position": 803
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07430/x3.png",
                "caption": "(a)Llama Bird",
                "position": 1006
            },
            {
                "img": "https://arxiv.org/html/2509.07430/x3.png",
                "caption": "(a)Llama Bird",
                "position": 1009
            },
            {
                "img": "https://arxiv.org/html/2509.07430/x4.png",
                "caption": "(b)Llama Spider",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2509.07430/x5.png",
                "caption": "Figure 4:Exploring the differences between base model and RL-Tuned models in Llama.",
                "position": 1028
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMultiple Style Capability Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07430/x6.png",
                "caption": "Figure 5:On the left, we construct a base model that outputs multiple solution styles for SQL problems. This model is then used for reinforcement learning training. We calculated the probability of the number of times the model outputted different styles across 32 samples.",
                "position": 1667
            }
        ]
    },
    {
        "header": "Appendix BRLVR Algorithms",
        "images": []
    },
    {
        "header": "Appendix CMethod for Divergence Definition",
        "images": []
    },
    {
        "header": "Appendix DTraining Details",
        "images": []
    },
    {
        "header": "Appendix EAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.07430/x7.png",
                "caption": "Figure 6:Error bar in Llama Sql. For each method in our Llama SQL experiments, we conducted three separate reinforcement learning training runs. We then selected the model that achieved the highest pass@16 score on the Bird.",
                "position": 2132
            }
        ]
    },
    {
        "header": "Appendix FCase Study",
        "images": []
    },
    {
        "header": "Appendix GProof of Theorem 1",
        "images": []
    }
]