[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25602/x1.png",
                "caption": "Figure 1:Compute flow of low-bit forward and backward propagation of linear layer.",
                "position": 349
            },
            {
                "img": "https://arxiv.org/html/2510.25602/x1.png",
                "caption": "Figure 1:Compute flow of low-bit forward and backward propagation of linear layer.",
                "position": 351
            },
            {
                "img": "https://arxiv.org/html/2510.25602/x2.png",
                "caption": "Figure 2:Impact of clipping range on INT8 final training loss on 145M model with 20B training tokens. Scale factor is kept on BF16 to emphasize the harm of asymmetric representation space during low-bit training.",
                "position": 355
            }
        ]
    },
    {
        "header": "3Quantization Recipe",
        "images": []
    },
    {
        "header": "4Theoretical Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25602/x3.png",
                "caption": "Figure 3:Theoretical QSNR comparison between various integer (INT) and floating-point (FP) formats across a range of crest factors (Îº\\kappa), derived from Eq. (13) and Eq. (14). The boxes represent the crest factor and QSNR of the crossover point of the INT and FP curves.",
                "position": 467
            }
        ]
    },
    {
        "header": "5FPv.s.INT",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25602/x4.png",
                "caption": "(a)QSNR across crest factor",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2510.25602/x4.png",
                "caption": "(a)QSNR across crest factor",
                "position": 591
            },
            {
                "img": "https://arxiv.org/html/2510.25602/x5.png",
                "caption": "(b)QSNR across crest factor (w/ Hadamard rotation)",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2510.25602/x6.png",
                "caption": "Figure 5:Loss curves comparison among BF16, MXFP8 and MXINT8 training on Llama-1B with 100B tokens. Results are smoothed by exponential moving average with a coefficient of 0.9.",
                "position": 776
            }
        ]
    },
    {
        "header": "6Hardware Cost Analysis",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Outlines",
        "images": []
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Proofs of Theorems",
        "images": []
    },
    {
        "header": "10Hardware Cost Modeling",
        "images": []
    },
    {
        "header": "11More Details for Reproduction",
        "images": []
    }
]