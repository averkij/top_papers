[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11718/x1.png",
                "caption": "Figure 1:A comparison of mathematical reasoning benchmarks and the methods on the visual reasoning problem. (1) illustrates that unlike existing benchmarks that rely on textual reasoning, Math-VR requires deep visual reasoning to resolve the math problems. (2) shows that on a visually ambiguous problem from Math-VR, both text-only and unified multimodal models fail. Our method, CodePlot-CoT, succeeds by programmatically generating the figure to uncover its true geometric properties, thus arriving at the correct solution.",
                "position": 112
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Math-VR: Dataset and benchmark for Math Visual Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/question.jpg",
                "caption": "Figure 2:Visualization of Math-VR sample.",
                "position": 201
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/analysis.jpg",
                "caption": "",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2510.11718/x2.png",
                "caption": "Table 1:Key Statistics for Math-VR Benchmark.We report statistics of our benchmark, including token lengths of questions and solutions, as well as the number and resolution of images.",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2510.11718/x2.png",
                "caption": "Figure 3:Distribution of Knowledge Types in Math-VR Benchmark.Geometry constitutes the majority of problems (77%), with Algebra and Calculus comprising 13%.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2510.11718/x3.png",
                "caption": "Figure 4:Math-VR Evaluation Pipeline.\nWe design a VLM-based framework to comprehensively assess visual reasoning abilities of different models. The evaluation uses two metrics: Answer Correctness (AC), which gives a reliable binary judgment of the final answer, and Process Score (PS), which provides a fine-grained assessment of the solving process.",
                "position": 332
            },
            {
                "img": "https://arxiv.org/html/2510.11718/x4.png",
                "caption": "Figure 5:Illustration of the CodePlot-CoT paradigm for mathematical visual reasoning. The model interleaves natural language reasoning with code-based visual reasoning. At points in the solution that require visual support, the model generates a sequence of executable plotting code, which is rendered via Python into precise figures and input back into the model. This allows the model to “see” its own visual thought and leverage it for subsequent reasoning, ultimately leading to a more accurate final solution. CodePlot-CoT supports interleave text and multi-image reasoning.",
                "position": 373
            }
        ]
    },
    {
        "header": "4CodePlot-CoT Paradigm: Code-driven CoT for Mathematics Visual Reasoning",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Ethics and Reproducibility Statement",
        "images": []
    },
    {
        "header": "8Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11718/x5.png",
                "caption": "Figure 6:Distribution of Knowledge Types in\nMath-VR Dataset.Geometry constitutes\nthe majority of problems (76%), with Algebra\nand Calculus comprising 12%.",
                "position": 1570
            }
        ]
    },
    {
        "header": "Appendix BBenchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/Figures/GUI.png",
                "caption": "Figure 9:The GUI interface for manual sample selection and meta information verification.\nThis interface displays the Question and Analysis files on the left and center panels, with the Review Checklist on the right.Left: The meta information extracted for each sample is displayed on the right panel.Right: Scrolling down reveals the items for annotators to check and flag.",
                "position": 1854
            }
        ]
    },
    {
        "header": "Appendix CTraining Details",
        "images": []
    },
    {
        "header": "Appendix DCodePlot-CoT Samples on Math-VR Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/0336ec645adbf91eb4506497da0cebd9.jpg",
                "caption": "Figure 10:Multimodal input sample from Math-VR.",
                "position": 1886
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/e56d4bf84211dba203fd1791b9a06131.jpg",
                "caption": "",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/c3443a1ce5e04c70ab5a37e15128b458.jpg",
                "caption": "Figure 11:Text input example from Math-VR.",
                "position": 1942
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/7ea8b3db4ad5e25316c74d7e4e7874d4.jpg",
                "caption": "",
                "position": 1986
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/mm_sample_0.jpg",
                "caption": "Figure 12:A multimodal math question form Math-VR benchmark and CodePlot-CoT generated analysis.",
                "position": 1995
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/mm_sample_1.png",
                "caption": "",
                "position": 2023
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/text_sample_0.png",
                "caption": "Figure 13:A pure textual math question form Math-VR benchmark and CodePlot-CoT generated analysis.",
                "position": 2067
            },
            {
                "img": "https://arxiv.org/html/2510.11718/Appendix/images/limit.png",
                "caption": "Figure 14:A pure textual math question form Math-VR benchmark and CodePlot-CoT generated solution. The textual reasoning is correct, but the model generates a slightly imperfect image in reasoning by placing H not on edge AD.",
                "position": 2116
            }
        ]
    },
    {
        "header": "Appendix ELimitations",
        "images": []
    }
]