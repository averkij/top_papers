[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05579/x1.png",
                "caption": "Figure 1:Left: Human-AI collaboration performance plotted against model solo performance for both code tasks (blue circles) and math tasks (green triangles). Models improve human-AI collaboration (r=0.84ğ‘Ÿ0.84r=0.84italic_r = 0.84for code,r=0.69ğ‘Ÿ0.69r=0.69italic_r = 0.69for math), but at a slower rate than their solo capabilities (gray line showsy=xğ‘¦ğ‘¥y=xitalic_y = italic_x). Right: Human preference rates show task-dependent correlations with model performance (positive for code tasks,r=0.73ğ‘Ÿ0.73r=0.73italic_r = 0.73; slight negative for math tasks,r=âˆ’0.14ğ‘Ÿ0.14r=-0.14italic_r = - 0.14), revealing that user preferences vary across task domains and do not consistently align with actual performance.",
                "position": 174
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3KITE: Quantifying Knowledge Transfer",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05579/x2.png",
                "caption": "Figure 2:Model knowledge (kMâˆˆMsubscriptğ‘˜ğ‘€ğ‘€k_{M}\\in Mitalic_k start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT âˆˆ italic_M) must be projected into a form understandable by human users (Î Mâ†’Hâ¢(kM)subscriptÎ â†’ğ‘€ğ»subscriptğ‘˜ğ‘€\\Pi_{M\\rightarrow H}(k_{M})roman_Î  start_POSTSUBSCRIPT italic_M â†’ italic_H end_POSTSUBSCRIPT ( italic_k start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT )) in order to communicate knowledge effectively. Effective projectionsâ€”via examples, analogies, or context aggregationâ€”bridge the gap between disjoint representations.",
                "position": 218
            }
        ]
    },
    {
        "header": "4KITE: Evaluating Knowledge Transfer",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05579/x3.png",
                "caption": "Figure 3:Two-phase evaluation framework. (1) Collaborative Ideation: Users and an AI assistant engage in open-ended discussion to explore problem-solving strategies. (2) Independent Solving: Users then implement a solution independently, without further assistance. This design leverages the nature of coding and math tasksâ€”where successful implementation demands deep understanding, not rote recallâ€”to isolate and measure genuine knowledge transfer.",
                "position": 276
            }
        ]
    },
    {
        "header": "5Results",
        "images": []
    },
    {
        "header": "6Qualitative Analysis: Interaction Dynamics",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05579/x4.png",
                "caption": "Figure 4:Analysis of human-AI problem-solving interactions. Human queries (left), model responses (center), and human feedback (right) are color-coded by correlation with successful problem resolution (green: positive, red: negative). Percentages indicate each categoryâ€™s frequency, revealing patterns in effective vs. ineffective knowledge transfer.",
                "position": 695
            }
        ]
    },
    {
        "header": "7Discussion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AParticipant Demographics",
        "images": []
    },
    {
        "header": "Appendix BAuxiliary Study Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.05579/extracted/6505936/figures/questionnaire.png",
                "caption": "Figure 16:Questionnaire that users answered after each problem solving session.",
                "position": 2068
            },
            {
                "img": "https://arxiv.org/html/2506.05579/extracted/6505936/figures/conversation_length.png",
                "caption": "Figure 18:Distribution of conversation lengths, based on number of messages sent by the human.",
                "position": 2248
            },
            {
                "img": "https://arxiv.org/html/2506.05579/extracted/6505936/figures/interface1.png",
                "caption": "Figure 19:Image of user interface during a math problem solving session. The user may not type in an answer or perform any calculations during Phase 1, the collective ideation phase.",
                "position": 2256
            },
            {
                "img": "https://arxiv.org/html/2506.05579/extracted/6505936/figures/interface-blurred.png",
                "caption": "Figure 20:Image of user interface during a math problem solving session. Once the user clicks \"ready to solve\", they may no longer view their chats with the model, isolating knowledge transfer.",
                "position": 2259
            },
            {
                "img": "https://arxiv.org/html/2506.05579/extracted/6505936/figures/interface2.png",
                "caption": "Figure 21:Image of user interface during a coding problem solving session. In place of a singular answer submission area is a code editor interface.",
                "position": 2262
            }
        ]
    },
    {
        "header": "Appendix CStudy Details",
        "images": []
    }
]