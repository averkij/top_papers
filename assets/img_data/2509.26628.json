[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26628/x1.png",
                "caption": "(a)",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x1.png",
                "caption": "(a)",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x2.png",
                "caption": "(b)",
                "position": 230
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26628/x3.png",
                "caption": "Figure 2:The visualization of steps with high FCI scores.",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x4.png",
                "caption": "Figure 3:Disruption results on AIME24 and AIME25. (a) Normalized average accuracy of different disruption types. (b) Average accuracy of different disruption positions.",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x5.png",
                "caption": "Figure 4:Average FCI scores of all problems during the training process of TreeRL on DeepScaleR dataset.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x6.png",
                "caption": "Figure 5:Training pipeline of AttnRL. Our method (left) only needs one-time generation per training iteration, while previous methods (right) require to sample twice and are inefficient.",
                "position": 527
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26628/x7.png",
                "caption": "Figure 6:The sampling statistics of ATB and entropy-based branching. The curves are smoothed using EMA for better visualization.",
                "position": 896
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x8.png",
                "caption": "Figure 7:Curves related to sampling information statistics of all methods. The curves are smoothed using EMA for better visualization.",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2509.26628/x9.png",
                "caption": "Figure 8:The training dynamics curves of all methods. The curves are smoothed using EMA for better visualization.",
                "position": 919
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26628/x10.png",
                "caption": "Figure 9:Test curves of GRPO, TreeRL, and our method on six benchmarks.",
                "position": 1982
            }
        ]
    },
    {
        "header": "Appendix CCases",
        "images": []
    }
]