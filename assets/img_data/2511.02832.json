[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02832/x1.png",
                "caption": "",
                "position": 72
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02832/x2.png",
                "caption": "Figure 2:System overview of TWIST2. We build a holistic humanoid teleoperation system with portable devices and egocentric active vision, enabling scalable imitation data collection. With data collected, we build a hierarchical visuomotor policy learning framework that directly predicts whole-body joint positions.",
                "position": 248
            }
        ]
    },
    {
        "header": "IIIOur System",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02832/figures/neck_design.png",
                "caption": "Figure 3:TWIST2Neck. We design a simple yet effective 2-DoF neck that can be easily assembled for a non-expert user and can be attached/detached to/from a Unitree G1 without removing the original LiDAR.",
                "position": 346
            },
            {
                "img": "https://arxiv.org/html/2511.02832/figures/TWIST2_neck_in_mujoco.png",
                "caption": "Figure 4:TWIST2Neck in MuJoCo. To facilitate the research in simulation and standardize our data, we build MuJoCo XML files for our TWIST2 neck.",
                "position": 349
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x3.png",
                "caption": "Figure 5:Mimic the human neck with the robot neck. We found that a 2 DoFs neck (yaw and pitch) is sufficient to mimic major human neck movements.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x4.png",
                "caption": "Figure 6:Mapping VR human bodies to robot links.",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x5.png",
                "caption": "Figure 7:Hierarchical whole-body visuomotor policy learning framework built upon data collected via TWIST2. Unlike previous works that focus on upper-body manipulation or lower-body locomotion separately, our visuomotor policy controls the entire body, enabling complex tasks such as Kick-T that require coordinated whole-body movements.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2511.02832/figures/pico_view2.jpg",
                "caption": "Figure 8:The view of the teleoperator in PICO. The robot vision is floating in the center.",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x6.png",
                "caption": "Figure 9:Illustrations on using the PICO joystick controller as the control center to make TWIST2a single-operator system.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x7.png",
                "caption": "Figure 10:Long-horizon humanoid teleoperation powered by TWIST2. All tasks are achieved with streamed robot egocentric vision, full whole-body control, and a single operator.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x8.png",
                "caption": "Figure 11:Closed-loop whole-body visuomotor policy execution in the real world. TWIST2enables effective and holistic whole-body humanoid data collection, which further enables versatile autonomous whole-body humanoid loco-manipulation & legged manipulation skills.",
                "position": 549
            }
        ]
    },
    {
        "header": "IVExperiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02832/x9.png",
                "caption": "Figure 12:Comparison of different teleoperation settings.",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2511.02832/x10.png",
                "caption": "Figure 13:Visualization of training demonstrations (egocentric robot view and whole-body joint positions) for WB-Dex and Kick-T tasks.",
                "position": 631
            },
            {
                "img": "https://arxiv.org/html/2511.02832/figures/wbdex_results.png",
                "caption": "Figure 14:All the success and failure cases in our WB-Dex task.",
                "position": 708
            }
        ]
    },
    {
        "header": "VConclusions and Limitations",
        "images": []
    },
    {
        "header": "VIDiscussions on Scaling Up Humanoid Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02832/x11.png",
                "caption": "Figure 15:We have manufactured 3 TWIST2 Necks, indicating that TWIST2 Neck is easy to assemble and can be democratized for research purposes.",
                "position": 747
            }
        ]
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]