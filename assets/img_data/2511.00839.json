[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/x1.png",
                "caption": "Figure 1:CodeClash is a benchmark where players (LMs as SWE-agents) compete in programming tournaments spanning multiple rounds.\nPer round, models edit their codebases (editphase) before the codebases face off in a code arena (competitionphase). Then, the competition logs are copied back into the codebases and the next round begins.",
                "position": 195
            }
        ]
    },
    {
        "header": "2CodeClash",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/x2.png",
                "caption": "",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x3.png",
                "caption": "",
                "position": 425
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/x4.png",
                "caption": "Figure 4:Probability of winning the next round after losing several rounds in a row. Even the highest ranking models struggle to recover after losing one or more consecutive rounds in a tournament. Numbers in parentheses indicate the overall average win rate.",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x4.png",
                "caption": "Figure 4:Probability of winning the next round after losing several rounds in a row. Even the highest ranking models struggle to recover after losing one or more consecutive rounds in a tournament. Numbers in parentheses indicate the overall average win rate.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x5.png",
                "caption": "Figure 5:To measure solution diversity, we compute code similarity of each model’s solutions to itself at the same round.\nEach data point represents the mean pairwise similarity between a model’s solution (main.py) at roundnacross7070BattleSnake tournaments.",
                "position": 498
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x6.png",
                "caption": "Figure 6:The total number of created files scales almost linear with the round.RRrefers to the filename redundancy at round 15; high values indicate repeating patterns in filenames (such asmain1.py,main2.py, …).",
                "position": 543
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x6.png",
                "caption": "Figure 6:The total number of created files scales almost linear with the round.RRrefers to the filename redundancy at round 15; high values indicate repeating patterns in filenames (such asmain1.py,main2.py, …).",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x7.png",
                "caption": "Figure 7:Models differ in the average number ofthrowaway files(files not used after the round in which they were created). The stacked bars distinguish between files at the repository root and those in subdirectories.",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x8.png",
                "caption": "Figure 8:LMs struggle to analyze log files from previous rounds and frequently hallucinate about why rounds were lost.\nUsing LM-as-a-judge, we annotate players’ trajectories with answers to three questions (a) Are changes to solutions grounded in the analysis of previous rounds or testing? (b) Are there hallucinated or unsubstantiated claims about why a round was lost? (c) Are changes validated by arena simulations or unit tests?",
                "position": 585
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Discussion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AInfrastructure",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/figures/tech-overview.png",
                "caption": "Figure 9:Technical overview of a CodeClash round.\nEach round, during theeditphase, LMs edit their respective codebases within Docker containers, usingmini-SWE-agentto facilitate multi-turn editing (Step 1).\nThis is followed by thecompetitionphase, where the codebases are copied the arena docker container (Step 2).\nThe arena then runs codebases against each other, with the game-play and outcomes captured as logs (Step 3).\nThese logs are copied into each player’s codebase before the next round begins (Step 4).",
                "position": 1670
            }
        ]
    },
    {
        "header": "Appendix BArenas",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/battlecode.png",
                "caption": "Figure 10:Battlecode 2025: Chromatic Conflict screen capture.\nThe goal is to control a team of robobunnies to paint7070% of a map.",
                "position": 1976
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/battlecode.png",
                "caption": "Figure 10:Battlecode 2025: Chromatic Conflict screen capture.\nThe goal is to control a team of robobunnies to paint7070% of a map.",
                "position": 1979
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/battlesnake.png",
                "caption": "Figure 12:Battlesnake screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2122
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/battlesnake.png",
                "caption": "Figure 12:Battlesnake screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2125
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/corewar.png",
                "caption": "Figure 14:Core War screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2259
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/corewar.png",
                "caption": "Figure 14:Core War screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2262
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/halite.png",
                "caption": "Figure 16:Halite screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2376
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/halite.png",
                "caption": "Figure 16:Halite screen capture.\nYour code controls a snake that should find food, avoid other snakes, and survive.",
                "position": 2379
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/poker.png",
                "caption": "Figure 18:Poker (Husky Hold ’Em) screen capture.\nPlayers implement bot that aims to earn the most money acrossnrounds.",
                "position": 2512
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/poker.png",
                "caption": "Figure 18:Poker (Husky Hold ’Em) screen capture.\nPlayers implement bot that aims to earn the most money acrossnrounds.",
                "position": 2515
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/robocode.png",
                "caption": "Figure 20:RoboCode screen capture.\nYour code controls a tank that should outmaneuver and outgun opposing tanks.",
                "position": 2669
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/robocode.png",
                "caption": "Figure 20:RoboCode screen capture.\nYour code controls a tank that should outmaneuver and outgun opposing tanks.",
                "position": 2672
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/robotrumble.png",
                "caption": "Figure 22:RobotRumble screen capture.\nYour code controls a tank that should outmaneuver and outgun opposing tanks.",
                "position": 2803
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/arena_card/robotrumble.png",
                "caption": "Figure 22:RobotRumble screen capture.\nYour code controls a tank that should outmaneuver and outgun opposing tanks.",
                "position": 2806
            }
        ]
    },
    {
        "header": "Appendix CEvaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.00839/x9.png",
                "caption": "Figure 24:Distribution of rounds scores by game.",
                "position": 3260
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x10.png",
                "caption": "Figure 25:Distribution of the number of rounds won by the players across arenas. The non-uniform distributions demonstrate that the rounds are not independent of each other.",
                "position": 3263
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x11.png",
                "caption": "Figure 26:Log likelihood profiles for a fit to all arenas results.",
                "position": 3310
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x12.png",
                "caption": "Figure 27:Distribution of Elo scores from non-parametric and parametric bootstrapping",
                "position": 3542
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x13.png",
                "caption": "",
                "position": 3545
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x14.png",
                "caption": "Figure 28:Elo-based ranks from non-parametric and parametric bootstrapping",
                "position": 3549
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x15.png",
                "caption": "",
                "position": 3552
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x16.png",
                "caption": "Figure 29:CDF of files edited per round by each model.\nWhile some models typically never edit more than55files (o3,Gemini 2.5 Pro), others tend to create and manipulate many more (Claude Sonnet 4.5,GPT-5)",
                "position": 3570
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x16.png",
                "caption": "Figure 29:CDF of files edited per round by each model.\nWhile some models typically never edit more than55files (o3,Gemini 2.5 Pro), others tend to create and manipulate many more (Claude Sonnet 4.5,GPT-5)",
                "position": 3573
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x17.png",
                "caption": "Figure 30:Average lines changed per round per model.\nSome models are fairly consistent (Gemini 2.5 Pro), while others vary; Qwen3-Coder edits more in later rounds, while GPT-5 Mini’s edits largely occur earlier on.",
                "position": 3581
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x18.png",
                "caption": "Figure 31:Average lines changed per round per model for theREADME_agent.md, a file we suggest agents write important information to.\nThe Anthropic family of models write copious amounts of notes – other models tend to add more brief summaries.",
                "position": 3590
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x19.png",
                "caption": "Figure 32:Average lines changed per round per model for game-playing related functionality (e.g.warrior.redin Core War).\nModels typically make the majority of their changes early on, with a steady decline in later rounds as changes become more targeted.",
                "position": 3598
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x20.png",
                "caption": "Figure 33:CDF of number of steps taken per round per model.\nThe Anthropic family of models along withQwen3-Coderusually consumes more of the allotted step budget.",
                "position": 3618
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x20.png",
                "caption": "Figure 33:CDF of number of steps taken per round per model.\nThe Anthropic family of models along withQwen3-Coderusually consumes more of the allotted step budget.",
                "position": 3621
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x21.png",
                "caption": "Figure 34:Average steps taken for each round per model.\nThe chart reflects similar conclusions as Figure34, and also suggests that steps used are fairly steady.",
                "position": 3629
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x22.png",
                "caption": "Figure 35:CDF of thought length (in words) per model.\nThe thought lengths are computed per model response.\nOur calculation does not consider the action produced by the model within the same response.",
                "position": 3648
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x22.png",
                "caption": "Figure 35:CDF of thought length (in words) per model.\nThe thought lengths are computed per model response.\nOur calculation does not consider the action produced by the model within the same response.",
                "position": 3651
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x23.png",
                "caption": "Figure 36:Average thought length (in words) per model response at each round.\nWhile most models fall within the range of3535to5555words per response,Gemini 2.5 Proando3are notable outliers.",
                "position": 3660
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x24.png",
                "caption": "Figure 37:A heatmap of errant action rates for models in different arenas.\n“Errant” means the action resulted inreturncode==0.\nWe find that malformed actions doesnotconstitute a significant reason for why models might struggle in CodeClash.",
                "position": 3682
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x24.png",
                "caption": "Figure 37:A heatmap of errant action rates for models in different arenas.\n“Errant” means the action resulted inreturncode==0.\nWe find that malformed actions doesnotconstitute a significant reason for why models might struggle in CodeClash.",
                "position": 3685
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x25.png",
                "caption": "Figure 38:“Recovery time” is the number of steps between a failed command (returncode!=0) and the next successful command (returncode==0).\nEach data point indicates the likelihood that recovery requires more thanxsteps for a model.",
                "position": 3694
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x26.png",
                "caption": "Figure 39:Lead change rate comparison.\nA “lead change” is defined as a roundnwhere the winner is different from the roundn-1winner.\nWe make comparisons between22-player and66-player tournaments specifically for the Core War arena.",
                "position": 3712
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x27.png",
                "caption": "",
                "position": 3721
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x28.png",
                "caption": "Figure 41:Share of rounds which a model inspects its opponent’s codebase.\nWe find variance across models and round ranges.",
                "position": 3754
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x28.png",
                "caption": "Figure 41:Share of rounds which a model inspects its opponent’s codebase.\nWe find variance across models and round ranges.",
                "position": 3757
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x29.png",
                "caption": "Figure 43:Results for the groundedness of edits, hallucinated loss causality, and validation of edits for different arenas (part 1). For the identical plot averaged over all arenas, see Figure8.",
                "position": 3833
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x30.png",
                "caption": "",
                "position": 3837
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x31.png",
                "caption": "Figure 44:Results for the groundedness of edits, hallucinated loss causality, and validation of edits for different arenas (part 2). For the identical plot averaged over all arenas, see Figure8.",
                "position": 3841
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x32.png",
                "caption": "",
                "position": 3845
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x33.png",
                "caption": "",
                "position": 3847
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x34.png",
                "caption": "",
                "position": 3849
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x35.png",
                "caption": "Figure 45:Models perform different kinds of edits on the main player file as the tournament progresses.\nFor this, the full changes to the main player file during a round are summarized into five categories:Featurerepresents significant additions,changea larger change to overall logic,fixare smaller-scale fixes,tweakare minor modification of parameters, andnonemeans that no significant change was made to the player file.\nThe y axis shows the fraction of rounds in which the edits can best be summarized by this category.",
                "position": 3853
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x36.png",
                "caption": "Figure 46:What do models spend their turns on? The mean number of actions a model spends on reading files (read), modifying the main player file (modify main), running unittests, analysis, or arena simulations (unittests,analysis,simulations), or performing any other action. We present separate averages for early tournament (round≤7\\leq 7) and late tournament (round≥8\\geq 8).",
                "position": 3860
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/robotrumble_leaderboard.png",
                "caption": "Figure 47:RobotRumble leaderboard screen capture as of October3131,20252025.\nWe evaluateClaude Sonnet 4.5against the top open-source submissiongigachadbyentropicdrifter",
                "position": 3939
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x37.png",
                "caption": "Figure 48:Code similarity of models’ codebases with respect to each opponent for round11of BattleSnake (1010samples each).",
                "position": 3978
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x37.png",
                "caption": "Figure 48:Code similarity of models’ codebases with respect to each opponent for round11of BattleSnake (1010samples each).",
                "position": 3981
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x38.png",
                "caption": "Figure 49:Code similarity of models’ codebases with respect to each opponent for round11of BattleSnake (1010samples each).",
                "position": 3988
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x39.png",
                "caption": "Figure 50:Scatter plot of file reuse ratio and root level clutter with error bars.\nThe top left quadrant represents most desirable practices (high file reuse, low root level clutter).",
                "position": 3996
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x39.png",
                "caption": "Figure 50:Scatter plot of file reuse ratio and root level clutter with error bars.\nThe top left quadrant represents most desirable practices (high file reuse, low root level clutter).",
                "position": 3999
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x40.png",
                "caption": "Figure 51:Line chart of redundancy rate in filenames across rounds per model.\nModels increasingly create files with similar names as tournaments progress.",
                "position": 4007
            },
            {
                "img": "https://arxiv.org/html/2511.00839/x41.png",
                "caption": "Figure 52:Cumulative probability density function of the number of files created during a tournament. While Claude Sonnet 4.5 consistently creates more files than the other models, GPT-5 reaches a high average number of created files because of an extreme number of output files in the CoreWar arena that are not cleaned up.",
                "position": 4016
            },
            {
                "img": "https://arxiv.org/html/2511.00839/figures/bloated_codebase.png",
                "caption": "Figure 53:Screenshot of the5252files created byClaude 4.5 Sonnetby the1515th round of a BattleSnake tournament.\nSeveral files are created for the purpose of notes, analyses, unit testing, and backups of the main bot.",
                "position": 4037
            }
        ]
    },
    {
        "header": "Appendix DExtended Results",
        "images": []
    }
]