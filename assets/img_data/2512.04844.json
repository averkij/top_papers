[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04844/x1.png",
                "caption": "Figure 1:Overview ofSource-ShieldedUpdate (SSU). The method comprises three stages: importance scoring, column-wise mask generation, and continual pre-training on unlabeled target language data with the masks.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SSU: Selective Parameter Updates via Importance Freezing",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04844/x2.png",
                "caption": "Table 2:Aggregated average performance across all languages per task.Greendenotes scores better than Source with subscripts showing relative changes.Boldandunderlinedindicate best and second-best methods for each model scale.\nTablesC,C,C, andCinclude a full suite of results.",
                "position": 449
            }
        ]
    },
    {
        "header": "5Results",
        "images": []
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04844/x2.png",
                "caption": "Figure 2:Model performance (SSU-Wanda, HFT, GMT) on Igbo as target language across freezing ratios.\nThe dashed red line indicates Source performance (omitted for MT and SUM due to very low scores).\nSome data points for HFT and GMT are also omitted due to extremely low performance.",
                "position": 1142
            },
            {
                "img": "https://arxiv.org/html/2512.04844/x3.png",
                "caption": "Table 4:Performance of different SSU importance scoring methods using Igbo as the target.Boldandunderlineddenote best and second-best adaptation approaches with relative changes in subscripts.",
                "position": 1283
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CSupplementary Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04844/x3.png",
                "caption": "Table 7:Language-specific prompt templates. We generate the templates for each target language using a machine translation API, followingYong etÂ al. (2023).",
                "position": 3731
            }
        ]
    },
    {
        "header": "Appendix DSupplementary Analysis",
        "images": []
    },
    {
        "header": "Appendix EExtended Related Work",
        "images": []
    }
]