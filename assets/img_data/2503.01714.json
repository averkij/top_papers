[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": []
    },
    {
        "header": "4Dataset",
        "images": []
    },
    {
        "header": "5How to Measure the Degree of Semantic Reconstruction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01714/x1.png",
                "caption": "Figure 1:Relationship betweenΔΔ\\Deltaroman_ΔSR and Average NegCorrScore across LLaMA models of different scales. The increasing trend of NegCorrScore withΔΔ\\Deltaroman_ΔSRvalidates SemRecScore as a reliable measure of semantic reconstruction.",
                "position": 335
            }
        ]
    },
    {
        "header": "6How Word Form and Contextual Information Influence LLMs’ Semantic Reconstruction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01714/x2.png",
                "caption": "Figure 2:Semantic reconstruction performance across different Scramble Ratios (SR) and Context Integrity (CI) levels. The top row (a-d) presents SemRecScore trends under varying SR values for 1B, 3B, and 70B models. The bottom row (e-h) illustrates SemRecScore evolution for fixed SR values while varying CI.Across all models, word form plays a dominant role, with context integrity having minimal impact on reconstruction performance.",
                "position": 387
            }
        ]
    },
    {
        "header": "7How LLMs Utilize Word Form Information",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01714/x3.png",
                "caption": "Figure 3:Attention allocation to word form under varying Scramble Ratios (SR).\nSubplots (a-c) show AttentionSelf trends for 1B, 3B, and 70B models with full context (CI=1), while (d) presents the 3B model without context (CI=0). Higher SR values consistently elicit stronger attention to word form, and the cyclic attention pattern remains unchanged even without context,suggesting that LLMs process word form independently of contextual information.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x4.png",
                "caption": "Figure 4:Heatmaps of attention allocation to word form in the LLaMA-1B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers.Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating a structured and stable processing mechanism.",
                "position": 430
            }
        ]
    },
    {
        "header": "8Conclusion and Future Work",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASemantic reconstruction performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01714/x5.png",
                "caption": "Figure 5:Semantic Reconstruction Performance across Different LLM Scales and Context Integrity Levels.\nThe plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various SR values across different LLaMA models (1B, 3B, and 70B). The top row represents CI = 0, while the bottom row represents CI = 0.25. The legend indicates different SR conditions, including the “Completely Scrambled” setting. The similarity of the curves across different CI values suggests that Context Integrity (CI) has minimal impact on semantic reconstruction performance.",
                "position": 809
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x6.png",
                "caption": "Figure 6:Semantic Reconstruction Performance across Different LLM Scales and Context Integrity Levels.\nThe plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various SR values across different LLaMA models (1B, 3B, and 70B). The top row represents CI = 0.25, while the bottom row represents CI = 0.75. The legend indicates different SR conditions, including the “Completely Scrambled” setting. The similarity of the curves across different CI values suggests that Context Integrity (CI) has minimal impact on semantic reconstruction performance.",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x7.png",
                "caption": "Figure 7:Semantic Reconstruction Performance across Different LLM Scales and Scramble Ratio Levels.\nThe plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various CI values across different LLaMA models (1B, 3B, and 70B). The top row represents SR = 0, while the bottom row represents CI = 0.5. The legend indicates different CI conditions.The close alignment of curves across different CI values suggests that Context Integrity has a limited impact on semantic reconstruction.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x8.png",
                "caption": "Figure 8:Semantic Reconstruction Performance across Different LLM Scales and Scramble Ratio Levels.\nThe plots illustrate the layer-wise Semantic Reconstruction Score (SemRecScore) for various CI values across different LLaMA models (1B, 3B, and 70B). The top row represents SR = 0.75, while the bottom row represents CI = 1. The legend indicates different CI conditions.The close alignment of curves across different CI values suggests that Context Integrity has a limited impact on semantic reconstruction. In the rows with higher SR, all curves are noticeably lower, confirming that Word Form plays a crucial role in semantic reconstruction.",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x9.png",
                "caption": "Figure 9:Heatmaps of attention allocation to word form in the LLaMA-3.2-3B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers.Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating a structured and stable processing mechanism.",
                "position": 843
            },
            {
                "img": "https://arxiv.org/html/2503.01714/x10.png",
                "caption": "Figure 10:Heatmaps of attention allocation to word form in the LLaMA-3.3-70B-Instruct across Scramble Ratios (SR). The x-axis denotes attention heads, and the y-axis denotes layers.Specific heads consistently focus on word form, with higher SR activating more form-sensitive heads, indicating a structured and stable processing mechanism.",
                "position": 846
            }
        ]
    },
    {
        "header": "Appendix BHeatmap of attention allocaton",
        "images": []
    }
]