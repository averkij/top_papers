[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04460/images/fig1.jpg",
                "caption": "Figure 1:The three paradigms of vision-centric reasoning.",
                "position": 154
            },
            {
                "img": "https://arxiv.org/html/2511.04460/x1.png",
                "caption": "Figure 2:Representative examples of V-Thinker‚Äôs knowledge-driven synthesis spanning diverse reasoning domains.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04460/x2.png",
                "caption": "Figure 3:The rendering process from code to image.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2511.04460/images/fig4.png",
                "caption": "Figure 4:The Data Evolution Flywheel framework:Left:knowledge-driven evolution mechanism.Middle:coordinated calibration and progressive expansion stages.Right:representative synthetic QA instances generated through the flywheel.",
                "position": 297
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04460/x3.png",
                "caption": "Figure 5:A representative sample from the synthesized dataset V-Interaction-400K (ùíü\\mathcal{D}).",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2511.04460/x4.png",
                "caption": "Figure 6:The overview of the perception data synthesis.",
                "position": 582
            },
            {
                "img": "https://arxiv.org/html/2511.04460/x5.png",
                "caption": "Figure 7:The construction guideline of our VTBench.",
                "position": 655
            }
        ]
    },
    {
        "header": "5VTBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04460/x6.png",
                "caption": "Figure 8:Qualitative analysis of V-Thinker-7B on vision-centric interactive reasoning tasks.",
                "position": 952
            },
            {
                "img": "https://arxiv.org/html/2511.04460/images/fig9.png",
                "caption": "Figure 9:Visualization of a series of samples in rollout sampling.",
                "position": 957
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04460/images/fig10.jpg",
                "caption": "Figure 10:Visualization of the evolved knowledge system through the Data Evolution Flywheel.",
                "position": 1021
            },
            {
                "img": "https://arxiv.org/html/2511.04460/x7.png",
                "caption": "Figure 11:Scaling analysis of the iterations in the Data Evolution Flywheel.",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2511.04460/x8.png",
                "caption": "Figure 12:Complete interactive reasoning samples of V-Thinker on open-source benchmarks.",
                "position": 1090
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]