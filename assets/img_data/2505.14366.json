[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14366/x1.png",
                "caption": "Figure 1.Synthetic environment and dataset elements. A minimal 3D scene is procedurally generated with a non-uniform scaled cube and overhead camera. Each instance yields an RGB image, a language prompt, and a 4Ã—4 transformation matrix(TOâ¢Bâ¢JCâ¢Aâ¢M)superscriptsubscriptğ‘‡ğ‘‚ğµğ½ğ¶ğ´ğ‘€\\left({}^{CAM}T_{OBJ}\\right)( start_FLOATSUPERSCRIPT italic_C italic_A italic_M end_FLOATSUPERSCRIPT italic_T start_POSTSUBSCRIPT italic_O italic_B italic_J end_POSTSUBSCRIPT )representing object reference frame pose(Râ¢FOâ¢Bâ¢J)ğ‘…subscriptğ¹ğ‘‚ğµğ½\\left(RF_{OBJ}\\right)( italic_R italic_F start_POSTSUBSCRIPT italic_O italic_B italic_J end_POSTSUBSCRIPT )with respect to the camera reference frame(Râ¢FCâ¢Aâ¢M)ğ‘…subscriptğ¹ğ¶ğ´ğ‘€\\left(RF_{CAM}\\right)( italic_R italic_F start_POSTSUBSCRIPT italic_C italic_A italic_M end_POSTSUBSCRIPT ), enabling structured spatial representations for supervised learning in embodied AI.",
                "position": 29
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Method",
        "images": []
    },
    {
        "header": "Dataset Availability",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]