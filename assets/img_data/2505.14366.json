[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14366/x1.png",
                "caption": "Figure 1.Synthetic environment and dataset elements. A minimal 3D scene is procedurally generated with a non-uniform scaled cube and overhead camera. Each instance yields an RGB image, a language prompt, and a 4×4 transformation matrix(TO⁢B⁢JC⁢A⁢M)superscriptsubscript𝑇𝑂𝐵𝐽𝐶𝐴𝑀\\left({}^{CAM}T_{OBJ}\\right)( start_FLOATSUPERSCRIPT italic_C italic_A italic_M end_FLOATSUPERSCRIPT italic_T start_POSTSUBSCRIPT italic_O italic_B italic_J end_POSTSUBSCRIPT )representing object reference frame pose(R⁢FO⁢B⁢J)𝑅subscript𝐹𝑂𝐵𝐽\\left(RF_{OBJ}\\right)( italic_R italic_F start_POSTSUBSCRIPT italic_O italic_B italic_J end_POSTSUBSCRIPT )with respect to the camera reference frame(R⁢FC⁢A⁢M)𝑅subscript𝐹𝐶𝐴𝑀\\left(RF_{CAM}\\right)( italic_R italic_F start_POSTSUBSCRIPT italic_C italic_A italic_M end_POSTSUBSCRIPT ), enabling structured spatial representations for supervised learning in embodied AI.",
                "position": 29
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Method",
        "images": []
    },
    {
        "header": "Dataset Availability",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]