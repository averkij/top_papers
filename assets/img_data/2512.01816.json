[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/figs/icon/github.png",
                "caption": "",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/icon/hf.png",
                "caption": "",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/icon/global.png",
                "caption": "",
                "position": 165
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/x1.png",
                "caption": "Figure 1:Envision Vision: (1) Semantic Anchoring, (2) Spatial Deconstruction, (3) Temporal Weaving, and (4) World Simulation. Progressive stages of cognitive development in generative models.",
                "position": 176
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x1.png",
                "caption": "Figure 1:Envision Vision: (1) Semantic Anchoring, (2) Spatial Deconstruction, (3) Temporal Weaving, and (4) World Simulation. Progressive stages of cognitive development in generative models.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Why the Multiple-Image Sequence?",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/x2.png",
                "caption": "Figure 2:Overview of Envision’s Multi-Image Framework.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x3.png",
                "caption": "Figure 3:Spanning six disciplines, representative cases showcase the causal structure of processes as discrete (dashed) or continuous (solid) spatial relations over time.",
                "position": 306
            }
        ]
    },
    {
        "header": "3Envision",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/x4.png",
                "caption": "Figure 4:Overview of the Event Process in generating and evaluating multi-image sequences for Envision. The process involves constructing a Dataset Suite using multi-domain knowledge sources (Science, Culture & History) and structured prompt generation. This feeds into an Image Generation process via a Text-to-Image model, followed by an Evaluation Suite which includes both Physicality, consistency, and aesthetics, and VLM as Judge and Metric Analysis using specific scoring criteria (0-5).",
                "position": 316
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x5.png",
                "caption": "Figure 5:Overview of the Envision Data Domain & Evaluation Dimension.",
                "position": 325
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/x6.png",
                "caption": "Figure 6:Comparison of Model Performance on Key Evaluation Dimensions, shows the average scores of UMMs (Red), Open-Source T2I Models (Blue) and Closed-Source T2I Models (Yellow) across metrics.",
                "position": 1123
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x7.png",
                "caption": "Figure 7:Visualization of Causal Event Progression and Failure Analysis. This figure compares the multi-step generative outputs of various generative model, including Flux-Kontext-max (Open-Source T2I Model), GPT-4o (Closed-Source T2I Model), Qwen-Image (UMM) and Bagel (UMM), across two distinct causal scenarios.",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7More Details about Envision",
        "images": []
    },
    {
        "header": "8Definition of Categories in Envision",
        "images": []
    },
    {
        "header": "9Prompt Structure",
        "images": []
    },
    {
        "header": "10Quadripartite Event Frame Structure",
        "images": []
    },
    {
        "header": "11Scoring Criteria of Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01816/x8.png",
                "caption": "(a)A four-stage visual narrative of a whale fall event in the deep ocean.",
                "position": 1861
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x8.png",
                "caption": "(a)A four-stage visual narrative of a whale fall event in the deep ocean.",
                "position": 1864
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x9.png",
                "caption": "(b)A four-stage historical narrative showing the evolution of Apple Computer’s founding in a 1970s garage.",
                "position": 1870
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_artistic_quality.png",
                "caption": "(a)AQ",
                "position": 1877
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_artistic_quality.png",
                "caption": "(a)AQ",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_authenticity.png",
                "caption": "(b)Auth",
                "position": 1885
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_expressiveness.png",
                "caption": "(c)Exp",
                "position": 1890
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_aesthetic_score.png",
                "caption": "(d)AS",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_semantic_consistency.png",
                "caption": "(e)SC",
                "position": 1901
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_spatial_temporal_consistency.png",
                "caption": "(f)STC",
                "position": 1906
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_factual_consistency.png",
                "caption": "(g)FC",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_consistency_score.png",
                "caption": "(h)CS",
                "position": 1916
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_basic_properties.png",
                "caption": "(i)BP",
                "position": 1922
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_dynamics_interactivity.png",
                "caption": "(j)DI",
                "position": 1927
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_physical_reliability.png",
                "caption": "(k)PR",
                "position": 1932
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_physicality_score.png",
                "caption": "(l)PS",
                "position": 1937
            },
            {
                "img": "https://arxiv.org/html/2512.01816/figs/subfigs/model_performance_overall_score.png",
                "caption": "(m)Overall",
                "position": 1943
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x10.png",
                "caption": "Figure 10:Scoring Criteria for theConsistencydimension, evaluating the spatiotemporal, semantic, and factual consistency of generated multi-image sequences. Each is scored on a 0–5 scale, where 0 indicates catastrophic failure and 5 represents flawless execution.",
                "position": 3774
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x11.png",
                "caption": "Figure 11:Scoring Criteria for thePhysicalitydimension, assessing the model’s adherence to physical laws and plausibility of dynamic processes. Scores range from 0 (failure) to 5 (excellent).",
                "position": 3777
            },
            {
                "img": "https://arxiv.org/html/2512.01816/x12.png",
                "caption": "Figure 12:Scoring Criteria for theAestheticsdimension, capturing the visual quality and narrative expressiveness of generated sequences. Scores range from 0 (failure) to 5 (excellent).",
                "position": 3780
            }
        ]
    },
    {
        "header": "12VLM Score Reliability Validation",
        "images": []
    }
]