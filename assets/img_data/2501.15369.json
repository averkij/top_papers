[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.15369/x1.png",
                "caption": "Figure 1:Comparison of latency and accuracy between our iFormer and other existing methods on ImageNet-1k.The latency is measured on an iPhone 13. Our iFormer is Pareto-optimal.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.15369/x2.png",
                "caption": "Figure 2:Illustration of the evolution from the ConvNeXt baseline towards the lightweight iFormer.The orange bars are model accuracies and the light blue bars are model latencies. We also include a red latency outline for better visualization.",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2501.15369/x3.png",
                "caption": "",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2501.15369/x4.png",
                "caption": "Figure 4:Overview of iFormer architecture, detailed convolutional stem, block design, and SHMA.The hatched area in SHMA indicates extra memory-intensive reshaping operations that are eliminated by SHMA.S‚Å¢(‚ãÖ)ùëÜ‚ãÖS(\\cdot)italic_S ( ‚ãÖ )denotes the softmax function.RùëÖRitalic_Ris the ratio for reducing channels of query and key. It is set to 2 in iFormer. We omit BN following project or convolution for simplicity.",
                "position": 258
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Ablation Studies",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "Appendix BExperimental Settings",
        "images": []
    },
    {
        "header": "Appendix CMore Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.15369/x5.png",
                "caption": "Figure 5:Comparison of SHMA and SHA in SHViT.In SHViT,r‚Å¢Cùëüùê∂rCitalic_r italic_Cchannels are utilized for spatial attention, whererùëüritalic_ris set to14.6714.67\\frac{1}{4.67}divide start_ARG 1 end_ARG start_ARG 4.67 end_ARG. SHMA projects the input into a higher dimension of1212\\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARGC (i.e., R=2) and avoids split and concatenation operations.",
                "position": 2881
            }
        ]
    },
    {
        "header": "Appendix DRelation to SHViT",
        "images": []
    },
    {
        "header": "Appendix EArchitecture Details",
        "images": []
    },
    {
        "header": "Appendix FiFormer for Higher Resolution",
        "images": []
    },
    {
        "header": "Appendix GComprehensive Comparison",
        "images": []
    }
]