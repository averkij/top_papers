[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22323/x1.png",
                "caption": "",
                "position": 116
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22323/x2.png",
                "caption": "Figure 2:Reconstruction results at different timesteps.(Totalsteps T=50, seed=42, prompt = “Add a scarf to the dog.”) Each reconstructionx0^\\hat{x_{0}}is estimated following the rectified flow formulation:X0^=xt−t​vθ​(xt,c,t)\\hat{X_{0}}=x_{t}-t\\,v_{\\theta}(x_{t},c,t). It can be observed that some regions become sharp and visually consistent with the original image even at very early stages, while other regions continue to evolve until the final timestep.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22323/x3.png",
                "caption": "Figure 3:Overview of SpotEdit.The process consists of three stages:\n(1)Initial Steps: the model performs standard DiT denoising on all image tokens under the editing instruction, while caching the KV values for Spotfusion.\n(2)Spot Steps: SpotSelectordynamicallyidentifies regenerated region and non-edited region tokens using LPIPS-like perceptual scores. Non-edited region tokens are skipped by DiT computation, while regenerated region tokens are generated iteratively with SpotFusion, which builds a temporally consistent condition cache by fusing cached non-edited region KV values with condition image KV values.\n(3)Token Replacement: Regenerated tokens are updated through DiT, and non-edited tokens are directly covered by the corresponding reused tokens before decoding into an image, ensuring background fidelity with reduced computation.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2512.22323/x4.png",
                "caption": "Figure 4:PCA trajectories of hidden states of non-edited tokens across dual stream layers and single stream layers.\nAs denoising progresses, the trajectory of the generated image in the non-edited region (xx) gradually approaches that of the condition image (yy),\nindicating that their latent representations progressively align.\nEventually, both trajectories overlap, suggesting that unedited regions converge to the same latent subspace,\nthereby maintaining strong background consistency and semantic preservation.",
                "position": 381
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22323/x5.png",
                "caption": "Figure 5:Non-edited preservation comparison across different models. Prior methods either modify unnecessary background regions or distort color consistency, whereas our method preserves non-edited areas faithfully while applying accurate edits.",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2512.22323/x6.png",
                "caption": "Figure 6:The qualitative ablation study on token fusion",
                "position": 844
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix APseudocode of SpotEdit",
        "images": []
    },
    {
        "header": "Appendix BCompatibility with Existing Acceleration Methods",
        "images": []
    },
    {
        "header": "Appendix CDiscussion betweenℓ2\\ell_{2}-distance and LPIPS-like score",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22323/x7.png",
                "caption": "Figure S1:ℓ2\\ell_{2}Distance vs. LPIPS-like Score.Low-frequency changes (e.g., brightness) produce overly largeℓ2\\ell_{2}responses, while subtle high-frequency texture edits barely affect it.\nAs shown in the first sample,ℓ2\\ell_{2}incorrectly preserves the spaceship that should have been removed; in the second sample, it misclassifies background tokens as regenerate tokens, causing unnecessary regeneration and background degradation.\nLPIPS-like features avoid these failures by operating in a perceptually aligned feature space.",
                "position": 1628
            },
            {
                "img": "https://arxiv.org/html/2512.22323/x8.png",
                "caption": "Figure S2:More results of SpotEdit with various editing tasks",
                "position": 1663
            }
        ]
    },
    {
        "header": "Appendix DMore Visualization Results",
        "images": []
    }
]