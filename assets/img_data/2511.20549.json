[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20549/figures/banner.png",
                "caption": "",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/overview.jpg",
                "caption": "Figure 2:Overview of our proposed Flash-DMD.\nWe decouple the distillation objective by timestep into a Diffusion Matching loss and an adversarial loss. During high-noise timesteps, the DMD loss enables rapid alignment with the teacher model, while at low-noise timesteps and on real images, Pixel-GAN loss is employed to enhance realism and texture details. This design achieves a more efficient distillation. Building upon this, we further introduce a reinforcement strategy specifically tailored for few-step distilled models, which seamlessly integrates with the distillation objective to achieve superior and more stable performance.",
                "position": 138
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20549/figures/sample_test.png",
                "caption": "Figure 3:Sampling variance analysis at different time steps. The first row displays samples obtained at the 999th denoising step, while the second row corresponds to the 499th step.",
                "position": 405
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20549/figures/compare_rl.png",
                "caption": "Figure 4:Qualitative comparisons with other reinforcement approaches on SDXL.\ncom",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/ttur2_cmp.png",
                "caption": "Figure 5:Evaluation results of DMD2(red) and Flash-DMD (blue) with TTUR at the ratio of 2 on SDXL.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/ema_cmp.png",
                "caption": "Figure 6:Evaluation results of Flash-DMD (ours) with or without EMA on ImageReward, PickScore, and HPSv2. The training steps range from 1,000 to 8,000. Both models are trained with a two-time scale update rule (TTUR). The generator and the score estimator are updated at a rate of 1:2, i.e., TTUR=2.",
                "position": 833
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/rl_cmp.png",
                "caption": "Figure 7:Evaluation results of Reinforcement Learning with and without pixel-GAN. Both models use 5:1 setting.",
                "position": 844
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20549/figures/multiple_model3.jpg",
                "caption": "Figure 8:Qualitative comparisons with other models.",
                "position": 982
            }
        ]
    },
    {
        "header": "6Latent Reward Model: Selection Rationale",
        "images": []
    },
    {
        "header": "7Algorithm of Flash-DMD",
        "images": []
    },
    {
        "header": "84-steps and 8-steps Flash-DMD on SDXL",
        "images": []
    },
    {
        "header": "94-step Flash-DMD on SD3-Medium",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20549/visuals/ttur1-1k.jpg",
                "caption": "Figure 9:Qualitative results from Stage 1 of the 4-step Flash-DMD framework on SDXL. The model is trained with TTUR = 1 for 1,000 steps.",
                "position": 1448
            },
            {
                "img": "https://arxiv.org/html/2511.20549/visuals/ttur2-4k.jpg",
                "caption": "Figure 10:Qualitative results from Stage 1 of the 4-step Flash-DMD framework on SDXL. The model is trained with TTUR = 2 for 4,000 steps.",
                "position": 1451
            },
            {
                "img": "https://arxiv.org/html/2511.20549/visuals/lpo-4step.jpg",
                "caption": "Figure 11:Qualitative results from Stage 2 of the 4-step Flash-DMD framework on SDXL. The model is initialized from the TTUR1-1k checkpoint and fine-tuned for 5,000 steps.",
                "position": 1454
            },
            {
                "img": "https://arxiv.org/html/2511.20549/visuals/sdxl-8step-3k.jpg",
                "caption": "Figure 12:Qualitative results from Stage 1 of the 8-step Flash-DMD framework on SDXL. The model is trained with TTUR = 2 for 3,000 steps.",
                "position": 1457
            },
            {
                "img": "https://arxiv.org/html/2511.20549/visuals/lpo-8steps-3k.jpg",
                "caption": "Figure 13:Qualitative results from Stage 2 of the 8-step Flash-DMD framework on SDXL. The model is initialized from the 8-step TTUR2-3k checkpoint and fine-tuned for 3,000 steps.",
                "position": 1460
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/sd3-4-p1.png",
                "caption": "Figure 14:Qualitative results from stage 1 of the 4-step Flash-DMD framework on SD3-Medium. The model is trained with TTUR=2 for 7.000 steps.",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2511.20549/figures/sd3-4-p2.png",
                "caption": "",
                "position": 1467
            }
        ]
    },
    {
        "header": "10Additional Visualizations and Captions",
        "images": []
    }
]