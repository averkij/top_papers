[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04668/x1.png",
                "caption": "Figure 1:SIMS-Venables learning real-world spatial concepts in simulation.We generate spatially-rich videos with dense spatial annotations via privileged simulator data, creating diverse question-answer pairs.\nModels trained on this simulated data transfer effectively to real-world spatial reasoning benchmarks.",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Simulated Spatial Instruction-Tuning",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04668/x2.png",
                "caption": "Figure 2:TheSIMS-Vpipeline generates diverse spatial training data with perfect ground truth.We procedurally generate 3D scenes using AI2-THOR[30], ProcTHOR[17], and Objaverse[16], capture agent navigation trajectories, extract dense annotations (global spatial layout and per-frame observations), and programmatically generate quality-controlled question-answer pairs spanning diverse spatial reasoning categories.\nThis systematic pipeline enables controlled ablations of question types and data configurations, maintaining perfect spatial ground truth.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2511.04668/x3.png",
                "caption": "Figure 3:Examples of different question types used in our experiments. Each question is shown alongside its corresponding visual context from a simulated environment. The questions span diverse spatial reasoning capabilities including numerical measurement, relative positioning, and temporal tracking. Full details of all question formats are provided inSection˜B.2.",
                "position": 279
            }
        ]
    },
    {
        "header": "3Investigating Simulated Data Properties",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04668/x4.png",
                "caption": "Figure 4:Training on individual question types yields large on-task gains with localized cross-task effects.We fine-tune LLaVA-Video-7B on 5k simulated questions of each question type and format (rows), evaluating each model on all VSI-Bench question types (columns).\nValues are performanceΔ\\Deltavs. the pretrained baseline (positive is green, negative is red).",
                "position": 289
            },
            {
                "img": "https://arxiv.org/html/2511.04668/x5.png",
                "caption": "Figure 5:Minimal 3Q mix is more data-efficient than comprehensive coverage.Left:Both training mixes show rapid improvement on VSI-Bench,\nwith 3Q consistently outperforming the full baseline mix despite using\nonly three question types. At 5K examples, we surpass Gemini-1.5 Flash;\nat 25K, we approach Gemini-1.5 Pro.Right:Distribution of question types in VSI-Baseline mix,\nwhich mirrors the VSI-Bench test set composition.",
                "position": 368
            }
        ]
    },
    {
        "header": "4Sim-to-Real Evaluation on Real-World Benchmarks",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BSIMS-VSIDataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04668/x6.png",
                "caption": "Figure 6:Question type transfer patterns remain consistent on VSI-Bench-Debiased.Similar toFig.˜4, appearance order and absolute distance show strong cross-task transfer on the debiased benchmark, confirming that observed patterns reflect genuine spatial learning rather than exploitation of statistical shortcuts.",
                "position": 2824
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results and Analysis",
        "images": []
    }
]