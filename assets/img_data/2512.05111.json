[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05111/x1.png",
                "caption": "Figure 1:Overview of ARM-Thinker.(a) Case Comparison:Given a complex document QA task, ARM-Thinker correctly identifies the answer by autonomously invoking the retrieval tool, while the baseline model provides an incorrect response.(b) ARMBench-VL:It evaluates reward models across three task types, each requiring specialized tool use (image manipulation, document retrieval, instruction verification).(c) Performance of ARM-Thinker:The agentic capability enables substantial gains across multiple benchmarks.",
                "position": 113
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3ARM-Thinker",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05111/fig/method_v2.png",
                "caption": "Figure 2:Overview of ARM-Thinkerâ€™s architecture and training pipeline.(a) Agent Loop: ARM-Thinker follows a think-act-observe paradigm, maintaining indexed context for texts and images while iteratively invoking tools from the toolkit (image zoom-in, document retrieval, instruction validators) until producing the final answer.(b) Pipeline: our pipeline starting with (1) SFT & Cold Start using difficulty-filtered data, followed by (2) two-stage Group Relative Policy Optimizationgrpo(GRPO) that first encourages correct tool calls (Stage 1) and then refines for accuracy with verifiable rewards that balance correctness and tool efficiency (Stage 2).",
                "position": 192
            }
        ]
    },
    {
        "header": "4ARMBench-VL",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05111/x2.png",
                "caption": "Figure 3:Representative examples from ARMBench-VL.\nEach block shows the multimodal context, candidate responses, and available tools for one of the three tracks in ARMBench-VL:Fine-grained Perception(image crop/zoom tools for local visual details),Multimodal Long Document QA(page-retrieval tools), andMultimodal Instruction Following(instruction-checking tools).",
                "position": 452
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05111/x3.png",
                "caption": "Figure 4:Ablation study comparing three reward function designs during GRPO training.Left:Evaluation accuracy over training steps.Right:Average tool-call frequency over training steps.\nOur ARM-Thinker reward (blue) achieves the highest accuracy while maintaining stable tool usage, avoiding both the under-use pitfall of accuracy-only rewards (orange) and the over-use pitfall of fixed tool rewards (green).",
                "position": 1103
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Supplementary Material",
        "images": []
    },
    {
        "header": "Outline",
        "images": []
    },
    {
        "header": "Appendix AModel, Dataset and Benchmark Statistic",
        "images": []
    },
    {
        "header": "Appendix BARMBench-VL Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05111/fig/appx_cases_1.png",
                "caption": "Figure 10:Case of Multimodal Instruction Following Judgment Task in ARMBench-VL.",
                "position": 1328
            },
            {
                "img": "https://arxiv.org/html/2512.05111/fig/appx_cases_2.png",
                "caption": "Figure 11:Case of Fine-Grained\nImage Perception Judgment Task in ARMBench-VL.",
                "position": 1334
            }
        ]
    },
    {
        "header": "Appendix CQualitative Case Study",
        "images": []
    },
    {
        "header": "Appendix DBroader Impact and Future Directions",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details of Multimodal Tools",
        "images": []
    },
    {
        "header": "Appendix FPrompts",
        "images": []
    }
]