[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/x1.png",
                "caption": "Figure 1:SVG2 accelerates video generation while maintaining high quality. On a single H100, for HunyuanVideo and Wan 2.1, SVG2 achieves up to 2.30 and 1.89 end-to-end speedup, with a PSNR up to 30 and 26.",
                "position": 83
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/x2.png",
                "caption": "Figure 2:Trade-off curves between generation quality (PSNR) and efficiency (density). SVG2 consistently surpasses existing methods given the same density, achieving a Pareto frontier.",
                "position": 89
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/x3.png",
                "caption": "Figure 3:Comparison of attention recall versus density (i.e., number of sparse computation normalized by total computation) for the oracle policy, SVG, and SpargeAttention. Notably, the significant gap between the oracle policy and existing methods highlights the potential for improvement.",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2505.18875/x4.png",
                "caption": "Figure 4:Illustration of how existing methods fall short due to theinaccurate identificationandcomputation waste, assuming a computation unit of4×4444\\times 44 × 4block. (a) Original attention map of a demonstration example. (b) Position-based clustering groups distinct tokens within the same clustering, causing the imprecise representation of mean-pooling or max-pooling. Therefore, blocks with smaller number of critical tokens are ignored, causing lower recall of attention scores. (c) Due to the scattered layout of critical tokens, even if achieving a high attention recall, each compute block processes both critical and non-critical tokens, thus causing computation waste and decreasingeffective computeon critical tokens. (d) Semantic-aware permutation clusters and reorders similar tokens into contiguous layout, thus achieving high attention recall while minimizing computation waste.",
                "position": 192
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/x5.png",
                "caption": "Figure 5:Overview of SVG2. (a) Original attention map of a demonstration example, with various colors representing various semantics. Only tokens with similar semantic attend to each other, having a high attention scores thus selected as critical tokens. (b) Afterk-means clustering, semantic-similar tokens (i.e., similar colors) are grouped into the same cluster, with the query and key centroids to precisely represent the cluster-level semantic. These centroids are then used to approximate the attention score for accurate identification of critical tokens. (c) Combined with Top-pselection, critical tokens can be dynamically identified in a contiguous layout.",
                "position": 228
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/x6.png",
                "caption": "Figure 6:Visualization of attention maps from different attention heads in Wan2.1 when generating videos from VBenchhuang2023vbenchcomprehensivebenchmarksuite. (a) Original attention maps with diverse sparse patterns, assuming critical tokens highlighted in red. (b) Permuted attention maps. After semantic-aware permutation, critical tokens are permuted into a contiguous layout based on thek-means clustering, enabling efficient block-wise computation without waste. (c) Recovered attention maps after applying centroid-based top-pselection and undoing the permutation. The high similarity between the original and recovered attention maps demonstrates the effectiveness of SVG2.",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2505.18875/x7.png",
                "caption": "Figure 7:Efficiency evaluation for fastk-means with centroids cache and customized attention kernel.",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2505.18875/x8.png",
                "caption": "Figure 8:Attention recall across various densities. Enabling permutation consistently surpasses disabling permutation.",
                "position": 601
            }
        ]
    },
    {
        "header": "6Conclusion & Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/dense/concatenated_001.png",
                "caption": "Figure 9:Comparion of Dense Attention and SVG2 on HunyuanVideo and Wan 2.1 Text-to-Video generation.",
                "position": 993
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/SVG_2/concatenated_001.png",
                "caption": "",
                "position": 1011
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/dense/concatenated_002.png",
                "caption": "",
                "position": 1021
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/SVG_2/concatenated_002.png",
                "caption": "",
                "position": 1031
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/dense/concatenated_003.png",
                "caption": "",
                "position": 1041
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-hunyuan/SVG_2/concatenated_003.png",
                "caption": "",
                "position": 1051
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/dense/concatenated_001.png",
                "caption": "",
                "position": 1061
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/SVG_2/concatenated_001.png",
                "caption": "",
                "position": 1071
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/dense/concatenated_002.png",
                "caption": "",
                "position": 1081
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/SVG_2/concatenated_002.png",
                "caption": "",
                "position": 1091
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/dense/concatenated_003.png",
                "caption": "",
                "position": 1101
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/SVG_2/concatenated_003.png",
                "caption": "",
                "position": 1111
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/dense/concatenated_004.png",
                "caption": "",
                "position": 1121
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan-I2V/SVG_2/concatenated_004.png",
                "caption": "",
                "position": 1131
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_003.png",
                "caption": "Figure 10:Comparison of Dense Attention and SVG2 on Wan 2.1 Image-to-Video generation.",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_003.png",
                "caption": "",
                "position": 1148
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_004.png",
                "caption": "",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_004.png",
                "caption": "",
                "position": 1161
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_005.png",
                "caption": "",
                "position": 1168
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_005.png",
                "caption": "",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_006.png",
                "caption": "",
                "position": 1181
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_006.png",
                "caption": "",
                "position": 1187
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_007.png",
                "caption": "",
                "position": 1194
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_007.png",
                "caption": "",
                "position": 1200
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_008.png",
                "caption": "",
                "position": 1207
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_008.png",
                "caption": "",
                "position": 1213
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_001.png",
                "caption": "",
                "position": 1223
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_001.png",
                "caption": "",
                "position": 1233
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/dense/concatenated_002.png",
                "caption": "",
                "position": 1244
            },
            {
                "img": "https://arxiv.org/html/2505.18875/extracted/6473290/figures/Visualization/Concat-wan/SVG_2/concatenated_002.png",
                "caption": "",
                "position": 1254
            }
        ]
    },
    {
        "header": "Appendix AVisualization of the generated videos",
        "images": []
    }
]