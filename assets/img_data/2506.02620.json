[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x1.png",
                "caption": "",
                "position": 132
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x2.png",
                "caption": "Figure 2:Example of modality aggregation and semantic manipulation by controlling the image embedding strengthŒ±ùõº\\alphaitalic_Œ±.\nEach case‚Äôs first and second rows show text-to-image and image-to-image interpolation, respectively.",
                "position": 305
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x3.png",
                "caption": "Figure 3:Pipeline of our method.\nWe first generate multi-view images using the conditional input from the user.\nThe top two cases show the generation of using text-only or image-only conditions.\nLeveraging the linear operation in Equ.(4), we can also perform text-guided image refinement (shown in green) and stylization using reference image (shown in blue).\nThe right side shows our view-synchronization and weighting module.\nConsistent multi-view images can be generated by reprojection and weighting during each sampling step.",
                "position": 311
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x4.png",
                "caption": "Figure 4:Qualitative results on text-to-texture generation.",
                "position": 527
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x5.png",
                "caption": "Figure 5:Qualitative results on image-to-texture generation.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x6.png",
                "caption": "Figure 6:Our Applications includes tasks of text-to-texture, image-to-texture, text-guided image refinement, and reference image-based stylization.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x7.png",
                "caption": "Figure 7:Qualitative results of our ablation study.\nOur full model achieves consistent and high-quality generation results, while the ablated methods suffer from ghosting artifacts and degraded quality.",
                "position": 666
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x8.png",
                "caption": "Figure 8:More cases of our text-to-texture generation.",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x9.png",
                "caption": "Figure 9:More cases of our imgae-to-texture generation.",
                "position": 1686
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x10.png",
                "caption": "Figure 10:More cases of our applications.",
                "position": 1691
            }
        ]
    },
    {
        "header": "Appendix AAdditional Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x11.png",
                "caption": "Figure S1:Detailed pipeline of the texture completion and enhancement module.\nWe use a 3D-aware texture completion module containing UV blocks and point blocks to complete the partial texture.\nThen, we use a texture enhancement module to generate the super-resolution results.",
                "position": 1779
            }
        ]
    },
    {
        "header": "Appendix BMore Qualitative Results",
        "images": []
    },
    {
        "header": "Appendix CDetails of our user study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02620/x12.png",
                "caption": "Figure S2:More cases of our text-to-texture generation.",
                "position": 1828
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x13.png",
                "caption": "Figure S3:More cases of our image-to-texture generation.",
                "position": 1833
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x14.png",
                "caption": "Figure S4:More cases of our applications.",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x15.png",
                "caption": "Figure S5:More cases of our applications.",
                "position": 1843
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x16.png",
                "caption": "Figure S6:More cases of our applications.",
                "position": 1848
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x17.png",
                "caption": "Figure S7:Our user study interface.",
                "position": 1853
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x18.png",
                "caption": "Figure S8:Our user study interface.",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x19.png",
                "caption": "Figure S9:Our user study interface.",
                "position": 1863
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x20.png",
                "caption": "Figure S10:Our user study interface.",
                "position": 1868
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x21.png",
                "caption": "Figure S11:Our user study interface.",
                "position": 1873
            },
            {
                "img": "https://arxiv.org/html/2506.02620/x22.png",
                "caption": "Figure S12:Our user study interface.",
                "position": 1878
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Work",
        "images": []
    }
]