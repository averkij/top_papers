[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.17143/x1.png",
                "caption": "",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x2.png",
                "caption": "",
                "position": 100
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x3.png",
                "caption": "",
                "position": 105
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x4.png",
                "caption": "Figure 1:Comparison of the proposed Attention Prompting on Image (ùíú‚Å¢ùí´‚Å¢‚Ñêùíúùí´‚Ñê\\mathcal{API}caligraphic_A caligraphic_P caligraphic_I) with the naive VQA.ùíú‚Å¢ùí´‚Å¢‚Ñêùíúùí´‚Ñê\\mathcal{API}caligraphic_A caligraphic_P caligraphic_Iprovides hints for LVLM by simply overlying a heatmap on the image.",
                "position": 112
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.17143/x5.png",
                "caption": "Figure 2:In complex images including multiple objects, our method accurately highlights the fruits and masks the other objects, thereby simplifying the scene and facilitating the LVLM‚Äôs inference of spatial relationships.",
                "position": 1515
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x6.png",
                "caption": "Figure 3:Our method identifies regions related to the objects, thereby assisting the LVLM in spatial reasoning.",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x7.png",
                "caption": "Figure 4:Our method assists LVLM‚Äôs recognition process by highlighting the corresponding steps in the flowchart.",
                "position": 1529
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x8.png",
                "caption": "Figure 5:In this example, our method enhances LVLM‚Äôs OCR capability by masking background areas and highlighting the regions that require OCR.",
                "position": 1532
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x9.png",
                "caption": "Figure 6:In this example, our method highlights related regions and enables the LVLM to generate more detailed and accurate response.",
                "position": 1536
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x10.png",
                "caption": "Figure 7:In this example, where the question asks to determine whether the trash can is full, our method accurately highlights the area around the trash can‚Äôs opening, thereby guiding the LVLM to make a correct judgment.",
                "position": 1543
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x11.png",
                "caption": "Figure 8:In this example, where the question is related to books, our method accurately highlights the area where the books are located in the image.",
                "position": 1550
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x12.png",
                "caption": "Figure 9:In this example, the largest measurement number 50 on the ruler is not fully displayed, leading to error in the baseline method. In contrast, as seen through the heatmap, our method emphasizes the bottom right corner of the image where the end of the ruler is located, thereby guiding the LVLM to provide the correct answer.",
                "position": 1557
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x13.png",
                "caption": "Figure 10:Our method accurately emphasizes the baby and dog in the image, thereby facilitating the inference of their spatial relationship.",
                "position": 1564
            },
            {
                "img": "https://arxiv.org/html/2409.17143/x14.png",
                "caption": "Figure 11:In this example, the question is related to the shoes, which are small objects and are difficult to recognize for the model. Our method accurately located the shoes in the image, leading the LVLM to the correct answer.",
                "position": 1571
            }
        ]
    },
    {
        "header": "7Notation Table",
        "images": []
    },
    {
        "header": "8Observation and Discussion of API Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.17143/x15.png",
                "caption": "Figure 12:Comparison between the functionality of CLS token similarity and the Non-CLS token similarity.",
                "position": 1951
            }
        ]
    },
    {
        "header": "9More Experimental Results and Implementation Details",
        "images": []
    },
    {
        "header": "10Limitation, Future Direction, and Potential Impact",
        "images": []
    }
]