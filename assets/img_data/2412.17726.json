[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17726/x1.png",
                "caption": "Figure 1:An example illustrating the Structure and Dynamics latents. We select two frames,t1subscript𝑡1t_{1}italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTandt2subscript𝑡2t_{2}italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and show the original and reconstructed video frames, labeled Orig. and Recon., respectively. S. Recon. and D. Recon. refer to the reconstructed frames decoded using only the corresponding Structure or Dynamics latents. The Structure latent captures the main semantic content and overall motion trends, while the Dynamics latent encodes local details and rapid movements.",
                "position": 136
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17726/x2.png",
                "caption": "Figure 2:Details of our model. After obtaining the latentz𝑧zitalic_zfrom the Encoder, the process branches into two flows. TheStructure Latentextraction module,ℱ𝑺subscriptℱ𝑺\\mathcal{F}_{\\boldsymbol{S}}caligraphic_F start_POSTSUBSCRIPT bold_italic_S end_POSTSUBSCRIPT, which consists of a Q-Former and convolutional networks, extracts theStructure Latentcomponentz𝑺subscript𝑧𝑺z_{\\boldsymbol{S}}italic_z start_POSTSUBSCRIPT bold_italic_S end_POSTSUBSCRIPT. TheDynamics Latentextraction module,ℱ𝑫subscriptℱ𝑫\\mathcal{F}_{\\boldsymbol{D}}caligraphic_F start_POSTSUBSCRIPT bold_italic_D end_POSTSUBSCRIPT, comprising convolutional networks and an averaging operator, extracts theDynamics Latentcomponentz𝑫subscript𝑧𝑫z_{\\boldsymbol{D}}italic_z start_POSTSUBSCRIPT bold_italic_D end_POSTSUBSCRIPT. Finally, using the decoding module, we align all latents to the same dimension and combine them before passing them into the Decoder.",
                "position": 177
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17726/x3.png",
                "caption": "Figure 3:Qualitative comparison with baseline methods. Two examples are presented: a gradually rotating photo and a fast-motion boxing scene.\\modelnamedemonstrates the ability to reconstruct fine details and accurately capture rapid motion.",
                "position": 450
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17726/x4.png",
                "caption": "Figure 4:An illustration of a cross-replacement example, where Video C is generated using theStructure Latentfrom Video A and theDynamics Latentfrom Video B.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2412.17726/x5.png",
                "caption": "Figure 5:We present the FLOPs and training memory costs of the unified generative model, as applied to our model and the baselines.",
                "position": 521
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17726/x6.png",
                "caption": "Figure 6:Additional reconstruction cases comparing our\\modelnamemodel with baselines. Zoom in to observe finer details.",
                "position": 1294
            },
            {
                "img": "https://arxiv.org/html/2412.17726/x7.png",
                "caption": "Figure 7:Additional examples of decouplingStructure LatentandDynamics Latent.",
                "position": 1310
            },
            {
                "img": "https://arxiv.org/html/2412.17726/x8.png",
                "caption": "Figure 8:Additional examples of cross-reenactment.",
                "position": 1320
            }
        ]
    },
    {
        "header": "Appendix BAdditional Information on Experimental Settings",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DBasics for Diffusion Models and VAE",
        "images": []
    }
]