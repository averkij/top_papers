[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/x1.png",
                "caption": "Figure 1.(A) Temporal degradation. Model performance consistently declines on clinical cases that post-date their training knowledge cutoffs, highlighting the risk of data contamination. (B) Evaluation alignment. Our proposed Automated Rubric-based Evaluation Framework aligns better with physician experts compared to LLM-as-a-Judge.",
                "position": 226
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/x2.png",
                "caption": "Figure 2.Overview of the LiveMedBench framework. The pipeline consists of five phases: (a) Continuous mining of bilingual clinical data from verified online communities; (b) A Multi-Agent Curation Framework (Screener, Validator, Controller) that structures and validates data against medical guidelines; (c) Automated generation of case-specific evaluation rubrics; (d) Objective evaluation of LLMs using the generated rubrics; and (e) Rigorous human quality assurance to ensure clinical alignment.",
                "position": 295
            }
        ]
    },
    {
        "header": "3.LiveMedBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/fig/livemedbench_fig_1.png",
                "caption": "Figure 3.Data statistics of LiveMedBench. The figure illustrates the comprehensive distribution of (a) 38 clinical specialties, (b) five behavioral themes, (c) data sources and languages , (d) evaluation axes, and (e) the number of grading criteria per case (Mean=6.06).",
                "position": 423
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/x3.png",
                "caption": "Figure 4.The evaluation results of 38 LLMs on LiveMedBench, categorized into proprietary (green) and open-source (yellow) models. Models marked with a cross (+) are specialized medical models, while others are general-purpose. Solid bars represent performance on the full dataset, while hatched bars indicate performance on cases post-dating the modelâ€™s knowledge cutoff.",
                "position": 464
            }
        ]
    },
    {
        "header": "5.Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/x4.png",
                "caption": "Figure 5.Multi-dimensional performance analysis. (Left) Heatmap illustrating the score distribution of representative models across 38 clinical specialties. (Right) Radar chart depicting the capability profiles of representative models across the five behavioral themes.",
                "position": 495
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset",
        "images": []
    },
    {
        "header": "Appendix BExperimental Setup",
        "images": []
    },
    {
        "header": "Appendix CHuman Study Details",
        "images": []
    },
    {
        "header": "Appendix DMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10367/x5.png",
                "caption": "Figure 16.Correlation of model failed cases. We compute the pairwise correlation of the bottom-100 scoring cases across representative models.",
                "position": 3258
            },
            {
                "img": "https://arxiv.org/html/2602.10367/x6.png",
                "caption": "Figure 17.Theme correlation heatmap.",
                "position": 3270
            },
            {
                "img": "https://arxiv.org/html/2602.10367/x7.png",
                "caption": "Figure 18.Specialty correlation heatmap. Pairwise Pearson correlation coefficients of model performance across different clinical specialties.",
                "position": 3280
            }
        ]
    },
    {
        "header": "Appendix EEthical Considerations",
        "images": []
    },
    {
        "header": "Appendix FVersioning and Reproducibility",
        "images": []
    }
]