[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07133/x1.png",
                "caption": "Figure 1:This figure demonstrates the process of instruction tuning and the scope of this paper.",
                "position": 155
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Which Models are the most effective teachers for instruction tuning?",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07133/x2.png",
                "caption": "Figure 2:Average performance of five base models fine-tuned on various response generators across six model families. We use different colors to distinguish between model families, with darker bars indicating larger response generators within each family.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2411.07133/x3.png",
                "caption": "Figure 3:This figure demonstrates the impact of different sampling hyper-parameters when generating responses. We useGemma-2-9b-itas the response generator. All models are supervised-fine-tuned on the Llama-3.1-Minitron-4B base model.",
                "position": 572
            }
        ]
    },
    {
        "header": "4How can we determine the most effective response generators without instruction tuning?",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07133/x4.png",
                "caption": "Figure 4:This figures demonstrates the response quality measured by three reward models.",
                "position": 804
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Impact",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore on Experimental Setups",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07133/x5.png",
                "caption": "Figure 5:Task categories of the Magpie-100K instruction set used in our study.",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2411.07133/x6.png",
                "caption": "Figure 6:Average Output Length of synthetic datasets generated using different response generators (measured in Tokens).",
                "position": 2205
            },
            {
                "img": "https://arxiv.org/html/2411.07133/x7.png",
                "caption": "Figure 7:PPL-GPT2 and IFD-GPT2.",
                "position": 2208
            },
            {
                "img": "https://arxiv.org/html/2411.07133/x8.png",
                "caption": "Figure 8:PPL-Self of five base models.",
                "position": 2211
            },
            {
                "img": "https://arxiv.org/html/2411.07133/x9.png",
                "caption": "Figure 9:IFD-Self of five base models.",
                "position": 2214
            }
        ]
    },
    {
        "header": "Appendix BMore Experimental Results",
        "images": []
    }
]