[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/teaser.png",
                "caption": "Figure 1.AI Video Chat is a new paradigm for real-time communication. The user sends video and audio to the AI for thinking. The AI feeds back to the user. Low latency is crucial for making AI act like a real person.",
                "position": 66
            }
        ]
    },
    {
        "header": "2.Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/frame_latency.png",
                "caption": "Figure 2.How bitrate and packet loss affect latency (with 10 Mbps bandwidth). To optimize video quality, traditional RTC systems select bitrate from the gray region. But in AI video chat, to maintain accuracy, we only need to select bitrate from the yellow region (§2.2).",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/bitrate_reduce_accuracy.png",
                "caption": "Figure 3.Why video should be context-aware in AI Video Chat. In the first dialogue, even if the video bitrate decreases from 4000 Kbps to 200 Kbps, the MLLM can still response accurately. But in the second dialogue, the blurry video leads to incorrect responses. Therefore, rather than reducing bitrate in a context-agnostic manner, bitrate allocation should be determined by the current chat context (§2.3).",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/fps.png",
                "caption": "Figure 4.Frame Rate is FEC. MLLM processes video at a very low frame rate (green region), so higher frame rates will introduce redundancy (red region). Higher frame rates on one hand cause bitrate waste, while on the other hand enhance loss resilience (§2.3).",
                "position": 149
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/clip_vis.png",
                "caption": "Figure 5.How to achieve context awareness? The user words can indicate which regions in the video are important for the current chat context. Based on CLIP, we can even recognize important regions through high-level understanding. For example, in the third dialogue, the growth of grass implies the current season (§2.3).",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/fec.png",
                "caption": "Figure 6.How to achieve loss resilience? When the expected frame is not completely received on time, the MLLM directly discards it and uses the previous redundant frame, without waiting for retransmission.",
                "position": 160
            }
        ]
    },
    {
        "header": "3.Towards RTC for AI",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/sample_generation.png",
                "caption": "Figure 7.DeViBench’s pipeline for automatic QA sample construction. Details can be found in §3.1.",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/prompt.png",
                "caption": "Figure 8.Our prompt for QA Sample Generation.",
                "position": 211
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/accuracy.png",
                "caption": "Figure 9.Context-aware streaming can dramatically lower the bitrate while maintaining MLLM accuracy.",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2507.10510/extracted/6622311/figures/frame_rate_result.png",
                "caption": "Figure 10.Eliminating the latency caused by stalling, while avoiding the waste brought by high frame rates.",
                "position": 312
            }
        ]
    },
    {
        "header": "4.DISCUSSIONS AND OPEN QUESTIONS",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]