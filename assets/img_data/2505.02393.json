[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Uncertainty-Weighted Fusion for Multimodal Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02393/extracted/6411525/figures/fig1.png",
                "caption": "Figure 1:Overview of IEF-VAD framework.Each video frame and its corresponding synthetic event representation are processed by CLIP encoders to obtain feature embeddingszmsubscript𝑧𝑚z_{m}italic_z start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. These are further encoded by modality-specific transformersfmsubscript𝑓𝑚f_{m}italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTto producez^msubscript^𝑧𝑚\\hat{z}_{m}over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, which are then passed through projection headsgmsubscript𝑔𝑚g_{m}italic_g start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTandhmsubscriptℎ𝑚h_{m}italic_h start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTto estimateμmsubscript𝜇𝑚\\mu_{m}italic_μ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTandσmsubscript𝜎𝑚\\sigma_{m}italic_σ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. The estimatedσmsubscript𝜎𝑚\\sigma_{m}italic_σ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTis used to compute the uncertainty-aware fusion weightwmsubscript𝑤𝑚w_{m}italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, which is used to obtain the initial fused representationμft,0superscriptsubscript𝜇𝑓𝑡0\\mu_{f}^{t,0}italic_μ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t , 0 end_POSTSUPERSCRIPT. This is refined overN𝑁Nitalic_Niterative steps through a refinement network to produce the final outputμft,Nsuperscriptsubscript𝜇𝑓𝑡𝑁\\mu_{f}^{t,N}italic_μ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t , italic_N end_POSTSUPERSCRIPT.",
                "position": 184
            }
        ]
    },
    {
        "header": "4Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02393/extracted/6411525/figures/fig2.png",
                "caption": "Figure 2:Radar charts showing per-class anomaly detection performance (AUC and AP) for image-only (blue), event-only (orange), and fused (green) approaches. Each radial axis represents an anomaly category, and values are normalized per class by the maximum score. The fused approach consistently covers a larger area, highlighting improved detection across anomaly types.",
                "position": 601
            },
            {
                "img": "https://arxiv.org/html/2505.02393/extracted/6411525/figures/fig3.jpg",
                "caption": "Figure 3:Change in image-side uncertainty weightsΔ⁢wxΔsubscript𝑤𝑥\\Delta w_{x}roman_Δ italic_w start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPTunder modality-specific masking perturbations across four datasets. The horizontal axisi𝑖iitalic_idenotes the latent dimension index, and the vertical axisρ𝜌\\rhoitalic_ρindicates the proportion of values inzxsubscript𝑧𝑥z_{x}italic_z start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPTorzesubscript𝑧𝑒z_{e}italic_z start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPTthat are masked to zero. Each surface visualizesΔ⁢wx⁢(i,ρ)=wxmasked⁢(i)−wxclean⁢(i)Δsubscript𝑤𝑥𝑖𝜌superscriptsubscript𝑤𝑥masked𝑖superscriptsubscript𝑤𝑥clean𝑖\\Delta w_{x}(i,\\rho)=w_{x}^{\\text{masked}}(i)-w_{x}^{\\text{clean}}(i)roman_Δ italic_w start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( italic_i , italic_ρ ) = italic_w start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT masked end_POSTSUPERSCRIPT ( italic_i ) - italic_w start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT clean end_POSTSUPERSCRIPT ( italic_i )for a given masking ratio. The top row corresponds to masking applied tozxsubscript𝑧𝑥z_{x}italic_z start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT(image modality), while the bottom row applies masking tozesubscript𝑧𝑒z_{e}italic_z start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT(event modality), with both measuring the resulting change inwxsubscript𝑤𝑥w_{x}italic_w start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT. Positive values (blue) indicate increased confidence in the image modality under corruption, while negative values (red) reflect a reduction. The non-uniform patterns acrossi𝑖iitalic_ihighlight dimension-specific responses to value-level degradation.",
                "position": 613
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABounded Influence ofStudent’s t-Noise",
        "images": []
    },
    {
        "header": "Appendix BLaplace Approximation for theStudent’s tNoise Model",
        "images": []
    },
    {
        "header": "Appendix CTheoretical Foundations of Inverse Variance Weighting in Bayesian Inference",
        "images": []
    },
    {
        "header": "Appendix DIterative Refinement of Fused State",
        "images": []
    },
    {
        "header": "Appendix EDerivation of KL Divergence",
        "images": []
    },
    {
        "header": "Appendix FExperiment Details",
        "images": []
    },
    {
        "header": "Appendix GAblation Study",
        "images": []
    },
    {
        "header": "Appendix HFusion Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02393/extracted/6411525/figures/fig4.jpg",
                "caption": "",
                "position": 3848
            },
            {
                "img": "https://arxiv.org/html/2505.02393/extracted/6411525/figures/fig5.jpg",
                "caption": "",
                "position": 3850
            }
        ]
    },
    {
        "header": "Appendix IVisualizatation of Anomaly Detection with Uncertainty",
        "images": []
    }
]