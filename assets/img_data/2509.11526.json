[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11526/x1.png",
                "caption": "Figure 1:Comparison of MHIM-MIL with baseline methods. Theblueoutlines denote tumor regions annotated by pathologists; subfigure (a) shows masked instances asblackpatches. Subfigure (b) displays attention scores from the student model, where brighter patches indicate higher saliency (i.e., mined salient instances), while subfigure (c) presents the softmax-normalized attention weights, withcyanindicating high probability of tumor presence, which should ideally align with thebluetumor boundaries. Baseline methods tend to focus on highly activated or trivial regions (top part of subfigure (b) in the tumor slide) or noisy activations (top-right of normal tissue slides); in contrast, MHIM-MIL suppresses such dominant patches via masking, encouraging exploration of less-salient yet informative areas (bottom part of subfigure (b)), leading to more comprehensive and robust predictions.",
                "position": 167
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11526/x2.png",
                "caption": "Figure 2:Overview of proposed MHIM-MIL. A momentum teacher is used to compute class-aware instance probability for all instances. We mask instances based on these probabilities using randomly high score masking (RHSM) and random score masking (RSM) strategies. Then, we employ a global recycle network (GRN) to reconstruct key features from the large-scale RSM-masked instances. Finally, we feed these reconstructed features along with unmasked instances to the student model. The student is updated using a consistency loss termℒc​o​n\\mathcal{L}_{con}and a label error loss termℒc​l​s\\mathcal{L}_{cls}. The teacher parameters are updated with an Exponential Moving Average (EMA) of the student parameters without gradient updates. During inference, we use the complete input instances and the student model only.",
                "position": 269
            }
        ]
    },
    {
        "header": "3Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11526/x3.png",
                "caption": "Figure 3:Illustration of various hard instance mining methods.",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x4.png",
                "caption": "Figure 4:Illustration of Global Recycle Network.",
                "position": 580
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11526/x5.png",
                "caption": "Table 10:Comparison of different types of teachers.",
                "position": 3478
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x6.png",
                "caption": "Table 11:Comparison of different MIL models under student initialization.",
                "position": 3633
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x7.png",
                "caption": "Figure 5:Performance comparison between the simple Random Masking Strategy (RSM) and MHIM-v2 (Ours).",
                "position": 3868
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x8.png",
                "caption": "Figure 6:The performances of MHIM-v2 under different important hyperparameters.",
                "position": 3871
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x9.png",
                "caption": "Figure 7:Patch visualization produced by baselines and MHIM-v2 on CAMELYON. Thebluelines outline the tumor regions. Brighter patches indicate higher attention scores. Thecyancolors represent high probabilities of tumor presence at the corresponding locations. In the cyan patches, brightness reflects the confidence level. Ideally, the brightcyanpatches should cover only the area within thebluelines. We demonstrate that focusing solely on more salient regions reduces the generalization ability of baseline models. MHIM-v2 corrects the attention regions of baselines, making accurate and robust judgments from a pathologist’s perspective.",
                "position": 3874
            },
            {
                "img": "https://arxiv.org/html/2509.11526/x10.png",
                "caption": "Figure 8:Visualization of easy-to-classify instances based on different strategies during the training process by the teacher model. As training progresses, the discriminability of teacher model gradually improves, and the advantage of class-aware instance probability over class-agnostic attention score becomes increasingly significant. This advantage is also shown in normal slides (bottom part of figure), where the evaluation distribution should be more uniform.",
                "position": 3897
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Data Availability Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]