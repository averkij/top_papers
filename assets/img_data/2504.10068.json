[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10068/x1.png",
                "caption": "Figure 1:(a) Sparse sampling, which remains the high resolution but loses many details in the unsampled frames; (b) Dense sampling with low resolution, which understands the videos from a large number of frames but would confuse on the low-resolution content; (c) Dense sampling with token compression, which keeps the key tokens on the main characters but suffers from hallucinations owing to the missing of visual tokens; (d) Our Mavors, balancing the demands of resolution and number of frames. Though all these approaches could perform similarly on Video-MME, Mavors significantly improves the caption capability on complex scenes. Note that the words in red and green denote incorrect and correct details, respectively.",
                "position": 99
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10068/x2.png",
                "caption": "(a)Video-MME",
                "position": 211
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x2.png",
                "caption": "(a)Video-MME",
                "position": 214
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x3.png",
                "caption": "(b)Dream1K",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x4.png",
                "caption": "(a)Video-MME",
                "position": 227
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x4.png",
                "caption": "(a)Video-MME",
                "position": 230
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x5.png",
                "caption": "(b)Dream1K",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x6.png",
                "caption": "Figure 4:The architecture of Mavors.",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x7.png",
                "caption": "Figure 5:The dynamic resolution strategy in Mavors.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2504.10068/extracted/6359558/figures/mm_training_stage_v4.png",
                "caption": "Figure 6:Training paradigm of different stages.",
                "position": 381
            }
        ]
    },
    {
        "header": "4Training Paradigm",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10068/x8.png",
                "caption": "Figure 7:Performance with different numbers of frames in a video chunk.",
                "position": 872
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x8.png",
                "caption": "Figure 7:Performance with different numbers of frames in a video chunk.",
                "position": 875
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x9.png",
                "caption": "Figure 8:Performance with different token compression ratios.",
                "position": 880
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x10.png",
                "caption": "Figure 9:The dynamic of training losses across different stages for Mavors.",
                "position": 885
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x11.png",
                "caption": "Figure 10:Comparison of generated video captions from Qwen2.5-VL-7B and Mavors-7B.",
                "position": 1112
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "ATraining Datasets",
        "images": []
    },
    {
        "header": "BAnalysis on the Inference Costs",
        "images": []
    },
    {
        "header": "CDetails of Experiments",
        "images": []
    },
    {
        "header": "DNeedle in a Haystack Test",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10068/x12.png",
                "caption": "Figure 11:Results of NIAH of Mavors with at most 60 video chunks.",
                "position": 3115
            }
        ]
    },
    {
        "header": "EShowcases of Mavors in Image Captioning",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.10068/x13.png",
                "caption": "Figure 12:Comparison of the generated image captions from Qwen2.5-VL-7B and Mavors-7B. The text in red contains wrong content, and the text in green marks the detailed descriptions only appear in Mavors.",
                "position": 3140
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x14.png",
                "caption": "Figure 13:Example of captioning task with token compression: higher compression ratio leads to the missing of critical details.",
                "position": 3155
            },
            {
                "img": "https://arxiv.org/html/2504.10068/x15.png",
                "caption": "Figure 14:Example of captioning task with token compression: higher compression ratio leads to the missing of critical details.",
                "position": 3158
            }
        ]
    },
    {
        "header": "FShowcases of Mavors with Token Compression",
        "images": []
    }
]