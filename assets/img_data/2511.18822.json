[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18822/x1.png",
                "caption": "Figure 1:Comparison of vanilla latent diffusion model, vanilla pixel diffusion model and our method. Vanilla LDMs utilize VAEs to balance computational efficiency and generation quality. Vanilla pixel diffusion models use small patches to pursue detailed generation quality. Our method achieves high-quality generation while maintaining efficient end-to-end training in pixel space.",
                "position": 84
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18822/assets/pic/intro/teaser2_v6.png",
                "caption": "Figure 2:Our method achieves the best FID score with minimal computational cost. (Note: LDM latency includes VAE. The methods marked with dashed lines () are our estimated latency based on the sampling method in the corresponding paper, and should actually be greater than the marked values. The rest methods are the actual test results in the same hardware environment.)",
                "position": 96
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18822/x2.png",
                "caption": "Figure 3:Overfitting the DiT-only model using a single image in pixel space leads to poor detail reconstruction. Introducing a local inductive bias achieves better reconstruction and accelerates convergence. Please zoom in for details.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x3.png",
                "caption": "Figure 4:The t-SNE visualization of feature space. In the ImageNet validation set, 100 samples were randomly selected from each of the 10 classes for feature visualization. Features are extracted using DiT-only and our method, with each class shown in a distinct color.",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x4.png",
                "caption": "Figure 5:Patch Detailer Head with local inductive bias was placed at different locations in the model. The results in Sec.4.3show that all three methods offer gains compared to DiT-only.",
                "position": 213
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x5.png",
                "caption": "Figure 6:Patch Detailer Head framework. This design introduces the local inductive bias that DiT-only lacks with a low number of parameters, resulting in a high-quality image with rich detail.",
                "position": 245
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x6.png",
                "caption": "Table 1:Comparison of the performance of different methods on ImageNet 256×256 with Euler solver and CFG. Performance metrics are annotated with↑\\uparrow(higher is better) and↓\\downarrow(lower is better). Our method achieves the best FID score. Furthermore, compared to other pixel diffusion models, we achieve the best performance across all metrics with the lowest latency.",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x6.png",
                "caption": "Figure 7:Qualitative samples from our model trained at 256 × 256 resolution with classifier-free guidance scale of 4.0. DiP demonstrates fine-grained detail, and high visual quality.",
                "position": 563
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18822/x7.png",
                "caption": "Table 2:Impact of different design schemes on computational overhead and performance.",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x7.png",
                "caption": "Figure 8:The t-SNE visualization of feature space. Features are extracted using Post-hoc Refinement, Intermediate Injection, and Hybrid Injection, with each class shown in a distinct color.",
                "position": 802
            }
        ]
    },
    {
        "header": "Appendix AWhy Patch Detailer Head: A Theoretical Perspective",
        "images": []
    },
    {
        "header": "Appendix BProof of TheoremA.6",
        "images": []
    },
    {
        "header": "Appendix CMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix DHow to Preserving High-Frequency Signal: Patch or Image",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18822/x8.png",
                "caption": "Figure 11:Different input formats of Patch Detailer Head.",
                "position": 1399
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x9.png",
                "caption": "Figure 12:Toy experiment. (a) Visualization of manifold fitting with Patch-level input. The model precisely captures high-frequency branches. (b) Visualization of manifold fitting with Image-level input. The model exhibits over-smoothing and fails to resolve fine details.",
                "position": 1402
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x10.png",
                "caption": "Figure 13:256×\\times256 samples. Class lable = “goldfish, Carassius auratus” (1). CFG = 4.0.",
                "position": 1410
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x11.png",
                "caption": "Figure 14:256×\\times256 samples. Class lable = “junco, snowbird” (13). CFG = 4.0.",
                "position": 1413
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x12.png",
                "caption": "Figure 15:256×\\times256 samples. Class lable = “chickadee” (19). CFG = 4.0.",
                "position": 1416
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x13.png",
                "caption": "Figure 16:256×\\times256 samples. Class lable = “tree frog, tree-frog” (30). CFG = 4.0.",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x14.png",
                "caption": "Figure 17:256×\\times256 samples. Class lable = “mud turtle” (35). CFG = 4.0.",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x15.png",
                "caption": "Figure 18:256×\\times256 samples. Class lable = “teddy, teddy bear” (859). CFG = 4.0.",
                "position": 1425
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x16.png",
                "caption": "Figure 19:256×\\times256 samples. Class lable = “cauliflower” (938). CFG = 4.0.",
                "position": 1428
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x17.png",
                "caption": "Figure 20:256×\\times256 samples. Class lable = “potpie” (964). CFG = 4.0.",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x18.png",
                "caption": "Figure 21:256×\\times256 samples. Class lable = “bolete” (997). CFG = 4.0.",
                "position": 1434
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x19.png",
                "caption": "Figure 22:512×\\times512 samples. Class lable = “ptarmigan” (81). CFG = 4.0.",
                "position": 1437
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x20.png",
                "caption": "Figure 23:512×\\times512 samples. Class lable=”jellyfish” (107). CFG=4.0.",
                "position": 1440
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x21.png",
                "caption": "Figure 24:512×\\times512 samples. Class lable=”Maltese dog, Maltese terrier, Maltese” (153). CFG=4.0.",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x22.png",
                "caption": "Figure 25:512×\\times512 samples. Class lable = “lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens” (387). CFG = 4.0.",
                "position": 1446
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x23.png",
                "caption": "Figure 26:512×\\times512 samples. Class lable = “barn” (425). CFG = 4.0.",
                "position": 1449
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x24.png",
                "caption": "Figure 27:512×\\times512 samples. Class lable = “beacon, lighthouse, beacon light, pharos” (437). CFG = 4.0.",
                "position": 1452
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x25.png",
                "caption": "Figure 28:512×\\times512 samples. Class lable = “beer glass” (441). CFG = 4.0.",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x26.png",
                "caption": "Figure 29:512×\\times512 samples. Class lable = “wool, woolen, woollen” (911). CFG = 4.0.",
                "position": 1458
            },
            {
                "img": "https://arxiv.org/html/2511.18822/x27.png",
                "caption": "Figure 30:512×\\times512 samples. Class lable = “trifle” (927). CFG = 4.0.",
                "position": 1461
            }
        ]
    },
    {
        "header": "Appendix EMore Visualization Results",
        "images": []
    }
]