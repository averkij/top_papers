[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.11922/x1.png",
                "caption": "Figure 1:Illustration of two common failure cases in visual object tracking using SAM 2: (1) In a crowded scene with similar appearances between target and background objects, SAM 2 tends to ignore the motion cue and predict where the mask has the higher IoU score. (2) The original memory bank simply chooses and stores the previousnùëõnitalic_nframes into the memory bank, resulting in introducing some bad features during occlusion.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.11922/extracted/6006494/sec/figure/figure_2_pipeline_v2.png",
                "caption": "Figure 2:The overview of our SAMURAI visual object tracker.",
                "position": 168
            }
        ]
    },
    {
        "header": "3Revisiting Segment Anything Model 2",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.11922/x2.png",
                "caption": "Figure 3:SUC and Pnormnorm{}_{\\text{norm}}start_FLOATSUBSCRIPT norm end_FLOATSUBSCRIPTplots of LaSOT and LaSOTextext{}_{\\text{ext}}start_FLOATSUBSCRIPT ext end_FLOATSUBSCRIPT.",
                "position": 841
            },
            {
                "img": "https://arxiv.org/html/2411.11922/x2.png",
                "caption": "",
                "position": 844
            },
            {
                "img": "https://arxiv.org/html/2411.11922/x3.png",
                "caption": "",
                "position": 848
            },
            {
                "img": "https://arxiv.org/html/2411.11922/x4.png",
                "caption": "",
                "position": 853
            },
            {
                "img": "https://arxiv.org/html/2411.11922/x5.png",
                "caption": "",
                "position": 857
            },
            {
                "img": "https://arxiv.org/html/2411.11922/extracted/6006494/sec/figure/figure_4_visualization_sota.jpg",
                "caption": "Figure 4:Visualization of tracking results comparing SAMURAIwith existing methods. (Top) Conventional VOT methods often struggle in crowded scenarios where the target object is surrounded by objects with similar appearances. (Bottom) The baseline SAM-based method suffers from fixed-window memory composition, leading to error propagation and reduced overall tracking accuracy due to ID switches.",
                "position": 1460
            },
            {
                "img": "https://arxiv.org/html/2411.11922/extracted/6006494/sec/figure/figure_4_visualization_sota.jpg",
                "caption": "",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2411.11922/extracted/6006494/sec/figure/figure_4_visualization_sam_compare.png",
                "caption": "",
                "position": 1475
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]