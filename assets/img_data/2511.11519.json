[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Strategies For AI Systems",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11519/x1.png",
                "caption": "Figure 1:Comparison of existing experience-based adaptation methods (A and B) to our approach in (C) which dynamically produces a compiled strategy based on the current query and memory at inference time. Methods which augment existing strategies with state, such as Dynamic Cheatsheet[6]and Mem0[9], are depicted in (A) and methods such as ADAS[8]and OPTO[10]which optimize strategies offline are shown in (B). Our method shown in (C) uses a state (which can contain useful compiled strategies) during inference to guide the system in producing effective strategies for each query, unlike existing methods which cannot adapt their strategies per-query.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2511.11519/x2.png",
                "caption": "Figure 3:Comparison of strategy performance across tasks for Claude 3.7 Sonnet. Strategies closer to the top-left corner are best for the task in terms of accuracy and cost. The optimal strategy differs significantly across tasks. For example, Code\nexcels on 3-SAT and Word Sorting but performs poorly on Movie Recommendation and AIME. Descriptions of the above strategies are provided inSectionB.6.",
                "position": 280
            }
        ]
    },
    {
        "header": "3Experience-Guided Reasoner (EGuR)",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11519/x3.png",
                "caption": "Figure 4:Evolution of accuracy and cost on held-out evaluation sets as training progresses for Claude 3.7 Sonnet.EGuR-5 consistently improves accuracy while reducing cost with more experience. Cost is shown up to $1.0 for visualization; Dynamic Cheatsheet (DC) typically exceeds this threshold, reaching $9.95, $2.26, $2.88, $4.32, and $7.16 per sample after training on 3-SAT, AIME, Movie Rec., Word Sort., and Object Count., respectively. The complete results for Claude 3.7 Sonnet, GPT-OSS-120B, and Qwen3-Next-80B-A3B-Thinking are included inAppendixC.",
                "position": 542
            },
            {
                "img": "https://arxiv.org/html/2511.11519/x4.png",
                "caption": "Figure 5:Ablation of exploration level inEGuRfor Claude 3.7 Sonnet. Higher exploration levels (more strategies per problem) generally improve both accuracy and cost-efficiency by enabling comparative evaluation of strategy effectiveness.",
                "position": 568
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work Taxonomy",
        "images": []
    },
    {
        "header": "Appendix BStrategies",
        "images": []
    },
    {
        "header": "Appendix CFull results",
        "images": []
    },
    {
        "header": "Appendix DExample Generated Strategies",
        "images": []
    },
    {
        "header": "Appendix EExample Learned Context",
        "images": []
    },
    {
        "header": "Appendix FPrompts",
        "images": []
    }
]