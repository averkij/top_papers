[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07599/x1.png",
                "caption": "Figure 1:Left: Distribution oflogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x ).Right: Kernel density estimation (KDE) for the reward margin(râ¢(ğ’™,ğ’šw)âˆ’râ¢(ğ’™,ğ’šl))ğ‘Ÿğ’™subscriptğ’šğ‘¤ğ‘Ÿğ’™subscriptğ’šğ‘™(r(\\boldsymbol{x},\\boldsymbol{y}_{w})-r(\\boldsymbol{x},\\boldsymbol{y}_{l}))( italic_r ( bold_italic_x , bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ) - italic_r ( bold_italic_x , bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) ). The reward accuracy, which is the sample mean of1â¢{(ğ’™,ğ’šw,ğ’šl)|râ¢(ğ’™,ğ’šw)âˆ’râ¢(ğ’™,ğ’šl)>0}1conditional-setğ’™subscriptğ’šğ‘¤subscriptğ’šğ‘™ğ‘Ÿğ’™subscriptğ’šğ‘¤ğ‘Ÿğ’™subscriptğ’šğ‘™01\\{(\\boldsymbol{x},\\boldsymbol{y}_{w},\\boldsymbol{y}_{l})|r(\\boldsymbol{x},%\n\\boldsymbol{y}_{w})-r(\\boldsymbol{x},\\boldsymbol{y}_{l})>0\\}1 { ( bold_italic_x , bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) | italic_r ( bold_italic_x , bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ) - italic_r ( bold_italic_x , bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) > 0 }is listed. The three rows are plotted with three models including the SFTed Llama 3-8B, the model trained by one strategy of DPO-Shift, and the model trained by DPO (from top to bottom), separately. The ranges of the y-axis of all subfigures are the same.",
                "position": 111
            }
        ]
    },
    {
        "header": "2DPO-Shift: Formulation and Analysis",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07599/x2.png",
                "caption": "Figure 2:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback withfixedstrategy. Only limited cases offâ¢(Î»)ğ‘“ğœ†f(\\lambda)italic_f ( italic_Î» )are listed. For a full ablation study, please refer toSectionA.2. The ranges of the y-axis of all subfigures are the same.",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x3.png",
                "caption": "Figure 3:Distribution for reward margin and reward accuracy on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback withfixedstrategy. Only limited cases offâ¢(Î»)ğ‘“ğœ†f(\\lambda)italic_f ( italic_Î» )are listed. For a full ablation study, please refer toSectionA.2. The ranges of the y-axis of all subfigures are the same.",
                "position": 555
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07599/x4.png",
                "caption": "Figure 4:Reward accuracy vs differentfâ¢(Î»)ğ‘“ğœ†f(\\lambda)italic_f ( italic_Î» )(fixedstrategy) for Llama 3-8B trained on UltraFeedback, wherefâ¢(Î»)ğ‘“ğœ†f(\\lambda)italic_f ( italic_Î» )is selected from[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]0.50.550.60.650.70.750.80.850.90.95[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95][ 0.5 , 0.55 , 0.6 , 0.65 , 0.7 , 0.75 , 0.8 , 0.85 , 0.9 , 0.95 ].",
                "position": 582
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x5.png",
                "caption": "Figure 5:The comparison between DPO-Shiftwithfâ¢(Î»)=0.99ğ‘“ğœ†0.99f(\\lambda)=0.99italic_f ( italic_Î» ) = 0.99and DPO on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback.Left:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x ).Right:Reward accuracy and distribution for reward margin.",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x6.png",
                "caption": "Figure 6:The comparison betweenfixedstrategy withfâ¢(Î»)=0.75ğ‘“ğœ†0.75f(\\lambda)=0.75italic_f ( italic_Î» ) = 0.75andlinear_decreasewithÎ»min=0.75subscriptğœ†0.75\\lambda_{\\min}=0.75italic_Î» start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT = 0.75on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback.Left:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x );Right:Reward accuracy and distribution for reward margin.",
                "position": 594
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x7.png",
                "caption": "Figure 7:Win rate experiment against DPO using Llama 3-8B trained on the UltraFeedback dataset and tested with questions from the test split of UltraFeedback.",
                "position": 739
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASupplemented Experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.07599/x8.png",
                "caption": "Figure 8:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1232
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x9.png",
                "caption": "Figure 9:Distribution for reward margin and reward accuracy on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1235
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x10.png",
                "caption": "Figure 10:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of Capybara for Llama 3-8B trained on Capybara, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1239
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x11.png",
                "caption": "Figure 11:Distribution for reward margin and reward accuracy on test set split of Capybara for Llama 3-8B trained on Capybara, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1242
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x12.png",
                "caption": "Figure 12:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of UltraFeedback for Qwen 2-7B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1246
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x13.png",
                "caption": "Figure 13:Distribution for reward margin and reward accuracy on test set split of UltraFeedback for Qwen 2-7B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1249
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x14.png",
                "caption": "Figure 14:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of Capybara for Qwen 2-7B trained on Capybara, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1253
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x15.png",
                "caption": "Figure 15:Distribution for reward margin and reward accuracy on test set split of Capybara for Qwen 2-7B trained on Capybara, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1256
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x16.png",
                "caption": "Figure 16:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of Ultrafeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1265
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x17.png",
                "caption": "Figure 17:Distribution for reward margin and reward accuracy on test set split of Ultrafeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1268
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x18.png",
                "caption": "Figure 18:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of Capybara for Llama 3-8B trained on Capybara, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1272
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x19.png",
                "caption": "Figure 19:Distribution for reward margin and reward accuracy on test set split of Capybara for Llama 3-8B trained on Capybara, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1275
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x20.png",
                "caption": "Figure 20:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of UltraFeedback for Qwen 2-7B trained on UltraFeedback, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x21.png",
                "caption": "Figure 21:Distribution for reward margin and reward accuracy on test set split of UltraFeedback for Qwen 2-7B trained on UltraFeedback, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1282
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x22.png",
                "caption": "Figure 22:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of Capybara for Qwen 2-7B trained on Capybara, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1286
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x23.png",
                "caption": "Figure 23:Distribution for reward margin and reward accuracy on test set split of Capybara for Qwen 2-7B trained on Capybara, where DPO-Shiftuseslinear_increaseandlinear_decreasestrategies. The ranges of the y-axis of all subfigures are the same.",
                "position": 1289
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x24.png",
                "caption": "Figure 24:Distribution forlogâ¡Ï€Î¸â¢(ğ’šw|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘¤ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{w}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT | bold_italic_x )andlogâ¡Ï€Î¸â¢(ğ’šl|ğ’™)subscriptğœ‹ğœƒconditionalsubscriptğ’šğ‘™ğ’™\\log\\pi_{\\theta}(\\boldsymbol{y}_{l}|\\boldsymbol{x})roman_log italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | bold_italic_x )on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1298
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x25.png",
                "caption": "Figure 25:Distribution for reward margin and reward accuracy on test set split of UltraFeedback for Llama 3-8B trained on UltraFeedback, where DPO-Shiftusesfixedstrategy. The ranges of the y-axis of all subfigures are the same.",
                "position": 1301
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x26.png",
                "caption": "Figure 26:Win rate experiment for Llama 3-8B trained on UltraFeedback and tested with questions from the test split of Capybara.",
                "position": 1309
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x27.png",
                "caption": "Figure 27:Win rate experiment for Qwen 2-7B trained on UltraFeedback and tested with questions from the test split of UltraFeedback.",
                "position": 1313
            },
            {
                "img": "https://arxiv.org/html/2502.07599/x28.png",
                "caption": "Figure 28:Win rate experiment for Qwen 2-7B trained on UltraFeedback and tested with questions from the test split of Capybara.",
                "position": 1317
            }
        ]
    },
    {
        "header": "Appendix BProof ofTheorem2.1",
        "images": []
    }
]