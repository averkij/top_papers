[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04207/x1.png",
                "caption": "",
                "position": 125
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3GRAMMAR: Generalized Multimodal Reasoning Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04207/x2.png",
                "caption": "Figure 2:Absolute performance improvement on Qwen2.5-VL-7B-Instruct across textual and multimodal reasoning tasks.\nThe red and purple dashed lines represent the average absolute gains of VisionR1/R1-One-Vision and\nDeepMath/OpenR1-Math over the baseline, respectively, across four reasoning tasks.",
                "position": 364
            }
        ]
    },
    {
        "header": "4Staged Reinforcement Optimization (SRO)",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04207/x3.png",
                "caption": "Figure 3:Training reward of different strategies: PAD-sampling, GRPO-Baseline, GRPO-Filter, and Random-Sampling. PAD consistently reaches higher accuracy and converges faster.",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2506.04207/x4.png",
                "caption": "Figure 4:Training dynamics comparing models with (purple lines, “w efficient-length”) and without (green lines, “w/o efficient-length”) the Efficient-Length Reward.",
                "position": 953
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04207/extracted/6510770/figures/prompt.png",
                "caption": "Figure 5:Prompt Template for ReVisual-R1 in both inference and training stages.",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2506.04207/x5.png",
                "caption": "Figure 6:Our Revisual-R1 model reasoning case, showcasing its exceptional reasoning ability. The model generates long responses, continuously hypothesizing, reflecting, verifying, and correcting to arrive at the final answer, while also providing a summary answer.",
                "position": 2397
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]