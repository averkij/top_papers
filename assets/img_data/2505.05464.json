[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05464/x1.png",
                "caption": "Figure 1:Illustration of our work investigating how model merging works when transferring reasoning ability from a Math-specific LLM to the VLM, showcasing the effects and results of the merged model, as well as the interpretation of layer-wise abilities. The abilities are represented in corresponding colors:redindicatesperception ability hidden in early layers, whilebluedenotesreasoning ability hidden in relatively later layers.",
                "position": 119
            }
        ]
    },
    {
        "header": "2Model Merging Across Modalities",
        "images": []
    },
    {
        "header": "3Experiment settings",
        "images": []
    },
    {
        "header": "4Can Model Merging Enhance VLM Capabilities?",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05464/x2.png",
                "caption": "Figure 2:Accuracy changes after merging compared to the baseline. Generally, datasets directly requiring math-related and text-dominant capabilities, such as textbook QA and math word problem, exhibit clear improvements while domains requiring visual processing such as figure QA show performance degradation.",
                "position": 854
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/skill_accuracy_length_scatter_percent_llava_mathvista.png",
                "caption": "Figure 3:The relationship between answer length change (characters) and accuracy improvement after merging (The x-axis represents the relative change from the original answer, while the y-axis shows the absolute change in accuracy), classified by task and skills.",
                "position": 866
            }
        ]
    },
    {
        "header": "5Merging as Interpretability Tool ‚Äì Dive into the inner parameter space of LLaVA",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05464/x3.png",
                "caption": "Figure 4:LLaVA ‚Üí LLaMA(11and33): the accuracy changes after replacing the parameters of eachMLP(11) andAttention(33) layer of the LLaVA model with parameters from LLaMA. We find that masking out the early layers has a greater impact on general VQA tasks than masking the later layers, suggesting thatperception abilities gained from LLaVA-sft training are primarily located in the early layers.Dart-Merged LLaVA ‚Üí LLaVA(22and44): the accuracy changes after replacing eachMLP(22) andAttention layer(44) of the Dart-Merged LLaVA model to that of LLaVA. A significant drop in accuracy in math-targeted VQA tasks is observedfrom 5 layer onwards.(highlighted in blue), suggesting that thereasoning abilityis mainly located on these layers.",
                "position": 874
            },
            {
                "img": "https://arxiv.org/html/2505.05464/x4.png",
                "caption": "Figure 5:LLaVA ‚Üí 1/N(55and77): the accuracy changes after replacing the parameters of eachMLP(55) andAttention(77) layer of the LLaVA model with1N1ùëÅ\\frac{1}{N}divide start_ARG 1 end_ARG start_ARG italic_N end_ARG, whereNùëÅNitalic_Nis the first dimension of the weight matrix. The highlighted red area shows that early-to-middle layers are more crucial for both general and math-related tasks in the LLaVA model, as evidenced by the significant drops, i.e., 0.25 absolute accuracy drop in general tasks and 0.10 in math-targeted VQA.Dart-Merged LLaVA ‚Üí 1/N(66and88): the accuracy changes after replacing the parameters of eachMLP(66) andAttention(88) layer of the Dart-Merged LLaVA model with1N1ùëÅ\\frac{1}{N}divide start_ARG 1 end_ARG start_ARG italic_N end_ARG.\nComparing before and after merging when applied masking out, we observe a larger drop in accuracy in math-targeted VQA tasksacross all layers(highlighted in blue), suggesting that the contribution of all most all layers to math reasoning has increased.",
                "position": 880
            },
            {
                "img": "https://arxiv.org/html/2505.05464/x5.png",
                "caption": "Figure 6:Qualitative study: three examples that can be fixed by merging with Dart(Tong et¬†al.,2024).",
                "position": 907
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AThe checkpoints used in experiments",
        "images": []
    },
    {
        "header": "Appendix BMore analysis for MathVista",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/task.jpg",
                "caption": "Figure 7:The accuracy difference after merging across several subtasks in MathVista for LLaVA.",
                "position": 1757
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/task.jpg",
                "caption": "Figure 7:The accuracy difference after merging across several subtasks in MathVista for LLaVA.",
                "position": 1760
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/task_accuracy_length_scatter_percent_llava_mathvista_percentage.png",
                "caption": "Figure 8:The relationship between answer length change and accuracy improvement after merging, classified by task.",
                "position": 1765
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/skill_accuracy_length_diff_llava_mathvista.png",
                "caption": "Figure 9:The relationship between answer length change and accuracy improvement after merging, classified by task.",
                "position": 1771
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/skill_accuracy_length_diff_llava_mathvista.png",
                "caption": "Figure 9:The relationship between answer length change and accuracy improvement after merging, classified by task.",
                "position": 1774
            },
            {
                "img": "https://arxiv.org/html/2505.05464/extracted/6423197/Figures/ties_draw.png",
                "caption": "Figure 10:Performance comparison of TIES and linear merging methods across MathVerse (Text-Dominant) and MathVision benchmarks. Baseline presents the result ofLLaVA-Next-LLaMA3-8B. Linear shows the result of merging Dart-prop vector with hyperparameters of(0.9,0.1)0.90.1(0.9,0.1)( 0.9 , 0.1 ). Performance reached by TIES merging with the same two task vectors are labeled as the hyperparameter pair used.",
                "position": 1779
            }
        ]
    },
    {
        "header": "Appendix CDifferent merging methods perform generally comparable",
        "images": []
    },
    {
        "header": "Appendix DMore results on MM-Math",
        "images": []
    },
    {
        "header": "Appendix EAdditional results demonstrating generalization from logical to mathematical reasoning",
        "images": []
    },
    {
        "header": "Appendix FSignificance Test",
        "images": []
    }
]