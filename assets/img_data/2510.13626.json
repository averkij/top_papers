[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2How Do Single-Dimension Perturbations Affect VLA Models?",
        "images": []
    },
    {
        "header": "3Do contemporary VLA Models truly pay attention to visual inputs?",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x1.png",
                "caption": "Figure 1:Robustness to object layout perturbations. Comparison of different models under confounding and displacement perturbations, as well as their overall robustness.",
                "position": 633
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x2.png",
                "caption": "Figure 2:Illumination robustness and extreme ablation tests. The termLightdenotes the condition with light perturbation applied.3rd BlackandAll Blackrepresent conditions where only the third-view image is masked and where images from both views are masked, respectively.",
                "position": 642
            }
        ]
    },
    {
        "header": "4Do Contemporary VLA Models Truly Follow Language Instructions?",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x3.png",
                "caption": "Figure 3:Accuracy of different models on instruction removed (a) and target modified (b) tasks. Light bars: original success rate with language instruction; (a) dark bars: success rate after removing the instruction; (b) Dark bars: success rate under altered task goal and instruction (task substitution).",
                "position": 677
            }
        ]
    },
    {
        "header": "5Does There Exist Compositional Generalization Gap Across Multi-Dimensional Perturbations?",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x4.png",
                "caption": "Figure 4:Heatmap of conditional probabilities under pairwise perturbations. Upper triangular entries represent independence-based products of single-dimension probabilities, while lower triangular entries show actual joint outcomes.",
                "position": 829
            }
        ]
    },
    {
        "header": "6LIBERO-Plus",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x5.png",
                "caption": "Figure 5:Model performance trends across perturbation difficulty levels. The line plots show the success rate of each model as the intensity of four different perturbation dimensions increases.",
                "position": 860
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x6.png",
                "caption": "Figure 6:Architecture of the LIBERO-Plu benchmark, comprising 10,030 tasks organized across seven perturbation factors and twenty-one underlying components.",
                "position": 863
            }
        ]
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APerturbation Dimensions",
        "images": []
    },
    {
        "header": "Appendix BModel Details",
        "images": []
    },
    {
        "header": "Appendix CPerturbations and Benchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/imgs/difficulty_pies.png",
                "caption": "Figure 7:Proportion of tasks per difficulty level across the seven generalization dimensions.",
                "position": 2319
            }
        ]
    },
    {
        "header": "Appendix DTraining Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x7.png",
                "caption": "Figure 8:Model performance trends across perturbation difficulty levels. The line plots show the success rate of each model as the intensity of all seven different perturbation dimensions increases.",
                "position": 2397
            },
            {
                "img": "https://arxiv.org/html/2510.13626/imgs/dataset_action.png",
                "caption": "Figure 9:Distribution of the 7-dimensional robot actions in the generalized dataset. Plots are arranged from top to bottom and left to right, corresponding to action dimensions 1–7.",
                "position": 2414
            }
        ]
    },
    {
        "header": "Appendix EGoal Replacement Rollout Cases Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x8.png",
                "caption": "Figure 10:Behavioral Analysis of Goal Replacement Failures. Case studies showing model responses to modified instructions. For each pair: original→new instruction (above); actually executed behavior (below). The consistent execution of original tasks despite changed targets indicates shallow language processing and strong bias toward memorized visual-action associations.",
                "position": 2469
            }
        ]
    },
    {
        "header": "Appendix FDetails of the Compositional Generalization Experiments",
        "images": []
    },
    {
        "header": "Appendix GFailure Cases Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13626/x9.png",
                "caption": "Figure 11:Rendering results with background texture perturbations. The top-left image is the original; the others show results with the textures as labeled.",
                "position": 2739
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x10.png",
                "caption": "Figure 12:Rendering results under background texture perturbations, comparing the original image (top-left) with transformed versions. The labels denote the following transformation parameters: hr (horizontal rotation angle), vr (vertical rotation angle), dis (distance pulled away), chr (in-place horizontal rotation angle), and cvr (in-place vertical rotation angle).",
                "position": 2742
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x11.png",
                "caption": "Figure 13:Rendering results with robot initial state perturbations. The top-left image is the original; the others show results with the norm of the change in the robot’s joint angles as labeled.",
                "position": 2745
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x12.png",
                "caption": "Figure 14:Rendering results with light perturbations. The top-left image is the original; the others show results with the relative change as labeled.",
                "position": 2748
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x13.png",
                "caption": "Figure 15:Rendering results with sensor noise perturbations. The top-left image is the original; the others show results corresponding to the type and severity of the applied noise, as indicated by the labels.",
                "position": 2751
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x14.png",
                "caption": "Figure 16:Rendering results with object layout perturbations. The top-left image is the original; the others show results with the number of added objects as labeled.",
                "position": 2754
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x15.png",
                "caption": "Figure 17:Failure Mode Analysis Across Perturbation Types. Visualization of characteristic failure patterns induced by each perturbation dimension, revealing distinct vulnerability profiles: camera shifts cause viewpoint-dependent localization errors; language modifications lead to semantic misinterpretations; lighting variations introduce shadow artifacts; sensor noise produces feature corruption; initial state changes affect trajectory planning; and object distractors trigger recognition confusion.",
                "position": 2757
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x16.png",
                "caption": "Figure 18:Failure Mode Analysis Across Perturbation Types. Visualization of characteristic failure patterns induced by each perturbation dimension, revealing distinct vulnerability profiles: camera shifts cause viewpoint-dependent localization errors; language modifications lead to semantic misinterpretations; lighting variations introduce shadow artifacts; sensor noise produces feature corruption; initial state changes affect trajectory planning; and object distractors trigger recognition confusion.",
                "position": 2760
            },
            {
                "img": "https://arxiv.org/html/2510.13626/x17.png",
                "caption": "Figure 19:Failure Mode Analysis Across Perturbation Types. Visualization of characteristic failure patterns induced by each perturbation dimension, revealing distinct vulnerability profiles: camera shifts cause viewpoint-dependent object localization inaccuracy; object distractors provoke recognition confusion and mislocalization of the target, in some cases leading to incorrect collision-prone trajectories when arm motion flexibility is insufficient.",
                "position": 2763
            }
        ]
    },
    {
        "header": "Appendix HDetailed results of LIBERO-Plus",
        "images": []
    }
]