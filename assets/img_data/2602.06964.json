[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06964/x1.png",
                "caption": "Figure 1:Generative Latent Prior:an activation model trained with agenerativediffusion objective.\nThis activation diffusion model can be used as a prior for downstream tasks, like on-manifold steering, and exhibits reliable power-law scaling.",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x2.png",
                "caption": "a(a) Training Loss on FineWeb",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x2.png",
                "caption": "a(a) Training Loss on FineWeb",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x3.png",
                "caption": "b(b) On-Manifold Sentiment Steering",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x4.png",
                "caption": "c(c) 1-D Probe for 113 Binary Tasks",
                "position": 153
            }
        ]
    },
    {
        "header": "2Generative Latent Prior",
        "images": []
    },
    {
        "header": "3ScalingGLP",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06964/x5.jpg",
                "caption": "aNum Steps = 1",
                "position": 442
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x5.jpg",
                "caption": "aNum Steps = 1",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x6.jpg",
                "caption": "bNum Steps = 4",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x7.jpg",
                "caption": "cNum Steps = 20",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x8.jpg",
                "caption": "dNum Steps = 1000",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x9.png",
                "caption": "eNum Steps vs. Frechet Distance",
                "position": 467
            }
        ]
    },
    {
        "header": "4On-Manifold Steering withGLP",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06964/x10.png",
                "caption": "Figure 5:Improving SAE steering in Llama8B-Base. We plot the Pareto frontier of concept vs. fluency as we vary the steering coefficient.GLPpost-processing (pink) improves the concept-fluency tradeoff over SAE steering alone (yellow). Concept and fluency are scored by an LLM judge on a 0-2 scale(Wu et al.,2025). Error bars show 95% bootstrap CIs.",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x11.png",
                "caption": "Figure 6:Eliciting personas in Llama8B-Instruct.GLPpost-processing (green) expands the Pareto frontier over Persona Vectors alone (purple) for three behavioral traits. Concept and fluency are scored by an LLM judge on a 0-100 scaleChen et al. (2025). Error bars show 95% bootstrap CIs.",
                "position": 726
            }
        ]
    },
    {
        "header": "5Interpreting withGLP",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix APseudocode",
        "images": []
    },
    {
        "header": "Appendix BScaling: Extended Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06964/x12.png",
                "caption": "a(a) Training Loss on FineWeb",
                "position": 2653
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x12.png",
                "caption": "a(a) Training Loss on FineWeb",
                "position": 2656
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x13.png",
                "caption": "b(b) On-Manifold Sentiment Steering",
                "position": 2661
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x14.png",
                "caption": "c(c) 1-D Probe for 113 Binary Tasks",
                "position": 2666
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x15.png",
                "caption": "Exchange Rate of Multi-Layer / Single-LayerGLP",
                "position": 2679
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x15.png",
                "caption": "Exchange Rate of Multi-Layer / Single-LayerGLP",
                "position": 2682
            },
            {
                "img": "https://arxiv.org/html/2602.06964/figures/scaling/pca/llama8b_sae.jpg",
                "caption": "PCA of SAE Reconstructions",
                "position": 2691
            }
        ]
    },
    {
        "header": "Appendix CSteering: Extended Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06964/x16.png",
                "caption": "a(a)",
                "position": 2767
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x16.png",
                "caption": "a(a)",
                "position": 2770
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x17.png",
                "caption": "b(b)",
                "position": 2775
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x18.png",
                "caption": "c(c)",
                "position": 2780
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x19.png",
                "caption": "Figure 12:Controlling sentiment in Llama8B-Base. We score concept with a five-point sentiment classifier (higher is better) and fluency with the negative log-likelihood under the same LLM (lower is better). Error bars show 95% bootstrap confidence intervals with 10k resamples.",
                "position": 2792
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x19.png",
                "caption": "Figure 12:Controlling sentiment in Llama8B-Base. We score concept with a five-point sentiment classifier (higher is better) and fluency with the negative log-likelihood under the same LLM (lower is better). Error bars show 95% bootstrap confidence intervals with 10k resamples.",
                "position": 2793
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x20.png",
                "caption": "Effect of Scaling by Steering Coefficient Regime",
                "position": 2797
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x21.png",
                "caption": "a(a) Scaling FLOPs, More Noisy (t=0.5)",
                "position": 3474
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x21.png",
                "caption": "a(a) Scaling FLOPs, More Noisy (t=0.5)",
                "position": 3477
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x22.png",
                "caption": "b(b) Scaling FLOPs, More Clean (t=0.1)",
                "position": 3482
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x23.png",
                "caption": "c(c) Scaling Loss, More Noisy (t=0.5)",
                "position": 3488
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x24.png",
                "caption": "d(d) Scaling Loss, More Clean (t=0.1)",
                "position": 3493
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x25.png",
                "caption": "a(a) Scaling FLOPs, More Noisy (t=0.5)",
                "position": 3500
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x25.png",
                "caption": "a(a) Scaling FLOPs, More Noisy (t=0.5)",
                "position": 3503
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x26.png",
                "caption": "b(b) Scaling FLOPs, More Clean (t=0.1)",
                "position": 3508
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x27.png",
                "caption": "c(c) Scaling Loss, More Noisy (t=0.5)",
                "position": 3514
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x28.png",
                "caption": "d(d) Scaling Loss, More Clean (t=0.1)",
                "position": 3519
            },
            {
                "img": "https://arxiv.org/html/2602.06964/x29.png",
                "caption": "Locations of Top-1 Diffusion Meta-Neurons Across Layers",
                "position": 3527
            }
        ]
    },
    {
        "header": "Appendix DProbing: Extended Results",
        "images": []
    }
]