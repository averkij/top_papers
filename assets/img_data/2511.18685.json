[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18685/x1.png",
                "caption": "Figure 1:Illustration of CFG-Bench’s focus on embodied intelligence over descriptive accuracy. The top part shows how FAVOR-Bench annotates and questions from a third-person perspective, a task which current MLLMs can often solve. In contrast, the bottom part demonstrates CFG-Bench’s fine-grained annotation and first-person scenario questions, which probes for the actionable physical and intentional details necessary for embodied agents. Current MLLMs struggle to master the crucial fine-grained details required for physical interaction.",
                "position": 104
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3CFG-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18685/x2.png",
                "caption": "Figure 2:Task demonstration of CFG-Bench. Note:all QA pairs, including those above, are slightly simplified for clarity and brevity.",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x3.png",
                "caption": "Figure 3:Data statistics of CFG-Bench. (a) Distribution and video length statistics of the five datasets. (b) The distribution of tasks across four tiers. AW means average words of questions.",
                "position": 377
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x4.png",
                "caption": "Figure 4:Pipeline of dataset generation. Both annotation and QA generation are human-AI collaborative workflow. Open-ended and closed-ended questions share the same pipeline at the early stage.",
                "position": 392
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18685/x5.png",
                "caption": "Figure 5:The qualitative analysis of QA Forms.",
                "position": 1022
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x6.png",
                "caption": "Figure 6:The results of caption generation before and after SFT.",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x7.png",
                "caption": "Figure 7:Error Analysis. We show the recurring failure modes for each tier, along with the corresponding examples.",
                "position": 1115
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "AAppendix Outline",
        "images": []
    },
    {
        "header": "BMore Experimental Analysis",
        "images": []
    },
    {
        "header": "CMore Details of CFG-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18685/x8.png",
                "caption": "Figure S1:The statistics of words related to fine-grained actions with the highest frequency from four aspects, i.e., object parts, manipulation types, dynamic qualities, action directions.",
                "position": 1432
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x9.png",
                "caption": "Figure S2:The visualizations of the selected-out samples for three reasons: easy QA without visual grounding, no correct answer, and multiple matching answers.",
                "position": 2396
            }
        ]
    },
    {
        "header": "DMore Samples of CFG-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18685/x10.png",
                "caption": "Figure S3:Examples of each tasks in Physical Interaction (Tier 1).",
                "position": 2407
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x11.png",
                "caption": "Figure S4:Examples of each tasks in Temporal-Causal Relation (Tier 2).",
                "position": 2410
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x12.png",
                "caption": "Figure S5:Examples of each tasks in Intentional Understanding (Tier 3).",
                "position": 2413
            },
            {
                "img": "https://arxiv.org/html/2511.18685/x13.png",
                "caption": "Figure S6:Examples of each tasks in Evaluative Judgment (Tier 4).",
                "position": 2416
            }
        ]
    },
    {
        "header": "ELimitations and Broader Impacts",
        "images": []
    }
]