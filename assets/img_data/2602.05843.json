[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/x1.png",
                "caption": "Figure 1:Comparison between deductive and inductive settings in multi-turn agentic tasks.",
                "position": 347
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3OdysseyArena",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/x2.png",
                "caption": "Figure 2:Demonstrations of fourOdysseyArenaenvironments: Turn On Lights, AI Trading, Energy Dispatch, and Repo System. For clarity, we omit the task prompts here and present only the interaction trajectories. Full prompts are provided in AppendixC.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x3.png",
                "caption": "Figure 3:Overview of the benchmark architecture, illustrating the environment configuration initialization (left) and the interaction loop between the LLM agent and the environment step logic (right).",
                "position": 667
            }
        ]
    },
    {
        "header": "4OdysseyArena-LiteandOdysseyArena-Challenge",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/gemini.png",
                "caption": "Table 2:Performance comparison on four environments. We provide three different reasoning effort of gpt-oss-120b. ForAI Tradingenvironment, we report the profit rate and pass@4 is calculated based on the highest profit of each task. For other three environments, we report the success rate.Colored Rowsrepresent proprietary models. The best results are inbold.",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/gpt.png",
                "caption": "",
                "position": 859
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/deepseek.png",
                "caption": "",
                "position": 899
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/grok.png",
                "caption": "",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/qwen.png",
                "caption": "",
                "position": 926
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/glm.png",
                "caption": "",
                "position": 965
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/llama.png",
                "caption": "",
                "position": 991
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/x4.png",
                "caption": "Figure 4:Success rate comparison of w/ and w/o rules inTurn On Lights. We select Llama 3.3 70B Instruct, GLM-4-32B-0414, Qwen3-235B-A22B-Instruct, DeepSeek-V3.2, Grok 4 Fast, GPT-5, Gemini 3 Pro Preview for illustration.",
                "position": 1053
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x5.png",
                "caption": "Figure 5:Task success status (based onpass@4) of different tasks inTurn On Lights. Each row represents: (a) Human, (b) Gemini3 Pro Preview, (c) GPT-5, (d) Gemini 2.5 Pro, (e) gpt-oss-120b (high), (f) DeepSeek-V3.2, (g) Grok 4 Fast, (h) Qwen3-235B-A22B-Instruct, (i) gpt-oss-120b (medium), (j) Qwen3-30B-A3B-Instruct, (k) GLM-4-32B-0414, (l) gpt-oss-120b (low), (m) Llama 3.3 70B Instruct, (n) Qwen3-4B-Instruct, (o) Llama 3.1 8B Instruct, (p) GLM-4-9B-Chat.Dark greencells indicate tasks solved by Human.Greencells indicate tasks solved by LLM agents.Graycells indicate unsolved tasks. for each subset (Easy, Medium and Hard), we report the average success rate across all LLMs.",
                "position": 1084
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/x6.png",
                "caption": "Figure 6:Success Rate against Step in two environments.",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x7.png",
                "caption": "Figure 7:Model performance is significantly related to loop ratio. Infeasible region indicates that a high Loop Ratio results in an inability to solve long-horizon inductive reasoning tasks.",
                "position": 1119
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATask Curation",
        "images": []
    },
    {
        "header": "Appendix BDetails of Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/gemini.png",
                "caption": "Table 4:Performance comparison between w/o rules and w/ rules settings. We provide three different reasoning effort of gpt-oss-120b. ForAI Tradingenvironment, we report the profit rate and pass@4 is calculated based on the highest profit of each task. For other three environments, we report the success rate.Colored Rowsrepresent proprietary models.",
                "position": 2307
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x8.png",
                "caption": "Figure 8:All data for Success Rate against Step. We do not plot forEnergy Dispatchenvironment due to its complex success conditions.",
                "position": 2540
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x9.png",
                "caption": "Figure 9:Step density distribution for LLM models: (a) Gemini 3 Pro Preview, (b) GPT-5, (c) Gemini 2.5 Pro, (d) gpt-oss-120b (high), (e) DeepSeek-V3.2, (f) Grok 4 Fast, (g) Qwen3-235B-A22B-Instruct, (h) gpt-oss-120b (medium), (i) Qwen3-30B-A3B-Instruct, (j) GLM-4-32B-0414, (k) gpt-oss-120b (low), (l) Llama 3.3 70B Instruct, (m) Qwen3-4B-Instruct (n) Llama 3.1 8B Instruct, (o) GLM-4-9B-Chat.",
                "position": 2570
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x10.png",
                "caption": "Figure 10:Task success status (based onpass@4). Each row represents: (a) Human, (b) Gemini3 Pro Preview, (c) GPT-5, (d) Gemini 2.5 Pro, (e) gpt-oss-120b (high), (f) DeepSeek-V3.2, (g) Grok 4 Fast, (h) Qwen3-235B-A22B-Instruct, (i) gpt-oss-120b (medium), (j) Qwen3-30B-A3B-Instruct, (k) GLM-4-32B-0414, (l) gpt-oss-120b (low), (m) Llama 3.3 70B Instruct, (n) Qwen3-4B-Instruct, (o) Llama 3.1 8B Instruct, (p) GLM-4-9B-Chat.Dark greencells indicate tasks solved by Human.Greencells indicate tasks solved by LLM agents.Graycells indicate unsolved tasks. We report the average success rate inRepo Systemacross all LLMs for each subset (Easy, Medium and Hard).",
                "position": 2573
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x11.png",
                "caption": "Figure 11:The line chart represents token usage and the bar chart represents token efficiency. Token Usage is measured in units of10610^{6}, while Token Efficiency is reported in units of10−610^{-6}.",
                "position": 2641
            },
            {
                "img": "https://arxiv.org/html/2602.05843/x12.png",
                "caption": "Figure 12:Error types of Gemini 3 Pro Preview. (a) Behavior Stagnation, (b) Error Credit Assignment, (c) Long-Horizon Dependence Decay, (d) Local Optima.",
                "position": 2644
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/gemini.png",
                "caption": "Table 5:Comparison of different strategies, human and models. For LLM models, we provide the best results from both proprietary models and open-source models.Δ\\Deltarepresents the delta of average profit ratio against optimal strategy.Colored Rowsrepresent proprietary models.",
                "position": 2699
            },
            {
                "img": "https://arxiv.org/html/2602.05843/Figures/gemini.png",
                "caption": "Table 6:Performance of three LLMs inRepo SystemofOdysseyArena-ChallengeandOdysseyArena-Lite.Colored Rowrepresents proprietary models. We additionally provide the performance gap.",
                "position": 2790
            }
        ]
    },
    {
        "header": "Appendix CMain Results Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05843/x13.png",
                "caption": "Figure 13:Screenshot of the user interface and instructions provided to the human annotators.",
                "position": 3198
            }
        ]
    },
    {
        "header": "Appendix DHuman Annotation Details",
        "images": []
    }
]