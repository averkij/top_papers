[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06471/figs/RM4MT.png",
                "caption": "Figure 1:Illustration of the effectiveness of test-time scaling in reasoning models for machine translation. (1) TTS for general-purpose RMs yields only a small initial performance gain, but quickly plateauing as increased inference cost. (2) Forcing RMs to reason beyond their natural stopping point degrades quality by introducing noise. (3) In contrast, TTS becomes effective when applied to RMs specifically developed for MT. (4) TTS shows improvements in post-editing workflows. All these highlight TTSâ€™s value in MT lies in task-specialized models and multi-step self-correction, rather than as a robust strategy for enhancing single-pass translation with general-purpose RMs.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06471/x1.png",
                "caption": "Figure 2:Average GRB scores of Qwen-3 and Cogito models across all datasets with varying thinking budgets.",
                "position": 395
            }
        ]
    },
    {
        "header": "3Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06471/x2.png",
                "caption": "(a)",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x2.png",
                "caption": "(a)",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x3.png",
                "caption": "(b)",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x4.png",
                "caption": "Figure 4:Performance (dashed lines, right axis) and actual generated thinking tokens (solid lines, left axis) of DRT models across 3 literary translation tasks.",
                "position": 467
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x5.png",
                "caption": "(a)GRB scores for post-editing across Qwen-3 models.",
                "position": 893
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x5.png",
                "caption": "(a)GRB scores for post-editing across Qwen-3 models.",
                "position": 896
            },
            {
                "img": "https://arxiv.org/html/2510.06471/x6.png",
                "caption": "(b)GRF scores for post-editing across Qwen-3 models.",
                "position": 901
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Prompts",
        "images": []
    },
    {
        "header": "Appendix BEvaluation Results of General-purpose Models",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Results and Thinking Token Statistics of DRT Models on Literary Translation Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06471/x7.png",
                "caption": "Figure 6:Performance and actual generated thinking tokens of DRT models across 3 literary translation tasks.",
                "position": 2190
            }
        ]
    },
    {
        "header": "Appendix DPost-editing Prompts and Detailed Results",
        "images": []
    }
]