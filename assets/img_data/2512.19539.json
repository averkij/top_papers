[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19539/x1.png",
                "caption": "Figure 1:Given a story script with per-shot text descriptions,StoryMemgenerates appealing minute-long, multi-shot narrative videos with highly coherent characters and cinematic visual quality. This is achieved through shot-by-shot generation using a memory-conditioned single-shot video diffusion model.",
                "position": 110
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19539/x2.png",
                "caption": "Figure 2:Overview ofStoryMem.StoryMemgenerates each shot conditioned on a memory bank that stores keyframes from previously generated shots. During generation, the selected memory frames are encoded by a 3D VAE, fused with noisy video latents and binary masks, and fed into a LoRA-finetuned memory-conditioned Video DiT to synthesize the current shot. After generating each shot, semantic keyframe selection and aesthetic preference filtering are applied to obtain informative and reliable memory frames, enabling long-range cross-shot consistency and natural narrative progression. By iteratively generating shots with memory updates,StoryMemproduces coherent minute-long, multi-shot story videos.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2512.19539/x3.png",
                "caption": "Figure 3:Qualitative comparison.OurStoryMemgenerates coherent multi-scene, multi-shot story videos aligned with per-shot descriptions. In contrast, the pretrained model and keyframe-based baselines fail to preserve long-term character and scene consistency, while HoloCine[31]exhibits noticeable degradation in visual quality.",
                "position": 356
            },
            {
                "img": "https://arxiv.org/html/2512.19539/x4.png",
                "caption": "Figure 4:User study.Our method is consistently preferred over all baselines in most dimensions, highlighting its superior multi-shot consistency and narrative coherence.Winindicates that users prefer our method over the baseline,Tieindicates no significant preference, andLoseindicates that users prefer the baseline.",
                "position": 463
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19539/x5.png",
                "caption": "Figure 5:MR2V results.StoryMemenables customized story video generation by using reference images as the initial memory. The real-person reference images were used with proper consent from the individuals involved.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2512.19539/x6.png",
                "caption": "Figure 6:Ablation study.Top: our method effectively preserves newly emerged character consistency. Bottom: our method can maintain long-term visual fidelity. The selected keyframe in [Shot 1] is highlighted in blue box.",
                "position": 539
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19539/x7.png",
                "caption": "Figure 7:Limitation. Top: Our method may struggle to preserve consistency in complex multi-character scenarios where pure visual memory becomes ambiguous. Bottom: Explicitly providing character details in each shot prompt will mitigate the problem.",
                "position": 624
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6More Qualitative Results",
        "images": []
    },
    {
        "header": "7More Details of ST-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19539/x8.png",
                "caption": "Figure 8:Additional qualitative comparison.",
                "position": 1530
            },
            {
                "img": "https://arxiv.org/html/2512.19539/x9.png",
                "caption": "Figure 9:More qualitative results.",
                "position": 1533
            }
        ]
    },
    {
        "header": "8Limitation and Future Work",
        "images": []
    }
]