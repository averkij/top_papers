[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x1.png",
                "caption": "Table 1:Survey of prominent datasetsused for training visual similarity metrics. All are organized based on attribute similarity, whereas ours focuses on relational similarity.",
                "position": 77
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x2.png",
                "caption": "",
                "position": 133
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x3.png",
                "caption": "",
                "position": 157
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x4.png",
                "caption": "",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x5.png",
                "caption": "",
                "position": 208
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Relational Visual Similarity",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x6.png",
                "caption": "Figure 1:Overall pipeline.(a) We train an image filtering model to select high-quality relational images from LAION-2B[laion5b]. (b) Anonymous captioning model is trained on groups of images that share the same underlying logic, pairing all images in each group with the same anonymous caption. (c) Training relational visual similarity (relsim) model involves a contrastive loss between image features and their corresponding anonymous captions.",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x7.png",
                "caption": "Figure 2:Examples of relationally interesting vs. ordinary images.",
                "position": 311
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x8.png",
                "caption": "Figure 3:Writing an anonymous caption is hard from a single image, but easier with an image group where the pattern is clear.",
                "position": 336
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x9.png",
                "caption": "Figure 4:Attributes vs. Relational Visual Image Retrieval.Visualization of nearest neighbor using different visual similarity metrics. As can be seen, only ours understands and can detect the relational similarity.",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x10.png",
                "caption": "Figure 5:Relational visual similarity performance.All existing image similarity metrics fail to capture relational similarity, even after being tuned. Our final model (relsim) which leverages knowledge from VLMs, achieves the highest score (6.77).",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x11.png",
                "caption": "Figure 6:Similarity spaceshowing different kinds ofvisual similarityin terms of degree of relational vs. attribute similarity.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x12.png",
                "caption": "Figure 7:User study.AB testing shows that our model aligns significantly better with human perception of relational similarity compared to the baselines.",
                "position": 435
            }
        ]
    },
    {
        "header": "5Applications",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x13.png",
                "caption": "Figure 8:Relational image retrieval. We demonstrate that image can also be searched based on logic or abstraction (relational-based), not only perceptual or semantic similarity.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x14.png",
                "caption": "Figure 9:Qualitative results for analogical image generation. Proprietary models are generally better at understanding and performing sophisticated relational transformations, while open-sourced models still lag behind.",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x15.png",
                "caption": "Figure 10:Analogical image generation. Unlike standard image editing, which modifies surface attributes, analogical generation transfers deeper relational structures and conceptual ideas.",
                "position": 459
            }
        ]
    },
    {
        "header": "6Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Data Attributions",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x16.png",
                "caption": "Figure 11:Examples of interesting and uninteresting images filtered by the finetuned Image Filtering model.",
                "position": 574
            }
        ]
    },
    {
        "header": "7Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07833/x17.png",
                "caption": "Figure 12:Example of predicted anonymous caption",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x18.png",
                "caption": "Figure 13:Additional results for image retrieval (1).",
                "position": 694
            },
            {
                "img": "https://arxiv.org/html/2512.07833/x19.png",
                "caption": "Figure 14:Additional results for image retrieval (2).",
                "position": 697
            }
        ]
    },
    {
        "header": "8Additional Results",
        "images": []
    }
]