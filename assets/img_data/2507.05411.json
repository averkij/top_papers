[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05411/x1.png",
                "caption": "Figure 1.Specifying MoE transformer in AXLearn. Red components are reused from the the specification of standard transformer. In AXLearn, a user script that defines MoE only needs to specify the green parts of the neural network.",
                "position": 265
            }
        ]
    },
    {
        "header": "3.Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05411/x2.png",
                "caption": "Figure 2.AXLearnâ€™s system diagram. The blue components belong to AXLearn.",
                "position": 356
            }
        ]
    },
    {
        "header": "4.AXLearn Composer",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05411/extracted/6594419/figures/context.png",
                "caption": "Figure 3.Invocation Context. Module invocations push contexts to the stack, which retrieve child states, split PRNG keys, and create child output collections. Upon returning, contexts are popped, collecting outputs into the parent collection. The context stack can be programmatically traversed to retrieve shared state, allowing features like tied weights to preserve encapsulation.",
                "position": 552
            }
        ]
    },
    {
        "header": "5.AXLearn Runtime",
        "images": []
    },
    {
        "header": "6.Unifying Training and Inference",
        "images": []
    },
    {
        "header": "7.Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05411/x3.png",
                "caption": "(a)Model A (70B)",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2507.05411/x3.png",
                "caption": "(a)Model A (70B)",
                "position": 936
            },
            {
                "img": "https://arxiv.org/html/2507.05411/x4.png",
                "caption": "(b)Model B (150B)",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2507.05411/x5.png",
                "caption": "Figure 5.Comparing AXLearn with vLLM on inference throughput on TPUs.",
                "position": 988
            }
        ]
    },
    {
        "header": "8.Related Work",
        "images": []
    },
    {
        "header": "9.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMesh Rules",
        "images": []
    },
    {
        "header": "Appendix BLoC Analysis",
        "images": []
    }
]