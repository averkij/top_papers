[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23924/images/Motivation_new.jpg",
                "caption": "Figure 1:(a)and(b)illustrate the vertical and front view of Step-Position Heatmap of Token Probability, showing the frequency of<EOS>appearing at each position per step.(c)depicts the performance comparison of semi-AR and full-diffusion decoding strategies.(d)shows the average confidence of tokens as denoising progresses.",
                "position": 86
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23924/images/Decoding.jpg",
                "caption": "Figure 2:(a)EOS Early Rejection.(b)Ascending Step-Size Scheduler for fewer inference steps.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2509.23924/images/Algorithm.jpg",
                "caption": "Figure 3:(a) The causality gurarantee the consistency between AR LLMs’ rollout and optimization. (b) Two inconsistency trajectories RL training for MDLMs, we refer to①①as one-stepxS′→xSx^{\\prime}_{S}\\rightarrow x_{S}and②②as one-stepx0→xSx_{0}\\rightarrow x_{S}. (c) Consistency Trajectory Group Relative Policy Optimization.",
                "position": 221
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23924/images/EOSER.jpg",
                "caption": "Table 2:Performance of fewer decoding steps on Countdown, GSM8K, MATH500 and Sudoku:We report results under various decoding strategies and training algorithms when the decoding steps are set tolog2⁡L\\log_{2}L. For ascending step-size scheduler, the steps are set tolog2⁡L\\log_{2}L, whereas for uniform step-size ones, we fix the steps at 8 to ensure divisibility with both 128 and 256.",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2509.23924/images/EOSER.jpg",
                "caption": "Figure 4:The Step-Position Heatmap of EOSER.",
                "position": 760
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Ethics Statement",
        "images": []
    },
    {
        "header": "7Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Appendix",
        "images": []
    },
    {
        "header": "Appendix ASupplementary Experiments and Discussions",
        "images": []
    },
    {
        "header": "Appendix BLimitations",
        "images": []
    },
    {
        "header": "Appendix CThe Use of Large Language Models (LLMs) Statement",
        "images": []
    },
    {
        "header": "Appendix DShowcase on Sequential and Parallel Reasoning Tasks",
        "images": []
    }
]