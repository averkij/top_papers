[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06463/x1.png",
                "caption": "Figure 1:Negative log-likelihoodforGecko-7B,Megalodon-7B,Llama2-7B andLlama2-13B, w.r.t processed tokens during training.",
                "position": 156
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background: Backbone Architectures inMega",
        "images": []
    },
    {
        "header": "3Gecko",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06463/x2.png",
                "caption": "Figure 2:Comparison of various sparse attention patterns. (a) Chunk-wise Attention: attention is restricted to separated chunks; (b) Sliding Window Attention: attention is restricted to fixed-size windows; (c) Sliding Chunk Attention: attention is assigned to both current and previous chunks.",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2601.06463/x3.png",
                "caption": "(a)Adaptive Working Memory",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2601.06463/x3.png",
                "caption": "(a)Adaptive Working Memory",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2601.06463/x4.png",
                "caption": "(b)Attention from timestepsstos+1s+1.",
                "position": 776
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06463/x5.png",
                "caption": "(a)PPL in various context lengths.",
                "position": 940
            },
            {
                "img": "https://arxiv.org/html/2601.06463/x5.png",
                "caption": "(a)PPL in various context lengths.",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2601.06463/x6.png",
                "caption": "(b)NLL Loss by token positions.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2601.06463/figs/passkey.png",
                "caption": "(a)Passkey",
                "position": 960
            },
            {
                "img": "https://arxiv.org/html/2601.06463/figs/passkey.png",
                "caption": "(a)Passkey",
                "position": 963
            },
            {
                "img": "https://arxiv.org/html/2601.06463/figs/niah.png",
                "caption": "(b)NIAH",
                "position": 968
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix:Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths",
        "images": []
    },
    {
        "header": "AAdaptive Working Memory",
        "images": []
    },
    {
        "header": "BImplementation Details",
        "images": []
    },
    {
        "header": "CExperimental Details",
        "images": []
    }
]