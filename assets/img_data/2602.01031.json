[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/pics/github-mark.png",
                "caption": "",
                "position": 105
            },
            {
                "img": "https://arxiv.org/html/2602.01031/pics/web-mark.png",
                "caption": "",
                "position": 107
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/x1.png",
                "caption": "Figure 1:Average hallucination rate onHalluHardthat contains 950 multi-turn conversations across legal, research, medical, and coding domains. WS denotes web search. Lower values are better. Our challenging benchmark reveals that even frontier LLMs like Opus-4.5 hallucinate in more than 30% of cases with web search and 60% without.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x2.png",
                "caption": "Figure 2:An example of a hallucinated claim from our judge. A claim is classified as hallucination if either reference or content grounding failure happens.",
                "position": 126
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Why a New Benchmark?",
        "images": []
    },
    {
        "header": "4Our Benchmark:HalluHard",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/x3.png",
                "caption": "Figure 3:Our multi-turn response generation pipeline. Seed queries are provided byHalluHard, and follow-up queries are generated via a user LLM.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x4.png",
                "caption": "Figure 4:Our claim-based verification pipeline. For each claim, we check whether the reference is correct and whether the claimed content is grounded in that reference.",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x5.png",
                "caption": "Figure 5:Evaluation time and cost comparison for three different LLM judge pipelines. The time and cost are gathered from evaluating 10 responses (âˆ¼\\sim120 atomic claims in total).",
                "position": 318
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/x6.png",
                "caption": "Figure 6:Per-turn hallucination rates (Legal Cases). Per-turn hallucination rates in other domains are presented in AppendixB.1.",
                "position": 605
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x7.png",
                "caption": "Figure 7:Programming language- and type-wise hallucination rate comparison between GPT-5 and GPT-5-thinkng.",
                "position": 608
            }
        ]
    },
    {
        "header": "6When Models Abstain vs Hallucinate?",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/x8.png",
                "caption": "Figure 8:Domain-specific short-form QA-style hallucination and abstention rate.",
                "position": 724
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AModel List",
        "images": []
    },
    {
        "header": "Appendix BOmitted tables and figures",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.01031/x9.png",
                "caption": "(a)Research questions",
                "position": 1588
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x9.png",
                "caption": "(a)Research questions",
                "position": 1591
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x10.png",
                "caption": "(b)Medical guidelines",
                "position": 1596
            },
            {
                "img": "https://arxiv.org/html/2602.01031/x11.png",
                "caption": "(c)Coding",
                "position": 1601
            }
        ]
    },
    {
        "header": "Appendix CTemplates and prompts",
        "images": []
    },
    {
        "header": "Appendix DThe quality of our judge",
        "images": []
    }
]