[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/extracted/6293680/fig/teaser.png",
                "caption": "",
                "position": 115
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x1.png",
                "caption": "Figure 2:An overview of our method.DeepMesh is an auto-regressive transformer composed of both self-attention and cross-attention layers. The model is pre-trained on discrete mesh tokens generated by our improved tokenization algorithm. To further enhance the quality of results, we propose a scoring standard that combines 3D metrics with human evaluation. With this standard, we annotate 5,000 preference pairs and then post-train the model with DPO to align its outputs with human preferences.",
                "position": 149
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x2.png",
                "caption": "Figure 3:Distribution of face count in training dataset.We present the distribution of face counts in our training dataset. Our dataset size is approximately 500k, with an average face count of 8k.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x3.png",
                "caption": "Figure 4:Some examples of the collected preference pairs.We annotate the preferred meshes based on their geometry completeness, surface details and wireframe structure.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x4.png",
                "caption": "Figure 5:Qualitative comparison on point cloud conditioned generation between DeepMesh and baselines.DeepMesh outperforms baselines in both generated geometry and preservation of fine-grained details. The meshes generated by ours have much more faces than others.",
                "position": 226
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x5.png",
                "caption": "Figure 6:Image-conditioned generation results of our method.Our method can generate high-fidelity meshes aligned with the input images.",
                "position": 283
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x6.png",
                "caption": "Figure 7:Diversity of generations.DeepMesh can generate meshes with diverse appearance given the same point cloud.",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x7.png",
                "caption": "Figure 8:Ablation study on the effectiveness of DPO.We can observe that while both approaches yield excellent geometry, the results generated using DPO are more visually appealing.",
                "position": 318
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x8.png",
                "caption": "Figure 9:Details of our tokenization algorithm.We first traverse mesh faces by dividing them into patches according to their connectivity and quantize each vertex of faces intorùëüritalic_rbins (in our settingr=512ùëü512r=512italic_r = 512).Then we partition the whole coordinate system into three hierarchical levels of blocks and index the quantized coordinates as offsets within each block. We merge the index of neighbor vertices if they have the identical values.",
                "position": 1593
            }
        ]
    },
    {
        "header": "Appendix ADetails of Tokenization Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x9.png",
                "caption": "Figure 10:Comparison with other tokenization algorithms in training effciency.We integrate all tokenization algorithms into our model architecture and train them on a dataset of 80 meshes for each face count category (10K, 20K, 30K, 40K). Our method achieves the fastest training time across all face count categories, demonstrating superior training efficiency.",
                "position": 1667
            }
        ]
    },
    {
        "header": "Appendix BMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix CMore Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x10.png",
                "caption": "(a)Before data curation",
                "position": 1799
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x10.png",
                "caption": "(a)Before data curation",
                "position": 1802
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x11.png",
                "caption": "(b)After data curation",
                "position": 1808
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15265/x12.png",
                "caption": "Figure 12:More results of DeepMesh.We present more high-fidelity results generated by our method.",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x13.png",
                "caption": "Figure 13:More results of DeepMesh.We present more high-fidelity results generated by our method.",
                "position": 1833
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x14.png",
                "caption": "Figure 14:High resolution results of our generated meshes.",
                "position": 1836
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x15.png",
                "caption": "Figure 15:High resolution results of our generated meshes.",
                "position": 1839
            },
            {
                "img": "https://arxiv.org/html/2503.15265/x16.png",
                "caption": "Figure 16:High resolution results of our generated meshes.",
                "position": 1842
            }
        ]
    },
    {
        "header": "Appendix EMore Results",
        "images": []
    }
]