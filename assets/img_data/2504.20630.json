[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x1.png",
                "caption": "Figure 1:ISDrama uses scripts as content, prompt audio to guide timbre, and spatial information from multimodal prompts, to create continuous multi-speaker binaural speech with dramatic prosody.",
                "position": 128
            },
            {
                "img": "https://arxiv.org/html/2504.20630/x2.png",
                "caption": "Figure 2:The pipeline of MRSDrama data collection.\nHuman double-checks exist in each process.\nNotably, all data are desensitized.",
                "position": 262
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x3.png",
                "caption": "Figure 3:The statistics of MRSDrama.\nThe position distribution is plotted on the plane defined by the listenerâ€™s forward direction and ears.",
                "position": 307
            }
        ]
    },
    {
        "header": "3Dataset: MRSDrama",
        "images": []
    },
    {
        "header": "4Method: ISDrama",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x4.png",
                "caption": "Figure 4:The architecture of ISDrama.\nIn Figure (a), DP & LR means duration predictor and length regulator.\nIn Figure (b), the ODE Solver, autoencoder decoder, and vocoder generate predicted audio from Gaussian noise with conditions during inference.\nIn Figure (c), MPE is the Multimodal Pose Encoder, while IDT denotes the Immersive Drama Transformer.\nMPE predicts content duration and segments the inputs.\nThen IDL coherently generates the complete drama.\nIn Figure (d), FAN denotes Fourier Analysis Networks.",
                "position": 362
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APreliminaries",
        "images": []
    },
    {
        "header": "Appendix BDataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x5.png",
                "caption": "Figure 5:The extended statistics of MRSDrama.",
                "position": 2329
            },
            {
                "img": "https://arxiv.org/html/2504.20630/x6.png",
                "caption": "Figure 6:The binaural recording device we used.",
                "position": 2334
            }
        ]
    },
    {
        "header": "Appendix CModel Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x7.png",
                "caption": "Figure 7:Screenshot of monaural speech evaluation.",
                "position": 2617
            },
            {
                "img": "https://arxiv.org/html/2504.20630/x8.png",
                "caption": "Figure 8:Screenshot of binaural speech evaluation.",
                "position": 2622
            }
        ]
    },
    {
        "header": "Appendix DEvaluation Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20630/x9.png",
                "caption": "Figure 9:Visualization results.",
                "position": 2711
            },
            {
                "img": "https://arxiv.org/html/2504.20630/x10.png",
                "caption": "Figure 10:The statistics of spatial routing in Drama-MOE.",
                "position": 2778
            }
        ]
    },
    {
        "header": "Appendix EExtended Experiments",
        "images": []
    }
]