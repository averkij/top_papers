[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02423/x1.png",
                "caption": "Figure 1:The fitting results of the scaling law in Eq. (7) deriving fromKumar et¬†al. (2024), which have large bias in E1M1 case. In the three sub-figures on the left, middle and right, the sizes of the data points are approximately proportional toDùê∑Ditalic_D,Eùê∏Eitalic_E, andMùëÄMitalic_Mrespectively.",
                "position": 262
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x1.png",
                "caption": "",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x2.png",
                "caption": "",
                "position": 269
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x3.png",
                "caption": "",
                "position": 273
            }
        ]
    },
    {
        "header": "3Setup and Scaling Laws",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02423/x4.png",
                "caption": "(a)Chinchilla basic scaling law.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x4.png",
                "caption": "(a)Chinchilla basic scaling law.",
                "position": 497
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x5.png",
                "caption": "(b)OpenAI basic scaling law.",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x6.png",
                "caption": "Figure 3:Quantization Targets. We select P2, P4, and P6 as our quantization targets for the following exploration of scaling laws.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x7.png",
                "caption": "Figure 4:Results of loss gaps with different quantization targets.",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x8.png",
                "caption": "Figure 5:The correlations betweenŒ≥ùõæ\\gammaitalic_Œ≥,ŒπùúÑ\\iotaitalic_Œπin Eq. (12) andNùëÅNitalic_N,Dùê∑Ditalic_D.Œ≥ùõæ\\gammaitalic_Œ≥,ŒπùúÑ\\iotaitalic_Œπcould be viewed as functions ofNùëÅNitalic_N,Dùê∑Ditalic_D. Data point size is proportional toDùê∑Ditalic_D.",
                "position": 565
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x8.png",
                "caption": "",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x9.png",
                "caption": "",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x10.png",
                "caption": "",
                "position": 576
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x11.png",
                "caption": "Figure 6:The fitting results of our Exponent-related scaling law. Data point size is proportional toDùê∑Ditalic_D.",
                "position": 638
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x12.png",
                "caption": "Figure 7:The fitting results of our Mantissa-related scaling law. Data point size is proportional toDùê∑Ditalic_D.",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x13.png",
                "caption": "Figure 8:The fitting results of the joint Exponent & Mantissa scaling law: Data point sizes in left, middle, and right sub-figures are proportional toDùê∑Ditalic_D,MùëÄMitalic_M, andEùê∏Eitalic_E, respectively.",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x13.png",
                "caption": "",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x14.png",
                "caption": "",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x15.png",
                "caption": "",
                "position": 710
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x16.png",
                "caption": "Figure 9:The correlations betweenŒ∫ùúÖ\\kappaitalic_Œ∫,œàùúì\\psiitalic_œàin Eq. (19) andNùëÅNitalic_N,Dùê∑Ditalic_D.Œ∫ùúÖ\\kappaitalic_Œ∫,œàùúì\\psiitalic_œàcould be viewed as functions ofNùëÅNitalic_N,Dùê∑Ditalic_D. The data points are scaled proportionally to the value ofDùê∑Ditalic_D.",
                "position": 727
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x16.png",
                "caption": "",
                "position": 730
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x17.png",
                "caption": "",
                "position": 734
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x18.png",
                "caption": "",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x19.png",
                "caption": "Figure 10:Our scaling law precisely forecasts validation loss for diverse block sizes. Data point sizes are directly proportional toDùê∑Ditalic_DandBùêµBitalic_Bin the respective left and right sub-figures.",
                "position": 767
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x19.png",
                "caption": "",
                "position": 770
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x20.png",
                "caption": "",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x21.png",
                "caption": "Figure 11:The fitting results of the channel-wise scaling law. The size of the data point is proportional toDùê∑Ditalic_D.",
                "position": 797
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x22.png",
                "caption": "Figure 12:The correlations betweenlog2‚Å°Bsubscript2ùêµ\\log_{2}Broman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_BandNDùëÅùê∑\\frac{N}{D}divide start_ARG italic_N end_ARG start_ARG italic_D end_ARG. The size of the data point is proportional toDùê∑Ditalic_D.",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x23.png",
                "caption": "Figure 13:The fitting results of the tensor-wise scaling law. The size of the data point is proportional toDùê∑Ditalic_D.",
                "position": 819
            }
        ]
    },
    {
        "header": "4A Unified Scaling Law for Floating‚ÄìPoint Quantization Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02423/x24.png",
                "caption": "Figure 14:The fitting results of our scaling law for floating-point quantization training. Data point size is proportional toDùê∑Ditalic_D. The star points (1.2B models) are our validation.",
                "position": 928
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x25.png",
                "caption": "Figure 15:The optimal float layouts of different bit widths.",
                "position": 968
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x26.png",
                "caption": "Figure 16:Variation of loss with data size under different floating-point quantization settings.",
                "position": 975
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x27.png",
                "caption": "Figure 17:Under the constraint of computing the budget with block size (BùêµBitalic_B) set to 128, and based on the results of our experimental data fitting, the optimal precision (PùëÉPitalic_P) values for different data sizes (Dùê∑Ditalic_D) can be deduced. As depicted, across a substantially broad range of data sizes from 0.1T to 100T, the optimal precision value consistently falls within the range of 4 to 8 bits.",
                "position": 1031
            },
            {
                "img": "https://arxiv.org/html/2501.02423/x28.png",
                "caption": "Figure 18:The optimal cost-performance ratio precision as a function of the total compute budget, illustrating the relationship between precision (PùëÉPitalic_P) and computational budget (Cùê∂Citalic_C) when the block size (BùêµBitalic_B) is set to 128 andk=6/16ùëò616k=6/16italic_k = 6 / 16.",
                "position": 1091
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion, Limitation, and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOptimal Float Layout",
        "images": []
    },
    {
        "header": "Appendix BCritical Data Size",
        "images": []
    },
    {
        "header": "Appendix CCompute-optimality",
        "images": []
    },
    {
        "header": "Appendix DAblations",
        "images": []
    }
]