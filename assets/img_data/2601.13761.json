[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13761/x1.png",
                "caption": "Figure 1:Comparison betweenDARCand previous coupled self-play methods.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13761/x2.png",
                "caption": "Figure 2:Illustration of the two-stageDARCframework.\nIn the first stage (the upper half), theQuestionerlearns to generate questions matching specified difficultyÏ„\\tauwith a difficulty-anchored reward. In the second stage (the lower half), theSolveris trained on an offline curriculum with an answer correctness reward.",
                "position": 197
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x3.png",
                "caption": "Figure 3:Cross-Iteration Accuracy Heatmap in Coupled Self-Play. Golden label is annotated by DeepSeek-3.2Liuet al.(2025a)and only for analytical purposes.",
                "position": 455
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13761/x4.png",
                "caption": "(a)Training reward.",
                "position": 901
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x4.png",
                "caption": "(a)Training reward.",
                "position": 904
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x5.png",
                "caption": "(b)Validation reward.",
                "position": 909
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x6.png",
                "caption": "(c)Active prompts in GRPO.",
                "position": 914
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x7.png",
                "caption": "Figure 5:Accuracy of differentSolvers on questions generated under different difficulty levels.",
                "position": 1140
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperiment Details",
        "images": []
    },
    {
        "header": "Appendix BEffect of Curriculum Learning in TrainingSolver",
        "images": []
    },
    {
        "header": "Appendix CTraining Dynamics of theQuestioner",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13761/x8.png",
                "caption": "(a)Questionerreward.",
                "position": 1803
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x8.png",
                "caption": "(a)Questionerreward.",
                "position": 1806
            },
            {
                "img": "https://arxiv.org/html/2601.13761/x9.png",
                "caption": "(b)KL loss during GRPO.",
                "position": 1812
            }
        ]
    },
    {
        "header": "Appendix DCase Study of Generated Questions",
        "images": []
    },
    {
        "header": "Appendix EPrompt Design",
        "images": []
    }
]