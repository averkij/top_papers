[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Taxonomy of Speaker and Speech Traits",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14648/x1.png",
                "caption": "Figure 1:Overview of the proposedVox-ProfileBenchmark and its applications. We highlight three primary use cases: (1) speech model (such as ASR) performance analysis, (2) automated speech generation evaluation, and (3) automated speaking style tagging.",
                "position": 402
            }
        ]
    },
    {
        "header": "4Vox-Profile Benchmark",
        "images": []
    },
    {
        "header": "5Benchmark Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/vox_profile_ensemble.png",
                "caption": "Table 5:Experiments to compareVox-Profilewith existing work and impact of model ensembles.",
                "position": 748
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/vox_profile_ensemble.png",
                "caption": "(a)Comparing model ensembles with single model inVox-Profile.",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/vctk_wer.png",
                "caption": "Figure 2:ASR performance trends, grouped by ground truth and predicted labels byVox-Profile. We measure WER, stratified by accent and emotion labels. We observe similar performance trends between the predicted and ground truth trait labels.",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/msp_podcast_wer.png",
                "caption": "",
                "position": 927
            }
        ]
    },
    {
        "header": "6Enabling Versatile Speech Applications with Vox-Profile",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/UK_Conv.png",
                "caption": "Table 6:UtilizingVox-Profileto evaluate the accent conversion performance ofFreeVCandVALLE-X, by measuring cosine similarity (left table) and prediction scores (right table).",
                "position": 968
            },
            {
                "img": "https://arxiv.org/html/2505.14648/x2.png",
                "caption": "Figure 3:Comparing human evaluation results between synthetic speaking style prompts created byVox-Profileand human-annotated prompts fromParaSpeechCaps. Human raters provided their preferences across overall prompt quality, sex, age, accent, voice quality, fluency, and emotion.",
                "position": 1111
            }
        ]
    },
    {
        "header": "7Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails on the Datasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14648/x3.png",
                "caption": "(a)Speaker sex label distribution.",
                "position": 2131
            },
            {
                "img": "https://arxiv.org/html/2505.14648/x3.png",
                "caption": "(a)Speaker sex label distribution.",
                "position": 2134
            },
            {
                "img": "https://arxiv.org/html/2505.14648/x4.png",
                "caption": "(b)Speaker age label distribution.",
                "position": 2140
            },
            {
                "img": "https://arxiv.org/html/2505.14648/x5.png",
                "caption": "Figure 5:Accent label distribution",
                "position": 2146
            }
        ]
    },
    {
        "header": "Appendix BDetails on the Models",
        "images": []
    },
    {
        "header": "Appendix CDetails on the Modeling Experiments",
        "images": []
    },
    {
        "header": "Appendix DDetails on the Resources",
        "images": []
    },
    {
        "header": "Appendix EDetails on Speech Generation Task Evaluation",
        "images": []
    },
    {
        "header": "Appendix FDetails on Confidence Levels in Speaking Style Prompt Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14648/x6.png",
                "caption": "Figure 6:Prompt example for generating speaking style.",
                "position": 2202
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/humanevalpage/overview.png",
                "caption": "(a)Task overview page",
                "position": 2214
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/humanevalpage/overview.png",
                "caption": "(a)Task overview page",
                "position": 2217
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/humanevalpage/instruction.png",
                "caption": "(b)Instruction page",
                "position": 2222
            },
            {
                "img": "https://arxiv.org/html/2505.14648/extracted/6448607/figures/humanevalpage/main.png",
                "caption": "(c)Main evaluation page",
                "position": 2228
            }
        ]
    },
    {
        "header": "Appendix GDetails on Text Description Human Evaluation",
        "images": []
    }
]