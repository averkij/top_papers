[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18890/x1.png",
                "caption": "Figure 1:Visualizing (a) the accuracy–latency trade-off and (b) the accuracy-throughput trade-off of our Nemotron-Flash and SOTA SLMs, where the average accuracy is computed across 16 tasks spanning commonsense reasoning, math, coding, and recall tasks. Latency is measured on an NVIDIA H100 GPU for decoding 8k tokens with a batch size of 1 using CUDA Graph. Decoding throughput is measured with a 32k-token input length using the maximum batch size that does not cause out-of-memory (OOM) errors for each model. The marker size represents the model depth.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x2.png",
                "caption": "Figure 2:The accuracy–parameter/latency trade-offs when varying depth and width. While deeper models generally achieve a better accuracy–parameter trade-off, they may not perform as well in the accuracy–latency trade-off and there exists an\noptimal depth-width ratio for a latency budget.",
                "position": 187
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Towards Latency-Optimal SLM Design and Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18890/x3.png",
                "caption": "Figure 3:Fitting the scaling law and validating on larger depth/width settings.",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x4.png",
                "caption": "Figure 4:(a) The validation loss evolution, and (b) the PPL-latency trade-off of different operators.",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x5.png",
                "caption": "Figure 5:Visualizing the search trajectories.",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x6.png",
                "caption": "Figure 6:The weight distributions (absolute values) of the layers in the last attention block of 1B Llama models trained without and with our weight normalization technique.",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x7.png",
                "caption": "Figure 7:Validation loss trajectories of four model families with and without weight normalization.",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2511.18890/x8.png",
                "caption": "Figure 8:Visualizing the gradient norm and L2 norm of DeltaNet model weights during training.",
                "position": 582
            }
        ]
    },
    {
        "header": "4Nemotron-Flash: The New Hybrid SLM Family",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18890/x9.png",
                "caption": "Figure 9:Visualizing the NIAH scores of different attention configurations on the Ruler benchmark[hsieh2024ruler].",
                "position": 1052
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Settings",
        "images": []
    },
    {
        "header": "Appendix BMore Benchmark Results of Nemotron-Flash",
        "images": []
    },
    {
        "header": "Appendix CEvolutionary Search: More Details and Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18890/x10.png",
                "caption": "Figure 10:The gradient norm evolution of different models during training w/ and w/o weight normalization.",
                "position": 1743
            }
        ]
    },
    {
        "header": "Appendix DWeight Normalization: More Analysis and Experiments",
        "images": []
    },
    {
        "header": "Appendix EThe Choice of Tokenizers",
        "images": []
    },
    {
        "header": "Appendix FDeployment Flow",
        "images": []
    },
    {
        "header": "Appendix GLimitations and Future Work",
        "images": []
    }
]