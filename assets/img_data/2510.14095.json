[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14095/x1.png",
                "caption": "(a)Recurrence & Adaptive Computation",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x1.png",
                "caption": "(a)Recurrence & Adaptive Computation",
                "position": 184
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x2.png",
                "caption": "(b)Algorithmic Supervision",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x3.png",
                "caption": "(c)Anchored Discrete Latent Space",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x4.png",
                "caption": "(d)Error Correction",
                "position": 199
            }
        ]
    },
    {
        "header": "1.â€‚Introduction",
        "images": []
    },
    {
        "header": "2.â€‚Related Work",
        "images": []
    },
    {
        "header": "3.â€‚Problem Setup",
        "images": []
    },
    {
        "header": "4.â€‚Reasoning in Latent Space with Algorithmic Supervision",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14095/x5.png",
                "caption": "Figure 4:Out-of-Distribution generalization performance of different methods on the mathematical reasoning task.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x5.png",
                "caption": "Figure 4:Out-of-Distribution generalization performance of different methods on the mathematical reasoning task.",
                "position": 677
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x6.png",
                "caption": "Figure 5:Effective out-of-distribution generalization via input-adaptive scaling of computation time. This depictsDiscrete Latent Space Supervisionâ†º\\circlearrowleft",
                "position": 681
            }
        ]
    },
    {
        "header": "5.â€‚Mechanistic Interpretability",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14095/x7.png",
                "caption": "Figure 6:Illustration of the two-layer model performing the modular addition task. The colored squares represent attention heads, grouped by the variable positions they attend to. Black rectangles indicate the embedding components chosen by the value projection matrix.âŸ¨â‹…âŸ©\\langle\\cdot\\rangledenotes tokens, and â€˜â‹…\\,\\cdot\\,â€™ denotes embedding components.",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x8.png",
                "caption": "Figure 7:Left.An illustration of the functionality of attention heads by groups in the first attention layer. Head 4 and 8 attend to the first variable position, Head 5 and 12 attend to the second variable position, Head 3, 7, 11, 14 attend to the third variable position, and the remaining heads attend to the RHS position or do not show a clear attention pattern.Right.Norm amplification of each factorâ€™s embeddings passed through the combined attention OV matrix by head groups.âŸ¨ğš˜ğšğš‘ğšğš›ğšœâŸ©\\langle\\mathtt{others}\\rangleexhibits significantly higher norm amplification, primarily because head 15 performs a self-copy operation at the RHS position.",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x8.png",
                "caption": "",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x9.png",
                "caption": "",
                "position": 807
            }
        ]
    },
    {
        "header": "6.â€‚Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details on Chain-of-Thought & End-to-End Baselines",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14095/x10.png",
                "caption": "Figure 8:A comparison of average OOD generalization performance of different feedforward and recurrent baselines, varying architectural hyperparameters. This is computed as the average of the â€œ% Fully Solvedâ€ metric computed on inputs of varying size fromN=8N=8toN=128N=128.",
                "position": 1526
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x11.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1529
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x11.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1532
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x12.png",
                "caption": "(b)Average â€œ% Fully Solvedâ€ across test splits for the best model of each positional encoding method. The relative positional encoding methods, RoPE and DeBERTa perform best.",
                "position": 1537
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x13.png",
                "caption": "(c)% Fully solved by graph size for best model of each positional encoding method in thefeedforwardbaselines.",
                "position": 1543
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x14.png",
                "caption": "(d)% Fully solved by graph size for best model of each positional encoding method in therecurrentbaselines.",
                "position": 1548
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x15.png",
                "caption": "(e)% Fully solved by graph size for the best model of each architectural configuration. Recurrent models slightly outperform feedforward models. Computational depth (i.e.,Tâ‹…LT\\cdot L) is crucial, with shallow models performing poorly even on the smallest in-distribution inputs.",
                "position": 1554
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x16.png",
                "caption": "(f)Average attention score entropy by input size. Attention scores disperse as the input size increases.",
                "position": 1559
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x17.png",
                "caption": "Figure 10:A comparison of average OOD generalization performance of different CoT-supervised baselines, varying architectural hyperparameters. The metric is full sequence accuracy, which measures the proportion of inputs where every nodeâ€™s value is computed correctly. The naming scheme matches the previous section, but adds a prefix describing the format of the CoT trajectories. â€œValâ€ means that the CoT trajectory directly computes the values of each variable, whereas â€œEq-Valâ€ first recalls the equations and then computes the values. Here, â€œ(Var Len)â€ indicates runs where the input problem size is variable and randomly sampled inNâ‰¤32N\\leq 32, rather than being onlyN=32N=32.",
                "position": 1690
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x18.png",
                "caption": "Figure 11:A comparison of average OOD generalization performance of different CoT-supervised baselines, varying architectural hyperparameters. The metric is â€œ% Equation Structure Correctâ€, which measures the proportion of inputs where the autoregressively generated CoT has the correct equation structure (without checking whether the values computed are correct).",
                "position": 1693
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x19.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1696
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x19.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1699
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x20.png",
                "caption": "(b)Average OOD performance across test splits for the best model of each positional encoding method.",
                "position": 1704
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x21.png",
                "caption": "(c)% Fully solved by graph size for the best model of each positional encoding method. We find NoPE to achieve the best out-of-distribution generalization performance, generalizing well to 40 nodes when trained onNâ‰¤32N\\leq 32nodes. The other positional encoding methods fail to generalize beyond the training regime.",
                "position": 1710
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x22.png",
                "caption": "(d)% Fully solved by graph size for the best model of each architectural configuration. Computational depth (i.e.,Tâ‹…LT\\cdot L) is crucial for good performance, with shallow models performing poorly even in-distribution on larger inputs.",
                "position": 1715
            }
        ]
    },
    {
        "header": "Appendix BDetails on Latent State Supervision",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14095/x23.png",
                "caption": "Figure 13:Average â€œ% Fully Solvedâ€, across # nodes between 8 and 128, with training onâ‰¤32\\leq 32nodes,",
                "position": 1905
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x24.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1908
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x24.png",
                "caption": "(a)Each line corresponds to an experimental run. Lines are color-coded by positional encoding, but other architectural hyperparameters vary and are not represented.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x25.png",
                "caption": "(b)Average OOD performance across test splits for the best model of each positional encoding method.",
                "position": 1916
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x26.png",
                "caption": "(c)% Fully solved by graph size for best model of each positional encoding method.",
                "position": 1922
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x27.png",
                "caption": "(d)% Fully solved by graph size for best model of each architectural configuration.",
                "position": 1927
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x28.png",
                "caption": "(a)Relativeâ€‹Variance\\mathrm{Relative~Variance}forâŸ¨ğšŸğšŠğš›ğŸ¶âŸ©\\,\\langle\\mathtt{var0}\\rangle\\,",
                "position": 2157
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x28.png",
                "caption": "(a)Relativeâ€‹Variance\\mathrm{Relative~Variance}forâŸ¨ğšŸğšŠğš›ğŸ¶âŸ©\\,\\langle\\mathtt{var0}\\rangle\\,",
                "position": 2160
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x29.png",
                "caption": "(b)Relativeâ€‹Variance\\mathrm{Relative~Variance}forâŸ¨ğšŸğšŠğš›ğŸ·âŸ©\\,\\langle\\mathtt{var1}\\rangle\\,",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x30.png",
                "caption": "(c)Relativeâ€‹Variance\\mathrm{Relative~Variance}forâŸ¨ğšŸğšŠğš›ğŸ¸âŸ©\\,\\langle\\mathtt{var2}\\rangle\\,",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x31.png",
                "caption": "(d)Relativeâ€‹Variance\\mathrm{Relative~Variance}forâŸ¨ğš›ğš‘ğšœâŸ©\\,\\langle\\mathtt{rhs}\\rangle\\,",
                "position": 2176
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x32.png",
                "caption": "(a)Norm Amplification forOPERATION",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x32.png",
                "caption": "(a)Norm Amplification forOPERATION",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x33.png",
                "caption": "(b)Norm Amplification forSYNTAX",
                "position": 2342
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x34.png",
                "caption": "(c)Norm Amplification forVALUE",
                "position": 2348
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x35.png",
                "caption": "(d)Norm Amplification forVARIABLE",
                "position": 2353
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/Additional_Evidence/L0/head4_deg=2.png",
                "caption": "(a)Head 4 for equation with 2 variables",
                "position": 2370
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/Additional_Evidence/L0/head4_deg=2.png",
                "caption": "(a)Head 4 for equation with 2 variables",
                "position": 2373
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/Additional_Evidence/L0/head8_deg=2.png",
                "caption": "(b)Head 8 for equation with 2 variables",
                "position": 2379
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x36.png",
                "caption": "Figure 18:Histogram of the L2 relative error between the residual stream before and after the first layer MLP.",
                "position": 2392
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x37.png",
                "caption": "(a)âŸ¨ğšŸğšŠğš›ğŸ¶âŸ©\\,\\langle\\mathtt{var0}\\rangle\\,statistics",
                "position": 2425
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x37.png",
                "caption": "(a)âŸ¨ğšŸğšŠğš›ğŸ¶âŸ©\\,\\langle\\mathtt{var0}\\rangle\\,statistics",
                "position": 2428
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x38.png",
                "caption": "(b)âŸ¨ğšŸğšŠğš›ğŸ·âŸ©\\,\\langle\\mathtt{var1}\\rangle\\,statistics",
                "position": 2434
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x39.png",
                "caption": "(c)âŸ¨ğšŸğšŠğš›ğŸ¸âŸ©\\,\\langle\\mathtt{var2}\\rangle\\,statistics",
                "position": 2440
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x40.png",
                "caption": "(a)Norm Amplification forOPERATION",
                "position": 2494
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x40.png",
                "caption": "(a)Norm Amplification forOPERATION",
                "position": 2497
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x41.png",
                "caption": "(b)Norm Amplification forSYNTAX",
                "position": 2502
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x42.png",
                "caption": "(c)Norm Amplification forVALUE",
                "position": 2508
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x43.png",
                "caption": "(d)Norm Amplification forVARIABLE",
                "position": 2513
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x44.png",
                "caption": "Figure 21:Cosine similarity of theğš—ğšğš â€‹ğšŸğšŠğš•ğšğš\\mathtt{new~value}factored embeddings for all three variables in the residual stream after the second layer attention.",
                "position": 2616
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x45.png",
                "caption": "(a)DFT of L1 MLP pre-activation",
                "position": 2744
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x45.png",
                "caption": "(a)DFT of L1 MLP pre-activation",
                "position": 2747
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x46.png",
                "caption": "(b)DFT of L1 MLP post-activation",
                "position": 2753
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x47.png",
                "caption": "(c)DFT of L1 MLP output",
                "position": 2759
            },
            {
                "img": "https://arxiv.org/html/2510.14095/x48.png",
                "caption": "(d)DFT of decoder output",
                "position": 2765
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L0_prob_dep_ge_loop_var0.png",
                "caption": "Figure 23:Error analysis.Top Row.Histograms for the group-wise attention probability in the first layer for all three head groups attending toâŸ¨ğšŸğšŠğš›ğŸ¶âŸ©\\,\\langle\\mathtt{var0}\\rangle\\,,âŸ¨ğšŸğšŠğš›ğŸ·âŸ©\\,\\langle\\mathtt{var1}\\rangle\\,, andâŸ¨ğšŸğšŠğš›ğŸ¸âŸ©\\,\\langle\\mathtt{var2}\\rangle\\,, respectively.\nHere, the target equations considered all satisfyğšğšğš™ğšğš‘â‰¥ğš’ğšğšğš›\\mathtt{depth}\\geq\\mathtt{iter}as defined in (16).\nWe use different colors to separate the equations based on whether the decoded RHS value is correct or not after the second layer MLP.Middle Row.Histograms of the group-wise cosine similarity for the second layer attention head groupsâ€™ outputs with the target valuesâ€™ embedding. Only equations withğšğšğš™ğšğš‘â‰¥ğš’ğšğšğš›\\mathtt{depth}\\geq\\mathtt{iter}are included.Bottom Row.Histograms of the group-wise attention probability in the first layer for all three head groups.\nHere, the target equations considered all satisfyğšğšğš™ğšğš‘<ğš’ğšğšğš›\\mathtt{depth}<\\mathtt{iter}, meaning that the number of iterations is beyond the depth of the equations.",
                "position": 2908
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L0_prob_dep_ge_loop_var1.png",
                "caption": "",
                "position": 2913
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L0_prob_dep_ge_loop_var2.png",
                "caption": "",
                "position": 2914
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L1_cos_sim_var0.png",
                "caption": "",
                "position": 2917
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L1_cos_sim_var1.png",
                "caption": "",
                "position": 2918
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_L1_cos_sim_var2.png",
                "caption": "",
                "position": 2919
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_prob_L0_loop_ge_dep_var0.png",
                "caption": "",
                "position": 2922
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_prob_L0_loop_ge_dep_var1.png",
                "caption": "",
                "position": 2923
            },
            {
                "img": "https://arxiv.org/html/2510.14095/figs/experiment_results/mech_interp/err_prob_L0_loop_ge_dep_var2.png",
                "caption": "",
                "position": 2924
            }
        ]
    },
    {
        "header": "Appendix CDetails of Mechanistic Interpretability Analysis",
        "images": []
    }
]