[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14768/x1.png",
                "caption": "Figure 1:Validation accuracy and mean response length during RL training, illustrating how the model autonomously learns to allocate more thinking compute for improved performance. Remarkably, the model also demonstrates impressive generalization on completely unseen datasets (AIME, AMC).",
                "position": 102
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": []
    },
    {
        "header": "3Experiment",
        "images": []
    },
    {
        "header": "4Research Questions",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq1.png",
                "caption": "Figure 2:Comparison of GRPO (Blue), REINFORCE++ (Red), and PPO (Green) performance (averaged by sliding window = 50) in terms of training speed, accuracy, and reward gain.",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq7.png",
                "caption": "Figure 3:Impact of complex reasoning behaviours and language mixing on reasoning performance. We analyzed the model’s answer rewards for responses containing the tokens shown in the figure. Responses with \"verify\" and \"re-evaluate\" scored significantly higher than those without these words. Conversely, responses containing certain tokens from other languages generally received lower scores.",
                "position": 635
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/verify.png",
                "caption": "(a)Verify",
                "position": 682
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/verify.png",
                "caption": "(a)Verify",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/re-evaluate.png",
                "caption": "(b)Re-evaluate",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/check.png",
                "caption": "(c)Check",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/yet.png",
                "caption": "(d)Yet",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/lets.png",
                "caption": "(e)Let’s",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/chinese_yes.png",
                "caption": "(f)Chinese word",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2502.14768/x2.png",
                "caption": "Figure 5:Training Step vs. Accuracy on AIME (2021-2024) and AMC (2022-2023) Datasets.",
                "position": 724
            },
            {
                "img": "https://arxiv.org/html/2502.14768/x3.png",
                "caption": "",
                "position": 733
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/limem_rl32.png",
                "caption": "(a)RL",
                "position": 805
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/limem_rl32.png",
                "caption": "(a)RL",
                "position": 808
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/limem_rft32.png",
                "caption": "(b)RFT",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2502.14768/x4.png",
                "caption": "Figure 7:Comparison of test scores for curriculum learning and mixed-difficulty training. The plot uses a rolling average (window size = 5)",
                "position": 829
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq3.png",
                "caption": "Figure 8:Comparison of response length, validation accuracy, and mean reward across training steps for positive and negative example models.",
                "position": 844
            }
        ]
    },
    {
        "header": "5Discussion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Comparion Between Base and Instruct Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/base_reps.png",
                "caption": "Figure 9:Comparison of training metrics: Response Length, Validation Accuracy, Mean Reward, and KL Loss.",
                "position": 1202
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/val_acc.png",
                "caption": "",
                "position": 1211
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/Mean_reward.png",
                "caption": "",
                "position": 1217
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/KL_loss.png",
                "caption": "",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/base_length.png",
                "caption": "Figure 10:Length dynamics between base & instruct",
                "position": 1228
            }
        ]
    },
    {
        "header": "8Qualitative Analysis of Emergent Reasoning",
        "images": []
    }
]