[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/models1.jpeg",
                "caption": "Figure 1:Comparison between standard VAE(Rombach et al.,2022b), VA-VAE(Yao et al.,2025), RAE(Zheng et al.,2025)and our proposed FAE. The number shows the channel dimension of the generative modeling space.",
                "position": 92
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Motivation",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/training_scheme1.jpeg",
                "caption": "Figure 2:An illustration of Training Stages of FAE. Stage Ia and Ib can be trained independently.",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/cat_sim2.png",
                "caption": "Figure 3:Matching across images.\nWe match patch-level FAE features between images from different images that share similar semantic information. This exhibits the ability of our model to understand relations between similar parts of different objects.",
                "position": 274
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/speed.png",
                "caption": "Table 3:ImageNet Linear Probing top-1 accuracy comparison for FAE and different DinoV2 variants (all at 224 resolution).",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/speed.png",
                "caption": "Figure 4:FID Score Converging Curve",
                "position": 765
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/combined.png",
                "caption": "Figure 5:Random samples of ImageNet 256x256 and  Text-to-Images using diffusion models.",
                "position": 785
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/starflow_wo_cfg.png",
                "caption": "(a)Results without CFG.",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/starflow_wo_cfg.png",
                "caption": "(a)Results without CFG.",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/starflow_w_cfg.png",
                "caption": "(b)Results with CFG.",
                "position": 946
            }
        ]
    },
    {
        "header": "6Ablation Study",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AFAE Encoder Structure",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/x1.png",
                "caption": "Figure 7:Modified Attention",
                "position": 2047
            }
        ]
    },
    {
        "header": "Appendix BAblation on FlowMatching Timesteps Shift",
        "images": []
    },
    {
        "header": "Appendix CrFID",
        "images": []
    },
    {
        "header": "Appendix DFAE Hyper Parameters",
        "images": []
    },
    {
        "header": "Appendix EPatch Embedding Similarity Maps",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/cat_sim3.png",
                "caption": "Figure 8:Similarity of a photo of cat.",
                "position": 2479
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/deer_sim.png",
                "caption": "Figure 9:Similarity of a photo of impala.",
                "position": 2482
            }
        ]
    },
    {
        "header": "Appendix FMatching most Similar patch pair across two images",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/bird_sim.png",
                "caption": "Figure 10:Matching most similar patch pair from two photo of bird.",
                "position": 2496
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/elephant_pca.png",
                "caption": "Figure 11:Matching most similar patch pair from two photo of elephant.",
                "position": 2499
            }
        ]
    },
    {
        "header": "Appendix GText-to-Image Prompts",
        "images": []
    },
    {
        "header": "Appendix HSTARFlow Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07829/figure/starflow.png",
                "caption": "Figure 12:Random samples of ImageNet 256x256 generated by STarFlow model.",
                "position": 2525
            },
            {
                "img": "https://arxiv.org/html/2512.07829/figure/extra_examples.png",
                "caption": "Figure 13:Random samples of Siglip2 MMDiT384×384384\\times 384Model.",
                "position": 2532
            }
        ]
    },
    {
        "header": "Appendix IExtra Examples from Siglip2 MMDiT384×384384\\times 384Model",
        "images": []
    }
]