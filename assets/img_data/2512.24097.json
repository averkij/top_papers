[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24097/x1.png",
                "caption": "",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24097/x2.png",
                "caption": "Figure 2:Conceptual demonstration of the D2VLM framework.",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2512.24097/x3.png",
                "caption": "Figure 3:The visual semantic capture process of<evi>token.",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2512.24097/x4.png",
                "caption": "Figure 4:The proposed data synthesis pipeline, where factorized perturbation is imposed to form the dispreferred data.",
                "position": 228
            }
        ]
    },
    {
        "header": "4Factorized Preference Optimization",
        "images": []
    },
    {
        "header": "5Factorized Preference Data Synthesis",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": []
    },
    {
        "header": "7Conclusion and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24097/x5.png",
                "caption": "Figure 1:Qualitative examples for grounding-focused task, dense captioning-related task, and temporally grounded video question answering task.",
                "position": 997
            }
        ]
    },
    {
        "header": "Appendix BData Annotation Formats",
        "images": []
    },
    {
        "header": "Appendix CMore Experimental Results",
        "images": []
    },
    {
        "header": "Appendix DMore about the Factorized Data Synthesis",
        "images": []
    },
    {
        "header": "Appendix EVisualization Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24097/x6.png",
                "caption": "Figure 2:An illustrative example of the data synthesis approach.",
                "position": 1284
            },
            {
                "img": "https://arxiv.org/html/2512.24097/x7.png",
                "caption": "Figure 3:A qualitative example for dense captioning task.",
                "position": 1287
            },
            {
                "img": "https://arxiv.org/html/2512.24097/x8.png",
                "caption": "Figure 4:Qualitative examples for grounding-focused task.",
                "position": 1290
            },
            {
                "img": "https://arxiv.org/html/2512.24097/x9.png",
                "caption": "Figure 5:A qualitative example for temporally grounded video question answering task.",
                "position": 1293
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]