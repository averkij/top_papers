[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18941/x1.png",
                "caption": "",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2510.18941/figs/github-mark.png",
                "caption": "",
                "position": 131
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2ProfBench Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18941/x2.png",
                "caption": "Figure 2:Distribution of rubrics by category.\nReasoning dominates (62.9%), with most on logical validity and correctness.\nExtraction accounts for 34.1%, emphasizing accurate retrieval of information (w/o meaningful subcategories).\nStyle is minor (3.0%), with a focus on formatting and clarity.",
                "position": 234
            }
        ]
    },
    {
        "header": "3Data Collection",
        "images": []
    },
    {
        "header": "4Benchmarking Models as LLM-Judges",
        "images": []
    },
    {
        "header": "5Benchmarking Models as Report-Generators",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18941/x3.png",
                "caption": "Figure 3:Score Distribution and Optimal Samples for various tasks. Each blue box represents 25th, 50th and 75th percentile and whiskers represent the worst and best score out of 16 samples for a task by Gemini-2.5-Flash (Thinking). Tasks with lower variance can be estimated with fewer samples (shown as height of orange bar), reducing inference cost w/o sacrificing estimation robustness.",
                "position": 2329
            }
        ]
    },
    {
        "header": "6Ablation: How important are Grounding documents?",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExamples",
        "images": []
    },
    {
        "header": "Appendix BPrompt Templates",
        "images": []
    },
    {
        "header": "Appendix CAnnotator Recruitment",
        "images": []
    },
    {
        "header": "Appendix DFurther Descriptive Statistics",
        "images": []
    },
    {
        "header": "Appendix EInference Setup",
        "images": []
    },
    {
        "header": "Appendix FOptimal Performance on ProfBench at each price-point",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18941/x4.png",
                "caption": "Figure 4:Optimal ProfBench performance at each price-point. OpenAI models are on the Pareto Frontier at each price-point, likely because of first-mover advantages in rubric-style data such as HealthBench(Arora et al.,2025)and PaperBench(Starace et al.,2025). Gemini-2.5 and Qwen3-Instruct-2507 models are close to the Pareto Frontier.",
                "position": 3312
            },
            {
                "img": "https://arxiv.org/html/2510.18941/x5.png",
                "caption": "Figure 5:Standard deviation of overall performance using multiple samples per task. Optimal allocation of samples consistently reduce the variance across all budget levels.",
                "position": 3349
            }
        ]
    },
    {
        "header": "Appendix GFormulating Optimal Allocation Problem",
        "images": []
    }
]