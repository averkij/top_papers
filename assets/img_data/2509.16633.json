[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16633/images/result_graph.png",
                "caption": "Figure 1:Small models often struggle to match the performance of their larger counterparts. We show model sizes using circle with radius proportional to the parameter count, and their respective inference time and VQA accuracies in X and Y-axis, respectively on one of the datasets used in this paperSingh et¬†al. (2019). Proposed MPA significantly enhances VQA accuracy for fives-vlms across four datasets.(Best viewed in color).",
                "position": 87
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16633/x1.png",
                "caption": "Figure 2:Overview of the proposed MPA framework.It consists of three modules, namely (a) Pseudo Annotator (Section3.1), (b) Parity Identifier (Section3.2), and (c) Parity Leveler (Section3.3). Given a set of unlabeled images‚Ñê\\mathcal{I}and taskùíØ\\mathcal{T}, MPA begins with automatically annotating the unlabeled images, followed by strategic data selection that targets knowledge gaps ofs-vlmwith thel-vlm, while accounting for annotation quality. This selection process identifies parity, capturing instances where thel-vlmanswers correctly while thes-vlmfails. Finally, PL updates thes-vlm‚Äôs parameters on the obtained parity subset.(Best viewed in color).",
                "position": 118
            }
        ]
    },
    {
        "header": "3ModelParityAligner (MPA)",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16633/x2.png",
                "caption": "Figure 3:A selection of few pseudo annotations generated by our framework. We further show human annotations from their respective original dataset train splits.(Best viewed in color).",
                "position": 513
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations and Broader Impact",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Analysis",
        "images": []
    },
    {
        "header": "Appendix BDataset Details",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DPrompts used",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16633/x3.png",
                "caption": "Figure 4:Left two examples:Pseudo-annotations discarded by PI module as they do not constitute knowledge-gap.Right two examples:Pseudo-annotations discarded by PI module as they are noisy annotations.",
                "position": 2145
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x4.png",
                "caption": "",
                "position": 2149
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x5.png",
                "caption": "Figure 5:A selection of results showing zero-shot SVLM versus MPA-aligned SVLM. MPA config:s-vlm: Qwen2VL-2B,l-vlm: Qwen2VL-7B. Green and red text correspond to correct and incorrect answers, respectively.(Best viewed in color)",
                "position": 2163
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x6.png",
                "caption": "Figure 6:Few more results from TextVQA showing the efficiency of MPA-aligneds-vlmover baselines-vlm.",
                "position": 2166
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x7.png",
                "caption": "Figure 7:Few more results from STVQA showing the efficiency of MPA-aligneds-vlmover baselines-vlm. Green and red text correspond to correct and incorrect answers, respectively.(Best viewed in color)",
                "position": 2169
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x8.png",
                "caption": "Figure 8:Few more results from ChartQA showing the efficiency of MPA-aligneds-vlmover baselines-vlm. Green and red text correspond to correct and incorrect answers, respectively.(Best viewed in color)",
                "position": 2172
            },
            {
                "img": "https://arxiv.org/html/2509.16633/x9.png",
                "caption": "Figure 9:Few more results from OKVQA showing the efficiency of MPA-aligneds-vlmover baselines-vlm. Green and red text correspond to correct and incorrect answers, respectively.(Best viewed in color)",
                "position": 2175
            }
        ]
    },
    {
        "header": "Appendix EQualitative Results",
        "images": []
    }
]