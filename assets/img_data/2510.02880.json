[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02880/x1.png",
                "caption": "Figure 1:Left:MaskGRPOconsistently improves the base model with significant RL income across text and image generation tasks. Right: an intuitive demonstration of our method, integrated with modality-specific innovations on importance estimation and sampling methods.",
                "position": 128
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02880/x2.png",
                "caption": "Figure 2:A demonstration of reversing (re-mask) methods.We set mask raior=0.6r=0.6. Random reversing (right) applies masks to all the tokens with equal probability, while AR-like reversing (left) adapts a fading-out strategy. See AppendixCfor complete showcases.",
                "position": 311
            }
        ]
    },
    {
        "header": "3MaskGRPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02880/x3.png",
                "caption": "Figure 3:A comparison of sampled results.With identical sampling parameters on MMaDA (equipped with a 8192-vocab visual tokenizerXie et al. (2024)), images sampled by our emerge method (below) demonstrate better texture and expressiveness.",
                "position": 405
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02880/x4.png",
                "caption": "Figure 4:Qualitative comparison.Results are generated with identical sampling parameters and shown in {original, w/ RL} pairs. MaskGRPO demonstrates substantial improvement on the aesthetic quality of generated images, in terms of artistic style, photographic details and overall atmosphere. We strongly recommend that the readers view more portrait samples at Fig.7.",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2510.02880/x5.png",
                "caption": "Figure 5:Figures for ablative studies.a: ablation on timestep truncation in language tasks.b: ablation on reverse methods in language tasks.c: ablation on timestep truncation in vision tasks.d: ablation for clip range in vision tasks. See text for detailed explanation.",
                "position": 916
            },
            {
                "img": "https://arxiv.org/html/2510.02880/x6.png",
                "caption": "Figure 6:A comparison of reversing methods.Language are decoded in a semi-autoregressive manner, and the trace methodWang et al. (2025c)(above) reverses the decoding path accordingly. AR-like methods (below, ours), in contrast, balance the autoregressive bias and randomness with controlled probability, and can capture front fluctuations in the sequence at smaller masking ratios.",
                "position": 919
            }
        ]
    },
    {
        "header": "5Related work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADiscussing the Approximation",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02880/x7.png",
                "caption": "Figure 7:More generated portrait samples with identical prompt and sampling parameters (CFG=3.5, 64 steps). Above: sampled by default MaskGIT-style sampler before RL training. Below: sampled by our emerge sampler after RL training.",
                "position": 1834
            }
        ]
    },
    {
        "header": "Appendix CMore Results",
        "images": []
    }
]