[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19056/extracted/6476096/figures/refusal_completions.png",
                "caption": "Figure 1:Base vs. Extended Refusal.Standard LLMs issue an immediate refusal without providing context or explanation. In contrast, the extended refusal first explains the nature of the request before refusing to assist with it.",
                "position": 124
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19056/extracted/6476096/figures/llama_completions.png",
                "caption": "Figure 2:Base LLM Refusal Completions.LLaMA-2-7B-chatconsistently produces monotone and repetitive refusal templates across different categories of unethical requests.",
                "position": 174
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19056/extracted/6476096/figures/eval_pipeline.png",
                "caption": "Figure 3:Experiment pipeline overview.We begin with a base chat LLM and fine-tune it using the extended refusal dataset. Refusal direction vectors are then computed from the resulting model, and each vector is used to perform Abliteration, yielding an abliterated model‚Ñ≥~ER‚Å¢(i,j)subscript~‚Ñ≥ERùëñùëó\\widetilde{\\mathcal{M}}_{\\text{ER }(i,j)}over~ start_ARG caligraphic_M end_ARG start_POSTSUBSCRIPT ER ( italic_i , italic_j ) end_POSTSUBSCRIPT. Each abliterated model is subsequently evaluated for safety (refusal behavior) and general utility (coherence, MMLU, and perplexity).",
                "position": 213
            }
        ]
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19056/x1.png",
                "caption": "Llama-2-7B-extended-refusal",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x1.png",
                "caption": "Llama-2-7B-extended-refusal",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x2.png",
                "caption": "Qwen2.5-3B-extended-refusal",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x3.png",
                "caption": "Qwen2.5-1.5B-extended-refusal",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x4.png",
                "caption": "Llama-2-7B-extended-refusal",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x4.png",
                "caption": "Llama-2-7B-extended-refusal",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x5.png",
                "caption": "Qwen2.5-3B-extended-refusal",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2505.19056/x6.png",
                "caption": "Qwen2.5-1.5B-extended-refusal",
                "position": 471
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19056/x7.png",
                "caption": "Figure 6:Latent-Space Separation.Euclidean distance between hidden representations of safe and unsafe prompts, before and after abliteration, for both base and Extended-Refusal models.",
                "position": 598
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALLM as a Judge vs Llama-Guard",
        "images": []
    }
]