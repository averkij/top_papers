[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/x1.png",
                "caption": "Figure 1:Pareto curves for Physics SSAE trained with various data selection strategies as theŒªùúÜ\\lambdaitalic_Œªis varied on arXiv Physics test data. We plot (Left) Perplexity with spliced in SSAE relative to GSAE baseline and (Right) Absolute Perplexity with spliced in SSAE. Dense TracIn and BM25 TracIn achieve comparable performance, performing slightly better than Dense retrieval, which outperforms BM25 retrieval and OWT Baseline. All curves are averaged over three SAE training seeds.",
                "position": 669
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x2.png",
                "caption": "",
                "position": 672
            }
        ]
    },
    {
        "header": "3Experiments And Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/sae_comparison_plot_final.png",
                "caption": "Figure 2:Proportion of tokens with SAE features vs. Token frequency in Physics arXiv data. SSAE trained with dense retrieval captures more tail tokens (concepts) in its features.",
                "position": 727
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x3.png",
                "caption": "Figure 3:Reconstruction error vs. token rank for TERM-trained and ERM-trained GSAEs. TERM exhibits lower error variance and maximum error for tail tokens.",
                "position": 931
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/gsae_normalized_diversity_scores_distribution.png",
                "caption": "Figure 4:Feature diversity score distributions for TERM-trained and ERM-trained GSAEs. TERM leads to both higher and lower diversity features. Lower diversity features specialize in tail concepts, while higher diversity features capture a broader range of concepts.",
                "position": 940
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/merged.drawio.png",
                "caption": "Figure 5:TERM feature activation patterns. (Left) TERM token activation entropy is lower, suggesting more specialized features. (Right) TERM max feature activations per token are higher. These characteristics, from minimizing max risk, contribute to TERM‚Äôs enhanced tail concept detection.",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/tilt_tail_new_2_crop.png",
                "caption": "Figure 6:Cumulative proportion of tokens with SAE features vs. cumulative percentage of tokens in Physics arXiv data, normalized per model so that the cumulative proportion of tokens with features is 1 over the entire dataset. SSAE trained with dense retrieval and larger tilt captures more tail tokens (concepts) in its features.",
                "position": 963
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/tilt_log_log_camera_ready.png",
                "caption": "Figure 7:Feature activation count vs. feature rankfor SSAEs trained on the Physics arXiv dataset using different strategies: full OWT, Dense retrieval, and Dense retrieval with tilt. Tilt encourages the learning of more broadly activating features, indicating increased concept coverage and recall.",
                "position": 971
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/f1_score_distributions_large.png",
                "caption": "Figure 8:Automated interpretability:\nF1 score distributions for predicting feature activation on Physics arXiv, using only FM-generated explanations. An LM is given examples activating a feature and asked to generate an explanation, which is then used to predict activations on new examples. Dense retrieval with tilt produces more predictive explanations than both the OWT baseline and Dense retrieval alone.",
                "position": 998
            }
        ]
    },
    {
        "header": "4Conclusion and Future Work",
        "images": []
    },
    {
        "header": "5Acknowledgements",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BEvaluating SSAE for Physics on OOD data",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/x4.png",
                "caption": "Figure 9:Pareto curves for SSAE trained with various data selection strategies as the sparsity coefficient is varied on Physics instruction test data. We plot absolute perplexity with the spliced in SSAE. We find that both BM25 retrieval and training on the validation data generalize poorly when tested out of domain. All curves are averaged over three SAE training run seeds.",
                "position": 2271
            }
        ]
    },
    {
        "header": "Appendix CEvaluating Data Selection Strategies for Toxicity SSAEs",
        "images": []
    },
    {
        "header": "Appendix DProbing SSAE Tail Concept Learning for Toxicity",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/sae_comparison_plot_toxicity_adjusted_camera_ready.png",
                "caption": "Figure 11:Proportion of tokens with SAE features vs. Token frequency in Toxicity data. SSAE trained with dense retrieval captures more tail tokens (concepts) in its features.",
                "position": 2288
            }
        ]
    },
    {
        "header": "Appendix EPareto curves for Tilted ERM trained SSAE",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/x5.png",
                "caption": "Figure 12:Pareto curves for SSAEs finetuned on thePhysics arXiv datasetusing different strategies: full OpenWebText (OWT), Dense retrieval, and Dense retrieval with Tilted Empirical Risk Minimization (TERM, tilt=500 and TERM, tilt=109superscript10910^{9}10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT). TERM-finetuned SSAEs achieve competitive performance with Dense retrieval alone within theL0subscriptùêø0L_{0}italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTrange of 85-100. Outside this range, our current training methodology results in higher reconstruction errors. All curves are averaged over three SAE training run seeds.",
                "position": 2312
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x6.png",
                "caption": "Figure 13:Pareto curves for SSAEs finetuned on theToxicity datasetusing different strategies: full OpenWebText (OWT), Dense retrieval, and Dense retrieval with Tilted Empirical Risk Minimization (TERM, tilt=500). TERM-finetuned SSAEs achieve competitive performance with Dense retrieval alone within theL0subscriptùêø0L_{0}italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTrange of 100-140. All curves are averaged over three SAE training run seeds.",
                "position": 2315
            }
        ]
    },
    {
        "header": "Appendix FTERM-trained SSAE enhances Tail Concept Capture in Toxicity data",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/sae_normalized_cumulative_distribution_plot_log_matplotlib.png",
                "caption": "Figure 14:Cumulative proportion of tokens with SAE features vs. cumulative percentage of tokens in Toxicity data, normalized per model so that the cumulative proportion of tokens with features is 1 over the entire dataset. SSAE trained with dense retrieval and larger tilt captures more tail tokens (concepts) in its features. Note that the curves at tilt 500 and tilt109superscript10910^{9}10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPToverlap.",
                "position": 2326
            }
        ]
    },
    {
        "header": "Appendix GImplementation Details for Bias-in-Bios Classification Experiments",
        "images": []
    },
    {
        "header": "Appendix HSparse Feature Circuits for Bias in Bios Classifer",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/bib_circuit.png",
                "caption": "Figure 15:The full annotated feature circuit discovered for the Bias in Bios classifier with theGSAE patched in. The circuit was discovered usingTN=0.1subscriptùëáùëÅ0.1T_{N}=0.1italic_T start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT = 0.1andTE=0.01subscriptùëáùê∏0.01T_{E}=0.01italic_T start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = 0.01. We observe that the circuit contains many nodes that simply detect the presence of gendered pronouns or gendered names. A few features attend to profession information, including one which activates on words related to nursing, and another that activates on passages relating to science and academia.",
                "position": 2394
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/bib_circuit_v2.png",
                "caption": "",
                "position": 2399
            }
        ]
    },
    {
        "header": "Appendix IRelative Feature Activation Distribution",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/x7.png",
                "caption": "Figure 17:Distribution of log-ratio feature activation count differences between specialized SAEs and the OWT baseline on the Physics arXiv test set, normalized per SAE model. Blue represents the ERM-trained SSAE with Dense retrieval, orange represents the TERM-trained SSAE with tilt=500. The ERM-trained SSAE exhibits more probability mass on the right, indicating an emphasis on representing common concepts, while the TERM-trained SSAE‚Äôs shift towards the left suggests a greater focus on representing domain-specific tail concepts.",
                "position": 2434
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x8.png",
                "caption": "Figure 18:Distribution of log-ratio feature activation count differences on the Physics arXiv test set, normalized per SAE model. Blue represents the ERM-trained SSAE with Dense retrieval, orange represents the TERM-trained SSAE with tilt=109superscript10910^{9}10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT. The intensified leftward shift of probability mass with higher tilt demonstrates that TERM increasingly prioritizes representing tail concepts compared to standard ERM-trained SSAE, which focuses more on frequent concepts.",
                "position": 2437
            }
        ]
    },
    {
        "header": "Appendix JAutomated Intepretability Explanations",
        "images": []
    },
    {
        "header": "Appendix KAutomated Interpretability Prompts",
        "images": []
    },
    {
        "header": "Appendix LProof of Lower Description Length under Tilted ERM",
        "images": []
    },
    {
        "header": "Appendix MApplications of Tilted ERM SAEs in Capturing Tail Concepts",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00743/x9.png",
                "caption": "Figure 19:UMAP visualization of token activations and decoder features for a TERM-trained and ERM-trained GSAE. Decoder directions for TERM-trained GSAE appear more spread out, suggesting the SAE has wider coverage than the ERM-trained GSAE.",
                "position": 2879
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x10.png",
                "caption": "Figure 20:Distribution of cosine similarities between decoder directions of TERM-trained and ERM-trained GSAEs. TERM-trained GSAE shows lower similarity between decoder feature directions implying greater coverage.",
                "position": 2882
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x11.png",
                "caption": "Figure 21:Number of PCA components required to explain variance in decoder feature directions of TERM-trained and ERM-trained GSAEs. TERM-trained GSAE shows greater variance in decoder feature directions implying greater coverage.",
                "position": 2885
            },
            {
                "img": "https://arxiv.org/html/2411.00743/x12.png",
                "caption": "Figure 22:Reconstruction error distribution of TERM-trained and ERM-trained GSAE. TERM-trained GSAE minimizes the maximum error at the cost of average error.",
                "position": 2888
            },
            {
                "img": "https://arxiv.org/html/2411.00743/extracted/5971945/figures/token_coverage_comparison.png",
                "caption": "Figure 23:Proportion of tokens detected vs. activation threshold for TERM-trained and ERM-trained GSAEs. TERM-trained features exhibit stronger activations.",
                "position": 2891
            }
        ]
    },
    {
        "header": "Appendix NTERM-trained GSAE Features on TinyStories",
        "images": []
    },
    {
        "header": "Appendix ODataset Details",
        "images": []
    },
    {
        "header": "Appendix PComputational Resources",
        "images": []
    },
    {
        "header": "Appendix QTERM-trained and ERM-trained GSAE features on TinyStories",
        "images": []
    }
]