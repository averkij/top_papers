[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06052/x1.png",
                "caption": "Figure 1:The comparison among Long-to-short compression, Hybrid reasoning, and MixReasoning. MixReasoning dynamically adjusts the depth of reasoning within a single response. The resulting chain of thought then becomes a mixture of detailed reasoning on difficult steps and concise inference on simpler ones.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06052/x2.png",
                "caption": "Figure 2:MixReasoning use a single base model served together with a concise LoRA; during decoding we modulate the adapter strength to switch between short-form and long-form reasoning. When token-level uncertainty exceeds a threshold, we expand a local uncertain window and regenerate it in long-form mode; once confidence recovers, adapter strength is annealed back and decoding proceeds in the concise mode.",
                "position": 156
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06052/x3.png",
                "caption": "Figure 3:MixReasoning and Long-to-short reasoning(prompting(Han et al.,2024), finetuning(CoT-Valve(Ma et al.,2025b))) results on GSM8K dataset with QwQ-32B-Preview, Qwen3-14B and Qwen3-8B at varing token budgets. MixReasoning can achieve a better trade-off bwteen efficiency and accuracy.",
                "position": 498
            },
            {
                "img": "https://arxiv.org/html/2510.06052/x4.png",
                "caption": "Figure 4:Qualitative comparison: Long CoT produces a verbose trace with coherence fillers and redundant self-checks. MixReasoning (small window) expands only at the high-uncertainty fork and then anneals back to concise mode, reaching the correct answer with a substantially shorter trace. MixReasoning (large window) allocates more detailed reasoning across adjacent steps, trading a larger budget for additional rationale while staying focused around the pivotal region. In MixReasoning responses, thinking mode tokens are highlight inredand non-thinking mode tokens are highlight inblue.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2510.06052/x5.png",
                "caption": "(a)Token length under different LoRA targets.",
                "position": 547
            },
            {
                "img": "https://arxiv.org/html/2510.06052/x5.png",
                "caption": "(a)Token length under different LoRA targets.",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2510.06052/x6.png",
                "caption": "(b)Training loss curves: all converge similarly.",
                "position": 556
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06052/x7.png",
                "caption": "Figure 6:Additional qualitative comparison using Qwen3-8B model.In MixReasoning responses, we highlight thinking mode generated tokens withredbackground and non-thinking mode generated tokens withbluebackground.",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2510.06052/x8.png",
                "caption": "Figure 7:Additional qualitative comparison using Qwen3-14B model.In MixReasoning responses, we highlight thinking mode generated tokens withredbackground and non-thinking mode generated tokens withbluebackground.",
                "position": 1109
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]