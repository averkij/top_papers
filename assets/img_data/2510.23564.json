[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.23564/x1.png",
                "caption": "Figure 1:A comparison of LLM-based agent decision-making paradigms.(a)ReAct Agentoperates in a simple observation-action loop at a fixed, fine-grained level.(b)Agent with Plannerenforces a rigid separation between a high-level Planner and a low-level Executor, limiting adaptability.(c)ReCode Agentunifies plan and action in a code representation. The policy recursively refines high-level plans until primitive actions within a single dynamic loop, enabling fluid control over decision granularities.",
                "position": 187
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.23564/x2.png",
                "caption": "Figure 2:An overview of the ReCode.(a)The task instruction is transformed into an initial placeholder function via a rule-based text-to-code method.(b)The system traverses the tree depth-first, automatically executing the code of current node and expanding placeholder functions into child nodes when encountered.(c)LLM-based expansion operates with clean context. Only the current function signature and available variables are provided, without any tree structure or execution history.",
                "position": 303
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.23564/x3.png",
                "caption": "Figure 3:Effect of maximum recursion depth on agent performance in ScienceWorld seen set using GPT-4o mini. The star indicates the optimal depth achieving peak performance.",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2510.23564/x4.png",
                "caption": "",
                "position": 880
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.23564/x5.png",
                "caption": "Figure 5:A visualization of the ReCode execution flow for the task “put two alarmclock in dresser” in ALFWorld. The diagram shows how a high-level plan, composed of placeholder functions (e.g.,find_and_take_again), is recursively expanded on demand. Each arrow points from a function call to the code block it generates. This process illustrates the dynamic transition from abstract planning to the generation of fine-grained, executable code.",
                "position": 2617
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]