[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.04394/x1.png",
                "caption": "Figure 1:TiM’s superior performance across different NFEs, resolutions, and aspect ratios.On the GenEval[27]benchmark, TiM outperforms Flux.1 models[5,6]at different NFEs (top,1024×10241024\\times 1024), at higher resolutions (middle,1024×10241024\\times 1024to4096×40964096\\times 4096), and diverse aspect ratios (bottom,2:52:5to5:25:2).",
                "position": 143
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.04394/x2.png",
                "caption": "Figure 2:Illustration of Different Generative Paradigms. While conventional diffusion models learn the local vector field and few-step models learn a fixed endpoint map (a single large step), our Transition Models (TiM) are trained to master arbitrary state-to-state transitions. This approach allows TiM to learn the entire solution manifold of the generative process, unifying the few-step and many-step regimes within a single, powerful model.",
                "position": 187
            }
        ]
    },
    {
        "header": "3Transition Models",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.04394/x3.png",
                "caption": "Figure 3:Qualitative Analysis between TiM and existing methods under different NFEs.TiM delivers superior fidelity and text alignment across all NFEs. In contrast, multi-step diffusion and few-step distilled models exhibit pronounced step–quality trade-offs: SDXL, SD3.5-Large, and FLUX.1-Dev fail to generate images at low NFEs, while SDXL-Turbo, SD3.5-Turbo, and FLUX.1-Schnell produce over-saturated outputs at high NFEs.",
                "position": 1261
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ATransition Model Framework",
        "images": []
    },
    {
        "header": "Appendix BConnections with Existing Methods",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.04394/x4.png",
                "caption": "Figure 4:TiM Model Architecture.",
                "position": 3432
            },
            {
                "img": "https://arxiv.org/html/2509.04394/x4.png",
                "caption": "Figure 4:TiM Model Architecture.",
                "position": 3435
            },
            {
                "img": "https://arxiv.org/html/2509.04394/x5.png",
                "caption": "Figure 5:TiM T2I block.",
                "position": 3441
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.04394/x6.png",
                "caption": "Figure 6:High-resolution and multi-aspect generations from TiM (128 NFEs).TiM attains up to4096×40964096\\times 4096resolution and reliably handles multiple aspect ratios, including1024×40961024\\times 4096and2560×10242560\\times 1024.",
                "position": 4552
            }
        ]
    },
    {
        "header": "Appendix EQualitative Results",
        "images": []
    }
]