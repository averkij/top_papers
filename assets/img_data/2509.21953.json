[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x1.png",
                "caption": "Figure 1:MultiCrafter enables multi-subject personalization. Inputs are surrounded by squares.",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x2.png",
                "caption": "Figure 2:Visual comparison of attention maps. The ICL-based method UNO, which only relies on reconstruction loss (left), fails to preserve the subject fidelity, where the double blockâ€™s attention regions for each subject are entangled, leading to attribute leakage. Our method overcomes this problem and maintains subject fidelity.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x3.png",
                "caption": "Figure 3:Overall pipeline of MultiCrafter. Our framework is built on three core innovations: (Top Left) Identity-Disentangled Attention Regularization uses positional supervision to prevent attribute leakage; (Top Right) the MoE-LORA architecture boosts model capacity for diverse scenarios; and (Bottom) the Identity-Preserving Preference Alignment framework employs a novel online reinforcement learning strategy with a Multi-ID Alignment Reward and the stable GSPO algorithm to align the model with human preferences.",
                "position": 218
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x4.png",
                "caption": "Figure 4:Qualitative comparison with existing methods on the multi-human generation (Zoom in for best visual comparison). Our method significantly improves subject fidelity.",
                "position": 546
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Details for Identity-Preserving Preference Optimization",
        "images": []
    },
    {
        "header": "Appendix BMore Implementation Details.",
        "images": []
    },
    {
        "header": "Appendix CTraining Dataset Construction Pipeline.",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x5.png",
                "caption": "Figure 5:Data processing pipeline for customized multi human image generation.",
                "position": 1916
            }
        ]
    },
    {
        "header": "Appendix DMore Details for Our Benchmark.",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x6.png",
                "caption": "Figure 6:Visualization for part of our multi-human evaluation benchmarks.",
                "position": 1929
            }
        ]
    },
    {
        "header": "Appendix ELimitation.",
        "images": []
    },
    {
        "header": "Appendix FThe Use of Large Language Models.",
        "images": []
    },
    {
        "header": "Appendix GMore Results of Multi-Human Personalization.",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x7.png",
                "caption": "Figure 7:More Visualization of our method in Multi-Human Personalization.",
                "position": 1966
            },
            {
                "img": "https://arxiv.org/html/2509.21953/x8.png",
                "caption": "Figure 8:More Visualization of our method in Multi-Human Personalization.",
                "position": 1969
            }
        ]
    },
    {
        "header": "Appendix HMore Results of Multi-Object Personalization.",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21953/x9.png",
                "caption": "Figure 9:Visualization of our method in Multi-Object Personalization.",
                "position": 1982
            },
            {
                "img": "https://arxiv.org/html/2509.21953/x10.png",
                "caption": "Figure 10:Visualization of our method in Single-Subject Personalization.",
                "position": 1995
            },
            {
                "img": "https://arxiv.org/html/2509.21953/x11.png",
                "caption": "",
                "position": 1999
            },
            {
                "img": "https://arxiv.org/html/2509.21953/x12.png",
                "caption": "Figure 11:Qualitative comparison with existing methods on the single human generation.",
                "position": 2003
            }
        ]
    },
    {
        "header": "Appendix IMore Results of Single-Subject Personalization.",
        "images": []
    }
]