[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12769/extracted/6219631/images/estimation_pipeline.png",
                "caption": "Figure 1:Illustration of our approach for estimating hallucination rates in the wild.Hallucination Detection and Model Evaluation(left side): (1) We automatically translate the English FAVAMishra et¬†al. (2024)dataset to 30 languages and train our multilingual hallucination detection (HD) model on this (noisy) multilingual training data; (2) We synthesize asilvermultilingual hallucination evaluation dataset by prompting a state-of-the-art LLM (GPT-4) to introduce hallucinations in its answers to knowledge-seeking questions; for a subset of five high-resource languages, we additionally collectgold(i.e., human) hallucination annotations; we dub this 30-language evaluation benchmarkmFAVA. We usemFAVAto estimate HD model‚Äôs per-language performances (precision and recall).Hallucination Rate Estimation in the Wild(right side): (3) We estimate the hallucination rates for all 30 languages and six different LLM families from the number of detections of the HD model and its performance.",
                "position": 120
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12769/x1.png",
                "caption": "Figure 2:1)Inter-annotator agreement (IAA) for hallucination span detection (Binary; blue bars) and classification (Category; orange bars) for five high-resource languages;2)Hallucination span and class agreement between human labels and GPT-4 generated hallucinations (Silver-Gold; agreement on spans only: red bars; agreement on spansandhallucination type: green bars).",
                "position": 168
            }
        ]
    },
    {
        "header": "3Hallucination Detection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12769/x2.png",
                "caption": "Table 3:Token-level F1 performance of multilingual (Multi) and monolingual (Mono) hallucination detection models for five high-resource languages with bothSilverandGoldevaluation data inmFAVA. Performance reported for hallucination detection alone (Binary) and hallucination detection and type classification (Category). Models fine-tuned without (Bidirect) or with (Causal) future token masking.Bold: best result in each column.",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x2.png",
                "caption": "Figure 3:Comparison of hallucination rate estimatesùêªùëÖest,lsubscriptùêªùëÖestùëô\\mathit{HR}_{\\text{est},l}italic_HR start_POSTSUBSCRIPT est , italic_l end_POSTSUBSCRIPT(mean¬±plus-or-minus\\pm¬±std over five LLM runs) for Arabic (AR), Chinese (ZH), German (DE), Russian (RU), and Turkish (TR) for 3 LLMs based on the estimates ofPlsubscriptùëÉùëô\\mathit{P}_{l}italic_P start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTandRlsubscriptùëÖùëô\\mathit{R}_{l}italic_R start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTof theMulti(Bidirect) model on (1)mFAVA-Silver (top row) and (2)mFAVA-Gold (bottom row). The two sets of estimates are highly correlated(r=0.83,p=1.26‚Å¢e‚àí04)formulae-sequenceùëü0.83ùëù1.26ùëí04(r=0.83,p=1.26e-04)( italic_r = 0.83 , italic_p = 1.26 italic_e - 04 ).",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x3.png",
                "caption": "Figure 4:Mean estimates of in-the-wild hallucination rates (¬±plus-or-minus\\pm¬±std) for 30 languages and 11 LLMs. Each mean score is an average of 15ùêªùëÖest,lsubscriptùêªùëÖestùëô\\mathit{HR}_{\\text{est},l}italic_HR start_POSTSUBSCRIPT est , italic_l end_POSTSUBSCRIPTestimates, (3 different HD model instances applied to 5 different LLM responses). Average rates increase from top to bottom (over languages) and from left to right (over LLMs).",
                "position": 453
            }
        ]
    },
    {
        "header": "4Estimating Hallucination in the Wild",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12769/x4.png",
                "caption": "(a)",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x4.png",
                "caption": "(a)",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x5.png",
                "caption": "(b)",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x6.png",
                "caption": "(c)",
                "position": 513
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12769/x7.png",
                "caption": "Figure 6:Distribution of 6 labels across 30 languages inmFava-Silverdataset.",
                "position": 1726
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x8.png",
                "caption": "(a)Hallucinations vs response length correlation of smaller models.",
                "position": 2223
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x8.png",
                "caption": "(a)Hallucinations vs response length correlation of smaller models.",
                "position": 2226
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x9.png",
                "caption": "(b)Hallucinations vs response length correlation of bigger models.",
                "position": 2232
            },
            {
                "img": "https://arxiv.org/html/2502.12769/x10.png",
                "caption": "(c)Hallucinations vs response length correlation of bigger models.",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2502.12769/extracted/6219631/images/annotation_instruction.png",
                "caption": "Figure 8:Annotation Instructions.",
                "position": 2245
            },
            {
                "img": "https://arxiv.org/html/2502.12769/extracted/6219631/images/annotation_instruction.png",
                "caption": "",
                "position": 2248
            },
            {
                "img": "https://arxiv.org/html/2502.12769/extracted/6219631/images/annotation_instruction_2.png",
                "caption": "",
                "position": 2253
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]