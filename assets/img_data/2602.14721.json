[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x1.png",
                "caption": "Figure 1:Overview of WebWorld. WebWorld is a large-scale world model for the open web, trained on over 1M real-world trajectories. It supports long-horizon, multi-format simulation, enabling agents trained with its data to achieve significant performance gains.",
                "position": 106
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x2.png",
                "caption": "Figure 2:WebWorld Example. Left: Agent. Right: WebWorld.",
                "position": 310
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Training WebWorld",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x3.png",
                "caption": "(a)Overall Domain Distribution",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2602.14721/x3.png",
                "caption": "(a)Overall Domain Distribution",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2602.14721/x4.png",
                "caption": "(b)Token Length Distribution",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2602.14721/x5.png",
                "caption": "(c)Trajectory Turns Distribution",
                "position": 504
            }
        ]
    },
    {
        "header": "4Benchmarking Web World Model",
        "images": []
    },
    {
        "header": "5Extrinsic Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x6.png",
                "caption": "Figure 4:Scaling Law of WebWorld.Larger models achieve lower eval loss. Stars indicate predictions for the 72B model, suggesting continued performance gains with model scaling.",
                "position": 1336
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": []
    },
    {
        "header": "7Conclusions and Limitations",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AWorld Model Training Details",
        "images": []
    },
    {
        "header": "Appendix BAPI Models",
        "images": []
    },
    {
        "header": "Appendix CBaseline Implementation Details",
        "images": []
    },
    {
        "header": "Appendix DTraining Data Composition",
        "images": []
    },
    {
        "header": "Appendix EDomain Distribution Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x7.png",
                "caption": "Figure 5:Domain and Source Distribution of WebWorld Training Data.The chart illustrates the composition of our trajectory dataset, which contains over one million samples, across 15 distinct data sources.\nThe colors represent different semantic domains (e.g., Technology, E-Commerce), showing that our data collection pipelines significantly contribute to the diversity of open-domain topics compared to traditional web generation methods.",
                "position": 2351
            }
        ]
    },
    {
        "header": "Appendix FAction Space Definition",
        "images": []
    },
    {
        "header": "Appendix GFormat Conversion Pipeline",
        "images": []
    },
    {
        "header": "Appendix HURL Filtering with LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/fig/url_filter.png",
                "caption": "Figure 6:LLM-based URL Filtering Pipeline.We evaluate candidate URLs across four dimensions—accessibility, content suitability, interactivity, and engineering quality—using an LLM judge. The chart shows the distribution of scores and the filtering threshold (red dashed line), which retains only the top 32% of URLs for data collection.",
                "position": 2581
            }
        ]
    },
    {
        "header": "Appendix ICross-Environment Generalization Data",
        "images": []
    },
    {
        "header": "Appendix JWorld Model Evaluation Taxonomy",
        "images": []
    },
    {
        "header": "Appendix KGeneration Length Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14721/x8.png",
                "caption": "Figure 7:Impact of Reasoning Activation on Output Token Length.The plot compares the average tokens of answer between the Real-World Transition Modeling baseline (grey dashed line) and the Reasoning Activation stage (blue solid line). The introduction of reasoning data leads to a∼\\sim49.4% reduction in output length, indicating a shift from verbose raw state prediction to a more concise and structured simulation pattern.",
                "position": 2845
            }
        ]
    },
    {
        "header": "Appendix LMultimodality Discussion",
        "images": []
    },
    {
        "header": "Appendix MEthical Considerations",
        "images": []
    },
    {
        "header": "Appendix NPrompt Templates",
        "images": []
    }
]