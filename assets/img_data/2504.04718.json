[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.04718/x1.png",
                "caption": "(a)Concept figure",
                "position": 184
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x1.png",
                "caption": "(a)Concept figure",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x2.png",
                "caption": "(b)Concept-proof results",
                "position": 193
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.04718/x3.png",
                "caption": "Figure 2:Tool-integrated self-verification for mathematical reasoning.(a)Generator:A small language model (sLM) may produce incorrect solutions due to calculation errors.\n(b)Tool-based Verifier (ToolV):The sLM generates executable code based on its reasoning; the output of the code is used to verify the solution‚Äôs correctness.\n(c)Reward Model (RM)-based Verifier:The reward model (GenRM / PRM) still evaluates the solution as before, but its verdict only contributes to the final decision if the solution passes the tool-assisted filter.\nConcrete examples are inAppendix¬†F.",
                "position": 347
            }
        ]
    },
    {
        "header": "5Theoretical analysis",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.04718/x4.png",
                "caption": "Figure 3:MATH500 with PRM.Weighted Best-of-N performance of three small language models, emphasizing the benefits of ToolV on college-level math problems. ToolV significantly enhances PRM, enabling small models to outperform or match much larger models. Qwen2.5-1.5B and Llama3.1-8B performances are reported asN=1ùëÅ1N=1italic_N = 1greedy decoding.",
                "position": 631
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x5.png",
                "caption": "Figure 4:MATH500 with GenRM.Weighted Best-of-N performance of three small language models, showcasing the effectiveness of ToolV with GenRM, where even generative verification cannot supplement the calculation error which can be easily filtered out by using a tool.",
                "position": 646
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x6.png",
                "caption": "Figure 5:GSM8K with GenRM.Weighted Best-of-N performance comparison across three small language models. The results show that ToolV also improves model performance on graduate-level arithmetic problems. However, the gains are smaller on this simpler task, where existing verifiers already perform reliably compared to more challenging tasks.",
                "position": 649
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x7.png",
                "caption": "Figure 6:MMLU-Pro with PRM.Weighted Best-of-N (N=64ùëÅ64N=64italic_N = 64) performance of Llama-3.2-1B-Instruct on three knowledge-intensive domains, illustrating the effect of different document sources in ToolV + Distilled PRM (retrieved and gold documents). ToolV extends beyond math, improving PRM on multi-domain knowledge-intensive reasoning tasks.",
                "position": 652
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x8.png",
                "caption": "Figure 7:Analysis with problem types and levels.We perform analysis on the effect of tool-based verifier with problem types and levels inMATH500dataset. The results are from Llama-3.2-1B-Instruct with PRM using weighted Best-of-N (N=64ùëÅ64N=64italic_N = 64). This analysis shows ToolV is most effective on mid-level problems and calculational domains.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x9.png",
                "caption": "Figure 8:Effects of ToolV on sizes of GenRM.Weighted Best-of-N (N=64ùëÅ64N=64italic_N = 64) performance of GenRM based on different sizes of Llama 3(Dubey et¬†al.,2024)onMATH500. For ToolV, we use 1B and only scale up the GenRM.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x9.png",
                "caption": "Figure 8:Effects of ToolV on sizes of GenRM.Weighted Best-of-N (N=64ùëÅ64N=64italic_N = 64) performance of GenRM based on different sizes of Llama 3(Dubey et¬†al.,2024)onMATH500. For ToolV, we use 1B and only scale up the GenRM.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x10.png",
                "caption": "Figure 9:Correct solutions ratioamongN=64ùëÅ64N=64italic_N = 64generations to show how the tool-based verifier works.",
                "position": 671
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AConcept-Proof Experiment Details",
        "images": []
    },
    {
        "header": "Appendix BDetails of Our Method",
        "images": []
    },
    {
        "header": "Appendix CProof for Theoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    },
    {
        "header": "Appendix EAdditional experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.04718/x11.png",
                "caption": "Figure 10:Confusion matrix of verification results from GenRM and GenRM + ToolV, where True denotes the correct solution. This result indicates ToolV improves the performance on removing false positive cases. Results are from experiments with Llama-3.2-1B-Instruct on MATH500 benchmark.",
                "position": 2300
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x11.png",
                "caption": "",
                "position": 2303
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x12.png",
                "caption": "",
                "position": 2307
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x13.png",
                "caption": "Figure 11:Data-scale experiment.Performance comparison with varying distillation data sizes. In each plot, one verifier is distilled with 10% or 1% of data, while the other uses the full dataset. ToolV remains competitive even with only 10% of data, highlighting its data efficiency. Results are from experiments with Llama-3.2-1B-Instruct on MATH500.",
                "position": 2313
            },
            {
                "img": "https://arxiv.org/html/2504.04718/x14.png",
                "caption": "Figure 12:MMLU-Pro with PRM (Line Plot).Weighted Best-of-N performance of Llama-3.2-1B-Instruct on three knowledge-intensive domains from MMLU-Pro.",
                "position": 2316
            }
        ]
    },
    {
        "header": "Appendix FCase analysis",
        "images": []
    }
]