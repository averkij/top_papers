[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19402/x1.png",
                "caption": "Figure 1:(Left) Comparing reward-based pretraining (RPT) and traditional supervised pertaining (SPT). Supervised pretraining requires the model to directly predict answers, limiting its ability to refine intermediate solutions. In contrast, RPT enables step-by-step reasoning from the outset, allowing the model to iteratively approximate complex functions through simpler transitions that are easier to learn and more robust to errors(Carreira et al.,2016). (Right) Illustration of our proposed decoupled memory-reasoning architecture. This design allows the reasoning module to operate on shorter context windows that reduce the chances of learning spurious correlations and, thereby, more transferrable reasoning. The use of a shorter context window also encourages the model to learn how to dynamically read and write to memory, which facilitates the use of reasoning model on new problems and knowledge domains.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Background and Notation",
        "images": []
    },
    {
        "header": "3Evaluation of Reasoning Separate From Knowledge",
        "images": []
    },
    {
        "header": "4Proposed Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19402/x2.png",
                "caption": "Figure 2:Comparing the different training paradigms of RPT vs. SPT-then-RFT in Go 9×\\times×9. These results affirm the hypothesis that the SPT can restrict the model’s subsequent exploration with RL. The KL regularization is added to replicate common training paradigms in language models(Gao et al.,2023; Paulus,2017; Alami et al.,2024).",
                "position": 408
            }
        ]
    },
    {
        "header": "5Discussion and Alternative Views",
        "images": []
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Acknowledgment",
        "images": []
    },
    {
        "header": "8Author Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABrainf**k and Befunge Experimental Details",
        "images": []
    }
]