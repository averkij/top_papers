[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14616/x1.png",
                "caption": "Figure 1:WritingPreferenceBenchisolates subjective writing quality by neutralizing objective confounds (grammar, factuality, length). Across 1,800 human-validated preference pairs, standard sequence classifiers (SC-RM) perform near-randomly while generative reward models (GenRM) achieve 30% higher accuracyâ€”but both architectures exhibit catastrophic instability across genres, exposing the brittleness of current preference learning.",
                "position": 165
            }
        ]
    },
    {
        "header": "2WritingPreferenceBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14616/x2.png",
                "caption": "Figure 2:The data curation pipeline ofWritingPreferenceBench. Our multi-stage process begins with expert-crafted queries across 51 genres, generates diverse responses using 20 state-of-the-art models, and culminates in rigorous human evaluation by trained annotators. Quality control mechanisms operate throughout to ensure preference pairs reflect genuine subjective quality distinctions rather than objective differences.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2510.14616/x3.png",
                "caption": "Figure 3:Distribution of preference pairs across a sample of the 8 writing macro-categories for both English and Chinese inWritingPreferenceBench. The dataset maintains balanced coverage across diverse writing genres, with deliberate oversampling of underrepresented categories to ensure comprehensive evaluation of preference modeling capabilities.",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2510.14616/x4.png",
                "caption": "(a)English dataset",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2510.14616/x4.png",
                "caption": "(a)English dataset",
                "position": 368
            },
            {
                "img": "https://arxiv.org/html/2510.14616/x5.png",
                "caption": "(b)Chinese dataset",
                "position": 373
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": []
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Contributions and Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AUse of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix BFull Taxonomy of Writing Categories",
        "images": []
    },
    {
        "header": "Appendix CGenre-Specific Scoring Guidelines",
        "images": []
    },
    {
        "header": "Appendix DDataset Statistics",
        "images": []
    },
    {
        "header": "Appendix EExamples of Benchmark Queries",
        "images": []
    }
]