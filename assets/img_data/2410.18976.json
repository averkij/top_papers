[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18976/x1.png",
                "caption": "",
                "position": 72
            },
            {
                "img": "https://arxiv.org/html/2410.18976/x2.png",
                "caption": "Figure 1:The proposed CAMEL-Bench covers eight diverse and challenging domains:multimodal understanding and reasoning,OCR anddocuments,charts anddiagrams,videos,cultural-specific content,medical images,agricultural images, andremote sensing understandingin Arabic. CAMEL-Bench covers 38 sub-domains with over 29K questions carefully curated by native Arabic speakers to rigorously evaluate essential skills desired in Arabic LMMs.",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18976/extracted/5952265/Figures/CAMEL-Bench-Samples-4x2.png",
                "caption": "Figure 2:CAMEL-Bench examples spanning eight diverse domains, encompassing a wide range of visual data types and tasks.",
                "position": 102
            }
        ]
    },
    {
        "header": "2CAMEL-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18976/x3.png",
                "caption": "Figure 3:The CAMEL-Bench Filtering and Verification Pipeline consists of two paths: Original Arabic and translated Arabic. For original Arabic (top row), a 20% random sample undergoes manual verification; if errors are below 40%, the data passes; otherwise, the entire sub-category is reviewed. For Translated Arabic (bottom row), We employ Qwen7B model[8]to assess semantic similarity between the original and translated question-answer pairs on fuzzy-basis evaluation. Pairs passing the evaluation proceed, while those that fail undergo manual review. Based on this, data may requireManual Handlingfor manual re-translation,Refine & Verifyfor refinement through the model, orNon-Translated Reviewwhere the data is re-sent for translation due to the absence of an Arabic version.",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2410.18976/extracted/5952265/Figures/Closed-weight-Samples.png",
                "caption": "Figure 4:Qualitative example highlighting different scenarios where different closed-weight models struggle on CAMEL-Bench. The correct response is shown in green, and the incorrect one in the red box.",
                "position": 657
            }
        ]
    },
    {
        "header": "3CAMEL-Bench Benchmark Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18976/extracted/5952265/Figures/Open-weight-Samples.png",
                "caption": "Figure 5:Qualitative example highlighting different scenarios where different open-weight models struggle on CAMEL-Bench. The correct response is shown in green, and the incorrect one in the red box.",
                "position": 669
            }
        ]
    },
    {
        "header": "4Conclusion, Limitations and Societal Impact",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "Appendix BMore on Dataset Curation",
        "images": []
    },
    {
        "header": "Appendix CDataset Overview and Task Splits",
        "images": []
    },
    {
        "header": "Appendix DCAMEL-Bench Data Samples",
        "images": []
    }
]