[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15713/x1.png",
                "caption": "",
                "position": 72
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15713/x2.png",
                "caption": "Figure 2:Paradigm Shift and Modality Shift.We demonstrate that any autoregressive models with different modalities can be translated to the diffusion vision language models effectively.",
                "position": 117
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15713/x3.png",
                "caption": "Figure 3:The diffusion finetuning framework of our model.After the input is converted into the embedding space, block-wise noise is added to the answer text sequence within this space. The noise sequencextix_{t}^{i}is concatenated with the original sequencex0ix_{0}^{i}and fed into the language model. A noisy block can see information about the preceding blocks in the corresponding clean sequence (offset block causal) and other positions within the same block (block diagonal). During inference, the attention pattern of the clean sequence is used (block causal). The model performs denoising prediction and finally computes the loss at the masked noisy positions.",
                "position": 154
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15713/x4.png",
                "caption": "Figure 4:Balancing speed and quality for detailed image captioning.We define the parallelism factor for dVLMs as the average number of tokens generated simultaneously throughout the sequence (for instance,1Ã—1\\timesparallelism corresponds to single-token sampling). Speed metrics were collected using 8 GPUs, with results reported as the average per device.",
                "position": 903
            },
            {
                "img": "https://arxiv.org/html/2512.15713/x5.png",
                "caption": "Figure 5:Performance and speed between different thresholds for dynamic low-confidence remasking.By adjusting the thresholds, DiffusionVL can achieve extreme acceleration contrast to static low-confidence remasking. And it also offers a tunable balance between speed and output quality (BERTScore).",
                "position": 963
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    }
]