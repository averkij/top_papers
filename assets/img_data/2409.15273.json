[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15273/x1.png",
                "caption": "",
                "position": 125
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15273/x2.png",
                "caption": "Figure 2:StableMaterial receives an RGB image as input and outputs the albedoùêà^dsubscript^ùêàd\\hat{\\mathbf{I}}_{\\text{d}}over^ start_ARG bold_I end_ARG start_POSTSUBSCRIPT d end_POSTSUBSCRIPTand ORMùêà^ormsubscript^ùêàorm\\hat{\\mathbf{I}}_{\\text{orm}}over^ start_ARG bold_I end_ARG start_POSTSUBSCRIPT orm end_POSTSUBSCRIPT2D maps. To train StableMaterial, we use BlenderVault objects to render a dataset of multi-view images under varying illuminations as well as the corresponding albedo and ORM maps. Given a triplet(ùê±,ùêàd,ùêàorm)ùê±subscriptùêàdsubscriptùêàorm(\\mathbf{x},\\mathbf{I}_{\\text{d}},\\mathbf{I}_{\\text{orm}})( bold_x , bold_I start_POSTSUBSCRIPT d end_POSTSUBSCRIPT , bold_I start_POSTSUBSCRIPT orm end_POSTSUBSCRIPT )of an image and its albedo and ORM maps, we encode them using the pretrained Stable Diffusion encoder and concatenate the image latent with the noisy albedo and ORM latents. The model is then trained with a diffusion loss to denoise the albedo and ORM maps.",
                "position": 189
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15273/x3.png",
                "caption": "Figure 3:MaterialFusion reconstructs an object‚Äôs geometry, PBR materials, and environmental illumination from a set of multi-view images under a fixed lighting condition. In addition to the reconstruction and regularization losses computed between our rendered imagesùê±^^ùê±\\hat{\\mathbf{x}}over^ start_ARG bold_x end_ARGand reference RGB imagesùê±ùê±\\mathbf{x}bold_x, MaterialFusion employs priors from our pre-trained StableMaterial to enhance PBR material reconstruction. Specifically, it calculates an SDS loss for the rendered albedo and ORM components,ùêà^dsubscript^ùêàd\\hat{\\mathbf{I}}_{\\text{d}}over^ start_ARG bold_I end_ARG start_POSTSUBSCRIPT d end_POSTSUBSCRIPTandùêà^ormsubscript^ùêàorm\\hat{\\mathbf{I}}_{\\text{orm}}over^ start_ARG bold_I end_ARG start_POSTSUBSCRIPT orm end_POSTSUBSCRIPTconditioned onùê±ùê±\\mathbf{x}bold_x.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x4.png",
                "caption": "Figure 4:Qualitative comparison for MaterialFusion vs. other methods. We present the 3D reconstructed albedo, ORM, environment light map, and relit rendered images for three different objects, both synthetic and real. Our method demonstrates better accuracy compared to the baseline methods, as can be seen by the accuracy of the reconstructed materials and the relit image appearance. Our prior also acts as an additional regularizer on other 3D properties such as geometry and illumination.",
                "position": 283
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15273/x5.png",
                "caption": "Figure 5:Qualitative comparison of the albedo and ORM 2D predictions. The Derender3D ORM data is marked as N/A since it does not offer ORM predictions. Given 4 images of an object, StableMaterial recovers complex material data. StableMaterialMV attends to appearance details across views, recovering consistent and high quality materials across challenging views, as seen in the cup example.",
                "position": 544
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Visualizations",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.15273/x6.png",
                "caption": "",
                "position": 1645
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x7.png",
                "caption": "Figure 6:Full albedo and ORM comparison results for StableMaterial on the cup and armatures examples shown in Fig.5.",
                "position": 1647
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x8.png",
                "caption": "",
                "position": 1650
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x9.png",
                "caption": "Figure 7:Additional albedo and ORM comparisons for randomly selected examples from the BlenderVault test dataset.",
                "position": 1652
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x10.png",
                "caption": "",
                "position": 1655
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x11.png",
                "caption": "Figure 8:Additional albedo and ORM comparisons for randomly selected examples from the BlenderVault test dataset.",
                "position": 1657
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x12.png",
                "caption": "Figure 9:Comparison of MaterialFusion vs. other methods for relighting the clock object from the BlenderVault test dataset.",
                "position": 1660
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x13.png",
                "caption": "Figure 10:Additional comparisons for MaterialFusion vs. other methods on 3D physical properties reconstruction on more objects from the BlenderVault test dataset.",
                "position": 1663
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x14.png",
                "caption": "Figure 11:Additional comparisons for MaterialFusion vs. other methods on 3D physical properties reconstruction on the NeRFactor dataset.",
                "position": 1666
            },
            {
                "img": "https://arxiv.org/html/2409.15273/x15.png",
                "caption": "Figure 12:Additional comparisons for MaterialFusion vs. other methods on 3D physical properties reconstruction on the NeRF dataset.",
                "position": 1669
            }
        ]
    },
    {
        "header": "8Additional Details",
        "images": []
    }
]