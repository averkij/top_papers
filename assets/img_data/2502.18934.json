[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x1.png",
                "caption": "Figure 1:Performance to pre-training computational cost for Kanana and comparable models.\nWe measure computational cost in FLOPs (Floating Point Operations), which is approximately calculated as 6×\\times×training tokens×\\times×model size(Kaplan et al.,2020).\nWe only calculate student training FLOPs for distillation models.\nObviously, Kanana models achieves decent performance given their limited computational cost.",
                "position": 111
            }
        ]
    },
    {
        "header": "2Pre-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x2.png",
                "caption": "(a)Stage 1 data",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x2.png",
                "caption": "(a)Stage 1 data",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x3.png",
                "caption": "(b)Stage 2 data",
                "position": 515
            }
        ]
    },
    {
        "header": "3Post-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x4.png",
                "caption": "(a)SFT data",
                "position": 1310
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x4.png",
                "caption": "(a)SFT data",
                "position": 1313
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x5.png",
                "caption": "(b)Preference data",
                "position": 1318
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x6.png",
                "caption": "Figure 4:Kanana model performance for each stage of training across different model sizes.\nThe y-axis is the average of normalized scores of all benchmarks inTable 7andTable 8.\nThe normalization process is done by dividing each score with the maximum possible score.",
                "position": 1335
            }
        ]
    },
    {
        "header": "4Adaptations",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x7.png",
                "caption": "Figure 5:Performance Comparison of Various Models Based on averaged helpfulness and grounding in RAG-General-Bench.",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x8.png",
                "caption": "Figure 6:QA Generation Pipeline",
                "position": 1554
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Contributors and Acknowledgements",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x9.png",
                "caption": "Figure 9:Illustration of ensuring query-key-value alignment in GQA pruning.",
                "position": 3904
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix CQualititive Results",
        "images": []
    },
    {
        "header": "Appendix DEvaluation Details of Embedding Models",
        "images": []
    },
    {
        "header": "Appendix ERAG-General-Bench Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18934/x10.png",
                "caption": "(a)",
                "position": 4628
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x10.png",
                "caption": "(a)",
                "position": 4631
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x11.png",
                "caption": "(b)",
                "position": 4637
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x12.png",
                "caption": "(a)",
                "position": 4645
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x12.png",
                "caption": "(a)",
                "position": 4648
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x13.png",
                "caption": "(b)",
                "position": 4653
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x14.png",
                "caption": "Figure 14:FunctionChat-bench Example : Single-call(1_exact)",
                "position": 4670
            },
            {
                "img": "https://arxiv.org/html/2502.18934/x15.png",
                "caption": "Figure 15:FunctionChat-bench Example : Dialogue",
                "position": 4708
            }
        ]
    },
    {
        "header": "Appendix FFunctionChat-Bench Examples",
        "images": []
    }
]