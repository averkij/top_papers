[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20426/x1.jpg",
                "caption": "",
                "position": 69
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20426/figures/motivation.jpg",
                "caption": "Figure 2:Block Cascading Inference:Our inference pipeline reduces dependency on clean, denoised blocks for future block generation. For example in here (center), we denoise blockBt31={f3,f4,f5}B^{1}_{t_{3}}{=}\\{f^{3},f^{4},f^{5}\\}andBt20={f3,f4,f5}B^{0}_{t_{2}}{=}\\{f^{3},f^{4},f^{5}\\}jointly using bidirectional attention instead of waiting forBtc0B^{0}_{t_{c}}to denoiseBt31B^{1}_{t_{3}}(left)[51,14,47]. By reducing dependency on previous blocks, we can free up the inference pipeline and allow parallel processing of multiple blocks (right) to improve generation speed significantly.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2511.20426/x2.png",
                "caption": "Figure 3:Expensive KV-recaching:KV-recaching can result in FPS drop in interactive generation as previous generated and stored cache has to be recached using new context. We skip KV-recaching as our KV is auto-recomputed using new context.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2511.20426/figures/comparisons_full.jpg",
                "caption": "Figure 4:Qualitative comparisons:Comparing our bidirectional inference pipeline with corresponding original inference pipelines",
                "position": 331
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20426/figures/abl_single.png",
                "caption": "(a)Ablative config. in Single GPU environment",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2511.20426/figures/abl_single.png",
                "caption": "(a)Ablative config. in Single GPU environment",
                "position": 345
            },
            {
                "img": "https://arxiv.org/html/2511.20426/figures/abl_multi.png",
                "caption": "(b)Ablative config. in Multi GPU environment",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2511.20426/figures/interactive_generation.png",
                "caption": "(c)FPS drop from KV-recaching",
                "position": 355
            },
            {
                "img": "https://arxiv.org/html/2511.20426/x3.png",
                "caption": "Figure 6:Bidirectional Inference:Causal attention in fully parallelised generation (ùí´4\\mathcal{P}_{4}) can yield artifacts. These can be fixed by using bidirectional attention with same fully parallelised pipeline.",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2511.20426/x4.png",
                "caption": "Figure 7:Cascading Types:Different types of cascading leads to different levels of parallelism. We conduct a user study to analyse performance across differently cascaded pipelines. Atùí´1\\mathcal{P}_{1}, the pipeline reduces to block-causal pipelines like Self-Forcing[14]",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2511.20426/x5.png",
                "caption": "Figure 8:User Study:We conduct a user study to analyse video quality from our cascaded bidirectional pipeline against original inference pipelines of other models under different configurations.",
                "position": 384
            }
        ]
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]