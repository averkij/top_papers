[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_compare_pretrained.jpg",
                "caption": "Figure 3:Performance of age transformation techniques for age regression (first two rows) and age progression (last two rows). The first column shows the input image, and the second column provides a reference image of the same person at the target age. MyTM (Ours) is compared against other state-of-the-art methods including SAM[2], CUSP[14], AgeTransGAN[17], and FADING[7].",
                "position": 809
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_regression.jpg",
                "caption": "Figure 4:Performance of age transformation techniques for age regression, where an input test image around 70 is transformed to all target ages between 0 and 100. We show MyTM (Ours) trained on 40 years of data (ages30‚àº70similar-to307030\\sim 7030 ‚àº 70), with the age range included in the personal training data highlighted in red. An example image of the same person within 3 years of the target age is provided as a reference at bottom.",
                "position": 988
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/user_study.jpg",
                "caption": "Figure 5:User Study comparing our method with baselines‚ÄîFADING and SAM‚Äîfor age regression (atgt‚â§70subscriptùëétgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT ‚â§ 70) and age progression (atgt‚â•40subscriptùëétgt40a_{\\text{tgt}}\\geq 40italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT ‚â• 40).\nWe present the percentage of user preference for our method over the baselines.",
                "position": 991
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/video_reaging.jpg",
                "caption": "Figure 6:We apply video re-aging on a video ofJackie Chanfrom the movieBleeding Steel. Left: The keyframe from the source video that we re-age with MyTM. Right: The re-aged face is mapped onto other frames of the source video via face-swapping.",
                "position": 1098
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/ablation_dataset_size.jpg",
                "caption": "Figure 7:Effect of training dataset sizeùíüùíü\\mathcal{D}caligraphic_Don personalization. MyTM is trained on ages 30‚àºsimilar-to\\sim‚àº70 and tested foratgt‚â§70subscriptùëétgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT ‚â§ 70. Visual examples ofRobert De Niroare shown at the top, with quantitative results displayed below.",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/ablation_loss_net.jpg",
                "caption": "Figure 8:Contributions of our proposed loss functions and the adapter network for the age regression task, trained on ages 30‚àºsimilar-to\\sim‚àº70 and tested foratgt‚â§70subscriptùëétgt70a_{\\text{tgt}}\\leq 70italic_a start_POSTSUBSCRIPT tgt end_POSTSUBSCRIPT ‚â§ 70onAl Pacino.",
                "position": 1157
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOverview of Appendices",
        "images": []
    },
    {
        "header": "Appendix BDataset Curation",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DComparison with SOTA Methods without Personalization",
        "images": []
    },
    {
        "header": "Appendix EComparison with Naive Personalization Techniques.",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/ablation_personalization.jpg",
                "caption": "Figure 9:We compare MyTM (Ours) with naive personalization techniques: SAM Pers. ft., SAM Pers. ft. + MyStyle, and FADING + Dreambooth, trained on ages 30‚àºsimilar-to\\sim‚àº70 and tested within the same age range forAl Pacino. While SAM Pers. ft. + MyStyle achieves a highIDs‚Å¢i‚Å¢msubscriptIDùë†ùëñùëö\\text{ID}_{sim}ID start_POSTSUBSCRIPT italic_s italic_i italic_m end_POSTSUBSCRIPTscore, it suffers from poor visual quality, resulting in adversarial examples for ArcFace.",
                "position": 2480
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_progression.jpg",
                "caption": "Figure 10:Performance of personalized age transformation techniques for age progression, where an input test image is transformed to all target ages between 0 and 100. MyTM (Ours) is trained on 20 years of data (ages 20‚àºsimilar-to\\sim‚àº40). The age range included in the personal training data is highlighted in red. We also provide an example image of the same person within 3 years of the target age as a reference.",
                "position": 2529
            }
        ]
    },
    {
        "header": "Appendix FWhy Personalizing the Encoder SAM?",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/fading_failure.jpg",
                "caption": "Figure 11:Visual results of FADING using identical input and inference code. The instability in age transformation arises from the optimization of NTI[34], leading to inconsistencies.",
                "position": 2544
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_baseline.jpg",
                "caption": "Figure 12:Performance of age transformation techniques for age regression (top) and age progression (bottom). The input test images match those in Fig.4and Fig.10for consistency. For age regression, MyTM (Ours) is trained across a 40-year range (ages 30 to 70), while for age progression, it is trained over a 20-year range (ages 20 to 40). Personalized training data age ranges are marked in red. A reference image of the same person, taken within three years of the target age, is included for comparison.",
                "position": 2554
            },
            {
                "img": "https://arxiv.org/html/2411.14521/extracted/6016136/fig/age_regression_oprah.jpg",
                "caption": "Figure 13:Limitations of MyTM. Our method may struggle with accessories (e.g., glasses), as these elements are not consistently handled by the e4e encoder[57].",
                "position": 2559
            }
        ]
    },
    {
        "header": "Appendix GWhy Not Use a Reference Image for Face-Swapping?",
        "images": []
    }
]