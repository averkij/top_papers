[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05621/x1.png",
                "caption": "Figure 1:Image restoration results of GPT-4o on real world degradation. The first row and second row are degraded inputs and the restored outputs, respectively. (a)-(d) correspond to low-light conditions, heavy noise, motion blur, and dense haze, respectively.\\cref@constructprefixpage\\cref@result",
                "position": 62
            },
            {
                "img": "https://arxiv.org/html/2505.05621/x2.png",
                "caption": "Figure 2:Image restoration results of GPT-4o on real-world degraded images without ground truth. Each vertical pair shows a degraded input image (top) and its corresponding restored output (bottom), with the type of degradation labeled beside each pair.\\cref@constructprefixpage\\cref@result",
                "position": 74
            },
            {
                "img": "https://arxiv.org/html/2505.05621/x3.png",
                "caption": "Figure 3:Image restoration results of GPT-4o on real-world degraded images with available ground truth. Each triplet consists of the ground truth image, the degraded input, and the corresponding restored output, with the type of degradation labeled beside each set. We display the PSNR and CLIP-IQA scores below each image, reflecting perceptual quality and pixel-level structural fidelity, respectively.\\cref@constructprefixpage\\cref@result",
                "position": 77
            }
        ]
    },
    {
        "header": "2Restoration of Diverse Degradation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05621/x4.png",
                "caption": "Figure 4:Failure cases. (a) Variations in image proportions. (b) Shifts in object positions and quantities. (c) Changes in viewpoint.\\cref@constructprefixpage\\cref@result",
                "position": 95
            }
        ]
    },
    {
        "header": "3Failure Cases",
        "images": []
    },
    {
        "header": "4A Baseline Solution",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05621/x5.png",
                "caption": "Figure 5:Comparisons on the Rain800[48], LOL[39], and O-HAZE[3]datasets. Rows 1–2 show results on Rain800 dataset, Rows 3–4 are results on LOL dataset, and Rows 5–6 are for O-HAZE dataset. GPT-4o denotes the image restoration results generated by GPT-4o. Baseline refers to the restoration results without using GPT-4o priors, while Ours indicates the enhanced restoration results guided by GPT-4o priors.\\cref@constructprefixpage\\cref@result",
                "position": 132
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.05621/x6.png",
                "caption": "Figure 6:Comparison between GPT-4o and Gemini 2.0 on image restoration tasks.\\cref@constructprefixpage\\cref@result",
                "position": 244
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]