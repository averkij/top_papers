[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16965/x1.png",
                "caption": "Figure 1:Our text-only training using model synthesized textual data enhances VLM decision-making abilities, which are then applied to multimodal inputs in inference.\nThis enables model improvement without image-text paired training data. Complete data samples are shown in  §A.5.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Background and Preliminary Analysis",
        "images": []
    },
    {
        "header": "3Enhancing VLM Decision-Making via Text-Only Training.",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16965/x2.png",
                "caption": "Figure 2:VLM results after text-only training.",
                "position": 249
            }
        ]
    },
    {
        "header": "4How Do Textual Training Data Influence Model Performance?",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Further Discussions on VLM Self-Improvement for Decision-Making",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16965/x3.png",
                "caption": "Figure 4:Comparison of training and inference samples in our experiments. The upper panel shows a text-only training sample generated by GPT-4o, featuring a school conflict scenario that requires careful decision-making. The lower panel shows a multimodal sample from the VIVA benchmarkHu et al. (2024b), presenting a water emergency situation. The option with blue shadow indicates the correct answer.\nDuring training, VLMs are trained to predict the answer given the text-only situations and question. At inference time, these same models process real-world images along with questions to make appropriate situational decisions.",
                "position": 1089
            }
        ]
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    }
]