[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.19144/x1.png",
                "caption": "Figure 1:An overview diagram of the construction of the ChiseLLM datasets and models, including Source Data Processing & Synthesing, Prompt-Guided Reasoning Trace Generation and Reasoning Model Finetuning.",
                "position": 136
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIPreliminary",
        "images": []
    },
    {
        "header": "IVMethod",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.19144/x2.png",
                "caption": "Figure 2:Diagrams related to the ChiseLLM data processing and distillation workflow. Figure (a) illustrate the process of collecting and processing the source data. Figure (b) includes the prompt template used for prompt-guided distillation. Figure (c) shows the statistical characteristics of the ChiseLLM-{Completion,Decompile} datasets.",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2504.19144/x3.png",
                "caption": "Figure 3:Schematic diagrams of the three types of design variant. Practical examples of functional variants are shown in detail in the figure.",
                "position": 329
            }
        ]
    },
    {
        "header": "VExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.19144/x4.png",
                "caption": "Figure 4:Variability design capability of different models on the RTLLM dataset when performing Decompile-to-Chisel tasks. The blue bar represents the open-source reasoning and non-reasoning baseline models. The green bar represents the ChiseLLM-32B model. The red bars represent the commercial models. Each bar is distinctively hatched with different patterns.",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2504.19144/x5.png",
                "caption": "Figure 5:An actual example of ChiseLLM-32B and Qwen2.5-32B-Coder-Instruct decompiling Verilog source code. The gray part represents the Verilog source code, the blue part represents the Chisel module generated by the Qwen model, and the green part represents the Chisel module generated by the ChiseLLM model. The content within the<think>tags represents the thinking process of the ChiseLLM model during decompilation, which, due to its length, is summarized as a numbered list in the figure. The ChiseLLM model follows a structured reasoning process during decompilation, ultimately producing a Chisel module with higher variability and functional extensibility.",
                "position": 940
            }
        ]
    },
    {
        "header": "VICase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.19144/x6.png",
                "caption": "Figure 6:An actual example of ChiseLLM-32B decompiling Verilog source code. The gray part represents the Verilog source code, and the green part represents the Chisel module generated by ChiseLLM. While ensuring all functionalities of the Verilog source code are covered, the module generated by ChiseLLM introduces advanced language features, resulting in higher variability and functional extensibility.",
                "position": 955
            }
        ]
    },
    {
        "header": "VIIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]