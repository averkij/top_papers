[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/university-of-maryland-logo-1.png",
                "caption": "",
                "position": 94
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/722666.png",
                "caption": "",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/ASU-logo.png",
                "caption": "",
                "position": 96
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x1.png",
                "caption": "Figure 1:Attribution (represented by∙⁣−⁣∙⁣−⁣∙∙∙∙\\bullet\\!\\!-\\!\\!\\bullet\\!\\!-\\!\\!\\bullet∙ - ∙ - ∙) withFlowPathAgentensures logical consistency in flowchart-based reasoning.FlowPathAgentuses a neurosymbolic approach to generate attribution paths (➊&➋) in the flowchart. This enhances interpretability and reliability in flowchart driven automated decision-making.",
                "position": 141
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Post-hoc Flowchart Attribution",
        "images": []
    },
    {
        "header": "4FlowExplainBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x2.png",
                "caption": "Figure 2:Overview ofFlowPathAgent.FlowPathAgentprocesses a flowchart image through segmentation-based component labeling, constructs a symbolic graph representation using Mermaid, and employs a neurosymbolic agent, that treats the flowchart as a symbolic graph to attribute nodes based on an input statement. The agent interacts with predefined tools to analyze and traverse the flowchart structure, producing attributions as interpretable mappings of relevant nodes back onto the original flowchart.",
                "position": 246
            }
        ]
    },
    {
        "header": "5FlowPathAgent",
        "images": []
    },
    {
        "header": "6Experimental Set-up",
        "images": []
    },
    {
        "header": "7Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x3.png",
                "caption": "Figure 3:Performance comparison ofFlowPathAgentagainst baselines demonstrates superior effectiveness across long-tail distribution of node count in flowcharts.",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x4.png",
                "caption": "Figure 4:Flow diagram of the sequence of tools used byFlowPathAgentonFlowExplainBench. EachSteprefers to a cycle of Tool Selection + Call.",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x5.png",
                "caption": "Figure 5:Qualitative comparison ofFlowPathAgentwith baseline methods. The flowchart illustrates attributions generated by various baselines, highlighting the agentic trace ofFlowPathAgent. We contrast its output with the next strongest baseline, GPT-4o+SoM, to showcase differences in attribution quality and interpretability.",
                "position": 626
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/bubble_chart.png",
                "caption": "Figure 6:Scatter plot of segmentation IoU versus Word Overlap F1 for individual samples, color-coded by overall task F1. Clustering in the high-performance region indicates minimal error propagation across the pipeline.",
                "position": 738
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "10Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AFurther Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x6.png",
                "caption": "Figure 7:Box-plot distribution of time taken in each tool call, in seconds.",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x7.png",
                "caption": "Figure 8:Distribution of count of tool calls, segregated by question type.",
                "position": 1360
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/node_distribution_histogram.png",
                "caption": "Figure 9:Distribution of nodes in our benchmark.",
                "position": 1376
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/heatmap_tool_vs_nodes_filtered.png",
                "caption": "Figure 10:Heatmap of time taken by different tools to execute, binned by number of nodes in the flowchart.",
                "position": 1379
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/heatmap_step.png",
                "caption": "Figure 11:Heatmap of duration of tool call execution, arranged by agentic step.",
                "position": 1382
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x8.png",
                "caption": "Figure 12:Overview of training split used for FlowMask2Former, and Flow2Mermaid VLM. The figure demonstrates the style options, color palettes used, and distinction between both training sets.",
                "position": 1467
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x9.png",
                "caption": "Figure 13:Example fromFlowExplainBench--Instruct. This example represents anApplied Scenarioquestion, and has a style type 1 (single color).",
                "position": 1470
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x10.png",
                "caption": "Figure 14:Example fromFlowExplainBench--Code. This example represents aFact Retrievalquestion, and has a style type 2 (multiple colors).",
                "position": 1473
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x11.png",
                "caption": "Figure 15:Example fromFlowExplainBench--Instruct. This example representsTolopolgicalandFlow Referentialquestions, and has a style type 3 (mermaid default).",
                "position": 1476
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x12.png",
                "caption": "Figure 16:Qualitative comparison ofFlowPathAgentwith baselines via examples.",
                "position": 1486
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x13.png",
                "caption": "Figure 17:(Continued) Qualitative comparison ofFlowPathAgentwith baselines via examples.",
                "position": 1489
            }
        ]
    },
    {
        "header": "Appendix BAgent Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x14.png",
                "caption": "Figure 18:Class Diagram of theFlowChartdata structure representing directed graphs with conditional edges.",
                "position": 1506
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x15.png",
                "caption": "Figure 19:System prompt template provided toFlowPathAgent.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x16.png",
                "caption": "Figure 20:Planning prompt template provided toFlowPathAgent.",
                "position": 1735
            }
        ]
    },
    {
        "header": "Appendix CBenchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01344/x17.png",
                "caption": "Figure 21:Prompt Template used for initial automatic ground truth annotation using GPT4.",
                "position": 1749
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x18.png",
                "caption": "Figure 22:Diversity of color schemes used to augmentFlowExplainBenchflowchart styles",
                "position": 1759
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x19.png",
                "caption": "Figure 23:Summary of instructions given to human annotators.",
                "position": 1772
            },
            {
                "img": "https://arxiv.org/html/2506.01344/x20.png",
                "caption": "Figure 24:Human annotation platform for attribution annotation.",
                "position": 1775
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/hand1.png",
                "caption": "Figure 25:FlowPathAgent attributed D and F correctly. The blocks and labels represent FlowMask2Former annotations.",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/hand2.png",
                "caption": "Figure 26:FlowPathAgent attributed E correctly. The blocks and labels represent FlowMask2Former annotations.",
                "position": 1859
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/hand3.png",
                "caption": "Figure 27:FlowPathAgent attributed D correctly. The blocks and labels represent FlowMask2Former annotations.",
                "position": 1862
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/hand4.png",
                "caption": "Figure 28:FlowPathAgent attributed B, and E correctly. The blocks and labels represent FlowMask2Former annotations.",
                "position": 1865
            },
            {
                "img": "https://arxiv.org/html/2506.01344/extracted/6503011/figures/hand5.png",
                "caption": "Figure 29:FlowPathAgent attributed A, B, C, E. The blocks and labels represent FlowMask2Former annotations.",
                "position": 1868
            }
        ]
    },
    {
        "header": "Appendix DAdditional analysis on hand-constructed charts",
        "images": []
    }
]