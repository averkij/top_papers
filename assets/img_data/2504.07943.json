[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07943/x1.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07943/x2.png",
                "caption": "Figure 2:An overview of theHoloPartmodel design. Given a whole 3D shape and a corresponding surface segmentation mask, HoloPart encodes these inputs into latent tokens, using context-aware attention to capture global shape context and local attention to capture local part detailed features and position mapping. These tokens are used as conditions and injected into the part diffusion model via cross-attention respectively. During training, noise is added to complete 3D parts, and the model learns to denoise them and recover the original complete part.",
                "position": 140
            }
        ]
    },
    {
        "header": "33D Part Amodal Segmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07943/x3.png",
                "caption": "Figure 3:Qualitative comparison with PatchComplete, DiffComplete and Finetune-VAE on the ABO dataset.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x4.png",
                "caption": "Figure 4:Qualitative comparison with PatchComplete, DiffComplete and Finetune-VAE on the PartObjaverse-Tiny dataset.",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x5.png",
                "caption": "Figure 5:Our method seamlessly integrates with existing zero-shot 3D part segmentation models, enabling effective zero-shot 3D part amodal segmentation.",
                "position": 789
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07943/x6.png",
                "caption": "Figure 6:3D part amodal segmentation is capable of numerous downstream applications, such as Geometry Editing, Geometry Processing, Material Editing and Animation.",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x7.png",
                "caption": "Figure 7:Geometry Super-resolution. By representing a part with the same number of tokens as the overall object, we can achieve geometry super-resolution.",
                "position": 806
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.07943/x8.png",
                "caption": "Figure 8:Ablation study of semantic and instance part completion.",
                "position": 2122
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x9.png",
                "caption": "Figure 9:Examples of data filtered out by rules.",
                "position": 2146
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x10.png",
                "caption": "Figure 10:The absence of context-aware attention leads to a lack of guidance for completing individual components, resulting in inconsistent and lower-quality outcomes.",
                "position": 2149
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x11.png",
                "caption": "Figure 11:Visualization of generated parts across different guidance scales.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x12.png",
                "caption": "Figure 12:Qualitative comparison of different learning rate settings.",
                "position": 2155
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x13.png",
                "caption": "Figure 13:More Results of 3D Part Amodal Segmentation.",
                "position": 2158
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x14.png",
                "caption": "Figure 14:More qualitative results on the PartObjaverse-Tiny dataset.",
                "position": 2161
            },
            {
                "img": "https://arxiv.org/html/2504.07943/x15.png",
                "caption": "Figure 15:More qualitative results on the PartObjaverse-Tiny dataset.",
                "position": 2164
            }
        ]
    },
    {
        "header": "6Supplementary Material",
        "images": []
    }
]