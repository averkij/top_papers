[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06885/x1.png",
                "caption": "Figure 1:An overview of F5-TTS training (left) and inference (right). The model is trained on the text-guided speech-infilling task and condition flow matching loss. The input text is converted to a character sequence, padded with filler tokens to the same length as input speech, and refined by ConvNeXt blocks before concatenation with speech input. The inference leverages Sway Sampling for flow steps, with the model and an ODE solver to generate speech from sampled noise.",
                "position": 104
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06885/x2.png",
                "caption": "Table 1:Results on LibriSpeechtest-cleanand LibriSpeech-PCtest-clean. The boldface indicates the best result, and * denotes the score reported in baseline papers with different subsets for evaluation. The Real-Time Factor (RTF) is computed with the inference time of 10s speech. #Param. stands for the number of learnable parameters and #Data refers to the used training dataset in hours.",
                "position": 310
            },
            {
                "img": "https://arxiv.org/html/2410.06885/x2.png",
                "caption": "Table 2:Results on two test sets, Seed-TTStest-enandtest-zh. The boldface indicates the best result, the underline denotes the second best, and * denotes scores reported in baseline papers.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2410.06885/x2.png",
                "caption": "Figure 2:Ablation studies on model architecture. Seed-TTStest-zhevaluation results of 155M small models trained with WenetSpeech4TTS Premium a 945 hours Mandarin Corpus.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2410.06885/x3.png",
                "caption": "Figure 3:Probability density function of Sway Sampling on flow steptùë°titalic_twith different coefficientsùë†sitalic_s(left), and small models‚Äô performance on Seed-TTStest-zhwith Sway Sampling (right).",
                "position": 700
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABaseline Details",
        "images": []
    },
    {
        "header": "Appendix BExperimental Result Supplements",
        "images": []
    }
]