[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x1.png",
                "caption": "Figure 1:DYMO-HairOverview.We introduceDYMO-Hair, a unified, model-based robot hair care system. We propose the first 3D volumetric hair-combing dynamics model, featuring a novel learning paradigm. It uses an action-conditioned latent state editing mechanism, coupled with a compact 3D latent space of diverse hairstyles, enabled by our novel hair-combing simulator, for generalizable dynamics modeling.\nBuilding on this model, we develop DYMO-Hair with a MPPI-based planner for closed-loop visual goal-conditioned hair styling.",
                "position": 110
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Works",
        "images": []
    },
    {
        "header": "IIIProblem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x2.png",
                "caption": "Figure 2:Comparison of Hair State Representations.(a) Colors distinguish individual hair strands. (b) We show a resolution of 2K points, the maximum used for point cloud–based methods in our experiments (seeSec.˜VII-Bfor more details). (c) We show64×64×12864\\times 64\\times 128grids with a voxel size of about 5 mm. Colors denote local strand orientations. Red dashed box: a zoomed-in region. Brown dashed box: the corresponding local strand segments.",
                "position": 224
            }
        ]
    },
    {
        "header": "IVHair Combing Dynamics Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x3.png",
                "caption": "Figure 3:DYMO-Hair’s Dynamics Model Overview.Left: State latent space pre-training. A 3D volumetric hierarchical model with vector quantization enables compact compression while preserving detailed representation capability.Right: Dynamics learning. The pre-trained model is adapted to capture hair dynamics in a ControlNet-style framework, formulating dynamics as action-conditioned editing in the pre-trained state latent space.zero: zero-convolution;copy: weight copying for initialization;⊕\\oplus: element-wise addition;⊗\\otimes: 3D attention-based feature fusion. In this phase, only the motion encoding path is trainable, with all pre-trained components frozen.",
                "position": 253
            }
        ]
    },
    {
        "header": "VHair Dynamics Simulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x4.png",
                "caption": "Figure 4:Constraints for PBD-based Strand-level, Contact-rich Hair Combing Simulation.Top:Each constraint’s formulation and intended effect.Bottom:Simulation results under progressive constraint addition. Starting from the initial state (far left), a combing motion is applied along the white dashed arrow. The red dashed box marks the contact-rich region, with its simulation results shown on the right.\nWith all three constraints, the hair maintains a realistic shape; the twist constraint, in particular, preserves curvature and prevents gravity-induced oversmoothing.",
                "position": 318
            }
        ]
    },
    {
        "header": "VIModel-based Robot Hair Styling System",
        "images": []
    },
    {
        "header": "VIIExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x5.png",
                "caption": "Figure 5:Experiment Setup.Left: Synthetic hair used for training and evaluation; simulation environment.Right: Real-world setup for evaluation.",
                "position": 419
            },
            {
                "img": "https://arxiv.org/html/2510.06199/x6.png",
                "caption": "Figure 6:Quantitative Results for Closed-loop Hair Styling in Simulation.Experiments are conducted on 7 unseen hairstyles, each with 3 cases repeated 5 times.\n(a) Error curves over planning steps, where solid lines and shaded regions denote mean and standard deviation across hairstyles. Faster error reduction and lower final error indicate higher effectiveness.\n(b) Success rate curves w.r.t. error thresholds used to determine success, reflecting the distribution of final errors. Curves closer to the top-left correspond to more low-error outcomes and better performance.\nIn both (a) and (b), error is defined as relative error: the ratio of the current strand-level distance to the initial strand-level distance, providing a unified metric across hairstyles with varying absolute error magnitudes.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2510.06199/x7.png",
                "caption": "Figure 7:Qualitative Results for Closed-loop Hair Styling in Simulation.Threehardcases of different unseen hairstyles are shown, with columns (left to right) illustrating the initial state, the intermediate planning steps, the end state with relative error, and the goal.",
                "position": 545
            },
            {
                "img": "https://arxiv.org/html/2510.06199/x8.png",
                "caption": "Figure 8:Results for Closed-loop Hair Styling in the Real World.For each case, the visual goal is shown on the left, with key observations and actions for each method displayed alongside the curve.\nError is defined as relative error: the ratio of the current strand-level distance to the initial distance.",
                "position": 580
            }
        ]
    },
    {
        "header": "VIIIConclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06199/x9.png",
                "caption": "Figure 9:Qualitative Evaluation for Hair-combing Dynamics Learning on Unseen Hairstyles.From left to right: the initial state, the ground-truth end state, and predicted end states from different methods.\nKey regions are highlighted with red boxes.\nA color map is applied to local strand segments based on their orientations; however, due to discontinuities in the mapping, strands with similar orientations may sometimes appear in different colors.\nFor a best understanding of local orientations, please refer to the strand segment geometry by zooming in.",
                "position": 1259
            },
            {
                "img": "https://arxiv.org/html/2510.06199/x10.png",
                "caption": "Figure 10:Qualitative Evaluation of the Hierarchical Structure Ablation in Dynamics Learning.From left to right: the ground-truth state and the reconstructed states from different models.\nA color map is applied to local strand segments based on their orientations; however, due to discontinuities in the mapping, strands with similar orientations may sometimes appear in different colors.\nFor a best understanding of local orientations, please refer to the strand segment geometry by zooming in.",
                "position": 1573
            },
            {
                "img": "https://arxiv.org/html/2510.06199/x11.png",
                "caption": "Figure 11:More Qualitative Results of DYMO-Hair on Diverse Unseen Hairstyles with Various Messy Initial States in Simulation.Each row shows one unseen hairstyle with two different cases (A and B). From left to right: the goal, and for each case, the initial state, the intermediate planning steps, and the end state.",
                "position": 1624
            }
        ]
    },
    {
        "header": "IXAppendix",
        "images": []
    }
]