[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15715/figure/mae_teaser_1.png",
                "caption": "(a)model learns object co-occurrence patterns (left and right doors)",
                "position": 104
            },
            {
                "img": "https://arxiv.org/html/2512.15715/figure/mae_teaser_1.png",
                "caption": "(a)model learns object co-occurrence patterns (left and right doors)",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2512.15715/figure/mae_teaser_2.png",
                "caption": "(b)model infers hidden camera pose and 3D spatial layout",
                "position": 112
            },
            {
                "img": "https://arxiv.org/html/2512.15715/figure/mae_teaser_3.png",
                "caption": "(c)model reasons about symmetric color patterns (left red color is masked)",
                "position": 118
            },
            {
                "img": "https://arxiv.org/html/2512.15715/figure/mae_teaser_4.png",
                "caption": "(d)model understands reflection and predicts the mirrored person",
                "position": 123
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15715/x1.png",
                "caption": "Figure 2:Pixio introduces four simple yet critical updates to MAE, with following motivations.Deeper decoder:MAE’s shallow decoder lacks capacity for pixel regression, forcing the encoder to sacrifice representation quality for reconstruction.Larger mask block:single-patch masking causes reconstruction shortcuts and provides insufficient context.More[CLS]tokens:a single class token cannot capture diverse global properties.Web-scale training data:IN-1K lacks the visual diversity needed for learning transferable representations.",
                "position": 162
            }
        ]
    },
    {
        "header": "3Pixio",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15715/x2.png",
                "caption": "Figure 3:Probing frozenfeatures in different blocksof the original MAE encoder, which is trained on ImageNet-1K. The relative block depth is computed as the ratio of the block index to the total number of blocks, for easy comparison across architectures (ViT-H: 32 blocks, ViT-L: 24 blocks). We use a linear head for both monocular depth estimation (regression) and semantic segmentation (classification).",
                "position": 842
            },
            {
                "img": "https://arxiv.org/html/2512.15715/x3.png",
                "caption": "Figure 4:Ablation study of usingdecoders of different depth(#attention blocks) or width (feature dimension) to train MAE on IN-21K. The encoder is ViT-H (1280-d×\\times32-blocks). Here, we use a DPT head for depth estimation and a linear head for semantic segmentation.",
                "position": 845
            },
            {
                "img": "https://arxiv.org/html/2512.15715/x4.png",
                "caption": "Figure 5:Ablation study onmasking granularity(measured in #patches). MAE uses single-patch (1×\\times1) masking granularity.",
                "position": 914
            },
            {
                "img": "https://arxiv.org/html/2512.15715/x5.png",
                "caption": "Figure 6:Ablation study on thenumber of class tokens. MAE uses a single class token.",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2512.15715/x6.png",
                "caption": "Figure 7:Fine-tuning encoder blocks for ImageNet. “0 block” corresponds to linear probing. Pixio does not intentionally involve any ImageNet data for pre-training, while DINOv3 adds ImageNet images explicitly into its training set with repetitive sampling.",
                "position": 1076
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Failure Attempts, Limitations, and Future Directions",
        "images": []
    },
    {
        "header": "7Implementation Details",
        "images": []
    },
    {
        "header": "8Ablation Studies",
        "images": []
    }
]