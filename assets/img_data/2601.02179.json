[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.02179/x1.png",
                "caption": "Figure 1:InfoECE onGuess(Llama3.1-70B). Ideally, confidence (blue curves) increases as more information is provided. Calibration improves when the confidence curves (blue) are closer to the accuracy curve (red). In this setting,P(Sufficient)best satisfies both monotonicity and calibration.",
                "position": 151
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Dataset Construction",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.02179/x2.png",
                "caption": "Figure 2:Evolution of average confidence and accuracy across different information levels. While accuracy (right y-axis,red line) generally increases, the confidence metrics (left y-axis,blue line) exhibit varying trends.",
                "position": 942
            },
            {
                "img": "https://arxiv.org/html/2601.02179/x3.png",
                "caption": "Figure 3:Kendall’sτ\\tauforground truthanswers. Compared to theτ\\tauforeach turn’sanswers, all methods show substantially better monotonicity. All values are shown as percentages.",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2601.02179/x4.png",
                "caption": "Figure 4:Performance comparison across four language models. Six evaluation dimensions are shown: Vanilla-Verb, Cot-Verb, SC, P(true), P(sufficient), and ACC.Redindicates 20Q benchmarks,blueindicates GUESS benchmarks.",
                "position": 1330
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitation",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AInstruction Prompt Examples.",
        "images": []
    },
    {
        "header": "Appendix BIncremental QA datasets",
        "images": []
    },
    {
        "header": "Appendix CCalibration shifts reveal a scaling-dependent format effect.",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.02179/x5.png",
                "caption": "Figure 5:InfoECE of different confidence estimation methods across formats. Five confidence methods (Vanilla-Verb, CoT-Verb, SC, P(true), P(sufficient)) plus Accuracy, compared under multi-turn (darker) vs. summarized (lighter) presentation.Red:20Q;blue:Guess. Lower InfoECE indicates better calibration.",
                "position": 1661
            }
        ]
    },
    {
        "header": "Appendix DQuestion Examples",
        "images": []
    },
    {
        "header": "Appendix EPlacebo QA Examples",
        "images": []
    }
]