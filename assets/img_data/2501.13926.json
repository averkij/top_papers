[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x1.png",
                "caption": "",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x2.png",
                "caption": "",
                "position": 182
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Our Investigation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x3.png",
                "caption": "Figure 3:Comparison of Reward Models as Test-time Verifiers.We adopt Show-o[5]as the ‚ÄòBaseline‚Äô and evaluate Best-of-NùëÅNitalic_Nselection on the GenEval[38]benchmark.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x4.png",
                "caption": "Figure 4:Investigation of Reward Models in Autoregressive Image Generation.For test-time verification, we implement Outcome Reward Model (ORM) and Process Reward Model (PRM), and introduce a new Potential Assessment Reward Model (PARM) customized for image generation scenarios, which progressively performs three tasks (highlighted in blue) to enhance the reasoning of generation.",
                "position": 290
            }
        ]
    },
    {
        "header": "3Potential Assessment Reward Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x5.png",
                "caption": "Figure 5:The Reflection Mechanism in Potential Assessment Reward Model ++ (PARM++).As an upgraded version of PARM, PARM++ incorporates a reflection evaluation task, enabling the generative model to self-correct its low-quality images.",
                "position": 1137
            }
        ]
    },
    {
        "header": "4Potential Assessment Reward Model ++",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x6.png",
                "caption": "Figure 6:Qualitative Results with Reflection in PARM++.The proposed PARM++ incorporates a reflection evaluation stage to detect text-image misalignments and provides detailed explanations to guide the self-correction process in autoregressive image generation models.",
                "position": 1148
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x7.png",
                "caption": "Figure 7:Qualitative Results using Our Reasoning Strategies.Show-o[5]is adopted as the baseline model, and compared to our best-performing reasoning strategy: integrating PARM with iterative DPO for both reward model guidance and test-time verification.",
                "position": 1343
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x8.png",
                "caption": "Figure 8:Qualitative Results using Our Reasoning Strategies.Show-o[5]is adopted as the baseline model, and compared to our best-performing reasoning strategy: integrating PARM with iterative DPO for both reward model guidance and test-time verification.",
                "position": 1347
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x9.png",
                "caption": "Figure 9:Qualitative Results using Our Reasoning Strategies.Show-o[5]is adopted as the baseline model, and compared to our best-performing reasoning strategy: integrating PARM with iterative DPO for both reward model guidance and test-time verification.",
                "position": 1351
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x10.png",
                "caption": "Figure 10:Qualitative Results using Our Reasoning Strategies.Show-o[5]is adopted as the baseline model, and compared to our best-performing reasoning strategy: integrating PARM with iterative DPO for both reward model guidance and test-time verification.",
                "position": 1355
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x11.png",
                "caption": "Figure 11:Qualitative Results using Our Reasoning Strategies.Show-o[5]is adopted as the baseline model, and compared to our best-performing reasoning strategy: integrating PARM with iterative DPO for both reward model guidance and test-time verification.",
                "position": 1359
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BData and Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.13926/x12.png",
                "caption": "Figure 12:Visualization of Early-stage and Later-stage Images.We visualize the generated images in the intermediate steps of Show-o[5], where the early-stage images are too blurry to interpret, while the later-stage images are too similar to discriminate, posing great challenges for PRMs to evaluate.",
                "position": 3049
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x13.png",
                "caption": "Figure 13:Comparison of Reward Models as Test-time Verifiers with DPO Alignment.We adopt Show-o[5]with DPO alignment as the ‚ÄòBaseline with DPO‚Äô and evaluate Best-of-NùëÅNitalic_Nselection on the GenEval[38]benchmark.",
                "position": 3081
            },
            {
                "img": "https://arxiv.org/html/2501.13926/x14.png",
                "caption": "Figure 14:Comparison of Reward Models as Test-time Verifiers with Iterative DPO Alignment.We adopt Show-o[5]with iterative DPO alignment as the ‚ÄòBaseline with It. DPO‚Äô and evaluate Best-of-NùëÅNitalic_Nselection on GenEval[38].",
                "position": 3438
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    }
]