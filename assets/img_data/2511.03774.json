[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03774/x1.png",
                "caption": "Figure 1:Example of our multi-modal semantic perturbation pipeline applied to RealWorldQA benchmark. Using ControlNet trained with Flux models, a new speed limit sign is generated, changing the correct answer from (B) to (C) while preserving the original image’s overall composition. A contaminated model that has memorized the original question is likely to fail on the perturbed version.",
                "position": 64
            },
            {
                "img": "https://arxiv.org/html/2511.03774/x1.png",
                "caption": "Figure 1:Example of our multi-modal semantic perturbation pipeline applied to RealWorldQA benchmark. Using ControlNet trained with Flux models, a new speed limit sign is generated, changing the correct answer from (B) to (C) while preserving the original image’s overall composition. A contaminated model that has memorized the original question is likely to fail on the perturbed version.",
                "position": 66
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Investigation Setup",
        "images": []
    },
    {
        "header": "3Preparation of Contaminated Models",
        "images": []
    },
    {
        "header": "4Multi-Modal Semantic Perturbation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03774/x2.png",
                "caption": "Figure 2:Illustration of our multi-modal semantic perturbation pipeline. The original question–image pair is used to generate a dense caption with an LLM, which guides Flux ControlNet to produce a perturbed image and new answer, yielding a modified but semantically consistent benchmark sample.",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2511.03774/x2.png",
                "caption": "Figure 2:Illustration of our multi-modal semantic perturbation pipeline. The original question–image pair is used to generate a dense caption with an LLM, which guides Flux ControlNet to produce a perturbed image and new answer, yielding a modified but semantically consistent benchmark sample.",
                "position": 337
            }
        ]
    },
    {
        "header": "5Comparative Evaluation of Contamination Detection",
        "images": []
    },
    {
        "header": "6Analysis of Multi-modal Semantic Perturbation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_easy.jpg",
                "caption": "(a) Original",
                "position": 789
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_easy.jpg",
                "caption": "(a) Original",
                "position": 791
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_easy.jpg",
                "caption": "(a) Original",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_flux_easy.jpg",
                "caption": "(b) After multi-modal semantic perturbation",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_fail_orig.png",
                "caption": "(a) Original",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_fail_orig.png",
                "caption": "(a) Original",
                "position": 830
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_fail_orig.png",
                "caption": "(a) Original",
                "position": 852
            },
            {
                "img": "https://arxiv.org/html/2511.03774/figures/rqa_fail_flux.png",
                "caption": "(b) After multi-modal semantic perturbation",
                "position": 858
            }
        ]
    },
    {
        "header": "7Ablation Studies",
        "images": []
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperiment Settings",
        "images": []
    },
    {
        "header": "Appendix BPerplexity-based Methods",
        "images": []
    },
    {
        "header": "Appendix CDetecting Contaminated Models with Multi-Modal Semantic Perturbation on RealWorldQA",
        "images": []
    },
    {
        "header": "Appendix DExtended Evaluation on Additional Open-Source and Proprietary Models",
        "images": []
    },
    {
        "header": "Appendix EFull Experiment Results",
        "images": []
    }
]