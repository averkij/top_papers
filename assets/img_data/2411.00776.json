[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00776/x1.png",
                "caption": "Figure 1:Comparison among different language modeling compatible autoregressive (AR) image generators.The proposed RAR demonstrates significant improvements over previous AR methods. RAR-B, with only261Mparameters, achieves an FID score of 1.95, outperforming both LlamaGen-XXL (1.4B parameters) and Open-MAGVIT2-XL (1.5B parameters).",
                "position": 75
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x2.png",
                "caption": "Figure 2:Overview of the proposed Randomized AutoRegressive (RAR) model, which is fully compatible with language modeling frameworks.Left: RAR introduces a randomness annealing training strategy to enhance the model‚Äôs ability to learn bidirectional contexts. During training, the input sequence is randomly permuted with a probabilityrùëüritalic_r, which starts at 1 (fully random permutations) and linearly decreases to 0, transitioning the model to a fixed scan order, such as raster scan, by the end of training.Right: Randomly selected images generated by RAR, trained on ImageNet.",
                "position": 81
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00776/x3.png",
                "caption": "Figure 3:Illustration of the target-aware positional embedding.Subfigure (a) shows the training process of the proposed Randomized AutoRegressive (RAR) model, along with the target-aware position embedding.\nFollowing Vision Transformer[19], images are tokenized into patches with original position embeddings (blue tokens).\nThe token sequence is then randomly permuted, with the target-aware positional embeddings (green tokens) added to guide the model.\nSubfigures (b) and (c) highlight the importance of the target-aware positional embedding: (b) demonstrates a failure case where both permuted sequences yield identical prediction logits, while (c) shows that the target-aware positional embedding correctly guides the model to predict the next token accurately.",
                "position": 126
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00776/x4.png",
                "caption": "(a)training losses",
                "position": 1069
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x4.png",
                "caption": "(a)training losses",
                "position": 1072
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x5.png",
                "caption": "(b)FID scores w/o classifier-free guidance",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x6.png",
                "caption": "(c)FID scores w/ classifier-free guidance",
                "position": 1086
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x7.png",
                "caption": "Figure 5:Visualization of samples generated by RAR across various model sizes.RAR generates high-quality visual samples across all model sizes. As model size increases, fidelity and diversity improve, especially in challenging classes (e.g., dogsled).",
                "position": 1115
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "AHyper-parameters for Final RAR Models",
        "images": []
    },
    {
        "header": "BPseudo-Code for RAR",
        "images": []
    },
    {
        "header": "CVisualization of Scan Orders",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00776/x8.png",
                "caption": "(a)row-major",
                "position": 1464
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x8.png",
                "caption": "(a)row-major",
                "position": 1467
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x9.png",
                "caption": "(b)spiral in",
                "position": 1472
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x10.png",
                "caption": "(c)spiral out",
                "position": 1477
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x11.png",
                "caption": "(d)z-curve",
                "position": 1482
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x12.png",
                "caption": "(e)subsample",
                "position": 1488
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x13.png",
                "caption": "(f)alternate",
                "position": 1493
            }
        ]
    },
    {
        "header": "DVisualization on Generated Samples",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.00776/x14.png",
                "caption": "Figure 7:Visualization samples from RAR.RAR is capable of generating high-fidelity image samples with great diversity.",
                "position": 1507
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x15.png",
                "caption": "Figure 8:Visualization samples from RAR.RAR is capable of generating high-fidelity image samples with great diversity.",
                "position": 1512
            },
            {
                "img": "https://arxiv.org/html/2411.00776/x16.png",
                "caption": "Figure 9:Visualization samples from RAR.RAR is capable of generating high-fidelity image samples with great diversity.",
                "position": 1517
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]