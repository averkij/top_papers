[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/images/huggingface.png",
                "caption": "",
                "position": 115
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x1.png",
                "caption": "Figure 1:Visual comparison across datasets. For each dataset, we randomly sample three textâ€“image pairs (no cherry-picking) to illustrate overall dataset quality. Zoom in for details. Dataset names for each row are provided on the following page.",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x2.png",
                "caption": "Figure 2:Examples of our introducedFine-T2Idataset samples, which include diverse resolutions, aspect ratios, styles, categories, tasks,etc. Please check the supplementary for examples with detailed attributes and prompts. Images above the dashed line are our synthetic samples, and those below the dashed line are our curated real images. Please also refer ourHuggingface Space Pageto explore more.",
                "position": 256
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Fine-T2I Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x3.png",
                "caption": "Figure 3:Semantic cosine-similarities distribution in a random prompt subset. We set deduplication threshold to 0.8.",
                "position": 328
            }
        ]
    },
    {
        "header": "4Fine-T2I Dataset Specifications",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x4.png",
                "caption": "(a)Categories Analysis",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x4.png",
                "caption": "(a)Categories Analysis",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x5.png",
                "caption": "(b)Styles Analysis",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x6.png",
                "caption": "(c)Tasks Analysis",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x7.png",
                "caption": "Figure 5:The aesthetic score distribution of our Fine-T2I. Both the synthetic sets and the curated set demonstrate high aesthetic scores, implying strong visual quality for fine-tuning.",
                "position": 522
            }
        ]
    },
    {
        "header": "5Experiments with Fine-T2I",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x8.png",
                "caption": "(a)Human-evaluation results on LlamaGen.",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x8.png",
                "caption": "(a)Human-evaluation results on LlamaGen.",
                "position": 542
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x9.png",
                "caption": "(b)Human-evaluation results on SD-XL.",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x10.png",
                "caption": "Figure 7:Visual comparison between original generations and generations fine-tuned on our Fine-T2I. One can observe clearly better generation quality on our fine-tuned model.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x11.png",
                "caption": "Figure 8:Human evaluation results (win rate) comparing models fine-tuned on different datasets. For each comparison, the best generation result among the three is selected as the winning example.",
                "position": 655
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Distribution analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x12.png",
                "caption": "(a)synthetic sets prompt length distribution.",
                "position": 1656
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x12.png",
                "caption": "(a)synthetic sets prompt length distribution.",
                "position": 1659
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x13.png",
                "caption": "(b)curated real-image set prompt length distribution.",
                "position": 1665
            }
        ]
    },
    {
        "header": "Appendix BProblems, Ambiguity, Expectation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09439/x14.png",
                "caption": "Figure 10:Aesthetics scores may be ambiguous and may not be aligned with human preference. Indeed, aesthetics always change with the development and can be biased. Please zoom in to see details.",
                "position": 1812
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x15.png",
                "caption": "Figure 11:Visual comparison of LlamaGen fine-tuned on different datasets. We randomly pick examples from generated images for visualization.",
                "position": 1823
            },
            {
                "img": "https://arxiv.org/html/2602.09439/x16.png",
                "caption": "Figure 13:Comparison of text-image pairs from different fine-tuning datasets. We randomly select one tar file from the dataset, and list the first examples as a comparison, without any cherry-picking. The resolution is marked bottom-right. Clearly, our Fine-T2I presents the best alignment, visual quality, and high-resolution,etc.",
                "position": 1858
            }
        ]
    },
    {
        "header": "Appendix CDetailed studies",
        "images": []
    }
]