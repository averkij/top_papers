[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02294/x1.png",
                "caption": "Figure 1:Knowledge Distillation under Covariate Shift with ConfiG Data Augmentations.Our goal is to maximize student performance even on groups that are fully absent from the training data.Left:Without having seen similar samples, the student is incapable of correctly classifying the unseen groups in the test set.Right:Leveraging the discrepancy between a robust teacher and the biased student, ConfiG generates and adds challenging samples to the training set.\nFurther training improves the student’s performance on previously missing groups by removing shortcuts.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02294/extracted/6510398/figures/fidelity_plot.png",
                "caption": "Figure 2:The student relies on spurious features in the training data and disagrees with the teacher when tested in their absence. Distillation was performed with standard augmentations and EDRM as described in Section4.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2506.02294/x2.png",
                "caption": "Figure 3:Illustration of ConfiG and other diffusion-based augmentation methods:Left:the task is gender prediction (male/female) where the men in the training data all have glasses, are old and not blond.Right:Existing methods just produce high confidence for “male” but do not take into account the student. In contrast, ConfiG maximizes the difference between the teacher and the student over the latent space and so targets spurious features that the student picked up from the training data.\nAdded to the training set, these augmentations severely improve the student’s worst group accuracy.",
                "position": 356
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02294/x3.png",
                "caption": "Figure 4:Qualitative examples of our method ConfiG (green) and the baselines (red) on CelebA and SpuCo birds. ConfiG successfully identifies spurious features and changes removes in the augmentation process. The augmented images from the baselines still contain the spurious features.",
                "position": 1029
            },
            {
                "img": "https://arxiv.org/html/2506.02294/extracted/6510398/figures/fraction_3.png",
                "caption": "Figure 5:Two augmentations per real image maximizes worst and mean group accuracy.",
                "position": 1056
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02294/x4.png",
                "caption": "Figure 6:Further examples for diffusion-guided data augmentations for images from CelebA and SpuCo Birds",
                "position": 3319
            },
            {
                "img": "https://arxiv.org/html/2506.02294/x5.png",
                "caption": "Figure 7:Further examples for diffusion-guided data augmentations for images from CelebA and SpuCo Birds.",
                "position": 3322
            },
            {
                "img": "https://arxiv.org/html/2506.02294/x6.png",
                "caption": "Figure 8:Further examples for diffusion-guided data augmentations for images from ImageNet.",
                "position": 3325
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]