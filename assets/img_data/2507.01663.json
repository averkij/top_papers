[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x1.png",
                "caption": "Figure 1.System overview of AsyncFlow framework.",
                "position": 130
            }
        ]
    },
    {
        "header": "2.System Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x2.png",
                "caption": "Figure 2.Hierarchical architecture design of AsyncFlow framework.",
                "position": 180
            }
        ]
    },
    {
        "header": "3.TransferQueue: High-Performance Asynchronous Streaming Dataloader",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x3.png",
                "caption": "Figure 3.Architecture design of TransferQueue. Each DP group interacts with its corresponding TransferQueue controller to get the metadata upon request, then execute the read/write operation with storage units in the data plane. The dashed line represents metadata communication, while the solid line depicts the communication process with real data. All these interaction processes are encapsulated as a distributed streaming dataloader to seamlessly integrate into training and inference engines.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x4.png",
                "caption": "Figure 4.Data structure of TransferQueue. Each row represents a complete data sample, while each column represents the task-specific data component. Through the global index, we can accurately address the data samples across different storage units for concurrent read/write operations.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x5.png",
                "caption": "Figure 5.Metadata notification process of TransferQueue. Data storage units will broadcast the metadata (including the global index and corresponding data columns) to all the controllers.",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x6.png",
                "caption": "Figure 6.Scheduling process of TransferQueue controller. Red indexes demote that the corresponding data samples satisfies the RL task requirement, and the checkmark means the corresponding data has been consumed in earlier requests.",
                "position": 254
            }
        ]
    },
    {
        "header": "4.Producer-Consumer-Based Asynchronous Workflow Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x7.png",
                "caption": "Figure 7.Streaming pipeline overlapping.",
                "position": 360
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x8.png",
                "caption": "Figure 8.Illustration of the asynchronous off-policy RL workflow. Leveraging the proposed delay parameter update mechanism in (c), AsyncFlow can extend the steady phase of the RL pipeline to further reduce pipeline bubbles. By sequentially enabling parameter updates for rollout instances in (d), we can achieve a sub-step asynchrony.",
                "position": 367
            }
        ]
    },
    {
        "header": "5.Service-Oriented User Interface",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x9.png",
                "caption": "Figure 9.Architecture of service-oriented user interface.",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x10.png",
                "caption": "Figure 10.End-to-end throughput and scalability analysis across varying cluster and model sizes. We report the average throughput across 10-20 iterations to reduce measurement fluctuations at the beginning.",
                "position": 549
            }
        ]
    },
    {
        "header": "6.Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.01663/x11.png",
                "caption": "Figure 11.AsyncFlow workflow of each training and inference instances. We showcase the 32B model with 512 NPUs, with iteration 0-3.",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2507.01663/x12.png",
                "caption": "Figure 12.Reward and average response length comparison for the proposed asynchronous RL workflow and vanilla synchronous RL workflow.",
                "position": 654
            }
        ]
    },
    {
        "header": "7.Related Work",
        "images": []
    },
    {
        "header": "8.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]