[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21278/x1.png",
                "caption": "Figure 1:Showcase of our training-free image composition method,SHINE. This gallery highlights SHINE‚Äôs ability to seamlessly integrate subjects into complex scenes, includinglow-light conditions, intricate shadows, and water reflections.",
                "position": 88
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x2.png",
                "caption": "Figure 2:Image composition from advanced multimodal models under three challenging conditions: backlighting, shadows, and water surfaces. Refer to AppendixHfor prompt details.",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x3.png",
                "caption": "Figure 3:Overview of the proposed framework.(a)The noisy latent is created by inpainting the background with a VLM-derived object description, then adding Gaussian noise.(b)Manifold-Steered Anchor (MSA) loss guides noisy latents toward faithfully capturing the reference subject (red arrow), while preserving the structural integrity of the background. Concretely, it enforces that the prediction of the optimized latentùíõt‚àó\\bm{z}_{t}^{*}on the adapter-augmented model‚Äôs manifold remains close to the prediction of the original latentùíõt\\bm{z}_{t}on the base model‚Äôs manifold.(c)Degradation-Suppression Guidance (DSG) constructs a negative velocity pointing toward low-quality regions by blurringùë∏img\\bm{Q}_{\\text{img}}and, in a CFG-like manner, steers the trajectory away from this low-quality distribution.",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x4.png",
                "caption": "Figure 4:Left:Robustness of FLUX.Right:Impacts of blurring different features in FLUX.",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x5.png",
                "caption": "Figure 5:Comparison of rectangular-mask blending and Adaptive Background Blending (ABB). Boundary regions (pink dashed boxes) are enlarged for clarity. Zoom in for details.",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x6.png",
                "caption": "Figure 6:Qualitative comparison of our method with multiple baselines in challenging scenarios,drawn from our benchmark dataset. More qualitative comparisons are available in AppendixK.",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x7.png",
                "caption": "Figure 7:Qualitative ablation study comparing different variants of our framework.",
                "position": 851
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x8.png",
                "caption": "Figure 8:Composition inherit erroneous colors if the inpainting prompt specifies an incorrect color.",
                "position": 1018
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x9.png",
                "caption": "Figure 9:Comparison of composites from our Adaptive Background Blending (ABB) method and direct blending with a rectangular mask. Boundary regions within pink dashed boxes are enlarged for clarity. Please zoom in to see details.",
                "position": 3249
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x10.png",
                "caption": "Figure 10:The IoU is calculated between the mask produced from each block and the ground-truth mask, which is obtained by segmenting the final generated images using SAM. The IoU for each block is averaged over 100 images.",
                "position": 3346
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x11.png",
                "caption": "Figure 11:Visualization of cross-attention maps from different MMDiT blocks of FLUX.1-dev.",
                "position": 3349
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x12.png",
                "caption": "Figure 12:Comparison of Subject Identity Metrics. (a) Reference subject images used for metric calculations. (b) Image pairs generated by AnyDoor (left) and our method (right), with corresponding CLIP-I(‚Üë)(\\uparrow), DINOv2(‚Üë)(\\uparrow), IRF(‚Üë)(\\uparrow), and DreamSim(‚Üì)(\\downarrow)scores displayed below each image; the better score is highlighted in red. Despite AnyDoor‚Äôs results appearing less realistic and consistent, they often achieve higher CLIP-I, DINOv2, and IRF scores, indicating that these metrics may not reliably reflect compositional quality. In contrast, DreamSim provides a more reliable assessment.",
                "position": 3664
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x13.png",
                "caption": "Figure 13:(Part 1 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3903
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x14.png",
                "caption": "Figure 14:(Part 2 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3906
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x15.png",
                "caption": "Figure 15:(Part 1 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3909
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x16.png",
                "caption": "Figure 16:(Part 2 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3912
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x17.png",
                "caption": "Figure 17:(Part 1 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3915
            },
            {
                "img": "https://arxiv.org/html/2509.21278/x18.png",
                "caption": "Figure 18:(Part 2 of 2)Qualitative comparison of our method against baselines in challenging scenarios.",
                "position": 3918
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]