[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10609/x1.png",
                "caption": "Figure 1:Illustration of local structural off-policy patterns. Raw token-level importance-sampling (IS) ratios (blue) exhibit high local variance and structural inconsistency, whereas a sequence-level IS ratio (purple) is globally smooth but obscures within-sequence structure. Off-policy frequency increases over the sequence (window-wise statistics), off-policy runs are short-lived (run-length distribution), and token states switch frequently, suggesting weak local coherence. Token-level Kalman filtering (red) yields locally smoothed yet structurally consistent IS ratios.",
                "position": 100
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method: Online Causal Kalman Filtering",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10609/x2.png",
                "caption": "Figure 2:Causal Kalman filtering. The filter alternates prediction, adaptive gain computation, and update to produce a smoothed estimateœÅ^t|t\\hat{\\rho}_{t|t}and its uncertaintyPt|tP_{t|t}from streaming observationsztz_{t}, using process noiseQQand observation noiseVV.",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2602.10609/x3.png",
                "caption": "Figure 3:Training dynamics of KPO-clipped over optimization steps. From left to right: mean episodic reward, policy entropy, PPO clip fraction, and policy gradient loss. Solid lines denote the average across runs, and the shaded bands indicate variability across runs.",
                "position": 440
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10609/x4.png",
                "caption": "Figure 4:Effect of the Kalman filter noise ratioQ/VQ/Von training dynamics.\nFrom left to right, we report the mean episodic reward and the PPO clip fraction.\nSolid lines show the mean over multiple runs, and shaded regions indicate standard deviation.",
                "position": 593
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BThe experimental setting",
        "images": []
    },
    {
        "header": "Appendix CExperimental analysis",
        "images": []
    }
]