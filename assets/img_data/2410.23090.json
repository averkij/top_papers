[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23090/extracted/5965665/pictures/coral.jpg",
                "caption": "",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23090/x1.png",
                "caption": "Figure 1:Part (a) is an overview of the CORAL dataset construction process. The red arrows show the sampled conversation flow, with numerical labels on the nodes indicating the round of the sampled conversation turns. The content under each sampled (sub)title serves as the conversational response in CORAL.\nPart (b) is the three conversation compression strategies in conversational RAG.",
                "position": 273
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23090/x2.png",
                "caption": "Figure 2:Illustration of the four sampling strategies. The red arrows show the sampled conversation flow, with numerical labels on the nodes indicating the round of the sampled conversation turns.",
                "position": 313
            }
        ]
    },
    {
        "header": "3CORAL",
        "images": []
    },
    {
        "header": "4Conversational RAG Framework",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23090/x3.png",
                "caption": "Figure 3:The scaling analysis of generation and citation labeling performance.",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2410.23090/x4.png",
                "caption": "Figure 4:Generation results of different conversation history length. The curve in the figure represents the ROUGE-L score. The histogram shows the results of GPT-4 scores comparing model-generated responses with golden responses.Winindicates cases where model-generated responses outperform golden responses,Drawindicates cases where the two responses are considered equally good, andLoseindicates cases where the golden responses are considered better. The y-axis on the left represents the proportion of cases in the total number of cases.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2410.23090/x5.png",
                "caption": "Figure 5:The GPT-4 evaluation score.",
                "position": 817
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix APrompts of the Contextualization of Questions",
        "images": []
    },
    {
        "header": "Appendix BPrompts of Generating Responses with Citation Labeling",
        "images": []
    },
    {
        "header": "Appendix CPrompts of LLM Summarization Strategy",
        "images": []
    },
    {
        "header": "Appendix DMore Detailed Experimental Setting",
        "images": []
    },
    {
        "header": "Appendix EDataset Format",
        "images": []
    }
]