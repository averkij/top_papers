[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14191/x1.png",
                "caption": "Figure 1:Illustration of Multimodal RewardBench.We build a human-annotated benchmark that consists of (multimodal prompt, chosen response, rejected response) triplets (left). Using this benchmark, we evaluate the accuracy of various reward models or judges for vision-language models (right).\nSee Â§Afor real examples from our benchmark.",
                "position": 170
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Multimodal RewardBench",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations and future work",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExamples from Multimodal RewardBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14191/extracted/6215505/images/104.jpg",
                "caption": "",
                "position": 1721
            },
            {
                "img": "https://arxiv.org/html/2502.14191/extracted/6215505/images/8212.jpg",
                "caption": "",
                "position": 1749
            },
            {
                "img": "https://arxiv.org/html/2502.14191/extracted/6215505/images/802.jpg",
                "caption": "",
                "position": 1774
            },
            {
                "img": "https://arxiv.org/html/2502.14191/extracted/6215505/images/267_0.png",
                "caption": "",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2502.14191/extracted/6215505/images/365.jpeg",
                "caption": "",
                "position": 1995
            }
        ]
    },
    {
        "header": "Appendix BHuman annotation instruction",
        "images": []
    },
    {
        "header": "Appendix CPrompt template for VLM-as-a-judge",
        "images": []
    }
]