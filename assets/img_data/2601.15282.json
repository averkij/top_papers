[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/figs/icons/globe.png",
                "caption": "",
                "position": 155
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/icons/github.png",
                "caption": "",
                "position": 158
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/icons/hf.png",
                "caption": "",
                "position": 161
            },
            {
                "img": "https://arxiv.org/html/2601.15282/x1.png",
                "caption": "Figure 1:Overview of the comprehensive robotics benchmark and dataset for video generation.Top:We presentRBenchthat includes the embodiment-based evaluation set and automated evaluation metrics. Our evaluation results on 25 video models show a high level of agreement with subjective human assessments.Bottom:We introduce a large-scale high-quality robotic dataset (RoVid-X) specifically designed for training video generation models, with data sourced from internet videos and open-source embodied videos.",
                "position": 163
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/x2.png",
                "caption": "Figure 2:Qualitative illustration of failure modes captured by RBench.Unlike conventional metrics that focus primarily on pixel-level fidelity, RBench provides a granular evaluation across multiple dimensions, including physical plausibility and task-level consistency. These results highlight persistent challenges in robotic video generation, such as structural distortion, floating components, and key action omission, which are accurately identified by our proposed sub-metrics. More cases are shown in the AppendixB.",
                "position": 220
            }
        ]
    },
    {
        "header": "3RBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/x3.png",
                "caption": "Figure 3:Statistics in RBench.The benchmark covers diverse tasks, object categories, and environments, demonstrating the high quality and comprehensiveness of the evaluation set, highlighting its high applicability to a wide range of robotic video generation scenarios.",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2601.15282/x4.png",
                "caption": "Figure 4:Overview of RoVid-X Construction and Descriptive Statistics.(a) shows the four-stage pipeline for constructing the RoVid-X. (b) presents descriptive statistics, covering frame intervals, skill distribution, and common objects, highlighting the dataset’s diversity and suitability for robotic task training and video generation.",
                "position": 317
            }
        ]
    },
    {
        "header": "4RoVid-X",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/x5.png",
                "caption": "Figure 5:Qualitative comparison across representative tasks.We visualize the generated results for three representative tasks:Visual Reasoning,Long-horizon Planning, andSpatial Relationship, across six models. Each row displays temporally sampled frames from the same generated video, with captions below indicating the corresponding task instruction. More cases are shown in the Appendix.",
                "position": 1897
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Set Details",
        "images": []
    },
    {
        "header": "Appendix BAutomatic Metrics Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/physical_01.png",
                "caption": "Figure 6:Visualization of robot and subject floating.",
                "position": 3831
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/physical_02.png",
                "caption": "Figure 7:Visualization of robot interpenetration.",
                "position": 3837
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/physical_03.png",
                "caption": "Figure 8:Visualization of robot/subject sudden appearance, disappearance, or duplication.",
                "position": 3840
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/task.png",
                "caption": "Figure 9:Visualization of task responsiveness and key actions completeness.",
                "position": 3879
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/robot_consist.png",
                "caption": "Figure 10:Visualization of robot structural stability.",
                "position": 3972
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/subject_consist.png",
                "caption": "Figure 11:Visualization of subject appearance stability.",
                "position": 3975
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/motion_amplitude.png",
                "caption": "Figure 12:Visualization of robot motion amplitude.",
                "position": 4007
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/motion_smoothness.png",
                "caption": "Figure 13:Visualization of robot motion smoothness.",
                "position": 4076
            }
        ]
    },
    {
        "header": "Appendix CModel Descriptions and Implementation Setups",
        "images": []
    },
    {
        "header": "Appendix DHuman Preference Study Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/user_study.png",
                "caption": "Figure 14:Visualization of the Questionnaire for User Study",
                "position": 4334
            },
            {
                "img": "https://arxiv.org/html/2601.15282/x6.png",
                "caption": "Figure 15:Bland–Altman plot after linear leave-one-out calibration (H∗H^{\\ast}).\nPoints are models; x-axismi=Bi+Hi∗2m_{i}=\\tfrac{B_{i}+H_{i}^{\\ast}}{2}, y-axisdi=Bi−Hi∗d_{i}=B_{i}-H_{i}^{\\ast}.\nThe solid line indicates the bias (d¯\\bar{d}); dashed lines show the 95% limits of agreement (LoA).\nIn our study the legend reportsBias=0.002\\text{Bias}=0.002andLoA=[−0.108,0.112]\\text{LoA}=[-0.108,\\,0.112].",
                "position": 4343
            }
        ]
    },
    {
        "header": "Appendix EPrompt Template",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/prompt/vr_question_chain.png",
                "caption": "Figure 16:Question-chain construction for Visual Reasoning.This component analyzes the original instruction and transforms it into a sequence of binary verification questions that define causal and temporal dependencies in the robot’s intended actions.",
                "position": 4500
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/prompt/vr_main_prompt-1.png",
                "caption": "Figure 17:Visual Reasoning evaluation prompt (Part I).The first part of the evaluation prompt integrates the structured reasoning chain with contextual information extracted during dataset construction.",
                "position": 4511
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/prompt/vr_main_prompt-2.png",
                "caption": "Figure 18:Visual Reasoning evaluation prompt (Part II).The second part specifies the structured scoring protocol and the JSON output format used to ensure consistent and interpretable evaluation results.",
                "position": 4515
            }
        ]
    },
    {
        "header": "Appendix FAdditional Qualitative Comparisons",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/common_manipulation.png",
                "caption": "Figure 19:Visualization of Common Manipulation.The first row contains the reference image, and the accompanying text shows the input prompt.",
                "position": 4536
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/long-horizon_planning.png",
                "caption": "Figure 20:Visualization of Long-Horizon Planning.The first row contains the reference image, and the accompanying text shows the input prompt.",
                "position": 4540
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/multi-entity_collaboration.png",
                "caption": "Figure 21:Visualization of Multi-Entity Collaboration.The first row contains the reference image, and the accompanying text shows the input prompt.",
                "position": 4543
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/spatial_relationship.png",
                "caption": "Figure 22:Visualization of Spatial Relationship.The first row contains the reference image, and the accompanying text shows the input prompt.",
                "position": 4546
            },
            {
                "img": "https://arxiv.org/html/2601.15282/figs/appendix/qualities/visual_reasoning.png",
                "caption": "Figure 23:Visualization of Visual Reasoning.The first row contains the reference image, and the accompanying text shows the input prompt.",
                "position": 4549
            }
        ]
    },
    {
        "header": "Appendix GComprehensive Quantitative Results",
        "images": []
    }
]