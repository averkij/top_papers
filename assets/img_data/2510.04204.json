[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/x1.png",
                "caption": "Figure 1:Performance vs. Model Size landscape for optimization modeling.",
                "position": 198
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/x2.png",
                "caption": "(a)An optimization modeling example. Full details in AppendixB.",
                "position": 267
            },
            {
                "img": "https://arxiv.org/html/2510.04204/x2.png",
                "caption": "(a)An optimization modeling example. Full details in AppendixB.",
                "position": 270
            },
            {
                "img": "https://arxiv.org/html/2510.04204/x3.png",
                "caption": "(b)Comparison of reasoning paradigms in automated optimization modeling.",
                "position": 275
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/Two_categories_of_triggers.png",
                "caption": "Figure 3:Trigger Categorization and Distribution. The left (1) shows the macro-average frequency of each trigger, the first 6 triggers grouped into two primary categories. The right (2a and 2b) detail the frequency distribution of these two main categories across the evaluated benchmarks.",
                "position": 375
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/CALM_case_OR.png",
                "caption": "Figure 4:A representative example ofLack of OR Expertiseflaw. (1) The model’s native reasoning results in an incorrect problem formulation, leading to a wrong answer. (2) In contrast, the process underCLAM’s guidance correct the formulation, enabling the model to find the correct solution.",
                "position": 464
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/full_ablation_leap_vs_sota_styled.png",
                "caption": "Figure 5:Ablation study of our two-stage framework.",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2510.04204/x4.png",
                "caption": "Figure 6:The CALM data curation engine.",
                "position": 787
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/rl_val_performance.png",
                "caption": "(a)RL Performance on Complex Test Sets.",
                "position": 806
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/rl_val_performance.png",
                "caption": "(a)RL Performance on Complex Test Sets.",
                "position": 809
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/rl_avg_code_blocks_curve.png",
                "caption": "(b)Average Number of Code Blocks.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/rl_avg_response_length_curve.png",
                "caption": "(c)Average Response Length (Tokens).",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2510.04204/figures/flaw_evolution_stacked_bar.png",
                "caption": "(d)Evolution of Flaws.",
                "position": 825
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BIllustration: Input–Output Structure of Traditional LLMs for Optimization Problems",
        "images": []
    },
    {
        "header": "Appendix CProtocol for Human-in-the-Loop Flaw Taxonomy Creation",
        "images": []
    },
    {
        "header": "Appendix DTriggers Type",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/flaw_frequency_evolution_2x3.png",
                "caption": "Table 3:This table illustrates seven common LRM error patterns (’triggers’), showing the original error (red) and analysis of the errors. These triggers include:(1)Premature NL Solving, an attempt at manual calculation instead of coding;(2)Fragmented Coding, writing separate small code blocks;(3) Redundant Manual Verification, unnecessarily re-calculating a solver’s result;(4) Lack of Sanity Check, failing to reflect on a solution’s plausibility;(5) Flawed Reasoning or Modeling, formulating an incorrect mathematical model;(6) Implementation Error, correctly modeling a question but incorrectly coding a correct model; and(7)Protocol Violation, ignoring explicit instructions and embedding the boxed number within a sentence.",
                "position": 1358
            }
        ]
    },
    {
        "header": "Appendix EExperimental Details Appendix",
        "images": []
    },
    {
        "header": "Appendix FDetailed Breakdown of Flaw Frequency Evolution",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/flaw_frequency_evolution_2x3.png",
                "caption": "",
                "position": 1965
            }
        ]
    },
    {
        "header": "Appendix GComparison of reasoning paradigm",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/comparison_reasoning_patterns.png",
                "caption": "",
                "position": 1996
            }
        ]
    },
    {
        "header": "Appendix HIntervention process for Specific Flaws",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04204/figures/CALM_case_code.png",
                "caption": "",
                "position": 2008
            }
        ]
    },
    {
        "header": "Appendix IIllustrative Case Study of the CALM Framework",
        "images": []
    },
    {
        "header": "Appendix JFlaw Quantification of native LRMs",
        "images": []
    }
]