[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x1.png",
                "caption": "",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x2.png",
                "caption": "Figure 2:Directly applying single-concept method cannot handle the MCVC task, while the naive solution by combining multi-concept image generation and image-to-video generation models can also hardly create satisfactory customized results.",
                "position": 132
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary: Diffusion Transformer Models for Text-to-Video Generation",
        "images": []
    },
    {
        "header": "4ConceptMaster",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x3.png",
                "caption": "Figure 3:Overview of the framework of our proposed ConceptMaster.",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x4.png",
                "caption": "Figure 4:(a) The overview of multi-concept data collection pipeline. When dealing with complex scenarios that contain concepts with high visual appearance or textual semantic similarity, our data pipeline could still extract precise entity images and corresponding labels, while simply exploit previous methods like Grounded-SAM would introduce a large number of errors and it is difficult to remove these errors through subsequent processing. (b) The success rate of testing videos comparison between Grounded-SAM and our data pipeline.",
                "position": 319
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x5.png",
                "caption": "Figure 5:Qualitative comparison on multi-concept customization. When compared to several different methods to conduct the MCVC task, our approach clearly demonstrates superior capabilities on concept fidelity, identity decoupling and caption semantic consistency.",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x6.png",
                "caption": "Figure 6:Comparison with tuning-based method DreamBooth.",
                "position": 703
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x7.png",
                "caption": "Figure 7:Different injection methods of multi-concept references.",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x8.png",
                "caption": "Figure 8:Demonstration of the effectiveness of the Q-Former and DAM modules.",
                "position": 733
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "1Introduction of our text-to-video diffusion transformer models",
        "images": []
    },
    {
        "header": "2Implementation Details of ConceptMaster",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x9.png",
                "caption": "Figure 9:Overview framwork of our base text-to-video generation models.",
                "position": 1773
            }
        ]
    },
    {
        "header": "3Discussions on Comparison between Our Data Collection Pipeline and Grounded-SAM",
        "images": []
    },
    {
        "header": "4Comparison Methods Implementation",
        "images": []
    },
    {
        "header": "5More Discussions on Multi-Concept Embeddings Injection",
        "images": []
    },
    {
        "header": "6More Discussions on Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04698/x10.png",
                "caption": "Figure 10:More Qualitative comparison on multi-concept customization between ConceptMaster and naively combining the multi-concept image customization with image-to-video generation models.",
                "position": 1850
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x11.png",
                "caption": "Figure 11:More Qualitative comparison on multi-concept customization between ConceptMaster and DreamBooth.",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x12.png",
                "caption": "Figure 12:More Qualitative comparison on different injection methods of multi-concept references.",
                "position": 1862
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x13.png",
                "caption": "Figure 13:More Qualitative comparison the effectiveness of the Q-Former and DAM modules.",
                "position": 1868
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x14.png",
                "caption": "Figure 14:More qualitative results of ConceptMaster on diverse scenarios (1/2).",
                "position": 1874
            },
            {
                "img": "https://arxiv.org/html/2501.04698/x15.png",
                "caption": "Figure 15:More qualitative results of ConceptMaster on diverse scenarios (2/2).",
                "position": 1880
            }
        ]
    },
    {
        "header": "7More Qualitative Results Demonstration",
        "images": []
    }
]