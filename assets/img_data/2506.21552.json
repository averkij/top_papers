[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21552/x1.png",
                "caption": "Figure 1:Predicting Ego-centric Video from human Actions (PEVA). Given past video frames and an action specifying a desired change in 3D pose, PEVA predicts the next video frame. Our results show that, given the first frame and a sequence of actions, our model can generate videos of atomic actions (a), simulate counterfactuals (b), and support long video generation (c).",
                "position": 83
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3PEVA",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21552/x2.png",
                "caption": "Figure 2:Design of PEVA.To train on an input video, we choose a random subset of frames and encode them via a fixed encoder (a). They are then fed to a CDiT that is trained autoregressively with teacher forcing (b). During the denoising process, each token attends to same-image tokens and cross-attends to clean tokens from past image(s). Action conditioning is done via AdaLN layers.",
                "position": 123
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21552/x3.png",
                "caption": "Table 1:Baseline Perceptual Metrics.Comparison of baselines on single-step prediction 2 seconds ahead.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2506.21552/x3.png",
                "caption": "Figure 3:Video Quality Across Time (FID).Comparison of generation accuracy and quality as a function of time for up to16161616seconds. Qualitative results for16161616second rollouts can be seen in Figure1c and Figure5.",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2506.21552/x4.png",
                "caption": "Figure 4:Atom Actions Generation. We include video generation examples of different atomic actions specified by 3D-body poses.",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2506.21552/x5.png",
                "caption": "Figure 5:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2506.21552/x6.png",
                "caption": "Figure 6:Planning with Counterfactuals. We demonstrate a planning example by simulating multiple action candidates using PEVA and scoring them based on their perceptual similarity to the goal, as measured by LPIPS(Zhang et al.,2018). In the first case, we show that PEVA enables us to rule out action sequences that leads us to the sink in the top row, and outdoors in the second row. In the second case we show PEVA allows us to find a reasonable sequence of actions to open the refrigerator in the third row. PEVA enables us to rule out action sequences that grab the nearby plants and go to the kitchen and mix ingredients. PEVA allows us to choose the most correct action sequences that grab the box from the shelf.",
                "position": 350
            }
        ]
    },
    {
        "header": "5Failure Cases, Limitations and Future Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/left_id_4.png",
                "caption": "Figure 7:In this case, we are able to predict a sequence of actions that pulls our left arm in, similar to the goal.",
                "position": 669
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/left_id_10.png",
                "caption": "Figure 8:In this case, we are able to predict a sequence of actions that lowers our left arm, but not the same amount as the groundtruth sequence as we can see in the pose and hand at the bottom of our rollout.",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/left_id_15.png",
                "caption": "Figure 9:In this case, we are able to predict a sequence of actions that lowers our left arm that lowers the tissue. However, the goal image still has the tissue visible.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/right_id_18.png",
                "caption": "Figure 10:In this case, we are able to predict a sequence of actions that raises our right arm to the mixing stick. We see a limitation with our method as we only predict the right arm so we do not predict to move the left arm down accordingly.",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/right_id_36.png",
                "caption": "Figure 11:In this case, we are able to predict a sequence of actions that moves our right arm toward the left but not quite enough. We see a limitation with our method as we only predict the right arm so we do not predict any necessary additional body rotations.",
                "position": 681
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/PEVA_CEM_viz/right_kettle.png",
                "caption": "Figure 12:In this case, we are able to predict a sequence of actions that reaches toward the kettle but does not quite grab it as in the goal.",
                "position": 684
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_19.png",
                "caption": "Figure 13:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1633
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_22.png",
                "caption": "",
                "position": 1636
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_34.png",
                "caption": "Figure 14:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1638
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_40.png",
                "caption": "",
                "position": 1641
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_41.png",
                "caption": "Figure 15:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1643
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_44.png",
                "caption": "",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_47.png",
                "caption": "Figure 16:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_53.png",
                "caption": "",
                "position": 1651
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_58.png",
                "caption": "Figure 17:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1653
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_65.png",
                "caption": "",
                "position": 1656
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_66.png",
                "caption": "Figure 18:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1658
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_67.png",
                "caption": "",
                "position": 1661
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_75.png",
                "caption": "Figure 19:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1663
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_83.png",
                "caption": "",
                "position": 1666
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_84.png",
                "caption": "Figure 20:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1668
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_86.png",
                "caption": "",
                "position": 1671
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_87.png",
                "caption": "Figure 21:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1673
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_88.png",
                "caption": "",
                "position": 1676
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_89.png",
                "caption": "Figure 22:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1678
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_90.png",
                "caption": "",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_91.png",
                "caption": "Figure 23:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1683
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_92.png",
                "caption": "",
                "position": 1686
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_94.png",
                "caption": "Figure 24:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1688
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_104.png",
                "caption": "",
                "position": 1691
            },
            {
                "img": "https://arxiv.org/html/2506.21552/extracted/6571870/figure/supp_figure/id_107.png",
                "caption": "Figure 25:Generation Over Long-Horizons. We include16161616-second video generation examples.",
                "position": 1693
            }
        ]
    },
    {
        "header": "More Qualitative Results",
        "images": []
    }
]