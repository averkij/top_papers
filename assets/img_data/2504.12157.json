[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.12157/x1.png",
                "caption": "Figure 1.FocusedAD: We propose an automated character-centric AD generation model that emphasizes main character regions’ appearances and actions while incorporating narrative context. Characters appearing in the movie clip are annotated with colored bounding boxes.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2504.12157/x2.png",
                "caption": "Figure 2.Overview of FocusedAD: FocusedAD takes movie clips as input and captures the character best query bank through clustering. The Character Perception Module identifies main characters in key frames and bi-directionally propagates character regions across the entire key frame sequence. Then, through the Dynamic Prior Module, it dynamically integrates visual and text priors using soft prompts. Finally, the Focused Caption Module takes scene-level tokens, character-level tokens, and soft prompts as input to generate character-centric audio descriptions.",
                "position": 175
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.12157/x3.png",
                "caption": "Figure 3.Character Perception Module traverses the key frame sequence, detecting main characters in any frame and obtaining their segmented regions. Videos are processed in a streaming fashion, where each frame cross-attends to the main character memories from context frames. Finally, both the region prediction and key frame embeddings are stored into memory bank.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2504.12157/x4.png",
                "caption": "Figure 4.Instruction template with soft prompt. We use a well-designed instruction template with trainable soft prompts to inject the text prior and visual prior into Focused Caption Module.",
                "position": 356
            }
        ]
    },
    {
        "header": "4.Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.12157/x5.png",
                "caption": "Figure 5.Samples of Storyboard-v2. Our dataset involves three main part, i.e., (i)movie clips, (ii) character regions, (iii) movie audio description ground-truth",
                "position": 402
            },
            {
                "img": "https://arxiv.org/html/2504.12157/x6.png",
                "caption": "Figure 6.The clustering results for obtaining the best query from the movieHarry Potter and the Deathly Hallows.",
                "position": 432
            }
        ]
    },
    {
        "header": "5.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.12157/x7.png",
                "caption": "Figure 7.Ablation study on the filmLes Misérablesto evaluate changes in FocusedAD indicators under varying thresholds. This film is selected for its representative nature, as its metrics closely align with the average of MAD-eval-Named.",
                "position": 613
            },
            {
                "img": "https://arxiv.org/html/2504.12157/x8.png",
                "caption": "Figure 8.Qualitative results of our method. The top two movie clips demos are from MAD-eval-Named and the bottom two movie clips demos are from Cinepile-AD. The Character Perception Module can recognize active main characters and feed their names into the AD generation pipeline. For visualization purposes, we display the portrait images of characters that have the closest distance to the best query, but the model actually utilizes the best query features as input.",
                "position": 616
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]