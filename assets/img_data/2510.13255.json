[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/Framework.jpg",
                "caption": "Figure 1:A framework for Hierarchical Frequency Tagging Probes (HFTP) and an illustration of neurons involved in different levels of hierarchical linguistic processing in both LLMs and the human brain.A, hierarchical linguistic structure in English and Chinese including syllable, phrase, and sentence.B, hierarchical linguistic pattern (1​Hz1\\;\\mathrm{Hz}: sentence feature,2​Hz2\\;\\mathrm{Hz}: phrase feature) observed both in LLMs andC, human brain.",
                "position": 105
            }
        ]
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/correlation.jpg",
                "caption": "Figure 2:Alignment pipeline between LLMs and the human brain. SRDMs are computed for exclusive sentence/phrase and sentence&phrase MLP neurons and brain channels by comparing cosine similarities across different conditions. Subsequently, RSA (using Spearman correlation) is applied to quantify the similarity between the two SRDMs, thereby assessing the correspondence between model and brain representations.",
                "position": 112
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_Layer6_fft.png",
                "caption": "Figure 3:Hierarchical frequency patterns of MLP neurons selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Here, “experiment\" denotes the original corpus, while “random\" indicates the randomized version. Shaded bands show±1​s.e.m.\\pm 1\\;\\mathrm{s.e.m.}computed across 10 shuffled-input activation partitions. Significant peaks (*p<0.05p<0.05, FDR corrected) indicate amplitudes stronger than neighboring frequencies within±0.5​Hz\\pm 0.5\\;\\mathrm{Hz}. \"Normalized Amplitude\" represents the curves and bands scaled to a range of 0 to 1.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_gpt2.png",
                "caption": "(a)GPT-2",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_gpt2.png",
                "caption": "(a)GPT-2",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_gemma.png",
                "caption": "(b)Gemma",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_gemma2.png",
                "caption": "(c)Gemma 2",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_Llama2.png",
                "caption": "(d)Llama 2",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_llama3.png",
                "caption": "(e)Llama 3.1",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/ssvoc_GLM.png",
                "caption": "(f)GLM-4",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/MTG_L_ITPC_plot.png.png",
                "caption": "Figure 5:Hierarchical frequency patterns of sEEG channels selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Here, “setence\" denotes the originalsentencecorpus, while “random\" indicates the randomized version. Shaded bands show±1​s.e.m.\\pm 1\\;\\mathrm{s.e.m.}computed across channels. Significant peaks (*p<0.05p<0.05, FDR corrected) indicate amplitudes stronger than neighboring frequencies within±0.5​Hz\\pm 0.5\\;\\mathrm{Hz}. \"Normalized ITPC\" represents the curves and bands scaled to a range of 0 to 1.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Brain_.jpg",
                "caption": "(a)sEEG channel locations and Brain ROIs",
                "position": 291
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Brain_.jpg",
                "caption": "(a)sEEG channel locations and Brain ROIs",
                "position": 294
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/sentence_region_distribution.png",
                "caption": "(b)Significant sEEG channel distribution",
                "position": 301
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlignment pipeline for syntactic processing between LLMs and the human brain",
        "images": []
    },
    {
        "header": "Appendix BPredictive encoding control analysis",
        "images": []
    },
    {
        "header": "Appendix CBilingual sentence- and phrase-level representations in LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_gpt.png",
                "caption": "(a)GPT-2",
                "position": 4794
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_gpt.png",
                "caption": "(a)GPT-2",
                "position": 4797
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_gemma.png",
                "caption": "(b)Gemma",
                "position": 4802
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_gemma2.png",
                "caption": "(c)Gemma 2",
                "position": 4808
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_llama2.png",
                "caption": "(d)Llama 2",
                "position": 4813
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_llama3.png",
                "caption": "(e)Llama 3.1",
                "position": 4819
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/cross_language_neurons_GLM.png",
                "caption": "(f)GLM-4",
                "position": 4824
            }
        ]
    },
    {
        "header": "Appendix DPreliminary bilingual HFTP test on native Chinese speakers",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/Normal_ChenLong.png",
                "caption": "Figure 8:Hierarchical frequency patterns of sEEG channels from one participant, using four-word English sequence, selectively represent sentence features, phrase features, shared features of both and non-sensitive feature (from left to the right). Shaded bands show±1​s.e.m.\\pm 1\\;\\mathrm{s.e.m.}computed within each channel by bootstrapping across sliding-window ITPC estimates.",
                "position": 4841
            }
        ]
    },
    {
        "header": "Appendix EContribution Ratios of LLMs",
        "images": []
    },
    {
        "header": "Appendix FHFTP on naturalistic corpus",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/8-natural_Layer21_fft.png",
                "caption": "Figure 9:Hierarchical frequency patterns of MLP neurons, using a naturalistic Chinese 8-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4888
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/9-natural_Layer23_fft.png",
                "caption": "Figure 10:Hierarchical frequency patterns of MLP neurons, using a naturalistic Chinese 9-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4891
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/8-naturale_Layer28_fft.png",
                "caption": "Figure 11:Hierarchical frequency patterns of MLP neurons, using a naturalistic English 8-word corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4894
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/9-naturale_Layer20_fft.png",
                "caption": "Figure 12:Hierarchical frequency patterns of MLP neurons, using a naturalistic English 9-word corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4897
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/8-zhwiki_Layer5_fft.png",
                "caption": "Figure 13:Hierarchical frequency patterns of MLP neurons, using a Chinese Wikipedia 8-syllable corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4900
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/8-enwiki_Layer26_fft.png",
                "caption": "Figure 14:Hierarchical frequency patterns of MLP neurons, using a English Wikipedia 8-word corpus, selectively represent sentence features, phrase features, shared features of both, and non-sensitive features (from left to right).",
                "position": 4903
            }
        ]
    },
    {
        "header": "Appendix GModel details",
        "images": []
    },
    {
        "header": "Appendix HSyntactic corpora",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13255/images/gpt2-large-chinese_L_contribution_ratios.png",
                "caption": "Figure 15:Contribution ratios for GPT-2: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6123
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/gpt2-large-chinese_R_contribution_ratios.png",
                "caption": "",
                "position": 6127
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/gemma-2b_L_contribution_ratios.png",
                "caption": "Figure 16:Contribution ratios for Gemma: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6131
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/gemma-2b_R_contribution_ratios.png",
                "caption": "",
                "position": 6135
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/gemma-2-9b_L_contribution_ratios.png",
                "caption": "Figure 17:Contribution ratios for Gemma 2: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6139
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/gemma-2-9b_R_contribution_ratios.png",
                "caption": "",
                "position": 6143
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Llama-2-7b-hf_L_contribution_ratios.png",
                "caption": "Figure 18:Contribution ratios for Llama 2: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6147
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Llama-2-7b-hf_R_contribution_ratios.png",
                "caption": "",
                "position": 6151
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Llama-3.1-8B_L_contribution_ratios.png",
                "caption": "Figure 19:Contribution ratios for Llama 3.1: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6155
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/Llama-3.1-8B_R_contribution_ratios.png",
                "caption": "",
                "position": 6159
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/GLM-4-9b_L_contribution_ratios.png",
                "caption": "Figure 20:Contribution ratios for GLM-4: Left hemisphere (top) and Right hemisphere (bottom).",
                "position": 6163
            },
            {
                "img": "https://arxiv.org/html/2510.13255/images/GLM-4-9b_R_contribution_ratios.png",
                "caption": "",
                "position": 6167
            }
        ]
    },
    {
        "header": "Appendix IBrain ROIs",
        "images": []
    }
]