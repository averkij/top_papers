[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15879/x1.png",
                "caption": "Figure 1:An overview of Typed-RAG. Non-factoid questions are classified by the type classifier and processed based on their type. Prompts for the multi-aspect decomposer and answer aggregator handle the unique requirements of each type. Details of the prompt can be found in AppendixA.4.",
                "position": 182
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15879/x2.png",
                "caption": "Figure 2:Mean Percentile Rank (MPR) performance comparison of LLM, RAG, and Typed-RAG on six different non-factoid question categories from the Wiki-NFQA dataset. Results are reported using different model configurations (Llama-3.2-3B and Mistral-7B) and scorer LLMs (Mistral-7B and GPT-4o mini). The y-axis represents the MPR score (%), with higher values indicating better performance.",
                "position": 489
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Details",
        "images": []
    },
    {
        "header": "Appendix BConstruction of the Wiki-NFQA Dataset",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DDetailed Analysis per Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15879/x3.png",
                "caption": "Figure 16:Detailed process for each Non-Factoid question type. In (b) and (c),Knsubscriptğ¾ğ‘›K_{n}italic_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrepresents the extracted keywords. In (d) and (e), the single-aspect query generator creates multiple queries, and their answers are aggregated. Specifically, in (d),Sâ¢Qnğ‘†subscriptğ‘„ğ‘›SQ_{n}italic_S italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrefers to single-aspect queries, whileAnsubscriptğ´ğ‘›A_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTdenotes the corresponding answers. In (e),Oâ¢Pnğ‘‚subscriptğ‘ƒğ‘›OP_{n}italic_O italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrepresents queries generated for each distinct opinion.",
                "position": 1572
            },
            {
                "img": "https://arxiv.org/html/2503.15879/x3.png",
                "caption": "Figure 16:Detailed process for each Non-Factoid question type. In (b) and (c),Knsubscriptğ¾ğ‘›K_{n}italic_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrepresents the extracted keywords. In (d) and (e), the single-aspect query generator creates multiple queries, and their answers are aggregated. Specifically, in (d),Sâ¢Qnğ‘†subscriptğ‘„ğ‘›SQ_{n}italic_S italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrefers to single-aspect queries, whileAnsubscriptğ´ğ‘›A_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTdenotes the corresponding answers. In (e),Oâ¢Pnğ‘‚subscriptğ‘ƒğ‘›OP_{n}italic_O italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPTrepresents queries generated for each distinct opinion.",
                "position": 1574
            }
        ]
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    }
]