[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06864/x1.png",
                "caption": "Figure 1:AutoQ-VIS overview.In the initial training stage, both the VIS model and the mask quality predictor are trained on synthetic videos with pseudo annotations[videocutler]. During the multi-round self-training stage, the VIS model generates pseudo masks on unlabeled videos, which are then scored by the frozen quality predictor. Pseudo masks with high predicted quality are selected and added to the training set. The VIS model is subsequently retrained on both the synthetic data and the selected pseudo labels, enabling iterative refinement and progressive performance gains.",
                "position": 69
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06864/x2.png",
                "caption": "Figure 2:Network architecture of VideoMask2Former[mask2former,videomask2former]and Mask Quality Predictor.Our quality predictor integrates mask predictions and pixel decoder features following[maskscore], employing a sequential architecture with four convolution layers (3×\\times3 kernels, final layer stride of 2 for spatial reduction) followed by three fully-connected layers that ultimately produce mask IoU predictions.",
                "position": 116
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06864/x3.png",
                "caption": "Figure 3:The qualitative results of AutoQ-VIS on YouTubeVIS-2019valsplit.The quality scores are shown in the center of each object. The visual results demonstrate AutoQ-VIS’ proficiency in simultaneous multi-instance segmentation, persistent object tracking, and per-mask quality assessment across video sequences.",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x4.png",
                "caption": "Figure 4:The qualitative comparison on YouTubeVIS-2019valsplit.AutoQ-VIS demonstrates superior instance discovery capabilities compared to VideoCutLER[videocutler]: (1) Enhanced multi-object detection capacity, particularly for semantically distinct instances (e.g., person and bull in Column 2); (2) Improved segmentation fidelity through precise boundary delineation (e.g., the leopard in Column 3). (3) Better comprehensive instance coverage, eliminating false negatives (e.g., detecting humans in Columns 1 & 4 that VideoCutLER completely misses, even without occlusion or scale challenges).",
                "position": 524
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x5.png",
                "caption": "Figure 5:Visualized comparison of quality scoreQlQ_{l}and confidence scoresls_{l}on YouTubeVIS-2019valsplit.Here,ρs\\rho_{s}denotes the Spearman’s rank correlation coefficient. Subplot (a) visualizes quality scoresQlQ_{l}and their ground truth IoU. Subplot (b) visualizes confidence scoressls_{l}and their ground truth IoU.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x5.png",
                "caption": "",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x6.png",
                "caption": "",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x7.png",
                "caption": "Figure 6:Comparison of average ground-truth IoU and quality score across different mask sizes.The definitions ofSmall,Medium, andLargefollow those in COCO[coco]. Here,IoUrefers to the intersection-over-union between the predicted mask and the ground-truth annotation. We compare the average IoU and quality score across these area categories. The results demonstrate a strong alignment between our quality score and the ground-truth IoU, with only a limited overestimation for large objects. This minor bias does not substantially affect the distribution of pseudo labels across training rounds (as shown inFig.7).",
                "position": 797
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x7.png",
                "caption": "",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x8.png",
                "caption": "",
                "position": 805
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x9.png",
                "caption": "Figure 7:Comparison of object area distributions between pseudo labels across different rounds and ground-truth labels.Here,Log Arearefers to the natural logarithm of the normalized area (i.e., object area divided by image area). The definitions ofSmall,Medium, andLargefollow those in COCO[coco].Round 0denotes pseudo labels produced by the model in the beginning of the self-training. As shown, the object area distributions remain largely stable across different rounds. Nonetheless, relative to the ground truth, our pseudo-label set exhibits a higher proportion of large objects.",
                "position": 813
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "6Detailed methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06864/x10.png",
                "caption": "Figure 8:Qualitative results of our VIS model on YouTubeVIS-2019valsplit.",
                "position": 1057
            },
            {
                "img": "https://arxiv.org/html/2512.06864/x11.png",
                "caption": "Figure 9:Qualitative results of our quality predictor on YouTubeVIS-2019trainsplit.The quality scores are shown in the center of each pseudo label.",
                "position": 1060
            }
        ]
    },
    {
        "header": "7Additional qualitative visualizations",
        "images": []
    }
]