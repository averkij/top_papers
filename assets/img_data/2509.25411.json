[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries on SAT",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25411/x1.png",
                "caption": "Figure 1:From a CDCL run to a KeyTrace.The left pane sketches one run in three stages: (1) decidex4=⊤x_{4}=\\top, thenx3=⊤x_{3}=\\top, hit a conflict, backtrack to the decision onx3x_{3}; (2) setx3=⊥x_{3}=\\bot, conflict again, backtrack tox4x_{4}; (3) setx4=⊥x_{4}=\\bot, then decidex1=⊤x_{1}=\\topandx2=⊤x_{2}=\\topand solve. Unit assignments are omitted for clarity. Collapsing backtracks removes detours and keeps only the surviving root–to–current decisions, yielding the compactKeyTraceon the right, which serves as the expert for imitation. A step‑by‑step walkthrough is in AppendixH.",
                "position": 187
            }
        ]
    },
    {
        "header": "4ImitSAT",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25411/x2.png",
                "caption": "Figure 2:Propagation dominates CDCL time. MiniSAT spends about 88.9% in propagation, 9.2% in conflict analysis, and 1.9% in branching. Reducing propagation is therefore the main route to wall‑clock gains.",
                "position": 278
            },
            {
                "img": "https://arxiv.org/html/2509.25411/x3.png",
                "caption": "Figure 3:Compact KeyTrace replay. The expert replayed only a small share of MiniSAT events: 0.2% conflicts, 19.6% decisions, and 4.3% propagations.",
                "position": 362
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25411/x4.png",
                "caption": "Figure 4:Wall‑clock time versus instances solved on random test sets and structured families. Curves show end‑to‑end solver time per instance with all model calls included and preprocessing excluded. ImitSAT and Graph‑Q‑SAT use 3 calls per instance. SATformer performs a single VSIDS initialization. The lower curve is better.",
                "position": 804
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BDatasets",
        "images": []
    },
    {
        "header": "Appendix CCDCL runtime breakdown",
        "images": []
    },
    {
        "header": "Appendix DKeyTrace replay",
        "images": []
    },
    {
        "header": "Appendix EEarly decisions shape CDCL",
        "images": []
    },
    {
        "header": "Appendix FVariable Permutation Augmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25411/x5.png",
                "caption": "Figure 5:Training and validation loss curves with and without variable‑permutation augmentation on the 5–15 range for 20 epochs. Permutation keeps training and validation closely aligned and prevents overfitting, while removing it lowers training loss but drives validation loss up.",
                "position": 1714
            }
        ]
    },
    {
        "header": "Appendix GStaged curriculum across variable ranges",
        "images": []
    },
    {
        "header": "Appendix HKeyTrace Example",
        "images": []
    },
    {
        "header": "Appendix ILarge Language Models (LLMs) Usage Statement",
        "images": []
    },
    {
        "header": "Appendix JEthics statement",
        "images": []
    },
    {
        "header": "Appendix KReproducibility statement",
        "images": []
    },
    {
        "header": "Appendix LLimitations",
        "images": []
    }
]