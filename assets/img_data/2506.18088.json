[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18088/x1.png",
                "caption": "Figure 1:Overview ofRoboTwin2.0.RoboTwin 2.0 is a scalable framework for data generation and benchmarking in bimanual robotic manipulation. It integrates an expert data generation pipeline and a 50-task benchmark built on the RoboTwin Object Dataset (731 objects, 147 categories). A multimodal language model agent enables automatic task program synthesis, while flexible dual-arm configurations facilitate scalable and diverse data collection. Policies trained on RoboTwin 2.0 data demonstrate improved robustness and generalization to unseen environments.",
                "position": 116
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18088/x2.png",
                "caption": "Figure 2:RoboTwin 2.0 Pipeline.Leveraging RoboTwin-OD and a predefined skill API, our framework employs an MLLM-based expert code generation module with simulation-in-the-loop feedback to automatically synthesize expert-level task programs. These programs are used to generate diverse, domain-randomized trajectories that support downstream policy training and evaluation.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x3.png",
                "caption": "Figure 3:Expert Code Generation Pipeline.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x4.png",
                "caption": "Figure 4:Visualization of domain randomization and our texture library.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x5.png",
                "caption": "Figure 5:Five RoboTwin 2.0 Embodiment (Aloha-AgileX, ARX-X5, Piper, Franka and UR5).",
                "position": 217
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x5.png",
                "caption": "Figure 5:Five RoboTwin 2.0 Embodiment (Aloha-AgileX, ARX-X5, Piper, Franka and UR5).",
                "position": 219
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x6.png",
                "caption": "Figure 6:Different Grasping Behavior.",
                "position": 223
            }
        ]
    },
    {
        "header": "3RoboTwin 2.0 Data Generator, Benchmark and Large Scale Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18088/x7.png",
                "caption": "Figure 7:RoboTwin-OD.A large-scale object dataset for robotic manipulation with 147 categories and 731 objects, annotated with rich interaction labels and diverse language descriptions.",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x8.png",
                "caption": "Figure 8:Heterogeneous Dual-Arm Control via Object-Centric Manipulation.",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x9.png",
                "caption": "Figure 9:50 RoboTwin 2.0 Bimanual Manipulation Tasks.",
                "position": 275
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.18088/x10.png",
                "caption": "Table 1:Overall performance comparison across RoboTwin variants.Evaluated on the subset of tasks supported by both RoboTwin 1.0 and RoboTwin 2.0. Per-task success rate comparison is provided in Appendix8.",
                "position": 306
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x10.png",
                "caption": "Figure 10:RoboTwin Success Rate Distribution.",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2506.18088/x11.png",
                "caption": "Figure 11:Real-World Evaluation across Four Configurations.",
                "position": 984
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AContributions",
        "images": []
    },
    {
        "header": "Appendix BBenchmarking RoboTwin 2.0 Against Existing Datasets",
        "images": []
    },
    {
        "header": "Appendix CDomain Randomization Setting",
        "images": []
    },
    {
        "header": "Appendix DPolicies Training Details",
        "images": []
    },
    {
        "header": "Appendix EPrompts for Generating Task Instructions and Object Descriptions",
        "images": []
    },
    {
        "header": "Appendix FTask Instruction and Object Description Example",
        "images": []
    },
    {
        "header": "Appendix GExperimental Details and Metric Definitions for Code Generation",
        "images": []
    },
    {
        "header": "Appendix HSuccess Rates of Different Embodiments on RoboTwin 2.0 Tasks",
        "images": []
    }
]