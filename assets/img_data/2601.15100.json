[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15100/x1.png",
                "caption": "Figure 1.The WebSeek interface. (A) The AI Suggestions view, including a panel displaying proactive AI guidance (A1) and a Chat View (A2) for users to chat with the LLM to manage instances.\n(B) The instance view, a canvas holding the created data instances. They can either be data tables (B1-B4) or visualizations (B5).",
                "position": 136
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.A framework for mixed-initiative assistance in data tasks on the web",
        "images": []
    },
    {
        "header": "4.Design Goals",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15100/x2.png",
                "caption": "Figure 2.The table editor (A) and visualization editor (B) in WebSeek. In the table editor, an in-situ suggestion is provided suggesting the completion of the next few rows in green after users fill the initial ones. In the visualization editor, users may select a chart type and drag data attributes to the shelves (x-axis, y-axis, color, and size) to create a visualization.",
                "position": 939
            }
        ]
    },
    {
        "header": "5.WebSeek",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15100/x3.png",
                "caption": "Figure 3.Illustration of the data capture and source tracing interactions. (A) The user click on an empty cell and clicks on the “capture” button. (B) The user enters the selection mode and is enabled to capture DOM elements. (C) The captured image is saved in the cell. (D) The “source” button is clicked to locate the data source on the web. (E) The browser is automatically navigated to the source page with the source DOM highlighted.",
                "position": 988
            },
            {
                "img": "https://arxiv.org/html/2601.15100/figures/scenario.png",
                "caption": "Figure 4.An illustration of the usage scenario. (A) The user names the workspace before entering the interface. (B) A peripheral proactive AI suggestion is generated. (C) The user captures data from Amazon into cells. (D) An in-situ proactive AI suggestion is generated twice, and the user taps on thetabkey to accept it. The user repeats this to get the complete table. (E) The user chats to add new columns. (F) The extracted table from Amazon. (G) The user opens eBay and a new table is extracted simiarly. (H) An proactive AI suggestion for joining two tables is generated. (I) The results after the table join. (J) The user chats to create a visualization. (K) The user checks the generated visualization and navigates to the data source of a chosen item. (L) The item’s source highlighted on eBay.",
                "position": 1493
            }
        ]
    },
    {
        "header": "6.Technical Evaluation",
        "images": []
    },
    {
        "header": "7.User Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.15100/x4.png",
                "caption": "Figure 5.Participants’ ratings on (A) their perceived confidence on the final results and sense of control during the process, and (B) the perceived helpfulness of each system feature.",
                "position": 1624
            },
            {
                "img": "https://arxiv.org/html/2601.15100/x5.png",
                "caption": "Figure 6.Participants’ detailed ratings on the four features of the system regarding 1) whether the guidance/feature was reliable, 2) whether the guidance matched the user’s intent, 3) whether the guidance/feature helped avoid errors, and 4) whether the user regretted following the guidance.",
                "position": 1630
            },
            {
                "img": "https://arxiv.org/html/2601.15100/x6.png",
                "caption": "Figure 7.A visualization of P15’s workflow on Task 1. The color encoding is the same as previous figures (i.e., purple: in-situ suggestions; yellow: peripheral suggestions; orange: chatting with AI; blue: manual interactions). Consecutive events of the same category close to each other are merged into blocks, and the numbers on the blocks indicate the number of events merged (no merging if not shown).",
                "position": 1712
            },
            {
                "img": "https://arxiv.org/html/2601.15100/x7.png",
                "caption": "Figure 8.A visualization of P15, P7, and P13’s workflows on Task 2.",
                "position": 1735
            }
        ]
    },
    {
        "header": "8.Discussion",
        "images": []
    },
    {
        "header": "9.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]