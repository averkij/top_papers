[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14856/x1.png",
                "caption": "Figure 1:Comparison of the drafting and verification times of EAGLE-2 implemented by three frameworks (Huggingface, SGLang, and our optimized implementation) for two vocabulary sizes: 32k (Llama-2-7B) and 128k (Llama-3-8B).",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2502.14856/x2.png",
                "caption": "Figure 2:Token frequency distribution, statistically analyzed using the tokenizer of Llama-3-8B on a subset of 1B tokens randomly sampled from the SlimPajama-627B datasetSoboleva et¬†al. (2023). As shown in the figure, 75% of the vocabulary tokens account for less than 5% of all token occurrences in the dataset, presenting a ‚ÄúLong Tail‚Äù effect.",
                "position": 156
            },
            {
                "img": "https://arxiv.org/html/2502.14856/x3.png",
                "caption": "Figure 3:(Left) The drafting process of EAGLE-2 when promptP=ùëÉabsent~{}P=italic_P =‚ÄúIt‚Äù, beamw‚Å¢i‚Å¢d‚Å¢t‚Å¢h=2ùë§ùëñùëëùë°‚Ñé2width=2italic_w italic_i italic_d italic_t italic_h = 2and searchd‚Å¢e‚Å¢p‚Å¢t‚Å¢h=3ùëëùëíùëùùë°‚Ñé3depth=3italic_d italic_e italic_p italic_t italic_h = 3. It picks out the topK=8ùêæ8K=8italic_K = 8probability tokens (purple) as the draft tree. (Right) The drafting process of FR-Spec, where the LM Head is cropped during the drafting process while the beam search procedure remains the same.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2502.14856/x4.png",
                "caption": "Figure 4:The illustration of the verification process for EAGLE-2 and FR-Spec, given the draft in Figure3. FR-Spec¬†solely modifies the drafting process while the verification process remains consistent with EAGLE-2.",
                "position": 162
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14856/x5.png",
                "caption": "Figure 5:Comparison of Python-based implementation and C-based implementation. X, Y, and Z represent three different short-duration computational tasks.",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2502.14856/x6.png",
                "caption": "Figure 6:Time breakdown of the drafting process of EAGLE-2. We profile the EAGLE-2 trained on Llama-2-7B (32k vocabulary) and the EAGLE-2 trained on Llama-3-8B (128k vocabulary).",
                "position": 259
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14856/x7.png",
                "caption": "Figure 7:Decoding speed (token/s) of FR-Spec¬†and EAGLE-2 for Llama-3-8B under different frameworks.",
                "position": 574
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14856/x8.png",
                "caption": "Figure 8:Decoding speed (token/s) of FR-Spec¬†and EAGLE-2 for Llama-3.2-1B under different implementation framework.",
                "position": 1981
            }
        ]
    },
    {
        "header": "Appendix AAdditional Results",
        "images": []
    }
]