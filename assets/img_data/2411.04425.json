[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04425/x1.png",
                "caption": "Figure 1:DELIFT data selection across fine-tuning stages. (a)Instruction Tuning: Diverse instructions selected; redundant samples pruned. (b)Task-Specific Fine-Tuning: Mutually informative (with benchmark data) and diverse samples are prioritized for selection. (c)Continual Fine-tuning: New samples that are novel are integrated; new samples with overlapping information are pruned.",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x2.png",
                "caption": "",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x3.png",
                "caption": "",
                "position": 152
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experimental Results",
        "images": []
    },
    {
        "header": "5Conclusion, Limitations, and Future Work",
        "images": []
    },
    {
        "header": "6Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASubset Size Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04425/x4.png",
                "caption": "Figure 2:Graphs of LLM-A-J scores (y-axis) of Qwen2-72B-Instruct with varying subset sizes (x-axis) of Use Case 1 on MixInstruct for(a)ICL and(b)QLoRA, Use Case 2 on MixInstruct and MT-Bench for(c)ICL and(d)QLoRA, and Use Case 3 on IBM and Government for(e)ICL and(f)QLoRA.",
                "position": 1921
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x5.png",
                "caption": "",
                "position": 1941
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x6.png",
                "caption": "",
                "position": 1942
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x7.png",
                "caption": "",
                "position": 1943
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x8.png",
                "caption": "",
                "position": 1944
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x9.png",
                "caption": "",
                "position": 1945
            }
        ]
    },
    {
        "header": "Appendix BPrometheus Rubric",
        "images": []
    },
    {
        "header": "Appendix CLLM-as-Judges Scores",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04425/x10.png",
                "caption": "Table 8:LLM-as-Judges score distributions for Use Case 1 with MixInstruct training and validation set on the Qwen2-72B-Instruct model on the Initial, Random, and SelectIT baselines. The corresponding table is Table1.",
                "position": 2093
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x11.png",
                "caption": "",
                "position": 2106
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x12.png",
                "caption": "",
                "position": 2109
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x13.png",
                "caption": "",
                "position": 2110
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x14.png",
                "caption": "",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x15.png",
                "caption": "",
                "position": 2114
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x16.png",
                "caption": "Table 9:LLM-as-Judges score distributions for Use Case 1 with MixInstruct training and validation set on the Qwen2-72B-Instruct model on the LESS, DELIFT with Sentence Embedding, DELIFT, and Full Data methods. The corresponding table is Table1.",
                "position": 2120
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x17.png",
                "caption": "",
                "position": 2133
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x18.png",
                "caption": "",
                "position": 2136
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x19.png",
                "caption": "",
                "position": 2137
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x20.png",
                "caption": "",
                "position": 2140
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x21.png",
                "caption": "",
                "position": 2141
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x22.png",
                "caption": "",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2411.04425/x23.png",
                "caption": "",
                "position": 2145
            }
        ]
    },
    {
        "header": "Appendix DLimitations",
        "images": []
    },
    {
        "header": "Appendix EFuture Work",
        "images": []
    },
    {
        "header": "Appendix FCode and Data Availability",
        "images": []
    },
    {
        "header": "Appendix GHyperparameter Settings",
        "images": []
    }
]