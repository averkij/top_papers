[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/logo/huggingface-color.png",
                "caption": "",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2602.17588/logo/github.png",
                "caption": "",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/x1.png",
                "caption": "Figure 1:In this paper, we presentCowCorpus, a dataset of 400 real-user collaborative web trajectories that captures when and how humans intervene during execution, enabling intervention-aware agents that engage users only when needed.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Problem Formulation: Human Intervention Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/x2.png",
                "caption": "Figure 2:Visual Illustration of how PTS is calculated. We measure theL2L_{2}squared distance between the ground truth intervention and false-positive predictions. The score then penalizes based on the following distance.",
                "position": 171
            }
        ]
    },
    {
        "header": "3CowCorpus: Collecting Human-Agent Collaborative Web Activities",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/figures/globe.png",
                "caption": "Table 1:Standard tasks selected from Mind2Web[Deng et al.,2024].",
                "position": 211
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/speak.png",
                "caption": "",
                "position": 221
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x3.png",
                "caption": "Figure 3:Four distinct types of human-agent interaction patterns:Takeover,Hands-on,Hands-off, andCollaborative. We visualize the user groups using PCA (left), and describe the interaction mechanism of each group (right).",
                "position": 627
            }
        ]
    },
    {
        "header": "4Experiments: Modeling Human Intervention",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/x4.png",
                "caption": "Figure 4:Perfect Timing Score onCowCorpus. Out of the proprietary models, Claude outperforms GPT-4o and Gemini-2.5. On the finetuned model, Gemma 27B significantly boosts the performance when finetuned onCowCorpus.",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x5.png",
                "caption": "Figure 5:The heatmap shows the PTS score on the cluster-wise trained models for each of the three clusters. Models trained for corresponding clusters generally outperform the others, with the only exception of theTakeovergroup, which is analyzed in §4.3",
                "position": 797
            }
        ]
    },
    {
        "header": "5Deploying Collaborative Web Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/x6.png",
                "caption": "Figure 6:User response to the Likert scale questionnaire after the study. On average, user reports 26.5% higher in user rating compared to existing collaborative agents[Huq et al.,2025].",
                "position": 825
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACowCorpus: Human-Agent Collaborative Web Corpus",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.17588/x7.png",
                "caption": "(a)Information Access",
                "position": 1513
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x7.png",
                "caption": "(a)Information Access",
                "position": 1516
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x8.png",
                "caption": "(b)Personalized Interests and Lifestyle",
                "position": 1521
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x9.png",
                "caption": "(c)Product and Service Interaction",
                "position": 1527
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/chatgpt.jpg",
                "caption": "Table 5:Related backgrounds of participants, including frequency of AI usage, familiarity with AI agents with examples, and the types of tasks executed. Agent familiarity is scored on a 1–7 scale.",
                "position": 1537
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/claude.png",
                "caption": "",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/perplexity.jpeg",
                "caption": "",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/curson.jpeg",
                "caption": "",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/deepseek.png",
                "caption": "",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/openhands.png",
                "caption": "",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x10.png",
                "caption": "Figure 8:Overview of the collaborative AI agent,CowPilotHuq et al. [2025]used in our data collection. 1) Before the task is initiated, the user gives a textual task description as input. 2) During task execution, the system tracks the actions performed by the user and the agent. 3) After the task is executed, the user can download the task log.",
                "position": 1893
            },
            {
                "img": "https://arxiv.org/html/2602.17588/x11.png",
                "caption": "Figure 9:Time log across participants for the same task",
                "position": 1989
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/0shot_PTS_vs_alpha_fixed.png",
                "caption": "Figure 10:Zero-shot models maintain consistent PTS rankings acrossα\\alpha. We sweepα\\alphaover a fixed grid while holding all inputs constant and recompute PTS for each model under zero-shot setting. Kendall’s W significant test reveals that PTS preserves relative ordering under different temporal penalties.",
                "position": 2681
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/0shot_PTS_vs_alpha_fixed.png",
                "caption": "Figure 10:Zero-shot models maintain consistent PTS rankings acrossα\\alpha. We sweepα\\alphaover a fixed grid while holding all inputs constant and recompute PTS for each model under zero-shot setting. Kendall’s W significant test reveals that PTS preserves relative ordering under different temporal penalties.",
                "position": 2684
            },
            {
                "img": "https://arxiv.org/html/2602.17588/figures/close_PTS_vs_alpha_fixed.png",
                "caption": "Figure 11:Closed-source models maintain consistent PTS rankings acrossα\\alpha. We sweepα\\alphaover a fixed grid while holding all inputs constant and recompute PTS for each closed-source model. Kendall’s W significant test reveals that PTS preserves relative ordering under different temporal penalties.",
                "position": 2689
            }
        ]
    },
    {
        "header": "Appendix BAblation on Modeling Human Intervention",
        "images": []
    }
]