[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Limitations of Supervised Fine-Tuning in Planning",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22613/x1.png",
                "caption": "(a)Edge Frequency",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x1.png",
                "caption": "(a)Edge Frequency",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x2.png",
                "caption": "(b)SFT",
                "position": 285
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x3.png",
                "caption": "(c)SFT + PG",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x4.png",
                "caption": "(d)SFT + Q-Learning",
                "position": 295
            }
        ]
    },
    {
        "header": "4Path Planning Capacities of Policy Gradient",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22613/x5.png",
                "caption": "(a)Test Accuracy",
                "position": 452
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x5.png",
                "caption": "(a)Test Accuracy",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x6.png",
                "caption": "(b)Train Accuracy",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x7.png",
                "caption": "(c)Output Diversity",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x8.png",
                "caption": "(d)Influence of KL",
                "position": 470
            }
        ]
    },
    {
        "header": "5Analysis of the Q-Learning-Based Planning Mechanism",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22613/x9.png",
                "caption": "(a)Train Accuracy and Test Accuracy of Q-Learning",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x9.png",
                "caption": "(a)Train Accuracy and Test Accuracy of Q-Learning",
                "position": 647
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x10.png",
                "caption": "",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x11.png",
                "caption": "(b)Output Diversity vs. Accuracy",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x12.png",
                "caption": "",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2509.22613/q_learning_logits_10000.png",
                "caption": "(a)Epoch 10000",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2509.22613/q_learning_logits_10000.png",
                "caption": "(a)Epoch 10000",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2509.22613/q_learning_logits_30000.png",
                "caption": "(b)Epoch 30000",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2509.22613/q_learning_logits_100000.png",
                "caption": "(c)Epoch 100000",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2509.22613/q_learning_logits_300000.png",
                "caption": "(d)Epoch 300000",
                "position": 685
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AThe Use of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix BMore Related Works",
        "images": []
    },
    {
        "header": "Appendix CAppendix for SFT",
        "images": []
    },
    {
        "header": "Appendix DAppendix for Policy Gradient",
        "images": []
    },
    {
        "header": "Appendix EAppendix for Q-Learning",
        "images": []
    },
    {
        "header": "Appendix FEquivalence of Unclipped PPO and Policy Gradient",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22613/x13.png",
                "caption": "Figure 5:The test accuracy of PG with different KL coefficients on four data splits after fine-tuning the SFT model onDRL​-​TrainD_{\\mathrm{RL\\text{-}Train}}. All accuracies are evaluated with greedy decoding.",
                "position": 2104
            },
            {
                "img": "https://arxiv.org/html/2509.22613/x14.png",
                "caption": "Figure 6:The test accuracy of Q-learning on four data splits after fine-tuning the SFT model onDRL​-​TrainD_{\\mathrm{RL\\text{-}Train}}. All accuracies are evaluated with greedy decoding.",
                "position": 2107
            }
        ]
    },
    {
        "header": "Appendix GAdditional Experimental Results",
        "images": []
    }
]