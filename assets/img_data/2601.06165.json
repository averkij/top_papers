[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/figures/github-mark.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/hf-logo.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/haerae_logo.png",
                "caption": "",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/x1.png",
                "caption": "Figure 1:Representative examples from HAERAE-Vision across six of the 13 domains.Each example shows an under-specified Korean question with English translation, the corresponding image, and evaluation checklist criteria. Note the informal, context-dependent nature of the original queries.",
                "position": 198
            },
            {
                "img": "https://arxiv.org/html/2601.06165/x2.png",
                "caption": "Figure 2:Filtering pipeline showing data reduction at each stage.Numbers indicate pipeline stages described in Section2.1. The 0.76% survival rate reflects rigorous quality control. Each validated question is paired with an explicitated rewrite, yielding 1,306 query variants.",
                "position": 231
            }
        ]
    },
    {
        "header": "2HAERAE-Vision Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/figures/89_0.jpg",
                "caption": "Figure 3:Examples of query explicitation across three domains (Daily Life, Gaming, IT/Software).Original queries contain vague references that depend on images. Explicitated versions include background information to clarify the user request.",
                "position": 393
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/89_1.jpg",
                "caption": "",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/0_0.jpg",
                "caption": "",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/569_0.jpg",
                "caption": "",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2601.06165/figures/korean_specific.png",
                "caption": "Figure 4:Examples highlighting the cultural specificity of HAERAE-Vision:(a) Seoul subway interface, (b) traditional painting with calligraphy, (c) Korean drama scene requiring celebrity recognition, (d) TV channel settings, (e) historical family registry. Such culturally grounded items require knowledge rarely represented in English-centric datasets.",
                "position": 442
            }
        ]
    },
    {
        "header": "3Evaluation Framework",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/x3.png",
                "caption": "Figure 5:Effect of query explicitation on model performance.Models are sorted by improvement magnitude. Smaller models benefit most from explicitation, with GPT-5 Nano showing +21.7 points improvement. All results averaged over 3 runs.",
                "position": 722
            }
        ]
    },
    {
        "header": "6Additional Analysis on Explicitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/x4.png",
                "caption": "Figure 6:Category-level explicitation effects.Categories like Mathematics and Coding show large gains, while Entertainment and Natural Objects remain difficult even after clarification, with failures shifting toward cultural knowledge and visual grounding.",
                "position": 898
            }
        ]
    },
    {
        "header": "7Reliability of LLM-as-a-Judge",
        "images": []
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendices",
        "images": []
    },
    {
        "header": "Appendix ADataset Construction Details",
        "images": []
    },
    {
        "header": "Appendix BPipeline Prompts",
        "images": []
    },
    {
        "header": "Appendix CHuman Annotation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/figures/annotation_tool.png",
                "caption": "Figure 8:Screenshot of our Phase 1 annotation tool. The interface (shown in Korean) allowed annotators to assess image relevance, question/answer appropriateness, checklist accuracy, and category assignment.",
                "position": 2189
            }
        ]
    },
    {
        "header": "Appendix DLLM-as-Judge Prompt",
        "images": []
    },
    {
        "header": "Appendix EAdditional Results & Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06165/",
                "caption": "(a)Performance scaling with model size. Accuracy rises up to∼\\sim10B parameters but improves more slowly thereafter.",
                "position": 3189
            },
            {
                "img": "https://arxiv.org/html/2601.06165/",
                "caption": "(a)Performance scaling with model size. Accuracy rises up to∼\\sim10B parameters but improves more slowly thereafter.",
                "position": 3192
            },
            {
                "img": "https://arxiv.org/html/2601.06165/x6.png",
                "caption": "(b)Domain-level results. Health/Medical yields the highest accuracy, whereas Entertainment/Gaming remains the most challenging.",
                "position": 3197
            }
        ]
    },
    {
        "header": "Appendix FError Annotation Methodology",
        "images": []
    }
]