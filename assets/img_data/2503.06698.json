[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/tsne_features_models.png",
                "caption": "Figure 1:T-SNE visualization of the latent space from different pre-training objectives:CLIP[53], DiT[49], MAE[20], ResNet-50[18]on the domain generalization benchmark VLCS[15]. VLCS is curated from4444different datasets, thus dataset-specific biases like spatial composition and object size variations serve as different domains. Note how the diffusion features separate domains effectively, suggesting that latent domain structures can be captured without explicit supervision. Best viewed in color.",
                "position": 80
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/x1.png",
                "caption": "Figure 2:Training Pipeline.Thegreen-shaded regionrepresents the clustering and transformation step.Green solid arrowsindicate gradient flow, whilered arrowsrepresent non-gradient operations. The feature extractorùöøùöø{\\bm{\\Psi}}bold_Œ®first clusters samples to compute the pseudo-domain centroids. The transformation functionùíØùíØ\\mathcal{T}caligraphic_Tthen transforms these centroids to the latent space ofùöΩùöΩ{\\bm{\\Phi}}bold_Œ¶, producing transformed pseudo-domain centroids, which are concatenated with the features fromùöΩùöΩ{\\bm{\\Phi}}bold_Œ¶, and sent to the classifier.",
                "position": 183
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/ppseudo.png",
                "caption": "Figure 3:T-SNE visualization of how pseudo-domains are clustered together in the latent space of DiT for PACS.Note how the sketch domain forms distinct clusters, with light and dark pencil strokes mapped to separate regions in the latent space. Best viewed in color.",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/pseduo5_resized.png",
                "caption": "Figure 4:Pseudo-domains captured in the diffusion latent space of DiT on PACS.The clusters group images based on nuanced style-specific variances rather than class-specific variances.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/pseduo3_resized.png",
                "caption": "",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/pseduo4_resized.png",
                "caption": "",
                "position": 545
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/synth_images.png",
                "caption": "Figure 5:Example images from Synth-Artists and Synth-Photography, generated using Stable Diffusion XL[51].Synth-Artistsincludes artistic styles such as Van Gogh and Kinkade, while theSynth-Photographycaptures photography effects like Tilt-Shift and Bokeh.",
                "position": 1028
            }
        ]
    },
    {
        "header": "5Discussion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATransformation Function",
        "images": []
    },
    {
        "header": "Appendix BDomain Predictability",
        "images": []
    },
    {
        "header": "Appendix CLabel Noise and Domain Inconsistencies",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/x2.png",
                "caption": "Figure 6:Examples of inconsistent or confusing domain labels. Given that most datasets in this study are web-scraped, we expect there to be label noise and domain inconsistencies which may impact the NMI scores. These examples from the PACS dataset and SD-2.1 feature space illustrate cases where domain assignments may be unclear or conflicting. The color of the border on the images denotes the ground truth domain label.",
                "position": 2254
            }
        ]
    },
    {
        "header": "Appendix DEffect of Text-Conditioning in SD-2.1 for Domain Separation",
        "images": []
    },
    {
        "header": "Appendix EEffect of Layer and Timestep in Diffusion Models for Domain Separation (DiT vs SD-2.1) on PACS, and VLCS",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/layer_vs_block_domain_nmi.png",
                "caption": "Figure 7:Domain NMI comparison across layers and timesteps for PACS.Top: Domain NMI scores for SD-2.1 layers (best: up_ft:1) and DiT blocks (best: block:14). Bottom: Domain NMI scores across various denoising timesteps for SD-2.1 and DiT on PACS.",
                "position": 2307
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/timestep_vs_domain_nmi_combined.png",
                "caption": "",
                "position": 2311
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/imgs/layer_vs_block_domain_nmi_VLCS.png",
                "caption": "Figure 8:Domain NMI comparison across layers for VLCS.The Bottleneck Layer of Stable Diffusion (SD-2.1) which capture more coarse-grained features aids in separating high-level domain shifts in VLCS. However, DiT‚Äôs superior capability to capture global context via self-attention outperforms the domain NMI scores atbottleneckandup_ft:1.",
                "position": 2316
            }
        ]
    },
    {
        "header": "Appendix FGUIDE Pseudo-code",
        "images": []
    },
    {
        "header": "Appendix GDomain Shift Examples and Domain Separation in Feature Spaces",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/domain_class_grid_PACS.png",
                "caption": "Figure 9:Class examples across domains in the PACS dataset. Each column represents a domain, and each row corresponds to a class.",
                "position": 2488
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/PACS_class_vs_domain_nmi.png",
                "caption": "Figure 10:Class vs Domain NMI scores for PACS.Note how RN50 has the highest class NMI and diffusion models have low class NMI scores. Diffusion models also has the highest domain NMI scores, thereby capturing domain-specific class invariant structures.",
                "position": 2522
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/PACS_tsne_grid_plot.png",
                "caption": "Figure 11:T-SNE visualization of domain separation for PACS. Each point represents a sample, colored by its domain. Notice how well separated the domains are when diffusion features are used compared to other models.",
                "position": 2525
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/domain_class_grid_VLCS.png",
                "caption": "Figure 12:Class examples across domains in the VLCS dataset. Each column represents a domain, and each row corresponds to a class.",
                "position": 2534
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/VLCS_class_vs_domain_nmi.png",
                "caption": "Figure 13:Class vs Domain NMI scores for VLCS.Note how RN50 has the highest class NMI score, and diffusion models have low class NMI scores. DiT has a much higher domain NMI score than SD-2.1, resulting from its stronger capability in capturing high-level dataset-specific biases, as discussed in Sec.4.3.",
                "position": 2568
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/VLCS_tsne_grid_plot.png",
                "caption": "Figure 14:T-SNE visualization of domain separation for VLCS. Each point represents a sample, colored by its domain. Note how the DiT feature space best separate the domains.",
                "position": 2571
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/domain_class_grid_OH.png",
                "caption": "Figure 15:Class examples across domains in the OfficeHome dataset. Each column represents a domain, and each row corresponds to a class.",
                "position": 2580
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/OfficeHome_class_vs_domain_nmi.png",
                "caption": "Figure 16:Class vs Domain NMI scores for OfficeHome.Note how RN50 has the highest class NMI score and DINOv2 has the highest domain NMI score, resulting form its stronger ability in capturing low-level style shifts, as discussed in Sec.4.3. DiT and SD-2.1 have moderate domain NMI scores, with DiT having a lower class NMI score.",
                "position": 2614
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/OfficeHome_tsne_grid_plot.png",
                "caption": "Figure 17:T-SNE visualization of domain separation for OfficeHome.Each point represents a sample, colored by its domain. All models struggle to separate the domains in this dataset. The ‚Äúreal‚Äù domain has considerable overlap with the other domains.",
                "position": 2617
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/domain_class_grid_Terra.png",
                "caption": "Figure 18:Class examples across domains in the TerraIncognita dataset. Each column represents a domain, and each row corresponds to a class.",
                "position": 2626
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/TerraInc_class_vs_domain_nmi.png",
                "caption": "Figure 19:Class vs Domain NMI scores for TerraIncognita.Most models have a high class NMI score. SD-2.1 has the highest domain NMI score, resulting from its stronger capability in capturing spatial information, as discussed in Sec.4.3.",
                "position": 2660
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/terra_tsne_grid_plot.png",
                "caption": "Figure 20:T-SNE visualization of domain separation for TerraIncognita. Each point represents a sample, colored by its domain. Note how the SD-2.1 feature space best groups samples from the same domain closer together, and separate from other domains.",
                "position": 2663
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/domain_class_grid_DN.png",
                "caption": "Figure 21:Class examples across domains in the DomainNet dataset. Each column represents a domain, and each row corresponds to a class.",
                "position": 2672
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/DomainNet_class_vs_domain_nmi.png",
                "caption": "Figure 22:Class vs Domain NMI scores for DomainNet.Note how RN50 has the highest class NMI and diffusion models, and MAE have the highest domain NMI scores, with DiT having a lower class NMI score. All models except CLIP exhibit a moderate domain NMI score, likely due to the varied domain shifts inherent in the dataset, as discussed in Sec.4.3.",
                "position": 2675
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/synth_photo_grid.png",
                "caption": "Figure 23:Synth-Photography examples generated using Stable Diffusion XL[51], each column is a photography effect which forms the domain.",
                "position": 2717
            },
            {
                "img": "https://arxiv.org/html/2503.06698/extracted/6264892/appendix_imgs/synth_artists_grid.png",
                "caption": "Figure 24:Synth-Artists examples generated using Stable Diffusion XL[51], each column is an artistic style which forms the domain.",
                "position": 2720
            }
        ]
    },
    {
        "header": "Appendix HSynth-Photography and Synth-Artists Custom Datasets",
        "images": []
    }
]