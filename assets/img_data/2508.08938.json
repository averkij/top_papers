[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIDecoder-centric regularization",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08938/x1.png",
                "caption": "TABLE I:WERs (with confidence intervals) of ED and DeCRED models reported across multiple in-domain test sets using normalized transcripts, with Whisper-medium and OWSM v3.1 included as references.",
                "position": 300
            }
        ]
    },
    {
        "header": "IIIExperimental setup",
        "images": []
    },
    {
        "header": "IVResults",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08938/x1.png",
                "caption": "TABLE II:Comparison of ED and DeCRED models on out-of-domain test sets.",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2508.08938/x1.png",
                "caption": "TABLE III:Zero-Attention ILM BPE-level perplexity estimation of ED and DeCRED models on in- and out-of-domain test sets.",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2508.08938/x1.png",
                "caption": "Figure 2:The impact of model size and decoding approach on the average time needed to transcribe an utterance and macro average WER",
                "position": 527
            }
        ]
    },
    {
        "header": "VFurther analysis",
        "images": []
    },
    {
        "header": "VIConclusion and limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]