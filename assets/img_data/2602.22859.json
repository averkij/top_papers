[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/Fig1.png",
                "caption": "Figure 1:Due to the lack of interpretable diagnostics and scarcity of visual diversity, previous self-evolution frameworks can alleviate hallucination to some extent but fail to provide meaningful improvements on long-tail tasks such as mathematics and OCR. As a result, the model often exhibits instability or even degradation in these capabilities during the evolution process. In contrast, our DPE framework effectively addresses these blind spots and supports a more comprehensive and balanced progression of the model’s abilities.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/Fig2.jpg",
                "caption": "Figure 2:Overview of the DPE framework.",
                "position": 207
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/Fig3.png",
                "caption": "Figure 3:Ablation results on CharXiv and MathVision across three iterations, comparing full DPE with variants.",
                "position": 995
            },
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/Fig4.png",
                "caption": "Figure 4:Category distribution of the seed set and the diagnosis-guided mixture ratios recommended by DPE over three iterations.",
                "position": 1022
            },
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/Fig5.png",
                "caption": "Figure 5:UMAP visualization of image diversity (left) and text diversity (right) for VisPlay and DPE.",
                "position": 1050
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/case1.jpg",
                "caption": "(a)VisPlay generates a question that lacks essential visual grounding and cannot be answered based on the image.",
                "position": 1863
            },
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/case1.jpg",
                "caption": "(a)VisPlay generates a question that lacks essential visual grounding and cannot be answered based on the image.",
                "position": 1866
            },
            {
                "img": "https://arxiv.org/html/2602.22859/2602.22859v1/Fig/case2.jpg",
                "caption": "(b)VisPlay produces a multiple‑choice question without options, resulting in an incomplete structure.",
                "position": 1871
            }
        ]
    },
    {
        "header": "Appendix ACase Study",
        "images": []
    }
]