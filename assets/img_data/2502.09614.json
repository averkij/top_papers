[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x1.png",
                "caption": "Figure 1:DexTracklearns a generalizable neural tracking controller for dexterous manipulation from human references.It generates hand action commands from kinematic references, ensuring\nclose tracking of input trajectories (Fig. (a)), generalizes to novel and challenging tasks involving thin objects, complex movements and intricate in-hand manipulations (Fig. (b)),\nand demonstrates robustness to large kinematics noise and utility in real-world scenarios (Fig. (c)).\nKinematic references are illustrated inorange rectanglesandbackground.",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x2.png",
                "caption": "Figure 2:DexTracklearns a generalizable neural tracking controller for dexterous manipulation from human references. It alternates between training the tracking controller using abundant and high-quality robot tracking demonstrations and improving the data\nvia the tracking controller through a homotopy optimization scheme.",
                "position": 159
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x3.png",
                "caption": "Figure 3:Robustness w.r.t. unreasonable states.Please checkour websiteandvideofor animated results.",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x4.png",
                "caption": "Figure 4:Qualitative comparisons.Please checkour websiteandthe accompanying videofor animated results.",
                "position": 368
            }
        ]
    },
    {
        "header": "5Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x5.png",
                "caption": "Figure 5:Scaling the amount of demonstrations.",
                "position": 614
            }
        ]
    },
    {
        "header": "6Conclusions and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Technical Explanations",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x6.png",
                "caption": "Figure 6:DexTracklearns a generalizable neural tracking controller for dexterous manipulation from human references. It alternates between training the tracking controller using abundant and high-quality robot tracking demonstrations, and improving the data\nvia the tracking controller through a homotopy optimization scheme.",
                "position": 1345
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09614/x7.png",
                "caption": "Figure 7:Robustness towards out-of-distribution objects and manipulations.Please refer toour websiteandthe accompanying videofor animated results.",
                "position": 1666
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x8.png",
                "caption": "Figure 8:Additional qualitative comparisons.Please refer toour websiteandthe accompanying videofor animated results.",
                "position": 1679
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x9.png",
                "caption": "Figure 9:Additional real-world qualitative results.Please refer toour websiteandthe accompanying videofor animated results.",
                "position": 1889
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x10.png",
                "caption": "Figure 10:Failure cases in real-world experiments.Please refer toour websitefor animated results.",
                "position": 1906
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x11.png",
                "caption": "Figure 11:Effectiveness of the homotopy optimization scheme.Please refer toour websiteandthe accompanying videofor animated results.",
                "position": 1920
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x12.png",
                "caption": "Figure 12:Failure Cases.Please refer toour websiteandthe accompanying videofor animated results.",
                "position": 2024
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x13.png",
                "caption": "Figure 13:Examples of novel objects from the seen object category (TACO).",
                "position": 2042
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x14.png",
                "caption": "Figure 14:Examples of objects from new object categories (TACO).",
                "position": 2047
            },
            {
                "img": "https://arxiv.org/html/2502.09614/x15.png",
                "caption": "Figure 15:Real-world experiment setup.",
                "position": 2117
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experimental Details",
        "images": []
    }
]