[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14855/x1.png",
                "caption": "Figure 1:Pipeline of P2L.P2L takes a prompt and outputs anMùëÄMitalic_M-dimensional vector that we call a leaderboard. Once we have a leaderboard, we can build better data products, like routers and automatic analyses (see right).",
                "position": 125
            }
        ]
    },
    {
        "header": "2P2L method",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14855/x2.png",
                "caption": "Figure 2:Loss metrics.The line plot shows the validation loss as a function of the number of data points seen during training. The P2L models all substantially outperform the baselines, and performance scales with dataset and model size. The bar plots show the validation loss and mean squared error of the models trained on all 1.5M training points.",
                "position": 633
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x3.png",
                "caption": "Figure 3:P2L router performanceon Chatbot Arena. The left barplot shows the overall score of the router after it was deployed prospectively on Chatbot Arena. The right barplot shows the worst-case category score on Chatbot Arena. In both plots, larger models lead to higher Arena scores after better routers.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x4.png",
                "caption": "Figure 4:Router model choice distributionin each prompt category. The rows are different models, and the columns are different categories. Each cell represents the probability that the model was selected within that category (i.e., columns sum to 1). Models with an average selection rate below 1% are not shown.",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x5.png",
                "caption": "Figure 5:Arena score versus cost. Both plots show routing performance as a function of average cost. The left plot shows the averaged performance across all categories, and the right plot shows the performance in the creative writing category. The black open circles give the raw performance and cost of the models used by the router. Each gold dot represents the Arena score of theP2L-7Brouter as a function of the cost constraint in¬†(13). The plots show that the P2L router dominates and substantially improves the cost-performance Pareto frontier. All confidence intervals are 95%.",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x6.png",
                "caption": "Figure 6:Regression test.We show the strengths of different OpenAI models on various topic clusters based on their win rate againstGPT-4o-2024-05-13as predicted byP2L-7B. For each category, we show the probability a given model wins againstGPT-4o-2024-05-13under the BT model. The results show strong category-specific variability in performance; for example,o1-miniis substantially better thanGPT-4o-2024-05-13in ‚ÄúArithmetic Operations and Calculations‚Äù but substantially worse when asked to write a ‚ÄúSuspenseful Horror Story‚Äù.",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x7.png",
                "caption": "Figure 7:Aggregation scaling.The L1 distance between the aggregated leaderboard and the marginal BT regression as a function of the number of randomly sampled and aggregated datapoints in two categories: Chinese (left) and Math (right). The optimal performance is given by an estimate of the finite-sample fluctuations in the empirical BT coefficients from the finite validation sample of 1M data points.\nThe P2L estimate converges to a near-optimal solution with increased data.",
                "position": 745
            }
        ]
    },
    {
        "header": "4Discussion and related work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProofs",
        "images": []
    },
    {
        "header": "Appendix BAdditional theory",
        "images": []
    },
    {
        "header": "Appendix CAdditional regression tests",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14855/x8.png",
                "caption": "Figure 8:Regression teston Llama models with creative writing and math prompts. The percentages shown signify win rates againstLlama-3-70Bunder the BT coefficients predicted fromP2L-7B.",
                "position": 1503
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x9.png",
                "caption": "Figure 9:Regression teston Llama models with instruction following and coding prompts. The percentages shown signify win rates againstLlama-3-70Bunder the BT coefficients predicted fromP2L-7B.",
                "position": 1506
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x10.png",
                "caption": "Figure 10:Regression test using grounded Rao-Kupper.We show the strengths of different OpenAI models on various topic clusters based onP2L-7Bwith a grounded RK regression head (see Section2.2) and a dataset of unlabeled prompts. The percentage represents the sigmoid of the model coefficient.\nBecause the RK model is grounded, this corresponds roughly to a signal of the model‚Äôs reliability, i.e., its tendency to produce an answer that exceeds the voter‚Äôs minimum bar of quality. The results show strong category-specific variability in performance; for example,GPT-4o-miniando1have roughly the same reliability in the category ‚ÄúSuspenseful Horror Story‚Äù, but not ‚ÄúArithmetic Operations and Calculations‚Äù. We can also see that some categories are more difficult in general for LLMs to answer reliably, and thus we see larger performance improvements from test-time compute models likeo1ando1-mini.",
                "position": 1509
            },
            {
                "img": "https://arxiv.org/html/2502.14855/x11.png",
                "caption": "Figure 11:LiveBench cost routing.Comparison of the P2L cost-aware router and static models on LiveBench under various inference-cost constraints. The left plots show each model‚Äôs overall LiveBench performance at different maximum cost thresholds, while the right plots display models‚Äô relative rankings across multiple categories at the specific cost limit. By adaptively allocating prompts to cheaper or more expensive models when advantageous, the P2L router consistently matches or surpasses the best single model within each budget.",
                "position": 1513
            }
        ]
    },
    {
        "header": "Appendix DAdditional information",
        "images": []
    }
]