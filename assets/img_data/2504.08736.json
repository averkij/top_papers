[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x1.png",
                "caption": "Figure 1:Reconstructionvs.generation dilemma: Naively scaling visual tokenizers achieves better reconstruction but degrades downstream autoregressive (AR) generation. In contrast, GigaTok achieves better performance for both reconstruction and generation as tokenizers scale up.",
                "position": 96
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x2.png",
                "caption": "Figure 2:The 2.9B GigaTok achieves SOTA autoregressive image generation with a 1.4B AR model on ImageNet 256×\\times×256 resolution.",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Pilot Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x3.png",
                "caption": "Figure 3:Scaling trend for vanilla 1D tokenizers.As the model size increases, the reconstruction quality of vanilla tokenizers improves but the downstream AR Probing gFID consistently degrades. The increasing AR Probing validation loss indicates that scaling vanilla tokenizers results in a more complex latent space, making it difficult for AR models to learn effectively.",
                "position": 197
            }
        ]
    },
    {
        "header": "4GigaTok",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x4.png",
                "caption": "Figure 4:GigaTok architecture and semantic regularization.Top:We use a hybrid CNN-Transformer design for our visual tokenizer. The transformer layers are implemented with ViT for 2D tokenizer and Q-Former for 1D tokenizer.Bottom:We use a frozen DINOv2[43]image encoder\nfor semantic regularization.",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x5.png",
                "caption": "Figure 5:Training curves for 2.9B XL-XXL tokenizers with and without entropy loss.A 2.9B tokenizer does not converge without entropy loss. The entropy loss encourages high codebook usage and stabilizes training loss.",
                "position": 291
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x6.png",
                "caption": "Figure 6:Correlation between AR Probing Performance and Larger AR models.For 3 tokenizers: S-S, S-L, and B-L, we present that as the tokenizer improves, the performance improvements of AR Probing correlate to the performance improvements of larger AR models. Therefore, the AR Probing can effectively indicate how the tokenizer affects downstream larger AR models with limited computational costs.",
                "position": 389
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x7.png",
                "caption": "Figure 7:Scaling trends of tokenizers for reconstruction, downstream generation and representation quality with and without semantic regularization.By semantic regularization, GigaTok resolves the reconstructionvs.generation dilemma for tokenizer scaling in contrast to the vanilla version without semantic regularization. Moreover, GigaTok consistently improves the representation quality of downstream AR models by scaling up visual tokenizers. Note that in the last two figures, the red and blue curves correspond to different scales on the y-axis.",
                "position": 398
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x8.png",
                "caption": "Figure 8:Visualization\nof tokenizer features with and without semantic regularization.We compute PCA among the tokenizer features of a group of images of the same “golden retriever” class\nand visualize the first 3 PCA components.\nWe observe that the latent space of vanilla tokenizers shows inconsistent features both within a single image or across multiple semantically similar images. In contrast, GigaTok encodes images with semantic consistency and thus reduces the latent space complexity for AR models.",
                "position": 423
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x9.png",
                "caption": "Figure 9:Scalability comparison for 1D and 2D tokenizers.Using the same training setting, 1D tokenizers shows better reconstruction (rFID) and downstream representation quality (AR Probing: Lin Acc.). For downstream generation (gFID), 1D tokenizers present a steeper improving trend than 2D tokenizers.",
                "position": 481
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix BConfigurations for AR models",
        "images": []
    },
    {
        "header": "Appendix CDetailed GigaTok Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x10.png",
                "caption": "Figure 10:The architecture of GigaTok with Q-Former.",
                "position": 2179
            },
            {
                "img": "https://arxiv.org/html/2504.08736/x11.png",
                "caption": "Figure 11:Initialization of 1D queries in Q-Former modules.",
                "position": 2329
            }
        ]
    },
    {
        "header": "Appendix DFull Evaluation Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x12.png",
                "caption": "Figure 12:Training duration scaling trends of tokenizers for reconstruction, downstream generation and representation quality with and without semantic regularization.Note that in the last two figures, the red and blue curves correspond to different scales on the y-axis.",
                "position": 2553
            }
        ]
    },
    {
        "header": "Appendix ETraining Tokenizers for More Iterations",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08736/x13.png",
                "caption": "Figure 13:The linear probing accuracy of tokenizer encoders does not necessarily reflect downstream model performance.As the training proceeds, the XL-XXL tokenizer encoder presents an overfitting trend measured by linear probing accuracy, but downstream model performances consistently improve.",
                "position": 2571
            }
        ]
    },
    {
        "header": "Appendix FLinear Probing Accuracy of Tokenizers",
        "images": []
    },
    {
        "header": "Appendix GMore Discussions About Related Work",
        "images": []
    }
]