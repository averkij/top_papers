[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.08267/x1.png",
                "caption": "Figure 1:Performance comparison SFT on AIME 2024 and 2025.Mean Pass@1 accuracy and mean token length per training epoch.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2507.08267/x2.png",
                "caption": "Figure 2:Ablation study of Reward functions.The mean Pass@1 accuracy versus the mean token length for different combinations of reward functions. To clearly illustrate the performance at different token budgets, points are also plotted for outputs truncated at maximum token lengths of 8k, 12k, 16k, 24k, and 32k.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2507.08267/x3.png",
                "caption": "Figure 3:Per-problem changes in mean pass@1 and token length from the original model to our proposed recipe.This plot illustrates the shift in performance and efficiency for each problem after applying our training recipe.",
                "position": 363
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]