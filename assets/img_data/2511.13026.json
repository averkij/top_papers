[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13026/x1.png",
                "caption": "Figure 1:Operational workflow of the proposed REVISOR framework, contrasting it with traditional reflection mechanisms. The top panel illustrates a typical traditional approach, often employing a text-based re-evaluation mechanism. In contrast, the bottom panel details the REVISOR framework. This process involves two distinct stages: (1) Initial Inference, which generates a preliminary reasoning trace and identifies critical regions for detailed analysis; and (2) Reflective Reasoning, which integrates this initial trace with newly sampled, fine-grained visual evidence to yield a refined and robust final prediction.",
                "position": 105
            },
            {
                "img": "https://arxiv.org/html/2511.13026/x2.png",
                "caption": "Figure 2:Motivation for proposing a multimodal reflection mechanism. Left: Text-only reflection mechanisms, such as VL-Rethinker, achieve significant performance improvements in image understanding tasks. Middle: However, applying the same text-based reflection strategy to long-form video understanding leads to performance degradation. Right: Incorporating a revisit of key video segments during the reflection stage effectively improves performance on video understanding tasks.",
                "position": 114
            }
        ]
    },
    {
        "header": "2Motivation",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13026/x3.png",
                "caption": "Figure 3:Overview of the Dual-Attribution Decoupled Reward Mechanism (DADR). Final Answer Verification Reward (top) is derived from verifying the correctness of the model’s synthesized final answer, directly targeting the accuracy objective of the reflective stage. Conversely, Causal Segment Sufficiency Reward (bottom) is granted upon verifying an attribution answer derived exclusively from reviewed video segments, thereby guiding the model to identify and utilize segments highly pertinent to the user query.",
                "position": 183
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Extended Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13026/x4.png",
                "caption": "Figure 4:The superior efficacy of visual reflection over textual reflection in long-form video understanding. The left panel demonstrates that the length of the generated textual reflection consistently decreases throughout training. The right panel further indicates that forcing the model to perform longer textual reflection actually leads to a degradation in model performance.",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2511.13026/x5.png",
                "caption": "Figure 5:Comparative accuracy of key moment review across different methods. Methods based on the REVISOR framework and its variants are highlighted in blue, while different Temporal Grounding baselines are represented in green.",
                "position": 843
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8More Experimental Details on REVISOR",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13026/x6.png",
                "caption": "Figure 6:REVISOR framework training dataset composition. The training dataset for the REVISOR framework consists of three tasks: Short Video QA, Temporal Grounding, and Grounded Video QA, totaling 25K training samples. The parenthetical value for each dataset denotes its specific sample contribution.",
                "position": 1096
            }
        ]
    },
    {
        "header": "9Training Qwen2.5-VL-7B with Textual Reflection Mechanism on Video Data",
        "images": []
    },
    {
        "header": "10Case Study of REVISOR Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13026/x7.png",
                "caption": "Figure 7:Successful example of the REVISOR framework: achieving more accurate detail capture.",
                "position": 1149
            },
            {
                "img": "https://arxiv.org/html/2511.13026/x8.png",
                "caption": "Figure 8:Successful example of the REVISOR framework: achieving more accurate scene understanding.",
                "position": 1152
            },
            {
                "img": "https://arxiv.org/html/2511.13026/x9.png",
                "caption": "Figure 9:Successful example of the REVISOR framework: achieving more accurate object counting.",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2511.13026/x10.png",
                "caption": "Figure 10:As training progressed, REVISOR’s outputted reflective text paragraphs became increasingly concise, and the video segments it referenced grew more precise. Ultimately, it accurately concluded that respiratory cells could potentially be used in the treatment of cardiovascular disease.",
                "position": 1158
            }
        ]
    },
    {
        "header": "11Prompt Templates of REVISOR",
        "images": []
    }
]