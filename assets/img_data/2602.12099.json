[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12099/x1.png",
                "caption": "",
                "position": 211
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3GigaBrain-0.5M*",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12099/x2.png",
                "caption": "Figure 2:Overview ofRAMP.TheRAMPframework operates through a four-stage pipeline. (1)World Model Pre-trainingestablishes a unified representation space for both future state prediction and value estimation. (2)Policy Training with World Model Conditioninitializes theGigaBrain-0.5policy with explicit world model conditioning. (3)Human-in-the-Loop Rollout (HILR) Data Collectiongenerates diverse and high-quality trajectories through autonomous execution followed by expert corrections. (4)Continual Training with Rollout Dataupdates the policy using the annotated trajectory data, incorporating both successful demonstrations and corrective signals. This tightly integrated closed-loop process facilitates continuous policy refinement and self-improvement.",
                "position": 296
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12099/images/pretrain-data.png",
                "caption": "Figure 3:Data distribution of the pre-training stage ofGigaBrain-0.5.",
                "position": 444
            },
            {
                "img": "https://arxiv.org/html/2602.12099/images/gigabrain05_exp.png",
                "caption": "Figure 4:Performance ofGigaBrain-0.5on internal evaluation.",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x3.png",
                "caption": "Figure 5:Deployment ofGigaBrain-0.5on PiPER arms for real-worldBox Packing.",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x4.png",
                "caption": "Figure 6:Deployment ofGigaBrain-0.5on the G1 humanoid robot for real-worldBox Moving.",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x5.png",
                "caption": "Figure 7:Deployment ofGigaBrain-0.5on PiPER arms for real-worldEspresso Preparation.",
                "position": 467
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x6.png",
                "caption": "Figure 8:Deployment ofGigaBrain-0.5on the G1 humanoid robot for real-worldJuice Preparation.",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x7.png",
                "caption": "Figure 9:Deployment ofGigaBrain-0.5on the G1 humanoid robot for real-worldLaundry Collection.",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x8.png",
                "caption": "Figure 10:Deployment ofGigaBrain-0.5on PiPER arms for real-worldLaundry Folding.",
                "position": 476
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x9.png",
                "caption": "Figure 11:Deployment ofGigaBrain-0.5on PiPER arms for real-worldPaper Towel Preparation.",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x10.png",
                "caption": "Figure 12:Deployment ofGigaBrain-0.5on the G1 humanoid robot for real-worldTable Bussing.",
                "position": 482
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x11.png",
                "caption": "Figure 13:Value prediction visualization from the world model. Theorangebounding box highlights a value drop during aLaundry Foldingtask when a green garment interferes with the folding process, the predicted value recovers after the manipulator successfully removes the obstruction.",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x12.png",
                "caption": "Figure 14:Comparison of single-task and multi-task performance with and without world model conditions.",
                "position": 556
            },
            {
                "img": "https://arxiv.org/html/2602.12099/x13.png",
                "caption": "Figure 15:Comparison of different RL methods.",
                "position": 587
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]