[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10739/figures/teaser.png",
                "caption": "Figure 1:The motivation (a) and performance(b) of Intern-S1-MO.As problem difficulty increases, both the average human thinking time and the model token consumption per problem grow exponentially (a), already reaching concerning limits under current development trends. Intern-S1-MO enables LRMs to use about 512K tokens to solve a single problem, achieving state-of-the-art performance on challenging mathematical benchmarks (b).",
                "position": 144
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Building Hierarchical Reasoning Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10739/figures/method.png",
                "caption": "Figure 2:The agentic framwork of Intern-S1-MO.In each reasoning round, the reasoner agent tries to solve the question, and the summarizer agent compresses the current reasoning history into a series of lemmas, which will be added to the memory system after being verified by the verifier agent.\nExcept for the first round, the lemma library will be input into the reasoning agent along with the question.\nIn the final round, the solution generated by the reasoner agent undergoes a modification loop, which improves the quality of the solution based on feedback from the verifier agent, until the verification is passed or the maximum number of loop rounds is reached.",
                "position": 220
            }
        ]
    },
    {
        "header": "4RL training for Evolution of math agents",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "The Use of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix ASystem Prompts for Math Agents",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix COReal-H Algorithm",
        "images": []
    },
    {
        "header": "Appendix DGrading Details",
        "images": []
    },
    {
        "header": "Appendix ELemma Graph",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10739/figures/lemma_highlighted.png",
                "caption": "Figure 3:Example of a lemma graph.Red nodes mark all lemmas contributing to the final conclusion, with the numbers below indicating the number of rollout in which each lemma appeared.",
                "position": 1650
            }
        ]
    },
    {
        "header": "Appendix FCase Example",
        "images": []
    }
]