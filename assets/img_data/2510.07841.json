[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07841/x1.png",
                "caption": "Figure 1:Overview of the Test-Time Self-Improvement (TT-SI) framework.(Left)TT-SI enableson-the-flyadaptation by targeting uncertain test instances during inference. It consists of three steps:(1) Self-Awareness:AnUncertainty Estimator(H) identifies challenging samples.(2) Self-Data Augmentation:For each identified uncertain sample, one similar variant is automatically generated usingData Synthesis Function(G).(3) Self-Improvement:Test-Time Fine-tuning(T) applies a lightweight update using onlyone generated training instance per case.(Right)Δ\\Delta-accuracy gains of TT-SI over the prompting baseline at test-time. TT-SI improves the baseline by +5.48% on average across ToolAlpaca (+5.84%), NexusRaven (+6.05%), SealTool (+5.76%), and API-Bank (+4.26%).",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07841/x2.png",
                "caption": "Figure 2:Experimental Results on SealTool.Left: Accuracy comparison of TT-SI against standard baselines (left-most) and its variants (middle), including ablations (right-most).Right: Scaling behavior under different adaptation strategies with varying numbers of samples. Shaded regions show variance over five runs; dashed lines denote baseline references.",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2510.07841/x3.png",
                "caption": "Figure 3:Model Scaling.Model Scale and Architectural Generalization withQwen2.5-7B-Instruct.",
                "position": 683
            },
            {
                "img": "https://arxiv.org/html/2510.07841/x4.png",
                "caption": "Figure 4:Impact of Uncertainty.Performance of TT-SI when trained on certain samples (w.H’), uncertain samples (main), and all samples (w/oH).",
                "position": 691
            }
        ]
    },
    {
        "header": "5Discussions",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ATerminology: Self-Improving and Self-Evolving Agents",
        "images": []
    },
    {
        "header": "Appendix BOther Examples from Self-Regulated Learning",
        "images": []
    },
    {
        "header": "Appendix CPrevious Work on Large Language Models (LLMs) and Agent Fine-tuning",
        "images": []
    },
    {
        "header": "Appendix DUncertainty Estimation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07841/x5.png",
                "caption": "Figure 5:Comparison of PPL and RSS (ours) asUncertainty Estimator(H) on SealTool.Histograms show score differences between the top-1 and top-2 predictions. Thegreenbars denote correct predictions, andredbars denote incorrect ones. PPL-based uncertainty (left) shows strong overlap between correct and incorrect cases, whereas our RSS-based estimator (right) yields a clearer separation, enabling more reliable uncertainty filtering.",
                "position": 1812
            },
            {
                "img": "https://arxiv.org/html/2510.07841/x6.png",
                "caption": "Figure 6:Threshold (τ\\tau) Experiments withUncertainty Estimator(H) on SealTool.We investigate the effect of the softmax-difference thresholdτ\\tau, which controls the sensitivity ofHin flagging uncertain cases.\nThe left plot shows the true positive rate (TPR, proportion of correctly identified uncertain cases), while the right plot reports the false positive rate (FPR, proportion of certain cases incorrectly flagged as uncertain).\nAsτ\\tauincreases, TPR rises, but so does FPR, illustrating the trade-off between coverage and reliability.",
                "position": 1823
            }
        ]
    },
    {
        "header": "Appendix EData Generation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07841/x7.png",
                "caption": "Figure 7:Self-Generated Data Visualization.All test samples (circles) are projected into a two-dimensional semantic space via UMAP, and shown with the density contour distributions. The star denotes the uncertain inputxix_{i}, and triangles indicate 10 randomly sampled, self-generated synthetic queries from uncertain samplexix_{i}. Generated samples are tightly clustered and situated nearxix_{i}, demonstrating distributional alignment ofG.",
                "position": 1904
            }
        ]
    },
    {
        "header": "Appendix FCheating Experiments and TT-SI Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07841/x8.png",
                "caption": "Figure 9:Cheating Experiment on SealTool.Comparison of baseline methods—Base, in-context learning (ICL), supervised fine-tuning (SFT), and test-time training (TTT)—when explicitly trained on the test set (left four bars) usingQwen-2.5-1.5B-Instruct. We also report actual (non-cheating) scores for our TT-SI algorithm and its TT-D variant (right two bars).",
                "position": 1939
            }
        ]
    },
    {
        "header": "Appendix GImplementation Details of TT-SI",
        "images": []
    },
    {
        "header": "Appendix HAdditional Run-time Overhead and Resource Usage Analysis",
        "images": []
    },
    {
        "header": "Appendix IUse of LLMs",
        "images": []
    }
]