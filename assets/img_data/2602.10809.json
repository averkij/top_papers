[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/Figures/icons/hf-logo.png",
                "caption": "",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2602.10809/Figures/icons/crown-logo.png",
                "caption": "",
                "position": 192
            },
            {
                "img": "https://arxiv.org/html/2602.10809/x1.png",
                "caption": "Figure 1:Evolution of image retrieval paradigms.(a) Direct retrieval matches queries to images through visual semantic alignment. (b) Reasoning-intensive retrieval requires inference over external knowledge, but still evaluates each image independently. (c) DeepImageSearch demands corpus context awareness, where models must first locate target events within the visual history and then identify qualifying images through multi-step reasoning.",
                "position": 194
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/x2.png",
                "caption": "Figure 2:Two query types in DISBench. (a) Intra-Event queries locate a specific event and filter targets within it. (b) Inter-Event queries scan across events to verify recurring elements under temporal/spatial constraints.",
                "position": 241
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3DISBench: The Proposed Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/x3.png",
                "caption": "Figure 3:Semi-automated data construction pipeline.Starting from raw images, we first parse visual content to extract salient clues and person attributes, then mine latent associations across the corpus through retrieval and verification strategy. These elements are organized into a memory graph, from which we sample subgraphs via random walks to synthesize candidate queries for human verification.",
                "position": 285
            }
        ]
    },
    {
        "header": "4ImageSeeker: An Agentic Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/x4.png",
                "caption": "Figure 4:Dataset statistics of DISBench.(a) Query type distribution shows a balanced split between intra-event and inter-event queries. (b) Target images span diverse themes including portraits, nature views, daily items, and scenic spots.",
                "position": 619
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/x5.png",
                "caption": "Figure 5:Effect of test-time scaling with different strategies.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2602.10809/x6.png",
                "caption": "Figure 6:Distribution of error categories across four representative models on DISBench.",
                "position": 665
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEthical Considerations",
        "images": []
    },
    {
        "header": "Appendix BLimitations",
        "images": []
    },
    {
        "header": "Appendix CDetails of Automated Query Synthesis Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10809/x7.png",
                "caption": "Figure 7:Geographic distribution of geotagged photos in DISBench. Each point represents a photo location, covering all continents except Antarctica.",
                "position": 1522
            }
        ]
    },
    {
        "header": "Appendix DAgent Implementation Details",
        "images": []
    },
    {
        "header": "Appendix EQualitative Examples",
        "images": []
    }
]