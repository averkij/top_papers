[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11701/figs/git.png",
                "caption": "",
                "position": 93
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/HF.png",
                "caption": "",
                "position": 93
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11701/figs/overview.png",
                "caption": "Figure 1:An overview of our research on agentic RL.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Problem Formulation",
        "images": []
    },
    {
        "header": "3Data in Agentic Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11701/figs/diversity.png",
                "caption": "Figure 2:Comparison between our dataset with higher diversity and the ReTool dataset, which only contains math problems.Leftis the average@32 accuracy on AIME2025 during training based on two different dataset.Rightis the policy entropy during the training process.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/model_aware.png",
                "caption": "Figure 3:The comparison and analysis between the impact of the 30k full dataset and our tailored dataset for Qwen2.5-RA-SFT on subsequent RL training.Leftis the average@32 performance on AIME2025.Rightis the analysis for the average reward during training.",
                "position": 504
            }
        ]
    },
    {
        "header": "4Algorithmic Design and Training Dynamics in Agentic RL",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11701/figs/aime_accuracy_comparison_4x3.png",
                "caption": "Figure 4:The overall performance of our constructed three recipes:GRPO-T,GRPO-TCR, andGRPO-SCRon AIME2024/AIME2025 benchmark.",
                "position": 517
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/fig4_entropy.png",
                "caption": "Figure 5:The analysis for the policy entropy in agentic RL training.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/clip_ratio_comparison.png",
                "caption": "Figure 6:The analysis of clipping strategy on AIME2025 benchmark.Leftis the analysis for Qwen2.5-7B models.Rightis the analysis for Qwen3-4B models.",
                "position": 596
            }
        ]
    },
    {
        "header": "5Reasoning Modes in Agentic RL",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11701/figs/tool_usage_analysis.png",
                "caption": "Figure 7:Analysis of the average number of tool calls and average response length per round in Agentic RL.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2510.11701/x1.png",
                "caption": "Figure 8:Tool-use efficiency comparison across different models.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/training_dynamics_dual_axis.png",
                "caption": "Figure 9:The training dynamics of current Long-CoT with Agentic RL.",
                "position": 674
            },
            {
                "img": "https://arxiv.org/html/2510.11701/figs/thinking_vs_base_comparison.png",
                "caption": "Figure 10:Comparison between the instruction-based models and Long-CoT reasoning models.Leftis the average@32 performance on AIME2025.Rightis the average response length during training.",
                "position": 705
            }
        ]
    },
    {
        "header": "6Contributions and Comparison on Challenging Benchmarks",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Discussion and Future Work",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperiment Setup",
        "images": []
    },
    {
        "header": "Appendix BPrompt Template",
        "images": []
    }
]