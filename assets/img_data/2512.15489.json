[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Nemotron-Math Overview",
        "images": []
    },
    {
        "header": "3Experiments Setup",
        "images": []
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15489/x1.png",
                "caption": "Figure 1:Scaling with model size and architecture onNemotron-Math.\nEach panel reportspass@1as a function of training progress (evaluated every half epoch),\ncomparingQwen3-8BandQwen3-30B-A3Bunder the high reasoning mode.\nThe left panel shows results on Comp-Math-24-25 and the right panel shows results on HLE-Math.\nWithin each panel, both without Python TIR and with Python TIR settings are plotted.",
                "position": 637
            },
            {
                "img": "https://arxiv.org/html/2512.15489/x2.png",
                "caption": "",
                "position": 647
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix ATraining Configuration By Bucket Length",
        "images": []
    },
    {
        "header": "Appendix BFurther Evidence via NVIDIA-Nemotron-3-Nano-30B-A3B-BF16 Evaluation",
        "images": []
    },
    {
        "header": "Appendix CLearning Rate Grid Search",
        "images": []
    },
    {
        "header": "Appendix DAnswer Judgment Prompt",
        "images": []
    }
]