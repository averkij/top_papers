[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13592/x1.png",
                "caption": "Figure 1:Overview of ourDiffusion Previewframework for efficient image generation using diffusion models.\nGiven a text prompt and a noise map, we first perform faster diffusion sampling to quickly generate a preview image. The user then decides whether the result is satisfactory. If not, they may refine the prompt or change the random seed. Once satisfied, full-step diffusion sampling is applied to generate the final high-quality image. This iterative workflow improves sampling efficiency and reduces unnecessary computational cost.",
                "position": 143
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related works",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13592/x2.png",
                "caption": "Figure 2:Overview of our RL framework for optimizing a learnable ODE solver in diffusion sampling. Given a prompt and a noise map, the diffusion modelÏµÏ•\\boldsymbol{\\epsilon}_{\\boldsymbol{\\phi}}predicts denoising directions conditioned on the prompt. A learnable ODE solverğš¿ğœ½\\mathbf{\\Psi}_{\\boldsymbol{\\theta}}generates a preview imageğ±p\\mathbf{x}_{\\text{p}}via few-step sampling, while a training-free solverğš¿\\mathbf{\\Psi}produces a target imageğ±gt\\mathbf{x}_{\\text{gt}}using full-step sampling. The similarity rewardâ„›\\mathcal{R}based on depth maps, segmentation masks, DINO featuresetc. guides the update ofğœ½\\boldsymbol{\\theta}via Proximal Policy Optimization (PPO).",
                "position": 208
            }
        ]
    },
    {
        "header": "3Preliminaries on ODE solvers",
        "images": []
    },
    {
        "header": "4ConsistencySolver",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13592/x3.png",
                "caption": "Figure 3:Visual comparison on Stable Diffusion for text-to-image generation.",
                "position": 1151
            },
            {
                "img": "https://arxiv.org/html/2512.13592/x4.png",
                "caption": "Figure 4:Visual comparison on FLUX.1-Kontext for instructional image editing. Previews are generated with 5 inference steps.",
                "position": 1154
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13592/x5.png",
                "caption": "Figure 5:Workflow of the generalized learnable ODE solverğš¿ğœ½\\mathbf{\\Psi}_{\\boldsymbol{\\theta}}with Order 4Â (m=4m=4). At each sampling step, the diffusion model predicts noiseÏµi\\epsilon_{i}conditioned on the input prompt and timestep. A learnable neural networkğ’‡Î¸\\boldsymbol{f}_{\\theta}generates adaptive coefficientswj{w}_{j},j=1,2,3,4j=1,2,3,4from current timesteptit_{i}, and target timestepti+1t_{i+1}, which are used to form a multi-step noise estimateÏµâ€²=âˆ‘j=14wjâ‹…Ïµi+1âˆ’j\\boldsymbol{\\epsilon}^{\\prime}=\\sum_{j=1}^{4}w_{j}\\cdot\\boldsymbol{\\epsilon}_{i+1-j}. The ODE solverğš¿ğœ½\\mathbf{\\Psi}_{\\boldsymbol{\\theta}}then updates the sample fromğ±ti\\mathbf{x}_{t_{i}}toğ±ti+1\\mathbf{x}_{t_{i+1}}. This approach enables more accurate and stable integration in the generative sampling process.",
                "position": 1701
            }
        ]
    },
    {
        "header": "Appendix ACommon Diffusion ODE Solvers via Taylor Expansion",
        "images": []
    },
    {
        "header": "Appendix BCommon diffusion ODE solvers interpreted using ConsistencySolver",
        "images": []
    },
    {
        "header": "Appendix CVisualization of ConsistencySolver",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    }
]