[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14755/x1.png",
                "caption": "Figure 1:Comparison between inefficient reasoning model and efficient model. The former tends to make a verbose self-check process after having derived the correct answer corresponding to the given question, resulting in the inefficient reasoning. The model trained withLC-R1get more efficient reasoning process to get correct answer, without any invalid thinking process.",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2506.14755/x2.png",
                "caption": "Figure 2:Pareto analysis of the Efficacy-Efficiency trade-off of different methods on two reasoning models. The x-axis represents the reasoning length change, and the y-axis shows the accuracy change, relative to the original model (defined in Eq.12), with the top-left corner representing the ideal position. A smaller and darker marker indicates a higher Valid Thinking (VT) rate (defined in Eq.1), signifying a more efficient thinking process. Compared to other methods also on the pareto frontier,LC-R1achieves a more favorable trade-off, attaining a substantially higher compression rate at the cost of a minimal drop in accuracy, and it also achieves a higher VT rate. The sub-optimal performance of our ablation variants (w/o C-reward, w/o L-reward) further proves the criticality of our dual-reward designs.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Preliminary: Compression and Efficienct Reasoning Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14755/x3.png",
                "caption": "Figure 3:An overview of theLC-R1training three-stage pipeline.(1)Valid Segment Extraction:First, an extractor model processes the original reasoning traces to identify the valid thinking portion and generate compressed sequences.(2)Reward Calculation:Next, these compressed sequences are used to compute our dual rewards—Length Reward and Compress Reward, with the latter applied exclusively as a bonus or penalty on the final</think>token. These are then combined to calculate the final advantages.(3)Policy Optimization:Finally, the GRPO loss is calculated using the compressed sequences and corresponding advantages, steering the model toward more concise and efficient reasoning.",
                "position": 422
            }
        ]
    },
    {
        "header": "3LC-R1: Length Compression with Efficient Reasoning Principles",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14755/x4.png",
                "caption": "Figure 4:The impact ofLC-R1compression method on the AIME25 benchmark.Left:The Pass@k scores show thatLC-R1models maintain competitive performance compared to the originals, preserving the model’s potential.Right:Per-problem analysis on Deepseek-R1-Distill-Qwen-7B reveals thatLC-R1achieves similar Pass@1 accuracy while maintaining a consistent token compression ratio across problems of varying difficulty, demonstrating a universal compression effect.",
                "position": 2775
            }
        ]
    },
    {
        "header": "5Compression Impact Analysis",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BDetails of LC-Extractor",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14755/x5.png",
                "caption": "Figure 5:Our prompt for extraction of answer prefix.",
                "position": 3406
            },
            {
                "img": "https://arxiv.org/html/2506.14755/extracted/6548382/Figures/dabiao.png",
                "caption": "Figure 6:The annotation tool to evaluate the LC-Extratcor.",
                "position": 3409
            }
        ]
    },
    {
        "header": "Appendix CDetailed Experiment Setups",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14755/x6.png",
                "caption": "Figure 7:Case study of the comparison ofLC-R1and O1-Pruner.",
                "position": 3626
            },
            {
                "img": "https://arxiv.org/html/2506.14755/x7.png",
                "caption": "Figure 8:Case study of the comparison ofLC-R1and the original model.",
                "position": 3629
            }
        ]
    },
    {
        "header": "Appendix DCase Study",
        "images": []
    }
]