[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10274/x1.png",
                "caption": "Figure 1:Overview of our empirical study, covering three domains: speech, music, and general audio, with four evaluation components: Downstream Evaluation (Section3.2) using the DASB benchmark, Reconstructed Audio Evaluation (Section3.1) using Codec-SUPERB and Versa, Acoustic LLM Evaluation (Section3.3) using SALMon and the Zero-Resource benchmark, Tokenizer Training Ablation Study (Section4) using ESPnet-Codec.",
                "position": 254
            }
        ]
    },
    {
        "header": "2Literature Review and Proposed Taxonomy",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10274/x2.png",
                "caption": "Figure 2:Overall architecture of a standard audio tokenizer. The input signalxùë•xitalic_xis encoded into a latent representationztsubscriptùëßùë°z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, which is then discretized by a quantizerQ‚Å¢(‚ãÖ)ùëÑ‚ãÖQ(\\cdot)italic_Q ( ‚ãÖ ). The decoder reconstructs the signalx^^ùë•\\hat{x}over^ start_ARG italic_x end_ARGfrom the quantized representationsz^tsubscript^ùëßùë°\\hat{z}_{t}over^ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. Training typically involves a combination of reconstruction (‚ÑíReconsubscript‚ÑíRecon\\mathcal{L}_{\\text{Recon}}caligraphic_L start_POSTSUBSCRIPT Recon end_POSTSUBSCRIPT), adversarial (‚ÑíGANsubscript‚ÑíGAN\\mathcal{L}_{\\text{GAN}}caligraphic_L start_POSTSUBSCRIPT GAN end_POSTSUBSCRIPT,‚ÑíFeatssubscript‚ÑíFeats\\mathcal{L}_{\\text{Feats}}caligraphic_L start_POSTSUBSCRIPT Feats end_POSTSUBSCRIPT),\nand vector quantization losses (‚ÑíV‚Å¢Qsubscript‚ÑíùëâùëÑ\\mathcal{L}_{VQ}caligraphic_L start_POSTSUBSCRIPT italic_V italic_Q end_POSTSUBSCRIPT).",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2506.10274/x3.png",
                "caption": "Figure 3:Taxonomy of audio tokenizers based on: encoder-decoder architecture (Section2.3), quantization method (Section2.2), training paradigm (Section2.4), and target domain and streamability (Section2.5). CNN denotes Convolutional networks, T represents Transformer models, and RNN refers to any recurrent neural network including LSTM and GRU. RVQ stands for Residual Vector Quantization, GVQ for Group Vector Quantization, SVQ for Single Vector Quantization, MSRVQ stands for Multi-Scale Residual Vector Quantization, CSRVQ stands for Cross-Scale Residual Vector Quantization, PQ stands for Product Quantization, FSQ for Finite Scalar Quantization. K-Means signifies that the tokenizer is trained independently of the encoder and the decoder pipeline. Objectives include adversarial learning (GAN), diffusion-based generation (Diff), and masked prediction (MP) as a generative training strategy, feature matching loss (Feats), and reconstruction loss (Recon).\nThe interactive version of this figure can be accessed throughhttps://dates-tokens.github.io/taxonomy_interactive.html",
                "position": 333
            }
        ]
    },
    {
        "header": "3Benchmark Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10274/x4.png",
                "caption": "(a)Speech Ranking",
                "position": 4006
            },
            {
                "img": "https://arxiv.org/html/2506.10274/x4.png",
                "caption": "",
                "position": 4009
            },
            {
                "img": "https://arxiv.org/html/2506.10274/x5.png",
                "caption": "(a)Speech Ranking",
                "position": 4011
            },
            {
                "img": "https://arxiv.org/html/2506.10274/x6.png",
                "caption": "(b)Audio Ranking",
                "position": 4015
            },
            {
                "img": "https://arxiv.org/html/2506.10274/x7.png",
                "caption": "(c)Music Ranking",
                "position": 4018
            }
        ]
    },
    {
        "header": "4Ablation Studies",
        "images": []
    },
    {
        "header": "5Conclusion and Future Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]