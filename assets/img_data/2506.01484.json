[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01484/extracted/6503502/hf_icon.png",
                "caption": "",
                "position": 80
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01484/extracted/6503502/intro_figure_2.png",
                "caption": "Figure 1:An example of a hate speech input and its detoxified version generated by an LLM. Our evaluation indicates that LLMs perform comparably to human annotators in the task of hate speech detoxification.",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2506.01484/x1.png",
                "caption": "Figure 2:Pipeline for constructingParadehate. We begin by collecting hate speech texts from widely used datasets. An LLM acts as the annotator, performing three tasks: rephrasing hate speech, verifying content preservation, and evaluating toxicity. Texts that pass all three checks are considered detoxified and are included in the resulting parallel dataset.",
                "position": 111
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3LLM in the Loop vs Human in the Loop",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01484/x2.png",
                "caption": "Figure 3:Prompt for Task 1: Generation of Paraphrases.",
                "position": 204
            },
            {
                "img": "https://arxiv.org/html/2506.01484/x3.png",
                "caption": "Figure 4:Prompt for Task 2: Content Preservation Check.",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2506.01484/x4.png",
                "caption": "Figure 5:Prompt for Task 3: Toxicity Check.",
                "position": 233
            }
        ]
    },
    {
        "header": "4Dataset Creation",
        "images": []
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AHyperparameters for GPT-4o-mini",
        "images": []
    },
    {
        "header": "Appendix BHyperparameters for BART Fine-Tuning",
        "images": []
    },
    {
        "header": "Appendix CPrompt for Task 1 to Mitigate False Refusal Behaviour",
        "images": []
    },
    {
        "header": "Appendix DCost of CreatingParadehate",
        "images": []
    },
    {
        "header": "Appendix EExamples",
        "images": []
    }
]