[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06036/x1.png",
                "caption": "Figure 1:Speedup comparison between DFlash, EAGLE-3 against Autoregressive Decoding on Qwen3-8B(Yanget al.,2025)with the Transformers backend. Overall, DFlash achieves more than 2.5× higher speedup than EAGLE-3.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06036/x2.png",
                "caption": "Figure 2:DFlash Inference Design.Hidden context features extracted from the target model are fused and injected into each draft layer’s Key-Value cache to enable conditional speculation.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2602.06036/x3.png",
                "caption": "Figure 3:Draft cost of 1, 3, 5-layer DFlash and 1-layer EAGLE-3.",
                "position": 227
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06036/x4.png",
                "caption": "Figure 4:DFlash training attention.The target model provides context features (blue) that condition the draft model. The input consists of clean prompt tokensppand clean response tokensrr. Within each masked block, a subset of clean response tokens (yellow) is randomly sampled as anchors, while mask tokensmm(green) mark positions for parallel prediction. Invisible tokens (white) denote the attention mask, which enforces causal consistency and prevents inter-block information leakage during training.",
                "position": 269
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06036/x5.png",
                "caption": "Figure 5:The loss decay makes training converge faster and better.",
                "position": 2059
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]