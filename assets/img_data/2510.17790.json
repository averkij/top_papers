[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17790/x1.png",
                "caption": "(a)OSWorld and WindowsAgentArena",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x1.png",
                "caption": "(a)OSWorld and WindowsAgentArena",
                "position": 112
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x2.png",
                "caption": "(b)Existing Agents v.s. UltraCUA",
                "position": 117
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17790/x3.png",
                "caption": "Figure 2:An overview of UltraCUAâ€™s design. The agent adaptively switches between visual grounding and programmatic tool call, establishing the hybrid action mechanism.",
                "position": 172
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17790/x4.png",
                "caption": "(a)Outcome Reward",
                "position": 915
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x4.png",
                "caption": "(a)Outcome Reward",
                "position": 918
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x5.png",
                "caption": "(b)Format Reward",
                "position": 923
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x6.png",
                "caption": "(c)Tool-call Pattern",
                "position": 928
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x7.png",
                "caption": "Figure 4:Tool-call patterns across domains and models. Stronger models exhibit higher frequency and diversity.",
                "position": 982
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17790/x8.png",
                "caption": "Figure 5:An example of UltraCUA-32B helping processing emails. The agent alternates between low-level actions and programmatic tool calls smartly, leading to efficient completion of the task.",
                "position": 1949
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x9.png",
                "caption": "Figure 6:An example of UltraCUA-32B helping clear certain Chrome history with hybrid action. The agent calls prothe grammatic tool at the first step to assist in going into the desired page directly.",
                "position": 1952
            },
            {
                "img": "https://arxiv.org/html/2510.17790/x10.png",
                "caption": "Figure 7:An example of UltraCUA-32B helping processing images with hybrid action. The model starts coding at the very first step by calling the terminal tool, and finally writes a bash script and executes it to make the task successful.",
                "position": 1955
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]