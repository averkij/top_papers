[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05169/x1.png",
                "caption": "Figure 1:Familiar example of reasoning by simulation ‚Äì an individual (possibly self-serving) decides to offer help to a crying person by mentally simulating multiple possible outcomes, with the best expected reward in mind.",
                "position": 167
            }
        ]
    },
    {
        "header": "2World Model and Agent Decision-Making",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05169/x2.png",
                "caption": "Figure 2:A possible definition of an optimal agent",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x3.png",
                "caption": "Figure 3:An agent in real world where groundtruth world state and universe are unavailable to experience or experiment, so world model is crucial for simulation.",
                "position": 353
            }
        ]
    },
    {
        "header": "3The World Model Landscape",
        "images": []
    },
    {
        "header": "4Critiques of World Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05169/x4.png",
                "caption": "Figure 4:Framework for world model proposed by a vocal school of thought.",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x5.png",
                "caption": "Figure 5:Vocabulary-based tokens is an effective way to categorize perceptual inputs into discrete concepts for reasoning (left). We may scale up or scale out discrete code to deal with increasing data complexity (right). Thm.1shows either is effective, but scaling out is more efficient.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x6.png",
                "caption": "Figure 6:Comparison of the critiqued JEPA world model architecture (left) and our proposed Generative Latent Prediction (GLP) architecture (right), which includes a diffusion-based next-embedding predictor for modeling continuous perceptual dynamics and an enhanced LLM backbone for discrete long-horizon structures.",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x7.png",
                "caption": "Figure 7:Comparison of the critiqued world model objective based on reconstruction in latent space (left) and our proposed alternative of generative data reconstruction objectives (right).",
                "position": 723
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x8.png",
                "caption": "Figure 8:As Thm.2shows, the JEPAlatentreconstruction loss (‚Ñílatentsubscript‚Ñílatent\\mathcal{L}_{\\text{latent}}caligraphic_L start_POSTSUBSCRIPT latent end_POSTSUBSCRIPT) is upper bounded by the generativedatareconstruction loss (‚Ñígensubscript‚Ñígen\\mathcal{L}_{\\text{gen}}caligraphic_L start_POSTSUBSCRIPT gen end_POSTSUBSCRIPT) plus a small encoder-decoder reconstruction error (œµitalic-œµ\\epsilonitalic_œµ).œµitalic-œµ\\epsilonitalic_œµis small in practice, meaning‚Ñílatent‚â§‚Ñígensubscript‚Ñílatentsubscript‚Ñígen\\mathcal{L}_{\\text{latent}}\\leq\\mathcal{L}_{\\text{gen}}caligraphic_L start_POSTSUBSCRIPT latent end_POSTSUBSCRIPT ‚â§ caligraphic_L start_POSTSUBSCRIPT gen end_POSTSUBSCRIPTusually holds. Minimizing‚Ñílatentsubscript‚Ñílatent\\mathcal{L}_{\\text{latent}}caligraphic_L start_POSTSUBSCRIPT latent end_POSTSUBSCRIPT, therefore, does not guarantee consistency with observed data, which is required for minimizing‚Ñígensubscript‚Ñígen\\mathcal{L}_{\\text{gen}}caligraphic_L start_POSTSUBSCRIPT gen end_POSTSUBSCRIPT.",
                "position": 881
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x9.png",
                "caption": "Figure 9:Comparison of the critiqued approach to using world model (left) vs. our proposed alternative (right).",
                "position": 919
            }
        ]
    },
    {
        "header": "5The PAN World Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.05169/x10.png",
                "caption": "Figure 10:Illustration of the architecture of PAN-World, our proposed framework for general-purpose world modeling. At each time point, PAN-World estimates the world states^^ùë†\\hat{s}over^ start_ARG italic_s end_ARGbased on the current sensory observationoùëúoitalic_o, predicts the future world statess^‚Ä≤superscript^ùë†‚Ä≤\\hat{s}^{\\prime}over^ start_ARG italic_s end_ARG start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPTbased on proposed actionsaùëéaitalic_afor agentic reasoning, and reconstructs the future observationso^‚Ä≤superscript^ùëú‚Ä≤\\hat{o}^{\\prime}over^ start_ARG italic_o end_ARG start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPTfor generative supervision and external usage.",
                "position": 987
            },
            {
                "img": "https://arxiv.org/html/2507.05169/x11.png",
                "caption": "Figure 11:Illustration of our proposed simulative reasoning agent powered by the PAN World Model. Unlike traditional RL agents that rely on reactive policies, or model-precitive control (MPC) agents that expensively simulates futures at decision time, this agent leverages a cache of precomputed simulations generated by the PAN WM. During decision-making, the agent selects actions based on its current beliefs and expected outcomes, enabling a more efficient, flexible, and intentional form of planning, which, as we argue, is closer to the flexibility of human reasoning.",
                "position": 1117
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof for Theorem1",
        "images": []
    },
    {
        "header": "Appendix BProof for Proposition1",
        "images": []
    },
    {
        "header": "Appendix CProof for Proposition2",
        "images": []
    },
    {
        "header": "Appendix DProof of Theorem2",
        "images": []
    }
]