[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/VFM_vs_VLM.png",
                "caption": "Figure 1:Comparative analysis of the VFM and the VLM features. VFM: Visualization of PCA-computed features from DINOv2 (the first three components of PCA, computed on the image features, serve as color channels), displaying fine-grained details but lacking text alignment. VLM: Image-text similarity map from EVA02-CLIP using the query ‘car’, demonstrating good alignment with text but insufficient localization of queried objects. MFuser: Our proposed fusion framework integrates VFM and VLM, resulting in unified features that exhibit both precise locality and robust text alignment. Quantitative results on synthetic-to-real DGSS benchmarks further validate our approach, with MFuser consistently achieving the highest mIoU scores across all tasks.",
                "position": 108
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/main_fig.png",
                "caption": "Figure 2:Overall architecture of MFuser. MFuser takes inputs through both VFM and VLM visual encoders. Features from each encoder layer are concatenated and refined in MVFuser, which captures sequential and spatial dependencies in parallel. The refined features are then added back to the original features and passed to the next layer. MTEnhancer strengthens text embeddings of each class by integrating visual features through a hybrid attention-Mamba mechanism. The enhanced text embeddings serve as object queries for the Mask2Former decoder, alongside multi-scale visual features. During training, only MVFusers, MTEnhancers, and the segmentation decoder are trainable while the VFM and VLM remain frozen, preserving their generalization ability and enabling efficient training. Note that skip connections between each block of MTEnhancer are omitted for clarity.",
                "position": 187
            }
        ]
    },
    {
        "header": "4Proposed Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/qualitative.png",
                "caption": "Figure 3:Qualitative results on unseen target domains under the G→→\\rightarrow→{C, B, M} setting. MFuser is compared with Rein[55]and tqdm[40].",
                "position": 696
            },
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/fea_PCA.png",
                "caption": "Figure 4:PCA visualization of features from DINOv2 and EVA02-CLIP, illustrating how MVFuser-based adaptation refines their distributions before and after tuning.",
                "position": 967
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "7Evaluate on Additional VFMs",
        "images": []
    },
    {
        "header": "8Evaluate on SYNTHIA Benchmarks",
        "images": []
    },
    {
        "header": "9Evaluate on ACDC Benchmarks",
        "images": []
    },
    {
        "header": "10Ablation on the Number of MVFusers",
        "images": []
    },
    {
        "header": "11More Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/sup_vis_g2m.png",
                "caption": "Figure 5:Qualitative results on unseen target domains under the G→→\\rightarrow→M setting. MFuser is compared with Rein[55]and tqdm[40].",
                "position": 1485
            },
            {
                "img": "https://arxiv.org/html/2504.03193/extracted/6335383/figures/sup_vis_g2b.png",
                "caption": "Figure 6:Qualitative results on unseen target domains under the G→→\\rightarrow→B setting. MFuser is compared with Rein[55]and tqdm[40].",
                "position": 1602
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]