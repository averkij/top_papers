[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x1.png",
                "caption": "(a)Equivalent Language CoTs for a question",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x1.png",
                "caption": "(a)Equivalent Language CoTs for a question",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x2.png",
                "caption": "(b)Existing Imitation-based Latent Reasoning methods",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x3.png",
                "caption": "(c)Active Planning for better latent reasoning policies (Ours)",
                "position": 150
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x4.png",
                "caption": "(a)SFT stage of ATP-Latent",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x4.png",
                "caption": "(a)SFT stage of ATP-Latent",
                "position": 253
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x5.png",
                "caption": "(b)RL stage of ATP-Latent",
                "position": 258
            }
        ]
    },
    {
        "header": "3Studies on Exploring Latent CoTs",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x6.png",
                "caption": "Figure 3:GRPO validation curve over Coconut and SIM-CoT and noises in different scales.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x7.png",
                "caption": "Figure 4:GRPO validation curve of SIM-CoT finetuned after Coconut training.",
                "position": 319
            }
        ]
    },
    {
        "header": "4Method: Active Latent Planning",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x8.png",
                "caption": "(a)RL stage of ATP-Latent",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x8.png",
                "caption": "(a)RL stage of ATP-Latent",
                "position": 758
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x9.png",
                "caption": "(b)SFT stage of ATP-Latent",
                "position": 763
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x10.png",
                "caption": "(c)Correctness vs Coherence Reward",
                "position": 768
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": []
    },
    {
        "header": "6Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x11.png",
                "caption": "Figure 6:Examples of interpretability of latent tokens and improvements after RL. The accuracy and coherence can be improved.",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x12.png",
                "caption": "Figure 7:Pass@K curve for ATP-Latent and baselines. We run methods 64 times with Gaussian noise and different variances for Pass@K. The variances in ATP-Latent are predicted by itself.",
                "position": 856
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BPrompt for ATP-Latent",
        "images": []
    },
    {
        "header": "Appendix CDetailed parameters",
        "images": []
    },
    {
        "header": "Appendix DSupplementary Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21598/x13.png",
                "caption": "Figure 8:Pattern change after the RL training of ATP-Latent. The upper is for ATP-Latent-SFT, and the lower shows the pattern of ATP-Latent. We run each instance 64 times, decode each latent token to language steps by decoder, and count the probability of going into the top-1 branch or the branches with lower probabilities. Numbers in branches represent the probability of going into that branch. We do not show the branches with probability<1%<1\\%and the branches stopped by the stop head, so the summation of probabilities may not be 100%.",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2601.21598/x14.png",
                "caption": "",
                "position": 2148
            }
        ]
    },
    {
        "header": "Appendix EBaselines & Datasets & Licenses",
        "images": []
    }
]