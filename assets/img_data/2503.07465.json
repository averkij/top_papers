[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/extracted/6267888/figures/logo.png",
                "caption": "",
                "position": 63
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/x1.png",
                "caption": "Figure 1:Comparison of performance, training cost, and inference efficiency between YOLOE (Ours) and advanced YOLO-Worldv2 in terms of open text prompts. LVIS AP is evaluated onminivalset and FPS w/ TensorRT and w/ CoreML is measured on T4 GPU and iPhone 12, respectively. The results highlight our superiority.",
                "position": 71
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/x2.png",
                "caption": "Figure 2:The overview of YOLOE, which supports detection and segmentation for diverse open prompt mechanisms. For text prompts, We design a re-parameterizable region-text alignment strategy to improve performance with zero inference and transferring overhead. For visual prompts, SAVPE is employed to encode visual cues with enhanced prompt embedding under minimal cost. For prompt-free setting, we introduce lazy region-prompt contrast strategy to provide category names for all identified objects efficiently by retrieval.",
                "position": 93
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/x3.png",
                "caption": "Figure 3:(a) The structure of lightweight auxiliary network in RepRTA, which consists of one SwiGLU FFN block[53]. (b) The structure of SAVPE, which consists of semantic branch to generate prompt-agnostic semantic features and activation branch to provide grouped prompt-aware weights. Visual prompt embedding can thus be efficiently derived by their aggregation.",
                "position": 165
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/x4.png",
                "caption": "Figure 4:(a) Zero-shot inference on LVIS. (b) Results with customized text prompt, where “white hat, red hat, white car, sunglasses, mustache, tie” are provided as text prompts. (c) Results with visual prompt, where the red dashed bounding box serves as the visual cues. (d) Results in prompt-free scenario, where no explicit prompt is provided. Please refer to the supplementary for more examples.",
                "position": 1146
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BMore Analyses for LRPC",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07465/x5.png",
                "caption": "Figure 5:The count of retained anchor points under different filtering thresholds in LRPC. The dashed line means the total number.",
                "position": 2419
            },
            {
                "img": "https://arxiv.org/html/2503.07465/x6.png",
                "caption": "Figure 6:Zero-Shot inference on LVIS. The categories of LVIS are provided as text prompts.",
                "position": 2435
            },
            {
                "img": "https://arxiv.org/html/2503.07465/x7.png",
                "caption": "Figure 7:Prompt with customized texts. YOLOE adapts to both generic and specific text prompts for flexible usage.",
                "position": 2438
            },
            {
                "img": "https://arxiv.org/html/2503.07465/x8.png",
                "caption": "Figure 8:Prompt with visual inputs. YOLOE demonstrates the ability to identify objects guided by various visual prompts, like bounding box (top left), point (top right), handcrafted shape (bottom left). The visual prompt can also be applied across images (bottom right).",
                "position": 2441
            },
            {
                "img": "https://arxiv.org/html/2503.07465/x9.png",
                "caption": "Figure 9:Prompt-free inference (omitting segmentation masks for clearer visualization). YOLOE can find diverse objects without prompt.",
                "position": 2444
            }
        ]
    },
    {
        "header": "Appendix CMore Visualization Results",
        "images": []
    }
]