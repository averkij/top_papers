[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15952/x1.png",
                "caption": "Figure 1:Sample tasks fromVideoGameQA-Bench.\n(a) \nAunit testwhere the model should verify small details in the image, such as the character’s posture and the eye lenses.\n(b) \nAvisual regression testwhere the model should detect unacceptable changes between two versions of the same scene.\n(c) \nAUI unit testin which the model must visually verify user interface components, such as a chemistry graph between players.\n(d) \nAbug report generation taskwhere the model needs to generate a bug report for a glitch.\n(e) \nTwoglitch detectiontasks, where the model must identify visual anomalies, such as unnatural body configuration (left) or object clipping (right, fingers clipping the apple).\n(f) \nTwoglitch detectiontasks, where the model is required to verify the glitch-free status of images with intentional object clipping and high scene complexity.\n(g) \nAparametric testthat evaluates whether the model can detect clipping at various object proximities.\n(h) \nAneedle-in-a-haystack task, which requires the model to identify the first frame in which a glitch occurs.",
                "position": 126
            }
        ]
    },
    {
        "header": "2VideoGameQA-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/logos/gamephysics-logo_transparent.png",
                "caption": "",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/logos/YouTube_Logo_2017.png",
                "caption": "",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/logos/Unity-logo.png",
                "caption": "",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/logos/steam-logo-symbol-300x300.png",
                "caption": "Table 1:Overview of tasks, their data sources, and expected format/contents of the responses to the questions inVideoGameQA-Bench. All responses must be formatted in JSON.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x2.png",
                "caption": "",
                "position": 356
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/logos/team.png",
                "caption": "",
                "position": 358
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15952/x3.png",
                "caption": "Figure 2:Samples from challenging cases that most VLMs consistently struggle with.\n(a) Failure to understandspatial reasoning, such as object orientation (whether an airplane is facing toward the camera or away).\n(b) Failure to readUIs with complex layoutsandobjects arranged in grids.\n(c) Failure to detectcommon-sense inconsistencies, such as a missing gun in the hand.\n(d) Failure to detectunnatural body configurations.\n(e) Failure to detectmissing foreground objects(candles).\n(f) Failure to detect and analyzeobject movementsuch as shaking or bouncing.",
                "position": 910
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Discussion, Limitations, and Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInference Providers",
        "images": []
    },
    {
        "header": "Appendix BQuestion Generation Prompts",
        "images": []
    },
    {
        "header": "Appendix CModel Inference Prompts",
        "images": []
    },
    {
        "header": "Appendix DLLM-as-a-Judge",
        "images": []
    },
    {
        "header": "Appendix EAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/1.jpg",
                "caption": "(a)",
                "position": 2370
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/1.jpg",
                "caption": "(a)",
                "position": 2373
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/3.jpg",
                "caption": "(b)",
                "position": 2378
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/4.jpg",
                "caption": "(c)",
                "position": 2384
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/5.jpg",
                "caption": "(d)",
                "position": 2389
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/6.jpg",
                "caption": "(e)",
                "position": 2395
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/failures/7.jpg",
                "caption": "(f)",
                "position": 2400
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/0.jpg",
                "caption": "(a)",
                "position": 2414
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/0.jpg",
                "caption": "(a)",
                "position": 2417
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/4.jpg",
                "caption": "(b)",
                "position": 2422
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/2.jpg",
                "caption": "(c)",
                "position": 2428
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/3.jpg",
                "caption": "(d)",
                "position": 2433
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/1.jpg",
                "caption": "(e)",
                "position": 2439
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/failures/5.jpg",
                "caption": "(f)",
                "position": 2444
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/success/gd_success_1.jpg",
                "caption": "Figure A15:Sample successful glitch detections by various models that identified the floating vehicle.",
                "position": 3343
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/success/gd_success_2.jpg",
                "caption": "Figure A16:Sample successful glitch detections by various models that identified a clipping knife overlapping with a gun.",
                "position": 3390
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/Failure/gd_fail_1.jpg",
                "caption": "Figure A17:Sample image where models failed to detect a clipping glitch between two cars.",
                "position": 3437
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/Failure/gd_fail_2.jpg",
                "caption": "Figure A18:Sample image where various models incorrectly reported the presence of a glitch, although the image is glitch-free.",
                "position": 3484
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/success/gd_success_3.jpg",
                "caption": "Figure A19:Sample image where various models correctly reported the image as glitch-free.",
                "position": 3531
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/1.jpg",
                "caption": "Figure A20:Sample images from image-based glitch detection, where models reported the image as glitchy despite it being glitch-free (false positive).",
                "position": 3586
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/1.jpg",
                "caption": "",
                "position": 3610
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/2.jpg",
                "caption": "",
                "position": 3614
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/3.jpg",
                "caption": "",
                "position": 3619
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/4.jpg",
                "caption": "",
                "position": 3623
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/5.jpg",
                "caption": "",
                "position": 3628
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/11.jpg",
                "caption": "",
                "position": 3632
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/7.jpg",
                "caption": "",
                "position": 3637
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FP/8.jpg",
                "caption": "",
                "position": 3641
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/1.jpg",
                "caption": "Figure A21:Sample images from image-based glitch detection, where the majority of models failed to detect the glitch in the image (false negative).",
                "position": 3647
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/1.jpg",
                "caption": "",
                "position": 3675
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/2.jpg",
                "caption": "",
                "position": 3679
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/3.jpg",
                "caption": "",
                "position": 3684
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/4.jpg",
                "caption": "",
                "position": 3688
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/5.jpg",
                "caption": "",
                "position": 3693
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/6.jpg",
                "caption": "",
                "position": 3697
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/7.jpg",
                "caption": "",
                "position": 3702
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/8.jpg",
                "caption": "",
                "position": 3706
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/9.jpg",
                "caption": "",
                "position": 3711
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/FN/10.jpg",
                "caption": "",
                "position": 3715
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vgd/success/vgd_success_2.jpg",
                "caption": "Figure A22:Sample from a video-based glitch detection task in which various models correctly identified a glitch related to the character’s body.",
                "position": 3726
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vgd/success/vgd_success_1.jpg",
                "caption": "Figure A23:Sample from a video-based glitch detection task in which various models correctly identified a glitch related to a skateboard.",
                "position": 3752
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x4.png",
                "caption": "Figure A24:Heatmap for testing clipping between a white 3D cube and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4038
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube1/image_003_0000.jpg",
                "caption": "",
                "position": 4038
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube1/image_003_0036.jpg",
                "caption": "",
                "position": 4038
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube1/image_003_0099.jpg",
                "caption": "",
                "position": 4038
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x5.png",
                "caption": "Figure A25:Heatmap for testing clipping between a white 3D cube and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4041
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube2/image_004_0000.jpg",
                "caption": "",
                "position": 4041
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube2/image_004_0035.jpg",
                "caption": "",
                "position": 4041
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/cube2/image_004_0099.jpg",
                "caption": "",
                "position": 4041
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x6.png",
                "caption": "Figure A26:Heatmap for testing clipping between a white 3D sphere and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4044
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere1/image_002_0000.jpg",
                "caption": "",
                "position": 4044
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere1/image_002_0042.jpg",
                "caption": "",
                "position": 4044
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere1/image_002_0095.jpg",
                "caption": "",
                "position": 4044
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x7.png",
                "caption": "Figure A27:Heatmap for testing clipping between a white 3D sphere and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4047
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere2/image_001_0000.jpg",
                "caption": "",
                "position": 4047
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere2/image_001_0043.jpg",
                "caption": "",
                "position": 4047
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sphere2/image_001_0099.jpg",
                "caption": "",
                "position": 4047
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x8.png",
                "caption": "Figure A28:Heatmap for testing clipping between a white 2D plane (quad) and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4050
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quad/image_013_0000.jpg",
                "caption": "",
                "position": 4050
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quad/image_013_0055.jpg",
                "caption": "",
                "position": 4050
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quad/image_013_0099.jpg",
                "caption": "",
                "position": 4050
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x9.png",
                "caption": "Figure A29:Heatmap for testing clipping between a white 2D plane (quad) and a human character. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4053
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quadbehind/image_021_0000.jpg",
                "caption": "",
                "position": 4053
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quadbehind/image_021_0074.jpg",
                "caption": "",
                "position": 4053
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/quadbehind/image_021_0099.jpg",
                "caption": "",
                "position": 4053
            },
            {
                "img": "https://arxiv.org/html/2505.15952/x10.png",
                "caption": "Figure A30:Heatmap for testing clipping between two human characters. The dashed line on the heatmap indicates the frame where clipping occurs.",
                "position": 4056
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/human/image_018_0000.jpg",
                "caption": "",
                "position": 4056
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/human/image_018_0031.jpg",
                "caption": "",
                "position": 4056
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/human/image_018_0099.jpg",
                "caption": "",
                "position": 4056
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/sucess/21.jpg",
                "caption": "Figure A31:Sample successful test run by various models that successfully detected unacceptable changes between two images.",
                "position": 4064
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/sucess/22.jpg",
                "caption": "",
                "position": 4068
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/11.jpg",
                "caption": "Figure A32:Sample visual regression test that top-performing models likeGPT-4o,GPT-4.1,o4-mini, andGemini-2.5-Profail to answer correctly. The models pass the test when they should fail due to one of the wooden pillars of the roof being missing in the alternative image.",
                "position": 4107
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/12.jpg",
                "caption": "",
                "position": 4111
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/31.jpg",
                "caption": "Figure A33:Sample visual regression test that top-performing models likeGPT-4o,GPT-4.1,o4-mini, andGemini-2.5-Profail to answer correctly. The models pass the test when they should fail due to incorrect wall rendering on the right side of the image.",
                "position": 4150
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/32.jpg",
                "caption": "",
                "position": 4154
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/41.jpg",
                "caption": "Figure A34:Sample visual regression test that top-performing models likeGPT-4o,GPT-4.1,o4-mini, andGemini-2.5-Profail to answer correctly. The models pass the test when they should fail due to missing the table in the center of the image.",
                "position": 4193
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/42.jpg",
                "caption": "",
                "position": 4197
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/51.jpg",
                "caption": "Figure A35:Sample visual regression test that top-performing models likeGPT-4o,GPT-4.1, andGemini-2.5-Profail, buto4-minianswers correctly.",
                "position": 4236
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/o4-fails/52.jpg",
                "caption": "",
                "position": 4240
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/full_bug_report_3.jpg",
                "caption": "Figure A36:A sample model response for the image-based bug report generation task, along with the judge’s evaluation. The model provides an inaccurate description of the glitch, and the judge correctly rejects it.",
                "position": 4284
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/full_bug_report_4.jpg",
                "caption": "Figure A37:A sample model response for the image-based bug report generation task, along with the judge’s evaluation. The model provides an inaccurate description of the glitch, and the judge correctly rejects it.",
                "position": 4318
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/full_bug_report_2.jpg",
                "caption": "Figure A38:A sample model response for the image-based bug report generation task, along with the judge’s evaluation. The model provides a description that matches our ground truth, and the judge correctly accepts it.",
                "position": 4352
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/full_bug_report_1.jpg",
                "caption": "Figure A39:A sample model response for the image-based bug report generation task, along with the judge’s evaluation. The model provides a description that matches our ground truth, and the judge correctly accepts it.",
                "position": 4392
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/bad_judge_1.jpg",
                "caption": "Figure A40:Sample model response for the image-based bug report generation task along with the judge’s evaluation.\nWhile certain glitches are challenging to describe precisely, the model correctly identifies and highlights the relevant aspects and regions in the image. However, the judge strictly evaluates the wording, entirely rejecting the response despite the model correctly pinpointing the problematic regions.",
                "position": 4433
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/bad_judge_2.jpg",
                "caption": "Figure A41:Sample model response for the image-based bug report generation task along with the judge’s evaluation.\nWhile the model’s generated report is accurate, the judge incorrectly rejects it for being too strict about small details and wording that are correct but missing from the ground truth.",
                "position": 4470
            }
        ]
    },
    {
        "header": "Appendix FVideoGameQA-BenchSamples",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/viislbeeyes.jpg",
                "caption": "Figure A42:Sample test from a visual unit test, where the model is asked to summarize some visual properties into a JSON structure.",
                "position": 4516
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/unittest_bird.jpg",
                "caption": "Figure A43:Sample test from a visual unit test, where the model is asked to summarize some visual properties into a JSON structure.",
                "position": 4536
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/unittest/cardoor.jpg",
                "caption": "Figure A44:Sample test from a visual unit test, where the model is asked to summarize some visual properties into a JSON structure.",
                "position": 4577
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/dashboard.jpg",
                "caption": "Figure A45:Sample UI unit test, where the model is asked to extract and summarize visual information from game UI elements into a JSON structure.",
                "position": 4619
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/dicegrid.jpg",
                "caption": "Figure A46:Sample UI unit test, where the model is asked to extract and summarize visual information from game UI elements into a JSON structure.",
                "position": 4679
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/ui_ocr/inventory.jpg",
                "caption": "Figure A47:Sample UI unit test, where the model is asked to extract and summarize visual information from game UI elements into a JSON structure.",
                "position": 4686
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_1_1.jpg",
                "caption": "Figure A48:Sample test from a visual regression task, where the model is asked to compare two versions of the same scene to verify whether the changes are acceptable or unacceptable.",
                "position": 4702
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_1_2.jpg",
                "caption": "",
                "position": 4706
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_2_1.jpg",
                "caption": "Figure A49:Sample test from a visual regression task, where the model is asked to compare two versions of the same scene to verify whether the changes are acceptable or unacceptable.",
                "position": 4741
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_2_2.jpg",
                "caption": "",
                "position": 4745
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_3_1.jpg",
                "caption": "Figure A50:Sample test from a visual regression task, where the model is asked to compare two versions of the same scene to verify whether the changes are acceptable or unacceptable.",
                "position": 4780
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/vr/vr_3_2.jpg",
                "caption": "",
                "position": 4784
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/gd1.jpg",
                "caption": "Figure A51:Sample for the image-based glitch detection task.",
                "position": 4824
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/gd2.jpg",
                "caption": "Figure A52:Sample for the image-based glitch detection task.",
                "position": 4846
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/gd3.jpg",
                "caption": "Figure A53:Sample for the image-based glitch detection task.",
                "position": 4868
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sample_cube.jpg",
                "caption": "Figure A54:Sample test from a parametric clipping detection task, where the model is asked to detect clipping glitches when an object is placed at various distances from a human character, to verify whether the model can robustly detect such glitches.",
                "position": 4895
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/parametric/sample_human.jpg",
                "caption": "Figure A55:Sample test from a parametric clipping detection task, where the model is asked to detect clipping glitches when an object is placed at various distances from a human character, to verify whether the model can robustly detect such glitches.",
                "position": 4915
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/bgr_1.jpg",
                "caption": "Figure A56:Sample for the image-based bug report generation task.",
                "position": 4940
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/bgr_2.jpg",
                "caption": "Figure A57:Sample for the image-based bug report generation task.",
                "position": 4964
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/bgr_3.jpg",
                "caption": "Figure A58:Sample for the image-based bug report generation task.",
                "position": 4988
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/vgd1.jpg",
                "caption": "Figure A59:Sample for the video-based glitch detection task. In this video (only 6 sample frames are shown), a horse is moving up and down, which is a glitch.",
                "position": 5017
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/vgd2.jpg",
                "caption": "Figure A60:Sample for the video-based glitch detection task. In this video (only 6 frames are shown), the non-player character is performing an action, but the animation and table are misaligned.",
                "position": 5039
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/gd/vgd3.jpg",
                "caption": "Figure A61:Sample for the video-based glitch detection task. In this video (only 6 frames are shown), the objects in the water are shaking violently, which is caused by a glitch in the physics engine simulation.",
                "position": 5061
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/niah/dynamic_1.jpg",
                "caption": "Figure A62:Sample from the needle-in-a-haystack task. Please note that only 6 out of 50 frames are shown to highlight the glitch.",
                "position": 5088
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/niah/dynamic_2.jpg",
                "caption": "Figure A63:Sample from the needle-in-a-haystack task. Please note that only 6 out of 50 frames are shown to highlight the glitch.",
                "position": 5119
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/niah/static_1.jpg",
                "caption": "Figure A64:Sample from the needle-in-a-haystack task. Please note that only 6 out of 50 frames are shown to highlight the glitch.",
                "position": 5150
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/niah/static_2.jpg",
                "caption": "Figure A65:Sample from the needle-in-a-haystack task. Please note that only 6 out of 50 frames are shown to highlight the glitch.",
                "position": 5181
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/vbr_1.jpg",
                "caption": "Figure A66:Sample for the video-based bug report generation task. In this video (only 6 frames are shown), a helicopter emerges from the ground.",
                "position": 5217
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/vbr_2.jpg",
                "caption": "Figure A67:Sample for the video-based bug report generation task. In this video (only 6 frames are shown), a helicopter is stuck under the bridge.",
                "position": 5241
            },
            {
                "img": "https://arxiv.org/html/2505.15952/extracted/6464265/images/bugreport/vbr_3.jpg",
                "caption": "Figure A68:Sample for the video-based bug report generation task. In this video (only 6 frames are shown), a player character is stuck in a falling position, descending from the water into the air.",
                "position": 5265
            }
        ]
    },
    {
        "header": "Appendix GDataset License",
        "images": []
    }
]