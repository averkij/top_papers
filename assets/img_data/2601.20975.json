[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20975/00001.png",
                "caption": "Figure 1:DeepSearchQA benchmark overview. The benchmark features a balanced distribution of prompts across diverse topics (Left), preventing domain overfitting. When evaluated on this diverse set, the Gemini Deep Research agent demonstrates strong performance scaling (Right), with accuracy increasing monotonically as more test-time compute (samples) is applied.",
                "position": 276
            }
        ]
    },
    {
        "header": "2DeepSearchQA: Dataset and Taxonomy",
        "images": []
    },
    {
        "header": "3Evaluation Methodology",
        "images": []
    },
    {
        "header": "4Results and Analysis",
        "images": []
    },
    {
        "header": "5Future Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Contributions and Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AJudge Prompt Templates",
        "images": []
    }
]