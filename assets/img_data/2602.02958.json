[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02958/x1.png",
                "caption": "Figure 1:QVG makes long video generation extremely memory-efficient and maintains high video quality. On LongCat-Video and HY-WorldPlay, QVG reduces the memory footprint by up to7×7\\timesand achieves a PSNR of 28.7, much better than the baseline.",
                "position": 110
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02958/x2.png",
                "caption": "Figure 2:(a) Adopting full KV-cache can resolve the drifting problem but is very likely to be bottlenecked by memory. QVG can successfully generation high-quality long-videos. (b) Video diffusion models exhibit substantial spatiotemporal redundancy: tokens that are spatially or temporally adjacent have high cosine similarity, making compression feasible.",
                "position": 152
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02958/x3.png",
                "caption": "Figure 3:(a-c) Semantic-Aware Smoothing effectively smoothing the KV-cache distribution to make it more regular and quantization-friendly. We (1) group similar tokens together based on their semantic similarity and (2) subtract the centroid for each group to smooth the distribution. (d) The magnitude is significantly reduced and more concentrated around 0, making it much easier to be quantized.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2602.02958/x4.png",
                "caption": "Figure 4:Overview of QVG framework. (a) Original tensor’s distribution is irregular and hard to quantize. (b) Semantic-Aware Smoothing groups similar tokens and subtracts centroids for each group to make the residual quantization friendly. (c) Progressive Residual Quantization further lowers quantization error by iteratively applying Semantic-Aware Smoothing algorithm. (d) The final residual tensor becomes much easier to quantize and has a much lower quantization error.",
                "position": 216
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02958/x5.png",
                "caption": "Figure 5:(a–b) Imaging Quality over long-horizon generation on Self-Forcing Model. Both QVG and QVG-Pro preserve near-lossless quality, while prior baselines degrade drastically.\n(c) The first stage of Progressive Residual Quantization yields the most significant reduction in MSE. Subsequent stages further reduce the error, but with diminishing returns.",
                "position": 696
            },
            {
                "img": "https://arxiv.org/html/2602.02958/x6.png",
                "caption": "Figure 6:Semantic-Aware Smoothing effectively reduces the quantization error by∼6.9×\\sim 6.9\\timesand∼2.6×\\sim 2.6\\timesfor keys and values, respectively. Keys has a higher MSE reduction since values cache are more irregular than keys cache.",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2602.02958/x7.png",
                "caption": "Figure 7:(a) Memory usage decomposition of QVG. (b-c) Trade-off curve of quantization block size for KV Cache.",
                "position": 794
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]