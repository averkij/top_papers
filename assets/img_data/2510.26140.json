[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/images/teaser2_tmp5_sp.png",
                "caption": "Figure 1:FullPart achieves high-quality part-based 3D generation.",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/x1.png",
                "caption": "Figure 2:FullPart framework. FullPart comprises three sequential stages: (a) layout generation using implicit vecset diffusion, (b) generating each part at a full-resolution grid with explicit voxel representation, and (c) refining coarse part structures to texture meshes.",
                "position": 153
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/x2.png",
                "caption": "Figure 3:Illustration of our 3D part representation. Our model generates each part at isolated full resolution (c), which contains more fine details than the previous sharing global voxel grid strategy (b). Also, tokens from different parts represent varying spatial extents, e.g., head and body in (d).",
                "position": 263
            }
        ]
    },
    {
        "header": "4PartVerse-XL Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/x3.png",
                "caption": "Figure 4:Comparison with state-of-the-art 3D Part generators. Our method can generate more detailed and reasonably divided parts.",
                "position": 333
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/x4.png",
                "caption": "Figure 5:Comparison with the state-of-the-art 3D generators.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2510.26140/x5.png",
                "caption": "Figure 6:Comparison with different model settings under identical training budgets: (a) no corner encoding, (b) using metadata-derived structural information without manual annotations, (c) all layout boxes constrained to a single voxel space, causing each box may only occupy a small number of voxels, and (d) normal setting with all things.",
                "position": 441
            },
            {
                "img": "https://arxiv.org/html/2510.26140/x6.png",
                "caption": "Figure 7:Editing applications.",
                "position": 466
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26140/x7.png",
                "caption": "Figure 8:Data examples from PartVerse-XL.",
                "position": 996
            }
        ]
    },
    {
        "header": "Appendix BPartVerse-XL Dataset",
        "images": []
    }
]