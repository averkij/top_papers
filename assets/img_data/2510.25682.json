[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/figs/intro.png",
                "caption": "Figure 1:Performance Conflict Mechanism Analysis: Median gradient cosine similarity scores between understanding and generation components, alongside benchmark performance on two understanding benchmarks (MMMU[53], MMStar[5]) and one image generation benchmark (GenEval[10]). The analysis encompasses six distinct data combination scenarios: PairUG, Retrieval-based Pairs, Unpair data with low similarity scores, pure Generation-only data, pure Understanding-only data, and Random Pairs.",
                "position": 141
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/x1.png",
                "caption": "Figure 3:Data Pairing Pipeline.Left: examples of aligned quadruples from generation and understanding tasks. Right: pairing strategy using retrieval and clustering.",
                "position": 219
            },
            {
                "img": "https://arxiv.org/html/2510.25682/figs/GRPO.png",
                "caption": "Figure 4:Framework of PairUni: A dual-component design integrating a data processing pipeline and the GRPO reinforcement learning algorithm.",
                "position": 259
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/figs/cases.png",
                "caption": "Figure 5:Case Study: The generated image of Janus-Pro-7B and PairUni",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2510.25682/figs/reward_curve.png",
                "caption": "Figure 6:Training rewards of PairUG and random pairs.",
                "position": 1155
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6More Training Setting",
        "images": []
    },
    {
        "header": "7More details about data",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/figs/data_distribution.png",
                "caption": "Figure 7:Distributional comparison between multimodal understanding and image generation data.",
                "position": 2089
            },
            {
                "img": "https://arxiv.org/html/2510.25682/figs/understand_generation_case.png",
                "caption": "Figure 8:Representative paired cases for understanding and generation.",
                "position": 2105
            },
            {
                "img": "https://arxiv.org/html/2510.25682/figs/data_analysis.png",
                "caption": "Figure 9:Distribution of PairUG. From left to right: (1) source breakdown for Aligned Pairs; (2) class distribution for Aligned Pairs; (3) class distribution for Retrieved Pairs; (4) similarity distribution for Retrieved Pairs.",
                "position": 2112
            }
        ]
    },
    {
        "header": "8Case Studies on Understanding Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/x2.png",
                "caption": "Figure 10:Representative cases comparing Janus-Pro and PairUni on understanding tasks.",
                "position": 2125
            }
        ]
    },
    {
        "header": "9Prompts for GPT-o3",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25682/figs/generate_prompt.png",
                "caption": "Figure 11:GPT-o3 prompt used for generating quadruple data.",
                "position": 2138
            },
            {
                "img": "https://arxiv.org/html/2510.25682/figs/understand_case.png",
                "caption": "Figure 12:GPT-o3 prompt used for understanding quadruple data.",
                "position": 2141
            }
        ]
    },
    {
        "header": "The Use of Large Language Models",
        "images": []
    }
]