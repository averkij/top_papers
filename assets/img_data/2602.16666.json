[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16666/x1.png",
                "caption": "Figure 1:Reliability gains lag behind capability progress.Overall reliability shows slow improvement over time. While accuracy rises steadily across both benchmarks (left), reliability trails behind (center), and the relationship between the two varies across benchmarks (right), indicating that accuracy gains do not automatically yield reliability.",
                "position": 292
            }
        ]
    },
    {
        "header": "1  Introduction",
        "images": []
    },
    {
        "header": "2  A Cross-Domain Perspective of Reliability",
        "images": []
    },
    {
        "header": "3  Operationalizing Reliability for AI Agents",
        "images": []
    },
    {
        "header": "4  Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16666/x2.png",
                "caption": "Figure 2:Outcome consistency across models.Results show only modest consistency across the board; even current frontier models do not reliably improve across both benchmarks.",
                "position": 964
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x3.png",
                "caption": "Figure 3:Prompt robustness across models.Many models remain susceptible to surface-level prompt reformulations. Latest frontier models generally show modest but not dependable improvements.",
                "position": 967
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x4.png",
                "caption": "Figure 4:Calibration and discrimination across models.Calibration, the alignment between predicted confidence and accuracy, generally improves in frontier models. Discrimination performance, the ability to distinguish correct and incorrect predictions, is inconsistent across benchmarks and has in fact generally worsened on GAIA.",
                "position": 970
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x5.png",
                "caption": "",
                "position": 974
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x6.png",
                "caption": "Figure 5:Safety analysis onτ\\tau-bench.Top: Average violations per evaluation run stratified by severity level.Bottom: Breakdown of violations by constraint category. The most recent frontier models exhibit significantly lower overall violation rates. Financial accuracy (i.e., incorrect charges/refunds) remains the most common failure mode across all models.",
                "position": 1024
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x7.png",
                "caption": "Figure 6:Comparison ofτ\\tau-bench vs.τ\\tau-bench (clean). Accuracy improves significantly across the board. Many agents also show improved reliability across dimensions on the verified subset ofτ\\tau-bench. Predictability sees the most noticeable improvement.",
                "position": 1034
            }
        ]
    },
    {
        "header": "5  Recommendations",
        "images": []
    },
    {
        "header": "6  Limitations",
        "images": []
    },
    {
        "header": "7  Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Metric Details",
        "images": []
    },
    {
        "header": "Appendix BExtended Background",
        "images": []
    },
    {
        "header": "Appendix CExtended Research Agenda",
        "images": []
    },
    {
        "header": "Appendix DExtended Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16666/x8.png",
                "caption": "(a)GAIA.",
                "position": 4401
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x8.png",
                "caption": "(a)GAIA.",
                "position": 4404
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x9.png",
                "caption": "(b)τ\\tau-bench.",
                "position": 4409
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x10.png",
                "caption": "Figure 8:Reliability by model type (top: GAIA, bottom:τ\\tau-bench).Larger and reasoning models improve reliability on average over smaller models. Notably though, reasoning models do not significantly improve in predictability on GAIA or in robustness onτ\\tau-bench.",
                "position": 4418
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x11.png",
                "caption": "",
                "position": 4422
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x12.png",
                "caption": "Figure 9:Reliability by provider (top: GAIA, bottom:τ\\tau-bench).",
                "position": 4426
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x13.png",
                "caption": "",
                "position": 4430
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x14.png",
                "caption": "(a)GAIA.",
                "position": 4440
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x14.png",
                "caption": "(a)GAIA.",
                "position": 4443
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x15.png",
                "caption": "(b)τ\\tau-bench.",
                "position": 4448
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x16.png",
                "caption": "(a)GAIA.",
                "position": 4464
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x16.png",
                "caption": "(a)GAIA.",
                "position": 4467
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x17.png",
                "caption": "(b)τ\\tau-bench.",
                "position": 4472
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x18.png",
                "caption": "Figure 12:Reliability plots of different agent models on GAIA.Calibration plots show confidence (x-axis) versus actual accuracy (y-axis), where the diagonal represents perfect calibration. Agents are noticeably better calibrated compared toτ\\tau-bench. Anthropic models (Claude Opus 4.5 in particular) stand out as well calibrated.",
                "position": 4494
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x19.png",
                "caption": "Figure 13:Calibration plots of different agent models onτ\\tau-bench.All agents suffer from severe overconfidence. Only newer Claude models show modest calibration improvements.",
                "position": 4497
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x20.png",
                "caption": "Figure 14:Selective prediction curves of different agent models on GAIA.Accuracy-coverage curves show whether models can improve accuracy by abstaining on low-confidence predictions; the ideal curve rises steeply while the random baseline indicates confidence provides no signal. Most models demonstrate meaningful selective prediction ability, with Gemini 2.5 Flash, o1, and Claude Opus 4.5 showing particularly strong performance.",
                "position": 4500
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x21.png",
                "caption": "Figure 15:Selective prediction curves of different agent models onτ\\tau-bench.Selective prediction largely fails in more complex agentic settings: most models produce curves indistinguishable from the random baseline, indicating confidence scores carry no information about correctness. Only Claude Sonnet 4.5 and Opus 4.5 retain modest selective prediction ability.",
                "position": 4503
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x22.png",
                "caption": "Figure 16:Detailed abstention results (top: GAIA, bottom:τ\\tau-bench).Top row shows three key calibration metrics: Abstention Rate measures how often models choose to abstain overall; Abstention Precision (P(would fail|\\ |\\abstained)) indicates whether models are abstaining on the right tasks—high precision means when a model abstains, it likely would have failed anyway; and Abstention Recall (P(abstained|\\ |\\failed)) captures whether models catch their failures—high recall means models successfully abstain on most tasks they would have gotten wrong. The bottom row provides additional context: Selective Accuracy compares overall accuracy to accuracy on non-abstained tasks (showing whether abstaining improves effective performance); the Confusion Matrix breaks down all outcomes into four categories (proceeded/abstained × succeeded/failed); and Abstention by Type shows the reasons models give for abstaining (e.g., inability vs. uncertainty).",
                "position": 4506
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x23.png",
                "caption": "",
                "position": 4510
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x24.png",
                "caption": "(a)GAIA.",
                "position": 4519
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x24.png",
                "caption": "(a)GAIA.",
                "position": 4522
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x25.png",
                "caption": "(b)τ\\tau-bench.",
                "position": 4527
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x26.png",
                "caption": "Figure 18:Safety results across agents onτ\\tau-bench.Extension of Figure5.",
                "position": 4536
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x27.png",
                "caption": "Figure 19:Comparison of reasoning vs non-reasoning models.We observe that reasoning models are generally more reliable than non-reasoning models, albeit reliability improves slower than accuracy.",
                "position": 4550
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x28.png",
                "caption": "Figure 20:Reliability metrics stratified by task difficulty on GAIA.Accuracy degrades as expected on harder tasks, while Claude models invest significantly more actions on difficult problems. Outcome consistency shows mixed patterns driven by accuracy-dependent failure modes. Robustness metrics remain stable across difficulty levels, suggesting robustness is largely orthogonal to task complexity.",
                "position": 4553
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x29.png",
                "caption": "Figure 21:Consistency results across agents onτ\\tau-bench (original).We observe a noticeable degradation in terms of outcome consistency on the full benchmark. Other consistency metrics do not show significant performance losses.",
                "position": 4563
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x30.png",
                "caption": "Figure 22:Robustness results across agents onτ\\tau-bench (original).We observe no noticeable degradation on the original benchmark.",
                "position": 4566
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x31.png",
                "caption": "Figure 23:Predictability results across agents onτ\\tau-bench (original).We observe a meaningful degradation in calibration on the original benchmark. However, discrimination is generally comparable.",
                "position": 4569
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x32.png",
                "caption": "Figure 24:Calibration plots of different agent models onτ\\tau-bench (original).Calibration noticeably decrades over the clean subset fromτ\\tau-bench (see Figure13).",
                "position": 4572
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x33.png",
                "caption": "Figure 25:Selective prediction curves of different agent models onτ\\tau-bench (original).In contrast to calibration, discrimination does not significantly degrade on the original benchmark. However, performance on the clean subset was generally poor (except for on the latest OpenAI / Anthropic models).",
                "position": 4575
            },
            {
                "img": "https://arxiv.org/html/2602.16666/x34.png",
                "caption": "Figure 26:Safety results across agents onτ\\tau-bench (original).We observe a slight increase of safety violations on the original benchmark.",
                "position": 4578
            }
        ]
    },
    {
        "header": "Appendix EExtended Experimental Results",
        "images": []
    }
]