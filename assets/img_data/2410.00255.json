[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00255/extracted/5891227/figures/robin_logo.png",
                "caption": "",
                "position": 69
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00255/x1.png",
                "caption": "Figure 1:Robin3D surpasses previous SOTA across all the benchmarks (left), by training on our RIG-generated 1 million data (right).",
                "position": 117
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00255/x2.png",
                "caption": "Figure 2:Overview of the proposed Robin3D model structure.Bottom: Our Relation-Augmented Projecter fuses the features and position embedding from Mask3D and Uni3D to generate final 3D features. 2D features from DINO v2 are projected into the LLM space. We freeze the Mask3D, Uni3D, and DINO v2.Middle: ID-Feature Bonding enhances the connection between object IDs and object features by wrapping the features with identical IDs and the Post-Vision order.Top: We use LoRA to fine-tune the LLM on our constructed 1 million instruction data.",
                "position": 169
            }
        ]
    },
    {
        "header": "4Robust Instruction Generation (RIG)",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00255/x3.png",
                "caption": "Figure 3:The visualization of examples of adversarial / negative data. For better visualization, we associate each object ID with the same color as its bounding box. The black solid circles with numbers are solely for visualization purposes and are not included in the actual data.",
                "position": 216
            },
            {
                "img": "https://arxiv.org/html/2410.00255/x4.png",
                "caption": "Figure 4:(Upper) Pipeline to generate our Diverse Instruction data by the in-context learning of ChatGPT.\n(Lower) The one-shot examples for ChatGPT to rephrase the instruction-following data.",
                "position": 278
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00255/x5.png",
                "caption": "Figure 5:Visualization of Robin3Dâ€™s responses on all the five benchmarks.",
                "position": 925
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]