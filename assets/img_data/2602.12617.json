[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12617/x1.png",
                "caption": "Figure 1:GeoSeek Dataset.We train GeoAgent with GeoSeek, a geolocation dataset with bias-reducing sampling and a val-bench annotated with locatability and geographic elements. Remarkably, a single image may contain multiple geographic elements.",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x2.png",
                "caption": "Figure 2:Data construction and training pipeline of GeoAgent.GeoSeek-CoT contains 10k high-quality reasoning processes labeled by geography experts and geolocation game players.\nGeoSeek-Loc includes 20k images for the cold start ofGeoAgent-SFT. During the GRPO-based training, based onGeoAgent-SFT, we design the geo-similarity reward to encourage the model to converge towards correct answers both physically and semantically.\nAlso, the consistency reward is introduced to keep the integrity and consistency of CoT.",
                "position": 313
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3GeoSeek Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12617/x3.png",
                "caption": "Figure 3:Inconsistent CoT and different descriptions of the same location.Left: incomplete and inconsistent CoT, Right: consistent CoT after training with the consistency agent. Meanwhile, different final answers probably refer to the same location (e.g., Hefei and Hefei City). Therefore, Geo-Similarity is introduced to solve this problem.",
                "position": 388
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12617/x4.png",
                "caption": "Figure 4:Discussion of reward functions.The two scatter plots respectively reveal the reasons for the unreasonable directly-judge reward and the positive effect of semantic similarity reward.\nWe also demonstrate the curve of reward value changes over training steps, reflecting the importance of applying consistency reward to enable the model to establish a complete reasoning framework.",
                "position": 397
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x5.png",
                "caption": "Figure 5:GeoScore on GeoSeek-Val.We compare different models in multiple locatabilities and geographic elements.",
                "position": 930
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12617/x6.png",
                "caption": "Figure 6:Reasoning comparison of six different models (GPT-5[openai2025gpt5], Gemma3[team2025gemma], Kimi[team2025kimi], Qwen2.5-VL-32B[bai2025qwen2], GeoAgent and GeoAgent with only SFT).Green: correct reasoning, Yellow: reasoning with certain issues, Red: reasoning that deviates significantly.\nNotably, brown highlights instances where the reasoning process isincompleteorinconsistentwith the result.",
                "position": 1064
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "7Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BDetails of GeoSeek",
        "images": []
    },
    {
        "header": "Appendix CDifferent Base Models",
        "images": []
    },
    {
        "header": "Appendix DCase Study",
        "images": []
    },
    {
        "header": "Appendix EDiscussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12617/x7.png",
                "caption": "Figure 7:Prompts in SFT and GRPO.",
                "position": 1539
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x8.png",
                "caption": "Figure 8:Prompts in locatability scoring and category annotation.",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x9.png",
                "caption": "Figure 9:Comparison between human-annotated and AI-standardized thought processes versus direct AI annotation.",
                "position": 1545
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x10.png",
                "caption": "Figure 10:More cases of GeoSeek Dataset.",
                "position": 1548
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x11.png",
                "caption": "Figure 11:More cases of IM2GPS3K[zhou_img2loc_2024].",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x12.png",
                "caption": "Figure 12:More cases of GeoSeek-Val.",
                "position": 1554
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x13.png",
                "caption": "Figure 13:Failure cases of GeoAgent.",
                "position": 1557
            },
            {
                "img": "https://arxiv.org/html/2602.12617/x14.png",
                "caption": "Figure 14:Robustness of GeoAgent.",
                "position": 1560
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]