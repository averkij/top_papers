[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Real-world Trajectory Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00531/x1.png",
                "caption": "Figure 1:Data Collection Pipeline with Agent Self-evolving",
                "position": 192
            }
        ]
    },
    {
        "header": "3Training",
        "images": []
    },
    {
        "header": "4AgentRR: Record-Replay-based Agent Acceleration with Multi-level Experiences",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00531/x2.png",
                "caption": "Figure 2:Multi-Agent Architecture using the AgentRR Framework",
                "position": 355
            },
            {
                "img": "https://arxiv.org/html/2509.00531/x3.png",
                "caption": "Figure 3:Construction of the ActTree Structure During Mobile Task Execution",
                "position": 408
            }
        ]
    },
    {
        "header": "5MobiFlow: a DAG-Based Benchmark Framework for Mobile Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00531/x4.png",
                "caption": "Figure 4:The overall architecture of MobiFlow",
                "position": 663
            }
        ]
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.00531/figs/avg_score.png",
                "caption": "(a)Overall Average Score",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2509.00531/figs/avg_score.png",
                "caption": "(a)Overall Average Score",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2509.00531/figs/avg_score_easy.png",
                "caption": "(b)Average Easy Task Score",
                "position": 819
            },
            {
                "img": "https://arxiv.org/html/2509.00531/figs/avg_score_hard.png",
                "caption": "(c)Average Hard Task Score",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2509.00531/figs/replay_rate.png",
                "caption": "Figure 6:Action Replay Rate with AgentRR under Different Distributions.",
                "position": 852
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]