[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13344/figures/method.png",
                "caption": "Figure 1:Visualization of MoE within the YOLOv9 architecture, multiple experts process the input image to produce multi-scale feature maps and outputs (class and bounding box logits).\nRouters at different resolutions (8×8, 16×16, 32×32) generate adaptive routing weights that fuse expert outputs into final detections.\nThe loss is computed between model outputs beforeNon-maximum suppression(NMS)[Hosang2017LearningNS,wang2024yolov9]and the ground truth, ensuring end-to-end differentiability.",
                "position": 89
            }
        ]
    },
    {
        "header": "IIProposed MoE-Based YOLOv9 Architecture",
        "images": []
    },
    {
        "header": "IIIExperiments and results",
        "images": []
    },
    {
        "header": "IVConclusions and future work",
        "images": []
    }
]