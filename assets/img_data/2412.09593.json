[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/results/results_main-HQ.jpeg",
                "caption": "",
                "position": 90
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09593/x1.png",
                "caption": "Figure 2:Framework Overview.Multi-light diffusion generates multi-light images from an input image. These images with corresponding lighting orientations are then used to predict surface normals and PBR materials with a regression U-Net.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09593/x2.png",
                "caption": "Figure 3:Hybrid condition in multi-light diffusion. Input images are incorporated viaconcatenationwith noise latents and enhanced throughreference attention, where queries in the denoise stream attend to keys and values from both streams.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2412.09593/x3.png",
                "caption": "Figure 4:Visualization of multi-light setup inLightProp. Camera and point lights are positioned on a sphere around the object.Œ∏,œÜùúÉùúë\\theta,\\varphiitalic_Œ∏ , italic_œÜare spherical coordinates to determine each light‚Äôs orientation relative to the object.",
                "position": 289
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/normal/normal_compare_main-HQ.jpeg",
                "caption": "Figure 5:Qualitative comparison on surface normal estimation. Ground truth normals (G.T.) are provided for input images rendered from available 3D objects (the last two rows) and are omitted for in-the-wild images (the first two rows).",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/relit/relit_compare_main-HQ.jpeg",
                "caption": "Figure 6:Qualitative comparison on single-image relighting.",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/pbr/pbr_compare_main-HQ.jpeg",
                "caption": "Figure 7:Qualitative comparison on PBR material estimation. Ground truth materials (G.T.) are provided for input images rendered from available 3D objects (the right column) and are omitted for in-the-wild images (the left column).",
                "position": 592
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/ablation/ablate_diffusion-HQ.jpeg",
                "caption": "Figure 8:Visualization of different conditioning strategies in multi-light diffusion.Concatstands for concatenation.RAstands for reference attention.",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/ablation/ablate_ref-HQ.jpeg",
                "caption": "Figure 9:Visualization of using different numbers of multi-light images. We evaluate the G-Buffer prediction model with different numbers of novel-light images (00,3333,6666, and9999) as conditions.",
                "position": 829
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/ablation/ablate_aug-HQ.jpeg",
                "caption": "Figure 10:Visualization of the augmentation strategy.",
                "position": 840
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADataset Details",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CLimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/failcase/failcase-crop-L.jpeg",
                "caption": "Figure 11:Failure case.",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/results/results_supp_1-L.jpeg",
                "caption": "Figure 12:More results of our method.",
                "position": 1761
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/results/results_supp_2-L.jpeg",
                "caption": "Figure 13:More results of our method.",
                "position": 1764
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/various_relighting/various_relighting_supp_1-L.jpeg",
                "caption": "Figure 14:More single-image relighting results of our method.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/various_relighting/various_relighting_supp_2-L.jpeg",
                "caption": "Figure 15:More single-image relighting results of our method.",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/normal/normal_compare_supp_eval-L.jpeg",
                "caption": "Figure 16:More comparisons on surface normal estimation.",
                "position": 1773
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/pbr/pbr_compare_supp_1-L.jpeg",
                "caption": "Figure 17:More comparisons on PBR material estimation.",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/pbr/pbr_compare_supp_2-L.jpeg",
                "caption": "Figure 18:More comparisons on PBR material estimation.",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2412.09593/extracted/6065430/Figures/relit/relit_compare_supp-L.jpeg",
                "caption": "Figure 19:More comparisons on single-image relighting.",
                "position": 1782
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": []
    }
]