[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04364/x1.png",
                "caption": "Figure 2:Overall Pipeline.VideoGuide is a framework for enhancing temporal quality without additional training, leveraging the capabilities of any pretrained VDM. Throughout the denoising process of the sampling VDM, the guiding VDM receives an intermediate latentğ’›tsubscriptğ’›ğ‘¡{\\boldsymbol{z}}_{t}bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand provides a temporally consistent sampleğ’›tâˆ’Ï„subscriptğ’›ğ‘¡ğœ{\\boldsymbol{z}}_{t-\\tau}bold_italic_z start_POSTSUBSCRIPT italic_t - italic_Ï„ end_POSTSUBSCRIPTby proceeding in its own denoising for a small number of stepsÏ„ğœ\\tauitalic_Ï„. The sampleğ’›tâˆ’Ï„subscriptğ’›ğ‘¡ğœ{\\boldsymbol{z}}_{t-\\tau}bold_italic_z start_POSTSUBSCRIPT italic_t - italic_Ï„ end_POSTSUBSCRIPTis then denoised and interpolated with the denoisedğ’›tsubscriptğ’›ğ‘¡{\\boldsymbol{z}}_{t}bold_italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTto produce a fused latentğ’›tâ€²subscriptsuperscriptğ’›â€²ğ‘¡{\\boldsymbol{z}}^{\\prime}_{t}bold_italic_z start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. Such interpolation only needs to take part in the first few steps of inference, and effectively guides samples towards a direction of improved temporal consistency. To further ensure model flexibility in refining high-frequency areas for better image quality, the latentğ’›tâ€²subscriptsuperscriptğ’›â€²ğ‘¡{\\boldsymbol{z}}^{\\prime}_{t}bold_italic_z start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTis passed through a Low-Pass Filter (LPF). Overall, VideoGuide is a straightforward addition to the original pipeline, yet it is powerful enough to significantly enhance temporal consistency without compromising imaging quality or motion smoothness.",
                "position": 260
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3VideoGuide",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04364/x2.png",
                "caption": "Figure 3:Qualitative Comparison.VideoGuide is applied on various base models for different text prompts.\nFor each prompt, frames of generated samples from four different models are displayed: (i)Base model(first row); (ii)Base model with FreeInit(second row); (iii)Base model with VideoGuide (self-guided case)(third row); (iv)Base model with VideoGuide (external model-guided case)(fourth row). AD, VC, LV indicate guidance models of AnimateDiff, VideoCrafter-2.0, LaVie, respectively. Samples for the base model show substandard temporal consistency, especially regarding color fluctuation and subject appearance change. Applying FreeInit improves consistency but introduces degradation in imaging quality, such as smoothing out of textural details. In contrast, applying VideoGuide significantly enhances temporal consistency while preserving imaging quality, both for the self-guided case and the external model-guided case.",
                "position": 547
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04364/x3.png",
                "caption": "Figure 4:(a) The interpolation process between denoised samples from the sampling model (S) and the guiding model (G) for high guidance scalew=7.5ğ‘¤7.5w=7.5italic_w = 7.5is shown. (b) The interpolation process for low guidance scalew=0.8ğ‘¤0.8w=0.8italic_w = 0.8is shown. Both interpolations are performed atT=980ğ‘‡980T=980italic_T = 980andÎ²=0.7ğ›½0.7\\beta=0.7italic_Î² = 0.7. Results indicate that with high guidance scalewğ‘¤witalic_w, influence of the guiding diffusion model is significantly reduced due to color saturation.",
                "position": 887
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x4.png",
                "caption": "Figure 5:Prior Distillation Results.VideoGuide solves degraded performance regarding text coherency by enabling the utilization of a superior data prior. Example results for certain ambiguous prompts are displayed. For each prompt, the same random seed is shared for both methods. AnimateDiff directs generation of â€˜beetleâ€™ and â€˜jaguarâ€™ towards car samples due to a substandard data prior. Using VideoGuide, users can distill a superior prior for correct generation.",
                "position": 1019
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    },
    {
        "header": "Appendix BQuantitative Analysis of CFG and CFG++",
        "images": []
    },
    {
        "header": "Appendix CUser Study",
        "images": []
    },
    {
        "header": "Appendix DPseudo Code",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04364/x5.png",
                "caption": "Figure 6:Prior Distillation. For each prompt, we share the same random seed for both methods.",
                "position": 1744
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x6.png",
                "caption": "Figure 7:More Qualitative Results of VideoGuide on AnimateDiff (with RealisticVision).",
                "position": 1747
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x7.png",
                "caption": "Figure 8:More Qualitative Results of VideoGuide on AnimateDiff (with RealisticVision).",
                "position": 1750
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x8.png",
                "caption": "Figure 9:More Qualitative Results of VideoGuide on AnimateDiff (with ToonYou).",
                "position": 1753
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x9.png",
                "caption": "Figure 10:More Qualitative Results of VideoGuide on AnimateDiff (with RCNZCartoon).",
                "position": 1756
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x10.png",
                "caption": "Figure 11:More Qualitative Results of VideoGuide on AnimateDiff (with FilmVelvia).",
                "position": 1759
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x11.png",
                "caption": "Figure 12:More Qualitative Results of VideoGuide on LaVie.",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x12.png",
                "caption": "Figure 13:More Qualitative Results of VideoGuide on LaVie.",
                "position": 1765
            },
            {
                "img": "https://arxiv.org/html/2410.04364/x13.png",
                "caption": "Figure 14:VideoGuide helps solve the issue of sudden frame shifts in LaVie samples. By integrating an external guiding model, VideoGuide provides smoother frame transitions to the base model. LV indicates that guidance model of LaVie is used (the self-guided case), and VC indicates that guidance model of VideoCrafter2 is used. Guidance given with the external model VideoCrafter2 solves sudden frame shift unsolvable by other methods.",
                "position": 1768
            }
        ]
    },
    {
        "header": "Appendix EMore Qualitative Examples",
        "images": []
    }
]