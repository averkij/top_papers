[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x1.png",
                "caption": "Figure 1:Our synthetic LongBioBench has a high correlation with the real task HELMET[12].The performance is tested on 128K context length from 12 overlapped models.",
                "position": 294
            }
        ]
    },
    {
        "header": "2LongBioBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x2.png",
                "caption": "Figure 2:The example of our data (left), the supported configs and the extensible tasks (right). The underlined text shows the inserted attributes. The color of different tasks marks the category of the task.",
                "position": 369
            }
        ]
    },
    {
        "header": "3Main Evaluation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x3.png",
                "caption": "Figure 3:The average performance of all models on Understanding, Reasoning, and Trustworthiness categories.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2506.02921/x4.png",
                "caption": "Figure 4:The performance of 8 different models by tasks. Some results are blank since the length of target biographies exceed the specified context length.",
                "position": 449
            }
        ]
    },
    {
        "header": "4Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x5.png",
                "caption": "Figure 5:The bar chart of performance by different attributes on the 2-retrieval task. For simplicity, we abbreviate the names of all instruct models.",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2506.02921/x6.png",
                "caption": "Figure 6:Performance of Qwen-7b-Instruct-1M and InternLM-7B-Instruct on both our LongBioBench and BiaH. The task is controlled as standard retrieval on the left figure,s and the retrieval number is fixed to be 2 on the right figures. A bigger gap is observed on both models as the task difficulty increases.",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2506.02921/x7.png",
                "caption": "Figure 7:The performance of Qwen2.5 at the long-context pretraining stage on our bench with 32K context length. The x-axis represents the number of training steps. The y-axis shows the accuracy over different tasks.",
                "position": 544
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset Construction Details",
        "images": []
    },
    {
        "header": "Appendix BData Statistics",
        "images": []
    },
    {
        "header": "Appendix CTask Description",
        "images": []
    },
    {
        "header": "Appendix DAnalysis: Density and Needle position v.s Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x8.png",
                "caption": "Figure 8:The performance on calculation (left) task and pronoun retrieval (right) task corresponding with the answer depth and distractor density. Y-axis shows the percentage of insertion depth in the context and x-axis shows the percentage of the distracted information appeared in the context.",
                "position": 1951
            }
        ]
    },
    {
        "header": "Appendix EModel Details",
        "images": []
    },
    {
        "header": "Appendix FFull Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02921/x9.png",
                "caption": "Figure 9:The performance of 16 models by tasks.",
                "position": 2093
            }
        ]
    },
    {
        "header": "Appendix GPrompts",
        "images": []
    }
]