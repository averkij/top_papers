[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06496/x1.png",
                "caption": "Figure 1:Overview of 3D CoCa v2 and OOD results on TOD3Cap.(a) 3D CoCa v2 extends 3D CoCa(Huanget al.,2025c)with an inference-only test-time search (TTS) module and an external LLM judge.\n(b) Zero-shot OOD performance on TOD3Cap(Jin and others,2025)comparing 3D-VLP(Zhanget al.,2024), 3D CoCa(Huanget al.,2025c), and 3D CoCa v2 under standard captioning metrics at IoU 0.25 and 0.5.",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06496/x2.png",
                "caption": "Figure 2:Overview of 3D CoCa v2.(a)3D CoCalearns aligned 3Dâ€“text representations by jointly optimizing contrastive alignment and caption generation: a point-cloud scene encoder and a text encoder produce fused features for a multi-modal decoder to generate a draft caption. (b)Test-Time Search (inference-only)improves robustness without any parameter updates by generating best-of-NNcandidate captions from the backbone, conditioning an external LLM judge on a compact scene summary, and selecting the highest-scoring candidate as the final caption.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3The Proposed Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06496/x3.png",
                "caption": "Figure 3:Qualitative comparisons on ScanRefer(Chen and others,2020).We visualize four representative scenes and the captions generated by 3D CoCa, 3D CoCa v2, and the ground truth (GT).\nCompared to the baseline, 3D CoCa v2 produces more detailed and better-grounded descriptions, capturing richer scene semantics and functional cues.\nRed-highlighted phrases mark the additional informative content provided by our method beyond the baseline.",
                "position": 1315
            },
            {
                "img": "https://arxiv.org/html/2601.06496/x4.png",
                "caption": "Figure 4:Qualitative results on TOD3Cap(Jin and others,2025)(OOD, zero-shot).We compare captions generated by the indoor-trained Vote2Cap-DETR++, 3D CoCa and 3D CoCa v2 on outdoor scenes with paired front and back views.\nVote2Cap-DETR++ and 3D CoCa often exhibit a strong indoor bias, producing generic indoor descriptions, whereas 3D CoCa v2 generates more scene-consistent outdoor captions that better reflect key semantics. Ground-truth (GT) captions are shown for reference.\nRed words highlight informative details captured by 3D CoCa v2 but missing in the baseline.",
                "position": 1504
            },
            {
                "img": "https://arxiv.org/html/2601.06496/x5.png",
                "caption": "Figure 5:Qualitative comparisons on ScanReferChen and others (2020)(w/o TTS vs w/ TTS).For each example, we show the reconstructed 3D scene (top) and a zoomed-in view (bottom), where the target object is indicated by themagentabox.\nCompared with standard decoding (w/o TTS), Test-Time Search (w/ TTS) yields more specific and better-grounded captions, capturing object identities and layout cues supported by the highlighted region rather than generic room-level descriptions.Green textmarks the object-specific details introduced by w/ TTS.",
                "position": 1603
            }
        ]
    },
    {
        "header": "5Test-Time Efficiency",
        "images": []
    },
    {
        "header": "6Limitation and Future Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]