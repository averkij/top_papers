[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x1.png",
                "caption": "",
                "position": 108
            }
        ]
    },
    {
        "header": "Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x2.png",
                "caption": "Figure 2:Comparison with SOTA identity-preserving video generation methods. The size of bubbles represents the number of need-to-train parameters for identity preservation. Our approach achieves the highest performance in both face similarity and naturalness, while utilizing the fewest parameters.",
                "position": 120
            }
        ]
    },
    {
        "header": "Related Work",
        "images": []
    },
    {
        "header": "Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x3.png",
                "caption": "Figure 3:The overview of our identity-preserving text-to-video generation framework. We introduce a conditional image branch alongside the original video branch. Given the conditional image, the VAE encoder maps it into tokens, which are concatenated with the video latent tokens and then sent to the DiT. Within the DiT blocks, identity information is incorporated into the video features through restricted self-attention.",
                "position": 221
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x4.png",
                "caption": "Figure 4:Design of our restricted self-attention: For the input video and image tokens, we compute their Query, Key, and Value matrices independently. Next, we apply 3D RoPE to the Query and Key matrices. Finally, the image matrices operate independently, while the video Query performs attention using the concatenation of the image and video Key and Value matrices.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x5.png",
                "caption": "Figure 5:Examples from our human-centric video dataset.",
                "position": 300
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x6.png",
                "caption": "Figure 6:Comparison on identity-preserving video generation. Please refer to the supplementary material for full prompts.",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x7.png",
                "caption": "Figure 7:Our results on subjects other than real-person. Please refer to the supplementary material for full prompts.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x8.png",
                "caption": "Figure 8:Comparison on pose-guided video generation against VACE.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x9.png",
                "caption": "Figure 9:Application of our model in video face swapping.",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x10.png",
                "caption": "Figure 10:Our model applied with stylization LoRA.",
                "position": 543
            }
        ]
    },
    {
        "header": "Experiments",
        "images": []
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Comparison Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x11.png",
                "caption": "Figure 11:Visual comparison with other cutting-edge methods. Our method,Stand-In, demonstrates superior identity fidelity and detail preservation (1/5).",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x12.png",
                "caption": "Figure 12:Visual comparison with other cutting-edge methods. Our method,Stand-In, demonstrates superior identity fidelity and detail preservation (2/5).",
                "position": 1107
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x13.png",
                "caption": "Figure 13:Visual comparison with other cutting-edge methods. Our method,Stand-In, demonstrates superior identity fidelity and detail preservation (3/5).",
                "position": 1111
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x14.png",
                "caption": "Figure 14:Visual comparison with other cutting-edge methods. Our method,Stand-In, demonstrates superior identity fidelity and detail preservation (4/5).",
                "position": 1115
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x15.png",
                "caption": "Figure 15:Visual comparison with other cutting-edge methods. Our method,Stand-In, demonstrates superior identity fidelity and detail preservation (5/5).",
                "position": 1119
            }
        ]
    },
    {
        "header": "Appendix BMore Ablation Study Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x16.png",
                "caption": "Figure 16:Visual results of the ablation study.",
                "position": 1133
            }
        ]
    },
    {
        "header": "Appendix CPseudocode",
        "images": []
    },
    {
        "header": "Appendix DComplete Video Generation Prompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07901/x17.png",
                "caption": "Figure 17:We present more visual results of Stand-In (1/2).",
                "position": 1307
            },
            {
                "img": "https://arxiv.org/html/2508.07901/x18.png",
                "caption": "Figure 18:We present more visual results of Stand-In (2/2).",
                "position": 1311
            }
        ]
    },
    {
        "header": "Appendix EMore Results",
        "images": []
    }
]