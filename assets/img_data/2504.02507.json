[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/zclip3.png",
                "caption": "Figure 1:Training loss graph comparing 1) training without clipping, 2) clipping with fixed threshold 1.0, and 3) ZClip for a LLaMA 1B model.The learning rate for all three experiments is3.0√ó10‚àí33.0superscript1033.0\\times 10^{-3}3.0 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.\nWhile both ‚Äúno clipping‚Äù and ‚Äúconstant clipping‚Äù exhibit spiky behavior and diverge early, ZClip (withzthressubscriptùëßthresz_{\\text{thres}}italic_z start_POSTSUBSCRIPT thres end_POSTSUBSCRIPT=2.5 andŒ±=0.97ùõº0.97\\alpha=0.97italic_Œ± = 0.97) remains stable and continues to optimize effectively throughout training.\nDetails on the model configuration and other training hyperparameters are presented in Appendix Section6.1.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Gradient Clipping Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/1.png",
                "caption": "Figure 2:Training loss graph for a LLaMA 1B model trained with fixed-threshold clipping c = 1.0.\nGradient norm spikes persist due to a mismatch between the static threshold and the running distribution.\nThis reveals a key limitation of fixed-threshold clipping in dynamically changing training regimes.",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/zt_zstar_2_5.png",
                "caption": "Figure 3:Three possible choices for the z-score adjustment functionŒæ‚Å¢(zt)ùúâsubscriptùëßùë°\\xi(z_{t})italic_Œæ ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )illustrated forzthres=2.5subscriptùëßthres2.5z_{\\text{thres}}=2.5italic_z start_POSTSUBSCRIPT thres end_POSTSUBSCRIPT = 2.5.Note the discontinuity forŒæ‚Å¢(zt)=0ùúâsubscriptùëßùë°0\\xi(z_{t})=0italic_Œæ ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = 0, and the reciprocal nature ofŒæ‚Å¢(zt)=zthres2/ztùúâsubscriptùëßùë°superscriptsubscriptùëßthres2subscriptùëßùë°\\xi(z_{t})=\\nicefrac{{z_{\\text{thres}}^{2}}}{{z_{t}}}italic_Œæ ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = / start_ARG italic_z start_POSTSUBSCRIPT thres end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARGleading to more aggressive clipping for more extreme outliers.",
                "position": 381
            }
        ]
    },
    {
        "header": "3Experiment Setup",
        "images": []
    },
    {
        "header": "4Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/low_high.png",
                "caption": "Figure 4:Comparison of Test Loss between ZClip (lr=3e-3) and a baseline model (lr=5e-4) on a 50B token corpus.\nZClip achieved the same final loss as the baseline while requiring 18.6B fewer tokens to get there.\nThe plot uses log-scaled training loss for visibility, and smoothing has been applied to reduce noise.\nZClip allows for faster convergence without compromising on final loss value.",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/5e3.png",
                "caption": "((a))",
                "position": 818
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/5e3.png",
                "caption": "((a))",
                "position": 821
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_5e3_before.png",
                "caption": "((b))",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_5e3_after.png",
                "caption": "((c))",
                "position": 833
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/3e3.png",
                "caption": "((d))",
                "position": 843
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_3e3_before.png",
                "caption": "((e))",
                "position": 849
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_3e3_after.png",
                "caption": "((f))",
                "position": 855
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/1e3.png",
                "caption": "((a))",
                "position": 880
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/1e3.png",
                "caption": "((a))",
                "position": 883
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_1e3_before.png",
                "caption": "((b))",
                "position": 889
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_1e3_after.png",
                "caption": "((c))",
                "position": 895
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/7e4.png",
                "caption": "((d))",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_7e4_before.png",
                "caption": "((e))",
                "position": 911
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_7e4_after.png",
                "caption": "((f))",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/5e4.png",
                "caption": "((g))",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_5e4_before.png",
                "caption": "((h))",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_5e4_after.png",
                "caption": "((i))",
                "position": 939
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/3e4.png",
                "caption": "((j))",
                "position": 949
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_3e4_before.png",
                "caption": "((k))",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_3e4_after.png",
                "caption": "((l))",
                "position": 961
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/1e4.png",
                "caption": "((m))",
                "position": 971
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_1e4_before.png",
                "caption": "((n))",
                "position": 977
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/lr_1e4_after.png",
                "caption": "((o))",
                "position": 983
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/grad_norm_before3.png",
                "caption": "((a))",
                "position": 1043
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/grad_norm_before3.png",
                "caption": "((a))",
                "position": 1046
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/grad_norm_after3.png",
                "caption": "((b))",
                "position": 1052
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/clip_algo2.png",
                "caption": "Figure 8:Training loss for three ZClip variants‚Äîmax, reciprocal, and mean.The learning rate for all experiments is1.0√ó10‚àí31.0superscript1031.0\\times 10^{-3}1.0 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.",
                "position": 1434
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/nd1.png",
                "caption": "((a))",
                "position": 1492
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/nd1.png",
                "caption": "((a))",
                "position": 1495
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/nd2.png",
                "caption": "((b))",
                "position": 1501
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/through.png",
                "caption": "Figure 10:Training throughput comparison between fixed-threshold gradient clipping, AutoClip, and ZClip methods.",
                "position": 1529
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/clip_percent.png",
                "caption": "Figure 11:Clipping percentage vs.¬†training step for different z-score thresholds. Lower thresholds yield higher clipping percentages, indicating more aggressive clipping. The learning rate for all experiments is1.0√ó10‚àí31.0superscript1031.0\\times 10^{-3}1.0 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT. The token budget was 50BT.",
                "position": 1615
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/mean.png",
                "caption": "Figure 12:EMA-estimated mean for differentŒ±ùõº\\alphaitalic_Œ±values.The learning rate for all experiments is1.0√ó10‚àí31.0superscript1031.0\\times 10^{-3}1.0 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, and the threshold iszthres=2.5subscriptùëßthres2.5z_{\\text{thres}}=2.5italic_z start_POSTSUBSCRIPT thres end_POSTSUBSCRIPT = 2.5. The token budget was 50BT.",
                "position": 1689
            },
            {
                "img": "https://arxiv.org/html/2504.02507/extracted/6297715/data/std.png",
                "caption": "Figure 13:EMA-estimated standard deviation for differentŒ±ùõº\\alphaitalic_Œ±values.The learning rate for all experiments is1.0√ó10‚àí31.0superscript1031.0\\times 10^{-3}1.0 √ó 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, and the threshold iszthres=2.5subscriptùëßthres2.5z_{\\text{thres}}=2.5italic_z start_POSTSUBSCRIPT thres end_POSTSUBSCRIPT = 2.5. The token budget was 50BT.",
                "position": 1692
            }
        ]
    },
    {
        "header": "6Appendix",
        "images": []
    }
]