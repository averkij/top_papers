[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11481/x1.png",
                "caption": "Figure 1:(A) Motivation.Comparison of the adaptation capabilities of humans, contemporary RL-based control policies and our RAPTOR method.(B) The RAPTOR Method.Overview over all stages of the RAPTOR architecture.",
                "position": 107
            }
        ]
    },
    {
        "header": "2Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11481/x2.png",
                "caption": "Figure 2:Training Results.(A)shows the pre-training learning curve,(B)shows the meta-imitation learning curve,(C)shows the Pareto frontier between performance and number of teachers, and(D)shows the Pareto frontier between performance and student/foundation policy size.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2509.11481/x3.png",
                "caption": "Figure 3:Inference Results.Here we show a recovery of a simulated quadrotor from an adverse initial condition using the trained foundation policy. We show the latent state of the policy throughout the trajectory and test if it performs emergent/implicit system identification by training a linear probe.",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2509.11481/x4.png",
                "caption": "Figure 4:Test Quadrotors.A diverse set of1010real and22simulated quadrotors that we use in the experiments.",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2509.11481/x5.png",
                "caption": "Figure 5:Trajectory Tracking Results.Trajectory tracking results of the1010real and22simulation quadrotors.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2509.11481/x6.png",
                "caption": "Figure 6:RAPTOR Policy in Different Situations.(A): The foundation policy is activated in mid-air, starting with a linear velocity of4.54.5m/s.(B)Crazyflie Brushless tracking an agile trajectory.(C)Long exposure photo of three consecutive loops of the Crazyflie Brushless trajectory.(D)The foundation policy recovers from being poked and tilting>90âˆ˜>90^{\\circ}.(E)A tool is rested onto the quadrotor flown by the foundation policy.(F)A quadrotor with four different propellers (2- and 3-blade) is tracking a trajectory using the foundation policy.",
                "position": 498
            }
        ]
    },
    {
        "header": "3Discussion",
        "images": []
    },
    {
        "header": "4Materials and Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11481/x7.png",
                "caption": "Figure 7:(A)A probabilistic graphical model (Bayesian Network) of the dynamics and control of a random quadrotor. This formal model allows us to derive the RAPTOR architecture from probabilistic principles.(B): Foundation policy network architecture.(C): Illustration of inferring dynamics parameters by reasoning about the observed input/output behavior of the system.",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2509.11481/x8.png",
                "caption": "Figure 8:Meta-Imitation Learning Algorithm.",
                "position": 707
            }
        ]
    },
    {
        "header": "References and Notes",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.11481/x9.png",
                "caption": "Figure S1:Probabilistic Graphical Model for Ancestral Sampling of Quadrotors",
                "position": 1812
            }
        ]
    },
    {
        "header": "Supplementary Materials forRAPTOR: A Foundation Policy for Quadrotor Control",
        "images": []
    }
]