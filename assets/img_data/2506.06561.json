[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/overview-figure-v202505200403.png",
                "caption": "Figure 1:Overview of\\dataset. For each target figure, the dataset provides a multimodalsource—the figure image and figure-mentioning paragraphs—and a multimodalprofileof up to three other figures (i.e., profile figures) from the same paper, each with its image, caption, and related paragraphs. The model generates a caption for the target figure using this source and profile.",
                "position": 156
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3\\datasetDataset",
        "images": []
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig04_easyHard/01_easy_bleu4-v2.png",
                "caption": "a-1BLEU-4 (Context-Aligned Subset)",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig04_easyHard/01_easy_bleu4-v2.png",
                "caption": "a-1BLEU-4 (Context-Aligned Subset)",
                "position": 544
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig04_easyHard/03_hard_bleu4-v2.png",
                "caption": "b-1BLEU-4 (Context-Misaligned Subset)",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig04_easyHard/02_easy_rouge2-v4.png",
                "caption": "a-2ROUGE-2 (Context-Misaligned Subset)",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig04_easyHard/04_hard_rouge2-v4.png",
                "caption": "b-2ROUGE-2 (Context-Misaligned Subset)",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig01/fig01_ablation_study-v5.png",
                "caption": "Figure 3:Ablation study on caption generation by removing one profile element at a time (caption, image, or figure-mentioning paragraph). Captions contribute the most, followed by images, then paragraphs.",
                "position": 592
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Ethics Statements",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix A\\datasetDataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig02/data-split-distribution-v2.png",
                "caption": "Figure 4:Data split of\\datasetby figure type. The dataset contains 307,903 figures from 110,828 scientific papers, split into training (80%), validation (10%), and testing (10%) sets. Each set includes target and profile figures. The five main figure types are a) Graph Plot, b) Node Diagram, c) Equation, d) Bar Chart, and e) Scatterplot. Graph plots are the most common figure type across all splits.",
                "position": 1149
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig03/profile-dist-v2.png",
                "caption": "Figure 5:Profile distribution in\\dataset, showing the number of target figures with 1, 2, or 3 profile figures.",
                "position": 1152
            }
        ]
    },
    {
        "header": "Appendix BPrompts",
        "images": []
    },
    {
        "header": "Appendix CGeneration Output Cleaning Procedure",
        "images": []
    },
    {
        "header": "Appendix DText Preprocessing and Evaluation",
        "images": []
    },
    {
        "header": "Appendix EDetail about Caption Evaluation",
        "images": []
    },
    {
        "header": "Appendix FContext-Alignment Data Partition",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig05_maxscoreDist/distribution_plot_max_bert.png",
                "caption": "Figure 6:Distribution of BERTScore (left) and ROUGE-L (right) metrics between Target and Profile captions in the\\datasetTest Set. Both these scores share a left-shifted skewed unimodal distribution. The BERTScore plot shows that the provided profile captions for each target arevery semantically related. On the other hand, the broader spread of ROUGE-L scores shows that profile captions exhibitlow lexical overlap. High semantic relatedness and lexical variety motivates our use of profile captions as key style indicators for personalization.",
                "position": 1406
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig05_maxscoreDist/distribution_plot_max_bert.png",
                "caption": "",
                "position": 1409
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig05_maxscoreDist/distribution_plot_max_rouge.png",
                "caption": "",
                "position": 1413
            }
        ]
    },
    {
        "header": "Appendix GDetailed Result of Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig06_mainStudy-BLEU4-dist/01_bleu4_4o.png",
                "caption": "(a)BLEU-4 for GPT-4o",
                "position": 1801
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig06_mainStudy-BLEU4-dist/01_bleu4_4o.png",
                "caption": "(a)BLEU-4 for GPT-4o",
                "position": 1804
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig06_mainStudy-BLEU4-dist/02_bleu4_Llama.png",
                "caption": "(b)BLEU-4 for Llama-4 Scout",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig06_mainStudy-BLEU4-dist/03_bleu4_gemini.png",
                "caption": "(c)BLEU-4 for Gemini-2.5 Flash Preview",
                "position": 1815
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig06_mainStudy-BLEU4-dist/04_bleu4_mini.png",
                "caption": "(d)BLEU-4 for GPT-4.1 Mini",
                "position": 1820
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig07_mainStudy-ROUGE2-dist/01_rouge2_4o.png",
                "caption": "(a)ROUGE-2 for GPT-4o",
                "position": 1827
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig07_mainStudy-ROUGE2-dist/01_rouge2_4o.png",
                "caption": "(a)ROUGE-2 for GPT-4o",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig07_mainStudy-ROUGE2-dist/02_rouge2_Llama.png",
                "caption": "(b)ROUGE-2 for Llama-4 Scout",
                "position": 1835
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig07_mainStudy-ROUGE2-dist/03_rouge2_gemini.png",
                "caption": "(c)ROUGE-2 for Gemini-2.5 Flash Preview",
                "position": 1841
            },
            {
                "img": "https://arxiv.org/html/2506.06561/extracted/6520514/figures/fig07_mainStudy-ROUGE2-dist/04_rouge2_mini.png",
                "caption": "(d)ROUGE-2 for GPT-4.1 Mini",
                "position": 1846
            }
        ]
    },
    {
        "header": "Appendix HDisclosure of AI Assistance",
        "images": []
    }
]