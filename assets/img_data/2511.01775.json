[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01775/x1.png",
                "caption": "Figure 1:(a) The Surgical Plausibility Pyramid (SPP) framework, illustrating four hierarchical assessment dimensions: (i) Visual Perceptual Plausibility at the appearance level, assessing the clarity and stability of generated videos, (ii) Instrument Operation Plausibility at the action level, judging the accuracy and technical proficiency of instrument manipulation, (iii) Environment Feedback Plausibility at the consequence level, measuring the realism and credibility of scene feedback, and (iv) Surgical Intent Plausibility at the Strategy level, evaluating the appropriateness and clinical reasoning of surgical actions. (b) Detailed 5-point scoring rubrics (5=excellent to 1=poor) for evaluating each dimension.",
                "position": 179
            }
        ]
    },
    {
        "header": "2The SurgVeo Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01775/x2.png",
                "caption": "Figure 2:The overall pipeline of this study. (a) The overview of the SurgVeo benchmark preparation and evaluation workflow. The surgical video dataset is processed to create the paired surgical frame and surgical video continuation. The Veo model takes the surgical frame with a prompt as input to generate the surgical video prediction. A panel of four board-certified surgeons evaluates the generated surgical videos against the real surgical video continuation as reference under the Surgical Plausibility Pyramid (SPP). (b) The illustration of the generation and evaluation process for a single sample in the SurgVeo benchmark. A starting surgical frame and a text prompt are fed into the Veo model to generate an 8-second surgical video prediction. This output is then scored by expert surgeons by comparing it to the real 8-second reference video with a focus on four dimensions of surgical plausibility, particularly at the 1-second, 3-second, and 8-second time points.",
                "position": 195
            }
        ]
    },
    {
        "header": "3Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01775/x3.png",
                "caption": "Figure 3:Violin plots illustrating the performance on the laparoscopic surgery track in the SurgVeo benchmark. Results are shown for (a) the baseline prompt and (b) the stage-aware prompt. The performance is assessed across four evaluation dimensions in the SPP, with three progressively deeper shades representing evaluations at 1-second, 3-second, and 8-second. Each sample point reflects the average score provided by two laparoscopic surgery experts.",
                "position": 592
            },
            {
                "img": "https://arxiv.org/html/2511.01775/x4.png",
                "caption": "Figure 4:Violin plots illustrating the performance on the neurosurgery track in the SurgVeo benchmark. Results are shown for (a) the baseline prompt and (b) the stage-aware prompt. The performance is assessed across four evaluation dimensions in the SPP, with three progressively deeper shades representing evaluations at 1-second, 3-second, and 8-second. Each sample point reflects the average score provided by two neurosurgery experts.",
                "position": 595
            },
            {
                "img": "https://arxiv.org/html/2511.01775/x5.png",
                "caption": "Figure 5:Qualitative examples of typical failures identified in the generated videos. Each example presents a side-by-side comparison of the real surgical frame (left) and the generated surgical frame (right). These examples elaborate on failures across the Surgical Plausibility Pyramid, including: (a) visual quality distortions, (b) surgical instrument errors, (c) inappropriate surgical operations, (d) inappropriate surgical targets, (e) environment feedback errors, and (f) surgical intent errors. Red arrows indicate specific illogical, anatomically incorrect, or physically impossible artifacts.",
                "position": 605
            },
            {
                "img": "https://arxiv.org/html/2511.01775/x6.png",
                "caption": "Figure 6:Distribution of error types identified by expert surgeons in generated videos of the SurgVeo benchmark. The charts quantify the frequency of different failures in surgical plausibility for (a) the laparoscopic surgery track and (b) the neurosurgery track. Across both specialties, errors related to high-level surgical logic, such as Surgical intent errors, Surgical instrument errors, and Inappropriate surgical operations, constitute the vast majority of all failures. In contrast, basic Visual quality distortions represent only a small fraction of the total errors, reinforcing the finding of the plausibility gap.",
                "position": 658
            }
        ]
    },
    {
        "header": "4Discussions",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATracks of SurgVeo Benchmark",
        "images": []
    },
    {
        "header": "Appendix BStatistics of SurgVeo Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01775/x7.png",
                "caption": "Figure 7:The surgical stage distribution of the proposed SurgVeo benchmark in two tracks, including (a) the distribution of the laparoscopic surgery track, and (b) the distribution of the neurosurgery track. Note that not every surgery includes all possible surgical stages.",
                "position": 983
            }
        ]
    },
    {
        "header": "Appendix CData Structure of SurgVeo Benchmark",
        "images": []
    },
    {
        "header": "Appendix DTask Formulation of Surgical Video Generation",
        "images": []
    },
    {
        "header": "Appendix EPrompting Strategy with Templates",
        "images": []
    },
    {
        "header": "Appendix FImplementation Details of Surgical Video Generation",
        "images": []
    },
    {
        "header": "Appendix GSurgical Plausibility Pyramid for Expert Evaluation",
        "images": []
    },
    {
        "header": "Appendix HQualitative Case Studies of Generated Videos",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01775/x8.png",
                "caption": "Figure 8:Qualitative examples of high-scoring video generations from the SurgVeo benchmark. Each pair shows the real surgical video (top row) and the generated video (bottom row) evolving from the same starting frame. (a) A laparoscopic procedure where the Veo model generates a naturally flowing and plausible dissection. (b) A neurosurgical procedure where the generated video is nearly identical to the real reference video, presenting a high-quality case.",
                "position": 1323
            },
            {
                "img": "https://arxiv.org/html/2511.01775/x9.png",
                "caption": "Figure 9:Qualitative examples of low-scoring video generations, demonstrating catastrophic failures in plausibility. Each pair shows the real surgical video (top row) and the generated video (bottom row). (a) A laparoscopic procedure where the Veo model is expected to perform suturing. Instead, it hallucinates a fabricated surgical instrument and performs an unrecognizable, non-standard operation. (b) A neurosurgical procedure where the real intent is to apply biologic glue. The generated video completely misses this intent, failing on all three high-level SPP dimensions despite acceptable visual quality.",
                "position": 1326
            }
        ]
    },
    {
        "header": "Appendix IPublic Release and Reproducibility",
        "images": []
    }
]