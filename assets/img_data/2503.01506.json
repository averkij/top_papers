[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01506/x1.png",
                "caption": "Figure 1:We conduct data clustering analysis using the SlimPajama dataset.\nFor each domain (row), each cell shows the percentage of its clusters that also include samples from other domains (column). E.g., 76.60% of ArXiv‚Äôs clusters include Wikipedia samples (1st row, 6th column). The results reveal substantial overlap between domains.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x2.png",
                "caption": "Figure 2:(a) Traditional methods determine domain weights and construct the training dataset by uniformly sampling from each domain.\n(b)SampleMixemploys asample-wisemixing strategy by:\nevaluating sample quality and diversity,\nassigning appropriate weights, and\nconstructing an optimal dataset based on these weights. Dots of the same color represent data from the same domain..",
                "position": 183
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01506/x3.png",
                "caption": "(a)Quality Distribution",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x3.png",
                "caption": "(a)Quality Distribution",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x4.png",
                "caption": "(b)Diversity Distribution",
                "position": 322
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01506/x5.png",
                "caption": "Figure 4:Training efficiency comparison. SampleMix reaches the average baseline accuracy at 100k training steps - 1.9 times faster than the averaged baselines.",
                "position": 651
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x6.png",
                "caption": "Figure 5:Average performance of downstream tasks with different weighting factorŒ±ùõº\\alphaitalic_Œ±.",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x7.png",
                "caption": "(a)Proportion of different sampling counts.",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x7.png",
                "caption": "(a)Proportion of different sampling counts.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x8.png",
                "caption": "(b)Sampling weight (i.e.,p‚Å¢(x)ùëùùë•p(x)italic_p ( italic_x )) of different sampling counts.",
                "position": 789
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADomain Overlaps",
        "images": []
    },
    {
        "header": "Appendix BSamples from Slimpajama CommonCarwl",
        "images": []
    },
    {
        "header": "Appendix CDomain Weights of Different Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01506/x9.png",
                "caption": "Figure 9:Domain weights of different methods.",
                "position": 1442
            }
        ]
    },
    {
        "header": "Appendix DHyper-Parameters of Training Models",
        "images": []
    },
    {
        "header": "Appendix EQuality Evaluation Prompt",
        "images": []
    },
    {
        "header": "Appendix FCode of Quality Evaluator",
        "images": []
    },
    {
        "header": "Appendix GK-means Clustering Details",
        "images": []
    },
    {
        "header": "Appendix HCoverage Speed of All Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.01506/x10.png",
                "caption": "Figure 11:Coverage speed of all baselines and SampleMix. SampleMix achieves the best training efficiency.",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x11.png",
                "caption": "(a)Proportion of different sampling count forTtgt=TsrcsubscriptùëátgtsubscriptùëásrcT_{\\mathrm{tgt}}=T_{\\mathrm{src}}italic_T start_POSTSUBSCRIPT roman_tgt end_POSTSUBSCRIPT = italic_T start_POSTSUBSCRIPT roman_src end_POSTSUBSCRIPT",
                "position": 1892
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x11.png",
                "caption": "(a)Proportion of different sampling count forTtgt=TsrcsubscriptùëátgtsubscriptùëásrcT_{\\mathrm{tgt}}=T_{\\mathrm{src}}italic_T start_POSTSUBSCRIPT roman_tgt end_POSTSUBSCRIPT = italic_T start_POSTSUBSCRIPT roman_src end_POSTSUBSCRIPT",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2503.01506/x12.png",
                "caption": "(b)Sampling weight (i.e.,p‚Å¢(x)ùëùùë•p(x)italic_p ( italic_x )) of different sampling counts forTtgt=TsrcsubscriptùëátgtsubscriptùëásrcT_{\\mathrm{tgt}}=T_{\\mathrm{src}}italic_T start_POSTSUBSCRIPT roman_tgt end_POSTSUBSCRIPT = italic_T start_POSTSUBSCRIPT roman_src end_POSTSUBSCRIPT",
                "position": 1900
            }
        ]
    },
    {
        "header": "Appendix IAnalysis of Sampling Count Distribution",
        "images": []
    }
]