[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/extracted/6476729/star-icon.png",
                "caption": "",
                "position": 55
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/x1.png",
                "caption": "Figure 1:Comparison of addressing the TVR task by STAR-SFT and STAR-R1. STAR-SFT finetunes MLLMs with supervised instructions, while STAR-R1 employs RL-guided thinking.",
                "position": 82
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/x2.png",
                "caption": "Figure 2:The STAR-R1 Framework. Given initial/final images and a question, STAR-R1 establishes object correspondences by systematically comparing all objects across both images. It generates Step-by-step reasoning in<think></think>tags before delivering the final answer in<answer></answer>tags. We demonstrate the reward function of STAR-R1 using a partially correct case study. Correct/incorrect answers are shown inblueandredrespectively.",
                "position": 142
            }
        ]
    },
    {
        "header": "3Our Method: STAR-R1",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/x3.png",
                "caption": "Figure 3:A case study comparing the reasoning processes of STAR-SFT and STAR-R1. STAR-SFT performs only cursory comparisons, failing to detect view changes, which results in incorrect object matching and answers. In contrast, STAR-R1 systematically compares all objects step-by-step, identifies the view shift, and accurately tracks object correspondences, producing correct results.Blueindicates correct answers whilereddenotes incorrect ones.",
                "position": 757
            },
            {
                "img": "https://arxiv.org/html/2505.15804/x4.png",
                "caption": "Figure 4:Dynamics of model response length. Zoom in to examine specific examples.",
                "position": 768
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset and Experimental Setup",
        "images": []
    },
    {
        "header": "Appendix BTraining Curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/x5.png",
                "caption": "Figure 5:Training curves about accuracy reward and format reward.",
                "position": 1985
            },
            {
                "img": "https://arxiv.org/html/2505.15804/x6.png",
                "caption": "Figure 6:Dynamics of the total accuracy as well as the\nattribute accuracy for the four types throughout the training process.",
                "position": 1994
            },
            {
                "img": "https://arxiv.org/html/2505.15804/extracted/6476729/sft_vs_rl_accuracy_comparison.png",
                "caption": "Figure 7:Accuracy curves of RL and SFT.",
                "position": 2001
            },
            {
                "img": "https://arxiv.org/html/2505.15804/extracted/6476729/sft_vs_rl_accuracy_comparison.png",
                "caption": "Figure 7:Accuracy curves of RL and SFT.",
                "position": 2004
            }
        ]
    },
    {
        "header": "Appendix CTraining STAR-SFT with RL",
        "images": []
    },
    {
        "header": "Appendix DMore Cases",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15804/x7.png",
                "caption": "Figure 8:The problem prompt.",
                "position": 2112
            },
            {
                "img": "https://arxiv.org/html/2505.15804/x8.png",
                "caption": "Figure 9:A case study comparing the reasoning processes of STAR-SFT and STAR-R1.Blueindicates correct answers whilereddenotes incorrect ones.",
                "position": 2115
            },
            {
                "img": "https://arxiv.org/html/2505.15804/x9.png",
                "caption": "Figure 10:A case study comparing the reasoning processes of STAR-SFT and STAR-R1.Blueindicates correct answers whilereddenotes incorrect ones.",
                "position": 2118
            },
            {
                "img": "https://arxiv.org/html/2505.15804/x10.png",
                "caption": "Figure 11:A case study comparing the reasoning processes of STAR-SFT and STAR-R1.Blueindicates correct answers whilereddenotes incorrect ones.",
                "position": 2121
            }
        ]
    },
    {
        "header": "Appendix ELimitations",
        "images": []
    }
]