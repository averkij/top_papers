[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04581/images/T3_Fig_1.png",
                "caption": "Figure 1:Geometric concentration of safe text embeddings in high-dimensional space.The distribution of Euclidean distances from the mean for 10,000 safe embeddings (Alpaca, d=1024) empirically validates the concentration of measure phenomenon.(a, d)The distances closely follow a theoreticalχ1024\\chi_{1024}distribution, confirmed by a Q-Q plot (R2>0.99R^{2}>0.99).(b, c, f)This results in a concentrated “typical set” where 90% of data forms an annulus (“hollow sphere”) around the mean, a structure visible even in 2D PCA projections.(e)As predicted by theory, this concentration tightens relative to the dimension (O​(d−1/2)O(d^{-1/2})).",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2602.04581/images/T3_Fig_2.png",
                "caption": "Figure 2:Distinguishing safe vs. toxic text using geometric typicality.This figure compares simple Euclidean and Mahalanobis distances for separating 10,000 safe and 2,000 toxic embeddings.(a, b)Mahalanobis distance, which accounts for the safe data’s covariance, provides far better separation between safe (green) and toxic (red) distributions.(c, d)This superiority is quantified by a significantly higher ROC AUC (0.944 vs. 0.733) and confirmed by box plots.(e)A 2D PCA projection visually confirms that toxic samples fall predominantly outside the 95% typical set boundary of safe data.",
                "position": 184
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04581/images/AblationSampleSize2.png",
                "caption": "",
                "position": 3208
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix BExperiment Technique Details",
        "images": []
    },
    {
        "header": "Appendix CExperiment Parameters",
        "images": []
    },
    {
        "header": "Appendix DIntegrating T3 with vLLM for Online Generation Guardrailing",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04581/x1.png",
                "caption": "Figure 4:NVIDIA Nsight Systems profiling of vLLM baseline vs. vLLM+T3.\n(a) Full execution timeline comparison.\n(b) Zoomed-in view showing kernel concurrency and reduced GPU bubbles in vLLM+T3.\n(c) Conceptual illustration of overlapping inference kernels (Worker Processes) with T3 prediction kernels (Main Process).\nThe integration reduces idle GPU periods between consecutive generations, improving utilization while preserving low-latency inference.",
                "position": 6939
            }
        ]
    },
    {
        "header": "Appendix EAdditional Experiments",
        "images": []
    }
]