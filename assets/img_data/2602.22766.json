[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/x1.png",
                "caption": "Figure 1:Comparison between visual reasoning with tools and through imagination.\n(a) Reasoing with tools perceive visual content through function calling such as zoom-in or drawing.\n(b) Latent-space imagination exploits the hidden states of MLLMs to conduct visual reasoning.\n(c) We show that imagination can be more effective in text-space.",
                "position": 106
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Analysis: Latent Tokens Hardly Helps",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/x2.png",
                "caption": "Figure 2:Our systematic latent analysis frameworkfor investigating the internal mechanisms and behavioral patterns of latent tokens. (a) Model Inference illustrates the latent inference process. (b) and (c) respectively illustrate two causal analysis approaches. In diagram Intervention onZZ,œÑ\\taudenotes a fixed tensor,œµ\\epsilonrepresents random Gaussian noise withœµ‚àºùí©‚Äã(0,œÉ2)\\epsilon\\sim\\mathcal{N}(0,\\sigma^{2}), andŒº\\muis a small value close to zero.",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/x3.png",
                "caption": "Figure 3:Illustration of Our Method and Data Construction Pipeline, through which we conduct a strictly controlled training setting with Monet for fair and convincing comparisons. The upper section presents the interleaved format of original data. The middle section clarifies the key methodological differences between the two approaches. The lower section shows the data construction procedures.",
                "position": 345
            }
        ]
    },
    {
        "header": "4CapImagine",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/x4.png",
                "caption": "Figure 4:Inter-instance and Intra-instance Analysisof the inner hidden states ofCapImagineduring reasoning process.",
                "position": 729
            },
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/image5.png",
                "caption": "Figure 5:Inference Speed Comparisonof Monet,CapImagineand DeepEyes on V*. (Unit: Seconds)",
                "position": 803
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExamples for Derived Questions in Probing Analysis.",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22766/2602.22766v1/image6.png",
                "caption": "Figure 6:The derived questions focus on the same region or object as the original question, while differing in the queried attribute aspects.",
                "position": 1344
            }
        ]
    },
    {
        "header": "Appendix BDetailed Results for Intervention onZZ.",
        "images": []
    },
    {
        "header": "Appendix CLimitations and Future Work",
        "images": []
    }
]