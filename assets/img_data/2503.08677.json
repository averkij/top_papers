[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08677/x1.png",
                "caption": "",
                "position": 77
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08677/x2.png",
                "caption": "Figure 2:Visualization of CFD metric assessment for object removal. The segmentation results are obtained using SAM[17]with refinement, with purple masks for background, orange masks for segments fully within the original mask, and unmasked for those extending beyond the original mask. Note that the orange masked regions correspond to hallucinated objects. A higher ReMOVE[4]score is better, while a lower CFD score is preferable. In these cases, ReMOVE scores are too similar to indicate removal success, while CFD score offers a clearer distinction.",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2503.08677/x3.png",
                "caption": "Figure 3:Illustration of the proposed CFD metric for evaluating object removal quality. Left: We apply SAM to segment the inpainted image into object masks and classify them into nested (Î©â„³nsubscriptÎ©superscriptâ„³ğ‘›\\Omega_{\\mathcal{M}^{n}}roman_Î© start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT) and overlapping (Î©â„³osubscriptÎ©superscriptâ„³ğ‘œ\\Omega_{\\mathcal{M}^{o}}roman_Î© start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT end_POSTSUBSCRIPT) masks. Middle: The context coherence term measures the feature deviation between the inpainted region (Î©ğŒsubscriptÎ©ğŒ\\Omega_{\\mathbf{M}}roman_Î© start_POSTSUBSCRIPT bold_M end_POSTSUBSCRIPT) and its surrounding background (Î©ğâˆ–ğŒsubscriptÎ©ğğŒ\\Omega_{\\mathbf{B}\\setminus\\mathbf{M}}roman_Î© start_POSTSUBSCRIPT bold_B âˆ– bold_M end_POSTSUBSCRIPT) in the DINOv2 feature space. Right: The hallucination penalty is computed by comparing deep features of detected nested objects (Î©â„³nsubscriptÎ©superscriptâ„³ğ‘›\\Omega_{\\mathcal{M}^{n}}roman_Î© start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT) with their adjacent overlapping masks (Î©â„³osubscriptÎ©superscriptâ„³ğ‘œ\\Omega_{\\mathcal{M}^{o}}roman_Î© start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT end_POSTSUBSCRIPT) to assess whether unwanted object-like structures have emerged.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08677/x4.png",
                "caption": "Figure 4:Illustration of CycleFlow. The mappingFğ¹Fitalic_Fremoves the object, predicting an estimated targetğ³1â€²superscriptsubscriptğ³1â€²\\mathbf{z}_{1}^{\\prime}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, whileGğºGitalic_Greinserts the object, generating estimated targetğ³Â¯1subscriptÂ¯ğ³1\\overline{\\mathbf{z}}_{1}overÂ¯ start_ARG bold_z end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Cycle consistency is enforced by ensuringGğºGitalic_Greconstructs the original latentğ³1subscriptğ³1\\mathbf{z}_{1}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTfrom the effect removal output. Dashed arrows indicate the cycle loss supervision.",
                "position": 400
            },
            {
                "img": "https://arxiv.org/html/2503.08677/x5.png",
                "caption": "Figure 5:Qualitative comparison on object insertion. Given masked images and reference object images (top row), we compare results from AnyDoor[5], IMPRINT[34], and OmniPaint.",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2503.08677/x6.png",
                "caption": "Figure 6:Qualitative comparison of object removal in challenging scenarios.Top:Simultaneous removal of objects and glass reflections.Middle:Shadow-free removal under real-world lighting.Bottom:Occlusion-robust inpainting, reconstructing background objects without distortion. The compared methods include FreeCompose[6], PowerPaint[58], CLIPAway[7], and FLUX-Inpainting[37].",
                "position": 554
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08677/x7.png",
                "caption": "Figure 7:Impact of inference steps and cycle loss weights.(a)Removal (top) and insertion (bottom) results across different neural function evaluations (NFE).(b)Insertion results with varying cycle loss weightsÎ³ğ›¾\\gammaitalic_Î³, with OmniPaint defaulting toÎ³=1.5ğ›¾1.5\\gamma=1.5italic_Î³ = 1.5.",
                "position": 973
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]