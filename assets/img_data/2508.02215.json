[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x1.png",
                "caption": "Figure 1:LeftandMiddle: K channel sparsity remains static across different RULERtasksandsequence lengths.Right: There exist channels with relativelylarge normbut haslimited impacton end-to-end performance.",
                "position": 128
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x2.png",
                "caption": "",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x3.png",
                "caption": "",
                "position": 142
            }
        ]
    },
    {
        "header": "2Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x4.png",
                "caption": "Figure 2:Overall demonstration of LeanKâ€™s double-stage training and deployment method.",
                "position": 219
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x5.png",
                "caption": "Figure 3:Visualization of the training objectives of the two training stages.",
                "position": 295
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x6.png",
                "caption": "Figure 4:Comparison of performance on RULER 64K under different pruning ratios.",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x7.png",
                "caption": "Figure 5:Kernel execution time of each layer on Llama-3.1-8B-Instruct. LeanK uses 70% pruning ratio. Both Baseline and LeanK use Tilelang implementation.",
                "position": 918
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x8.png",
                "caption": "Figure 6:Batch Size and Memory. LeanK enables a 20% larger batch size, saving 10GB memory.",
                "position": 1013
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x8.png",
                "caption": "Figure 6:Batch Size and Memory. LeanK enables a 20% larger batch size, saving 10GB memory.",
                "position": 1016
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x9.png",
                "caption": "Figure 7:Channel Pair Index and Remained Channel Ratio on Llama-3.1-8B-Instruct.",
                "position": 1021
            },
            {
                "img": "https://arxiv.org/html/2508.02215/x10.png",
                "caption": "Figure 8:Converting heads with highest or lowestwhfw_{\\text{hf}}italic_w start_POSTSUBSCRIPT hf end_POSTSUBSCRIPTvalues into streaming heads and performance.",
                "position": 1026
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AQuantifying K Channel Staticity",
        "images": []
    },
    {
        "header": "Appendix BComparison with Double Sparsity",
        "images": []
    },
    {
        "header": "Appendix CChannel Frequency Analysis for Qwen2.5-7B-Instruct",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x11.png",
                "caption": "Figure 9:Remained Ratio and Channel Pair Index on Qwen2.5-7B-Instruct.",
                "position": 1769
            }
        ]
    },
    {
        "header": "Appendix DHead Pruning based on High Frequency Ratio",
        "images": []
    },
    {
        "header": "Appendix ENecessity of Training Stage 2",
        "images": []
    },
    {
        "header": "Appendix FKernel Benchmarking on Qwen",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02215/x12.png",
                "caption": "Figure 10:Kernel execution time of each layer on Qwen2.5-7B-Instruct. LeanK uses 70% pruning ratio.",
                "position": 1843
            }
        ]
    },
    {
        "header": "Appendix GFull Evaluation Results on RULER",
        "images": []
    },
    {
        "header": "Appendix HFull Evaluation Results on GSM-Infinite",
        "images": []
    },
    {
        "header": "Appendix IAdditional Experimental Results",
        "images": []
    },
    {
        "header": "Appendix JChoice of Hyperparameter Lambda",
        "images": []
    },
    {
        "header": "Appendix KChoice of Training Task",
        "images": []
    },
    {
        "header": "Appendix LComparison with Static Channel Pruning Baseline",
        "images": []
    },
    {
        "header": "Appendix MAnalysis of V-Cache Pruning Conditions",
        "images": []
    },
    {
        "header": "Appendix NComparison with SnapKV",
        "images": []
    }
]