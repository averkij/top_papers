[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22281/x1.png",
                "caption": "Figure 1:Pipeline overview.Given an image, the CoMAE encoder selects the most influential patches needed to reconstruct each patch, while trivial patches are masked with heavier noise injection. These selection weights form a patch dependency graph on which we compute the PageRank scores to determine the collapse order of patches, where higher-rank patches are less dependent on the rest of the image. Finally, we use this ranking to supervise image generation and classification tasks to follow the correct patch processing order.",
                "position": 157
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22281/x2.png",
                "caption": "Figure 2:Comparison of generators and classifiers.Our generator (CMAR) and classifier (CViT) respect the collapse order.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2511.22281/media/graph.png",
                "caption": "Figure 3:Visualization of collapse order.The left figure shows image patches with different collapse ranks indicated by circle sizes. The right figure connects the top-ranked 64 patches by collapse order. One can observe that top patches outline important shapes in each image.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2511.22281/media/graph-c.png",
                "caption": "",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2511.22281/x3.png",
                "caption": "Figure 4:Class-wise collapse order patterns.These heatmaps show sample patch indices sorted in collapse order for each class.",
                "position": 318
            },
            {
                "img": "https://arxiv.org/html/2511.22281/x4.png",
                "caption": "Figure 5:Training of CoMAE (last 140 epochs).Mask entropy drops together with reconstruction loss.",
                "position": 321
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22281/x5.png",
                "caption": "Figure 6:Qualitative comparison of ARs.MAR is framed in purple. Our MAR+C and CMAR results are in blue and green respectively.",
                "position": 377
            },
            {
                "img": "https://arxiv.org/html/2511.22281/x6.png",
                "caption": "Figure 10:ViT accuracy curves.Our CViT outperforms baselines consistently along different mask ratios.",
                "position": 648
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Proof of Optimal Collapse Ranking",
        "images": []
    },
    {
        "header": "7Additional Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22281/media/qual-sup.jpg",
                "caption": "Figure 11:Additional qualitative samples of CMAR.Our method generates high-fidelity images across classes.",
                "position": 834
            }
        ]
    },
    {
        "header": "8Model Architectures",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22281/x7.png",
                "caption": "Figure 12:Architecture of CoMAE.Both the encoder and decoder follow ViT to pool information into a [cls] token.",
                "position": 844
            }
        ]
    },
    {
        "header": "9Limitations and Future Improvements",
        "images": []
    },
    {
        "header": "10Ethical Statement",
        "images": []
    }
]