[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x1.png",
                "caption": "Figure 1:Selected images generated by the Sphere Encoderin one-step for CIFAR-10 (32√ó3232\\times 32) and Animal-Faces, two-steps for Oxford-Flowers, and four-steps for ImageNet (256√ó256256\\times 256).",
                "position": 88
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x2.png",
                "caption": "Figure 2:A sphere encoderEEmaps the natural image distribution uniformly onto a global sphereSS.\nThe decoderDDthen generates a realistic image by decoding a random point on the sphere.",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x3.png",
                "caption": "Figure 3:Posterior hole problem in VAEs.\nColumns:\n(1) Input images;\n(2) Autoencoder reconstructions;\n(3) Samples from standard Gaussian prior;\nand (4) Samples from estimated Gaussian posterior on Animal-Faces training set.\nUnlike modern FLUX.1/2(Labs et¬†al.,2025)and SD-VAE(Podell et¬†al.,2024), our sphere encoder produces realistic images by decoding random points sampled from the sphere.",
                "position": 134
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x4.png",
                "caption": "Figure 4:Spherifying latent with noise.\nEncoderEEmaps imageùê±\\mathbf{x}to a latent, whichffprojects toùêØ\\mathbf{v}on sphereSS.\nDuring training, random Gaussian noiseœÉ‚ãÖùêû\\sigma\\cdot\\mathbf{e}is added toùêØ\\mathbf{v}, whereœÉ\\sigmais jittered magnitude.\nDecoderDDreconstructs the imageùê±^\\hat{\\mathbf{x}}from the re-projected noisy latentf‚Äã(ùêØ+œÉ‚ãÖùêû)f(\\mathbf{v}+\\sigma\\cdot\\mathbf{e}).",
                "position": 196
            }
        ]
    },
    {
        "header": "3Quantitative Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x5.png",
                "caption": "Figure 5:Uncurated CIFAR-10 conditional generationwith different sampling steps and with/without CFG.\nConvincing images can be formed with a single forward pass, with reliability and gFID improving with up to 4 steps.",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x6.png",
                "caption": "Figure 6:Latent interpolationon Animal-Faces and Oxford-Flowers.\nImages are generated in 4 steps without CFG.\n(left) Interpolation in a 2D space that spans 4 synthetic images.\n(right) Each row interpolates between a random vectorùêû\\mathbf{e}on the sphere and a class conditional vectorùê≤\\mathbf{y}.\nNote that our model exhibits fast/sudden transitions between image classes rather than producing ‚Äúhybrid‚Äù images that unrealistically merge properties of different object types.\nThis property is necessary for a model to reliably convert random samples from the sphere into realistic images, as it makes the probability of observing a hybrid image small.",
                "position": 682
            }
        ]
    },
    {
        "header": "4Qualitative Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x7.png",
                "caption": "Figure 7:Latent space visualizationusing random projection on CIFAR-10 training set.\nEach sphere shows the latent vectors of a different class. The conditional latent distributions appear approximately uniform.",
                "position": 898
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x8.png",
                "caption": "Figure 8:Conditional manipulationvia iterative encoding and decoding on ImageNet model. We demonstrate the model‚Äôs expressivity using an out-of-domain input (a ‚Äúwoolly panda‚Äù top-left).\nEach row shows the result of conditioning the iterative process on different ImageNet classes without CFG.\nFor example, the first row is conditioned on class 580 (greenhouse, nursery, glasshouse).",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x9.png",
                "caption": "Figure 9:Image crossoverusing the sphere encoder trained on Animal-Faces.\nA composite of two images (A and B) is iteratively processed through the encoder-decoder pipeline until it converges to a coherent sample on the learned image manifold.",
                "position": 931
            }
        ]
    },
    {
        "header": "5Image Editing",
        "images": []
    },
    {
        "header": "6Main Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x10.png",
                "caption": "Figure 10:Quantitative impact of the angleŒ±\\alphaon ImageNet.",
                "position": 1018
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x11.png",
                "caption": "",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x12.png",
                "caption": "Figure 12:Consistency optimization pathfrom noisy latent to clean latent on the sphere, pushing the decoder to generate consistent and diverse images from right to left.",
                "position": 1155
            }
        ]
    },
    {
        "header": "7Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x13.png",
                "caption": "Figure 13:Qualitative impact of sampling schemeson generation without CFG for CIFAR-10 (top) and ImageNet (bottom).\nThe‚úì\\checkmarkindicates sharing the same noiseùêû\\mathbf{e}across steps.\nShared noise withŒ≥=1\\gamma=1yields superior coherence and a sharp ‚Äúpaper art‚Äù aesthetic on ImageNet as sampling steps increase.",
                "position": 1417
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x14.png",
                "caption": "Figure 14:Randomly selected images generated by the Sphere encoderfor ImageNet (256√ó256256\\times 256).\nResults are generated using Sphere-XL with 4-step sampling and CFG=1.4=1.4.",
                "position": 1453
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x15.png",
                "caption": "Figure 15:Uncurated resultson ImageNet (256√ó256256\\times 256).\nResults are generated using Sphere-XL with 4-step sampling and CFG=1.4=1.4.",
                "position": 1461
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x16.png",
                "caption": "Figure 16:Uncurated resultson ImageNet (256√ó256256\\times 256).\nResults are generated using Sphere-XL with 4-step sampling and CFG=1.4=1.4.",
                "position": 1469
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x17.png",
                "caption": "Figure 17:Uncurated qualitative resultson CIFAR-10 (32√ó3232\\times 32), Oxford-Flowers and Animal-Faces (256√ó256256\\times 256).\nResults are 2-step generation without CFG.",
                "position": 1477
            },
            {
                "img": "https://arxiv.org/html/2602.15030/x18.png",
                "caption": "Figure 18:Uncurated qualitative resultson CIFAR-10 (32√ó3232\\times 32), Oxford-Flowers and Animal-Faces (256√ó256256\\times 256).\nResults are 4-step generation without CFG.",
                "position": 1485
            }
        ]
    },
    {
        "header": "Appendix AAdditional Results on CIFAR-10",
        "images": []
    },
    {
        "header": "Appendix BMemorization Risk on CIFAR-10",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x19.png",
                "caption": "Figure 19:Memorization riskwith longer1010K training epochs on CIFAR-10.\nEach row is a different sampling run showing near-duplicate birds of the real training image (in red box).",
                "position": 1513
            }
        ]
    },
    {
        "header": "Appendix CAdditional Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15030/x20.png",
                "caption": "Figure 20:Quantitative impact of volume compression ratioon ImageNet.\nDetails inTable13.",
                "position": 2193
            }
        ]
    },
    {
        "header": "Appendix DHyperparameters",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]