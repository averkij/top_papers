[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/x1.png",
                "caption": "Figure 1:We introduceOmniWorld, a large-scale, multi-domain, and multi-modal dataset.OmniWorldprovides a rich resource for 4D world modeling by integrating high-quality data from multiple domains and offers a variety of data types, including depth maps, camera poses, text captions, optical flow and foreground masks.OmniWorldis designed to accelerate the development of more general models for modeling the real physical world.",
                "position": 241
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/figs/smile_icon.png",
                "caption": "Table 2:OmniWorldstructure. A smiling face () indicates the modality is newly (re-)annotated by us, a green check (✔) denotes ground-truth data that already exists in the original dataset, and a red cross (✗) marks missing modalities.",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x2.png",
                "caption": "Figure 2:OmniWorldacquisition and annotation pipeline.",
                "position": 750
            }
        ]
    },
    {
        "header": "2OmniWorldDataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/x3.png",
                "caption": "(a)OmniWorldCompositional Distribution",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x3.png",
                "caption": "(a)OmniWorldCompositional Distribution",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x4.png",
                "caption": "(b)OmniWorld-GameInternal Composition",
                "position": 836
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x5.png",
                "caption": "(c)Caption Tokens Distribution",
                "position": 841
            }
        ]
    },
    {
        "header": "3OmniWorld-GameBenchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/x6.png",
                "caption": "Figure 4:Visual results of Monocular Depth Estimation onOmniWorld-Gamebenchmark.",
                "position": 1136
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x7.png",
                "caption": "Figure 5:Qualitative comparison of multi-view 3D reconstruction onOmniWorld-Gamebenchmark.",
                "position": 1139
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x8.png",
                "caption": "Figure 6:Visual results of Camera Control Video Generation models onOmniWorld-Gamebenchmark. In T2V setting, AC3D takes the text as a condition signal. In I2V setting, MotionCtrl, CamCtrl, CAMI2V takes the image as a condition signal. Condition images are the first images of each row.",
                "position": 1213
            }
        ]
    },
    {
        "header": "4Model Fine-tuning and Efficacy Validation",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BOmniWorldDataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/figs/statistic_poi_primary.png",
                "caption": "Figure 7:TheOmniWorld-Gamedistribution of scene category (the primary POI locations).",
                "position": 2777
            },
            {
                "img": "https://arxiv.org/html/2509.12201/figs/statistic_outdoor_secondary_distribution.png",
                "caption": "Figure 8:Scene Diversity within the \"Nature & Outdoors\" Category. A quantitative breakdown of second- and third-level scene categories inOmniWorld-Gamedataset, demonstrating the high internal diversity and distribution of natural environments.",
                "position": 2785
            }
        ]
    },
    {
        "header": "Appendix COmniWorld-GameBenchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.12201/x9.png",
                "caption": "Figure 9:Qualitative comparison of DUSt3R(Wang et al.,2024c)and CUT3R(Wang et al.,2025b)on the Sintel(Butler et al.,2012)subset of the Video Depth Estimation benchmark. The\nnotation * denotes models that have been fine-tuned onOmniWorld. After fine-tuning, both models recover finer geometric details and produce more accurate depth maps, highlighting the efficacy ofOmniWorldas a geometric supervision source.",
                "position": 2983
            },
            {
                "img": "https://arxiv.org/html/2509.12201/x10.png",
                "caption": "Figure 10:Visual comparison of AC3D(Bahmani et al.,2024)fine-tuned onOmniWorld. The visualizations show that fine-tuning with our dataset significantly improves the model’s ability to generate videos that more accurately follow camera trajectories and maintain higher temporal consistency for moving objects.",
                "position": 2987
            }
        ]
    },
    {
        "header": "Appendix DModel Fine-tuning",
        "images": []
    }
]