[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_first2-min.jpg",
                "caption": "",
                "position": 61
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Backgrounds",
        "images": []
    },
    {
        "header": "4Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_method2.png-min.jpg",
                "caption": "Figure 2:Method Overview.(a) To enhance the multi-object generation of text-to-image model, we use content-aware sampling in which we sample the image with non fine-tuned modelœµŒ∏0subscriptbold-italic-œµsubscriptùúÉ0{\\bm{\\epsilon}}_{\\theta_{0}}bold_italic_œµ start_POSTSUBSCRIPT italic_Œ∏ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPTand multi-object aware textùêúm‚Å¢u‚Å¢lsubscriptùêúùëöùë¢ùëô\\mathbf{c}_{mul}bold_c start_POSTSUBSCRIPT italic_m italic_u italic_l end_POSTSUBSCRIPT. In the intermediate steptc‚Å¢o‚Å¢nsubscriptùë°ùëêùëúùëõt_{con}italic_t start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT, we extract mask from the images denoised with Tweedie‚Äôs formula. (b) Aftertc‚Å¢o‚Å¢nsubscriptùë°ùëêùëúùëõt_{con}italic_t start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT, we apply custom concept using region-wise guidance and concept-wise finetuned models. We propose to region-wise mixing of different models in Tweedie‚Äôs denoised space.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_resample4-min.png",
                "caption": "Figure 3:Resampling Strategy.To improve the multi-object sampling in content-aware sampling stage, we use resampling strategy. At initial timestepTùëáTitalic_T, we subtract the single-concept samples from multi-concept samples to fortify the multi-concept text condition. This process is again calculated in the denoised space using Tweedie‚Äôs formula. With the denoised image visualizations, we can see the effectiveness of our proposed resampling.",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/Fig_method_vid3-min.png",
                "caption": "Figure 4:Method for Video Extension.To preserve the context of reference image which is generated from our multi-concept sampling strategy, we propose to inject the residual features of first frame to the other frame features.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_main-min.jpg",
                "caption": "Figure 5:Qualitative Evaluation of Multi-Concept Image Generation.We evaluate the image generation quality of our method in comparison to baseline approaches, using prompts that incorporate each concept displayed on the left. In the overall results, our method maintains the appearance of the target concepts without any concept missing problems, whereas the baseline methods fails to preserve the identity of the concepts or generate the intended action corresponding the text.",
                "position": 326
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_ablation-min.jpg",
                "caption": "Figure 6:Ablation Study on Image Generation.To evaluate the proposed method components, we conduct ablation study. (a) Results without CFG++. (b) Results without using resampling strategy. (c) Results without content aware sampling. (d) Results with mixing in noisy latent space.",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_video-min.jpg",
                "caption": "Figure 7:Qualitative Evaluation of Video Generation.Our model can generate high-quality multi-concept video generation while the baseline Dreamvideo fails to generate concept-aware videos.",
                "position": 497
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_ablation_video-min.jpg",
                "caption": "Figure 8:Ablation study on Video GenerationWithout using our proposed feature injection method, the output video shows degraded performance without preserving the inter-frame context.",
                "position": 507
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Experimental Details",
        "images": []
    },
    {
        "header": "Appendix BLimitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_failure.jpg",
                "caption": "Figure 9:Failure cases.If the text condition becomes extremely complex, then the generated concepts loses the detailed appearance.",
                "position": 1198
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/Fig_supp_1-min.jpg",
                "caption": "Figure 10:Additional Results.Our model can generate high-quality multi-concept generation results on image domains.",
                "position": 1215
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/fig_supp_2-min.jpg",
                "caption": "Figure 11:Additional Results.Our model can generate high-quality multi-concept generation results on image domains.",
                "position": 1219
            },
            {
                "img": "https://arxiv.org/html/2410.05591/extracted/5906186/Figure/supp_video_min.jpg",
                "caption": "Figure 12:Additional Results.Our model can generate high-quality multi-concept generation results on video domains.",
                "position": 1223
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    }
]