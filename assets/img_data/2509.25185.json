[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/figs/logo.png",
                "caption": "",
                "position": 63
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x1.png",
                "caption": "Figure 1:Comparison between CoT, visual CoT, and our proposed PixelCraft. Compared with existing methods, PixelCraft enables high-fidelity image processing and flexible visual reasoning.",
                "position": 105
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3PixelCraft",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x2.png",
                "caption": "Figure 2:An illustration of the PixelCraft workflow. The process begins with Agent Selection, where the dispatcher chooses the appropriate tools. Next, during Agent Discussion, the planner coordinates tool agents to process the image (e.g., cropping and masking) and the reasoner to perform analysis, with the visual critic providing real-time validation. Finally, the planning critic performs a post-hoc review of the entire process, confirming its correctness.",
                "position": 167
            }
        ]
    },
    {
        "header": "4Grounding for High-Fidelity Image Editing",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x3.png",
                "caption": "(a)Comparison of grounding methods.",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x3.png",
                "caption": "(a)Comparison of grounding methods.",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x4.png",
                "caption": "(b)Illustrative grounding example.",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x5.png",
                "caption": "Figure 4:Effectiveness and prevalence of tool usage with GPT-4.1-mini on CharXiv(Wang et al.,2024)and Geometry3K(Lu et al.,2021).",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x6.png",
                "caption": "Table 4:Role-wise ablation over Tool Agents (TA), Dispatcher (Disp), Visual Critic (VC), and Planning Critic (PC).",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x6.png",
                "caption": "Figure 5:Critic-based erroneous query identification (TP/FP counts) and post-refinement accuracy.",
                "position": 635
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAutomated Generation of Visual Tools",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x7.png",
                "caption": "(a)Clustering visualization",
                "position": 1471
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x7.png",
                "caption": "(a)Clustering visualization",
                "position": 1474
            },
            {
                "img": "https://arxiv.org/html/2509.25185/figs/output_with_color_intersections.jpg",
                "caption": "(b)Line-intersection case",
                "position": 1479
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x8.png",
                "caption": "Figure 7:Examples of our visual tools for structured images:\n(a) cropping subfigures, (b) magnifying regions, (c) masking elements by legend, and (d) adding auxiliary lines.",
                "position": 1567
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25185/x9.png",
                "caption": "Figure 8:Illustration of self-correction.",
                "position": 1792
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x10.png",
                "caption": "Figure 9:Illustration of Geometric Reasoning.",
                "position": 1802
            },
            {
                "img": "https://arxiv.org/html/2509.25185/x11.png",
                "caption": "Figure 10:Additional grounding examples.",
                "position": 1878
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Works",
        "images": []
    }
]