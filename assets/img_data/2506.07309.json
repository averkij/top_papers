[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/overall_factuality_improvement.png",
                "caption": "Figure 1:Overall factuality improvement of our Dual Neural Knowledge framework. Our fine-tuned modelConfQAreduces hallucination to under 5%; when combined with RAG, we increase accuracy by 45% on average while cutting latency by selective RAG triggering.",
                "position": 190
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Experiment Setup",
        "images": []
    },
    {
        "header": "4Q1. Does an LLM Know What It Knows?",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/figure-all-calibration-htt.png",
                "caption": "Figure 2:LLMs’ self-reported confidences is correlated with QA accuracy, but often over-confident. The answer consistency is often better calibrated with QA accuracy.",
                "position": 377
            }
        ]
    },
    {
        "header": "5Q2. Can We Teach LLMs to Refrain from Hallucinating?",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/dbpedia_benchmark_for_htt_new.png",
                "caption": "(a)DBPedia",
                "position": 942
            },
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/dbpedia_benchmark_for_htt_new.png",
                "caption": "(a)DBPedia",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/imdb_benchmark_for_htt_new.png",
                "caption": "(b)IMDB",
                "position": 950
            },
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/crag_static_benchmark_for_htt_new.png",
                "caption": "(c)CRAG",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/architecture.png",
                "caption": "Table 5:ConfQA does not regress on MMLU.",
                "position": 1055
            },
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/architecture.png",
                "caption": "Figure 4:RAG invocation architecture.",
                "position": 1092
            }
        ]
    },
    {
        "header": "6Q3. What Is the Optimal Strategy for Triggering RAG?",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "9Prompts",
        "images": []
    },
    {
        "header": "10Experiment Setup Details",
        "images": []
    },
    {
        "header": "11Influence of entity popularity on confidence",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07309/extracted/6523830/Figure/figure-q-type.png",
                "caption": "Figure 5:Correlation between LLM’s self-reported confidences and average accuracies on the CRAG dataset and the Head-to-Tail dataset, categorized by question types.",
                "position": 2404
            }
        ]
    },
    {
        "header": "12Fine tuning implementation",
        "images": []
    },
    {
        "header": "13p-Value of ConfQA models",
        "images": []
    },
    {
        "header": "14Full ablation study",
        "images": []
    }
]