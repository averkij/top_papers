[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x1.png",
                "caption": "Figure 1:Benchmarking the accuracy–throughput trade-offs between Efficient-DLM 8B and SOTA AR/dLMs, with accuracy averaged over 12 tasks across math, coding, and commonsense reasoning.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x2.png",
                "caption": "Figure 2:Visualizing continuous pretraining of dLMs with different attention patterns from pretrained AR models. (b) and (c) show bidirectional attention and block-wise attention without clean context, respectively, using a block size of 2 as an example. (d) illustrates the block-wise attention with clean context (using a block size of 2 as an example), wheredenotes attention among noisy tokens,denotes attention from noisy tokens to clean-context tokens, anddenotes attention within the clean context. (e) shows weight changes in the attention and feed-forward network (FFN) layers after training under these three attention patterns.",
                "position": 205
            }
        ]
    },
    {
        "header": "2Efficient-DLM: A Study of Attention Patterns",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x3.png",
                "caption": "Figure 3:The average accuracy achieved by different training–evaluation block size pairs.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x4.png",
                "caption": "Figure 4:The weight changes in attention and FFN layers after training with different block sizes.",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x5.png",
                "caption": "Figure 5:The average accuracy on six tasks of different evaluation block sizes under varying NFEs.",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x6.png",
                "caption": "Figure 6:(a) The average number of denoising steps required at each token position on GSM8K using diffusion Qwen2.5 1.5B with two different confidence thresholds, where \"None\" denotes one token per step. (b) The confidence distribution within a block across different denoising steps for an example from GSM8K, with red boxes marking tokens that are decoded. (c) The average loss at each token position within a block of size 16.",
                "position": 533
            }
        ]
    },
    {
        "header": "3Efficient-DLM: Position-dependent Token Masking",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x7.png",
                "caption": "Table 2:Comparing token masking schemes based on the average accuracy across six generation tasks under varying parallel decoding settings, measured in tokens per forward (TPF).",
                "position": 558
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x7.png",
                "caption": "Figure 7:The average masking probability of each token position within a block.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x8.png",
                "caption": "Figure 8:(a) The accuracy evolution on likelihood tasks during training. (b–d) The accuracy–NFE trade-offs across different generation tasks for models trained with varying token budgets.",
                "position": 646
            }
        ]
    },
    {
        "header": "4Analysis of Training Dynamics",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x9.png",
                "caption": "Figure 9:Visualizing the accuracy-throughput trade-off of different models across different generation tasks.",
                "position": 910
            }
        ]
    },
    {
        "header": "5Efficient-DLM: A New Family of Efficient dLMs",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x10.png",
                "caption": "Figure 10:Comparing the accuracy-throughput trade-off with Dream/LLaDA plus Fast-dLLM.",
                "position": 1127
            },
            {
                "img": "https://arxiv.org/html/2512.14067/x11.png",
                "caption": "Figure 11:Visualizing the accuracy-throughput trade-off under different batch sizes on the GSM8K dataset.",
                "position": 1130
            }
        ]
    },
    {
        "header": "Appendix BMore Benchmarks with SOTA AR LMs and dLMs",
        "images": []
    },
    {
        "header": "Appendix CThe Impact of Initial LR",
        "images": []
    },
    {
        "header": "Appendix DLoss Distributions across Tokens",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14067/x12.png",
                "caption": "Figure 12:Visualizing the loss distributions over token positions of AR models and dLMs.",
                "position": 1237
            }
        ]
    },
    {
        "header": "Appendix EAR-to-dLM Conversion via Parameter-Efficient Tuning",
        "images": []
    }
]