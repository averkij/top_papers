[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/figure/icon.png",
                "caption": "",
                "position": 142
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/x1.png",
                "caption": "Figure 1:ODYSSEY pipeline spans the entire process of a long-horizon task, including multi-modal semantic perception, map-aware global planning, geometry-constrained action grounding, and step-wise execution by a learned low-level policy.",
                "position": 221
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/x2.png",
                "caption": "Figure 2:An overview of the mobile manipulator policy and its two-stage training framework.",
                "position": 326
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/x3.png",
                "caption": "Figure 3:The robot system and real-world experiments",
                "position": 1139
            }
        ]
    },
    {
        "header": "5Conclusions and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALong-horizon Planner Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/x4.png",
                "caption": "Figure 4:Instance-level graph construct pipeline.",
                "position": 1620
            }
        ]
    },
    {
        "header": "Appendix BWhole-body Policy Training",
        "images": []
    },
    {
        "header": "Appendix CBenchmark Configurations",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08240/x5.png",
                "caption": "Figure 5:ARNOLD converted environments of four tasks.",
                "position": 2007
            },
            {
                "img": "https://arxiv.org/html/2508.08240/x6.png",
                "caption": "Figure 6:The continuous state monitoring of ARNOLD short-horizon tasks.",
                "position": 2047
            },
            {
                "img": "https://arxiv.org/html/2508.08240/x7.png",
                "caption": "Figure 7:ODYSSEY benchmark details. Including task type, scene, and object configuration details.",
                "position": 2058
            },
            {
                "img": "https://arxiv.org/html/2508.08240/x8.png",
                "caption": "Figure 8:Failure breakdown by environment type. Failures are categorized into reasoning, control, and navigation errors. Indoor tasks suffer more from language and control failures, while navigation becomes more challenging in outdoor scenarios.",
                "position": 2288
            },
            {
                "img": "https://arxiv.org/html/2508.08240/x9.png",
                "caption": "Figure 9:Prompt examples for task-level planning using LLM. The model is conditioned on a semantic instance graph and a goal instruction, and produces a structured list of atomic actions.",
                "position": 3282
            },
            {
                "img": "https://arxiv.org/html/2508.08240/x10.png",
                "caption": "Figure 10:Prompt examples for local manipulation guidance using VLM. Given an egocentric image and sub-task description, the model predicts a contact point and end-effector orientation under geometric constraints.",
                "position": 3285
            }
        ]
    },
    {
        "header": "Appendix DExperiment Details",
        "images": []
    }
]