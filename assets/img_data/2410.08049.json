[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08049/x1.png",
                "caption": "Figure 1:UniRepLKNet models learn universal representation across multiple modalities. Regarding precision and efficiency across image, audio, point Cloud, and time-series modalities, UniRepLKNet delivers better scaling abilities between performance and computation burdens. The latency is tested with an A100 GPU, batch size of 128, and full precision (fp32).",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x2.png",
                "caption": "",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x3.png",
                "caption": "",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x4.png",
                "caption": "",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x5.png",
                "caption": "Figure 2:TheEffective Receptive Field (ERF)of ResNet-50/101/152 and the large kernel (K) variants of ResNets, respectively. A more widely distributed dark area indicates a larger ERF. More layers (e.g., from ResNet-101 to ResNet-152) help little in enlarging ERFs. Instead, the large-kernel ConvNets effectively obtain large ERFs.",
                "position": 214
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3A Roadmap to Universal ConvNets",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08049/x6.png",
                "caption": "Figure 3:Architectural design of UniRepLKNet. A LarK Block comprises a Dilated Reparam Block proposed in this paper, an SE Block[63], an FFN, and Batch Normalization (BN)[64]layers. The only difference between a SmaK Block and a LarK Block is that the former uses a depth-wise 3√ó\\times√ó3 conv layer in replacement of the Dilated Reparam Block in the latter. Stages are connected by down-sampling blocks implemented by stride-2 dense 3√ó\\times√ó3 conv layers. We may flexibly arrange the blocks in different stages and the details of our provided instances are shown in TableIV.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x7.png",
                "caption": "Figure 4:An example of re-parameterizing a small kernel (e.g., 3√ó\\times√ó3) in TableII(b)into a large one (e.g., 7√ó\\times√ó7). We use the structural re-parameterization as previous practices[68,12].",
                "position": 522
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x8.png",
                "caption": "Figure 5:Illustration to convolution with small feature map and large kernel. Two outputs at adjacent locations only share a part of kernel weights. Translational equivariance does not strictly hold.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x9.png",
                "caption": "Figure 6:Dilated Reparam Block¬†(¬ß3.2.2) uses dilated small-kernel conv layers to enhance a non-dilated large-kernel layer. Such dilated layers are equivalent to a non-dilated conv layer with a larger sparse kernel, as shown from the parameter perspective so that the whole block can be equivalently transformed into a single large-kernel conv. This example showsKùêæKitalic_K=9, and we may use more dilated layers for largerKùêæKitalic_K.",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x10.png",
                "caption": "Figure 7:Options of the extra structures to increase the depth.",
                "position": 575
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix A: General Transformation from Dialted Convolution to Non-dilated Large-Kernel Convolution",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08049/x11.png",
                "caption": "Figure 8:Shape bias of ImageNet-22K-pretrained UniRepLKNet-L and RepLKNet-31L.",
                "position": 4506
            },
            {
                "img": "https://arxiv.org/html/2410.08049/x12.png",
                "caption": "Figure 9:Shape bias of ImageNet-1K and ImageNet-22K-pretrained RepLKNet-31B and Swin-B. This figure is directly taken from the supplementary material of RepLKNet without any modifications",
                "position": 4509
            }
        ]
    },
    {
        "header": "Appendix B: Training Configurations",
        "images": []
    },
    {
        "header": "Appendix C: Shape Bias",
        "images": []
    }
]