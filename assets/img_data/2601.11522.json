[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11522/x1.png",
                "caption": "Figure 1:The quantitative and qualitative results of UniX. Quantitative results show UniX’s superiority over existing unified and single-task medical foundation models in understanding and generation. Qualitatively, UniX enables multi-disease X-ray interpretation and high-fidelity medical image generation.",
                "position": 83
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11522/x2.png",
                "caption": "Figure 2:Model Architecture.UniX comprises two decoupled yet synergistic branches: an autoregressive understanding branch for semantic encoding, and a diffusion-based generation branch for visual synthesis. To enable effective collaboration between them, we introduce a cross-modal self-attention mechanism that allows semantic features to dynamically guide the generation process.Data Processing and Training Pipeline.To fully exploit the potential of this architecture, we design a rigorous data cleaning pipeline and a three-stage training strategy. This strategy progressively freezes the branches during different stages, ensuring efficient knowledge transfer and stable training.",
                "position": 131
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11522/x3.png",
                "caption": "Figure 3:Demonstration of Data Processing and Report Generation Efficacy.The application of large language models enables the purification of raw data by eliminating extraneous information. This process ensures that the model prioritizes and extracts pertinent information related to disease diagnosis.",
                "position": 538
            },
            {
                "img": "https://arxiv.org/html/2601.11522/x4.png",
                "caption": "Figure 4:Qualitative Examples from UniX.(A)-(C)illustrate the model’s precise control over the attributes of generated findings, including their severity and location. In(D), the model successfully synthesizes a complex radiographic scene containing multiple findings that are consistent with a full clinical report, highlighting its ability to process and integrate extensive contextual information.",
                "position": 728
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Ablations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]