[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19437/x1.png",
                "caption": "Figure 1:Benchmark performance of DeepSeek-V3 and its counterparts.",
                "position": 479
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19437/x2.png",
                "caption": "Figure 2:Illustration of the basic architecture of DeepSeek-V3.\nFollowing DeepSeek-V2, we adopt MLA and DeepSeekMoE for efficient inference and economical training.",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x3.png",
                "caption": "Figure 3:Illustration of our Multi-Token Prediction (MTP) implementation.\nWe keep the complete causal chain for the prediction of each token at each depth.",
                "position": 1074
            }
        ]
    },
    {
        "header": "3Infrastructures",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19437/x4.png",
                "caption": "Figure 4:Overlapping strategy for a pair of individual forward and backward chunks (the boundaries of the transformer blocks are not aligned).\nOrange denotes forward, green denotes \"backward for input\", blue denotes \"backward for weights\", purple denotes PP communication, and red denotes barriers.\nBoth all-to-all and PP communication can be fully hidden.",
                "position": 1204
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x5.png",
                "caption": "Figure 5:Example DualPipe scheduling for 8 PP ranks and 20 micro-batches in two directions.\nThe micro-batches in the reverse direction are symmetric to those in the forward direction, so we omit their batch ID for illustration simplicity.\nTwo cells enclosed by a shared black border have mutually overlapped computation and communication.",
                "position": 1226
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x6.png",
                "caption": "Figure 6:The overall mixed precision framework with FP8 data format. For clarification, only theLinearoperator is illustrated.",
                "position": 1335
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x7.png",
                "caption": "Figure 7:(a) We propose a fine-grained quantization method to mitigate quantization errors caused by feature outliers; for illustration simplicity, onlyFpropis illustrated.\n(b) In conjunction with our quantization strategy, we improve the FP8 GEMM precision by promoting to CUDA Cores at an interval ofNC=128subscriptùëÅùê∂128N_{C}=128italic_N start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT = 128elements MMA for the high-precision accumulation.",
                "position": 1374
            }
        ]
    },
    {
        "header": "4Pre-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19437/x8.png",
                "caption": "Figure 8:Evaluation results on the ‚ÄùNeedle In A Haystack‚Äù (NIAH) tests.\nDeepSeek-V3 performs well across all context window lengths up to 128K.",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x9.png",
                "caption": "Figure 9:Expert load of auxiliary-loss-free and auxiliary-loss-based models on three domains in the Pile test set.\nThe auxiliary-loss-free model shows greater expert specialization patterns than the auxiliary-loss-based one.\nThe relative expert load denotes the ratio between the actual expert load and the theoretically balanced expert load.\nDue to space constraints, we only present the results of two layers as an example, with the results of all layers provided in AppendixC.",
                "position": 2546
            }
        ]
    },
    {
        "header": "5Post-Training",
        "images": []
    },
    {
        "header": "6Conclusion, Limitations, and Future Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AContributions and Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix BAblation Studies for Low-Precision Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19437/x10.png",
                "caption": "Figure 10:Loss curves comparison between BF16 and FP8 training.\nResults are smoothed by Exponential Moving Average (EMA) with a coefficient of 0.9.",
                "position": 5111
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x11.png",
                "caption": "(a)Layers 1-7",
                "position": 5148
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x12.png",
                "caption": "(b)Layers 7-13",
                "position": 5151
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x13.png",
                "caption": "(c)Layers 13-19",
                "position": 5154
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x14.png",
                "caption": "(d)Layers 19-25",
                "position": 5157
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x15.png",
                "caption": "(e)Layers 25-27",
                "position": 5160
            },
            {
                "img": "https://arxiv.org/html/2412.19437/x15.png",
                "caption": "(e)Layers 25-27",
                "position": 5161
            }
        ]
    },
    {
        "header": "Appendix CExpert Specialization Patterns of the 16B Aux-Loss-Based and Aux-Loss-Free Models",
        "images": []
    }
]