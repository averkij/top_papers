[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01123/x1.png",
                "caption": "Figure 1:AIME 2024: Accuracy vs. sequential budgetBseqB_{\\mathrm{seq}}.\nWe compare Long CoT,\\SR, and\\PDR; the dashed curve is an oracle upper bound (Oracle-\\PDR) that perfectly transmits any correct solutions under the same budgets to the compact workspace.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x2.png",
                "caption": "Figure 2:(a)Parallel-Distill-Refine (\\PDR). In roundrr, the model generatesMrM_{r}parallel drafts, then distills them into a compact workspace using one of the schemes in (b); the refined state seeds the next round. (b) Distillation schemes used to build the workspace (e.g., global summary, shared top-kk, per-sample top-kk, random-kk). (c) Three inference regimes. Top-Long chain-of-thought: a single, long trace. Middle-Sequential Refinement (SR): one draft updated over short rounds. Bottom-\\PDR: each round spawnsMrM_{r}drafts, distills into a workspace, and refines. The example shows a 3-round configurationM=(8,4,1)M=(8,4,1)(configuration is a hyperparameter, and any other choice is possible). Across panels, the per-callsequential budgetBseqB_{\\mathrm{seq}}(latency proxy) is held fixed, while\\PDRincreasestotal computeBtotalB_{\\mathrm{total}}via parallelism without increasing per-call context.",
                "position": 151
            }
        ]
    },
    {
        "header": "2Background & Related Work",
        "images": []
    },
    {
        "header": "3LLMs as Improvement Operators",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01123/x3.png",
                "caption": "Figure 3:AIME 2024: Iterative improvement beats single-pass long-CoT at matched sequential budgets.Thexx-axis reportsBseqB_{\\mathrm{seq}}: the thinking tokens consumed along the accepted path of the iterative chain, plus any distilled summary that conditions the next step. Tokens spent on unused parallel proposals are excluded, soBseqB_{\\mathrm{seq}}serves as a latency proxy. At comparableBseqB_{\\mathrm{seq}}, both\\SRand\\PDRoutperform the single-pass long CoT baseline, with\\PDRyielding the largest gains by converting additional total compute (via parallelism) into accuracy without increasing per-call context.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x4.png",
                "caption": "",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x5.png",
                "caption": "Figure 4:Token Budgets comparison:We plot all the different configurations for Long CoT,\\SRand\\PDRoperators for bothBseqB_{\\text{seq}}andBtotalB_{\\text{total}}token budgets forgemini-2.5-flash. ForBseqB_{\\text{seq}},\\PDRforms the Pareto-frontier and gives consistent gains over Long CoT and\\SR. However, forBtotalB_{\\text{total}},\\SRforms the pareto-frontier because there are no parallel drafts involved so no generations are discarded.",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x6.png",
                "caption": "",
                "position": 505
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x7.png",
                "caption": "Figure 5:AIME 2024: Long CoT,\\SR, and\\PDRat thinking budget of 24576.Thexx-axis reportsBseqB_{\\mathrm{seq}}: the thinking tokens consumed along the accepted path of the iterative chain, plus any distilled summary that conditions the next step. Tokens spent on unused parallel proposals are excluded, soBseqB_{\\mathrm{seq}}serves as a latency proxy. At a token matched budget of442​k442ktokens,\\SRhas a score of 90.4 butBseqB_{\\mathrm{seq}}of442​k442k, whereas\\PDRhas a score of 90.6 butBseqB_{\\mathrm{seq}}of172​k172ktokens.",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x8.png",
                "caption": "Figure 6:AIME 2024: Anchoring bias due to++ve and−-ve examples:With\\PDRwe compare three selection policies for the summary: Random-kk, Oracle-Incorrect (allkkcandidates are incorrect), and Oracle-Correct (allkkcandidates are correct), evaluated on bothgemini-2.5-flashando3-mini. Across all thinking budgets, admitting only incorrect candidates into the summary yields a pronounced drop in accuracy, whereas admitting only correct candidates improves over the Random-kkbaseline. The degradation under Oracle-Incorrect is larger foro3-minithan forgemini-2.5-flash, indicating weaker self-verification ino3-mini.",
                "position": 626
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Related Work",
        "images": []
    },
    {
        "header": "Appendix BPrompts",
        "images": []
    },
    {
        "header": "Appendix CComplexity of Space-bounded computation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01123/x9.png",
                "caption": "Figure 7:Space-bounded Turing Machine [Figure fromComputational Complexityby Arora and Barak, 2007]. The input has sizeNNand the machine has read-only capability for the input. A special “tape head” can be moved over the input to read bits from it. The amount of working memory (read/write/erase) for actual computation has sizeS​(N)S(N)whereS​(N)≥log⁡NS(N)\\geq\\log N.",
                "position": 1742
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01123/x10.png",
                "caption": "Figure 8:AIME 2025: Anchoring bias due to++ve and−-ve examples:With\\PDRwe compare three selection policies for the summary: Random-kk, Oracle-Incorrect (allkkcandidates are incorrect), and Oracle-Correct (allkkcandidates are correct), evaluated on bothgemini-2.5-flashando3-mini. Across all thinking budgets, admitting only incorrect candidates into the summary yields a pronounced drop in accuracy, whereas admitting only correct candidates improves over the Random-kkbaseline. The degradation under Oracle-Incorrect is markedly larger foro3-minithan forgemini-2.5-flash, indicating weaker self-verification ino3-mini.",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x11.png",
                "caption": "Figure 9:AIME 2025: Iterative improvement beats single-pass long-CoT at matched sequential budgets.Thexx-axis reportsBseqB_{\\mathrm{seq}}: the thinking tokens consumed along the accepted path of the iterative chain, plus any distilled summary that conditions the next step. Tokens spent on unused parallel proposals are excluded, soBseqB_{\\mathrm{seq}}serves as a latency proxy. At comparableBseqB_{\\mathrm{seq}}, both\\SRand\\PDRoutperform the single-pass long CoT baseline, with\\PDRyielding the largest gains by converting additional total compute (via parallelism) into accuracy without increasing per-call context.",
                "position": 1765
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x12.png",
                "caption": "",
                "position": 1769
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x13.png",
                "caption": "Figure 10:Token Budgets comparison:We plot all the different configurations for Long CoT,\\SRand\\PDRoperators for bothBseqB_{\\text{seq}}andBtotalB_{\\text{total}}token budgets foro3-mini. For bothBseqB_{\\text{seq}}andBtotalB_{\\text{total}},\\PDRforms the pareto-frontier and gives consistent gains over Long CoT and\\SR.",
                "position": 1785
            },
            {
                "img": "https://arxiv.org/html/2510.01123/x14.png",
                "caption": "",
                "position": 1789
            }
        ]
    },
    {
        "header": "Appendix EMechanics of Improvement operator: Source of accuracy gain",
        "images": []
    }
]