[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Short Survey",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.03912/x1.png",
                "caption": "Figure 1:Key Design of Dual-System VLAs.It mainly includes: MMLM Selection, Policy Selection, Latent Feature Representation Selection, MLLM Training Strategy, Policy Training Strategy, Dual-System Integration Strategy, and Dual-System Asynchronous Strategy.",
                "position": 243
            }
        ]
    },
    {
        "header": "2Empirical Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.03912/x2.png",
                "caption": "Figure 2:Three Different Evaluation Environments.",
                "position": 318
            },
            {
                "img": "https://arxiv.org/html/2505.03912/extracted/6416779/figtex/figures/Comparasion_VLM.png",
                "caption": "Figure 3:Three Different MLLM Training Strategy.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2505.03912/x3.png",
                "caption": "Figure 4:Evaluations on hierarchical inference.We evaluate the performance of the dual system on the CALVIN benchmark, with inference steps set to 1 and 60, respectively.‚ÄúSteps\" refers to the inference steps of action policy during a single MLLM inference step. The longest environmental steps of the action policy[11]are 60, which means MLLM only inference once and represents the most typical asynchronous scenarios.",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2505.03912/x4.png",
                "caption": "Figure 5:Evaluation on the shortcoming of existing dual systems.From top to bottom, the first row displays the input to the MLLM. The second row visualizes a special scenario where, at environment step 3, the blue block is manually shifted to the left. In the third row, we present the top 10 words that are semantically closest to the latent embedding. The bottom row illustrates the probability distribution of spatial words associated with the latent embedding.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2505.03912/",
                "caption": "Figure 6:Overview of our proposed Dual System VLA.",
                "position": 910
            },
            {
                "img": "https://arxiv.org/html/2505.03912/x6.png",
                "caption": "Figure 7:Detailed framework.(a) The high-level MLLM (left) takes third-view RGBo‚Ä≤superscriptùëú‚Ä≤o^{\\prime}italic_o start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT, task instructionlùëôlitalic_l, and a learnable token<ACT>as input. After processing through the Large Language Model (LLM), we extract the feature embedding from the final layer of the<ACT>token as the latent goal for the low-level policy. To fully leverage the MLLM‚Äôs multimodal reasoning capability, we propose an auxiliary task, using MLPs to predict the action (locationalsuperscriptùëéùëôa^{l}italic_a start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT, rotationarsuperscriptùëéùëüa^{r}italic_a start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT, open/closeagsuperscriptùëéùëîa^{g}italic_a start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT) based on this feature embeddingz<ACT>superscriptùëß<ACT>z^{{\\texttt{<ACT>}}}italic_z start_POSTSUPERSCRIPT <ACT> end_POSTSUPERSCRIPT, ensuring it encapsulates both visual and textual information. (b) The low-level policy (right) receives the latent goal from the high-level MLLM, combines it with 3D scene tokensoùëúoitalic_oand proprioception tokencùëêcitalic_c, and iteratively predicts action noiseœµitalic-œµ\\epsilonitalic_œµto produce an accurate action trajectoryœÑùúè\\tauitalic_œÑand gripper stateagsuperscriptùëéùëîa^{g}italic_a start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT. Notably, our approach keep all parameters of the MLLM frozen and fine-tune the learnable prompt to adjust the MLLM‚Äôs output, significantly reducing training costs compared to previous methods.",
                "position": 913
            }
        ]
    },
    {
        "header": "3A Simple yet Effective Dual System VLA",
        "images": []
    },
    {
        "header": "4Discussion & Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]