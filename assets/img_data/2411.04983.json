[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/intro.png",
                "caption": "Figure 1:We presentDINO-WM, a method for training visual models by using pretrained DINOv2 embeddings of image frames (a). Once trained, given a target observationoTsubscriptùëúùëáo_{T}italic_o start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, we can directly optimize agent behavior by planning throughDINO-WMusing model-predictive control (b). The use of pretrained embeddings significantly improves performance over prior state-of-the-art world models (c).",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3DINO World Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04983/x1.png",
                "caption": "Figure 2:Architecture ofDINO-WM. Given observationsot‚àík:tsubscriptùëú:ùë°ùëòùë°o_{t-k:t}italic_o start_POSTSUBSCRIPT italic_t - italic_k : italic_t end_POSTSUBSCRIPT, we optimize the sequence of actionsat:T‚àí1subscriptùëé:ùë°ùëá1a_{t:T-1}italic_a start_POSTSUBSCRIPT italic_t : italic_T - 1 end_POSTSUBSCRIPTto minimize the predicted loss to the desired goalogsubscriptùëúùëîo_{g}italic_o start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT. All forward computation is done in the latent spacezùëßzitalic_z. HerepŒ∏subscriptùëùùúÉp_{\\theta}italic_p start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPTindicatesDINO-WM‚Äôs dynamics model, which is used for making future predictions.",
                "position": 164
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/env.png",
                "caption": "Figure 3:We evaluateDINO-WMon 5 environment suites, from left to right: PointMaze, Push-T, Two Room, Rope Manipulation, and Granular Manipulation.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/openloop4.png",
                "caption": "Figure 4:Openloop rollout of world models trained with various pre-trained encoders on Push-T and Granular environment. For each trajectory, the model is given the first frame as well as sequence of actions. The world models performs openloop rollout with these actions, and the images are reconstructed by a pre-trained decoder. For each environment, the bottom row denotes the ground truth.DINO-WM(Ours) rollouts are bolded and are visually indistinguishable from the ground truth observations.",
                "position": 357
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/plan_results2.png",
                "caption": "Figure 5:Planning visualizations for PointMaze, Push-T, and Granular, on randomly sampled initial and goal configurations. The task is defined by Start and Goal, denoting the initial and goal observations. Final shows the final state the system arrives at after planning with each world model. For comparison, we show the best performing world models DINO CLS and DreamerV3.",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/generalization_exps.png",
                "caption": "Figure 6:Training and testing visualizations for WallRandom, PushObj and GranularRandom. Test setups are highlighted in blue boxes, showcasing unseen configurations for assessing the model‚Äôs generalization ability.",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/avdc_comp.png",
                "caption": "Figure 7:Comparison of plans generated byDINO-WMand AVDC, a diffusion-based generative model.",
                "position": 573
            }
        ]
    },
    {
        "header": "5Conclusion, Limitations & Future Work",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/ac_avdc.png",
                "caption": "Figure 8:Openloop rollout on PushT with DINO-WM and action-conditioned AVDC (AVDC-AC). For each trajectory, the model is given the first frame as well as sequence of actions. The world models performs openloop rollout with these actions.",
                "position": 1769
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/plan_pusht_same_init.png",
                "caption": "Figure 9:Trajectories planned withDINO-WMon PushT with the same initial states but different goal states.",
                "position": 1901
            },
            {
                "img": "https://arxiv.org/html/2411.04983/extracted/5982932/figures/plan_pointmaze_same_init.png",
                "caption": "Figure 10:Trajectories planned withDINO-WMon PointMaze with the same initial states but different goal states.",
                "position": 1904
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]