[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17532/x1.png",
                "caption": "Figure 1:Comparison with other existing robustness enhancement approaches. (A) is based on implicit training/adaptation, which only considers the visual encoder feature alignment. (B) is ours, and we explicitly integrate the degradation-aware reasoning chain into MLLM.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17532/x2.png",
                "caption": "Figure 2:Overview ofRobust-R1. (A) Supervised Fine-Tuning (SFT): we train the model using reasoning data to equip it with basic degradation-aware reasoning capability; (B) Reinforcement Learning (RL): we propose two reward functions to (i) align precise degradation-aware space while (ii) adaptively scaling to suitable reasoning lengths based on degradation intensity.",
                "position": 217
            },
            {
                "img": "https://arxiv.org/html/2512.17532/x3.png",
                "caption": "Figure 3:Correlation between degradation intensity and reasoning chain length on Seed-1.5-VL(guo2025seed1). Higher degradation intensities require longer chains to maintain accuracy, even multi-step reasoning.",
                "position": 379
            },
            {
                "img": "https://arxiv.org/html/2512.17532/x4.png",
                "caption": "Figure 4:Data generation pipeline. Theoriginal imagesundergo various real-world processing stages, where multiple degradations are randomly added to obtaindegraded imagesand their corresponding degradation<TYPE>s. Based on these and the original question-answering pairs (QAs), the pipeline progressively generates<INFLUENCE>,<REASONING>, and<CONCLUSION>. Finally, the reasoning chain is scaling according to differentintensitiesto achieve optimal efficiency.",
                "position": 463
            }
        ]
    },
    {
        "header": "4Data Construction",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17532/x5.png",
                "caption": "Figure 5:Qualitative evaluation for anti-degradation. Ours (SFT and RL) can provide robust and efficient result.",
                "position": 920
            },
            {
                "img": "https://arxiv.org/html/2512.17532/x6.png",
                "caption": "Figure 6:Statistics analysis for (A)rdegr_{\\text{deg}}and (B)rlenr_{\\text{len}}.",
                "position": 1081
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    }
]