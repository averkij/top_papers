[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/Logos/neobabel_new_color.png",
                "caption": "",
                "position": 90
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x1.png",
                "caption": "",
                "position": 141
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x2.png",
                "caption": "",
                "position": 146
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x3.png",
                "caption": "",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x4.png",
                "caption": "Figure 1:NeoBabel establishes a new Pareto frontier in multilingual image generation performance, efficiency, and inclusivity.Left: GenEval English-only scores show thatNeoBabelmatches state-of-the-art models despite being 2–4× smaller. Right: On our multilingual benchmark extensions, m-GenEval and m-DPG,NeoBabeloutperforms the second-best model, demonstrating strong multilingual generalization.NeoBabelis fully open (weights, code, data) and supports six languages with consistent cross-lingual performance.",
                "position": 173
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2NeoBabel Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06137/x5.png",
                "caption": "Figure 2:NeoBabel: A Multilingual Open\nTower for Visual Generation.Regardless of modality, all input data is first tokenized and embedded into a unified input sequence.NeoBabelthen applies causal attention to text tokens and full attention within a discrete denoising diffusion framework for image tokens, ultimately generating the desired image. This design enablesNeoBabelto support a wide range of tasks, including text-to-image generation, text-guided inpainting and extrapolation, as well as cross-lingual image generation.",
                "position": 256
            }
        ]
    },
    {
        "header": "3NeoBabel Multilingual Datasets",
        "images": []
    },
    {
        "header": "4NeoBabel Training Stages: Learning Progression",
        "images": []
    },
    {
        "header": "5Multilingual Evaluation of Image Generation",
        "images": []
    },
    {
        "header": "6Results and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06137/x6.png",
                "caption": "Figure 3:m-GenEval benchmark comparison.Models such as Janus Pro and BLIP3-o rely on multilingual base LLMs but are trained solely on English image-generation data, leading to a sharp performance drop in non-English languages. In contrast,NeoBabelmaintains strong and consistent results across all six languages, demonstrating robust cross-lingual generalization. Here baseline models are ordered by parameter count.",
                "position": 997
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x7.png",
                "caption": "Figure 4:Qualitative evaluation ofNeoBabel.Each row is based on a single concept expressed in six different languages. For clarity, we show only one of the prompts (in one language) and present six images generated from its translated prompts in the other five languages. Across all languages,NeoBabeldelivers semantically accurate and visually cohesive outputs with reliable consistency.",
                "position": 1121
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x8.png",
                "caption": "Figure 5:Qualitative evaluation ofNeoBabel.Each row is based on a single concept expressed in six different languages. For clarity, we show only one of the prompts (in one language) and present six images generated from its translated prompts in the other five languages. No matter the language,NeoBabelconsistently produces semantically aligned, visually coherent results.",
                "position": 1131
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x9.png",
                "caption": "Figure 6:Multilingual image inpainting.NeoBabelsupports multilingual text-guided image inpainting, highlighting its potential for interactive and language-inclusive visual editing across diverse user groups.",
                "position": 1134
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x10.png",
                "caption": "Figure 7:Multilingual image extrapolation.NeoBabelsuccessfully performs text-guided image extrapolation using multilingual prompts. Given the middle image and two different multilingual prompts (for the left and right extensions),NeoBabelgenerates coherent visual completions on both sides, demonstrating extrapolation capability.",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2507.06137/x11.png",
                "caption": "Figure 8:Cross-Lingual Prompt Generation.Examples of code-switched prompts mixing three languages, along with images generated byNeoBabel. Top: English, Dutch and French. Bottom: Hindi, Persian and Chinese. English translations are shown below each prompt for reader convenience, they are not used as input.",
                "position": 1153
            }
        ]
    },
    {
        "header": "7Ablations and Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/progressive-training-merged.png",
                "caption": "Figure 9:Effect of Progressive Pretraining and Instruction Tuning.Performance on m-GenEval (top) and m-DPG (bottom) improves steadily across pretraining and instruction tuning stages. Pretraining at256×256256256256{\\times}256256 × 256yields significant gains—especially on m-DPG—when scaling to large multilingual datasets (Stage 2), followed by refinement using higher-quality data (Stage 3). Instruction tuning at512×512512512512{\\times}512512 × 512brings a substantial boost (e.g., +0.52 on m-GenEval) and further improvement by increasing the share of curated, instruction-aligned samples. These results highlight how scale drives broad generalization, while data quality and resolution are key for performance refinement.",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/boxplot_cosine_similarity_statistical_summaries.png",
                "caption": "Figure 10:Cross-Lingual Consistency (CLC) Score Distributions across Models.We show the distribution of CLC scores computed using EVA-CLIP (left column) and DINOv2 (right column), where higher values reflect greater consistency across languages. EVA-CLIP captures semantic similarity, while DINOv2 is more sensitive to visual structure and layout.NeoBabelachieves the highest scores under both backbones—particularly with DINOv2—demonstrating strong alignment in both meaning and visual form. Box widths reflect model size, showing that bigger models aren’t always more consistent.",
                "position": 1352
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/boxplot_cosine_similarity_statistical_summaries_dinov2_large.png",
                "caption": "",
                "position": 1361
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/code_mix_baselines_boxplot_english-first_clip.png",
                "caption": "Figure 11:Variation in Code Switching Similarity (CSS) Scores across Models.We report CSS scores for code-mixed prompts under two settings: English-first (left column) and English-second (right column), using EVA-CLIP (top row) and DINOv2 (bottom row) as backbones. Higher scores indicate stronger visual alignment with the reference image, while smaller EF–ES gaps suggest robustness to code-switch position.NeoBabelconsistently achieves higher medians and lower variance than larger baselines, especially under DINOv2, highlighting its effective and stable handling of multilingual prompts.",
                "position": 1378
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/code_mix_baselines_boxplot_english-first_clip.png",
                "caption": "",
                "position": 1381
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/code_mix_baselines_boxplot_english-second_clip.png",
                "caption": "",
                "position": 1385
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/code_mix_baselines_boxplot_english-first_dinov2.png",
                "caption": "",
                "position": 1390
            },
            {
                "img": "https://arxiv.org/html/2507.06137/extracted/6604934/assets/code_mix_baselines_boxplot_english-second_dinov2.png",
                "caption": "",
                "position": 1394
            }
        ]
    },
    {
        "header": "8Related Works",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06137/x12.png",
                "caption": "Figure 12:Qualitative Evaluation ofNeoBabel.Each row corresponds to a single concept expressed in six different languages: English, Chinese, Dutch, French, Hindi, and Persian.\nAlthough prompts are not shown for readability, all images were generated using translated versions of the same underlying prompt in each language.NeoBabelconsistently produces semantically aligned and visually coherent results across languages, highlighting its strong multilingual generation capabilities. We intentionally omit the prompts here due to their length, focusing instead on the visual consistency across languages.",
                "position": 2717
            }
        ]
    },
    {
        "header": "Appendix A",
        "images": []
    }
]