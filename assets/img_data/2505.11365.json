[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x1.png",
                "caption": "Figure 1:Pharedataset generation and LLMs evaluation methodology.",
                "position": 170
            }
        ]
    },
    {
        "header": "3Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x2.png",
                "caption": "Figure 2:Impact of prompt and input perturbations on hallucination-related tasks.A.Effect of user message confidence tone on model ability to debunk controversial claims. Each cell shows the average debunking accuracy score, and the models are sorted by increasing p-value for theÏ‡2superscriptðœ’2\\chi^{2}italic_Ï‡ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPTtest. Details about the statistics are reported in AppendixA.2.B.Impact of system prompt instructions (neutral vs. concise formulation) on model resistance to misinformation (see AppendixA.2for statistical details).C.Tool call accuracy under different input perturbations. Bars represent mean accuracy across all evaluated models, with error bars indicating 95% confidence intervals.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2505.11365/x3.png",
                "caption": "Figure 3:A.Generation pipeline for measuring attribute associations in open-ended generation tasks.B.CramÃ©râ€™s V association measure between base and extracted attributes, across stories generated by all models.C.Proportion of models achieving good self-coherency score (> 0.7) by base attribute.D.Examples of debatable associations and real-world patterns.",
                "position": 427
            },
            {
                "img": "https://arxiv.org/html/2505.11365/x4.png",
                "caption": "Figure 4:Resistance to harmful misguidance across all tested models.",
                "position": 472
            }
        ]
    },
    {
        "header": "4Perspectives",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails on Hallucinations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x5.png",
                "caption": "Figure 5:Scores per category, task and language for hallucinations aggregated over models.\nOverall thereâ€™s a performance variability on language but not necessarily consistent over the submodules, except for English which is most of the time better handled by LLMs.",
                "position": 2001
            }
        ]
    },
    {
        "header": "Appendix BDetails on Biases",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x6.png",
                "caption": "Figure 6:Number of models exhibiting strong associations (CramÃ©râ€™s V > 0.4) for each pair of attribute categories.",
                "position": 2375
            },
            {
                "img": "https://arxiv.org/html/2505.11365/x7.png",
                "caption": "Figure 7:Self-coherency scores per model across base attribute categories.",
                "position": 2385
            },
            {
                "img": "https://arxiv.org/html/2505.11365/x8.png",
                "caption": "Figure 8:Number of models exhibiting strong associations (CramÃ©râ€™s V > 0.4) for each pair of attribute categories.",
                "position": 2395
            }
        ]
    },
    {
        "header": "Appendix CPhare Performance by Model and Provider",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x9.png",
                "caption": "Figure 9:Performance over each Phare submodule for each model and provider.",
                "position": 2409
            }
        ]
    },
    {
        "header": "Appendix DScorers Details",
        "images": []
    },
    {
        "header": "Appendix ESample Generation",
        "images": []
    },
    {
        "header": "Appendix FInfluence of System Prompt on Tool Reliability",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/extracted/6452979/figures/tools/tools_usage_by_model_and_template.png",
                "caption": "Figure 23:Influence of System Prompt on Tool Reliability computed on the public and private splits of the dataset.",
                "position": 3352
            }
        ]
    },
    {
        "header": "Appendix GToken Usage and costs",
        "images": []
    },
    {
        "header": "Appendix HInfluence of Concisness Instructions on Misinformation",
        "images": []
    },
    {
        "header": "Appendix ICopyrights and Licensing",
        "images": []
    },
    {
        "header": "Appendix JHuman Preference vs. Phare Submodule Scores",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11365/x10.png",
                "caption": "Figure 24:Chatbot Arena ELO (higher is better) score against the Phare submodule scores of all models for each submodule.",
                "position": 3566
            }
        ]
    },
    {
        "header": "Appendix KModel List",
        "images": []
    }
]