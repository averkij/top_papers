[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14146/x1.png",
                "caption": "Figure 1:Training Data vs Averaged Performance across six general and five medical QA Datasets(tested with Claude-3-Haiku as the generator LLM).",
                "position": 138
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x2.png",
                "caption": "Figure 2:RAG has progressed from fixed or supervised retrieval to RL-based agentic methods. While prior work trains retrieval or generation jointly,s3focuses solely on the searcher, improving generation without tuning the generator LLM.",
                "position": 141
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x3.png",
                "caption": "Figure 3:Decomposition of Agentic RAG.End-to-end approaches fine-tune the entire model using the entire generation accuracy, making it difficult to isolate the contribution of search. In contrast,s3freezes the generator and trains only the searcher with Gain Beyond RAG (GBR), a novel reward that quantifies the added value of retrieved context over na√Øve RAG, enabling modular, efficient optimization.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x4.png",
                "caption": "Figure 4:Overview of thes3framework.The searcher iteratively generates queries, retrieves documents, and selects useful documents until completion. The final contextDs‚Å¢3subscriptùê∑ùë†3D_{s3}italic_D start_POSTSUBSCRIPT italic_s 3 end_POSTSUBSCRIPTis then passed to a frozen generator LLM. The searcher is trained using Gain Beyond RAG (GBR), which quantifies improvement over na√Øve top-kùëòkitalic_kretrieval from the original question.",
                "position": 186
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3s3: OptimizedSearch-Select-Serve Flow with Reinforcement Learning",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14146/x5.png",
                "caption": "Figure 5:Reward Curves for topk={3,5,8}ùëò358k=\\{3,5,8\\}italic_k = { 3 , 5 , 8 }and#‚Å¢turns={3,4}#turns34\\#\\text{turns}=\\{3,4\\}# turns = { 3 , 4 }. The maximum selection is kept as 3.",
                "position": 1708
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x6.png",
                "caption": "Figure 6:Ablation study on s3 components.Each row corresponds to a different configuration of Retrieval:Selection:Turns = 8:3:3, 5:3:3, and 3:3:3. The first six columns report generation accuracy.‚ÄúBegin with Search‚Äùrefers to initializing the first query with the original question.‚ÄúDocument Selection‚Äùrefers to the selection step within the s3 loop (Step 3). We observe that removing Begin with Search leads to a significant drop in performance. While removing Document Selection sometimes yields better performance, the full s3 system still performs competitively‚Äîand most importantly, drastically reduces input token usage (2.6√ó\\times√ó‚àºsimilar-to\\sim‚àº4.2√ó\\times√óless tokens), improving overall efficiency.",
                "position": 1711
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Contents of Appendix",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BHuman Alignment Study of Evaluation Metrics (GenAcc and EM)",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.14146/x7.png",
                "caption": "Figure 8:Confusion matrices comparingGeneration Accuracy(top) andExact Match(bottom) against human judgment. Each cell indicates the proportion of samples falling into the corresponding category.",
                "position": 3039
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x8.png",
                "caption": "Figure 9:Scalability study: mean reward curve when trainings3(5-3-4) for 300 steps.",
                "position": 3048
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x8.png",
                "caption": "Figure 9:Scalability study: mean reward curve when trainings3(5-3-4) for 300 steps.",
                "position": 3051
            },
            {
                "img": "https://arxiv.org/html/2505.14146/x9.png",
                "caption": "Figure 10:Performance comparison at Step 20 vs. Step 300 across datasets.",
                "position": 3056
            }
        ]
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    },
    {
        "header": "Appendix DScalability Study",
        "images": []
    }
]