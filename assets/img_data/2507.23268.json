[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23268/x1.png",
                "caption": "",
                "position": 114
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x2.png",
                "caption": "",
                "position": 114
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23268/x3.png",
                "caption": "Figure 1:Selected256×256256\\times 256256 × 256and512×512512\\times 512512 × 512resolution samples.Generated from PixNerd-XL/16 trained on ImageNet256×256256\\times 256256 × 256resolution and ImageNet512×512512\\times 512512 × 512resolution with CFG = 3.5.",
                "position": 121
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x4.png",
                "caption": "Figure 2:The Text-to-Image512×512512\\times 512512 × 512visualization with text descriptions of different lengths and styles.Given text descriptions of different lengths and styles, PixNerd can generate promising samples with a large patch size of 16. We used Adams-2nd solver with 25 steps and a CFG value of 4.0 for sampling.",
                "position": 124
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x5.png",
                "caption": "Figure 3:Training-free arbitrary resolution generation.We keep the amount of tokens in PixNerd as constant as pretraining resolution, weonly interpolate the neural field coordinatesfor different resolutions to yield multi-resolution images.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.23268/x6.png",
                "caption": "Figure 4:The visualization Comparison with Baseline-L/16 under 400k training steps.With the help of neural field representation, our PixNerd-L/16 yields promising details and better structure.",
                "position": 411
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x7.png",
                "caption": "(a)REPA loss (DINOv2-B)",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x7.png",
                "caption": "(a)REPA loss (DINOv2-B)",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x8.png",
                "caption": "(b)Flow Matching Loss",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x9.png",
                "caption": "(a)Neural Field Normalization",
                "position": 436
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x9.png",
                "caption": "(a)Neural Field Normalization",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x10.png",
                "caption": "(b)Neural Field Channels",
                "position": 444
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x11.png",
                "caption": "(c)Neural Field MLPs layers",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x12.png",
                "caption": "(d)Coordinate-Encoding",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x13.png",
                "caption": "(e)Interval Guidance",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x14.png",
                "caption": "(f)Sampling Solver",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2507.23268/x15.png",
                "caption": "Figure 7:The Text-to-Image512×512512\\times 512512 × 512visualization with different solvers.We armed PixNerd with different ODE solvers, eg, Euler, Adams-2nd, Adams-3rd. Adams solver achieves better visual quality than the naive Euler solver. Also, thanks to the powerful text embedding in Qwen3 models, though we only trained PixNerd with English captions, PixNerd can generate samples of promising quality with other languages.",
                "position": 1329
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]