[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26788/x1.png",
                "caption": "Figure 1:Training reward comparison between BF16 and FP16. We evaluate across diverse settings: ourSanitytest (SectionÀú4) with various algorithms (GRPO, GSPO, TIS, MIS, PG); different model families (R1D, Qwen andOctoThinker); alternative fine-tuning methods (Lora); and larger scale models (Dense-14B,MoE). Results are validated on two independent frameworks (VeRL and Oat).",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Revisiting FP16 Precision",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26788/x2.png",
                "caption": "Figure 2:FP16 significantly reduces the training-inference mismatch. The left two plots show the token-level probability distribution, and the right two plots present the distribution of sequence-level log probability ratio between the inference policy (ùúá\\operatorname*{{\\color[rgb]{1,0,0}\\mu}}) and the training policy (ùúã\\operatorname*{{\\color[rgb]{0,0,1}\\pi}}).\nDashed lines in black denote perfect precision without mismatch.",
                "position": 463
            }
        ]
    },
    {
        "header": "4A Sanity Test for RL Algorithms",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26788/x3.png",
                "caption": "Figure 3:Simply switching from BF16 to FP16 stabilizes and prolongs RL training. The basic importance-weighted policy gradient algorithm in FP16 outperforms all baselines in BF16. Note that the third metric reported in each row slightly differs in implementation due to the use of separate codebases (VeRL and Oat). These metrics are semantically similar, and the minor differences do not affect our conclusions.",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2510.26788/x4.png",
                "caption": "Figure 4:Comparisons between various algorithms based on FP16.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2510.26788/x5.png",
                "caption": "Figure 5:Ablation on the precision combinations.",
                "position": 587
            }
        ]
    },
    {
        "header": "5Generalization Across Models, Data, and Training Regimes",
        "images": []
    },
    {
        "header": "6Discussions",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26788/x6.png",
                "caption": "Figure 6:Evaluation comparisons between BF16 and FP16 across various frameworks, algorithms, datasets and training regimes.",
                "position": 1421
            }
        ]
    },
    {
        "header": "Appendix BMore Experimental Results",
        "images": []
    }
]