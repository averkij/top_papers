[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Overview of neural scaling laws",
        "images": []
    },
    {
        "header": "4The2222-simplicial Transformer",
        "images": []
    },
    {
        "header": "5Determinant based Trilinear Forms",
        "images": []
    },
    {
        "header": "6Model design",
        "images": []
    },
    {
        "header": "7Kernel Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.02754/extracted/6592001/images/2_simplical_tiling.png",
                "caption": "Figure 2:Left:Visualization of sliding window 2-simplical attention. EachQisubscript𝑄𝑖Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTattends to a[w⁢1,w⁢2]𝑤1𝑤2[w1,w2][ italic_w 1 , italic_w 2 ]shaped rectangle ofK𝐾Kitalic_K,K′superscript𝐾′K^{\\prime}italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT.Right:Tiling to reduce\n2-simplicial einsumQ⁢K⁢K′𝑄𝐾superscript𝐾′QKK^{\\prime}italic_Q italic_K italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPTto elementwise mulQ⁢K′𝑄superscript𝐾′QK^{\\prime}italic_Q italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPTon CUDA core and tiled matmul(Q⁢K′)⁢@⁢K𝑄superscript𝐾′@𝐾(QK^{\\prime})@K( italic_Q italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) @ italic_Kon tensor core.",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2507.02754/extracted/6592001/images/2_simplical_flops.png",
                "caption": "Figure 3:FLOPs and Latencies of FAv3 vs 2-simplical attention",
                "position": 627
            },
            {
                "img": "https://arxiv.org/html/2507.02754/extracted/6592001/images/2_simplical_flops.png",
                "caption": "",
                "position": 630
            },
            {
                "img": "https://arxiv.org/html/2507.02754/extracted/6592001/images/2_simplical_latency.png",
                "caption": "",
                "position": 634
            }
        ]
    },
    {
        "header": "8Experiments & Results",
        "images": []
    },
    {
        "header": "9Discussion",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    },
    {
        "header": "11Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARotation invariant trilinear forms",
        "images": []
    },
    {
        "header": "Appendix BTriton Kernel: Forward pass for 2-simplicial Attention",
        "images": []
    },
    {
        "header": "Appendix CTriton Kernel: Backward pass for 2-simplicial Attention",
        "images": []
    }
]