[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24824/figures/phdv2_figures/figure1_activation_origin_loop.drawio.png",
                "caption": "(a)Inference pipeline in vanilla loop transformer",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2510.24824/figures/phdv2_figures/figure1_activation_origin_loop.drawio.png",
                "caption": "(a)Inference pipeline in vanilla loop transformer",
                "position": 178
            },
            {
                "img": "https://arxiv.org/html/2510.24824/figures/phdv2_figures/figure1_activation_ours_loop.drawio.png",
                "caption": "(b)Inference pipeline in proposed PLT .",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2510.24824/figures/phdv2_figures/main_graph.png",
                "caption": "Figure 2:Training and inference pipeline of PLT with loop countL=3L{=}3.Training (Left):Same Colored boxes trace how input tokens traverse the loops to predict their targets (e.g., tokenT1T_{1}passes three loops to predictT4T_{4}, consistent with Figure1(b)). Training is parallel along thetokendimension and serial along theloopdimension.Inference (Right):Parallelized forward pass of PLT when decodingT4T_{4}andT5T_{5}in a Loop Transformer withL=3L{=}3. Because there are no horizontal (same-step, cross-loop) activation dependencies during training, computations within the same step (each row; see the blue dashed box) run in parallel during decoding.",
                "position": 232
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24824/x1.png",
                "caption": "Figure 3:Batch size vs latency on Seed-MoE (2.5B/60B) and PLT-2 (1.7B/40B).",
                "position": 1006
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Contributions and Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24824/x2.png",
                "caption": "(a)Dense latency.",
                "position": 1976
            },
            {
                "img": "https://arxiv.org/html/2510.24824/x2.png",
                "caption": "(a)Dense latency.",
                "position": 1979
            },
            {
                "img": "https://arxiv.org/html/2510.24824/x3.png",
                "caption": "(b)MoE latency.",
                "position": 1984
            },
            {
                "img": "https://arxiv.org/html/2510.24824/x4.png",
                "caption": "(c)Dense throughput.",
                "position": 1989
            },
            {
                "img": "https://arxiv.org/html/2510.24824/x5.png",
                "caption": "(d)MoE throughput.",
                "position": 1994
            }
        ]
    },
    {
        "header": "7Experiments opensource",
        "images": []
    }
]