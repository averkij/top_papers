[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x1.png",
                "caption": "Figure 1.VideoPainterenables plug-and-play text-guided video inpainting and editing for any video length and pre-trained Diffusion Transformer with masked video and video caption (user editing instruction).The upper part demonstrates the effectiveness ofVideoPainterin various video inpainting scenarios, including object, landscape, human, animal, multi-region (Multi), and random masks.\nThe lower section demonstrates the performance ofVideoPainterin video editing, including adding, removing, changing attributes, and swapping objects.\nIn both video inpainting and editing, we demonstrate strong ID consistency in generating long videos (Any Len.).Project Page:https://yxbian23.github.io/project/video-painter",
                "position": 74
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x2.png",
                "caption": "Figure 2.Framework Comparison.\nNon-generative approaches, limited to pixel propagation from backgrounds, fail to inpaint fully segmentation-masked objects. Generative methods adapt single-branch image inpainting models to video by adding temporal attention, struggling to maintain background fidelity and generate foreground contents in one model. In contrast,VideoPainterimplements a dual-branch architecture that leverages an efficient context encoder with any pre-trained DiT, decoupling video inpainting to background preservation and foreground generation, and enabling plug-and-play video inpainting control.",
                "position": 164
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x3.png",
                "caption": "Figure 3.Dataset Construction Pipeline. It consists of five pre-processing steps: collection, annotation, splitting, selection, and captioning.",
                "position": 327
            }
        ]
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x4.png",
                "caption": "Figure 4.Model overview.The upper figureshows the architecture ofVideoPainter. The context encoder performs video inpainting based on concatenation of the noisy latent, downsampled masks, and masked video latent via VAE. Features extracted by the context encoder are integrated into the pre-trained DiT in a group-wise and token-selective manner, where two encoder layers modulate the first and second halves of the DiT, respectively, and only the background tokens will be integrated into the backbone to prevent information ambiguity.The lower figureillustrates the inpainting ID region resampling with the ID Resample Adapter. During training, tokens of the current masked region are concatenated to the KV vectors, enhancing ID preservation of the inpainting region. During inference, the ID tokens of the last clip are concatenated to the current KV vectors, maintaining ID consistency with the last clip by resampling.",
                "position": 338
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x5.png",
                "caption": "Figure 5.Comparison of previous inpainting methods andVideoPainteron standard and long video inpainting. More visualizations are in the demo video.",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2503.05639/x6.png",
                "caption": "Figure 6.Comparison of previous editing methods and VideoPainter on standard and long video editing.\nMore visualizations are in the demo video.",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2503.05639/x7.png",
                "caption": "Figure 7.IntegratingVideoPainterto Gromit-style LoRA(Cseti,2024).",
                "position": 1027
            }
        ]
    },
    {
        "header": "5.Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05639/x8.png",
                "caption": "Figure 8.More video inpainting results.",
                "position": 1966
            },
            {
                "img": "https://arxiv.org/html/2503.05639/x9.png",
                "caption": "Figure 9.More video editing results.",
                "position": 1969
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]