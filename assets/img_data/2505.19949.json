[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19949/x1.png",
                "caption": "Figure 1:An illustration of our key findings towards the question:Which attributes of training data effectively stimulate reasoning capabilities?Mixing challenging math problems with easier coding tasks leads to the highest influence scores for mathematical and coding reasoning (left). Guided by this insight, we curate an improved dataset and observe enhanced performance (right).",
                "position": 97
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19949/x2.png",
                "caption": "Figure 2:Cross-domain influence analysis of LLaMA3-8B-Base fine-tuned on combined MetaMathQA and OSS-Instruct for math and code performance. The most beneficial examples for math performance predominantly come from the math domain, while code-domain data also contributes non-trivially (left). A similar cross-domain benefit is observed for code performance (right).",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x3.png",
                "caption": "Figure 3:Average influence score of the training dataset combining MetaMathQA and OSS-Instruct, evaluated on MBPP and GSM8K performance. Results are grouped by training data category (left) and MATH problem difficulty (right).",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x4.png",
                "caption": "Figure 4:Different types of MATH questions from MetaMathQA[39]dataset.",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x5.png",
                "caption": "Figure 5:Left:Average influence scores of math and code training data from varying difficulty levels on reasoning performance. For instance, Math‚Üíabsent‚Üí\\xrightarrow{}start_ARROW start_OVERACCENT end_OVERACCENT ‚Üí end_ARROWCode denotes the influence of math data on code reasoning tasks.Right:Distribution of math and code samples across difficulty levels in the BS17k dataset. The original distribution is shown alongside the adjusted distribution obtained via the difficulty-flip strategy. See Table1for a comparison of SFT results under different mixing strategies.",
                "position": 323
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x6.png",
                "caption": "Figure 6:Left:An example of long CoT illustrating cognitive behaviors: verification (systematic error-checking) and exploration (searching for another approach after reaching the correct answer).Right:Distribution of different cognitive behaviors in BS-17k training dataset and their average impact on math and code reasoning performance.",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x7.png",
                "caption": "Figure 7:Left:Visualization of top 5% influential tokens in math CoT.Right:Visualization of top 5% influential tokens in code CoT.",
                "position": 496
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADerivation of Influence Score",
        "images": []
    },
    {
        "header": "Appendix BCross Domain Influence Analysis in Long CoT Scenarios",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19949/x8.png",
                "caption": "Figure 8:Cross-domain influence analysis of Qwen2.5-7B-Instruct fine-tuned on Bespoke-Stratos-17k dataset for math and code reasoning performance.",
                "position": 1098
            }
        ]
    },
    {
        "header": "Appendix CRobustness onnùëõnitalic_n",
        "images": []
    },
    {
        "header": "Appendix DCase of Truncating Exploration Behavior",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19949/x9.png",
                "caption": "Figure 9:To assess whether the exploration behavior has a positive or negative impact, we use GPT-4o to truncate all exploration behaviors in the BS-17K dataset for SFT. If reasoning contains any searching for another approach after reaching correct answers, like \"Alternatively, maybe there‚Äôs a different way to approach the problem?\", the exploration content will be truncated.",
                "position": 1146
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x10.png",
                "caption": "Figure 10:Left:Exploration: When performing reasoning, seeking alternative approaches after reaching a correct answer. We capture this behavior and calculate the number of exploration steps by analyzing the content like \"Another way to look at this is‚Ä¶\" etc..Right:Verification: The behavior of reasoning from desired outcomes to initial inputs when performing reasoning. We capture and calculate the number of backward chaining instances by finding the content like \"To solve this equation, let‚Äôs start with what we want to prove\" etc..",
                "position": 1156
            },
            {
                "img": "https://arxiv.org/html/2505.19949/x11.png",
                "caption": "Figure 11:Left:Backtracking: The behavior of realizing a path won‚Äôt work and explicitly going back to try a different approach. We capture this behavior and calculate the number of backtracking steps by finding the content like \"This approach leads to a contradiction. Going back to the original equation‚Ä¶\"\netc..Right:Backward Chaining: The behavior of systematic error-checking when performing reasoning. We capture and calculate the number of backward chaining instances by finding the content like \"To ensure this solution is valid, I‚Äôll check if it satisfies all the given constraints.\" etc..",
                "position": 1159
            }
        ]
    },
    {
        "header": "Appendix EExamples for Reasoning Behaviors Classifier",
        "images": []
    }
]