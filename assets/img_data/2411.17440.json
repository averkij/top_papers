[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17440/x1.png",
                "caption": "Figure 2:Overview of the proposed ConsisID.Based onFindings of DiT, low-frequency facial information is embedded into the shallow layers, while high-frequency information is incorporated into the vision tokens within the attention blocks. The ID-preserving Recipe is applied to ease training and improve generalization. Thecross face,DropTokenandDropoutare executed based on probability.",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2411.17440/x2.png",
                "caption": "Figure 1:Examples of identity-preserving video generation (IPT2V) by our ConsisID.Given a reference image, our method can generate realistic and personalized human-centered videos while preserving identity.Redindicates that attributes in long instructions.",
                "position": 101
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17440/x3.png",
                "caption": "Figure 3:(a - e) Fourier spectrum of different id signal injection.The center area represents low frequencies and the surrounding area represents high frequencies.(f) Relative log amplitudes of Fourier transformed generated videos.A larger response value indicates a higher inclusion of frequency information. (a - f) verify the effect of our frequency decomposition.",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2411.17440/x4.png",
                "caption": "Figure 4:User Study between ConsisID and state-of-the-art methods.ConsisID is preferred by voters in all dimensions.",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2411.17440/x5.png",
                "caption": "Figure 5:Qualitative analysis between ConsisID and ID-Animator[15].ID-Animator can only generate videos of the face region, and the identity Preservation is poor (e.g., shape, texture). Additionally, it cannot generate specified content according to the text prompt (e.g., action, decoration, background). ConsisID achieves advantages in identity preservation, visual quality, motion amplitude, and text relevance. Moreover, our ConsistID can generate more frames rather than ID-Animator (49 480√ó\\times√ó720p frames v.s. 16 512√ó\\times√ó512p frames).",
                "position": 336
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17440/x6.png",
                "caption": "Figure 6:Effect of Different Components via Qualitative Analysis.Removing any component may result in the loss of high- or low-frequency facial information, or hinder the ability to modify video content based on the text prompt.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2411.17440/x7.png",
                "caption": "Figure 7:Effect of Different Control Signal Injection Way via Qualitative Analysis.Only (c), which injects both high & low-freq face signals into the suitable location, performs best.",
                "position": 366
            },
            {
                "img": "https://arxiv.org/html/2411.17440/x8.png",
                "caption": "Figure 8:Effect of the Inversion Stepstùë°titalic_t.Overall quality does not improve consistently astùë°titalic_tincreases, but first improves and then declines. This may be because the early steps are dominated by low frequency, whereas the later steps are dominated by high frequency.",
                "position": 517
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]