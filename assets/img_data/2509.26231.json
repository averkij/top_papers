[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26231/x1.png",
                "caption": "Figure 2:Comparison between our Implicit Multimodal Guidance (IMG) and existing editing-based alignment methods.a) Existing methods require additional editing operations that improve alignment in local regions but may compromise overall image quality. b) In contrast, IMG employs a re-generation-based alignment framework by manipulating diffusion conditioning features, ensuring pipeline simplicity and high-quality outputs.",
                "position": 86
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26231/x2.png",
                "caption": "Figure 3:Comparison with editing-based methods.We evaluate the performance of Instruct Pix2Pix[6]and SLD[70]with IMG. For Instruct Pix2Pix, the instructions are “add a woman” and “make the ball a rubber ball”, generated by our finetuned MLLM.",
                "position": 149
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x3.png",
                "caption": "Figure 4:Overview of the Implicit Multimodal Guidance (IMG) framework.Given an initial image that exhibits misalignments with its prompt, IMG begins by conducting an MLLM-driven misalignment analysis. Following this, IMG utilizes an Implicit Aligner to translate the initial image features into better-aligned features according to the MLLM’s guidance. Finally, these aligned image features are incorporated as new conditions to re-generate images with improved prompt-image alignment.",
                "position": 166
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26231/x4.png",
                "caption": "Figure 5:Qualitative comparison with base models and finetuning-based alignment methods.The first two rows show that IMG addresses various misalignment types across different prompts, while the last row shows that IMG resolves misalignment issues that challenge both models.",
                "position": 398
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x5.png",
                "caption": "Figure 6:Qualitative comparison with editing-based methods.IMG surpasses SLD in visual quality and image comprehension.",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x6.png",
                "caption": "Figure 7:Multi-round generation results.IMG continuously improves prompt-image alignment by executing multiple rounds.",
                "position": 563
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x7.png",
                "caption": "Figure 8:Dense prompt generation.We integrate IMG with FLUX[37]and compare it against leading community models, including Stable Diffusion 3.5 Large (SD3.5)[2], PixArt-σ\\sigma[7]and Playground v2.5[38], using complex dense prompts.",
                "position": 601
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26231/x8.png",
                "caption": "Figure 9:Detailed architecture of Implicit Aligner.Our Implicit Aligner contains 4 cross-attention layers and 2 linear layers. The number of color cubes here represents the token dimensions rather than the number of tokens.",
                "position": 1889
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x9.png",
                "caption": "Figure 10:Pseudo code of Implicit Aligner.Our Implict Aligner (1) projects MLLM features to the same dimension as image features; (2) conducts cross-attention between initial image features and projected MLLM features; and (3) processes attention outputs with a linear layer as aligned image features.",
                "position": 1892
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x10.png",
                "caption": "Figure 11:MLLM finetuning on instruction-based image data.We conduct finetuning on{\\{Original Image, Edited Prompt, Edit Instruction}\\}triplets from image editing datasets[6]to enhance MLLM’s comprehension on prompt-image misalignments.",
                "position": 1910
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x11.png",
                "caption": "Figure 12:Text response comparison of the original MLLM and our finetuned MLLM. The original MLLM primarily outlines an image generation process based on the prompt, while our finetuned MLLM emphasizes aligning the input image with the provided prompt, showcasing its misalignment detection capability.",
                "position": 1913
            }
        ]
    },
    {
        "header": "Appendix BObjective Derivation",
        "images": []
    },
    {
        "header": "Appendix CAdditional Quantitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26231/x12.png",
                "caption": "Figure 13:Comparison between MLLM-based editing and IMG.",
                "position": 2178
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x13.png",
                "caption": "Figure 14:Additional qualitative results by integrating IMG with FLUX.",
                "position": 2181
            },
            {
                "img": "https://arxiv.org/html/2509.26231/x14.png",
                "caption": "Figure 15:Additional qualitative results by integrating IMG with SDXL and SDXL-DPO.",
                "position": 2184
            }
        ]
    },
    {
        "header": "Appendix DAdditional Qualitative Results",
        "images": []
    }
]