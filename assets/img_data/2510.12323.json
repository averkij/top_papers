[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2The RAG-Anything Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12323/x1.png",
                "caption": "Figure 1:Overview of our proposed universal RAG framework RAG-Anything.",
                "position": 130
            }
        ]
    },
    {
        "header": "3Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12323/figs/Accuracy_by_Page_Range.png",
                "caption": "Figure 2:Performance evaluation across documents of varying lengths.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2510.12323/x2.png",
                "caption": "Figure 3:Multi-panel figure interpretation case. The query requires identifying cluster separation patterns from the style-space panel, while avoiding confusion from the adjacent content-space panel.",
                "position": 598
            },
            {
                "img": "https://arxiv.org/html/2510.12323/x3.png",
                "caption": "Figure 4:Financial table navigation case. The query involves locating the specific intersection of “Wages and salaries” row and “2020” column amid similar terminological entries.",
                "position": 605
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12323/x4.png",
                "caption": "Figure 5:Visual reasoning case. RAG-Anything correctly identifies \"-S-A\" as the lowest accuracy configuration, while baselines misinterpret spatial relationships.",
                "position": 965
            },
            {
                "img": "https://arxiv.org/html/2510.12323/x5.png",
                "caption": "Figure 6:Tabular navigation case. RAG-Anything locates the highest AUPRC value (0.506), while the compared approaches struggle with structural ambiguity.",
                "position": 974
            },
            {
                "img": "https://arxiv.org/html/2510.12323/figs/vision_analysis_prompt.png",
                "caption": "Figure 7:Vision analysis prompt for context-aware image interpretation and knowledge extraction.",
                "position": 993
            },
            {
                "img": "https://arxiv.org/html/2510.12323/figs/table_analysis_prompt.png",
                "caption": "Figure 8:Table analysis prompt for structured content decomposition and semantic understanding.",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2510.12323/figs/equation_analysis_prompt.png",
                "caption": "Figure 9:Equation analysis prompt for mathematical expression interpretation and integration.",
                "position": 1005
            },
            {
                "img": "https://arxiv.org/html/2510.12323/figs/accuracy_evaluation_prompt.png",
                "caption": "Figure 10:Accuracy evaluation prompt for consistent factual assessment across question types.",
                "position": 1012
            },
            {
                "img": "https://arxiv.org/html/2510.12323/x6.png",
                "caption": "Figure 11:Cross-modal noise case. All methods fail to retrieve the correct answer from the specified image, instead retrieving noisy textual evidence that misaligns with the structured visual content.",
                "position": 1035
            },
            {
                "img": "https://arxiv.org/html/2510.12323/x7.png",
                "caption": "Figure 12:Ambiguous table structure case. All methods fail to correctly parse the confusing table layout with merged cells and unclear column boundaries, leading to incorrect data extraction.",
                "position": 1038
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]