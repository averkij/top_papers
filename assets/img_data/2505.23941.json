[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/patterned_grid.png",
                "caption": "",
                "position": 29
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/dog_icon.png",
                "caption": "Figure 1:VLMs fail on 6 counting tasks (a–e & g) and one low-level vision task (f).",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/logo_examples/mercedes_benz-white-convertible_1152.png",
                "caption": "",
                "position": 205
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/full_examples/us_14_stripes.png",
                "caption": "",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/full_examples/chess_remove_piece.png",
                "caption": "",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/full_examples/sudoku_8_rows.png",
                "caption": "",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/full_examples/zonner_illusion_fake.png",
                "caption": "",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/full_examples/dice_C3.png",
                "caption": "",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/claude-35.png",
                "caption": "",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2505.23941/",
                "caption": "",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x3.png",
                "caption": "",
                "position": 323
            }
        ]
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x6.png",
                "caption": "Table 1:OurVLMBiaspresents natural, objective counting and identification questions while prior benchmarks insert biased statements into the prompt.",
                "position": 559
            }
        ]
    },
    {
        "header": "3TheVLMBiasBenchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x7.png",
                "caption": "Figure 2:Given a subject (e.g., Adidas logo), we first confirm thatallVLMs have sufficient knowledge about the subject via anIDandcountingsanity-check questions (a).\nThen, we test VLMs on the counterfactual image (b) and report its accuracy on the counting (Q1&Q2) and an Y/N identification task (Q3).\nFor all tasks, we test the hypothesis that the visual bias cues in thebackground(c) may be so strong that it cause VLMs to ignore the modified object and default to biased answers.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x8.png",
                "caption": "",
                "position": 761
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x9.png",
                "caption": "",
                "position": 792
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x10.png",
                "caption": "",
                "position": 793
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/dog_icon.png",
                "caption": "Figure 3:VLMs fail to detect subtle changes in counterfactuals (CF) and default tobiasedanswers.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/original_modifed/puma.png",
                "caption": "",
                "position": 881
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/original_modifed/modifed_puma.png",
                "caption": "",
                "position": 882
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/original_modifed/adidas.png",
                "caption": "",
                "position": 884
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/original_modifed/adidas-black-basketball-5.png",
                "caption": "",
                "position": 885
            }
        ]
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/transparent_o4mini.png",
                "caption": "Table 2:All VLMs achieve100%on identification and counting tasks with unmodified images, showing that they fully recognize the original version but fail on the counting questions on the modified images (i.e., counterfactuals) inVLMBias.\nThemean accuracyof five state-of-the-art VLMs on our seven tasks is17.05%.o4-miniachieves the highest accuracy (20.25%) which however is still low.\nVLMs with “thinking” capabilities (o4-mini,o3) only slightly outperform non-thinking models (Gemini-2.5Pro,Sonnet-3.7,GPT-4.1).",
                "position": 1145
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x17.png",
                "caption": "Figure 4:On thecounterfactualimages inVLMBias, five VLMs mostly output answers that match the biased choices that wepredefinefor each question,75.70%of the time, on average.This biased behavior is the most severe on the leftmost 6 tasks where there are existing prior knowledge on the Internet.\nPatterned gridis the only task where the visual pattern is created from scratch in this work.\nYet, VLMs still are biased43.45%of the time.",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/knight.png",
                "caption": "Figure 5:VLMs perform poorly atcountingelements on counterfactual images across,, anddomains, heavily defaulting to the biased answers.",
                "position": 1310
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/abtract_examples_1/xiangqi_pieces_003_remove_red_soldier_at_e7_notitle_px1152.png",
                "caption": "",
                "position": 1350
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/flag_examples/Flag_of_the_United_States-stripes=14_1152.png",
                "caption": "",
                "position": 1351
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/abtract_examples_1/sudoku_grid_02_row_add_last_row_notitle_px1152.png",
                "caption": "",
                "position": 1352
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/flag_examples/Flag_of_Europe-stars=11_1152.png",
                "caption": "",
                "position": 1353
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/abtract_examples_1/chess_grid_01_row_remove_first_row_notitle_px1152.png",
                "caption": "",
                "position": 1354
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/dog_icon.png",
                "caption": "Table 3:VLMs perform poorly across six (out of seven)VLMBiastasks, spanning photo-realistic images (animals andlogos) and abstract images (flag,chess pieces,optical illusions, andpatterned grids).",
                "position": 1563
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x1.png",
                "caption": "Table 4:Accuracy (%) of VLMs on questionQ3(e.g.., “Is this an animal with 4 legs?”) when the image is original (4 legs) or counterfactual (5 legs).\nVLMs mostly answer “Yes” even on counterfactuals, resulting in accuracy far below the 50% random baseline.",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x1.png",
                "caption": "Table 4:Accuracy (%) of VLMs on questionQ3(e.g.., “Is this an animal with 4 legs?”) when the image is original (4 legs) or counterfactual (5 legs).\nVLMs mostly answer “Yes” even on counterfactuals, resulting in accuracy far below the 50% random baseline.",
                "position": 1841
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x23.png",
                "caption": "Figure 6:Original vs. modified versions without (top) and with (bottom) the in-image text (“Ebbinghaus illusion”).",
                "position": 1906
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x1.png",
                "caption": "Table 5:Adding adversarial, in-image textual cues that state the subject name (e.g., “Adidas”) cause VLMs to decrease their accuracy (-4.49) on counterfactual images (b).\nIn contrast, instructing VLMs to rely exclusively on the image details to answer questions (Debiased) or to double-check its answers (Double-Check) only slightly improves accuracy, by+1.87and+2.70, respectively (c).",
                "position": 1932
            }
        ]
    },
    {
        "header": "5Discussion and Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x27.png",
                "caption": "",
                "position": 2059
            }
        ]
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Table of Contents",
        "images": []
    },
    {
        "header": "Appendix AIllustrative questions",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/dog_icon.png",
                "caption": "Table 6:Some examples of questions onanimal,brand logos, andflags",
                "position": 3249
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/knight.png",
                "caption": "Table 7:Some examples of questions onchesse pieces,game boards andpatterned grid.",
                "position": 3408
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/illusion_icon.png",
                "caption": "Table 8:Some examples of questions onoptical illusions.",
                "position": 3567
            }
        ]
    },
    {
        "header": "Appendix BModels and access details",
        "images": []
    },
    {
        "header": "Appendix CTask 1: Counting legs with added limb",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x28.png",
                "caption": "Figure 7:Data generation pipeline for Task 1: Counting legs with added limb.",
                "position": 3759
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x29.png",
                "caption": "",
                "position": 3814
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x30.png",
                "caption": "",
                "position": 3820
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/dog_icon.png",
                "caption": "Figure 8:VLMs are often biased toward the original number of legsanimals have, and they tend to answer based on prior knowledge rather than by analyzing the image.",
                "position": 3932
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/lion_0_0_768.png",
                "caption": "",
                "position": 3969
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/stork_2_1_768.png",
                "caption": "",
                "position": 3970
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/african_elephant_2_0_768.png",
                "caption": "",
                "position": 3971
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/duck_0_3_768.png",
                "caption": "",
                "position": 3972
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/domestic_dog_4_3_768.png",
                "caption": "",
                "position": 3973
            }
        ]
    },
    {
        "header": "Appendix DTask 2: Counting elements in modified brand logos",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x33.png",
                "caption": "Figure 9:Data generation pipeline of shoe logos for Task 2: Counting elements in modified brand logos",
                "position": 4204
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x34.png",
                "caption": "Figure 10:Data generation pipeline of car logos for Task 2: Counting elements in modified brand logos",
                "position": 4208
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/logo.png",
                "caption": "Figure 11:VLMs are often biased and rely on prior knowledge when answering questions aboutshoe logos, even with simple ones like the Nike Swoosh. Please zoom in to see the logo clearly.",
                "position": 4212
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/shoe_logos/adidas-red-running-5_1152.png",
                "caption": "",
                "position": 4251
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/shoe_logos/nike-black-soccer-1_1152.png",
                "caption": "",
                "position": 4252
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/shoe_logos/adidas-black-tennis-1_1152.png",
                "caption": "",
                "position": 4253
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/shoe_logos/nike-white-basketball-1_1152.png",
                "caption": "",
                "position": 4254
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/shoe_logos/adidas-white-soccer-4_1152.png",
                "caption": "",
                "position": 4255
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/logo.png",
                "caption": "Figure 12:VLMs are completely biased and rely entirely on prior knowledge when answering questions aboutbrand logos. Please zoom in to see the logo clearly.",
                "position": 4846
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/car_logo_examples/audi-gray-convertible_1152.png",
                "caption": "",
                "position": 4885
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/car_logo_examples/mercedes_benz-white-coupe_1152.png",
                "caption": "",
                "position": 4886
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/car_logo_examples/maserati-black-coupe_1152.png",
                "caption": "",
                "position": 4887
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/car_logo_examples/audi-black-convertible_1152.png",
                "caption": "",
                "position": 4888
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/car_logo_examples/mercedes_benz-gray-convertible_1152.png",
                "caption": "",
                "position": 4889
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/logo.png",
                "caption": "Figure 13:VLMs are often biased and rely on prior knowledge when answering questions aboutshoe logos, even with simple ones like the Nike Swoosh. Please zoom in to see the logo clearly.",
                "position": 5091
            }
        ]
    },
    {
        "header": "Appendix ETask 3: Counting stripes/stars in modified national flags",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x41.png",
                "caption": "Figure 14:Data generation pipeline for Task 3: Counting stripes/stars in modified national flags.",
                "position": 5343
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/flag.png",
                "caption": "Figure 15:VLMs are biased when counting the stars and stripes onnational flags.",
                "position": 5581
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/flag_examples/Flag_of_Europe-stars=13_1152.png",
                "caption": "",
                "position": 5622
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/flag_examples/Flag_of_Zimbabwe-stripes=6_1152.png",
                "caption": "",
                "position": 5623
            }
        ]
    },
    {
        "header": "Appendix FTask 4: Counting chess pieces on modified starting position",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x44.png",
                "caption": "Figure 16:Data generation pipeline for Task 4: Counting chess pieces on modified starting position",
                "position": 5832
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/chess_pieces_examples/chess_pieces_004_remove_blackbishop_at_c8_notitle_px1152.png",
                "caption": "Figure 17:VLMs are biased when counting the pieces onchess and xiangqi.",
                "position": 6131
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/chess_pieces_examples/chess_pieces_004_replace_blackbishop_to_blackpawn_at_c8_notitle_px1152.png",
                "caption": "",
                "position": 6167
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/chess_pieces_examples/xiangqi_pieces_006_remove_red_chariot_at_i10_notitle_px1152.png",
                "caption": "",
                "position": 6168
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/chess_pieces_examples/xiangqi_pieces_006_replace_red_chariot_to_red_general_at_i10_notitle_px1152.png",
                "caption": "",
                "position": 6169
            }
        ]
    },
    {
        "header": "Appendix GTask 5: Counting rows and columns of board game",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x47.png",
                "caption": "Figure 18:Data generation pipeline for Task 5: Counting rows and columns of board game",
                "position": 6343
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/task_icon/sudoku_icon.png",
                "caption": "Table 9:All VLMs’ performance is extremely low (2.26%) acrossgame boards, confirming that current VLMs are largely unable to perform even simple counting operations in structured visual settings",
                "position": 6500
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/game_board_examples/sudoku_grid_07_col_remove_first_col_notitle_px1152.png",
                "caption": "Figure 19:VLMs are biased when counting the rows and columns ongame boards.",
                "position": 6703
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/game_board_examples/go_grid_03_add_row_px1152.png",
                "caption": "",
                "position": 6738
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/game_board_examples/xiangqi_grid_04_row_add_row_in_river_bottom_notitle_px1152.png",
                "caption": "",
                "position": 6739
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/game_board_examples/chess_grid_02_row_remove_last_row_notitle_px1152.png",
                "caption": "",
                "position": 6740
            }
        ]
    },
    {
        "header": "Appendix HTask 6: Visual testing with both original and modified optical illusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x51.png",
                "caption": "Figure 20:Data generation pipeline for Task 6: Visual testing with both original and modified optical illusion",
                "position": 6914
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/MullerLyer_007_str45_diff0_notitle_px1152.png",
                "caption": "Figure 21:VLMs show systematic biases, often relying on prior knowledge aboutoptical illusions rather than directly interpreting the image.",
                "position": 7283
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/MullerLyer_023_str50_diff0p5_notitle_px1152.png",
                "caption": "",
                "position": 7336
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/Zollner_007_str65_diff0_notitle_px1152.png",
                "caption": "",
                "position": 7337
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/Zollner_021_str75_diff2p5_notitle_px1152.png",
                "caption": "",
                "position": 7338
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/Ebbinghaus_002_strneg3_diff0_notitle_px1152.png",
                "caption": "",
                "position": 7339
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/illusion_example/Ebbinghaus_016_strneg3_diffneg0p6_notitle_px1152.png",
                "caption": "",
                "position": 7340
            }
        ]
    },
    {
        "header": "Appendix ITask 7: Counting circles or lines in an anomaly cell within a patterned grid",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x54.png",
                "caption": "Figure 22:Data generation pipeline for Task 7: Counting circles or lines in an anomaly cell within a patterned grid",
                "position": 7588
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/patterned_grid_examples/dice_001_remove_C3_notitle_px1152.png",
                "caption": "Figure 23:All VLMs, exceptSonnet-3.7, fail to correctly identify the abnormal cell (C3) in both thepatterned grids.",
                "position": 7879
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/patterned_grid_examples/dice_001_replace_C3_notitle_px1152.png",
                "caption": "",
                "position": 7918
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/patterned_grid_examples/tally_001_remove_C3_notitle_px1152.png",
                "caption": "",
                "position": 7919
            },
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/patterned_grid_examples/tally_001_add_C3_notitle_px1152.png",
                "caption": "",
                "position": 7920
            }
        ]
    },
    {
        "header": "Appendix JQualitative results onanimals",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/animal_examples/chicken_0_3_768.png",
                "caption": "Figure 24:VLMs fail 100% of the time, even on simple tasks like counting chicken legs, despite helpful prompts such as debiasing or double-checking.",
                "position": 8096
            }
        ]
    },
    {
        "header": "Appendix KQualitative results onflags",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/extracted/6494441/images/flag_examples/Flag_of_the_United_States-stripes=12_1152.png",
                "caption": "Figure 25:VLMs fail and remain biased toward 13 even when one stripe is removed from the U.S. flag.",
                "position": 8130
            }
        ]
    },
    {
        "header": "Appendix LMore findings",
        "images": []
    },
    {
        "header": "Appendix MPrompts used for image generation and image editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23941/x65.png",
                "caption": "Table 10:Prompts used for image generation and image editing withGemini-2.0FlashandGPT-4oby topic and prompt type",
                "position": 8227
            },
            {
                "img": "https://arxiv.org/html/2505.23941/x67.png",
                "caption": "Table 11:Prompts used for image generation and image editing withGemini-2.0FlashandGPT-4oby topic and prompt type",
                "position": 8299
            }
        ]
    },
    {
        "header": "Appendix NQuestions for sanity check",
        "images": []
    }
]