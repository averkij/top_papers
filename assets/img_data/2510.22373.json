[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/x1.png",
                "caption": "Figure 1:The “Fidelity, Expressiveness, and Aesthetics” evaluation framework.",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x2.png",
                "caption": "Figure 2:From natural images to visualization: the need for specialized visualization assessment.Greenandreddenote positive and negative assessments, respectively, highlighting the contrast\nbetween MLLMs’ capabilities in general aesthetics versus visualization-specific evaluation.",
                "position": 190
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3VisJudge-Bench: Design and Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/x3.png",
                "caption": "Figure 3:VisJudge-Benchconstruction framework.",
                "position": 463
            }
        ]
    },
    {
        "header": "4VisJudge: A Specialized Model for Visualization Evaluation",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/x4.png",
                "caption": "Figure 4:Distribution and bias analysis of MLLM scores. Score distribution density curves showing the rating patterns of different models compared to human experts on the 1-5 scale.",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x5.png",
                "caption": "Figure 5:Model–Human rating correlation across visualization types.",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x6.png",
                "caption": "Figure 6:Model evaluation examples on low-quality visualizations.",
                "position": 1067
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x7.png",
                "caption": "Figure 7:Case study highlighting the conservative bias of Gemini-2.5-Pro.",
                "position": 1070
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x8.png",
                "caption": "(a)Training data scale vs. human-model correlation",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x8.png",
                "caption": "(a)Training data scale vs. human-model correlation",
                "position": 1082
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x9.png",
                "caption": "(b)Training data scale vs. prediction error",
                "position": 1087
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "LLM Usage Statement",
        "images": []
    },
    {
        "header": "Appendix ADataset Construction Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/figures/overall_score_distribution_large_font.png",
                "caption": "(a)",
                "position": 2385
            },
            {
                "img": "https://arxiv.org/html/2510.22373/figures/overall_score_distribution_large_font.png",
                "caption": "(a)",
                "position": 2388
            },
            {
                "img": "https://arxiv.org/html/2510.22373/figures/single_view_score_distribution_large_font.png",
                "caption": "(b)",
                "position": 2394
            },
            {
                "img": "https://arxiv.org/html/2510.22373/figures/multi_view_score_distribution_large_font.png",
                "caption": "(c)",
                "position": 2400
            },
            {
                "img": "https://arxiv.org/html/2510.22373/figures/dashboard_score_distribution_large_font.png",
                "caption": "(d)",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x10.png",
                "caption": "Figure 10:Representative samples fromVisJudge-Bench",
                "position": 2413
            },
            {
                "img": "https://arxiv.org/html/2510.22373/figures/clean_normal_distribution.png",
                "caption": "Figure 11:Quality score distributions across six evaluation dimensions.",
                "position": 2686
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x11.png",
                "caption": "Figure 12:Crowdsourcing interface for expert annotation process.",
                "position": 3151
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x12.png",
                "caption": "Figure 13:Examples of validation checks embedded in the crowdsourcing interface.",
                "position": 3217
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x13.png",
                "caption": "Figure 14:Expert review interface.",
                "position": 3231
            }
        ]
    },
    {
        "header": "Appendix BCase Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/x14.png",
                "caption": "Figure 15:High score cases.",
                "position": 3252
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x15.png",
                "caption": "Figure 16:Medium score cases.",
                "position": 3266
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x16.png",
                "caption": "Figure 17:Low score cases.",
                "position": 3280
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x17.png",
                "caption": "Figure 18:Low fidelity cases.",
                "position": 3292
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x18.png",
                "caption": "Figure 19:Low expressiveness cases.",
                "position": 3295
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x19.png",
                "caption": "Figure 20:Low aesthetics cases.",
                "position": 3298
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x20.png",
                "caption": "Figure 21:Overview of error cases.",
                "position": 3335
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x21.png",
                "caption": "Figure 22:Qwen2.5-VL-7B and GPT-5 error cases.",
                "position": 3338
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x22.png",
                "caption": "Figure 23:Gemini-2.0-Flash and Claude-3.5-sonnet error cases.",
                "position": 3341
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x23.png",
                "caption": "Figure 24:Claude-4-sonnet and GPT-4o error cases.",
                "position": 3344
            },
            {
                "img": "https://arxiv.org/html/2510.22373/x24.png",
                "caption": "Figure 25:Gemini-2.5-Pro error case.",
                "position": 3347
            }
        ]
    },
    {
        "header": "Appendix CEvaluation Framework and Criteria",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.22373/x25.png",
                "caption": "Figure 26:Rewriting result of customized evaluation questions and scoring criteria for a single visualization chart.",
                "position": 3431
            }
        ]
    },
    {
        "header": "Appendix DModel Implementation and Training Details",
        "images": []
    }
]