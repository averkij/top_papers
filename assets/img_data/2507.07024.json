[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07024/x1.png",
                "caption": "",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2507.07024/x2.png",
                "caption": "",
                "position": 236
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07024/x3.png",
                "caption": "Figure 1:An overview ofFlexOlmo.Data owners can contribute without sharing the data by training their own expert modules (FFNs and router embeddings) with a shared public model as an anchor point. At inference, these modules are integrated into a MoE model via a novel router embedding concatenation. This design enables flexible inclusion or exclusion of experts and strict opt-out guarantees, e.g., Github data can be excluded at no cost (blurred) during inference.",
                "position": 256
            }
        ]
    },
    {
        "header": "2Background & Related Work",
        "images": []
    },
    {
        "header": "3FlexOlmo: LMs with Flexible Data Use",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07024/extracted/6609847/figures/router.png",
                "caption": "Figure 2:Routing pattern analysis.\nWe visualize how text from different domains activate experts (four experts activated). The horizontal gray lines indicate uniform routing.",
                "position": 1150
            },
            {
                "img": "https://arxiv.org/html/2507.07024/extracted/6609847/figures/active_expert.png",
                "caption": "Figure 3:Effect of active expert count on MMLU performance.Model performance stabilizes after activating four experts.",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2507.07024/extracted/6609847/figures/active_expert.png",
                "caption": "Figure 3:Effect of active expert count on MMLU performance.Model performance stabilizes after activating four experts.",
                "position": 1158
            },
            {
                "img": "https://arxiv.org/html/2507.07024/extracted/6609847/figures/opt_out.png",
                "caption": "Figure 4:Opting out of news data. Removing the news expert reduces performance on NewsG with minimal impact on other tasks.",
                "position": 1163
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AModel Details",
        "images": []
    },
    {
        "header": "Appendix BData Details",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07024/extracted/6609847/figures/negative_bias.png",
                "caption": "Figure 6:During training, the negative bias shifts the decision boundary. So that a more selective subset of data will be used to train the expert corresponding toùíû1subscriptùíû1\\mathcal{C}_{1}caligraphic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.",
                "position": 3292
            }
        ]
    },
    {
        "header": "Appendix DMethodology Intuition",
        "images": []
    }
]