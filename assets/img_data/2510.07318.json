[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07318/x1.png",
                "caption": "(a)",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x1.png",
                "caption": "(a)",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x2.png",
                "caption": "(b)",
                "position": 100
            }
        ]
    },
    {
        "header": "1Instruction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07318/x3.png",
                "caption": "(a)",
                "position": 230
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x3.png",
                "caption": "(a)",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x4.png",
                "caption": "(b)",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x5.png",
                "caption": "(a)",
                "position": 358
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x5.png",
                "caption": "(a)",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x6.png",
                "caption": "(b)",
                "position": 366
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x7.png",
                "caption": "(c)",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x8.png",
                "caption": "(d)",
                "position": 376
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07318/x9.png",
                "caption": "Figure 4:AHN modules demonstrate strong context generalization capacity on LongBench.",
                "position": 1071
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x9.png",
                "caption": "Figure 4:AHN modules demonstrate strong context generalization capacity on LongBench.",
                "position": 1073
            },
            {
                "img": "https://arxiv.org/html/2510.07318/x10.png",
                "caption": "Figure 5:Green regions mark tokens with low L2 gradient magnitudes, indicating they are preferentially selected by AHN to store in the compressed memory; red denotes the opposite.",
                "position": 1138
            }
        ]
    },
    {
        "header": "5Conclusion and discussion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6AHN instantiation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07318/x11.png",
                "caption": "Figure 6:Illustration of the model augmented with Artificial Hippocampus Networks (AHNs). In this example, the number of attention sinks is 2, and the sliding window length is 3. When the input sequence length is less than or equal to the sum of attention sinks and the window length, the model operates identically to a standard Transformer. For longer sequences, AHNs continually compress the token outside the window into a compact memory representation. The model then utilizes the lossless information within the attention sinks and the sliding window, as well as the compressed memory to generate the next token.",
                "position": 2688
            }
        ]
    },
    {
        "header": "7Additional benchmark results",
        "images": []
    }
]