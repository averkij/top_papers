[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data Processing",
        "images": []
    },
    {
        "header": "3Model Design and Architecture",
        "images": []
    },
    {
        "header": "4Model Training",
        "images": []
    },
    {
        "header": "5Infrastructure",
        "images": []
    },
    {
        "header": "6Applications & Model Performance",
        "images": []
    },
    {
        "header": "7Related Works",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAdditional Technical Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17519/x1.png",
                "caption": "Figure 1:The visualization of Video VAE reconstruction examples. For each example, we provide the input video frame (the whole frame and local details) and the local patch extracted from the reconstructed video clip (the right enlarge part).",
                "position": 966
            },
            {
                "img": "https://arxiv.org/html/2510.17519/x2.png",
                "caption": "Figure 2:The human evaluation comparisons on generated e-commerce video of their quality.",
                "position": 971
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17519/x3.png",
                "caption": "Figure 3:Visualization of text-to-video generation results produced by the MUG-V 10B model. (enlarge for more details.)",
                "position": 1001
            },
            {
                "img": "https://arxiv.org/html/2510.17519/x4.png",
                "caption": "Figure 4:Visualization of image-to-video generation results produced by the MUG-V 10B model. In each example, the first frame corresponds to the conditioning image. (enlarge for more details.)",
                "position": 1006
            },
            {
                "img": "https://arxiv.org/html/2510.17519/x5.png",
                "caption": "Figure 5:Visualization of e-commerce video generation results across different models. Since each model is optimized for distinct prompt styles, we employed their respective default prompts or prompt-rewriting tools for fair comparison. (enlarge for more details.)",
                "position": 1011
            },
            {
                "img": "https://arxiv.org/html/2510.17519/x6.png",
                "caption": "Figure 6:Visualization of e-commerce video generation results across different models. Since each model is optimized for distinct prompt styles, we employed their respective default prompts or prompt-rewriting tools for fair comparison. (enlarge for more details.)",
                "position": 1016
            },
            {
                "img": "https://arxiv.org/html/2510.17519/x7.png",
                "caption": "Figure 7:Visualization of e-commerce video generation results across different models. Since each model is optimized for distinct prompt styles, we employed their respective default prompts or prompt-rewriting tools for fair comparison. (enlarge for more details.)",
                "position": 1021
            }
        ]
    },
    {
        "header": "Appendix CChallenges and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]