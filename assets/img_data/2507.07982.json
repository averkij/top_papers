[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07982/x1.png",
                "caption": "Figure 1:Geometry Forcing equips video diffusion models with 3D awareness.(a)We propose Geometry Forcing (GF), a simple yet effective paradigm to internalize geometric-aware structure into video diffusion models by aligning with features from a pretrained geometric foundation model,i.e., VGGT(Wang et al.,2025).(b)Compared to the baseline method(Song et al.,2025), our method produces more consistent generations both temporally and geometrically.(c)Features learned by the baseline model fail to reconstruct meaningful 3D geometry, whereas our method internalize 3D representation, enabling accurate 3D reconstruction from the intermediate features.",
                "position": 151
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Geometry Forcing",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07982/x2.png",
                "caption": "Figure 2:Qualitative comparison of camera view-conditioned video generation under full-circle rotation.Videos are generated from a single input frame and corresponding per-frame camera poses simulating a full 360° rotation. Our method (GF) is compared with DFoT(Song et al.,2025), VideoREPA(Zhang et al.,2025c), and REPA(Zhang et al.,2025c). The results demonstrate that the baseline methods fail to maintain temporal consistency, while our proposed GF consistently revisit the starting viewpoint.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2507.07982/extracted/6612720/figs/alignment_depth.png",
                "caption": "Figure 3:Ablation study on alignment depth.We present FVD-256 and FVD-16 results for aligning VGGT to different layers of the diffusion model. The results suggest that mid-level feature alignment is most effective for improving long-term video quality.",
                "position": 745
            },
            {
                "img": "https://arxiv.org/html/2507.07982/extracted/6612720/figs/alignment_depth.png",
                "caption": "Figure 3:Ablation study on alignment depth.We present FVD-256 and FVD-16 results for aligning VGGT to different layers of the diffusion model. The results suggest that mid-level feature alignment is most effective for improving long-term video quality.",
                "position": 748
            },
            {
                "img": "https://arxiv.org/html/2507.07982/extracted/6612720/figs/fvd_over_frames.png",
                "caption": "Figure 4:Exposure bias analysis.This figure shows the trend of FVD scores during long-term video generation. Compared to the baseline, GF results in significantly lower FVD after 100 frames.",
                "position": 753
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07982/x3.png",
                "caption": "Figure 5:Qualitative comparisons on camera-conditioned video generation.All the videos are generated given first frame and per-frame camera pose. We comprehensively compare GF (ours) with DFoT(Song et al.,2025), VideoREPA(Zhang et al.,2025c), REPA(Zhang et al.,2025c). The results demostrate consistency in long-term video generation both inside (left) and outside (right) scenes.",
                "position": 2157
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]