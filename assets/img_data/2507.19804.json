[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image1.png",
                "caption": "Figure 1:Visualization of Deformation Degree.We compute the deformation displacement for each pixel and visualize it using a heatmap. Blue represents minor deformation, while red indicates significant displacement.",
                "position": 88
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image3_4.png",
                "caption": "(a)Label Generation",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image3_4.png",
                "caption": "(a)Label Generation",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image3_5.png",
                "caption": "(b)The Architecture of ForCenNet",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image3_6.png",
                "caption": "(c)Curvature Consistency Loss",
                "position": 153
            }
        ]
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image14.png",
                "caption": "Figure 3:Qualitative Comparison with Prior Methods on DocUNet and DIR300 Benchmarks.Red arrows highlight the differences. Additional visualizations are available in the appendix.",
                "position": 306
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image6.png",
                "caption": "Figure 4:Visualization of Foreground Segmentation.From left to right: the distorted input image, segmentation results from the frozen model and the differentiable model, followed by the corresponding dewarped outputs generated by each model.",
                "position": 934
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image4.png",
                "caption": "Figure 5:Visualization of Foreground Results on WarpDoc[49]and DocReal[53]benchmarks.Columns 1-3: detection results of line elements. Columns 4-6: detection results of text elements. Highlighted colors indicate detected regions, while red arrows mark differences.",
                "position": 940
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image12.png",
                "caption": "Figure 6:Quantitative evaluation of straight-line rectification.The first image displays results on the DocReal[53]dataset, while the second image presents results on the WarpDoc[49]dataset.",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image5.png",
                "caption": "Figure 7:Visualization of intermediate layer results.Left to right: distorted image, foreground mask, foreground attention map, and rectification results of our model.",
                "position": 961
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Experimental Details",
        "images": []
    },
    {
        "header": "7Data augmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image15.png",
                "caption": "Figure 8:Visualization of the cropping process",
                "position": 1776
            }
        ]
    },
    {
        "header": "8Downstream tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image16.png",
                "caption": "Figure 9:Exploration of enhancement tasks.",
                "position": 1789
            }
        ]
    },
    {
        "header": "9Bias Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.19804/image/image11.png",
                "caption": "Figure 10:Statistic analysis of bias.",
                "position": 1825
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image17.png",
                "caption": "Figure 11:Visualization comparison on the DocUNet dataset.",
                "position": 1835
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image18.png",
                "caption": "Figure 12:Visualization comparison on the DIR300 dataset.",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image19.png",
                "caption": "Figure 13:Visualization comparison on the DocReal dataset.",
                "position": 1841
            },
            {
                "img": "https://arxiv.org/html/2507.19804/image/image20.png",
                "caption": "Figure 14:Visualization comparison on the WarpDoc dataset.",
                "position": 1844
            }
        ]
    },
    {
        "header": "10More visualizations",
        "images": []
    }
]