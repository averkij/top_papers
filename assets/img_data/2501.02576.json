[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02576/x1.png",
                "caption": "Figure 2:The overall framework of DepthMaster.\nRGB is first projected into the latent space by the I2L Encoder to obtainzRâ¢Gâ¢Bsubscriptğ‘§ğ‘…ğºğµz_{RGB}italic_z start_POSTSUBSCRIPT italic_R italic_G italic_B end_POSTSUBSCRIPT.\nNext, the U-Net converts RGB latent to depth prediction latentzpâ¢râ¢eâ¢dsubscriptğ‘§ğ‘ğ‘Ÿğ‘’ğ‘‘z_{pred}italic_z start_POSTSUBSCRIPT italic_p italic_r italic_e italic_d end_POSTSUBSCRIPT, which is decoded back to the depth map by the I2L Decoder.\nThe Feature Alignment module is applied in the first stage to align the representation of the U-Net to that of the high-quality external encoder, introducing semantic information into the diffusion model.\nIn the second stage, the Fourier Enhancement module adaptively balances low-frequency structure and high-frequency details to enhance the visual quality.",
                "position": 254
            }
        ]
    },
    {
        "header": "IIIMethod",
        "images": []
    },
    {
        "header": "IVExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02576/x2.png",
                "caption": "Figure 5:Depth distribution of different depth preprocess methods on Virtual KITTI. Square-root disparity exhibits the most uniform distribution.",
                "position": 1449
            }
        ]
    },
    {
        "header": "VLimitations",
        "images": []
    },
    {
        "header": "VIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]