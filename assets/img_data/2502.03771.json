[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x1.png",
                "caption": "Figure 1:Left:VectorQlearns embedding-specific similarity threshold regions (Rn‚Å¢n1,Rn‚Å¢n2,Rn‚Å¢n3superscriptsubscriptùëÖùëõùëõ1superscriptsubscriptùëÖùëõùëõ2superscriptsubscriptùëÖùëõùëõ3\\displaystyle\\small R_{nn}^{1},R_{nn}^{2},R_{nn}^{3}italic_R start_POSTSUBSCRIPT italic_n italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_R start_POSTSUBSCRIPT italic_n italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_R start_POSTSUBSCRIPT italic_n italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT) to make cache hit or miss decisions in semantic prompt caches. Bayesian sampling, guided by an embedding-specific correctness posterior (orange line), enablesVectorQto prioritize re-evaluations for uncertain cache hits.Right:VectorQconsistently outperforms state-of-the-art semantic prompt caches across all static thresholds by achieving a higher number of cache hits and a reduced number of errors.",
                "position": 92
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x2.png",
                "caption": "Figure 2:Kernel Density Functions (KDFs) for correct (green) and incorrect (red) cache hits for Amazon Prime Video Review Dataset.",
                "position": 225
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x3.png",
                "caption": "Figure 3:The figure illustrates the evolution of the three threshold regions (R01,R02,R03superscriptsubscriptùëÖ01superscriptsubscriptùëÖ02superscriptsubscriptùëÖ03\\displaystyle\\small R_{0}^{1},R_{0}^{2},R_{0}^{3}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT) for the prompt ‚ÄúName a paper about human Biology‚Äù. Six candidates use this embedding as their nearest neighbor and attempt to reuse its cached response (i.e., the name of a paper about human Biology). Steps 3 and 6.1 demonstrate how correctness sampling re-evaluations either increase certainty inR03superscriptsubscriptùëÖ03\\displaystyle\\small R_{0}^{3}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTor reduce its size, respectively. Further details are provided in Sections5.1and5.2.",
                "position": 228
            }
        ]
    },
    {
        "header": "4The Problem of Static Similarity Thresholds",
        "images": []
    },
    {
        "header": "5VectorQ",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x4.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x4.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x5.png",
                "caption": "(b)E-Commerce Dataset",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x6.png",
                "caption": "(c)Semantic Prompt Cache Benchmark",
                "position": 471
            }
        ]
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x7.png",
                "caption": "Figure 5:Performance comparison ofVectorQand a static-threshold approach on the Semantic Prompt Caching Benchmark.Top:VectorQachieves steady improvement, unlike the static similarity threshold‚Äôs converging performance.Bottom:Error rates, given a static threshold of 0.8 and anuncertainty gateof 0.2.",
                "position": 517
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x8.png",
                "caption": "Figure 6:Latency comparison betweenVectorQand static-threshold methods on the Semantic Prompt Caching Benchmark (AppendixE). The results demonstrate thatVectorQintroduces minimal overhead, achieving nearly identical latency to static-threshold methods despite incorporating embedding-specific threshold region updates and Bayesian sampling.",
                "position": 526
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASemantic Prompt Cache Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x9.png",
                "caption": "Figure 7:Semantic prompt cache architecture whereVectorQreplaces the static similarity threshold.",
                "position": 988
            }
        ]
    },
    {
        "header": "Appendix BDatasets and Prompt Construction",
        "images": []
    },
    {
        "header": "Appendix CThe Problem of Static Similarity Thresholds",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x10.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 1100
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x10.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x11.png",
                "caption": "(b)E-Commerce Dataset",
                "position": 1108
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x12.png",
                "caption": "(c)Semantic Prompt Cache Benchmark",
                "position": 1113
            }
        ]
    },
    {
        "header": "Appendix DThreshold Regions: Convergence Speed",
        "images": []
    },
    {
        "header": "Appendix ESemantic Prompt Caching Benchmark",
        "images": []
    },
    {
        "header": "Appendix FEvaluation: Threshold Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.03771/x13.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 1263
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x13.png",
                "caption": "(a)Amazon Product Review Dataset",
                "position": 1266
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x14.png",
                "caption": "(b)E-Commerce Dataset",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2502.03771/x15.png",
                "caption": "(c)Semantic Prompt Cache Benchmark",
                "position": 1276
            }
        ]
    },
    {
        "header": "Appendix GAblation Study: Correctness Sampling",
        "images": []
    }
]