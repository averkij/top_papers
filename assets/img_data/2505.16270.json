[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Definition of Mistake Log",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16270/x1.png",
                "caption": "Figure 1:Illustration of theMistake Log. We use the encoder-decoder architecture as an example here.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2505.16270/x2.png",
                "caption": "Figure 2:Transformer Copilot Framework. The overall framework comprises three key components:(1) Copilot Model Design,(2) Training Paradigm, and(3) Inference Paradigm.",
                "position": 254
            }
        ]
    },
    {
        "header": "3Transformer Copilot",
        "images": []
    },
    {
        "header": "4Analyses - Why Learn from the Mistake Log?",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16270/x3.png",
                "caption": "Figure 3:Logits Correction by Copilot.We visualize the logits correction introduced by a 1B Copilot model (computed as||||Fused logits−--Pilot logits||||) to highlight theshiftby the Copilot’s rectification.Left:Percentage of logits correction over original Pilot’s output logits range for three LLaMA-3 Pilot models.Right:Distribution of logits correction magnitudes across reasoning types.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2505.16270/x4.png",
                "caption": "Figure 4:Example of Copilot’s Token-level Rectification on SIQA.The token-level formatting error (‘forgot’) originates during the Pilot’s mid-way generation and is corrected (‘answer’) by incorporating the Copilot.",
                "position": 610
            }
        ]
    },
    {
        "header": "5Empirical Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16270/extracted/6465584/images/effeciency.png",
                "caption": "Figure 5:Efficiency Analysis on T-Copilot during fine-tuning and inference.(a)Inference model throughput.(b)Fine-tuning running speeds.(c)Overall training and inference time overhead.",
                "position": 1308
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABroader impact and Limitation",
        "images": []
    },
    {
        "header": "Appendix BAdditional Details on Transformer Copilot",
        "images": []
    },
    {
        "header": "Appendix CProof of Theorem4.1",
        "images": []
    },
    {
        "header": "Appendix DAdditional Empirical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16270/x5.png",
                "caption": "Figure 6:Example of Copilot’s Token-level Rectification on MAWPS.",
                "position": 3199
            }
        ]
    },
    {
        "header": "Appendix EDatasets",
        "images": []
    },
    {
        "header": "Appendix FExperiment Setups",
        "images": []
    },
    {
        "header": "Appendix GAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16270/x6.png",
                "caption": "Figure 7:Inference Scaling Lawsfor T-Copilot. We evaluate the average accuracy of T-Copilot and backbone frontier LLMs across all reasoning tasks at varying model scales. The results are shown for three architectures: FLAN-T5 (left), LLaMA-3 (middle), and Qwen2.5 (right).",
                "position": 5265
            }
        ]
    },
    {
        "header": "Appendix HAdditional Related Works",
        "images": []
    }
]