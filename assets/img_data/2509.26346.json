[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26346/x1.png",
                "caption": "Figure 1:An overview of our framework, illustrating the construction of theEditReward-Dataand the subsequent training of our reward model,EditReward.Top:The data pipeline, where we generate a diverse candidate pool from multiple state-of-the-art models and collect multi-dimensional human preference annotations.Bottom:The model pipeline, whereEditRewardis optimized onEditReward-Datausing our proposed Multi-Dimensional Uncertainty-Aware Ranking Loss for training, followed by its use in inference.",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2509.26346/x2.png",
                "caption": "Figure 2:Statistics of ourEditReward-DataandEditReward-Bench.",
                "position": 106
            }
        ]
    },
    {
        "header": "2EditReward-Data",
        "images": []
    },
    {
        "header": "3EditReward",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26346/x3.png",
                "caption": "Figure 3:Representative examples of our reward model aligning with human judgments.",
                "position": 361
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26346/x4.png",
                "caption": "Figure 4:Annotation Interface",
                "position": 1989
            },
            {
                "img": "https://arxiv.org/html/2509.26346/x5.png",
                "caption": "Figure 5:Loss curve and Valid set Acc by using or not using Disentangling Ties via Dimensional Preference during model training.",
                "position": 2094
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]