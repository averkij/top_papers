[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Preliminaries",
        "images": []
    },
    {
        "header": "3PERK: Meta-Learning Parameter-Efficient Reasoning over Knowledge",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/training.png",
                "caption": "Figure 1:Meta-learningPERKfor long-context reasoning.The training procedure involves a nested inner and outer loop. The inner loop optimizes the likelihood of a batch of long context segments with respect to the parameters of the LoRA-based memory scratchpad. In the outer loop, the model uses the encoded information in the memory scratchpad to answer questions. In both cases, only the memory scratchpad parameters are updated while the base LLMâ€™s parameters are frozen.",
                "position": 267
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/results.png",
                "caption": "Figure 2:Performance on NIAH with BabiLong and DIO with Student Records. All models are trained and tested on sequences ranging from 1K to 8K tokens. AllPERKmodels are trained to first generate the supporting facts relevant to a query, followed by the final answer prediction. In contrast, baseline models directly generate the answer, as this approach yields better performance for them in this setting. The number of trainable parameters for each method is indicated in the legend.",
                "position": 407
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/length-generalization_v3.png",
                "caption": "Figure 3:Test-time length extrapolation beyond 32Kon BabiLong QA1 (a) and QA2 (b). BothPERKand FT-ICR are trained on 8K-token sequences. The context length for inference grows from 64K to 128K.PERKextrapolates substantially better than FT-ICR.",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/length-generalization_updated.png",
                "caption": "Figure 4:Test-time context length generalization evaluationon BabiLong QA1 (a) and QA2 (b): comparison betweenPERKand FT-ICR on the Qwen-2.5-0.5B model. The y-axis represents the training context lengths, while the x-axis indicates various test-time context lengths. We test for bothinterpolation(test lengths shorter than the training length) andextrapolation(test lengths longer than the training length). Bordered cells denote the boundary: evaluation on context lengths equal to those in training.PERKshows stronger generalization across both settings.",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/length-generalization_updated.png",
                "caption": "Figure 4:Test-time context length generalization evaluationon BabiLong QA1 (a) and QA2 (b): comparison betweenPERKand FT-ICR on the Qwen-2.5-0.5B model. The y-axis represents the training context lengths, while the x-axis indicates various test-time context lengths. We test for bothinterpolation(test lengths shorter than the training length) andextrapolation(test lengths longer than the training length). Bordered cells denote the boundary: evaluation on context lengths equal to those in training.PERKshows stronger generalization across both settings.",
                "position": 481
            },
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/positional_bias_v2.png",
                "caption": "Figure 5:Positional Bias.Comparison ofPERKand FT-ICR on 4K and 8K contexts, on Qwen-2.5-0.5B. We train on problems where the relevant information appears in the beginning (Pre), middle (Mid), or end (Post) of the context, and evaluate on all three positional settings. We also train models on contexts where the relevant information is randomly located (Rnd), testing these on all four positional distributions (Pre,Post,Mid,Rnd).\nBordered cells show in-distribution performances.PERKdemonstrates strong positional robustness.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/efficiency_results.png",
                "caption": "Figure 6:(a):Peak GPU memory usage during training with context lengths ranging from 1K to 8K tokens forReckoningandPERK. WhilePERKsuccessfully scales to 8K tokens,Reckoningencounters out-of-memory (OOM) errors at shorter context lengths.(b):Memory footprint and wall-clock runtime during inference as context length increases (up to 128K tokens), comparingPERKwith FT-ICR. Curves that terminate before 128K indicate that the method failed with an OOM error at longer context lengths, preventing further measurement.PERKdemonstrates more efficient scaling in both memory and runtime, particularly for extremely long sequences.",
                "position": 523
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.06415/extracted/6607134/figures/data_examples.png",
                "caption": "Figure 7:Dataset Examples.Here we show an example from the three datasets we used: (Top) BabiLong, (Middle) Student Records, and (Bottom) Lost-in-the-Middle API Retrieval.",
                "position": 1594
            }
        ]
    },
    {
        "header": "Appendix BTraining and Inference Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Analysis",
        "images": []
    }
]