[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12560/x1.png",
                "caption": "Figure 1:Overview of CoIRL-AD.CoIRL-AD adopts a dual-policy architecture that integrates imitation learning (IL) and reinforcement learning (RL) through a shared latent world model. In each iteration, the IL actor and RL actor are trained in parallel. The latent world model is learned during the IL phase and then used in the RL phase, where only the RL actor and critic are updated. For exploration, the RL actor samples multiple action sequences, predicts future states via the latent world model, and evaluates them with rule-based reward functions. The critic assigns advantages to each sequence based on the imagined future states and rewards. To promote interaction, a competitive learning mechanism exchanges knowledge between the IL and RL actors.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12560/x2.png",
                "caption": "Figure 2:The comparison of forward planning (using causal mask) and backward attention (use inverse causal mask)",
                "position": 237
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x3.png",
                "caption": "Figure 3:The flow chart of our rule-based competitive learning mechanism",
                "position": 369
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12560/x4.png",
                "caption": "(a)Cross-city Generalization Ability",
                "position": 624
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x4.png",
                "caption": "(a)Cross-city Generalization Ability",
                "position": 627
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x5.png",
                "caption": "(b)Performance on longtail scenarios",
                "position": 632
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12560/x6.png",
                "caption": "",
                "position": 973
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12560/x7.png",
                "caption": "(a)Naive sampling",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x7.png",
                "caption": "(a)Naive sampling",
                "position": 1466
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x8.png",
                "caption": "(b)Step-aware group sampling",
                "position": 1471
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x9.png",
                "caption": "(a)Naive sampling",
                "position": 1478
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x9.png",
                "caption": "(a)Naive sampling",
                "position": 1481
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x10.png",
                "caption": "(b)Step-aware group sampling",
                "position": 1486
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x11.png",
                "caption": "(a)Naive sampling",
                "position": 1493
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x11.png",
                "caption": "(a)Naive sampling",
                "position": 1496
            },
            {
                "img": "https://arxiv.org/html/2510.12560/x12.png",
                "caption": "(b)Step-aware group sampling",
                "position": 1501
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_e6f1a7e6218a4737bfedc6af90926b3e+frame_4.png",
                "caption": "Figure 9:Good Case: The baseline model collides with a car driving in the neighboring lane at high speed, while our model successfully avoids the collision.",
                "position": 1726
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_acc29386502047339e1ec6b9c7e512d2+frame_9.png",
                "caption": "Figure 10:Good Case: When pedestrians are crossing ahead, our model stops and waits for them to pass, whereas the baseline model continues to drive forward.",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_84e056bd8e994362a37cba45c0f75558+frame_21.png",
                "caption": "Figure 11:Good Case: In a queuing scenario while waiting for the green light, our model proceeds after the car ahead turns off its indicator and starts moving, whereas the baseline model remains stopped, which may lead to a rear-end collision.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_c4df079d260241ff8015218e29b42ea7+frame_10.png",
                "caption": "Figure 12:Good Case: When the high-level command is incorrect, our model adapts its planned trajectory based on the driving scenario, whereas the baseline model fails to adjust.",
                "position": 1735
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_e7ef871f77f44331aefdebc24ec034b7+frame_22.png",
                "caption": "Figure 13:Good Case: When exiting the parking lot, our model waits for the toll barrier to rise, whereas the baseline model proceeds forward and collides with it.",
                "position": 1738
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/good-case/scene_f24b4682fbb9482aba149534deed1cc9+frame_17.png",
                "caption": "Figure 14:Good Case: When the leading vehicle has its indicator on, our model slows down to avoid a rear-end collision, whereas the baseline model maintains speed and causes a collision.",
                "position": 1741
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/bad-case/scene_3a2d9bf6115f40898005d1c1df2b7282+frame_3.png",
                "caption": "Figure 15:Bad Case: When turning right at an intersection, both the baseline model and our model plan trajectories that collide with a vehicle waiting for the green light.",
                "position": 1751
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/bad-case/scene_93608f0d57794ba6b014314c488e2b4a+frame_2.png",
                "caption": "Figure 16:Bad Case: When pedestrians are crossing, our model continues to move forward at a low speed instead of stopping completely.",
                "position": 1754
            },
            {
                "img": "https://arxiv.org/html/2510.12560/figs/case-study/bad-case/scene_a2b005c4dd654af48194ada18662c8ca+frame_30.png",
                "caption": "Figure 17:Bad Case: Both the baseline model and our model fail to plan reasonable trajectories in lane-changing scenarios.",
                "position": 1757
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]