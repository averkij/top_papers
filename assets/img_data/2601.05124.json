[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05124/x1.png",
                "caption": "",
                "position": 88
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05124/x2.png",
                "caption": "Figure 2:Comparison of the reasoning paradigms of BAGEL and Re-Align. While BAGEL exhibits competent reasoning abilities, the resulting images fail to reflect its reasoning process in the complex image-text interleaved prompt. In contrast, Re-Align achieves strong reasoning–generation alignment, facilitated by the structured IC-CoT.",
                "position": 119
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05124/x3.png",
                "caption": "Figure 3:The two-stage training pipeline of Re-Align. First, we perform supervised fine-tuning on carefully curated training data to enable the model to generate images guided by IC-CoT reasoning. Next, we apply policy optimization to further enhance reasoning–generation consistency, using an alignment score between the structured IC-CoT and the corresponding generated image.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2601.05124/x4.png",
                "caption": "Figure 4:The data construction pipeline of Re-Align-410K and its task distribution.a)reference images preparation,b)adaptive instruction generation,c)reasoning text generation,d)target image generation,e)data filtering, andf)the data distribution of Re-Align-410K.",
                "position": 235
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05124/x5.png",
                "caption": "Figure 5:Qualitative comparisons of proposed Re-Align with BAGEL[12], OmniGen2[60], Echo-4o[69], Qwen-Image-Edit(2509)[59]and DreamOmni2[62]on the in-context image generation and editing tasks.",
                "position": 377
            },
            {
                "img": "https://arxiv.org/html/2601.05124/x6.png",
                "caption": "Figure 6:More examples for In-Context Image Generation and Editing. The last image in each group is the generated result, and the others are input reference images.",
                "position": 615
            },
            {
                "img": "https://arxiv.org/html/2601.05124/x7.png",
                "caption": "Figure 7:GSB evaluation results from the ablation study on the reasoning mechanism.",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2601.05124/x8.png",
                "caption": "Figure 8:Ablation visualization of reasoning–generation alignment with reasoning-induced diversity (RGA+RID).",
                "position": 1029
            },
            {
                "img": "https://arxiv.org/html/2601.05124/x9.png",
                "caption": "Figure 9:Failure cases of Re-Align.\nIn the first row, the model-generated reasoning text appears on an orange background, with incorrect parts marked in red.",
                "position": 1054
            }
        ]
    },
    {
        "header": "5Conclusion and Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]