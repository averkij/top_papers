[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/assets/teasers/teaser_no_logo.jpg",
                "caption": "Figure 1:World snapshots generated by WorldGen.Each scene consists of individually editable objects represented as fully textured 3D meshes. As explicit geometry, these worlds naturally support collision, and navigation‚Äîallowing characters to climb, jump, and interact.\nThe resulting assets are immediately deployable in game engines.",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2511.16825/x1.png",
                "caption": "Figure 2:WorldGen overview. Our pipeline begins by planning the scene layout, producing a blockout (BB), reference image (ùêë\\mathbf{R}), and navigation mesh (S) (Stage 1). Next, we generate a single 3D mesh that aligns with this plan, preserving navigable areas and overall composition (Stage 2). The scene is then decomposed into individual entities (Stage 3), which are refined at higher resolution (Stage 4), resulting in a high-quality, traversable, and visually cohesive final scene.",
                "position": 397
            }
        ]
    },
    {
        "header": "2WorldGen Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/x2.png",
                "caption": "Figure 3:3D Layout Generation. An LLM parses the input prompt into structured parameters (JSON) to drive a procedural generator, producing a coarse 3D blockout. This blockout is then rendered to depth, which conditions the generation of the final scene reference image.",
                "position": 470
            }
        ]
    },
    {
        "header": "3Stage I: Scene Planning",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/assets/depthconditioned_gen.png",
                "caption": "Figure 4:Depth-conditioned generation across density (columns) and verticality range (rows).In each grid cell, we show the input depth map (left) and the corresponding generated image conditioned on that depth (right). Columns are ordered by increasing density from left to right; rows are ordered by increasing verticality range from low to high.",
                "position": 562
            }
        ]
    },
    {
        "header": "4Stage II: Scene Reconstruction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/x3.png",
                "caption": "Figure 5:AssetGen2 and Navmesh architectures.Left: Overview of the base AssetGen mesh generation architecture. Right: Our Navmesh conditioned scene mesh generation (Stage II) based on cross-attention",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2511.16825/x4.png",
                "caption": "",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2511.16825/x5.png",
                "caption": "Figure 6:Navmesh-conditioned scene generation. Left to right: the procedurally generated 3D layout and the extracted navmesh (used as input condition for 3D scene generation), the generated reference image conditioned on the 3D layout, the input navmesh overlaid on our final generated scene, produced by the navmesh-conditioned model and the baseline AssetGen2, respectively.\nThis confirms our generated scene successfully adheres to the specified navigable path.",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2511.16825/x6.png",
                "caption": "Figure 7:Layout editing.Our navmesh-conditioned scene generation allows input editing to the procedurally generated layout and the corresponding navigable path.\nFor each row we show the generation results with manual editing on the initial procedurally generated layout.\nFor each column from left to right: procedurally generated scene layout with extracted navmesh overlaid, reference image, 3D scene generation output with input navmesh condition overlaid, procedurally generated scene layout with manual edits, 3D scene generation output with edited navmesh condition overlaid.",
                "position": 722
            }
        ]
    },
    {
        "header": "5Stage III: Scene Decomposition",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/assets/autopartgen_nikos.jpg",
                "caption": "Figure 8:Decomposition results.Our model is finetuned on scene data with part annotations such that given an input 3D scene, the model successfully decomposes it into its constituents, starting from the ground.",
                "position": 883
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/partgen_comparison.png",
                "caption": "Figure 9:Scene decomposition comparison. Our model demonstrates decomposition results of the highest quality and the least noise compared to other state-of-the-art methods, yet maintaining a fast inference speed.",
                "position": 906
            },
            {
                "img": "https://arxiv.org/html/2511.16825/figures/enhanced_objects_nikos.jpg",
                "caption": "Figure 10:Per-object image enhancement.The reference image, the top-down view with target object highlighted with red and the coarse textured rendering are sent to an LLM-VLM that outputs the final per-object enhanced image.",
                "position": 910
            },
            {
                "img": "https://arxiv.org/html/2511.16825/x7.png",
                "caption": "Figure 11:Per-object image enhancement without using the top-down view.Without access to a top-down view of the entire scene‚Äîwhich gives the LLM-VLM important information about object location and surrounding context‚Äîthe model has difficulty generating object images that are visually consistent with the scene‚Äôs style or faithful to the reference image. As a result, the generated images may not match the overall style of the scene or may differ from the appearance of the object in the reference image.",
                "position": 916
            },
            {
                "img": "https://arxiv.org/html/2511.16825/figures/verification.png",
                "caption": "Figure 12:Object image verification.This stage may require multiple iterations to achieve the desired visual quality, followed by an automatic verification step.\nHere, ‚Äúinitial‚Äù denotes the low-resolution input render, ‚Äúrejected‚Äù refers to enhanced images rejected by the verification step, and ‚Äúenhanced‚Äù represents the final accepted results.\nCommon failure cases include changes in object orientation, omission or hallucination of geometric details, and incorrect overlaying of objects onto the background scene.",
                "position": 922
            }
        ]
    },
    {
        "header": "6Stage IV: Scene Enhancement",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/x8.png",
                "caption": "Figure 13:Per-object mesh refinement. Given a coarse object mesh and a high-resolution image, we feed them to our mesh refinement model which outputs a refined high-quality mesh that adheres to the orientation and shape of the coarse input yet incorporates fine details from the image input.",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/refined_mesh_nikos.jpg",
                "caption": "Figure 14:Per-object mesh enhancement.Each row shows two objects from the same scene, with the columns corresponding to image, coarse mesh, and refined mesh.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/texture_gridview_example_2.jpeg",
                "caption": "Figure 15:Multi-view texture generation.Given a reference image as input, we sequentially generate: (1) frontal views, (2) side views conditioned on the frontal view, and (3) top and (4) bottom views conditioned on all previously generated views.",
                "position": 951
            }
        ]
    },
    {
        "header": "7Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_dilin1.jpg",
                "caption": "Figure 16:Medieval town square",
                "position": 1087
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1023_015.jpg",
                "caption": "Figure 17:Snowy village",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/image_to_3d_baselines/Qual_comparisons_fig_nikos_v3.png",
                "caption": "Figure 18:Comparison with state-of-the-art image-to-3D methods. WorldGen generates scenes that are significantly more detailed than single-shot reconstructions.",
                "position": 1115
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/worldlabs/worldlabs.jpg",
                "caption": "Figure 19:World Labs examples.Example results of the marble scene generation under different configurations.",
                "position": 1126
            }
        ]
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Conclusions and Limitations",
        "images": []
    },
    {
        "header": "10Acknowledgement",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1014_018.jpg",
                "caption": "Figure 20:Space port",
                "position": 1553
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1015_005.jpg",
                "caption": "Figure 21:Fruit-themed village",
                "position": 1558
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1015_008.jpg",
                "caption": "Figure 22:Sci-fi colony",
                "position": 1563
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1015_009.jpg",
                "caption": "Figure 23:Old industrial dockyard",
                "position": 1568
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1015_034.jpg",
                "caption": "Figure 24:Steampunk miniature city",
                "position": 1573
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1017_043.jpg",
                "caption": "Figure 25:Ancient temple courtyard",
                "position": 1578
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1017_050.jpg",
                "caption": "Figure 26:Military outpost",
                "position": 1583
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1017_054.jpg",
                "caption": "Figure 27:Japanese style medieval town",
                "position": 1588
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_002.jpg",
                "caption": "Figure 28:Fantasy mushroom village",
                "position": 1593
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_007.jpg",
                "caption": "Figure 29:Ancient East Asian temple complex",
                "position": 1598
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_013.jpg",
                "caption": "Figure 30:Cargo yard",
                "position": 1603
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_021.jpg",
                "caption": "Figure 31:Desert town",
                "position": 1608
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_iso15.jpg",
                "caption": "Figure 32:Futuristic industrial complex",
                "position": 1613
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_mj.jpg",
                "caption": "Figure 33:Charming city block",
                "position": 1618
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_mj4.jpg",
                "caption": "Figure 34:Suburban neighborhood",
                "position": 1623
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_mj8.jpg",
                "caption": "Figure 35:Forest outpost",
                "position": 1628
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_mj14.jpg",
                "caption": "Figure 36:Seaside terminal",
                "position": 1633
            },
            {
                "img": "https://arxiv.org/html/2511.16825/assets/scene_render_picked/scene_1029_nano16.jpg",
                "caption": "Figure 37:Halloween-themed village",
                "position": 1638
            }
        ]
    },
    {
        "header": "Appendix AScenes generated by WorldGen",
        "images": []
    }
]