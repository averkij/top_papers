[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/intro/balance5.png",
                "caption": "Figure 1:Illustration of balancing fidelity and editability.We demonstrate examples of over-, balanced, and under-editing across six types of edits:\n(a) color change, (b) texture modification (c) object replacement (d) background editing, (e) global style transfer, and (f) human face attribute editing.\nOver-editing occurs when excessive changes distort the original image, while under-editing results in changes too subtle to meet the text prompt‚Äôs requirements.\nIn contrast, ourUnifyEditbalances fidelity and editability within a unified framework, ensuring edits align with the text prompt while preserving the essential integrity.",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x1.png",
                "caption": "Figure 2:UnifyEdit vs.¬†dual-branch editing paradigm.(a) The typical dual-branch editing paradigm consists of source and target branches, usingattention injectionto maintain fidelity while relying on thetext promptto achieve editability.\n(b) In contrast, our method explicitly models the fidelity and editability using twoattention-based constraintsand performslatent optimizationwithin a unified framework, facilitating an adaptive balance across various editing types.",
                "position": 183
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05594/x2.png",
                "caption": "Figure 3:Experiments with self-attention and cross-attention.(a) Compared to SA injection, the SA constraint offers greater flexibility in editing.\n(b) When the CA map accurately focuses on the target region with a strong response, the resulting edits align effectively with the text prompt. However, attention leakage or low attention values can lead to misalignment or ineffective editing outcomes.",
                "position": 288
            }
        ]
    },
    {
        "header": "3Dual-Branch Tuning-Free Image Editing",
        "images": []
    },
    {
        "header": "4Unfiy-Edit via Latent Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05594/x3.png",
                "caption": "Figure 4:Illustration of UnifyEdit.UnifyEdit is applied to the diffusion latent featurezt‚àósuperscriptsubscriptùëßùë°‚àóz_{t}^{\\ast}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPTin the target branch, involving two key steps: 1) calculating‚ÑíSAPsubscript‚ÑíSAP\\mathcal{L}_{\\rm{SAP}}caligraphic_L start_POSTSUBSCRIPT roman_SAP end_POSTSUBSCRIPTand‚ÑíCAAsubscript‚ÑíCAA\\mathcal{L}_{\\rm{CAA}}caligraphic_L start_POSTSUBSCRIPT roman_CAA end_POSTSUBSCRIPTfor fidelity and editability, and 2) applying an adaptive time-step scheduler for latent optimization.",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x4.png",
                "caption": "Figure 5:Editing and visualization results of different gradients.(a) Using Eq.¬†(12) alone results in a significantly stronger influence of‚ÑíCAAsubscript‚ÑíCAA\\mathcal{L}_{\\rm{CAA}}caligraphic_L start_POSTSUBSCRIPT roman_CAA end_POSTSUBSCRIPT, disabling‚ÑíSAPsubscript‚ÑíSAP\\mathcal{L}_{\\rm{SAP}}caligraphic_L start_POSTSUBSCRIPT roman_SAP end_POSTSUBSCRIPTand causing an unbalanced guidance onztsubscriptùëßùë°z_{t}italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.\n(b) Although calculating their norms as in Eq.¬†(13) brings the magnitudes of the constraints closer, the irregular dynamics lead to either under-editing or over-editing failures.\n(c) In contrast, applying the adaptive time-step scheduler in Eq.¬†(14) shapes the gradient trends in Eq.¬†(15) such that‚àázt‚àó‚ÑíSAPsubscript‚àásuperscriptsubscriptùëßùë°subscript‚ÑíSAP\\nabla_{z_{t}^{*}}\\mathcal{L}_{\\rm{SAP}}‚àá start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT roman_SAP end_POSTSUBSCRIPTstarts small and gradually increases, whereas‚àázt‚àó‚ÑíCAAsubscript‚àásuperscriptsubscriptùëßùë°subscript‚ÑíCAA\\nabla_{z_{t}^{*}}\\mathcal{L}_{\\rm{CAA}}‚àá start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚àó end_POSTSUPERSCRIPT end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT roman_CAA end_POSTSUBSCRIPTexhibits the opposite trend, facilitating fidelity-editability balance.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/color_sim/5/5.jpg",
                "caption": "TABLE I:Examples in Unify-Bench.Each image in Unify-Bench is annotated with a source prompt, a target edit prompt, and an edit region mask.\nComplex scenarios within the dataset are distinctly highlighted with agrey.",
                "position": 728
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/color_sim/5/mask.png",
                "caption": "",
                "position": 765
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/color_cmp/8/8.jpg",
                "caption": "",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/color_cmp/8/mask.png",
                "caption": "",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/texture_sim/31/31.jpg",
                "caption": "",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/texture_sim/31/mask.png",
                "caption": "",
                "position": 833
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/texture_cmp/26/26.jpg",
                "caption": "",
                "position": 851
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/texture_cmp/26/mask.png",
                "caption": "",
                "position": 879
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/obj_sim/2/2.jpg",
                "caption": "",
                "position": 897
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/obj_sim/2/mask.png",
                "caption": "",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/obj_cmp/2/2.jpg",
                "caption": "",
                "position": 925
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/obj_cmp/2/mask.png",
                "caption": "",
                "position": 953
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/background/13/13.jpg",
                "caption": "",
                "position": 965
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/background/13/mask.png",
                "caption": "",
                "position": 975
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/style/18/18.jpg",
                "caption": "",
                "position": 987
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/human/14/14.jpg",
                "caption": "",
                "position": 1012
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/dataset/human/14/mask.png",
                "caption": "",
                "position": 1022
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x5.png",
                "caption": "Figure 6:Qualitative comparisons across various editing types.We use white dashed outlines to highlight the target object in foreground editing.\nOur proposed method achieves a superior balance compared to other baseline methods, demonstrating enhanced editing effects while more effectively maintaining structural consistency.",
                "position": 1033
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.05594/x6.png",
                "caption": "Figure 7:Quantitative comparisons of baselines and our UnifyEdit across various editing types.We quantify editability and fidelity using CLIP sore (righter is better) and DINO similarity distance (lower is better), respectively.\nBalancing the aspects requires a high CLIP score and relatively low DINO similarity.\nTherefore, points closer to thepinkregion of the background represent better performance, while those closer to theblueregion indicate poorer performance.",
                "position": 1152
            },
            {
                "img": "https://arxiv.org/html/2504.05594/extracted/6339207/sec/figs/exp/user_study4.png",
                "caption": "Figure 8:Average human preferences across various editing types.The values indicate the proportion of users who preferred our proposed method over comparative approaches.",
                "position": 1160
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x7.png",
                "caption": "Figure 9:Qualitative results of ablation study on attention-based constraints.White dashed outlines are used to highlight the target object in foreground editing.\nCombining both terms is crucial for achieving a good balance between fidelity and editability.",
                "position": 1694
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x8.png",
                "caption": "Figure 10:Qualitative results of ablation study on different gradients.The target object is accentuated with white dashed outlines in the foreground editing.ùí¢n‚Å¢a‚Å¢i‚Å¢v‚Å¢esubscriptùí¢ùëõùëéùëñùë£ùëí\\mathcal{G}_{naive}caligraphic_G start_POSTSUBSCRIPT italic_n italic_a italic_i italic_v italic_e end_POSTSUBSCRIPTin¬†Eq.¬†(12) can lead to over-editing and, in some cases, image collapse.\nWhileùí¢n‚Å¢o‚Å¢r‚Å¢msubscriptùí¢ùëõùëúùëüùëö\\mathcal{G}_{norm}caligraphic_G start_POSTSUBSCRIPT italic_n italic_o italic_r italic_m end_POSTSUBSCRIPTin Eq.¬†(13) mitigates these issues, it still encounters both under-editing and over-editing failures.\nIn contrast, our method, which employsùí¢b‚Å¢l‚Å¢csubscriptùí¢ùëèùëôùëê\\mathcal{G}_{blc}caligraphic_G start_POSTSUBSCRIPT italic_b italic_l italic_c end_POSTSUBSCRIPTin\nEq.¬†(15), successfully achieves a balanced result.",
                "position": 1701
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x9.png",
                "caption": "Figure 11:Ablation study on hyper-parameters in adaptive time-step scheduler.The scaling factorsŒ≤1subscriptùõΩ1\\beta_{1}italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTandŒ≤2subscriptùõΩ2\\beta_{2}italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, along with the rate factorsk1subscriptùëò1k_{1}italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTandk2subscriptùëò2k_{2}italic_k start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, regulate the magnitude and changing rate, influencing the editing outcomes.",
                "position": 1724
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x10.png",
                "caption": "Figure 12:Editing results using DDIM inversion.The proposed method maintains effectiveness by employing SA constraints derived from the SA maps generated during the DDIM inversion.",
                "position": 1777
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x11.png",
                "caption": "Figure 13:Diffusion latent optimization vs.¬†noise guidance.Latent optimization outperforms noise guidance in balancing fidelity and editability.",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2504.05594/x12.png",
                "caption": "Figure 14:More editing results of UnifyEdit.We highlight the target object with white dashed outlines in foreground editing.\nUnifyEdit can achieve balance across various editing types and can be applied to multiple target editing tokens.",
                "position": 1975
            }
        ]
    },
    {
        "header": "6Conclusions and Future works",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]