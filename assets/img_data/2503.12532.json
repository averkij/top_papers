[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12532/x1.png",
                "caption": "Figure 1:Windows File Explorer task completion rate of different computer-use agents:\n(i) Our powerful GUI grounding model achieves the current best task completion rate, setting a promising upper bound for computer-use agent finetuning.\n(ii) Using STEVE, our step verification pipeline, we are able to train\nour agents with KTO (red), which consistently outperforms (iii) the supervised finetuning (SFT).\nNotably, with increased computer operating time (x-axis), our 7B KTO agent is able to outperform the OmniParser with the GPT-4o planner.",
                "position": 561
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12532/x2.png",
                "caption": "Figure 3:Overview of STEVE, the step verification pipeline.\nWe first create a large number of feasible tasks from the seed tasks to scale up the quality and diversity of agent tasks. Then we deploy our computer-use agent in desktop environments to sample trajectory data. A GPT-4o judge is used to verify the quality of each step in the trajectory, resulting in a large process reward dataset for agent training.",
                "position": 708
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12532/x3.png",
                "caption": "Figure 4:Percentage consistency between human judges and the GPT-4o step verifier. We split all the positive and negative actions into early (step ID≤7absent7\\leq 7≤ 7) and late (step ID>7absent7>7> 7) groups, resulting in four bars in the figure. For example,92.3%percent92.392.3\\%92.3 %for the Early Pos. bar means the GPT-4o judge agrees with humans for92.3%percent92.392.3\\%92.3 %of the early positive actions.",
                "position": 1325
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x4.png",
                "caption": "(a)Task success rate on the File Explorer split.",
                "position": 1333
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x4.png",
                "caption": "(a)Task success rate on the File Explorer split.",
                "position": 1336
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x5.png",
                "caption": "(b)Task success rate on the Web Browser split.",
                "position": 1341
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x6.png",
                "caption": "(c)Task success rate on the VsCode split.",
                "position": 1346
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x7.png",
                "caption": "Figure 6:Zoom in visualization of UI localization performance of different models on four target GUIs: example.txt, Design tab, Cached image check box, and Title of PPT slide (left to right). The UI-Grounding Model’s performance is shown in green (top row), the SFT-trained agent in red (middle row), and the KTO-trained agent in blue (bottom row).",
                "position": 1359
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12532/x8.png",
                "caption": "Figure 7:The reward margin (vertical axis) between the chosen and rejected samples consistently improve during the KTO training.",
                "position": 1644
            }
        ]
    },
    {
        "header": "Appendix BPrompt Examples",
        "images": []
    },
    {
        "header": "Appendix CAgent Demo",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12532/x9.png",
                "caption": "Figure 8:The trajectories of our STEVE-KTO-7B agent for the chrome tasks from the WinAgentArena[4]with ID bb5e4c0d-f964-439c-97b6-bdb9747de3f4-wos (up) and b070486d-e161-459b-aa2b-ef442d973b92-wos (bottom). We display a simplified action for each step and plot the target UI localization results with a red bounding box in each screenshot. For high-resolution screenshots/videos, full model responses with screen analysis, multi-step planning, and python code blocks, please refer to the corresponding attachments.",
                "position": 1889
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x10.png",
                "caption": "Figure 9:The trajectories of our STEVE-KTO-7B agent for the file explorer tasks from the WinAgentArena[4]with ID 7c70e16b-e14f-4baa-b046-3e022b2d0305-WOS (up) and 5316686e-5688-4115-be24-052037df599f-WOS (bottom). We display a simplified action for each step and plot the target UI localization results with a red bounding box in each screenshot. For high-resolution screenshots/videos, full model responses with screen analysis, multi-step planning, and python code blocks, please refer to the corresponding attachments.",
                "position": 1892
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x11.png",
                "caption": "Figure 10:The trajectories of our STEVE-KTO-7B agent for the Windows setting tasks from the WinAgentArena[4]with ID a659b26e-4e31-40c1-adaf-34742b6c44ac-wos (up) and 37e10fc4-b4c5-4b02-a65c-bfae8bc51d3f-wos (bottom). Only the last two steps of the later task are shown. We display a simplified action for each step and plot the target UI localization results with a red bounding box in each screenshot. For high-resolution screenshots/videos, full model responses with screen analysis, multi-step planning, and python code blocks, please refer to the corresponding attachments.",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2503.12532/x12.png",
                "caption": "Figure 11:Comparisons of different computer-use agent models.",
                "position": 1905
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]