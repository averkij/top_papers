[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/fig/logo.jpg",
                "caption": "",
                "position": 139
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/x1.png",
                "caption": "Figure 1:Performance comparison onWebPRMBench.Left:Average Best-of-N Accvs. model size, showing superior efficiency despite smaller scale.Right:Domain-wiseAvg BoN Acc, where WebArbiter achieves the best results across all environments, confirming robustness and scalability.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/x2.png",
                "caption": "Figure 2:Overview of WebArbiter.\nGiven an instructionℐ\\mathcal{I}, current observationopo_{p}, and history(a<p,c<p)(a_{<p},c_{<p}), the model compares candidate actions(ap1,cp1)(a_{p}^{1},c_{p}^{1})and(ap2,cp2)(a_{p}^{2},c_{p}^{2}).\nInStage 1, principle-guided reasoning traces are distilled from a stronger teacher LLM.\nInStage 2, WebArbiter is trained with RL using verifiable rewardsR∈{−1,+1}R\\in\\{-1,+1\\}, producing structured justifications and a final verdict.\nDuring inference, the model induces principles (e.g., clarity, correctness, progress) from(ℐ,op,a<p,c<p,(ap1,cp1),(ap2,cp2))(\\mathcal{I},o_{p},a_{<p},c_{<p},(a_{p}^{1},c_{p}^{1}),(a_{p}^{2},c_{p}^{2})), applies them to candidate actions, and outputs an auditable judgment identifying the action that best advances task completion.",
                "position": 212
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4WebPRMBench",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation Summary",
        "images": []
    },
    {
        "header": "Appendix BExample of Preference Dataset",
        "images": []
    },
    {
        "header": "Appendix CTraining Details",
        "images": []
    },
    {
        "header": "Appendix DPrompt Repository",
        "images": []
    },
    {
        "header": "Appendix EBenchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/x3.png",
                "caption": "Figure 3:Action-type distribution inWebPRMBench.",
                "position": 2171
            }
        ]
    },
    {
        "header": "Appendix FAnalysis ofBoN Accvs.Pairwise AccEvaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/x4.png",
                "caption": "Figure 4:Correlation betweenBoNandPairwise Accacross web benchmarks. Each scatter point corresponds to a PRM. We report the correlation coefficientrrfor each environment. While the two metrics are strongly correlated across all environments, BoN exhibits higher variance and provides finer-grained discrimination\namong models, particularly in complex web environments.",
                "position": 2237
            }
        ]
    },
    {
        "header": "Appendix GInference-Time Scaling",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21872/x5.png",
                "caption": "(a)Pairwise Accuracy",
                "position": 2262
            },
            {
                "img": "https://arxiv.org/html/2601.21872/x5.png",
                "caption": "(a)Pairwise Accuracy",
                "position": 2265
            },
            {
                "img": "https://arxiv.org/html/2601.21872/x6.png",
                "caption": "(b)BoN Accuracy",
                "position": 2270
            },
            {
                "img": "https://arxiv.org/html/2601.21872/x7.png",
                "caption": "Figure 6:Milestone creation under multiple equivalent paths in GitLab. Checklist-based WebShepherd prefers a procedurally typical but non-essential navigation step under path multiplicity, while WebArbiter reasons over the current state and correctly selects the action that directly advances milestone creation.",
                "position": 2306
            },
            {
                "img": "https://arxiv.org/html/2601.21872/x8.png",
                "caption": "Figure 7:Merge request identification under an ambiguous context. When the target merge request is not yet identified, WebShepherd prematurely commits to an arbitrary request, whereas WebArbiter reasons about task preconditions and prioritizes disambiguation via search.",
                "position": 2309
            }
        ]
    },
    {
        "header": "Appendix HCase Study: WebArbiter vs. WebShepherd",
        "images": []
    }
]