[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/figures/Motivation.png",
                "caption": "Figure 1:LEGO-Evalperforms multi-hop grounding using tool-retrieved multimodal information (left), whereas VLMs fail to ground pencils in the scene (right).",
                "position": 144
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3LEGO-Eval: Evaluation with Tool-Augmented VLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/figures/Overview.png",
                "caption": "Figure 2:Overview ofLEGO-Eval.LEGO-Evalplans tool execution using diverse tools, and selects arguments before executing each tool. Constraints are evaluated using the collected outputs.",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2511.03001/figures/toolset.png",
                "caption": "Figure 3:Diverse tools included in our tool set.",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2511.03001/figures/BenchStatistics.png",
                "caption": "Figure 4:Statistics ofLEGO-Bench.",
                "position": 328
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/figures/ToolStatistics.png",
                "caption": "Figure 5:Distribution of tool types executed byLEGO-Evalduring evaluation.",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2511.03001/icons/mmr.png",
                "caption": "Table 2:Performance drop with tool types disabled.\n(M: Multimodal Reasoning,T: Textual Reasoning,E: Environment Interaction)",
                "position": 592
            },
            {
                "img": "https://arxiv.org/html/2511.03001/icons/text.png",
                "caption": "",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2511.03001/icons/env.png",
                "caption": "",
                "position": 621
            },
            {
                "img": "https://arxiv.org/html/2511.03001/figures/ConstraintComplexity.png",
                "caption": "Figure 6:Holistic SR drops as the complexity of the instruction rises.",
                "position": 747
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/figures/Refinement.png",
                "caption": "Figure 7:Comparison of refinement results using VLM-as-a-judge andLEGO-Evalas feedback signal.",
                "position": 898
            },
            {
                "img": "https://arxiv.org/html/2511.03001/figures/CaseStudy.png",
                "caption": "Figure 8:Comparison of evaluation results from VLM-as-a-judge, SceneEval, andLEGO-Eval.",
                "position": 916
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AThe Usage of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix BLEGO-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/figures/AnnotationTool.png",
                "caption": "Figure 9:Our annotation tool used for annotating constraints.",
                "position": 947
            },
            {
                "img": "https://arxiv.org/html/2511.03001/figures/AnnotationTool2.png",
                "caption": "Figure 10:Interface of Label Studio for constraint classification.",
                "position": 951
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/wordcloud_0_129.png",
                "caption": "Figure 11:Word cloud illustrating the diversity of instructions inLEGO-Bench.",
                "position": 1016
            }
        ]
    },
    {
        "header": "Appendix CLEGO-Eval",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/survey_1.png",
                "caption": "Figure 12:Our survey examples for asking human to describe the room.",
                "position": 1328
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/survey_2.png",
                "caption": "",
                "position": 1331
            }
        ]
    },
    {
        "header": "Appendix EBaselines",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/0_image.png",
                "caption": "Figure 13:Example image input for VLM-as-a-judge",
                "position": 1352
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/90_image.png",
                "caption": "",
                "position": 1355
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/180_image.png",
                "caption": "",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/270_image.png",
                "caption": "",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/clip_topdown_input.png",
                "caption": "Figure 14:Example image input for CLIPSCORE",
                "position": 1361
            }
        ]
    },
    {
        "header": "Appendix FLimitations",
        "images": []
    },
    {
        "header": "Appendix GExamples of Tool Image Outputs",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/topdown_scene.jpg",
                "caption": "Figure 15:Example Image Output of get topdown scene.",
                "position": 1392
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/topdown_room.jpg",
                "caption": "Figure 16:Example Image Output of get topdown room.",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/get_frontview.jpg",
                "caption": "Figure 17:Example Image Output of get frontview object.",
                "position": 1398
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/wall_1.jpg",
                "caption": "Figure 18:Example Image Output of get wall scene.",
                "position": 1401
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/wall_2.jpg",
                "caption": "",
                "position": 1404
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/topdown_new.png",
                "caption": "Figure 19:Example Image Output of get topdown object.",
                "position": 1408
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/material_image.png",
                "caption": "Figure 20:Example Image Output of get material image.",
                "position": 1411
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/multi_1.png",
                "caption": "Figure 21:Example Image Output of get multiview rendered object.",
                "position": 1414
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/multi_2.png",
                "caption": "",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/multi_3.png",
                "caption": "",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/multi_4.png",
                "caption": "",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2511.03001/tables/appendix/figure/spatial_new.png",
                "caption": "Figure 22:Example Image Output of get spatial relation.",
                "position": 1423
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x1.png",
                "caption": "Figure 23:Prompt used for Argument Selection in scene-component ID list generation tools.",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x2.png",
                "caption": "Figure 24:Prompt used for argument selection in scene-component information retrieval tools.",
                "position": 1434
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x3.png",
                "caption": "Figure 25:Prompt used for argument selection in scene-component information retrieval tools.",
                "position": 1437
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x4.png",
                "caption": "Figure 25:Prompt used for Argument Selection in scene-component visual rendering tools.",
                "position": 1440
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x5.png",
                "caption": "Figure 26:Prompt used for Argument Selection in object-level visual rendering tools.",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x6.png",
                "caption": "Figure 27:Prompt used for Argument Selection in object-level visual rendering tools.",
                "position": 1446
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x7.png",
                "caption": "Figure 27:Prompt used for Argument Selection in the spatial-relation visualization tool.",
                "position": 1449
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x8.png",
                "caption": "Figure 28:Prompt used for Argument Selection in the spatial-relation visualization tool.",
                "position": 1452
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x9.png",
                "caption": "Figure 28:Prompt used for Constraint Classification.",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x10.png",
                "caption": "Figure 29:Prompt used for Constraint Classification.",
                "position": 1458
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x11.png",
                "caption": "Figure 30:Prompt used for Constraint Identification.",
                "position": 1461
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x12.png",
                "caption": "Figure 30:Prompt used in Constraint Validation for Floor Layout constraints.",
                "position": 1464
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x13.png",
                "caption": "Figure 31:Prompt used in Constraint Validation for Floor Layout constraints.",
                "position": 1467
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x14.png",
                "caption": "Figure 31:Prompt used in Constraint Validation for Material Selection constraints.",
                "position": 1470
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x15.png",
                "caption": "Figure 32:Prompt used in Constraint Validation for Material Selection constraints.",
                "position": 1473
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x16.png",
                "caption": "Figure 32:Prompt used in Constraint Validation for Object Placement constraints.",
                "position": 1476
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x17.png",
                "caption": "Figure 33:Prompt used in Constraint Validation for Object Placement constraints.",
                "position": 1479
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x18.png",
                "caption": "Figure 33:Prompt used in Constraint Validation for Object Selection constraints.",
                "position": 1482
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x19.png",
                "caption": "Figure 34:Prompt used in Constraint Validation for Object Selection constraints.",
                "position": 1485
            },
            {
                "img": "https://arxiv.org/html/2511.03001/x20.png",
                "caption": "Figure 34:Prompt used for baseline VLM evaluation of instructionâ€“scene validity",
                "position": 1488
            }
        ]
    },
    {
        "header": "Appendix HPrompts used in our Works",
        "images": []
    }
]