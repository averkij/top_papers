[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19788/x1.png",
                "caption": "Figure 1:An illustration of responses from DeepSeek-R1-Distill-Qwen-7B and the transformed MinD-7B model on the same math problem. The original LRM follows a think-then-answer format, where the reasoning process consists of multiple thinking units (the start of each new unit is marked with an orange highlight). In contrast, MinD-7B adopts a multi-turn reasoning paradigm, where each turn contains a thinking unit followed by an answer. Also note that MinD-7B tends to use fewer thinking units due to the GRPO training (see Section3.3).",
                "position": 121
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19788/x2.png",
                "caption": "Figure 2:Left:An example of a standard CoT from DeepSeek-R1, naturally containing multiple discrete thinking units (the start of each new unit is marked with an orange highlight).Right:Empirical analysis of unit-level redundancy, which is calculated based onEquation5, in R1-distilled models on the MATH-500 dataset, showing an average redundancy rate of 69.8% for the 1.5B model and 35.8% for the 7B model.",
                "position": 184
            },
            {
                "img": "https://arxiv.org/html/2505.19788/x3.png",
                "caption": "Figure 3:Transforming think-then-answer LRMs into a multi-turn reasoning paradigm, consisting of four steps:\n(1) Rejection sampling to filter out responses with correct final answers;\n(2) Unit segmentation using GPT-4o to divide CoTs into discrete reasoning units;\n(3) Intermediate answer completion to extract answers (aksubscriptùëéùëòa_{k}italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT) for each prefix sub-trace (t‚â§ksubscriptùë°absentùëòt_{\\leq k}italic_t start_POSTSUBSCRIPT ‚â§ italic_k end_POSTSUBSCRIPT);\nand (4) SFT to align LRMs with the multi-turn format.",
                "position": 287
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19788/x4.png",
                "caption": "Figure 4:TTFT (time to first token) and total latency of two DeepSeek-R1-distilled models on MATH-500. MinD achieves up to 4.2√ó\\times√ó(1.5B) and 2.1√ó\\times√ó(7B) speedups over the original LRMs in TTFT, and 3.2√ó\\times√ó(1.5B) and 1.6√ó\\times√ó(7B) in total latency.",
                "position": 897
            },
            {
                "img": "https://arxiv.org/html/2505.19788/x4.png",
                "caption": "Figure 4:TTFT (time to first token) and total latency of two DeepSeek-R1-distilled models on MATH-500. MinD achieves up to 4.2√ó\\times√ó(1.5B) and 2.1√ó\\times√ó(7B) speedups over the original LRMs in TTFT, and 3.2√ó\\times√ó(1.5B) and 1.6√ó\\times√ó(7B) in total latency.",
                "position": 900
            },
            {
                "img": "https://arxiv.org/html/2505.19788/x5.png",
                "caption": "Figure 5:The distribution of reasoning turns for MinD at different training stages (1.5B model) on the MATH-500 dataset. Each bar represents a model checkpoint, including the SFT model and successive GRPO training steps. As GRPO training progresses, the number of reasoning turns per output decreases and becomes increasingly concentrated at 1 or 2 turns (highlighted in red and orange), demonstrating the effectiveness of GRPO in mitigating reasoning redundancy.",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2505.19788/x6.png",
                "caption": "Figure 6:Left:Comparison of GRPO training with and without‚Ñõunitsubscript‚Ñõunit\\mathcal{R}_{\\text{unit}}caligraphic_R start_POSTSUBSCRIPT unit end_POSTSUBSCRIPTon MATH-500 for different 1.5B model checkpoints, showing Average Output Tokens for each. Removing‚Ñõunitsubscript‚Ñõunit\\mathcal{R}_{\\text{unit}}caligraphic_R start_POSTSUBSCRIPT unit end_POSTSUBSCRIPTleads to instability and collapse in output length.Right:An illustrative case comparing the outputs of GRPO-100-step and GRPO-400-step checkpoints trained without‚Ñõunitsubscript‚Ñõunit\\mathcal{R}_{\\text{unit}}caligraphic_R start_POSTSUBSCRIPT unit end_POSTSUBSCRIPT. While the earlier checkpoint (GRPO-100) maintains clear multi-turn reasoning, the later checkpoint (GRPO-400) exhibits several thinking units within a single turn (the start of each new unit is marked with an orange highlight), demonstrating that omitting‚Ñõunitsubscript‚Ñõunit\\mathcal{R}_{\\text{unit}}caligraphic_R start_POSTSUBSCRIPT unit end_POSTSUBSCRIPTresults in blurred step boundaries and loss of controllable, structured reasoning.",
                "position": 1009
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AWord Frequency Analysis of Thinking Units",
        "images": []
    },
    {
        "header": "Appendix BPrompting for MinD",
        "images": []
    }
]