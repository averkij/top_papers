[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/teaser_couple_pottery_16_9.jpeg",
                "caption": "(a)Text-to-image generation",
                "position": 149
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/teaser_couple_pottery_16_9.jpeg",
                "caption": "",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/chameleon.jpeg",
                "caption": "",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/teaser/teaser.jpg",
                "caption": "(b)Finetuning",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/edifyctrl_results/controled_generation.jpg",
                "caption": "(c)Additional control",
                "position": 186
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Dimension-Varying EDM",
        "images": []
    },
    {
        "header": "31‚Å¢K1ùêæ1K1 italic_KGeneration Using Two-Stage Laplacian Diffusion Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/x1.png",
                "caption": "Figure 3:Model architecture.As shown in the left panel, our diffusion models use a U-Net based architecture with a sequence of residual blocks with skip connections. We use wavelet and Inverse wavelet transform at the beginning and end of the network to bring down the spatial resolution of the images. In the right panel, we show how the256256256256and1‚Å¢K1ùêæ1K1 italic_K-resolution models are combined in a 2-stage cascade to generate the1024102410241024-resolution image.",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/robot_painting_latest.jpg",
                "caption": "Figure 4:Samples generated by our text-to-image model with 16:9, 1:1 and 9:16 aspect ratios.",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/friends_camping.jpeg",
                "caption": "",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/landscape_2.jpeg",
                "caption": "",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/golden_brain.jpeg",
                "caption": "",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/goldsmith.jpeg",
                "caption": "",
                "position": 567
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/food_table.jpeg",
                "caption": "",
                "position": 571
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/palace_reflections.jpeg",
                "caption": "",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/astronaut_meditating.jpeg",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/couple_dinner.jpg",
                "caption": "Figure 5:Long prompt generation.Edify Image can faithfully generate images from long descriptive prompts.",
                "position": 638
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/girl_coffee_shop.jpeg",
                "caption": "",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/painting_watercolor2.jpeg",
                "caption": "",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/mouse_kayaking_2.jpeg",
                "caption": "",
                "position": 682
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity5.jpeg",
                "caption": "Figure 6:Human diversity.Our model is able to generate images with good gender and race diversity. The prompt used is\"A studio portrait of a smart CEO\".",
                "position": 765
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity2.jpeg",
                "caption": "",
                "position": 769
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity6.jpeg",
                "caption": "",
                "position": 770
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity8.jpeg",
                "caption": "",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity3.jpeg",
                "caption": "",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity1.jpeg",
                "caption": "",
                "position": 775
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity4.jpeg",
                "caption": "",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_diversity/diversity7.jpeg",
                "caption": "",
                "position": 777
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/palace_overhead.jpeg",
                "caption": "Figure 7:Camera controls - Pitch.",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/palace_eye_level.jpeg",
                "caption": "",
                "position": 791
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/palace_underneath.jpeg",
                "caption": "",
                "position": 792
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/three_women_overhead.jpeg",
                "caption": "",
                "position": 798
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/three_women_eye_level.jpeg",
                "caption": "",
                "position": 799
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/three_women_underneath.jpeg",
                "caption": "",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/chef_shallow_16_9.jpeg",
                "caption": "Figure 8:Camera controls - Depth of field.",
                "position": 808
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/chef_deep_16_9.jpeg",
                "caption": "",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/girl_coffee_shallow_16_9.jpeg",
                "caption": "",
                "position": 822
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/2D_1K_res/girl_shallow_deep_16_9.jpeg",
                "caption": "",
                "position": 823
            }
        ]
    },
    {
        "header": "44‚Å¢K4ùêæ4K4 italic_KUpsampling",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/x2.jpeg",
                "caption": "Figure 9:4‚Å¢K4ùêæ4K4 italic_KUpsampling results.Full (top) and zoomed-in images (bottom) show the additional details.",
                "position": 874
            },
            {
                "img": "https://arxiv.org/html/2411.07126/x2.jpeg",
                "caption": "",
                "position": 877
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/upsampling/scene_1k_zoomed.jpg",
                "caption": "",
                "position": 882
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/upsampling/scene_4k_zoomed.jpg",
                "caption": "",
                "position": 886
            },
            {
                "img": "https://arxiv.org/html/2411.07126/x3.jpeg",
                "caption": "Figure 10:4‚Å¢K4ùêæ4K4 italic_KUpsampling results.Full (top) and zoomed-in images (bottom) show the additional details.",
                "position": 892
            },
            {
                "img": "https://arxiv.org/html/2411.07126/x3.jpeg",
                "caption": "",
                "position": 895
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/upsampling/human_zoomed_1k.jpg",
                "caption": "",
                "position": 900
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/upsampling/human_zoomed_4k.jpg",
                "caption": "",
                "position": 904
            }
        ]
    },
    {
        "header": "5Generation with Additional Control",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/x4.png",
                "caption": "Figure 11:Model architecture with additional control inputs.The base model is frozen when training the ControlNet encoders. The Image Input Blocks are initialized from the base model U-Net. The Hint Input Blocks are randomly initialized.",
                "position": 952
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/controlnet_result2.jpg",
                "caption": "Figure 12:Results with additional control inputs for inpainting, depth, and edge.For each input condition, we generate 3 variants using different text prompts.",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/controlnet/control_strength.jpg",
                "caption": "Figure 13:Results with different control weight values for depth-to-image and edge-to-image.",
                "position": 988
            }
        ]
    },
    {
        "header": "6360‚àòHDR Panorama Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result1.jpg",
                "caption": "(a)sunset at a lookout point in a gravel parking lot with blue sky and a few autumn maple trees and beautiful smokey mountains in the background, scenic nature, inspiring, landscape panoramic, mountains.",
                "position": 1011
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result1.jpg",
                "caption": "(a)sunset at a lookout point in a gravel parking lot with blue sky and a few autumn maple trees and beautiful smokey mountains in the background, scenic nature, inspiring, landscape panoramic, mountains.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result2.jpg",
                "caption": "(b)flat sand beach by a lake in the swiss alps mountains at noon with beautiful swiss alps mountains in the background, god rays, scenic nature, inspiring, landscape panoramic.",
                "position": 1020
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/360_result3.jpg",
                "caption": "(c)moss and grass plains in scottish highlands, scotland, remote, photography, wilderness, moody cloudy sky, rain, bluffs in background.",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop0.jpg",
                "caption": "(a)ev+0",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop0.jpg",
                "caption": "(a)ev+0",
                "position": 1036
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-2.jpg",
                "caption": "(b)ev-2",
                "position": 1041
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-5.jpg",
                "caption": "(c)ev-5",
                "position": 1046
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/360/blue_sky_at_noon_in_the_desert_with_sand_stop-9.jpg",
                "caption": "(d)ev-9",
                "position": 1051
            }
        ]
    },
    {
        "header": "7Finetuning for Customization",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/10_80_old/07b472.jpeg",
                "caption": "Figure 16:The finetuned model is capable of generating realistic images of her at different ages and in a variety of scenarios that were not included in the finetuning dataset\n(Fig.23).",
                "position": 1125
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/10_80_old/0399eb.jpeg",
                "caption": "",
                "position": 1133
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/fangyin_scenarios/30f029.jpeg",
                "caption": "",
                "position": 1134
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/fangyin_outfits/04577c.jpeg",
                "caption": "",
                "position": 1135
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/sid_sj/368b13.jpeg",
                "caption": "",
                "position": 1153
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/sid/28421a.jpeg",
                "caption": "",
                "position": 1157
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/sj/3a6db8.jpeg",
                "caption": "",
                "position": 1161
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/icon/359324.jpeg",
                "caption": "",
                "position": 1182
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/icon/1b0e73.jpeg",
                "caption": "",
                "position": 1186
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/icon/39b80e.jpeg",
                "caption": "",
                "position": 1190
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/icon/368e05.jpeg",
                "caption": "",
                "position": 1194
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/car/1a7b55.jpeg",
                "caption": "Figure 19:The finetuned model is capable of learning multiple new styles while retaining knowledge of existing ones.",
                "position": 1255
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/car/377b0c.jpeg",
                "caption": "",
                "position": 1263
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/car/162714.jpeg",
                "caption": "",
                "position": 1264
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/car/333adc.jpeg",
                "caption": "",
                "position": 1265
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/controlnet/inpainting.jpeg",
                "caption": "",
                "position": 1289
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/controlnet/04d231.jpeg",
                "caption": "",
                "position": 1293
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/controlnet/005224.jpeg",
                "caption": "",
                "position": 1297
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/controlnet/0bc0da.jpeg",
                "caption": "",
                "position": 1303
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/controlnet/1924ba.jpeg",
                "caption": "",
                "position": 1307
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/controlnet/39c5f5.jpeg",
                "caption": "",
                "position": 1311
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/2e35c0.jpeg",
                "caption": "Figure 21:Effect of data diversity.Both training datasets lack explicit age labels in the captions and contain only images of the subject in her 20s. However, a more diverse training dataset facilitates generating the character across a broader range of ages.",
                "position": 1327
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/05e84c.jpeg",
                "caption": "",
                "position": 1342
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/1be844.jpeg",
                "caption": "",
                "position": 1343
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/202724.jpeg",
                "caption": "",
                "position": 1344
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/034583.jpeg",
                "caption": "",
                "position": 1358
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/116a52.jpeg",
                "caption": "",
                "position": 1359
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/37ece7.jpeg",
                "caption": "",
                "position": 1360
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/4k_compressed/data_diversity/222f81.jpeg",
                "caption": "",
                "position": 1361
            }
        ]
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "Appendix AContributors and Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix BMore Discussions on Laplacian Diffusion Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/formulation/elaphant_noise_free.png",
                "caption": "Figure 22:(Top) Noise-free imagesùê±ùê±{\\mathbf{x}}bold_xat different resolutions,256,128,64,322561286432256,128,64,32256 , 128 , 64 , 32. (Bottom) Noisy imagesùê±+0.02‚Å¢œµùê±0.02italic-œµ{\\mathbf{x}}+0.02\\epsilonbold_x + 0.02 italic_œµat different resolutions,œµitalic-œµ\\epsilonitalic_œµhas zero mean and identity matrix as covariance. From left to right in the bottom row, the images look less and less noisy, because the signal-to-noise ratio increases when we downsample the noisy images.",
                "position": 1489
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/formulation/elaphant_noisy.png",
                "caption": "",
                "position": 1493
            }
        ]
    },
    {
        "header": "Appendix CFinetuning Training Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/fangyin_120_selected_grid_improved-min.jpg",
                "caption": "Figure 23:Training images used for single-subject personalization.",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/sid_sj_grid_improved-min.jpg",
                "caption": "Figure 24:Training images used for multi-subject personalization.",
                "position": 1684
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/icon_grid_improved-min.jpg",
                "caption": "Figure 25:Training images used for single-subject stylization.",
                "position": 1687
            },
            {
                "img": "https://arxiv.org/html/2411.07126/extracted/5983786/images/finetuning/training_data/car_grid_improved-min.jpg",
                "caption": "Figure 26:Training images used for multi-subject stylization.",
                "position": 1690
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]