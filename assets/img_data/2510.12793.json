[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12793/x1.png",
                "caption": "(a)",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2510.12793/x1.png",
                "caption": "(a)",
                "position": 111
            },
            {
                "img": "https://arxiv.org/html/2510.12793/x2.png",
                "caption": "(b)",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Visual Consistency Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12793/x3.png",
                "caption": "Figure 2:Training procedure of Visual Consistency Learning (ViCO).During the Consistency Training stage, the model aligns outputs under different compression rates. During the Router Training, the Visual Resolution Router (ViR) is trained to determine the appropriate compression for each patch based on its effect on model predictions.",
                "position": 186
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12793/fig/combined_3x3_exp.jpg",
                "caption": "Figure 3:Visualization of Routing Results of the InternVL3.5-8B ViCO Model.White-shaded patches are compressed to 64 tokens, while unshaded patches retain 256 tokens. Each patch is annotated with the router’s confidence score, where higher values indicate a stronger tendency for compression.",
                "position": 928
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "ETHICS STATEMENT",
        "images": []
    },
    {
        "header": "REPRODUCIBILITY STATEMENT",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATHE USE OF LARGE LANGUAGE MODELS (LLMS)",
        "images": []
    },
    {
        "header": "Appendix BPerformance of ViCO on small-scale models",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.12793/fig/combined_3x3_append.jpg",
                "caption": "Figure 4:Routing results of the InternVL3.5-8B ViCO model on images split into3×33\\times 3patches.Grey-shaded patches are compressed to 64 tokens, while unshaded patches retain 256 tokens. Each patch is annotated with the router’s confidence score, where higher values indicate a stronger preference for compression.",
                "position": 1855
            },
            {
                "img": "https://arxiv.org/html/2510.12793/fig/combined_4x3_multiline.jpg",
                "caption": "Figure 5:Routing results of the InternVL3.5-8B ViCO model on images split into3×43\\times 4patches.Grey-shaded patches are compressed to 64 tokens, while unshaded patches retain 256 tokens. Each patch is annotated with the router’s confidence score, where higher values indicate a stronger preference for compression.",
                "position": 1858
            }
        ]
    },
    {
        "header": "Appendix CVisualization of Router",
        "images": []
    }
]