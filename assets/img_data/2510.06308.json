[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/figures/Lumina-DiMOO.png",
                "caption": "",
                "position": 157
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x1.png",
                "caption": "Figure 1:Overview of Lumina-DiMOO’s Versatile Multi-Modal Capabilities and Superior Performance.",
                "position": 367
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x2.png",
                "caption": "Figure 2:Characteristics Comparison Among Existing Unified Models.The overall architecture has transitioned from the initial pure autoregressive (AR), which also involved adding Diffusion Head after AR, to a combination of AR and discrete diffusion, and ultimately to the current model using pure discrete diffusion.",
                "position": 407
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x3.png",
                "caption": "Figure 3:An Overview of Lumina-DiMOO’s Discrete Diffusion Modeling.(a) Training: Lumina-DiMOO is trained on text and image tokens with mask. (b) Inference: Lumina-DiMOO predicts the masked tokens, refining its output progressively.",
                "position": 441
            }
        ]
    },
    {
        "header": "3Lumina-DiMOO",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x4.png",
                "caption": "Figure 4:Example of token logits statistics, illustrating that tokens with high maximal logit tend to have stable representations.",
                "position": 724
            }
        ]
    },
    {
        "header": "4Training Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x5.png",
                "caption": "Figure 5:Overview of the Proposed Self-GRPO Framework.Self-GRPO unifies text-to-image (T2I) generation and multi-modal understanding (MMU) under trajectory-consistent reinforcement learning.",
                "position": 892
            }
        ]
    },
    {
        "header": "5Data Construction",
        "images": []
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x6.png",
                "caption": "Figure 6:Qualitative Comparison on Text-to-Image Generation.We compare Lumina-DiMOO, MMaDA, Janus Pro, BAGEL, and GPT-4o across various common scenarios. Notably, MMaDA and Janus Pro lack support for arbitrary resolution generation.",
                "position": 2395
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x7.png",
                "caption": "Figure 7:Qualitative Results on Text-guided Image Inpainting and Extrapolation.",
                "position": 2398
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x8.png",
                "caption": "Figure 8:Qualitative Comparison on Controllable and Subject-Driven Generation Tasks.We compare Lumina-DiMOO, BAGEL, and GPT-4o in object addition, removal, replacement, as well as background and style modification. Lumina-DiMOO performes well in terms of instruction adherence and resolution preservation.",
                "position": 2798
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x9.png",
                "caption": "Figure 9:Qualitative Comparison on Image Editing Tasks.We compare Lumina-DiMOO, BAGEL, and GPT-4o in object addition, removal, replacement, as well as background and style modification. Lumina-DiMOO performed well in terms of instruction adherence and resolution preservation.",
                "position": 2811
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x10.png",
                "caption": "Figure 10:Qualitative Comparison on Style Transfer Task.Lumina-DiMOO completely outperforms OmniGen, which performs worse in most cases.",
                "position": 2814
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x11.png",
                "caption": "Figure 11:Visualization of OCR, Image Caption, Mathematical Geometry, and Table Understanding Tasks.",
                "position": 3205
            }
        ]
    },
    {
        "header": "7Ablation and Extension",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06308/x12.png",
                "caption": "Figure 12:Comparison of Sampling Time on Text-to-Image and Image Understanding Tasks.For the text-to-image, Lumina-mGPT 2.0 generates images at a resolution of 768, Emu3 produces images at 720 resolution, while the other models utilize a 1024 resolution. In the image understanding task, all models consistently generate 1024 tokens.",
                "position": 3222
            },
            {
                "img": "https://arxiv.org/html/2510.06308/x13.png",
                "caption": "Figure 13:Illustration of Interactive Retouching.Users can repeatedly modify specific areas while keeping the surrounding regions unchanged until they reach satisfaction.",
                "position": 3273
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]