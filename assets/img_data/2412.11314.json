[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11314/x1.png",
                "caption": "",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11314/x2.png",
                "caption": "Figure 1:Evalica facilitates the highlighted aspects of leaderboard-making that involve aggregation of judgements, scoring the models with bootstrapped confidence intervals (CIs), and getting the final model ranks.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Design of Evalica",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11314/x3.png",
                "caption": "Figure 2:Evalica has a core in Rust that is covered by a comprehensive suite of tests in Python. We simplify prototyping and increase test reliability by keeping an independent implementation of each method in Python.",
                "position": 144
            }
        ]
    },
    {
        "header": "4Implementation Details",
        "images": []
    },
    {
        "header": "5Performance Tests",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11314/x4.png",
                "caption": "Figure 3:Performance scaling analysis of the Rust implementations in Evalica on the synthetic version of the Chatbot Arena dataset. Both scales are logarithmic. Time is in seconds, dataset size is the number of pairs; a 95% confidence interval is shown for ten runs. Lower is better.",
                "position": 299
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11314/x5.png",
                "caption": "Figure 4:A screenshot of the Evalicaâ€™s Web interface with the LLMFAO benchmark(Ustalov,2023). On the left, there are the input file, algorithm choice, and additional parameters. On the right, there is a table with the ranking results and a win rate plot. For the sake of brevity, we showed only a truncated output, with no columns corresponding to the number of compared pairs and the current rank of the model. A live example can be accessed athttps://huggingface.co/spaces/dustalov/pair2rank.",
                "position": 681
            }
        ]
    },
    {
        "header": "Appendix AUsage Examples",
        "images": []
    }
]