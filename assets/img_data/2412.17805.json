[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17805/x1.png",
                "caption": "Figure 1:Our reconstruction results compared with a line of three recent strong baseline approaches.\nThe ground truth frame is (0). Our model significantly outperforms previous methods, especially under large motion scenarios such as people doing sports.",
                "position": 105
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17805/x2.png",
                "caption": "Figure 2:Comparison of our optimal spatiotemporal modeling and the two other options. Simultaneous modeling is achieved by inflating pre-trained 2D spatial VAE to 3D VAE. Sequential modeling indicates first compressing the spatial dimension with a spatial encoder and then compressing the temporal information with a temporal encoder.\nWe identify the issues of these two options and propose to combine both advantages and achieve a much better video reconstruction quality.\nOur VAE also benefits from cross-modality, i.e., text information.",
                "position": 193
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17805/x3.png",
                "caption": "Figure 3:The architecture of our temporal-aware spatial autoencoder. We expand the 2D convolution of SD VAE[25]to 3D convolution and append one additional 3D convolution as temporal convolution after the expanded 3D convolution, which forms the STBlock3D. We also inject the cross-attention layers for cross-modal learning with textual conditions.",
                "position": 302
            },
            {
                "img": "https://arxiv.org/html/2412.17805/x4.png",
                "caption": "Figure 4:Comparisons among simultaneous spatiotemporal modeling, sequential spatiotemporal modeling and our proposed solution.",
                "position": 328
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17805/x5.png",
                "caption": "Figure 5:The effectiveness of the cross-modal learning for our video VAE. The introduction of textural information improves the detail recovery. We visualize the learned attention map using keywords of the input prompts.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2412.17805/x6.png",
                "caption": "Figure 6:The effectiveness of joint image and video training.",
                "position": 710
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]