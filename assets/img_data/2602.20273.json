[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x1.png",
                "caption": "Figure 1:Truth representations in LLMs are graded in generality and reshaped by post-training.Left:Different truth types share partially overlapping but distinct sets of truth directions. These directions lie on a spectrum from domain-general to domain-specific. The geometry of truth representations changes through post-training, pushing sycophancy into a more distant subspace from other truth types. This reorganization causes probes trained on factual truth to fail on sycophancy detection, and vice versa (X). However, training on all domains still yields a domain-general direction (X).Right:Concept erasure analysis further reveals the full spectrum of truth directions.",
                "position": 174
            }
        ]
    },
    {
        "header": "2Truthfulness Datasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x2.png",
                "caption": "Figure 2:Probing Generalization Performance.We report the average AUROC for 5-fold cross-validation onLlama-3.3-70B. Probes trained on any one of our five truth types generalize to each other, but perform poorly on sycophantic and expectation-inverted lying. A probe trained on all domains generalizes well to all domains, performing on par with the best individual probe performance.",
                "position": 288
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x3.png",
                "caption": "Figure 3:Mahalanobis cosine similarity linearly predicts OOD probe performance.Each point is a pair of datasets: the probe is trained on one and tested on the other. Mahalanobis cosine similarity achievesR2=0.98R^{2}{=}0.98, substantially outperforming standard cosine similarity (R2=0.56R^{2}{=}0.56; Figure18).",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x4.png",
                "caption": "Figure 4:Post-training reduces alignment between sycophantic lying and other truth types.(a,b)Base models show substantially better probe generalization between FLEED and sycophancy than chat models, indicating that post-training pushes sycophancy into a subspace more orthogonal to other truth types.(c)Probe direction similarity between FLEED and sycophancy is significantly higher in the base models compared to chat models.\nSee similar results onQwenfamily models in AppendixEand Figure19.",
                "position": 319
            }
        ]
    },
    {
        "header": "4Probe Generalization Across Datasets",
        "images": []
    },
    {
        "header": "5Geometry of Probe Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x5.png",
                "caption": "Figure 5:Stratified INLP Reveals Highly Domain-general and Domain-specific Directions.(a)Domain-general directions. Cross-domain accuracies for the first fivemutually-orthogonaldirections extracted by training on all domains jointly are high across all domains.(b)Domain-specific Directions. Accuracy for directions extracted from individual domains after the four domain-general directions have been projected out. While in-distribution accuracy (”Self”; blue) remains high, generalization to other domains (”Other”; yellow) drops toward chance (0.50.5; gray dashed line), indicating these directions encode truth information unique to a specific domain.",
                "position": 355
            }
        ]
    },
    {
        "header": "6Post-training Reorganizes Geometry",
        "images": []
    },
    {
        "header": "7Revealing the Spectrum of Truthfulness Directions",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x6.png",
                "caption": "Figure 6:Performance of Selected Probes after LEACE Erasure.Each row shows one probe.\nProbes’ in-distribution performance is perfect (green), while performance on erased domains drops to chance (red). Probe generalization to other domains shows selective failure. From top to bottom, the probes get increasingly more domain-specific. For performances of all probes after LEACE erasure, see Figure24in AppendixF.",
                "position": 383
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x7.png",
                "caption": "Figure 7:Effect of Causal Intervention Along Domain-General and Domain-Specific Directions Identified by Stratified INLP.We report the intervention effect (α=−2\\alpha=-2) onLlama-8Bacross different levels of baseline P(correct)/P(incorrect), binned by percentile. Most domain-specific directions improve truthfulness, while domain-general direction hurts (redrectangle). Larger effects are observed for samples where the model is initially more confident for all directions.",
                "position": 437
            }
        ]
    },
    {
        "header": "8Causal Assessment of Truth Directions",
        "images": []
    },
    {
        "header": "9Related Works",
        "images": []
    },
    {
        "header": "10Discussion & Conclusion",
        "images": []
    },
    {
        "header": "11Limitations",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x8.png",
                "caption": "Figure 8:PCA on Truth Representations Across Datasets.Scatter plot showing activations fromLlama-70Blayer 33 for honest statements (blue) and deceptive (red) samples across the four truth type datasets, sycophancy,Goldowsky-Dill et al. (2025), andMarks & Tegmark (2023). The intermixing of true and false points in the highest-variance directions demonstrates that our datasets are well-controlled, with truth directions encoded in lower-variance subspaces.",
                "position": 1505
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x9.png",
                "caption": "Figure 9:Construction of the Sycophancy Dataset.Left:We first extract the model’s true belief on MMLU STEM questions.Middle:A sycophantic example in which the user’s preferred answer differs from the model’s true belief, yet the model agrees with the user, contradicting its own belief.Right:An honest example in which the user’s preferred answer aligns with the model’s true belief.",
                "position": 1519
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x10.png",
                "caption": "Figure 10:Sycophancy Rate by Correctness and Confidence forLlama-70B.Left:Sycophancy rate across confidence percentiles, grouped by whether the model’s original answer is correct. The sycophancy rate is lower when the original answer is correct.Right:Individual responses plotted against model confidence (log scale), with the blue line indicating the mean sycophancy rate. Both panels show that higher model confidence is associated with lower sycophantic rate, regardless of answer correctness.",
                "position": 1755
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x11.png",
                "caption": "Figure 11:Probing Generalization Performances (sycophancy filtered based on correctness).Similar to Figure2, probes trained on the four truth types generalize to each other, but no prior probes generalize to sycophantic lying. Probe trained on combined domains effectively bridges gaps to the best individual probe performance for both ID and OOD.",
                "position": 1764
            }
        ]
    },
    {
        "header": "Appendix BProbe Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x12.png",
                "caption": "Figure 12:Probe Design Tuning Process.(a) First, we fix the architecture to logistic regression and the token aggregation method to average token, and then pick the top-5 layers based on average cross-domain AUROC on our FLED dataset. (b) Second, we compute the same average AUROC for all combinations of architectures and token aggregation methods across these 5 layers. The final probe design in logistic regression with the average token.",
                "position": 1832
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x13.png",
                "caption": "Figure 13:Probing Layer Tuning.We compute the average cross-domain AUROC for all models (both base and chat models forLlama-70b,Llama-8b,Qwen-14b, andQwen-7b) across layers and select the best performing layer. The first column contains chat models, and the second contains base models. Note that the best layers of the base and the chat models of the same heritage are the same for all models tested. In addition, the best layers are some intermediate layers, and the base models’ performances drop more in later layers compared to the chat models.",
                "position": 1835
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results: Probe Generalization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x14.png",
                "caption": "Figure 14:Probe Generalization Performance onLlama-8B.",
                "position": 1847
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x15.png",
                "caption": "Figure 15:Probing Performance at the Best Layers for All Models.We use logistic regression withα=1\\alpha=1here. Note that the performances on the right (base models) are much higher than the ones on the left (chat models).",
                "position": 1850
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results: Probe Direction Geometric Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x16.png",
                "caption": "Figure 16:Mahalanobis cosine similarity linearly predicts OOD probe AUROC across various distributional assumptions.Each column corresponds to a synthetic generative model of increasing realism (left to right).Top row:Mahalanobis cosine similarity between ID and OOD probe weight vectors vs. OOD AUROC.Bottom row:standard cosine similarity vs. OOD AUROC. Mahalanobis cosine similarity is consistently linearly predictive of OOD AUROC (R2≥0.957R^{2}\\geq 0.957), while standard cosine similarity is not (R2≤0.553R^{2}\\leq 0.553), confirming that whitening by the test-set covariance is necessary to capture the geometrically meaningful notion of probe alignment.",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x17.png",
                "caption": "Figure 17:Cross-domain probe transfer performance (left) compared with Mahalanobis cosine similarity (center) and standard cosine similarity (right) between probe directions.Mahalanobis cosine similarity closely tracks out-of-domain AUROC, capturing both high transfer among definitional, empirical, fictional, and logical domains and the weak transfer involving sycophancy and inverted-expertise probes. Standard cosine similarity, by contrast, fails to predict generalization performance well.",
                "position": 1866
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x18.png",
                "caption": "Figure 18:Standard Probe Cosine Similarity vs. Generalization Performance.Standard cosine similarity achieves anR2R^{2}of 0.56, which is much lower than the Mahalanobis variant (R2=0.98R^{2}=0.98; Figure3).",
                "position": 1875
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results: Post-training Geometry Reorganization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x19.png",
                "caption": "Figure 19:Post-training reduces alignment between sycophancy and other truth types (Qwen models).",
                "position": 1883
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x20.png",
                "caption": "Figure 20:Sycophancy and FLEED Cross-Domain Probing Performance for All Models Across Layers.Base models (right) consistently outperform their chat model counterparts (left).",
                "position": 1894
            }
        ]
    },
    {
        "header": "Appendix FAdditional Results: Concept-Erasure",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20273/x21.png",
                "caption": "Figure 21:Full Stage 1 of Stratified INLP.We first remove 5 dimensions trained on all domains, then 3 for the honesty benchmarks, then 4 for our FLED datasets, and finally 10 for definitional, empirical, and fictional datasets.",
                "position": 1907
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x22.png",
                "caption": "Figure 22:Cross-generalization Performance of Domain-specific Directions Identified by Stratified INLP.Note that most directions only have high performance in-domain but are at chance for other domains.",
                "position": 1910
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x23.png",
                "caption": "Figure 23:Effect of LEACE on In-distribution performance.Targeted removal of a specific truth direction reduces the AUROC of that task to chance level (0.5). Crucially, this intervention does not degrade performance on other truth types (Non-Removed Tasks). This shows the existence of distinct, domain-specific directions, despite the ability of probes to generalize across them.",
                "position": 1913
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x24.png",
                "caption": "Figure 24:Effect of LEACE for All Probes.",
                "position": 1916
            },
            {
                "img": "https://arxiv.org/html/2602.20273/x25.png",
                "caption": "Figure 25:Inferred capacities of intersecting latent truth subspaces.We formalize probe transfer and selective concept erasure as a capacity allocation problem over shared representation subspaces. The bottom matrix denotes subspace membership (black dots indicate a domain utilizes that direction), while the top bar chart displays the inferred capacity of each subspace derived viaL1L_{1}-regularized least-squares optimization. For comparison, hypothetical pure domain-general (gold) and domain-specific (red) directions are manually appended. The empirical data reveals that representations predominantly rely on a patchwork ofpartially overlappingdirections (blue) shared by 3 to 6 domains. This structure explains the asymmetric generalization and selective degradation observed during LEACE interventions: erasing a concept selectively destroys its specific intersecting capacities while leaving others intact.",
                "position": 2026
            },
            {
                "img": "https://arxiv.org/html/2602.20273/figs/causal_decomposition_bars.png",
                "caption": "Figure 26:Decomposition of log-probability changes for correct vs. incorrect answers.Effective domain-specific directions primarily suppress incorrect answers while preserving correct ones. The general direction instead boosts both, disproportionately increasing incorrect answer probability—explaining its failure despite targeting the same phenomenon.",
                "position": 2049
            }
        ]
    },
    {
        "header": "Appendix GAdditional Results: Causal Experiments",
        "images": []
    }
]