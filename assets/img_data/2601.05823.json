[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05823/x1.png",
                "caption": "Figure 1:Our Send-VAE enhances VAEs by aligning their latent representations with the semantically rich representations of pre-trained vision foundation models using a specialized mapper network. Unlike the direct alignment methods typically used during diffusion model training, this mapper network efficiently bridges the representation gap, enabling a seamless integration of semantic information. Notably, the usage of Send-VAE results in significantly more efficient and effective training of diffusion models.",
                "position": 69
            },
            {
                "img": "https://arxiv.org/html/2601.05823/x2.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05823/x3.png",
                "caption": "Figure 2:We conduct experiments with three recently proposed evaluation methods for VAE latent space, and show their correlation with down stream generation performance (g-FID). Experimental results on four VAEs with identical specifications indicate that these metrics do not accurately reflect the impact of VAEs on downstream generative performance. Conversely, we find that the ability of VAEs regarding low-level attributes is the key factor.",
                "position": 201
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05823/x4.png",
                "caption": "Figure 3:Qualitative comparisons among VA-VAE, E2E-VAE, and Send-VAE. Results for both methods are sampled using the same seed, noise and class label. The classifier-free guidance scale is set to 4.0.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2601.05823/x5.png",
                "caption": "Figure 4:Qualitative Results on ImageNet 256 Ã— 256 using Send-VAE and SiT-XL.",
                "position": 673
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]