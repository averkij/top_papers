[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x1.png",
                "caption": "Figure 1:Multimodal chain-of-thought enables test-time scaling through emergent cognitive behaviors.We propose theUniTframework for unified multimodal models, which induces subgoal decomposition for compositional tasks and unlocks content understanding and memory for multi-turn editing. Controlling the number of test-time images, chain-of-thought sequential scaling outperforms best-of-N parallel scaling across generation and reasoning benchmarks.User inputModel output",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2602.12279/x2.png",
                "caption": "",
                "position": 138
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x3.png",
                "caption": "Figure 2:Agentic framework for synthesizing chain-of-thought training data.Starting from a user prompt, an image generation model generates an initial image. A vision-language model then performs verification - evaluating whether the output satisfies the prompt. When unsatisfactory, the VLM engages in explicit subgoal decomposition through thinking tokens, planning concrete improvements, and rewriting editing instructions. This iterative loop continues until verification succeeds, generating multi-turn reasoning trajectories that teach unified models to refine outputs through test-time computation. The explicit reasoning traces of the three models capture how cognitive behaviors emerge from the interplay between generation, verification, and planning.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x4.png",
                "caption": "Figure 3:UniT enables iterative refinement for compositional instructions through multimodal chain-of-thought reasoning.UniT exhibits:(i)error verification and correction—identifying and fixing constraint violations that Bagel\nmisses (top: correcting leash placement and dog action);(ii)subgoal decomposition with subject consistency—sequentially addressing instructions while maintaining subject identity across rounds (middle: preserving bear features through style\ntransformation, bottom: skateboard consistency);(iii)quality preservation—maintaining visual fidelity through iterative refinement rather than degradation (top: reduced artifacts and haloing).",
                "position": 201
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x5.png",
                "caption": "Figure 4:Qualitative examples of chain-of-thought test-time scaling.Representative trajectories showing progressive refinement across different tasks and computational budgets. Examples demonstrate how explicit chain-of-thought reasoning enables the model to iteratively improve compositional generation.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2602.12279/x6.png",
                "caption": "Figure 5:Training vs. inference round distribution demonstrates beyond-training generalization.The model is trained on trajectories averaging 3.6 refinement rounds, but effectively generalizes to longer inference chains averaging 4.7 rounds at test time. This distribution shift reveals the model’s emergent ability to extend inference beyond its training distribution, a key property of effective test-time scaling.",
                "position": 423
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x7.png",
                "caption": "Figure 6:Chain-of-thought visual reasoning on MIRA.The model decomposes the puzzle into subgoals (zoom in, identify patterns) before selecting the matching piece, demonstrating cognitive behaviors transferring from generation to understanding tasks.",
                "position": 681
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x8.png",
                "caption": "Figure 7:Data synthesis pipeline architecture.Three model roles coordinate via information flows: Image Gen Model produces initial images, Vision-language model verifies image and performs planning/prompt rewriting with content memory, Image Editing Model applies refinements. Trajectories loop until satisfied, producing interleaved text-image chain-of-thought data.",
                "position": 942
            }
        ]
    },
    {
        "header": "Appendix AData Synthesis Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x9.png",
                "caption": "Figure 8:Detailed chain-of-thought trajectory demonstrating cognitive behaviors.This bookshelf generation example shows the model’s explicit reasoning through<think>blocks across three refinement rounds.Verification:the model identifies that books are present when the prompt specifies “no books, only picture frames.”Subgoal decomposition:the model breaks the correction into sequential steps—first removing books, then adding picture frames.Content memory:the model explicitly references and compares Images #1, #2, and #3 to track cumulative progress. The reasoning demonstrates how chain-of-thought enables iterative self-correction through explicit evaluation and planning.",
                "position": 980
            }
        ]
    },
    {
        "header": "Appendix BAdditional Qualitative Results",
        "images": []
    },
    {
        "header": "Appendix CGeneralization Preservation",
        "images": []
    },
    {
        "header": "Appendix DScaling BeyondC=10C{=}10",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12279/x10.png",
                "caption": "Figure 9:Representative failure modes.Example 1:Compositional constraints with precise object counts and spatial arrangements (napkin count).Example 2:Complex spatial relationships requiring specific geometric configurations (forks encircling plate).Examples 3,4:Layout change from the intermediate images (people count).",
                "position": 1081
            }
        ]
    },
    {
        "header": "Appendix EFailure Analysis",
        "images": []
    }
]