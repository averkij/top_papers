[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07351/x1.png",
                "caption": "Figure 1:Inefficient utilization of predictions in masked diffusion language models, where distributions are computed for all positions but only a subset are used for decoding.[M1,M2,…,Mn][M_{1},M_{2},\\dots,M_{n}]denote the initial mask tokens following promptPP, andd​i​s​tidist_{i}represents the predicted probability distribution for theii-th token in the generation sequence.\nIn this example, the total sequence of542542tokens consists of3030prompt tokens and512512generated tokens, while only two positions are updated per step.",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x2.png",
                "caption": "Figure 2:Comparison between MDLMs and EvoToken-DLM.\n(a) Standard MDLMs employ only two token states, alternating between<mask>and discrete decoded tokens, leading to abrupt mask-to-token transitions.\n(b) EvoToken-DLM introduces soft tokens represented by probability distributions and four token states, enabling tokens to evolve progressively through iterative refinement.\nThe top-right panel illustrates a quantitative comparison between the two approaches under the same settings based on LLaDA-Instruct-8B.",
                "position": 202
            }
        ]
    },
    {
        "header": "2Preliminaries on MDLMs",
        "images": []
    },
    {
        "header": "3From Discrete to Continuous: A Continuous Relaxation Perspective",
        "images": []
    },
    {
        "header": "4EvoToken-DLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07351/x3.png",
                "caption": "Figure 3:Progressive step-wise token update with blockwise decoding in EvoToken-DLM.",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x4.png",
                "caption": "Figure 4:Continuous trajectory supervision by performingΔ​τ\\Delta\\tauconsecutive refinement steps during training and applying supervision at each step, aligning the training objective with the inference process.",
                "position": 443
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07351/x5.png",
                "caption": "Figure 5:Ablation study on the presence of intermediate refinement states in EvoToken-DLM.",
                "position": 855
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x6.png",
                "caption": "Figure 6:An illustrative example of EvoToken-DLM during inference, showing intermediate refinement states for a selected subsequence across successive steps.\nThe block size is set to 12, and the refinement process for the first 16 output tokens is visualized. For each position, only the topK=3K=3most probable tokens are retained.",
                "position": 858
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x7.png",
                "caption": "Figure 7:Comparison between EvoToken and binary masking baseline on MATH500 with KV-caching and different confidence thresholds. EvoToken consistently achieves higher accuracy than baseline across various thresholds under the same average tokens per step.",
                "position": 864
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x8.png",
                "caption": "Figure 8:Comparison between EvoToken and the binary masking baseline based on another pretrained model Dream-Instruct-7B. We apply continuous trajectory supervision and evaluate performance on various datasets.",
                "position": 867
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x9.png",
                "caption": "Figure 9:Comparison between EvoToken and the binary masking baseline based on blockwise diffusion model D2F-LLaDA. We apply continuous trajectory supervision and evaluate performance on SVAMP.",
                "position": 870
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x10.png",
                "caption": "Figure 10:EvoToken-DLM exhibits competitive inference efficiency, introducing minimal latency penalties relative to standard MDLM architectures.",
                "position": 873
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x11.png",
                "caption": "Figure 11:Performance comparison between the baseline and EvoToken-DLM with different top-KKsettings on Countdown.",
                "position": 876
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAppendix Overview",
        "images": []
    },
    {
        "header": "Appendix BMore Methodological Details",
        "images": []
    },
    {
        "header": "Appendix CMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix DMore Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07351/x12.png",
                "caption": "Figure S1:Performance comparison between the baseline and EvoToken-DLM with differentα\\alphasettings on various datasets.",
                "position": 1966
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x13.png",
                "caption": "Figure S2:Additional comparison of EvoToken and the binary masking baseline based on another pretrained model LLaDA-1.5. We apply continuous trajectory supervision and evaluate performance on various benchmarks.",
                "position": 1969
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x14.png",
                "caption": "Figure S3:Additional inference example with a block size of 12, showing intermediate refinement states for a selected subsequence across successive steps. We showcase the refinement states for the first 16 output tokens based on the prompt: \"Kyle bought last year’s best-selling book for $19.50. This is with a 25% discount from the original price. What was the original price of the book?\".",
                "position": 2153
            },
            {
                "img": "https://arxiv.org/html/2601.07351/x15.png",
                "caption": "Figure S4:Additional inference example with a block size of 8, showing intermediate refinement states for a selected subsequence across successive steps. We showcase the refinement states for the first 16 output tokens based on the prompt: \"In a school there are 569 girls and 236 boys.How many more girls than boys does the school have?\".",
                "position": 2169
            }
        ]
    },
    {
        "header": "Appendix EMore Experimental Results",
        "images": []
    }
]