[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18692/x1.png",
                "caption": "Figure 1:Illustration of our motivation.\n(a) Full attention suffers from dense computing when dealing with long sequences.\n(b) Block sparse attention[27]may fail when block-level similarity is confused, resulting in unreliable attention. (c) Mixture-of-Groups attention uses a lightweight token router (i.e., asingle linear layer) that assigns tokens to specialized groups, enabling groupwise attention and efficient long-context modeling.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18692/x2.png",
                "caption": "Figure 2:Left: Our model adopts a DiT architecture with interleaved Visual Attention and Cross-Modal Attention blocks. Visual Attention exclusively processes visual content, whereas Cross-Modal Attention enables shot-level text conditioning, instantiated via either cross-attention[36]or multi-modal attention[25,10].Top-right(a): Visual Attention combining MoGA with Spatial‑Temporal Group Attention for global-local consistency.Bottom‑right(b): MoGA, where a router groups tokens and performs intra-group attention, enabling long-range global interactions.",
                "position": 218
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x3.png",
                "caption": "Figure 3:Visualization of dynamic router grouping.",
                "position": 285
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x4.png",
                "caption": "Figure 4:Multi-shot long video data pipeline.",
                "position": 356
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18692/x5.png",
                "caption": "Figure 5:Qualitative results of MoGA and other methods. We present eight representative shots, demonstrating long-content coherence, character consistency, and visual quality.",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x6.png",
                "caption": "Figure 6:Computational efficiency. The x-axis denotes the generated video duration (s). As the number of groups (MM) increases, MoGA’s FLOPs decrease substantially.",
                "position": 694
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x7.png",
                "caption": "Figure 7:One-minute video generated by MoGA.",
                "position": 727
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x8.png",
                "caption": "Figure 8:Emergence of background consistency.",
                "position": 736
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x9.png",
                "caption": "Figure 9:Animation style generation for MoGA.",
                "position": 739
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x10.png",
                "caption": "Figure 10:Visual comparison of MoGA vs. full attention for multi-shot generation with a single subject. The left column shows the subject wearing the same outfit across different shots, while the right column shows the subject changing outfits at shot transitions according to the text instructions.",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2510.18692/x11.png",
                "caption": "Figure 11:Visual ablation of MoGA and STGA.",
                "position": 810
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Details of the Computational Complexity",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18692/x12.png",
                "caption": "Figure 12:Group balancing loss curves of MoGA.",
                "position": 1654
            }
        ]
    },
    {
        "header": "7Analysis of Group Balancing Loss",
        "images": []
    }
]