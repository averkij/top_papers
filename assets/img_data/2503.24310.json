[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Proposed Framework - BEATS",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24310/x1.png",
                "caption": "Figure 1:System design of BEATS evaluation framework - the proposed framework for bias assessment in LLM. BEATS evaluates diverse set of LLMs on selected bias detection dataset. BEATS then employs a consortium of LLM-as-a-Judge to quantify a set of curated metrics related to bias, fairness, ethics, and factuality.",
                "position": 143
            }
        ]
    },
    {
        "header": "3Key Findings",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24310/x2.png",
                "caption": "Figure 2:Total cumulative bias presence scores across large language model families, as evaluated by theBEATS framework. These results highlight significant presence of bias in response across different leading models and underscore the need for bias mitigation strategies in GenAI language models.",
                "position": 610
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x3.png",
                "caption": "Figure 3:Category-wise bias presence across as evaluated by theBEATS frameworkacross five leading Large Language Models. Each bar represents the total occurrence of a specific bias category. The results highlight the complex heterogeneous bias profiles of LLMs and underscore the importance of handling diverse set of intersectional biases in Gen AI models.",
                "position": 614
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x4.png",
                "caption": "Figure 4:Hexbin density plot showing the joint distribution of Bias Severity Score and Bias Impact Score for response from all models, as evaluated by the BEATS framework using Claude-3.5 Sonnet as the Judge. The highest density is concentrated at the lowest severity and impact scores, indicating that most responses exhibit minimal bias magnitude. However, a significant number of moderate-to-high severity and impact clusters suggest a prevalent generation of responses with non-trivial ethical or societal implications. The distribution underscores the importance of diagnosing and mitigating high-risk model responses.",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x5.png",
                "caption": "Figure 5:This box-and-whisker plot illustrates the distribution of ethics related BEATS evaluation metrics across LLM-generated responses. While the median scores are high across all four metrics, indicating strong ethical alignment in most cases, the wide interquartile ranges and the presence of low outliers indicate prevalent ethical lapses. These findings underscore the importance of improving models to achieve more consistent, higher ethical standards.",
                "position": 797
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x6.png",
                "caption": "Figure 6:Violin plot showing the distributional density of ethics-related BEATS evaluation metrics across LLM-generated responses. The long lower tails suggest the presence of ethical shortcomings, particularly in harm prevention and inclusivity. These findings highlight the need to identify and remediate ethically inconsistent outputs.",
                "position": 801
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x7.png",
                "caption": "Figure 7:Box-and-whisker plot illustrating the distribution of fairness-related BEATS evaluation metrics across model responses. While the consistently high median scores indicate good overall fairness levels, the broad interquartile ranges and extended lower whiskers reveal the presence of responses with notable fairness disparities.",
                "position": 904
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x8.png",
                "caption": "Figure 8:Violin plot depicting the distributional density of fairness-related BEATS evaluation metrics across model responses. The distributions are skewed toward higher values (8â€“10), indicating strong adherence to fairness. However, the observed spread and density in the mid-to-lower score ranges reflect variability in fairness across individual responses.",
                "position": 908
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x9.png",
                "caption": "Figure 9:Box-and-whisker plot illustrating the distribution of factuality-related BEATS evaluation metrics across model outputs. The Factual Accuracy Score distribution indicates generally reliable outputs, though a few low-scoring outliers exist. The Misinformation Risk Score distribution is skewed lower, with a broader spread and upper outliers, reflecting that while most responses pose minimal risk, certain instances carry elevated potential for misinformation. These results highlight the need for fine-grained fact verification mechanisms in generative AI systems.",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x10.png",
                "caption": "Figure 10:Violin plot displaying the distributional density of factuality-related BEATS evaluation metrics across model-generated responses. The Factual Accuracy Score is skewed toward higher values, indicating that most responses are factual. The Misinformation Risk Score has a long upper tail reflecting several outputs with elevated misinformation risk. These distributions highlight the need for continual validation to safeguard against sporadic but impactful factual inconsistencies in LLM outputs.",
                "position": 996
            }
        ]
    },
    {
        "header": "4Limitations",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Path Forward - Future Research Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Appendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.24310/x11.png",
                "caption": "Figure 11:Claude as a Judge: category-wise primary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by calude.",
                "position": 1638
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x12.png",
                "caption": "Figure 12:Claude as a Judge: category-wise secondary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by calude.",
                "position": 1642
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x13.png",
                "caption": "Figure 13:OpenAI GPT 4o as a Judge: category-wise primary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by GPT-4o.",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x14.png",
                "caption": "Figure 14:OpenAI GPT 4o as a Judge: category-wise secondary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by GPT-4o.",
                "position": 1650
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x15.png",
                "caption": "Figure 15:Google Gemini 1.5 pro as a Judge: category-wise primary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by Gemini 1.5 pro",
                "position": 1654
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x16.png",
                "caption": "Figure 16:Google Gemini 1.5 pro as a Judge: category-wise secondary bias presence across LLMs as evaluated by the BEATS framework. Each bar represents the total occurrence of a specific bias category across all evaluated model as judged by Gemini 1.5 Pro",
                "position": 1658
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x17.png",
                "caption": "Figure 17:Hexbin density plot showing the joint distribution of Bias Severity Score and Bias Impact Score for response from all evaluated models, as judged by the BEATS framework. GTP 4o and Clause 3.5 show relatively similar pattern whereas Gemini shows a very distinct pattern showing that it judges the bias severity and impact differently. - All models as judge",
                "position": 1666
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x18.png",
                "caption": "Figure 18:Box-and-whisker plot illustrating the distribution of cultural sensitivity metrics across all evaluated models.",
                "position": 1677
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x19.png",
                "caption": "Figure 19:Box-and-whisker plot illustrating the distribution of ethical alignment metrics across all evaluated models.",
                "position": 1689
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x20.png",
                "caption": "Figure 20:Box-and-whisker plot illustrating the distribution of harm prevention metrics across all evaluated models.",
                "position": 1700
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x21.png",
                "caption": "Figure 21:Box-and-whisker plot illustrating the distribution of inclusivity metrics across all evaluated models.",
                "position": 1711
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x22.png",
                "caption": "Figure 22:Box-and-whisker plot illustrating the distribution of value alignment metrics across all evaluated models.",
                "position": 1722
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x23.png",
                "caption": "Figure 23:Box-and-whisker plot illustrating the distribution demographic parity metrics across all evaluated models.",
                "position": 1733
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x24.png",
                "caption": "Figure 24:Box-and-whisker plot illustrating the distribution of equal opportunity metrics across all evaluated models.",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x25.png",
                "caption": "Figure 25:Box-and-whisker plot illustrating the distribution of group fairness metrics across all evaluated models.",
                "position": 1747
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x26.png",
                "caption": "Figure 26:Box-and-whisker plot illustrating the distribution of factual accuracy metrics across all evaluated models.",
                "position": 1758
            },
            {
                "img": "https://arxiv.org/html/2503.24310/x27.png",
                "caption": "Figure 27:Box-and-whisker plot illustrating the distribution of misinformation risk metrics across all evaluated models.",
                "position": 1765
            }
        ]
    },
    {
        "header": "Glossary",
        "images": []
    },
    {
        "header": "Acronyms",
        "images": []
    }
]