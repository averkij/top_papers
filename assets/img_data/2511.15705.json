[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15705/x1.png",
                "caption": "Figure 1:Agentic thinking of GeoVista for Real-world geolocalization.\nDuring the reasoning loop, our GeoVista seamlessly integrates the image–zoom-in tool to magnify regions of interest and the web-search tool to retrieve relevant information. This web-augmented visual reasoning process enables GeoVista validate or refine its geolocalization judgments.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15705/x2.png",
                "caption": "Figure 2:Image examples from GeoBench and the training data, and the agentic pipeline of GeoVista.Given a query and image, the policy model iteratively generates thoughts and actions; each action is parsed, executed, and yields a new observation, repeating this loop until it outputs a final geolocation prediction or reaches the maximum interaction turn limit.",
                "position": 180
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x3.png",
                "caption": "Figure 3:Localizable vs Non-Localizable.We remove the non-localizable (orange) and the landmarks (purple) from GeoBench, leaving only localizable images for rigorously evaluating models.",
                "position": 379
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x4.png",
                "caption": "Figure 4:Left:The evaluation pipeline of GeoBench dataset. The evaluation system consists of (1) Level-wise evaluation, which employs both rule-based and model-based verifiers to determine correctness at different administrative levels, and (2) nuanced evaluation, which extracts the predicted address, applies geocoding to obtain the predicted geolocalization point, and computes the haversine distance to the ground-truth location.Right:Geological distribution of GeoBench.GeoBench is a high-resolution, multi-source, globally annotated dataset to evaluate models’ general geolocalization ability.",
                "position": 392
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x5.png",
                "caption": "",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x6.png",
                "caption": "Figure 5:Illustration of GeoBench dataset, along with level-wise and nuanced evaluation.",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x7.png",
                "caption": "Figure 6:Left:Thinking trajectory curation. We mimic human geolocalization by using a VLM to propose tool calls and rationales, and assemble tool-call reasoning trajectories.Right:Comparison of GeoVista-7B and its counterpart w/o Hierarchical Reward.",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x8.png",
                "caption": "",
                "position": 474
            }
        ]
    },
    {
        "header": "4Training Recipe",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15705/x9.png",
                "caption": "Figure 7:Left:The performance on the panorama validation set during the RL stage.We observe nearly log-linear performance gains on the 512-panorama validation set.Right:The tool fail rate during RL training.The model’s erroneous tool-call rate decreases during RL, suggesting it learns to avoid invalid or malformed calls, leading to improved performance.",
                "position": 924
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x10.png",
                "caption": "",
                "position": 933
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix ARaw Data Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15705/x11.png",
                "caption": "Figure 8:The panorama pipeline in GeoBench and GeoVista training data.",
                "position": 962
            },
            {
                "img": "https://arxiv.org/html/2511.15705/x12.png",
                "caption": "Figure 9:The Reasoning Trajectory of GeoVista.We provide additional cases to facilitate the analysis of GeoVista’s reasoning trajectories and behavioral patterns, including one satellite-image example and one photo example from GeoBench.",
                "position": 998
            }
        ]
    },
    {
        "header": "Appendix BCase Study",
        "images": []
    }
]