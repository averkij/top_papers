[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16075/x1.png",
                "caption": "Figure 1:Our method is inspired by the natural human writing process, which includes\nplanning, drafting, and multiple revisions to the draft.",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x2.png",
                "caption": "Figure 2:Illustration of ourTest-Time Diffusion Deep Researcher (TTD-DR)framework, designed to mimic the iterative nature of human research through adraft. A user query initiates both a preliminary draft and a research plan. This evolving draft, along with the research plan, dynamically informs the generation of search questions and subsequent information retrieval to be timely and coherent, while reducing information loss. The retrieved information is then leveraged todenoiseand refine the initial draft in a continuous feedback loop. The entire workflow is further optimized by a self-evolutionary algorithm to enhance the quality of the research plan, generated questions, answers, and the final report, demonstrating the synergistic power of diffusion and self-evolution in achieving superior research outcomes.",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x3.png",
                "caption": "(a)Huggingface Open DR",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x3.png",
                "caption": "(a)Huggingface Open DR",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x4.png",
                "caption": "(b)GPT Researcher",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x5.png",
                "caption": "(c)Open Deep Research",
                "position": 310
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x6.png",
                "caption": "(d)Test-Time Diffusion DR (ours)",
                "position": 315
            }
        ]
    },
    {
        "header": "2Test-Time Diffusion Deep Researcher (TTD-DR)",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16075/x7.png",
                "caption": "Figure 4:Our backbone DR agent operates in three stages, as illustrated above.Stage 1generates a detailed research plan that outlines the final reportâ€™s structure and guides the information search.Stage 2iteratively generates search questions (2a) and then uses a RAG-like system to synthesize precise answers from retrieved documents (2b), rather than saving raw data. Finally,Stage 3synthesizes all gathered information to produce the final report. Each stage can be individually optimized using a self-evolutionary algorithm detailed in Sec.2.2.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x8.png",
                "caption": "Figure 5:Illustration of the component-wiseSelf-Evolutionapplied to Search Answer (Stage 2b in Figure4). The process starts with multiple variants of initial answers. Each variant then undergoes a self-evolving episode where it first interacts with the environment to obtain a fitness score and feedback. It is then revised based on the feedback. This process repeats until the maximum number of iterations is reached. Finally, multiple revised variants from all episodes are merged to produce the final answer.",
                "position": 386
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16075/x9.png",
                "caption": "(a)LongForm Research",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x9.png",
                "caption": "(a)LongForm Research",
                "position": 521
            },
            {
                "img": "https://arxiv.org/html/2507.16075/x10.png",
                "caption": "(b)HLE-search",
                "position": 526
            }
        ]
    },
    {
        "header": "4Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/revision_step_perf_research.png",
                "caption": "(a)Pareto frontier for revision steps.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/revision_step_perf_research.png",
                "caption": "(a)Pareto frontier for revision steps.",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/pareto_frontier_research.png",
                "caption": "(b)Pareto frontier for different DR designs.",
                "position": 683
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/metrics_research.png",
                "caption": "(a)LongForm Research",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/metrics_research.png",
                "caption": "(a)LongForm Research",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/metrics_deepconsult.png",
                "caption": "(b)DeepConsult",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/query_complexity.png",
                "caption": "(a)Query complexity comparison.",
                "position": 837
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/query_complexity.png",
                "caption": "(a)Query complexity comparison.",
                "position": 840
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/answer_complexity.png",
                "caption": "(b)Answer complexity comparison.",
                "position": 845
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/query_novelty.png",
                "caption": "(a)Cumulative search query novelty.",
                "position": 852
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/query_novelty.png",
                "caption": "(a)Cumulative search query novelty.",
                "position": 855
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/answer_coverage.png",
                "caption": "(b)Report information attribution.",
                "position": 860
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/denoising_evolution_gap.png",
                "caption": "(c)Performance gap: denoising v.s. self-evolution w/ 20 steps.",
                "position": 865
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16075/x11.png",
                "caption": "Figure 11:Helpfulness, Comprehensiveness, and side-by-side rating between Report A and B. Report are simplified for clarify purpose.",
                "position": 1995
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/revision_step_perf_hle.png",
                "caption": "(a)Pareto frontier for different DR designs.",
                "position": 2289
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/revision_step_perf_hle.png",
                "caption": "(a)Pareto frontier for different DR designs.",
                "position": 2290
            },
            {
                "img": "https://arxiv.org/html/2507.16075/extracted/6639007/diagrams/pareto_frontier_hle.png",
                "caption": "Figure 13:Pareto frontier between DR agent performances and latency for HLE-search. The dots from left to right represent 1)Gemini-2.5-pro w/ search tool, 2)Backbone DR Agent, 3)+Self-evolutionand 4)+Diffusion with Retrieval, which shows our final algorithm is most efficient in terms of test-time scaling (steepest slope).",
                "position": 2295
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]