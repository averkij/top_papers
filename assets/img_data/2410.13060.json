[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "",
        "images": []
    },
    {
        "header": "AERO: Softmax-Only LLMs for EfficientPrivate Inference",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13060/x1.png",
                "caption": "Figure 1:Latency and communication savings through nonlinearity and FLOPs reduction steps when AERO is applied on GPT-2, and trained from scratch on CodeParrot dataset. Further, we benchmark AERO against the SOTAHe & Hofmann (2024)at iso-latency points. See Table3for a detail analysis.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x2.png",
                "caption": "Figure 2:An illustration of threat model and cryptographic protocols used for LLM private inference.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x3.png",
                "caption": "(a)Headwise entropy distribution",
                "position": 403
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x3.png",
                "caption": "(a)Headwise entropy distribution",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x3.png",
                "caption": "(a)Headwise entropy distribution",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x4.png",
                "caption": "(b)Loss curve",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x5.png",
                "caption": "(a)Layerwise learnable slope",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x5.png",
                "caption": "(a)Layerwise learnable slope",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x6.png",
                "caption": "(b)Global learnable slope",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x7.png",
                "caption": "(a)SM + LN + G",
                "position": 528
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x7.png",
                "caption": "(a)SM + LN + G",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x8.png",
                "caption": "(b)SM + LN + R",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x9.png",
                "caption": "(c)SM + G",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x10.png",
                "caption": "(d)SM + R",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x11.png",
                "caption": "(a)Layerwise NaNs",
                "position": 566
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x11.png",
                "caption": "(a)Layerwise NaNs",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x12.png",
                "caption": "(b)Entropy heatmap",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x13.png",
                "caption": "(a)Weight normalization in FFN",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x13.png",
                "caption": "(a)Weight normalization in FFN",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x14.png",
                "caption": "(b)Spectral normalization in FFN",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x15.png",
                "caption": "(c)Learnable scaling of FFN outputs",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x16.png",
                "caption": "Figure 7:Overview of the proposed AERO method for reducing nonlinearities and FLOPs in transformer-based LLMs for efficient PI. The bottom of the figure shows the evolution of entropy in the attention mechanism and its distribution across attention heads.",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x17.png",
                "caption": "Figure 8:While normalizing weights or scaling outputs in the FFN of Softmax-only (GPT-2) model prevents entropy collapse, our proposed entropy regularization effectively mitigates entropic overload.",
                "position": 804
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x18.png",
                "caption": "(a)Values of learned threshold weights",
                "position": 1040
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x18.png",
                "caption": "(a)Values of learned threshold weights",
                "position": 1043
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x19.png",
                "caption": "(b)Layerwise mean and variance of threshold weights",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x20.png",
                "caption": "(a)FFN output scaling factorÎ±ğ›¼\\alphaitalic_Î±",
                "position": 3040
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x20.png",
                "caption": "(a)FFN output scaling factorÎ±ğ›¼\\alphaitalic_Î±",
                "position": 3043
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x21.png",
                "caption": "(b)FFN-blockâ€™s residual scaling factorÎ²ğ›½\\betaitalic_Î²",
                "position": 3048
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x22.png",
                "caption": "(a)SM + LN + G",
                "position": 3066
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x22.png",
                "caption": "(a)SM + LN + G",
                "position": 3069
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x23.png",
                "caption": "(b)SM + LN + R",
                "position": 3074
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x24.png",
                "caption": "(c)SM + LN",
                "position": 3080
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x25.png",
                "caption": "(d)SM + G",
                "position": 3085
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x26.png",
                "caption": "(e)SM + R",
                "position": 3091
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x27.png",
                "caption": "(f)SM",
                "position": 3096
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x28.png",
                "caption": "(a)Layerwise learnable slope",
                "position": 3103
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x28.png",
                "caption": "(a)Layerwise learnable slope",
                "position": 3106
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x29.png",
                "caption": "(b)Global slope",
                "position": 3111
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x30.png",
                "caption": "(a)Weight normalization in FFN",
                "position": 3118
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x30.png",
                "caption": "(a)Weight normalization in FFN",
                "position": 3121
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x31.png",
                "caption": "(b)Spectral normalization in FFN",
                "position": 3126
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x32.png",
                "caption": "(c)Scaled-FFN",
                "position": 3132
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x33.png",
                "caption": "(d)Entropy regularization",
                "position": 3137
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x34.png",
                "caption": "Figure 14:Latency and communication savings through nonlinearity and FLOPs reduction steps when AERO is applied on Pythia-70M, and model is trained from scratch on CodeParrot dataset with context length 256. Further, we benchmark AERO against the SOTAHe & Hofmann (2024)at iso-latency points.",
                "position": 3789
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x35.png",
                "caption": "Figure 15:Head-wise entropy distribution in the Softmax-only GPT-2 model (Lğ¿Litalic_L=12,Hğ»Hitalic_H=12,dğ‘‘ditalic_d=768) with earlier FFNs intact and deeper FFNs pruned, trained from scratch on the CodeParrot dataset.",
                "position": 3842
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x36.png",
                "caption": "(a)Training instability (NaNs) inğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ½ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’7{\\tt SM+ScFuFFNi_{7}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_7 end_POSTSUBSCRIPT",
                "position": 3854
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x36.png",
                "caption": "(a)Training instability (NaNs) inğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ½ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’7{\\tt SM+ScFuFFNi_{7}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_7 end_POSTSUBSCRIPT",
                "position": 3857
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x37.png",
                "caption": "(b)Entropy collapses inğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ½ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’7{\\tt SM+ScFuFFNi_{7}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_7 end_POSTSUBSCRIPT",
                "position": 3862
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x38.png",
                "caption": "(c)Entropy dynamics inğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ¼ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’6{\\tt SM+ScFuFFNi_{6}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_6 end_POSTSUBSCRIPT",
                "position": 3868
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x39.png",
                "caption": "(d)Entropy dynamics inğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš‚ğ™¼ğš‚ğšŒğ™µğšğ™µğ™µğ™½{\\tt SM+ScFuFFN}typewriter_SM + typewriter_ScFuFFN",
                "position": 3873
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x40.png",
                "caption": "(e)ğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ½ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’7{\\tt SM+ScFuFFNi_{7}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_7 end_POSTSUBSCRIPT",
                "position": 3879
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x41.png",
                "caption": "(f)ğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’ğŸ¼ğš‚ğ™¼subscriptğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš’6{\\tt SM+ScFuFFNi_{6}}typewriter_SM + typewriter_ScFuFFNi start_POSTSUBSCRIPT typewriter_6 end_POSTSUBSCRIPT",
                "position": 3884
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x42.png",
                "caption": "(g)ğš‚ğ™¼+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš‚ğ™¼ğš‚ğšŒğ™µğšğ™µğ™µğ™½{\\tt SM+ScFuFFN}typewriter_SM + typewriter_ScFuFFN",
                "position": 3889
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x43.png",
                "caption": "Figure 17:Headwise entropy distribution in theğš‚ğ™¼â¢(ğš)+ğš‚ğšŒğ™µğšğ™µğ™µğ™½ğš‚ğ™¼ğšğš‚ğšŒğ™µğšğ™µğ™µğ™½{\\tt SM(t)+ScFuFFN}typewriter_SM ( typewriter_t ) + typewriter_ScFuFFNGPT-2 model (Lğ¿Litalic_L=12,Hğ»Hitalic_H=12,dğ‘‘ditalic_d=768) when entropy regularization is applied with varying threshold margin, controlled by hyperparameterÎ³ğ›¾\\gammaitalic_Î³.",
                "position": 3901
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x44.png",
                "caption": "(a)Tolmargin=0.15â¢EmaxsubscriptTolmargin0.15subscriptEmax\\text{Tol}_{\\text{margin}}=0.15\\text{E}_{\\text{max}}Tol start_POSTSUBSCRIPT margin end_POSTSUBSCRIPT = 0.15 E start_POSTSUBSCRIPT max end_POSTSUBSCRIPT",
                "position": 3910
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x44.png",
                "caption": "(a)Tolmargin=0.15â¢EmaxsubscriptTolmargin0.15subscriptEmax\\text{Tol}_{\\text{margin}}=0.15\\text{E}_{\\text{max}}Tol start_POSTSUBSCRIPT margin end_POSTSUBSCRIPT = 0.15 E start_POSTSUBSCRIPT max end_POSTSUBSCRIPT",
                "position": 3913
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x45.png",
                "caption": "(b)Tolmargin=0.20â¢EmaxsubscriptTolmargin0.20subscriptEmax\\text{Tol}_{\\text{margin}}=0.20\\text{E}_{\\text{max}}Tol start_POSTSUBSCRIPT margin end_POSTSUBSCRIPT = 0.20 E start_POSTSUBSCRIPT max end_POSTSUBSCRIPT",
                "position": 3918
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x46.png",
                "caption": "(c)Tolmargin=0.25â¢EmaxsubscriptTolmargin0.25subscriptEmax\\text{Tol}_{\\text{margin}}=0.25\\text{E}_{\\text{max}}Tol start_POSTSUBSCRIPT margin end_POSTSUBSCRIPT = 0.25 E start_POSTSUBSCRIPT max end_POSTSUBSCRIPT",
                "position": 3924
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x47.png",
                "caption": "(d)Tolmargin=0.30â¢EmaxsubscriptTolmargin0.30subscriptEmax\\text{Tol}_{\\text{margin}}=0.30\\text{E}_{\\text{max}}Tol start_POSTSUBSCRIPT margin end_POSTSUBSCRIPT = 0.30 E start_POSTSUBSCRIPT max end_POSTSUBSCRIPT",
                "position": 3929
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x48.png",
                "caption": "(a)GPT-2 small",
                "position": 4103
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x48.png",
                "caption": "(a)GPT-2 small",
                "position": 4106
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x49.png",
                "caption": "(b)GPT-2 medium",
                "position": 4111
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x50.png",
                "caption": "(c)GPT-2 large",
                "position": 4117
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x51.png",
                "caption": "(d)GPT-2 XL",
                "position": 4122
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x52.png",
                "caption": "(a)Pythia-70M",
                "position": 4136
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x52.png",
                "caption": "(a)Pythia-70M",
                "position": 4139
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x53.png",
                "caption": "(b)Pythia-160M",
                "position": 4144
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x54.png",
                "caption": "(c)Pythia-410M",
                "position": 4150
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x55.png",
                "caption": "(d)Pythia-1B",
                "position": 4155
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x56.png",
                "caption": "(e)Pythia-1.4B",
                "position": 4161
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x57.png",
                "caption": "(f)Pythia-2.8B",
                "position": 4166
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x58.png",
                "caption": "(g)Pythia-6.9B",
                "position": 4172
            },
            {
                "img": "https://arxiv.org/html/2410.13060/x59.png",
                "caption": "(h)Pythia-12B",
                "position": 4177
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]