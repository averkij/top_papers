[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13968/x1.png",
                "caption": "Figure 1:We present twoRotBenchimages: one (left) to Gemini-2.5-Pro, the other (right) to GPT-5. Humans can easily identify the correct rotation of the two images, but both models fail to do so.",
                "position": 113
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x2.png",
                "caption": "Figure 2:RotBenchevaluation pipeline: for each image inRotBench, we rotate the image 0°, 90°, 180°, and 270° counter-clockwise. We represent the rotation estimation problem as a multiple-choice question answering problem (Section˜L.5), and separately measure accuracy on each image orientation. We optionally provide different forms of auxiliary information to aid the model in identifying image rotation. We emphasize that all forms of auxiliary information are separately extracted for each rotation; the ground truth rotation is not marked.",
                "position": 116
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3RotBench",
        "images": []
    },
    {
        "header": "4Experiment Setup",
        "images": []
    },
    {
        "header": "5Main Results",
        "images": []
    },
    {
        "header": "6Additional Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13968/x3.png",
                "caption": "Figure 3:Confusion matrix of true vs. predicted rotations for GPT-4o using CoT prompting, summed across three runs onRotBench-large. Rows represent ground-truth labels, columns represent predicted labels.",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x4.png",
                "caption": "Figure 4:GPT-4o answers incorrectly when asked to identify whether the image has been rotated 90° clockwise or counter-clockwise.",
                "position": 883
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x5.png",
                "caption": "Figure 5:Qwen-2.5-VL-7B-Instruct accuracy on different degrees of rotation as training progresses.",
                "position": 905
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13968/x6.png",
                "caption": "Figure 6:Figure describes our two-stage data filtering procedure. The example image is flagged during Stage 1, but subsequently accepted during Stage 2 as only one evaluator provided an incorrect response.",
                "position": 1561
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x7.png",
                "caption": "Figure 7:A screenshot of the custom interface shown to Stage 2 annotators.",
                "position": 1595
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x8.png",
                "caption": "Figure 8:Examples of the different types of auxiliary information provided to the models.",
                "position": 1605
            },
            {
                "img": "https://arxiv.org/html/2508.13968/x9.png",
                "caption": "Figure 9:Samples of accepted, flagged, and discarded images during Stage 1 of data filtering.",
                "position": 1608
            }
        ]
    },
    {
        "header": "Appendix BModel Inference and Training Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    },
    {
        "header": "Appendix DClockwise Prompting",
        "images": []
    },
    {
        "header": "Appendix EDifferentiating Clockwise and Counter-clockwise Rotations using GPT-5",
        "images": []
    },
    {
        "header": "Appendix FChain-of-Thought Example",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13968/x10.png",
                "caption": "Figure 10:Example image where GPT-4o’s reasoning falsely distinguishes between two identical forms of rotation.",
                "position": 2029
            }
        ]
    },
    {
        "header": "Appendix GModifying Temperature",
        "images": []
    },
    {
        "header": "Appendix HIn-Context Learning",
        "images": []
    },
    {
        "header": "Appendix INormalized Rotation Voting",
        "images": []
    },
    {
        "header": "Appendix JSimilar Images in Spatial-MM",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13968/x11.png",
                "caption": "Figure 11:A pair of images in Spatial-MM that closely resemble each other.",
                "position": 2335
            }
        ]
    },
    {
        "header": "Appendix KLicense",
        "images": []
    },
    {
        "header": "Appendix LPrompts",
        "images": []
    }
]