[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16282/x1.png",
                "caption": "Figure 1:Comparison of our framework with previous work.Top:Prior work[56,66]primarily enhances prototypes through interaction modules that integrate support/query features, making predictions based on refined prototypes. However, they are limited by the sparse knowledge from few-shot samples.Bottom:Our framework addresses this limitation by leveraging the extensive open-world knowledge from 3D VLMs through pseudo-labels. We mitigate the noise inherent in 3D VLMs by calibrating their raw pseudo-labels with precise few-shot samples, thereby effectively expanding novel class knowledge while ensuring reliability.",
                "position": 90
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3GFS-PCS Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16282/x2.png",
                "caption": "Figure 2:Overview of the proposed¬†GFS-VL.(a), (b) Given an input point cloudùêóbsubscriptùêób\\mathbf{X}_{\\rm b}bold_X start_POSTSUBSCRIPT roman_b end_POSTSUBSCRIPT, we apply a novel-base mix to embed support samples into the training scene while preserving essential context.\nThe scene is then processed by a 3D VLM, using all class names as prompts to generate raw predictionsùêò^^ùêò\\mathbf{\\hat{Y}}over^ start_ARG bold_Y end_ARG.\nLeveraging support prototypes{ùê©c}superscriptùê©c\\{\\mathbf{p}^{\\rm c}\\}{ bold_p start_POSTSUPERSCRIPT roman_c end_POSTSUPERSCRIPT }, the raw predictions undergo pseudo-label selection to filter out noisy regions, followed by adaptive infilling to label the filtered, unlabeled areas, yielding refined supervisionùêòb‚Ä≤‚Ä≤subscriptsuperscriptùêò‚Ä≤‚Ä≤b\\mathbf{Y}^{\\rm\\prime\\prime}_{\\rm b}bold_Y start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_b end_POSTSUBSCRIPTfor training the 3D segmentor. (c), (d) illustrate the details of the pseudo-label selection and adaptive infilling processes.",
                "position": 206
            }
        ]
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16282/x3.png",
                "caption": "Figure 3:Qualitative comparison between GW[66]and our GFS-VL¬†on ScanNet200.Class colors are shown at the top.",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2503.16282/x4.png",
                "caption": "Figure 4:Visualization of the improvements in pseudo-label quality after applying Pseudo-label Selection (PS) and Adaptive Infilling (AI). Note that AI effectively discovers missed novel classes in the red circles and completes partial pseudo-labels in the green circles.",
                "position": 2116
            },
            {
                "img": "https://arxiv.org/html/2503.16282/x5.png",
                "caption": "Figure 5:Visual illustration of mixing strategies.\nThe red and green boxes represent the two novel samples mixed into the scene.",
                "position": 2121
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Details on Novel-Base Mix",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16282/x6.png",
                "caption": "Figure 6:Visualization of the outputs from the proposed Novel-Base Mix. The red and green boxes represent the two novel samples mixed into the scene. The novel class colors are shown at the top.",
                "position": 3439
            }
        ]
    },
    {
        "header": "8Additional Details on the new Benchmarks",
        "images": []
    },
    {
        "header": "9Additional Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16282/x7.png",
                "caption": "Figure 7:Qualitative comparison between GW[66]and our GFS-VL¬†on ScanNet200.The visualizations demonstrate the superior segmentation performance and novel class generalization capabilities of¬†GFS-VL.\nFor clarity, class colors are displayed on the right and are restricted to those present in the ground truth annotations.",
                "position": 3643
            },
            {
                "img": "https://arxiv.org/html/2503.16282/x8.png",
                "caption": "Figure 8:Visualization of pseudo-label refinement using Pseudo-label Selection (PS) and Adaptive Infilling (AI).Red circles indicate novel objects discovered by AI that were missed in the raw pseudo-labels, while green circles indicate regions where AI completes previously partially segmented areas.\nFor clarity, class colors are displayed at the top and correspond to labels present in the full class annotations.",
                "position": 3653
            }
        ]
    },
    {
        "header": "10Additional Visualizations",
        "images": []
    }
]