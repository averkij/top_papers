[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07990/x1.png",
                "caption": "Figure 1:Comparison of training-free token reduction methods using LLaVA-Video-7B under 50% and 30% pre-filling token budgets.\nQuery-aware (Q. Aware) methods require re-computation for each new query, whereas query-agnostic methods support KV-cache reuse.\nThe evaluated video QA datasets cover short (<<<3 min), long (<<<1 hr), and needle-in-a-haystack (NIAH) videos.(a, b): Per-dataset accuracy.(c, d): Average results across all.",
                "position": 89
            },
            {
                "img": "https://arxiv.org/html/2507.07990/x2.png",
                "caption": "",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07990/x3.png",
                "caption": "Figure 2:(Left)Our spatio-temporal token merging method is a training-free, plug-and-play module that produces spatio-temporally multi-granular tokens.(Middle)In step 1, tokens are merged based on spatial locality, where similar tokens within a 2D grid are combined into a single token.(Right)In step 2, spatially multi-granular tokens are further merged along the temporal dimension, where similar tokens across frames are consolidated into their earliest occurrence.\nThe arrows indicate the direction of token merging.\nThegreen linesindicate merging over one timestep, andmagenta linesare merging over two timesteps.\nThe scale and the number of tokens are set for illustration.",
                "position": 176
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07990/x4.png",
                "caption": "Figure 3:Acoarse-to-fine spatial searchis performed using a quadtree structure.\nIf all four fine child nodes exhibit high similarity with the coarse parent node, the search process terminates, and the parent node is used to represent the corresponding region.\nOtherwise, the search continues until the finest level is reached.\nHere, the scale for each level is an example for illustration.",
                "position": 248
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07990/x5.png",
                "caption": "Table 5:Ablation study on the proposed multi-granular spatial token merging.\nLv.1: spatial scale of root nodes.",
                "position": 1499
            },
            {
                "img": "https://arxiv.org/html/2507.07990/x5.png",
                "caption": "Figure 4:Trade-off of accuracy and visual token retention ratio.",
                "position": 1954
            },
            {
                "img": "https://arxiv.org/html/2507.07990/x6.png",
                "caption": "Figure 5:Visualization of spatial token merging results.\nEach image patch within a green box represents a single token.",
                "position": 1959
            },
            {
                "img": "https://arxiv.org/html/2507.07990/x7.png",
                "caption": "Figure 6:Visualization of spatio-temporal token merging results on VideoMME.\n(a) The first eight consecutive frames are sampled.\n(b) Intermediate frames are sampled for illustration purpose.\nEmpty regions indicate areas that have been merged with early tokens.",
                "position": 1965
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    }
]