[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26330/x1.png",
                "caption": "Figure 1.Overview of SQUARE, our training-free framework for zero-shot composed image retrieval (ZS-CIR). SQUARE takes a coarse-to-fine strategy. In stage 1, Semantic Query-Augmented Fusion (SQAF) enriches the embedding-based composed query, formed by fusing the embeddings of the reference image and modification text from a VLM, by incorporating an MLLM-generated target image caption. This addition improves retrieval accuracy while also making the retrieval process interpretable.\nIn stage 2, Efficient Batch Reranking (EBR) leverages the MLLM’s multimodal reasoning to refine the ranking. The top-KKcandidate images from SQAF’s output are arranged in a grid, with each image annotated with a distinct label and a bounding box. This presentation allows the MLLM to assess all candidates jointly in a single forward pass, yielding faster inference and more precise reranking.††:",
                "position": 145
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26330/x2.png",
                "caption": "Figure 2.Example prompt used for generating the imagined target image caption. Our prompt is composed of three handcrafted few-shot examples and a set of explicit rules that guide the MLLM to generate a concise and concrete description of the target image based on a given reference image and textual modification.††:",
                "position": 306
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x3.png",
                "caption": "Figure 3.An example grid image used in the reranking process. Each candidate image is marked with a colored bounding box and a numeric label at the top-left corner. These identifiers enable the MLLM to reference specific images during reasoning and generate an updated ranking based on the image relevance to the user’s intent.††:",
                "position": 376
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x4.png",
                "caption": "Figure 4.Example prompt for the reranking stage. This prompt provides the MLLM with the reference image, the textual modification, and a grid of candidate images. The MLLM’s task is to reason over the visual differences and produce an updated ranking based on the candidates’ alignment with the user’s intent.††:",
                "position": 400
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26330/x5.png",
                "caption": "Figure 5.Example prompt for reranking with image captions generated in SQAF. The prompt guides the MLLM to reason over visual differences and update the ranking based on how well the candidates align with the user’s intent expressed as the captions.††:",
                "position": 1734
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x6.png",
                "caption": "Figure 6.Effect of the fusion hyperparametersα\\alphaandβ\\betaon SQAF performance.α\\alphaweights the relative contributions of the reference image and the modification text, andβ\\betadetermines the influence of the MLLM-generated description in the final query. Results are reported using CLIP ViT-G/14 on the CIRCO validation set.††:",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x7.png",
                "caption": "Figure 7.Qualitative comparisons of different retrieval methods on sample queries from (a) CIRR, (b) FashionIQ, and (c) CIRCO using CLIP G/14. Images highlighted with a green box denote the ground-truth target images.††:",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x8.png",
                "caption": "Figure 8.Qualitative comparison of different forms of user intent for reranking on CIRCO validation samples using CLIP G/14. (a) Results obtained using the reference image together with the modification text, which provide more reliable guidance for reranking. (b) Results relying solely on the MLLM-generated caption from SQAF. While MLLM captions provide high-level semantics, they may introduce errors (e.g., misinterpreting the cat as beside the bowl), leading to semantically incorrect reranking. Images highlighted with a green box denote the ground-truth target images.††:",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2509.26330/x9.png",
                "caption": "Figure 9.Failure cases of SQUARE on samples image using CLIP G/14. (a) Spatial reasoning limitation: the query from CIRR asks for the dog’s head to appear closer to the camera, but retrieved results mainly show frontal views rather than close-ups. (b) Compound attribute modification: the query from FashionIQ requests changing a blue V-neck shirt into a black non–V-neck shirt with a higher neckline. Our method fails to retrieve the annotated target image but still ranks semantically relevant alternatives among the top candidates. Images highlighted with a green box denote the ground-truth target images.††:",
                "position": 1799
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]