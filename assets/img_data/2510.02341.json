[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02341/x1.png",
                "caption": "Figure 1:Overview of user feedback signals and the DRIFT framework. Explicit feedback (left) is sparse and biased, as most users are passive consumers. In contrast, implicit feedback (middle) provides abundant and informative signals, where dissatisfaction (DSAT) is far more prevalent than satisfaction (SAT) (e.g., 12% vs 5% in theWildFeedbackdataset). DRIFT (right) leverages these DSAT signals for preference learning, enabling our 14B model to surpass commercial models.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3DRIFT:Dissatisfaction-RefinedIterative pre-FerenceTraining",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02341/figs/wildfeedback_share_q80.png",
                "caption": "Figure 2:Comparison of high reward region coverage.",
                "position": 712
            },
            {
                "img": "https://arxiv.org/html/2510.02341/figs/explore.png",
                "caption": "Figure 3:Example of response diversity and quality comparison via semantic clustering. Two central plots: Left is the UMAP scatter of all responses; Right is the reward-weighted topography showing the global high-reward region and the high-reward coverage of the three methods. DRIFT covers a substantially larger portion of the global high-reward region than SPIN or IterDPO and uniquely explores markdown formatting (yellow circle). Full prompt and responses are in AppendixE",
                "position": 723
            }
        ]
    },
    {
        "header": "5Theoretical Analysis",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADisclosure of LLM Use in Paper Preparation",
        "images": []
    },
    {
        "header": "Appendix BTheoretical Proofs",
        "images": []
    },
    {
        "header": "Appendix CDetailed Results",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02341/x2.png",
                "caption": "Figure 4:The top row shows DRIFT training dynamics for iteration 1 on Qwen2.5-14B-Instruct. The bottom row shows the training dynamics for iteration 2.",
                "position": 2176
            }
        ]
    },
    {
        "header": "Appendix EModel Responses Example",
        "images": []
    }
]