[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22753/x1.png",
                "caption": "",
                "position": 89
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22753/x2.png",
                "caption": "Figure 2:Degradation-modeled multipath diffusion framework (DMDiff). (a) The network architecture of DMDiff. The core of DMDiff is a diffusion-based large model, where LoRA fine-tuning is applied to the encoder and UNet. (b) To address the spatially varying degradation, a spatially varying degradation aware attention (SVDA) module is proposed to guide the LoRA fine-tuning process.",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x3.png",
                "caption": "Figure 3:(a) Multi-prompt paths training algorithm for DMDiff, including three paths with positive, neutral, and negative prompts. (b) In the inference step of DMDiff, the latent coded images of the neutral and positive paths are obtained. (c) Instantly tunable decoding of DMDiff, images with varying diffusion intensities can be generated quickly from the latent coded images.",
                "position": 210
            }
        ]
    },
    {
        "header": "4MetaCamera Design and Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22753/x4.png",
                "caption": "Figure 4:(a) Schematic of the metalens unit cell, consisting of a Si3N4nano-pillar on a SiO2substrate. The pillar diameter varies radially to modulate the optical phase. (b) Diameter distribution map of the metalens. (c) Top: Optical and SEM images of the fabricated metalens. Bottom: Optical image of the fully integrated MetaCamera, demonstrating its ultra-compact size.",
                "position": 325
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x5.png",
                "caption": "Figure 5:Qualitative comparisons of different methods on ourunseentest dataset, zoom in for details. Our method achieves high imaging quality with sharp details and maintains robust performance even in severely degraded edge regions.",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x6.png",
                "caption": "Figure 6:Qualitative comparisons of different methods on real-world images captured by our system. Reference views captured by a smartphone from a similar perspective are provided. Note that smartphone software processing may introduce slight color discrepancies. Real-world images present greater challenges, highlighting the strong robustness of our method.",
                "position": 336
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x7.png",
                "caption": "Figure 7:Instantly tunable decoding demonstration. Users can dynamically adjust the diffusion intensity.",
                "position": 339
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x8.png",
                "caption": "Figure 8:Degradation learning qualitative results. Our method effectively simulates the imaging effects of MetaCamera.",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2506.22753/x9.png",
                "caption": "Figure 9:Qualitative results of the ablation study for different modules in our method.",
                "position": 345
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]