[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03320/x1.png",
                "caption": "Figure 1:Comparison of medical image segmentation paradigms. (a) SAM-based models (e.g., SAM, MedSAM) require continuous manual prompting via points or bounding boxes. (b) MLLM-driven models (e.g., LISA, UniBioMed) employs MLLM with specialized seg decoders and<seg>tokens. (c) Ours MedSAM-Agent functions as an autonomous visual agent that performs multi-turn refinement through iterative feedback and tool interaction, emulating the professional decision-making process.",
                "position": 111
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03320/x2.png",
                "caption": "Figure 2:Overview of MedSAM-Agent.We develop a hybrid prompting strategy for expert-curated trajectory generation that transforms image-label pairs into high-quality interaction sequences via simulated clicks and IoU-based filtering. Then these trajectories support a two-stage training pipeline, stage-1 SFT cold-start for initial capability and stage-2 RL optimized by a fine-grained reward design. MedSAM-Agent can autonomously select between box and point tools and execute the “stop” action once the refinement is complete.",
                "position": 173
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03320/x3.png",
                "caption": "Figure 3:Analysis of multi-turn interaction.Theorangeandpurplelines represent the performance of the static Single-Turn Box and Single-Turn Point prompts, respectively, where inputs are derived from ground-truth bounding boxes and centroids. Theblueline plots the Mean IoU across successive interaction turns. The bar charts illustrate the distribution of sample outcomes at each turn, wheregreen,red, andgreysegments denote the proportion of samples exhibiting improved, declined, or unchanged IoU. The segmentation tool is IMISNet(Chenget al.,2025).",
                "position": 667
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Supplementary",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CExperiments Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03320/x4.png",
                "caption": "Figure 4:Case study.Yellow boxes indicate bounding box prompts, yellow points represent positive clicks, and red points denote negative clicks.",
                "position": 3333
            }
        ]
    },
    {
        "header": "Appendix DFuture Works",
        "images": []
    }
]