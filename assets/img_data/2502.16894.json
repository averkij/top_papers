[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.16894/x1.png",
                "caption": "Figure 1:The effect of initializations from different SVD segments(ui,Ïƒi,viâŠ¤)subscriptğ‘¢ğ‘–subscriptğœğ‘–superscriptsubscriptğ‘£ğ‘–top(u_{i},\\sigma_{i},v_{i}^{\\top})( italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Ïƒ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT )for rank 32 and 128. The performance normalized by min-max scaling.",
                "position": 311
            },
            {
                "img": "https://arxiv.org/html/2502.16894/x2.png",
                "caption": "Figure 2:SVD initializationvs.scalingsğ‘ sitalic_sand rankrğ‘Ÿritalic_r",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2502.16894/x3.png",
                "caption": "Figure 3:Illustration of Our Method.Single Low-Rank Adaptation: LoRA reduces trainable parameters by reparameterizingWğ‘ŠWitalic_WasW=W0+sâ¢Bâ¢Ağ‘Šsubscriptğ‘Š0ğ‘ ğµğ´W=W_{0}+sBAitalic_W = italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_s italic_B italic_A, withBğµBitalic_BandAğ´Aitalic_Aas low-rank matrices.MoE Fine-tuning: Full MoE fine-tuning, where expertsW1superscriptğ‘Š1W^{1}italic_W start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPTandWEsuperscriptğ‘Šğ¸W^{E}italic_W start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPTare selected by the router in this moment.Subfigure (I): Our method replaces the single pairB,Ağµğ´B,Aitalic_B , italic_Awith multiple pairs{Bi,Ai}i=1Esuperscriptsubscriptsuperscriptğµğ‘–superscriptğ´ğ‘–ğ‘–1ğ¸\\{B^{i},A^{i}\\}_{i=1}^{E}{ italic_B start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT, initialized from different segments of the SVD ofW0subscriptğ‘Š0W_{0}italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTand adaptively selected by the router.Subfigure (II): We align optimization with SVD-structured MoE by separately aligning each expert.Wressubscriptğ‘ŠresW_{\\text{res}}italic_W start_POSTSUBSCRIPT res end_POSTSUBSCRIPTensures the equivalent weight equalsW0subscriptğ‘Š0W_{0}italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTbefore optimization, and we scale each expertâ€™s equivalent gradient to closely approximate full MoE fine-tuning.",
                "position": 402
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.16894/x4.png",
                "caption": "Figure 4:Training loss curves of Different LoRA methods and Full Fine-tuning MoE on Cars. The balance loss is excluded in the MoE baselines for a fair comparison with single LoRA baselines.",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2502.16894/x5.png",
                "caption": "Figure 5:Performance of different methods across ranks.",
                "position": 1427
            },
            {
                "img": "https://arxiv.org/html/2502.16894/x6.png",
                "caption": "Figure 6:Performance vs.Â number of experts and activation ratio (total rank=32). â€œ2 in 8â€ means activating 2 out of 8 experts.",
                "position": 1430
            },
            {
                "img": "https://arxiv.org/html/2502.16894/x7.png",
                "caption": "Figure 7:Expert Load Distribution across different tasks. We illustrate the fraction of tokens assigned to each expert{ei}i=18superscriptsubscriptsubscriptğ‘’ğ‘–ğ‘–18\\{e_{i}\\}_{i=1}^{8}{ italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT",
                "position": 1453
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Impact Statements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof related with PiSSA Select Segment",
        "images": []
    },
    {
        "header": "Appendix BLoad Balance Loss",
        "images": []
    },
    {
        "header": "Appendix CProof of Theoretical Results",
        "images": []
    },
    {
        "header": "Appendix DExtend Our Method to Scenarios with Proper Scaling",
        "images": []
    },
    {
        "header": "Appendix EExperiment Details",
        "images": []
    },
    {
        "header": "Appendix FParameter and FLOPs Analysis",
        "images": []
    }
]