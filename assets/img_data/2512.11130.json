[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11130/x1.png",
                "caption": "",
                "position": 63
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11130/x2.png",
                "caption": "Figure 2:Zero-shot generalization accuracy (on Middlebury-Q dataset) of various stereo methods versus speed, measured on the same hardware NVIDIA 3090 GPU. Our model family achieves real-time performance with only slight decrease in accuracy compared with the best slow method. Green outlined stars are further accelerated by TensorRT.",
                "position": 77
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11130/x3.png",
                "caption": "Figure 3:Overview of our framework.Top:Foundational stereo matching networks (e.g.,[wen2025foundationstereo]) consist of three key steps: feature extraction, cost filtering, and disparity refinement. Each step is accelerated by a divide-and-conquer strategy.Middle-Left:Hybrid monocular and stereo priors from the teacher foundation model are distilled into a single backbone student model.Middle-right:Refinement network is pruned by first constructing a dependency graph that models the recurrent nature of the GRU module, followed by structured pruning and retraining to recover the accuracy.Bottom:Cost filtering network is divided into separate local blocks; block candidates are trained to match the teacher block’s output, taking as input the local feature from the previous block; and combinatorial search finds the best performing block combination for a given runtime constraint.",
                "position": 134
            }
        ]
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11130/x4.png",
                "caption": "Figure 4:Top:Distilling the hybrid monocular and stereo priors from FoundationStereo[wen2025foundationstereo]into a unified single backbone captures similar high-frequency edges and relative depth—while significantly reducing computational cost.Bottom:Distillation enhances robustness to translucency, which is challenging to traditional stereo matching.",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2512.11130/x5.png",
                "caption": "Figure 5:Recurrent dependency graph of the refinement module.denotes where pruning is performed.denotes where channel dimension remains fixed during the pruning process.",
                "position": 222
            },
            {
                "img": "https://arxiv.org/html/2512.11130/fig/scissors.png",
                "caption": "",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2512.11130/fig/lock.png",
                "caption": "",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2512.11130/x6.png",
                "caption": "Figure 6:Top:Pseudo-labeling pipeline on in-the-wild internet stereo data.Bottom:Visualization of our generated pseudo-labels.",
                "position": 240
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11130/x7.png",
                "caption": "Figure 7:Qualitative results of real-time methods on Middlebury, ETH3D, Booster and KITTI-2015 datasets (top to bottom). Results are obtained by zero-shot inference without training on any split of the target datasets.†Indicates methods trained on the exact same datasets as ours, including our proposed pseudo-labels. More results on in-the-wild images can be found in the appendix.",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2512.11130/x8.png",
                "caption": "Figure 8:Effects of blockwise architecture search for cost filtering module under varying latency budgetΔ​τ\\Delta\\tau, evaluated on Middlebury-Q.",
                "position": 809
            },
            {
                "img": "https://arxiv.org/html/2512.11130/x9.png",
                "caption": "Figure 9:Effects of pruning ratio for accuracy and speed.",
                "position": 815
            },
            {
                "img": "https://arxiv.org/html/2512.11130/x10.png",
                "caption": "Figure 10:Runtime decomposition.",
                "position": 867
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]