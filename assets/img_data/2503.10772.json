[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x1.png",
                "caption": "",
                "position": 66
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x2.png",
                "caption": "Figure 2:Text as Conditionsvs.Direct Flow between Modalities.Top:Conventional text-to-image generation relies on the diffusion process, where text serves as a conditioning signal to guide the denoising process.Bottom:The proposed FlowTok enables direct flow between text and image modalities by projecting both into a shared, compact 1D latent space, facilitating seamless generation of both.",
                "position": 73
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x3.png",
                "caption": "(a)FIDvs.Training Costs.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x3.png",
                "caption": "(a)FIDvs.Training Costs.",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x4.png",
                "caption": "(b)FIDvs.Inference Speed.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x5.png",
                "caption": "Figure 4:Overview of FlowTok.FlowTok is a minimal framework that facilitates seamless flow between 1Dtext tokensandimage tokensfor both text-to-image and image-to-text generation.Top:For text-to-image generation, the input text is encoded by the CLIP text encoder into𝐓init∈ℝN×Csubscript𝐓initsuperscriptℝ𝑁𝐶\\mathbf{T}_{\\text{init}}\\in\\mathbb{R}^{N\\times C}bold_T start_POSTSUBSCRIPT init end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_C end_POSTSUPERSCRIPT, projected into a low-dimensional latent space as text tokens𝐙T∈ℝN×Dsubscript𝐙Tsuperscriptℝ𝑁𝐷\\mathbf{Z}_{\\text{T}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_D end_POSTSUPERSCRIPT, then transformed into image tokens𝐙I∈ℝN×Dsubscript𝐙Isuperscriptℝ𝑁𝐷\\mathbf{Z}_{\\text{I}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_D end_POSTSUPERSCRIPTof the same shape through flow matching and decoded by a 1D Image VAE Decoder to generate the final image.Bottom:For image-to-text generation, an input image is encoded by a 1D Image VAE Encoder into𝐙Isubscript𝐙I\\mathbf{Z}_{\\text{I}}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT, mapped to𝐙Tsubscript𝐙T\\mathbf{Z}_{\\text{T}}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPTthrough flow matching and decoded into text via a text decoder. Unlike conventional approaches that rely on 2D noise and image latents (e.g.,32×32×43232432\\times 32\\times 432 × 32 × 4for 256-resolution images) with text as conditions, our direct 1D transformation (i.e.,77×16771677\\times 1677 × 16) achieves a 3.3×\\times×compression rate, significantly reducing memory costs, accelerating training, and enabling faster inference.",
                "position": 214
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "AMore Implementation Details",
        "images": []
    },
    {
        "header": "BQualitative Examples of FlowTok",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x6.png",
                "caption": "Figure 5:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x7.png",
                "caption": "Figure 6:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x8.png",
                "caption": "Figure 7:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x9.png",
                "caption": "Figure 8:Image-to-Text Generation Results by FlowTok.FlowTok generates precise captions.",
                "position": 1038
            }
        ]
    },
    {
        "header": "CLimitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]