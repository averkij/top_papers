[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x1.png",
                "caption": "",
                "position": 66
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x2.png",
                "caption": "Figure 2:Text as Conditionsvs.Direct Flow between Modalities.Top:Conventional text-to-image generation relies on the diffusion process, where text serves as a conditioning signal to guide the denoising process.Bottom:The proposed FlowTok enables direct flow between text and image modalities by projecting both into a shared, compact 1D latent space, facilitating seamless generation of both.",
                "position": 73
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x3.png",
                "caption": "(a)FIDvs.Training Costs.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x3.png",
                "caption": "(a)FIDvs.Training Costs.",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x4.png",
                "caption": "(b)FIDvs.Inference Speed.",
                "position": 129
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x5.png",
                "caption": "Figure 4:Overview of FlowTok.FlowTok is a minimal framework that facilitates seamless flow between 1Dtext tokensandimage tokensfor both text-to-image and image-to-text generation.Top:For text-to-image generation, the input text is encoded by the CLIP text encoder intoğ“initâˆˆâ„NÃ—Csubscriptğ“initsuperscriptâ„ğ‘ğ¶\\mathbf{T}_{\\text{init}}\\in\\mathbb{R}^{N\\times C}bold_T start_POSTSUBSCRIPT init end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_C end_POSTSUPERSCRIPT, projected into a low-dimensional latent space as text tokensğ™Tâˆˆâ„NÃ—Dsubscriptğ™Tsuperscriptâ„ğ‘ğ·\\mathbf{Z}_{\\text{T}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_D end_POSTSUPERSCRIPT, then transformed into image tokensğ™Iâˆˆâ„NÃ—Dsubscriptğ™Isuperscriptâ„ğ‘ğ·\\mathbf{Z}_{\\text{I}}\\in\\mathbb{R}^{N\\times D}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_D end_POSTSUPERSCRIPTof the same shape through flow matching and decoded by a 1D Image VAE Decoder to generate the final image.Bottom:For image-to-text generation, an input image is encoded by a 1D Image VAE Encoder intoğ™Isubscriptğ™I\\mathbf{Z}_{\\text{I}}bold_Z start_POSTSUBSCRIPT I end_POSTSUBSCRIPT, mapped toğ™Tsubscriptğ™T\\mathbf{Z}_{\\text{T}}bold_Z start_POSTSUBSCRIPT T end_POSTSUBSCRIPTthrough flow matching and decoded into text via a text decoder. Unlike conventional approaches that rely on 2D noise and image latents (e.g.,32Ã—32Ã—43232432\\times 32\\times 432 Ã— 32 Ã— 4for 256-resolution images) with text as conditions, our direct 1D transformation (i.e.,77Ã—16771677\\times 1677 Ã— 16) achieves a 3.3Ã—\\timesÃ—compression rate, significantly reducing memory costs, accelerating training, and enabling faster inference.",
                "position": 214
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "AMore Implementation Details",
        "images": []
    },
    {
        "header": "BQualitative Examples of FlowTok",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10772/x6.png",
                "caption": "Figure 5:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x7.png",
                "caption": "Figure 6:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x8.png",
                "caption": "Figure 7:Text-to-Image Generation Results by FlowTok.FlowTok generates diverse, high-fidelity images.",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2503.10772/x9.png",
                "caption": "Figure 8:Image-to-Text Generation Results by FlowTok.FlowTok generates precise captions.",
                "position": 1038
            }
        ]
    },
    {
        "header": "CLimitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]