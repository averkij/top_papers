[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10628/x1.png",
                "caption": "Figure 1:Average Score versus Pre-training Tokensfor base (left) and instruction-tuned (right) models. Instella surpasses prior fully open models of comparable size and, despite being trained on substantially fewer pre-training tokens, achieves competitive performance with state-of-the-art open-weight models for both(left)base models (Table4) and(right)instruction-tuned models (Table6).",
                "position": 80
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Instella",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10628/x2.png",
                "caption": "Figure 2:Instella-3B model training pipeline.",
                "position": 237
            }
        ]
    },
    {
        "header": "4Instella-Long",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10628/x3.png",
                "caption": "Figure 3:Instella-Long model training pipeline.",
                "position": 267
            }
        ]
    },
    {
        "header": "5Instella-Math",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10628/x4.png",
                "caption": "Figure 4:Instella-Math model training pipeline.",
                "position": 433
            }
        ]
    },
    {
        "header": "6Evaluation",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    }
]