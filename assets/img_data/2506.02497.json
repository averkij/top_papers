[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02497/x1.png",
                "caption": "Figure 1:The comparison of different long video generation pipelines. LumosFlow generates long videos through the process ofgenerating key frames and performing motion-guided intermediate frame interpolation.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x2.png",
                "caption": "Figure 2:Generated long videos with the prompt ‚Äúa man in a blue plaid shirt and a white cowboy hat is seen drinking whiskey from a glass‚Ä¶\" by FreeLong, FreeNoise, and LumosFlow. We randomly select some frames for comparison.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x3.png",
                "caption": "Figure 3:Generated intermediate frames based on the first and last frames. Since the absence of motion, the frames produced using the Motion-Free method exhibits unnatural movements from the subjects. In contrast, the result generated with the Motion-Guidance is significantly more realistic.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary on Diffusion model",
        "images": []
    },
    {
        "header": "4LumosFlow",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02497/x4.png",
                "caption": "Figure 4:The overall framework of LumosFlow includes key frame generation and intermediate frame generation. The intermediate frame generation comprises two components: motion generation (highlighted in yellow) and post-hoc refinement (highlighted in orange).",
                "position": 260
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02497/x5.png",
                "caption": "Figure 5:The generated long videos via LumosFlow, FreeLong, FreeNoise, Video-Infinity by given the prompt ‚ÄúA man with curly hair, dressed in a black shirt and wearing a white virtual reality headset‚Ä¶‚Ä¶\".",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x6.png",
                "caption": "Figure 6:The generated intermediate frames referring to the Frame 1 and Frame 17. We randomly select some frames for visualization.",
                "position": 442
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x7.png",
                "caption": "Figure 7:Generated key frames via LMTV-DM. We observe that different key frames can represent a significant range of motion.",
                "position": 646
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x8.png",
                "caption": "Figure 8:The optical flow generated from first and last frames.F^‚Üí1subscript^ùêπ‚Üíabsent1\\hat{F}_{\\rightarrow 1}over^ start_ARG italic_F end_ARG start_POSTSUBSCRIPT ‚Üí 1 end_POSTSUBSCRIPTandF^‚Üí9subscript^ùêπ‚Üíabsent9\\hat{F}_{\\rightarrow 9}over^ start_ARG italic_F end_ARG start_POSTSUBSCRIPT ‚Üí 9 end_POSTSUBSCRIPTdenote the generated optical flow from the first frame and last frame, respectively.F‚Üí1subscriptùêπ‚Üíabsent1F_{\\rightarrow 1}italic_F start_POSTSUBSCRIPT ‚Üí 1 end_POSTSUBSCRIPTandF‚Üí9subscriptùêπ‚Üíabsent9F_{\\rightarrow 9}italic_F start_POSTSUBSCRIPT ‚Üí 9 end_POSTSUBSCRIPTdenote the OF-VAE reconstructed optical flow from the first frame and last frame.",
                "position": 812
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Overview",
        "images": []
    },
    {
        "header": "Appendix ATraining and Inference Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02497/x9.png",
                "caption": "Figure 9:The overall encoding pipeline of LMTV-DM. Given a set of frames, the selected frames (indicated in dark green) are sampled at fixed intervals. Subsequently, we employ the CogVideoX VAE to encode these frames in a frame-by-frame manner, resulting in the corresponding latent representations (shown in blue), which are then utilized in the conducted diffusion pipeline.",
                "position": 1434
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix CMore Generated Intermediate Frames",
        "images": []
    },
    {
        "header": "Appendix DMore Generated Optical Flows",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02497/x10.png",
                "caption": "Figure 10:Generated intermediate frames via LumosFlow.",
                "position": 1511
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x11.png",
                "caption": "Figure 11:Generated optical flows and intermediate frames via the given first (Frame 1) and last frames (Frame 17). The first and last frames are generated by the LMTV-DM and the optical flows (F^‚Üí1subscript^ùêπ‚Üíabsent1\\hat{F}_{\\rightarrow 1}over^ start_ARG italic_F end_ARG start_POSTSUBSCRIPT ‚Üí 1 end_POSTSUBSCRIPTandF^‚Üí17subscript^ùêπ‚Üíabsent17\\hat{F}_{\\rightarrow 17}over^ start_ARG italic_F end_ARG start_POSTSUBSCRIPT ‚Üí 17 end_POSTSUBSCRIPT) are generated by the LOF-DM. The intermediate frames are generated by the MotionControlNet.",
                "position": 1514
            },
            {
                "img": "https://arxiv.org/html/2506.02497/x12.png",
                "caption": "Figure 12:Generated long videos via LumosFlow",
                "position": 1524
            }
        ]
    },
    {
        "header": "Appendix EMore Generated Long Videos",
        "images": []
    }
]