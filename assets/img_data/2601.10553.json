[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10553/x1.png",
                "caption": "Figure 1:Left:We achieve the new state-of-the-art on PhysicsIQ benchmark, improving physics plausibility in both single (I2V) and multiframe (V2V) conditioned video generation by a considerable margin.Right:Our latent world model rewardWMRewardsubstantially outperforms VLM and other vision foundation model-based reward signals under BoN search; the proposed∇\\nabla+BoNsampling strategy further improves the scaling effect.",
                "position": 156
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x2.png",
                "caption": "Figure 2:We improve the physics plausibility of video generation by aligning a pre-trained diffusion model with a latent world model at inference time. Using a reward derived from latent world models, we perform search on guided denoising trajectories to sample from a tilted physics plausible distribution. Compared to the baseline (middle row of each quadrant), our generation (bottom) adheres more closely to real-world physics (top), exhibiting smoother temporal continuity, more accurate solid interactions, and improved fluid behavior.",
                "position": 179
            }
        ]
    },
    {
        "header": "2Methodology:WMReward",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10553/x3.png",
                "caption": "Figure 3:Method Overview.We leverage a latent world model, VJEPA-2, to steer video generative models for better physics plausibility. During generation, we apply a sliding window approach and split the generative model’s output into sets of context and future frames. We encode generated context frames and predict the embedding of future frames using the latent world model’s predictor. Then, we encode the generated future frames and compute the cosine similarity between its embedding and the latent world model prediction, referred to as surprise score. The surprise score serves as reward to search and guide the denoising trajectories.",
                "position": 239
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10553/x4.png",
                "caption": "Figure 4:Improving Performance via Particle Scaling and Guidance.Visualization of PhysicsIQ score distributions with a Gaussian KDE for MAGI-1 V2V (left) and vLDM I2V (right) generations. Scaling the number of particles (here, 1 vs. 16) yields substantial gains for Best-of-NN, and adding guidance further sharpens the distribution toward higher physics plausibility. This leads to overall higher average score shown as dashed vertical line.",
                "position": 1127
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x5.png",
                "caption": "",
                "position": 1136
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Implementation Details",
        "images": []
    },
    {
        "header": "7Human Study Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10553/x6.png",
                "caption": "Figure 5:Human Study Interface.Annotators view a side-by-side video comparison and indicate their preference on three criteria—Physics Plausibility, Visual Quality, and Prompt Alignment—choosing one of three preference options: Left, Right, or Neutral.",
                "position": 1813
            }
        ]
    },
    {
        "header": "8Qualitative Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10553/x7.png",
                "caption": "Figure 6:Additional Qualitative Results on Physics-IQ.",
                "position": 1823
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x8.png",
                "caption": "Figure 7:Additional Qualitative Samples on Physics-IQ.",
                "position": 1827
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x9.png",
                "caption": "Figure 8:Additional Qualitative Samples on Physics-IQ.",
                "position": 1831
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x10.png",
                "caption": "Figure 9:Additional Qualitative Samples on VideoPhy.",
                "position": 1835
            },
            {
                "img": "https://arxiv.org/html/2601.10553/x11.png",
                "caption": "Figure 10:Failure Mode Analysis.We observe some failure modes that persist even when leveraging VJEPA-2 for sampling. For example, the model often fails on abrupt physical events, such as fluid overflowing from a bottle (top left quadrant) or a lit match igniting a balloon and causing it to explode (bottom left quadrant). It also struggles with more complex phenomena that requires reasoning and understanding of material properties, including mirror reflections (top right) and siphon effects (bottom right), indicating that both the base model and the reward model still have room of improvement on physics understanding.",
                "position": 1847
            }
        ]
    },
    {
        "header": "9Failure Mode Analysis",
        "images": []
    }
]