[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02812/x1.png",
                "caption": "Figure 1:Accuracy vs Time to First Token (TTFT) tradeoff for Llama-3.1-70B-Instruct, measured on the Ruler dataset with√ó\\times√ó8 compression. The TTFT is measured using 2 A100 GPUs on 8192-tokens sequences.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll8b_hists_14_5.png",
                "caption": "(a)Layer 14, Head 5 (œµ=‚àí1italic-œµ1\\epsilon=-1italic_œµ = - 1)",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll8b_hists_14_5.png",
                "caption": "(a)Layer 14, Head 5 (œµ=‚àí1italic-œµ1\\epsilon=-1italic_œµ = - 1)",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll8b_hists_31_14.png",
                "caption": "(b)Layer 31, Head 14 (œµ=+1italic-œµ1\\epsilon=+1italic_œµ = + 1)",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/svd_coeff_avg.png",
                "caption": "(c)SVD absolute average coefficients",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll1b_lay0_head_21.png",
                "caption": "(a)Layer 0, Head 21",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll1b_lay0_head_21.png",
                "caption": "(a)Layer 0, Head 21",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll1b_lay13_head_16.png",
                "caption": "(b)Layer 13, Head 16",
                "position": 173
            }
        ]
    },
    {
        "header": "2Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/corr_info_norm.png",
                "caption": "Figure 4:Spearman rank correlation between KV compression scoring metrics and the observed attentionShsuperscriptùëÜ‚ÑéS^{h}italic_S start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPTfor Llama-3.2-1B, for K-norm (top) and Q-Filters (bottom).",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/corr_info_norm.png",
                "caption": "",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/corr_info_svd.png",
                "caption": "",
                "position": 240
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll8b_comp_ppl.png",
                "caption": "Figure 5:Generation performance for a KV Cache size limited to 512 items for Llama-3.1-8B (top) and Llama-3.1-70B (bottom).",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll8b_comp_ppl.png",
                "caption": "",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll70b_comp_ppl.png",
                "caption": "",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/llama8b_cr-x64_s8_norm.png",
                "caption": "(a)K-norm (average accuracy: 63%)",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/llama8b_cr-x64_s8_norm.png",
                "caption": "(a)K-norm (average accuracy: 63%)",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/llama8b_cr-x64_s8_svd.png",
                "caption": "(b)Q-filters (average accuracy: 91%)",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_avg_curve.png",
                "caption": "(a)Average performance on Ruler (8192)",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_avg_curve.png",
                "caption": "(a)Average performance on Ruler (8192)",
                "position": 480
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/loogle__shortdep_qa__meta-llama--Llama-3.1-8B-Instruct_avg_curve.png",
                "caption": "(b)Average performance on Loogle (Short Dependency QA)",
                "position": 486
            },
            {
                "img": "https://arxiv.org/html/2503.02812/x2.png",
                "caption": "Figure 8:Perplexity after 1024 tokens for Q-Filters obtained using different sizes ofQhsuperscriptùëÑ‚ÑéQ^{h}italic_Q start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT(Eq.1) to calculate the SVD.",
                "position": 600
            },
            {
                "img": "https://arxiv.org/html/2503.02812/x3.png",
                "caption": "Figure 9:Cosine-similarity between Q-Filters computed on datasets coming from different domains and languages and on pre-trained and post-trained models. The scores are averaged over all layers and heads.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2503.02812/x4.png",
                "caption": "Figure 10:First token latency across KV Cache compression methods of Llama-3.2-8B with a length of 64k prompt.",
                "position": 632
            }
        ]
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Impact Statement",
        "images": []
    },
    {
        "header": "9Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof ofTheorem3.3",
        "images": []
    },
    {
        "header": "Appendix BGeneration Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll70b_final_ppl.png",
                "caption": "Figure 11:Final perplexity after 512 tokens for Llama-3.1-70B in the memory-constrained generation scenario.",
                "position": 1130
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/q7b-4k_comp_ppl.png",
                "caption": "Figure 12:Perplexity of the Qwen-2.5-7B-Instruct model along generation.",
                "position": 1136
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ll1b_4k_comp_ppl.png",
                "caption": "Figure 13:Perplexity of the Llama-3.2-1B model along generation.",
                "position": 1139
            }
        ]
    },
    {
        "header": "Appendix CRuler Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_vt_curve.png",
                "caption": "(a)Variable tracking",
                "position": 1149
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_vt_curve.png",
                "caption": "(a)Variable tracking",
                "position": 1152
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_single_1_curve.png",
                "caption": "(b)NIAH - single (1)",
                "position": 1157
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_single_2_curve.png",
                "caption": "(c)NIAH - single (2)",
                "position": 1162
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_single_3_curve.png",
                "caption": "(d)NIAH - single (3)",
                "position": 1168
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_multikey_1_curve.png",
                "caption": "(e)NIAH - Multi-key (1)",
                "position": 1173
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_multikey_2_curve.png",
                "caption": "(f)NIAH - Multi-key (2)",
                "position": 1178
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_multikey_3_curve.png",
                "caption": "(g)NIAH - Multi-key (3)",
                "position": 1184
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_multivalue_curve.png",
                "caption": "(h)NIAH - Multi-Value",
                "position": 1189
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_niah_multiquery_curve.png",
                "caption": "(i)NIAH - Multi-Query",
                "position": 1194
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_fwe_curve.png",
                "caption": "(j)Frequent Words Extraction (FWE)",
                "position": 1200
            },
            {
                "img": "https://arxiv.org/html/2503.02812/extracted/6252216/imgs/ruler__8192__meta-llama--Llama-3.1-8B-Instruct_cwe_curve.png",
                "caption": "(k)Common Words Extraction (CWE)",
                "position": 1205
            }
        ]
    },
    {
        "header": "Appendix DGeneration examples",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details",
        "images": []
    }
]