[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2The BFS-Prover-V2 System",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06493/x1.png",
                "caption": "Figure 1:Overview of the training-time scaling up architecture.\nThe process begins with a current expert model. The system then evaluates the model’s performance to check for a plateau, which determines the subsequent path. If performance is improving, the model enters an innerexpert iteration loopthat involves generating new proofs, applyingAdaptive Tactic Filtering, and refining the model. Conversely, if performance has plateaued, the system triggers the outerretraining loop, which consists ofData Re-synthesis,Aggressive Data Curation, and retraining the model from a base checkpoint. Upon completion, this retraining loop yields a new, improved expert model, which then serves as the starting point for the next cycle of evaluation and iteration.",
                "position": 219
            },
            {
                "img": "https://arxiv.org/html/2509.06493/x2.png",
                "caption": "Figure 2:Tactic-Level Data Filtering Based on the Perplexity Distribution. This histogram shows the probability distribution of tactic perplexity (represented as negative log-probability) from a single round of expert iteration. We filter out the low- and high-perplexity tails, shown in red. The low-perplexity tail represents overly simple tactics the model is already confident in, while the high-perplexity tail often consists of noisy or unnecessarily complex tactics. By training only on the central part of the distribution (blue), we focus the model’s learning on challenging yet meaningful examples, which prevents overfitting and encourages a smoother, more stable improvement in reasoning capabilities.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2509.06493/x3.png",
                "caption": "Figure 3:Sustained Performance Improvement through Expert Iteration and Periodic Retraining. This graph plots the prover’s performance on the MiniF2F benchmark against the number of expert iteration rounds. Performance steadily increases (blue circles) but eventually begins to plateau as the model settles into a local optimum. To counteract this, we periodically conduct a \"soft reset\" (red squares). This involves using the current expert model to re-solve all past problems to generate a cleaner, more efficient dataset, which is then used to retrain the model from a base checkpoint. This procedure allows the model to break out of its local optimum and continue improving, as evidenced by the significant performance jumps following each retraining phase. A model scale-up to 32 billion parameters is also shown (green diamond).",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2509.06493/x4.png",
                "caption": "Figure 4:Overview of the planner-enhanced multi-agent tree search architecture. ThePlanneragent decomposes the main theorem into a sequence of simpler subgoals, which are managed in aShared Subgoal Cacheand solved in parallel by multipleProveragents. Successfully proven subgoals augment the main proof’s context, while failures can trigger aDynamic Replanningloop. The inset provides a toy example, demonstrating how proving intermediate lemmas (h1\\mathrm{h}_{1},h2\\mathrm{h}_{2},h3\\mathrm{h}_{3}) facilitates the proof of the final goal.",
                "position": 318
            }
        ]
    },
    {
        "header": "3Practical Implementation and Benchmark Results",
        "images": []
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "5Case Studies",
        "images": []
    },
    {
        "header": "6Illustration of Planner-Prover Paradigm with an IMO Problem",
        "images": []
    },
    {
        "header": "7Prompts Used in This Work",
        "images": []
    }
]