[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Setup and Five-Axis Decomposition",
        "images": []
    },
    {
        "header": "4Representational Self-Modification (ℳH\\mathcal{M}_{H})",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04399/h_axis_comparison.png",
                "caption": "Figure 1:Representational axisℳH\\mathcal{M}_{H}.\nTwoGate accepts a few early edits and then plateaus at a lower test loss, while destructive policies continue modifying the hypothesis class and exhibit worsening generalization as complexity increases.",
                "position": 683
            }
        ]
    },
    {
        "header": "5Architectural Self-Modification (ℳZ\\mathcal{M}_{Z})",
        "images": []
    },
    {
        "header": "6Metacognitive Self-Modification (ℳM\\mathcal{M}_{M})",
        "images": []
    },
    {
        "header": "7Algorithmic Self-Modification (ℳA\\mathcal{M}_{A})",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.04399/a_axis_comparison.png",
                "caption": "Figure 2:ℳA\\mathcal{M}_{A}(Algorithmic axis).Generalization gap (test−-train loss) vs. cumulative step–massMT=∑tηtM_{T}=\\sum_{t}\\eta_{t}with a fixed hypothesis class.TwoGatehalts updates at a preset budgetB​(m)B(m)and keeps the gap small;Destructivecontinues updating and exhibits a larger, persistent gap.",
                "position": 998
            }
        ]
    },
    {
        "header": "8Substrate Self-Modification (ℳF\\mathcal{M}_{F})",
        "images": []
    },
    {
        "header": "9Outlook",
        "images": []
    },
    {
        "header": "10Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "11Definitions",
        "images": []
    },
    {
        "header": "12Full Proofs for Representational Self-Modification",
        "images": []
    },
    {
        "header": "13Full Proofs for Architectural Self-Modification",
        "images": []
    },
    {
        "header": "14Full Proofs for Algorithmic Self-Modification",
        "images": []
    },
    {
        "header": "15Full Proofs for Substrate Self-Modification",
        "images": []
    },
    {
        "header": "16Gödel Machine Foundations",
        "images": []
    },
    {
        "header": "17Experimental Details",
        "images": []
    }
]