[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04220/images/performance_comparison_7b_v2.png",
                "caption": "Figure 1:Comparative performance of LLDS and baseline methods on benchmark datasets. All\nbaselines are built upon Qwen2.5-7B-Instruct. SeeSec.˜6.1for details.",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/LD_dynamic_v3.png",
                "caption": "Figure 2:We illustrate the likelihood displacement in tool-integrated RL training. The steady-decay phase (60-120) emerges when the reward begins to increase only gradually. In the subsequent acceleration phase (after step 120), the likelihood of correct responses drops sharply, accompanied by a sudden surge in gradient magnitude (red star), leading to gradient explosion. A zoomed-in view of the acceleration region further highlights this effect, showing a clearer likelihood displacement, where the gradient accelerates rapidly while the reward starts to decline.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Priliminary",
        "images": []
    },
    {
        "header": "4Lazy Likelihood Displacement in Tool-integrated GRPO",
        "images": []
    },
    {
        "header": "5Lazy Likelihood Displacement in tool-integrated GRPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04220/images/Effect_of_LD/50.png",
                "caption": "Figure 3:Effect of likelihood displacement across different training iterations for the Qwen2.5-3B-Instruct model. Results are computed on the first 50 samples of the training set, discarding cases where all responses are uniformly correct or uniformly incorrect. Bars below zero (orange) indicate samples whose correct responses’ likelihood decreases\nafter training.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/Effect_of_LD/100.png",
                "caption": "",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/Effect_of_LD/120.png",
                "caption": "",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/Effect_of_LD/140.png",
                "caption": "",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/entropy_fig.png",
                "caption": "Figure 4:We illustrate how entropy, response length, and valid-search ratio evolve during training. For both Qwen2.5-3B-Instruct (a) and Qwen2.5-3B-Base (b), entropy exhibits a accerlerrated upward trend prior to collapse indicating a strong LD issue. Meanwhile, the response length and valid-search times remain stable in the early stages but later begin to fluctuate markedly and eventually drop sharply.",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/cross_logprob_fixed.png",
                "caption": "Figure 5:Evolution of token log-likelihood (measured before vs. after feedback; left axis) and the observation-match ratio for wrong answers (right axis). With training, both likelihoods drop while the overlap between tool observations in incorrect and correct trajectories increases, suggesting many incorrect responses begin with a correct search, which skews likelihood estimates and contributes to LLD.",
                "position": 358
            }
        ]
    },
    {
        "header": "6Experiments and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_3b_base.png",
                "caption": "(a)Qwen-2.5-3B-Base",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_3b_base.png",
                "caption": "(a)Qwen-2.5-3B-Base",
                "position": 1125
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_3b_instruct.png",
                "caption": "(b)Qwen-2.5-3B-Instruct",
                "position": 1130
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_7b_base.png",
                "caption": "(c)Qwen-2.5-7B-Base",
                "position": 1136
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_7b_instruct.png",
                "caption": "(d)Qwen-2.5-7B-Instruct",
                "position": 1141
            }
        ]
    },
    {
        "header": "7More Discussion and Guideline",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Appendix ATheorem and Proof",
        "images": []
    },
    {
        "header": "Appendix BAdditional Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04220/images/prior_collapse.png",
                "caption": "Figure 7:Demonstration of unstability prior collapse.",
                "position": 1409
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/7b-reg-strength.png",
                "caption": "Figure 8:Impact of regularization strength on Qwen2.5-7B-base.",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2512.04220/images/training_curves/comparison_valid_search_3b_collapse.png",
                "caption": "Figure 9:Evolution of the number of valid searches per question on Qwen-2.5-3B-Base. The base model inherently lacks multi-turn tool calling capabilities. While the baseline (blue) collapses and standard LLDS (red) stabilizes at a single search step, LLDS-MA (green) successfully unlocks the model’s potential for multi-step reasoning, driving the number of valid searches significantly above 1.0.",
                "position": 1438
            }
        ]
    },
    {
        "header": "Appendix CCase Studies of Likelihood Displacement",
        "images": []
    }
]