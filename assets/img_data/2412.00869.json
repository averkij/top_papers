[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00869/x1.png",
                "caption": "Figure 1:Knowledge-enhanced Prompting.An illustration of our knowledge-enhanced prompting approach with types of knowledge and prompting techniques. The question consists of two terms (‘‘Oxygen’’and‘‘Gas’’), and answer choices consist of term pairs that are analogous to the question term pair. Each model is queried using the prompting techniques illustrated.",
                "position": 155
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00869/x2.png",
                "caption": "Figure 2:An illustration of the knowledge filtering approach.“Random” indicates Random Filtering and “Semantic” indicates Semantic Filtering.",
                "position": 374
            }
        ]
    },
    {
        "header": "4Experimental Setting",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00869/x3.png",
                "caption": "Figure 3:Perfromance with structured knowledge.Performance of each model when Structured Knowledge Prompting with semantic filtering (SKP[semantic]) is used.Allindicates the prompt is enhanced with all three types of knowledge (Wikidata, ConceptNet and WordNet). EMA values are reported on  20% of the 15K dataset where all three knowledge types available.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2412.00869/x4.png",
                "caption": "Figure 4:Best and least performing modelsfor each prompting technique.",
                "position": 564
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AModel Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00869/x5.png",
                "caption": "Figure 5:Prompt Lengths vs. Peak Performance",
                "position": 1769
            }
        ]
    },
    {
        "header": "Appendix BPerformance and Additional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00869/x6.png",
                "caption": "Figure 6:Example of a Zero-shot prompt used on our dataset",
                "position": 1790
            },
            {
                "img": "https://arxiv.org/html/2412.00869/x7.png",
                "caption": "Figure 7:Example of a One-shot prompt used on our dataset",
                "position": 1793
            },
            {
                "img": "https://arxiv.org/html/2412.00869/x8.png",
                "caption": "Figure 8:Example of a Five-shot prompt used on our dataset",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2412.00869/x9.png",
                "caption": "Figure 9:Example of a Structured Knowledge Prompt[semantic] used on our dataset",
                "position": 1799
            },
            {
                "img": "https://arxiv.org/html/2412.00869/x10.png",
                "caption": "Figure 10:Example of a Targeted Knowledge Prompt used on our dataset",
                "position": 1802
            }
        ]
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    }
]