[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12100/x1.png",
                "caption": "Figure 1:Illustration of modular 3D assets.Modular assets can be decomposed into primitives, each possessing its own attributes, e.g., the orientationrrand the positionùíô\\bm{x}. The modular asset can be rendered with configurations to enable 3D deployment.",
                "position": 80
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12100/x2.png",
                "caption": "Figure 2:Overview of the AssetFormer Framework.Given the modular assets, e.g., the building, we first render the assets in digital engines and produce the images for querying GPT-4o. The cleaned captions, pre-filled with a re-ordered token set, serve as input for the autoregressive modeling. After training, AssetFormer autoregressively produces modular assets that are ready to be integrated into industrial environments, with model-based enhancement and application-driven deployment.",
                "position": 160
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12100/x3.png",
                "caption": "Figure 3:Qualitative comparison with comparison methods.(a) While PCG can synthesize high-quality building models, it requires meticulous algorithm design for complex buildings and can only produce simple assets that are difficult to control with text. (b) Compared with 3D generation methods, which typically yield dense meshes, struggle to accurately capture intricate geometries (the internal structure of buildings), and produce imperfect textures, our methods follow the design rationales of preferred rules (e.g., with standard primitives of plain faces) and deliver precise texture in real-world pipelines with primitive-texture mapping.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x4.png",
                "caption": "Figure 4:Qualitative ablation analysis.(a) Ablation on token orders. With improper token order, the model struggles to fit and generate the distribution accurately. (b) Ablation on data sources. The models fail to cover a wide range of diverse building types and exhibits a higher ratio of failure cases when trained on a single data source. The artifacts are indicated in red rectangles.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x5.png",
                "caption": "Figure 5:Qualitative analysis on fine-tuning native 3D generative models.(a) After Watertight conversion, the modular information is lost and the geometry erroneous (e.g., the ladder). (b) The geometry details are actually changed (zoom in to see the vertices and faces). (c) The fine-tuned Hunyuan3D 2.1 produces an overall inferior assets and (d) the details are poor.",
                "position": 501
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12100/x6.png",
                "caption": "Figure 6:Qualitative comparison with MeshGPT.We present the non-transparent and transparent results of MeshGPT and ours. Our method can produce compact arrangement of primitives, as demonstrated by the transparent rendering images and the viewpoint from the inside.",
                "position": 1597
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x7.png",
                "caption": "Figure 7:X-Ray results of the generated buildings.We further present transparent results that highlight the complex and compact structures of the generated samples. For supplementary illustration, we provide results from different viewpoints of the buildings in Fig.3.",
                "position": 1600
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x8.png",
                "caption": "Figure 8:Visualization of generated buildings with textured intricate modules mapping.Our generated assets can be seamlessly integrated into engine runtime, mapped with different textured modules of Level-of-details. We show various viewpoints for reference.",
                "position": 1603
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x9.png",
                "caption": "Figure 9:Illustration of emergent editing of AssetFormer.We showcase that without further training, the model is able to edit the modular buildings. The case (a) and case (b) show that the model can continue building and add roof. The two prompts are‚Äúsmall building, single-story, flat roof, minimal windows‚Äùand‚Äúmodern building, multi-story, pitched roof, lots of windows‚Äù.",
                "position": 1725
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x10.png",
                "caption": "Figure 10:The generated results with the same prompts.We showcase that the generated assets with the same prompts to show the diversity. The two rows are the cases of two different prompts.",
                "position": 1735
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x11.png",
                "caption": "Figure 11:Asset gallery in UE.We showcase that the generated assets can be easily edited and seamlessly integrated into Unreal Engine (UE), enabling the assembly of cohesive and production-ready gallery collections.",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x12.png",
                "caption": "Figure 12:Descriptions of primitives in building data.We showcases roof primitives, wall primitives, and other component primitives in three columns.",
                "position": 1758
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x13.png",
                "caption": "Figure 13:Phrases statistics of primitives.We show the histograms on primitives of PCG data and real data.",
                "position": 1791
            },
            {
                "img": "https://arxiv.org/html/2602.12100/x14.png",
                "caption": "Figure 14:Phrases statistics of text phrases.We show two histogram sets in (a) and (b) on text phrases of PCG data and real data. The three histograms in one set show the distribution of the first phrases, the second phrases, and the remaining phrases, used in our dataset.",
                "position": 1794
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]