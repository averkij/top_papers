[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15589/x1.png",
                "caption": "Figure 1:(a) A CoT case. Tokens highlighted in yellow represent critical reasoning tokens, while the remaining tokens primarily ensure fluency.\nHumans typically only write the yellow parts when solving this problem.\n(b) Comparison of reasoning between Vanilla and LightThinker.\n‚ÄúC Ti‚Äù denotes the i-th compressed thought representation, and we illustrate the semantic information potentially expressed after compression.",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x2.png",
                "caption": "Figure 2:Overview of LightThinker, illustrated with an example requiring three-step reasoning.\nFig. (a) shows the attention mask of Vanilla during both training and inference.\nFig. (b) depicts the attention mask of LightThinker¬†during the training.\nFig. (c) presents the complete inference process of LightThinker¬†along with the attention mask corresponding to each step.\nHere, ‚Äòw‚Äô denotes the size of the matrix.",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x2.png",
                "caption": "Figure 2:Overview of LightThinker, illustrated with an example requiring three-step reasoning.\nFig. (a) shows the attention mask of Vanilla during both training and inference.\nFig. (b) depicts the attention mask of LightThinker¬†during the training.\nFig. (c) presents the complete inference process of LightThinker¬†along with the attention mask corresponding to each step.\nHere, ‚Äòw‚Äô denotes the size of the matrix.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x3.png",
                "caption": "Figure 3:Contrast of AnLLM and ours.\nTwo differences are marked: one with a red box, and the other with blue and pink arrows.",
                "position": 194
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15589/x4.png",
                "caption": "Figure 4:The relationship between context length and the number of generated tokens across different methods.\nThe Dependency metric represents the area under the curve, while the Peak Token metric denotes the maximum value of the curve.\nSee App.Afor details.",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x5.png",
                "caption": "Figure 5:Efficiency Analysis and Ablation Results.\nFig.(a) represents the average tokens generated by the respective model on the specified dataset.\nFig.(b) shows the percentage of tokens falling within specified ranges, while the cumulative percentage curve illustrates the total proportion of tokens up to each range.\nFig.(c) illustrates the relationship between the number of generated tokens and inference time.\nEach subplot displays the inference time and peak token for various numbers of output tokens.\nFig.(d) represents the average compression ratios with 95% confidence intervals indicated by error bars.\nFig.(e-f) examines the impact of cache size (i.e.,|C|ùê∂|C|| italic_C |) on accuracy, Dep, inference time, peak tokens, generated tokens, and compression frequency.",
                "position": 2249
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x6.png",
                "caption": "Figure 6:Case Study.\nThe figure illustrates partial inference results of a case from GSM8K.\nSee App.B.5for the complete content.\nPink and light blue backgrounds are used to distinguish adjacent compression processes, where each color represents one compression.",
                "position": 2355
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMetric:Dependency",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15589/x7.png",
                "caption": "Figure 7:Illustration of the metric Dependency.",
                "position": 3166
            },
            {
                "img": "https://arxiv.org/html/2502.15589/x8.png",
                "caption": "Figure 8:Illustration of Attention Mask in Table3.",
                "position": 3275
            }
        ]
    },
    {
        "header": "Appendix BExperiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15589/x9.png",
                "caption": "Figure 9:Average number of generated tokens.",
                "position": 3343
            }
        ]
    },
    {
        "header": "Appendix CRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15589/x10.png",
                "caption": "Figure 10:Token compression frequency distribution for LightThinker.",
                "position": 3403
            }
        ]
    },
    {
        "header": "Appendix DDiscussions",
        "images": []
    }
]