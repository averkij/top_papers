[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01329/x1.png",
                "caption": "Figure 1:(Best view in color)Comparison of diffusion models across modeling spaces.Masked diffusion uses[MASK]as noise and follows a single mask-to-token path, jumping from an absorbing state to token predictions. Continuous (Gaussian) diffusion evolves in the full embedding space, but intermediate latents often do not decode to valid tokens until the final step because the search space is large. CADD combines thestabilityof masked diffusion with theflexibilityof continuous diffusion: discrete tokens anchor a context-consistent subspace, while the paired continuous latent allows smooth transitions among plausible token candidates, improving decoding at masked positions.",
                "position": 155
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Continuously Augmented Discrete Diffusion (CADD)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01329/x2.png",
                "caption": "Figure 2:Example of Signal-to-Noise Ratio (SNR) change ofone tokenin the forward of vanilla Mask Diffusion vs. CADD (Best view in color). After the second token is masked at the first time, CADD gradually corrupt the information of this token with Gaussian diffusion in the latents, resulting in a smooth decay.",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x3.png",
                "caption": "Figure 3:(Best view in color) Illustrative depiction of CADD model, combining both the discrete and continuous feature of the data. In training, the clean token at the masked position will be created by embedding matrix and used to form the noisy embedding according to the continuous forward. In sampling, the model is able to predict a diverse distribution of possible tokens by sampling multipleùíõt{\\bm{z}}_{t}. Then the predicted tokens will be recycled into the embedding matrix to formùíõ^0,Œ∏\\hat{\\bm{z}}_{0,\\theta}for the next iteration.",
                "position": 374
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01329/x4.png",
                "caption": "Figure 4:Unconditional text generative evaluation of model trained on OpenWebText (OWT) data. All method are evaluated with 128, 256, 512 1024, and 4096 sampling steps. MAUVE (Left Panel, higher is better) and generative perplexity (Right Panel, measured using GPT2-Large, lower is better) are reported.",
                "position": 688
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x4.png",
                "caption": "",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x5.png",
                "caption": "",
                "position": 695
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Derivations and Proof",
        "images": []
    },
    {
        "header": "Appendix BDetailed Experiment Settings",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01329/x6.png",
                "caption": "Figure 5:Analogous figure of Figure4. We compare the finetuned checkpoint using CADD objective with CADD and the initialization checkpoint of MDLM.",
                "position": 2781
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x6.png",
                "caption": "",
                "position": 2784
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x7.png",
                "caption": "",
                "position": 2788
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x8.png",
                "caption": "(a)MAUVE",
                "position": 3133
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x8.png",
                "caption": "(a)MAUVE",
                "position": 3136
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x9.png",
                "caption": "(b)Generative perplexity.",
                "position": 3141
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x10.png",
                "caption": "Figure 7:Analogous figure of Figure4: study of generation variance and diversity across all methods and across differentKK. We use entropy (higher indicates more stochasticity) are reported.",
                "position": 3148
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x10.png",
                "caption": "",
                "position": 3151
            },
            {
                "img": "https://arxiv.org/html/2510.01329/x11.png",
                "caption": "",
                "position": 3155
            },
            {
                "img": "https://arxiv.org/html/2510.01329/images/image_exp/cifar-vis.png",
                "caption": "Figure 8:Ablation results on image generation, trained with DDPM++ and ADM architecture. FID results measured using NFE=64, 256, 512.",
                "position": 3252
            },
            {
                "img": "https://arxiv.org/html/2510.01329/images/image_exp/cifar-vis.png",
                "caption": "Figure 9:Qualitative results of CIFAR-10, generated by ADM, using NFE=64,256,512 (from top row to bottom).",
                "position": 3284
            },
            {
                "img": "https://arxiv.org/html/2510.01329/images/image_exp/imagenet_grid.png",
                "caption": "Figure 10:Unconditional image generation, generated by CADD trained on ImageNet-32√ó3232\\times 32.",
                "position": 3676
            }
        ]
    },
    {
        "header": "Appendix DAdditional Generated Samples",
        "images": []
    }
]