[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x1.png",
                "caption": "Figure 1:Lingshuis trained on our meticulously curated datasets, encompassing rich and diverse open-sourced medical data across different modalities, general domain data, and high-quality synthetic medical data. Our results demonstrate thatLingshuachieves promising performance across various medical benchmarks and modalities. Furthermore, case studies in downstream tasks highlight its practical utility and significant potential in real-world healthcare settings.",
                "position": 237
            }
        ]
    },
    {
        "header": "2Data Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x2.png",
                "caption": "Figure 2:The overall data curation pipeline of medical multimodal and textual data.",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x3.png",
                "caption": "Figure 3:An example of the synthesized medical long-form caption for the MRI image.",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x4.png",
                "caption": "Figure 4:Illustration of the data synthesis process for synthetic medical VQA data.",
                "position": 636
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x5.png",
                "caption": "Figure 5:The distribution of medical image modality in our training data (medical subset), where the category “Pure Text” indicates text-only medical data.",
                "position": 657
            }
        ]
    },
    {
        "header": "3Model Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x6.png",
                "caption": "Figure 6:The training pipeline ofLingshu, which consists of four stages: medical shallow alignment, medical deep alignment, medical instruction tuning, and medical-oriented reinforcement learning. Note that ourLingshuis trained after the first three SFT stages. We additionally apply RL on top of it, leading toLingshu-RL version.",
                "position": 688
            }
        ]
    },
    {
        "header": "4MedEvalKit: A Unified Medical Evaluation Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x7.png",
                "caption": "(a)Medical Multimodal Benchmark",
                "position": 857
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x7.png",
                "caption": "(a)Medical Multimodal Benchmark",
                "position": 860
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x8.png",
                "caption": "(b)Medical Text-only Benchmark",
                "position": 865
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x9.png",
                "caption": "(c)Report Gen. Benchmark",
                "position": 870
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x10.png",
                "caption": "Figure 8:The prompt formats of different medical question types.",
                "position": 901
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x11.png",
                "caption": "Figure 9:Performance of different models across different medical modalities on OmniMedVQA.",
                "position": 2162
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x12.png",
                "caption": "Figure 10:The impact on downstream task performance when increasing the scale of training data.",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x13.png",
                "caption": "Figure 11:Case studies onLingshuin visual question answering across various medical imaging modalities.",
                "position": 2184
            }
        ]
    },
    {
        "header": "6Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07044/x14.png",
                "caption": "Figure 12:The comparison betweenLingshuand InternVL3 (the second-best MLLM in Table6) on medical diagnosis. Thegreen partsare some important reasoning during the generation ofLingshu. Thered partindicates the thoughtless reasoning of InternVL3.",
                "position": 2207
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x15.png",
                "caption": "Figure 13:Case study ofLingshuin explaining medical knowledge, where thered partis the incoherent or irrelevant content generated by Qwen2.5-VL.",
                "position": 2217
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x16.png",
                "caption": "Figure 14:Case study ofLingshuin dealing with a public health problem.",
                "position": 2235
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x17.png",
                "caption": "Figure 15:Case study ofLingshuin generating medical report.",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2506.07044/x18.png",
                "caption": "Figure 16:Case study ofLingshuin a real-life medical support.",
                "position": 2248
            }
        ]
    },
    {
        "header": "7Related work",
        "images": []
    },
    {
        "header": "8Conclusion, Limitations, and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "9More Details about Data Curation",
        "images": []
    },
    {
        "header": "10More Details aboutMedEvalKit",
        "images": []
    }
]