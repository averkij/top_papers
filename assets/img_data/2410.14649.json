[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.14649/x1.png",
                "caption": "Figure 1:Removing twelve transformer blocks from Llama-3-8B under the constraint that only pairs of consecutive blocks can be removed. EvoPress finds the optimal configuration from the8008800880088008possible removal combinations in generation 6.",
                "position": 455
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.14649/x2.png",
                "caption": "Figure 2:Depth pruning results, on Mistral-7B-v0.3. (Left) Relative to all prior methods, EvoPress shows significantly lower PPL gap relative to the uncompressed model, with remarkably large gaps at medium compression rates. (Right) Examining the blocks dropped, we observe that EvoPress isolates completely different profiles relative to ShortGPT (which scores by cosine similarity).",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x2.png",
                "caption": "",
                "position": 571
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x3.png",
                "caption": "",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x4.png",
                "caption": "Figure 3:Left: The convergence of EvoPress vs. number of generations and wall-clock time (on a single RTX 3090 GPU with 24GB RAM) for Llama-2-7B. We observe convergence close to optimum in 5-6h;Right: Convergence of the “super-fast” version which reduces the number of tokens used for each evaluation. It converges to similar accuracy in little over one hour, in the same setting.",
                "position": 830
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x4.png",
                "caption": "",
                "position": 833
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x5.png",
                "caption": "",
                "position": 837
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AConvergence Proof of EvoPress",
        "images": []
    },
    {
        "header": "Appendix BEvolutionary Search Parameter Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.14649/x6.png",
                "caption": "Figure 4:Convergence of EvoPress for unstructured sparsity (left) and quantization (right) for different fitness functions.",
                "position": 2809
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x6.png",
                "caption": "",
                "position": 2812
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x7.png",
                "caption": "",
                "position": 2816
            }
        ]
    },
    {
        "header": "Appendix CHyperparameter Setting",
        "images": []
    },
    {
        "header": "Appendix DAdditional Depth Pruning Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.14649/x8.png",
                "caption": "Figure 5:Convergence of EvoPress when removing 8 transformer blocks (left) and 16 transformer blocks (right) of Mistral-7B-v0.3.",
                "position": 3541
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x9.png",
                "caption": "",
                "position": 3544
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x10.png",
                "caption": "Figure 6:Optimal removal configurations identified by EvoPress for different models.",
                "position": 3555
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x10.png",
                "caption": "",
                "position": 3558
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x11.png",
                "caption": "",
                "position": 3562
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x12.png",
                "caption": "",
                "position": 3567
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x13.png",
                "caption": "",
                "position": 3571
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x14.png",
                "caption": "Figure 7:Effect of removing random subsets of blocks for Llama-3-8B.",
                "position": 3652
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x14.png",
                "caption": "",
                "position": 3655
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x15.png",
                "caption": "",
                "position": 3659
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x16.png",
                "caption": "",
                "position": 3663
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x17.png",
                "caption": "",
                "position": 3668
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x18.png",
                "caption": "",
                "position": 3672
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x19.png",
                "caption": "",
                "position": 3676
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x20.png",
                "caption": "",
                "position": 3681
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x21.png",
                "caption": "",
                "position": 3685
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x22.png",
                "caption": "",
                "position": 3689
            }
        ]
    },
    {
        "header": "Appendix EAdditional Unstructured Sparsity Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.14649/x23.png",
                "caption": "",
                "position": 4117
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x24.png",
                "caption": "",
                "position": 4125
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x25.png",
                "caption": "Figure 10:Convergence of EvoPress for 2.25 bit quantization on Llama-3.1-8B (left) and 3 bit quantization on Llama-3-8B (right).",
                "position": 4406
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x26.png",
                "caption": "",
                "position": 4409
            },
            {
                "img": "https://arxiv.org/html/2410.14649/x27.png",
                "caption": "",
                "position": 4422
            },
            {
                "img": "https://arxiv.org/html/2410.14649/",
                "caption": "",
                "position": 4430
            }
        ]
    },
    {
        "header": "Appendix FAdditional Quantization Results",
        "images": []
    }
]