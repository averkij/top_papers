[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.11909/x1.png",
                "caption": "Figure 1:In subfigure (a), an example of visual context overlook is illustrated using OpenFlamingo as a case study. Here, OpenFlamingo[6]erroneously generates a response by solely following the textual cues in the demonstration, leading to an inaccurate answer. After applying SymDPO to enhance alignment, OpenFlamingo with SymDPO successfully corrects its response, accurately addressing the question. Subfigure (b) further demonstrates that for OpenFlamingo (OF), replacing images in the demonstration with blank placeholders (OF w/ blank) or omitting images altogether (OF w/o image) surprisingly yields even better performance than the original setup. This result suggests a substantial model dependency on textual context over visual information.",
                "position": 77
            },
            {
                "img": "https://arxiv.org/html/2411.11909/x2.png",
                "caption": "Figure 2:Comparison of General DPO and SymDPO Formats: General DPO relies solely on standard text for Questions, Answers, Chosen, and Rejected Answers, focusing on text-based training. In contrast, SymDPO replaces textual Answers with symbolized text to boost multimodal understanding, requiring models to interpret both visual and symbolized cues. This approach strengthens the modelâ€™s ability to reason and decide in complex multimodal contexts.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.11909/x3.png",
                "caption": "Figure 3:Comparison of Symbol Tuning, General DPO, and SymDPO Methods: We optimized OF 3b using three different methods: Symbol Tuning, General DPO, and SymDPO, resulting in three distinct variants. The performance of these variants was visualized using line charts, showcasing the results across four-shot (4, 8, 16, 32) settings on the COCO, VQAv2, and OK-VQA benchmarks.",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2411.11909/x4.png",
                "caption": "Figure 4:Impact of Visual Context Removal on OF and OF+SymDPO Performance.",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2411.11909/x5.png",
                "caption": "Figure 5:Comparison of the Impact of General DPO and SymDPO on LMMs with Varying Data Proportions in the Preference Dataset",
                "position": 1000
            },
            {
                "img": "https://arxiv.org/html/2411.11909/x6.png",
                "caption": "Figure 6:Example Visualization of OpenFlamingo 3B and OpenFlamingo 3B + SymDPO in ICL 2-Shot Setting.",
                "position": 1003
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]