[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12202/extracted/6144353/figures/teaser.png",
                "caption": "",
                "position": 94
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x1.png",
                "caption": "Figure 1:An overall ofHunyuan3D 2.0system.",
                "position": 97
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Hunyuan3D 2.0Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12202/x2.png",
                "caption": "Figure 2:An overall ofHunyuan3D 2.0architecture for 3D generation. It consists of two main components: Hunyuan3D-DiT for generating bare mesh from a given input image and Hunyuan3D-Paint for generating a textured map for the generated bare mesh. Hunyuan3D-Paint takes geometry conditions – normal maps and position maps of generated mesh as inputs and generates multi-view images for texture baking.",
                "position": 128
            }
        ]
    },
    {
        "header": "3Generative 3D Shape Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12202/x3.png",
                "caption": "Figure 3:The overall architecture of Hunyuan3D-ShapeVAE.\nInstead of only using uniform sampling on mesh surface, We have developed an importance sampling strategy to extract high-frequency detail information from the input mesh surface, such as edges and corners. This allows the model to better capture and represent the intricate details of 3D shapes.\nNote that during the point query construction, the Farthest Point Sampling (FPS) operation is performed separately for the uniform point cloud and the importance sampling point cloud.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x4.png",
                "caption": "Figure 4:Overview of Hunyuan3D-DiT. It adopts a transformer architecture with both double- and single-stream blocks. This design benefits the interaction between modalities of shape and image, helping our model to generate bare meshes with exceptional quality. (Note that the orange blocks have no learnable parameters, the blue blocks contain trainable parameters, and the gray blocks indicate a module composed of more details.)",
                "position": 215
            }
        ]
    },
    {
        "header": "4Generative Texture Map Synthesis",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12202/x5.png",
                "caption": "Figure 5:Overview of Hunyuan3D-Paint. We leverage an image delighting module to convert the input image to an unlit state to produce light-invariant texture maps.\nThe system features a double-stream image conditioning reference-net, which provides faithfully conditional image features to the model. Furthermore, it facilitates the production of texture maps that conform closely to the input image.\nThe multi-task attention module ensures that the model synthesizes multi-view consistent images. This module maintains the coherence of all generated images while adhering to the input.",
                "position": 231
            }
        ]
    },
    {
        "header": "5Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12202/x6.png",
                "caption": "Figure 6:Visual comparisons.\nWe illustrate the reconstructed mesh (blue paint aims to show more details) in the figure, which showcases that only Hunyuan3D-ShapeVAE reconstructs mesh with fine-grained surface details and neat space. (Better viewed by zooming in.)",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x7.png",
                "caption": "Figure 7:Visual comparisons.\nWe display the input image and the generated bare mesh (blue paint aims to show more details) from all methods in the figure. The human faces and piano keys show that Hunyuan3D-DiT could synthesize detailed surface bumps, maintaining completeness. Several scenes or logos demonstrate that Hunyuan3D-DiT could generate intricate details. (Better viewed by zooming in.)",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x8.png",
                "caption": "Figure 8:Visual comparisons.\nWe demonstrate several generated texture maps on different bare meshes. The fish and rabbit texture map showcases that Hunyuan3D-Paint produces the most text-conforming results.\nThe football indicates that our model could synthesize seamless and clean texture maps.\nMoreover, Hunyuan3D-Paint could generate complex texture maps, like the castle and bear.\n(Better viewed by zooming in.)",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2501.12202/extracted/6144353/figures/texture/skinning.png",
                "caption": "Figure 9:Visual results.\nWe generate different texture maps for two meshes, and the results validate the performance of Hunyuan3D-Paint on texture reskinning. (Better viewed by zooming in.)",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x9.png",
                "caption": "Figure 10:The results of user study.",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2501.12202/x10.png",
                "caption": "Figure 11:Visual comparisons.\nThe first case reflects thatHunyuan3D 2.0could synthesize detailed surface bumps and correct texture maps.\nThe second penguin showcases our model’s ability to handle complex actions.\nThe last mountain demonstrates that Hunyuan3D-DiT could produce intricate structures, and Hunyuan3D-Paint can synthesize vivid texture maps.\n(Better viewed by zooming in.)",
                "position": 785
            }
        ]
    },
    {
        "header": "6Hunyuan3D-Studio",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Contributors",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]