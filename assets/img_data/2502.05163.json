[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x1.png",
                "caption": "Figure 1:Illustration of the use-case of a guardrail model for LLMs, which functions as moderation between the user-LLM conversation.",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x2.png",
                "caption": "Figure 2:Overview of our main results.In the left figure, we demonstrate a consistently superior performance of average f1 score across 6 benchmarks in the four languages. In the right figure, we show that our model maintains the lowest inference cost while achieving superior average performance across languages. We note that, although we focus on the four languages to demonstrate the two-player data synthesis framework,DuoGuardretains its base model Qwen-2.5’s capacity to support all 29 languages.",
                "position": 155
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x3.png",
                "caption": "Figure 3:Overview of the two-player training pipeline.The generator produces synthetic data from seed data. The classifier makes predictions and we measure these examples as being predicted correctly or incorrectly based on their seed data label. We train the generator with DPO to create increasingly challenging examples, which in turn improve the classifier through iterative training.",
                "position": 224
            }
        ]
    },
    {
        "header": "3Problem Setting and Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x4.png",
                "caption": "Table 1:Detailed F-1 scores on the classification benchmarks. Theboldnumbers indicate the best results among the methods evaluated and theunderscorednumbers represent the second-best results.",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x4.png",
                "caption": "Figure 4:Relative performance decline (average F1 across six benchmarks and three languages) of various models compared to the English performance ofDuoGuard.",
                "position": 730
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x5.png",
                "caption": "Table 2:Average F-1 scores across languages of different models trained with the dataset developed by our two-player scheme. The data can easily generalize to different base models (Llama-3.2) and different scales (1.5B).",
                "position": 740
            }
        ]
    },
    {
        "header": "6Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x5.png",
                "caption": "Figure 5:The F1 score on OpenAI benchmark of models trained with data containing different languages in our seed data. The inclusion of French in addition to English improves model performance on Spanish (36.9% to 62.8%) and German (31.9 to 59.6).",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x6.png",
                "caption": "Figure 6:Performance by languages of the model trained on seed data. With larger data proportion in seed data, the model’s average performance on English is markedly higher than on other languages.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x7.png",
                "caption": "Figure 7:(a) Iterative performance improvements ofDuoGuard. (b) Shift in data distribution across languages over iterations.",
                "position": 812
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x7.png",
                "caption": "",
                "position": 815
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x8.png",
                "caption": "",
                "position": 819
            },
            {
                "img": "https://arxiv.org/html/2502.05163/x9.png",
                "caption": "Table 3:Model’s average F1 with different training data at Iter1.",
                "position": 825
            }
        ]
    },
    {
        "header": "7Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix BAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix CSeed Data Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x9.png",
                "caption": "Figure 8:Data proportion by language in our collected seed data from open sources.",
                "position": 2988
            }
        ]
    },
    {
        "header": "Appendix DExperiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05163/x10.png",
                "caption": "Figure 9:Output Probability Distribution of False Positives and False Negatives in the Classifier Trained on Seed Data.A skewed distribution toward 0 for false negatives and toward 1 for false positives indicates higher classifier confidence in its incorrect predictions. Analysis across the four French datasets reveals that the classifier exhibits significant confidence in its false predictions.",
                "position": 3504
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results",
        "images": []
    }
]