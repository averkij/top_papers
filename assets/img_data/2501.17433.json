[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17433/extracted/6163167/pic/virus.png",
                "caption": "Figure 1:A three stage pipeline for harmful fine-tuning attack under guardrail moderation. i) At the first stage, the model is safety aligned with alignment data. ii) At the second stage, the service provider applies guardrail moderation to filter out the harmful samples over the uploaded fine-tuning data. iii) At the third stage, the filtered data is used for fine-tuning the aligned LLM. Our attack Virus is concerning how to construct the user dataset that can bypass the guardrail and break the victim LLM’s safety alignment.",
                "position": 107
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17433/extracted/6163167/pic/HS_FS_hr.png",
                "caption": "Figure 2:Harmful score and Fine-tune accuracy under different harmful ratio. HFA refers to harmful fine-tuning attack with a harmful ratio of harmful data. BFA refers to benign fine-tuning attack with pure GSM8K data. BF is a special case when harmful ratio=0 for HF. The average leakage ratio (ratio of leak-through harmful data) of HF w/ moderation is 0.348. All the data in BFA an leak through the moderation.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2501.17433/extracted/6163167/pic/example_figure.png",
                "caption": "Figure 3:Example illustration of different fine-tuning attack techniques. a) For benign fine-tuning attack, benign QA pair is uploaded for fine-tuning. b) For harmful fine-tuning attack, only harmful samples are uploaded. c) For Mixing attack, a benign QA is concatenated with a harmful QA in order to circumvent guardrail, which unfortunately does not succeed. d) For Virus, the benign QA is concated with a harmful QA and the harmful QA is optimized with the dual goals: i) To bypass moderation. ii) To guarantee attack performance.",
                "position": 226
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17433/extracted/6163167/pic/statistic.png",
                "caption": "Figure 4:Stepping over the data optimized by Virus with differentλ𝜆\\lambdaitalic_λ, harmful loss and gradient similarity across fine-tuning rounds are displayed. Whenλ=1𝜆1\\lambda=1italic_λ = 1, the method reduces to one of our failure attempt named guardrail jailbreak.",
                "position": 849
            }
        ]
    },
    {
        "header": "6Visualization",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Impact Statements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17433/extracted/6163167/pic/onehot.png",
                "caption": "Figure 5:Illustration of flattened one-hot vector.",
                "position": 2142
            }
        ]
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    }
]