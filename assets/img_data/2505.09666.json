[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.09666/x1.png",
                "caption": "Figure 1:Concept Figure.(A) The input prompt provided to LLMs typically consists of a task-agnostic system prompt, a task-specific user prompt, and a target example to handle. (B) Conventional Task-Specific Optimization focuses on optimizing user prompts for a single task but shows limited generalization to other tasks. (C) The goal of Bilevel System Prompt Optimization (Ours) is to enable the optimized system prompt to generalize effectively to unseen target tasks, for which we utilize a meta-learning framework to derive meta-knowledge from multiple source tasks.",
                "position": 152
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.09666/x2.png",
                "caption": "Figure 2:Overview of MetaSPO, which consists of the inner loop for user prompt optimization and the outer loop for system prompt optimization, operationalized through the meta-learning framework. (A) Inner Loop generates candidate user prompts by analyzing incorrectly predicted examples, and then evaluates them with the system prompt to select refined prompts for individual tasks. (B) Outer Loop generates candidate system prompts by analyzing incorrect examples from all source tasks, and then evaluates them across various user prompts and tasks to ensure generalizability.",
                "position": 188
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.09666/x3.png",
                "caption": "Figure 3:Performance of user prompts with MetaSPO (y洧녽yitalic_y) and Default (x洧논xitalic_x).Points overy=x洧녽洧논y=xitalic_y = italic_xindicate the superiority of MetaSPO.",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x3.png",
                "caption": "Figure 3:Performance of user prompts with MetaSPO (y洧녽yitalic_y) and Default (x洧논xitalic_x).Points overy=x洧녽洧논y=xitalic_y = italic_xindicate the superiority of MetaSPO.",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x4.png",
                "caption": "Figure 4:Relative performance improvements of our MetaSPO over Default as a function of the source-target tasks similarity, where the similarity is measured by Bag-of-Words (BoW).",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x5.png",
                "caption": "Figure 5:Results with generalization across different domains. (Left:) Performance of MetaSPO for domains not used for prompt optimization, with their similarity. (Right:) Effect of the number of training domains with stds.",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x6.png",
                "caption": "Table 2:Main Results on Test-Time Adaptation, where we optimize the user prompts with examples from target tasks, while fixing the system prompt. The average score for each domain is reported.",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x6.png",
                "caption": "Figure 6:Efficiency for test-time adaptation as the function of optimization iterations (left) and data quantity (right).The results are averaged over Review Analysis and Reasoning domains. The gray dashed line indicates the final performance of the Default baseline.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x7.png",
                "caption": "Figure 7:Results as a function of the number of source tasks for system prompt optimization on MetaSPO, ranging from 1 to 6. Standard deviation is shown as shaded areas.",
                "position": 608
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x7.png",
                "caption": "Figure 7:Results as a function of the number of source tasks for system prompt optimization on MetaSPO, ranging from 1 to 6. Standard deviation is shown as shaded areas.",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x8.png",
                "caption": "Figure 8:Comparison of input prompt structures, with separated inputs (system/user roles are explicitly separated) and unified input (both are assigned to the user role).",
                "position": 616
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x9.png",
                "caption": "Figure 9:Ratios of the attention scores directed toward system prompts over user prompts.A higher ratio indicates that LLMs pay more attention to the system prompt than the user prompt.",
                "position": 621
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x10.png",
                "caption": "Table 3:Results with different LLMs for MetaSPO, whereCross Modelrefers to prompts optimized with Llama3.2 (3B) and applied to other models. Results are averaged over Review Analysis and Reasoning domains. Numbers in bold indicate the highest followed by underline.",
                "position": 645
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.09666/x10.png",
                "caption": "Figure 10:Unseen Generalization Performance of MetaSPO for each iteration.",
                "position": 2944
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x11.png",
                "caption": "",
                "position": 2954
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x12.png",
                "caption": "",
                "position": 2960
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x13.png",
                "caption": "",
                "position": 2967
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x14.png",
                "caption": "",
                "position": 2973
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x15.png",
                "caption": "Figure 11:Performance of various user prompts with the system prompt from Default (x洧논xitalic_x) and MetaSPO (y洧녽yitalic_y) for each domain.Points abovey=x洧녽洧논y=xitalic_y = italic_xindicate the superiority of MetaSPO.",
                "position": 3026
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x16.png",
                "caption": "",
                "position": 3036
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x17.png",
                "caption": "",
                "position": 3042
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x18.png",
                "caption": "",
                "position": 3049
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x19.png",
                "caption": "",
                "position": 3055
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x20.png",
                "caption": "Figure 12:Relative improvements of MetaSPO against Default as a function of the similarity between source and target tasks, where the similarity is measured by the embedding-level cosine similarity from[33].",
                "position": 3070
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x21.png",
                "caption": "Figure 13:Performance of prompt optimization methods on the Reasoning domain using prompts trained on different source domains.",
                "position": 3143
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x22.png",
                "caption": "Figure 14:Results with varying the number of source tasks for system prompt optimization on MetaSPO, in the range of 1 to 20.",
                "position": 3154
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x23.png",
                "caption": "Figure 15:Result of the MetaSPO with varying the number of wrong examples for system prompt optimization.",
                "position": 3225
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x24.png",
                "caption": "",
                "position": 3235
            }
        ]
    },
    {
        "header": "Appendix CQualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.09666/x25.png",
                "caption": "Figure 16:Example of failure analysis prompt and analyzed problem.",
                "position": 3450
            },
            {
                "img": "https://arxiv.org/html/2505.09666/x26.png",
                "caption": "Figure 17:Example of prompt generation prompt and improved system prompt.",
                "position": 3454
            }
        ]
    },
    {
        "header": "Appendix DLimitation and Societal Impacts",
        "images": []
    }
]