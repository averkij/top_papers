[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18909/x1.png",
                "caption": "(a)Arc-Easy",
                "position": 104
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x1.png",
                "caption": "(a)Arc-Easy",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x2.png",
                "caption": "(b)Arc-Challenge",
                "position": 113
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x3.png",
                "caption": "(c)Hellaswag",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x4.png",
                "caption": "(d)PIQA",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x5.png",
                "caption": "(e)SCIQ",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x6.png",
                "caption": "(a)UMAP projection of text embeddings. The embeddings are reduced to two dimensions using UMAP.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x6.png",
                "caption": "(a)UMAP projection of text embeddings. The embeddings are reduced to two dimensions using UMAP.",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x7.png",
                "caption": "(b)Pairwise distance distribution of text embeddings. The distances are computed with cosine distances.",
                "position": 153
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18909/x8.png",
                "caption": "(a)Performance with data selected from PCs",
                "position": 669
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x8.png",
                "caption": "(a)Performance with data selected from PCs",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x9.png",
                "caption": "(b)Performance across selected data pools",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x10.png",
                "caption": "(a)Pairwise distance distribution",
                "position": 688
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x10.png",
                "caption": "(a)Pairwise distance distribution",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x11.png",
                "caption": "(b)UMAP projection of text embeddings",
                "position": 697
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x12.png",
                "caption": "(a)Correlation matrix between different dimensions",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x12.png",
                "caption": "(a)Correlation matrix between different dimensions",
                "position": 717
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x13.png",
                "caption": "(b)Correlation matrix between original and PC dimensions",
                "position": 723
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x14.png",
                "caption": "(a)UMAP for embeddings. The embeddings are generated through 1000 sampled top-scored data from each PC dimension.",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x14.png",
                "caption": "(a)UMAP for embeddings. The embeddings are generated through 1000 sampled top-scored data from each PC dimension.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2510.18909/x15.png",
                "caption": "(b)UpSet plot of top-scored subsets. Data selected with top scores of each dimension are shown, with intersections indicating data that simultaneously belong to multiple top-scored subsets.",
                "position": 746
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AUse of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix B11 evaluation dimensions",
        "images": []
    },
    {
        "header": "Appendix CMetrics and Prompt for each dimension",
        "images": []
    },
    {
        "header": "Appendix DBenchmarks Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18909/x16.png",
                "caption": "Figure 7:Performance across downstream tasks",
                "position": 2678
            }
        ]
    },
    {
        "header": "Appendix EScore distribution across different PC",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18909/x17.png",
                "caption": "Figure 8:Score distribution over different domains.",
                "position": 2688
            }
        ]
    },
    {
        "header": "Appendix FResults with single PC",
        "images": []
    }
]