[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13954/images/combined-emotions.png",
                "caption": "Figure 1:Visual representation of a wide range of emotions in the three-dimensional Valence–Arousal–Dominance (VAD) space.",
                "position": 77
            },
            {
                "img": "https://arxiv.org/html/2511.13954/images/individual-emotions.png",
                "caption": "Figure 2:Individual emotion representations within the three-dimensional Valence–Arousal–Dominance (VAD) space, showcasing the unique characteristics of each emotion.",
                "position": 80
            }
        ]
    },
    {
        "header": "IIMethodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13954/images/eeg-preprocessing.png",
                "caption": "Figure 3:Preprocessing pipeline applied across EEG datasets for RBTransformer.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2511.13954/images/model-diagram.png",
                "caption": "Figure 4:Schematic architecture diagram of RBTransformer implementing inter-cortical attention.",
                "position": 244
            }
        ]
    },
    {
        "header": "IIIExperimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13954/images/electrodes_used_in_datasets.png",
                "caption": "Figure 5:Electrode layouts for (a) SEED[zheng2015investigating]with 62 electrodes, (b) DEAP[koelstra2012deap]with 32 electrodes, and (c) DREAMER[katsigiannis2018dreamer]with 14 electrodes. Blue circles indicate active electrodes used in each dataset; Grey circles denote unused electrodes.",
                "position": 439
            }
        ]
    },
    {
        "header": "IVResults and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13954/images/ablations.png",
                "caption": "Figure 6:Ablation study for binary classification on the DREAMER dataset (Arousal dimension). Top: Impact of inter-cortical attention. Bottom: Impact of training and regularization components including ADASYN, SMOTE with label smoothing, weight decay, and dropout.",
                "position": 1194
            },
            {
                "img": "https://arxiv.org/html/2511.13954/images/tsne-plots-rbtransformer.png",
                "caption": "Figure 7:t-SNE visualization of RBTransformer’s learned feature representations on SEED, DEAP, and DREAMER for both binary and multi-class classification tasks across all dimensions (Valence, Arousal, and Dominance).",
                "position": 1329
            },
            {
                "img": "https://arxiv.org/html/2511.13954/images/confusion-matrices.png",
                "caption": "Figure 8:Confusion matrices of RBTransformer predictions on SEED, DEAP, and DREAMER for both binary and multi-class classification across all dimensions (Valence, Arousal, and Dominance).",
                "position": 1340
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    }
]