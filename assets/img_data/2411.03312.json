[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.03312/x1.png",
                "caption": "(a)Scaling laws for VLMs atQ=0ùëÑ0Q=0italic_Q = 0(cached text).",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x1.png",
                "caption": "(a)Scaling laws for VLMs atQ=0ùëÑ0Q=0italic_Q = 0(cached text).",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x2.png",
                "caption": "(b)Scaling laws for VLMs atQ=50ùëÑ50Q=50italic_Q = 50(variable text).",
                "position": 145
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Tokens vs Parameters: Inference Time Scaling Laws for VLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.03312/x3.png",
                "caption": "Figure 2:Our scaling laws (fitted on VLMs with 0.5-7B LLMs) estimate the performance of a 14B LLM VLM with an error margin of less than 2%.",
                "position": 294
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x4.png",
                "caption": "(a)Performance trends and trade-offs of VLMs change when varying the number of input text tokenQùëÑQitalic_Q.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x4.png",
                "caption": "(a)Performance trends and trade-offs of VLMs change when varying the number of input text tokenQùëÑQitalic_Q.",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x5.png",
                "caption": "(b)Scaling laws on OCR-like tasks favor visual token count over LLM size; the opposite of visual reasoning.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x6.png",
                "caption": "Figure 4:Performances of various LLM size and visual token count combinations at similar inference compute.For visual reasoning tasks, at a given fixed inference cost, increasing the LLM size by decreasing the number of visual tokens improves VLM performance. However, for text recognition tasks, decreasing the number of visual tokens is detrimental to performance (¬ß3.3.3).",
                "position": 353
            }
        ]
    },
    {
        "header": "4Query-Based Token Compression",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.03312/x7.png",
                "caption": "Figure 5:Our query-based convolutional cross-attention (QueCC, pronounced ‚Äúquick‚Äù) compression technique. User input text tokens are first processed through the LLM backbone to generate text embeddings that are then combined with the visual tokens. Within QueCC, the query-embedded visual tokens are downsampled via convolution. Next, local cross-attention is applied between the downsampled tokens and their respective visual tokens regions. The compressed tokens pass through an MLP before passing into the LLM, alongside input text tokens, for generation (¬ß4).",
                "position": 372
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Discussion and Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.03312/x8.png",
                "caption": "(a)Scaling law prediction for 14B LLM atQ=0ùëÑ0Q=0italic_Q = 0.",
                "position": 1636
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x8.png",
                "caption": "(a)Scaling law prediction for 14B LLM atQ=0ùëÑ0Q=0italic_Q = 0.",
                "position": 1639
            },
            {
                "img": "https://arxiv.org/html/2411.03312/x9.png",
                "caption": "(b)Scaling law prediction for 14B LLM atQ=50ùëÑ50Q=50italic_Q = 50.",
                "position": 1644
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]