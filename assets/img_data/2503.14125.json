[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14125/x1.png",
                "caption": "Figure 1:Comparison of Frac-Connections and Hyper-Connections based on their expansion rates. Frac-Connections correspond ton‚â§1ùëõ1n\\leq 1italic_n ‚â§ 1, while Hyper-Connections are defined byn‚â•1ùëõ1n\\geq 1italic_n ‚â• 1. The two connection types become identical when the expansion rate isn=1ùëõ1n=1italic_n = 1.",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14125/x2.png",
                "caption": "Figure 3:Figure 2. Frac-connections (FC) with an expansion rate ofn=1/2ùëõ12n=1/2italic_n = 1 / 2.(a) Residual connections.\n(b) Hyper-connections:Œ≤1subscriptùõΩ1\\beta_{1}italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,Œ≤2subscriptùõΩ2\\beta_{2}italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT,Œ±0,0subscriptùõº00\\alpha_{0,0}italic_Œ± start_POSTSUBSCRIPT 0 , 0 end_POSTSUBSCRIPT,Œ±0,1subscriptùõº01\\alpha_{0,1}italic_Œ± start_POSTSUBSCRIPT 0 , 1 end_POSTSUBSCRIPT,Œ±1,0subscriptùõº10\\alpha_{1,0}italic_Œ± start_POSTSUBSCRIPT 1 , 0 end_POSTSUBSCRIPT,Œ±1,1subscriptùõº11\\alpha_{1,1}italic_Œ± start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT,Œ±2,1subscriptùõº21\\alpha_{2,1}italic_Œ± start_POSTSUBSCRIPT 2 , 1 end_POSTSUBSCRIPT, andŒ±2,2subscriptùõº22\\alpha_{2,2}italic_Œ± start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPTare learnable scalars or scalars predicted by the network, depending on the specific HC version.\n(c) Frac-connections: Frac-connections split the hidden representations into smaller fractions and process each fraction independently. The scalarsŒ≥1,2subscriptùõæ12\\gamma_{1,2}italic_Œ≥ start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT,Œ≥2,1subscriptùõæ21\\gamma_{2,1}italic_Œ≥ start_POSTSUBSCRIPT 2 , 1 end_POSTSUBSCRIPT, andŒ≥2,2subscriptùõæ22\\gamma_{2,2}italic_Œ≥ start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPTare either learnable or predicted by the network, similar to hyper-connections. These fractions are concatenated (denoted asCat) after processing, followed by integration into the main network pipeline.",
                "position": 144
            }
        ]
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14125/x3.png",
                "caption": "Figure 4:Training loss (0.999 EMA smoothed) loss forOLMoE-1.3Bmodels.",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x4.png",
                "caption": "",
                "position": 681
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x5.png",
                "caption": "",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x6.png",
                "caption": "Figure 5:Training and evaluation performance ofOLMoE-7Bmodels. The plots show the training loss, C4-en loss, and accuracy on HellaSwag, SciQ, Commonsense QA, Social IQA, and WinoGrande over the course of training. The results are EMA-smoothed for clarity. TheOLMoE-7B-DFCx4variant demonstrates improved loss reduction and higher accuracy across multiple benchmarks compared to the baselineOLMoE-7Bmodel, indicating enhanced optimization efficiency and generalization.",
                "position": 712
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x7.png",
                "caption": "",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x8.png",
                "caption": "",
                "position": 726
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x9.png",
                "caption": "",
                "position": 731
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x10.png",
                "caption": "",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x11.png",
                "caption": "",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x12.png",
                "caption": "",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x13.png",
                "caption": "",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x14.png",
                "caption": "Figure 6:Training and evaluation performance ofOLMo2-1B2models. The plots show the training loss, C4-en loss, and accuracy on HellaSwag and SciQ over the course of training. The results are EMA-smoothed for clarity. TheOLMo2-1B2-DFCx4variant demonstrates improved loss reduction and higher accuracy compared to the baseline OLMo2-1B2 model.",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x15.png",
                "caption": "",
                "position": 856
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x16.png",
                "caption": "",
                "position": 861
            },
            {
                "img": "https://arxiv.org/html/2503.14125/x17.png",
                "caption": "",
                "position": 866
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7PyTorch Implementation of Frac-connections",
        "images": []
    },
    {
        "header": "8OLMo2 Model Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14125/x18.png",
                "caption": "Figure 7:Loss and accuracy curves forOLMo2-1B2andOLMo2-1B2-DFC√ó4absent4\\times{4}√ó 4models.",
                "position": 1610
            }
        ]
    },
    {
        "header": "9OLMoE-7B Model Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14125/x19.png",
                "caption": "Figure 8:Loss and accuracy curves forOLMoE-7BandOLMoE-7B-DFC√ó4absent4\\times{4}√ó 4models.",
                "position": 1618
            }
        ]
    },
    {
        "header": "10Downstream Benchmarks",
        "images": []
    }
]