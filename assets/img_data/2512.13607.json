[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x1.png",
                "caption": "",
                "position": 298
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x2.png",
                "caption": "Figure 1:The LiveCodeBench v6 (08/24–05/25) performance of the Nemotron-Cascade-14B-Thinking model throughout the Cascade RL process. Note that DeepSeek-R1-0528 (671B) serves as the teacher model for SFT data curation.",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x3.png",
                "caption": "Figure 2:Cascade RL applies sequential, domain-wise reinforcement learning after SFT, leading to substantial improvements across the corresponding domains.",
                "position": 494
            }
        ]
    },
    {
        "header": "2Main Results",
        "images": []
    },
    {
        "header": "3Supervised Fine-Tuning",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x4.png",
                "caption": "Figure 3:(Left) The chat template employs the/thinkand/no_thinktags in the user prompt to control whether the model operates in thethinkingornon-thinkinggeneration mode.\n(Right) For tool calling, the available tools are listed in the system prompt. The model is instructed to call tools within the<tool_call>and</tool_call>tags.",
                "position": 817
            }
        ]
    },
    {
        "header": "4Cascade RL",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x5.png",
                "caption": "Figure 4:Training curve of math RL for 8Bunifiedmodel on AIME24 and AIME25 (max response length 64K, avg@64).",
                "position": 2094
            }
        ]
    },
    {
        "header": "5Deep Dive on Competitive Coding",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x6.png",
                "caption": "Figure 5:IOI 2025: Nemotron-Cascade-14B-Thinking’s score on(Left)Full problem set;(Right)Problem 2Triplesafter rounds of our proposed test-time scaling pipeline.",
                "position": 3162
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x7.png",
                "caption": "Figure 6:(Left)Average Token Entropy(Right)Model accuracy curves of our 8Bunifiedmodel during Code RL training under different temperatures {0.6, 0.8, 1.0}. Training with high temperature yields better model accuracy but may suffer from training instability.",
                "position": 3171
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x7.png",
                "caption": "",
                "position": 3174
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x8.png",
                "caption": "",
                "position": 3178
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x9.png",
                "caption": "Figure 7:Topic-wise accuracy of unified Nemotron-Cascade-8B after Cascade RL stages on LCB v6 set. DS refers to Data Structure and Geo refers to Geometry.",
                "position": 3202
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x10.png",
                "caption": "Figure 8:Nemotron-Cascade-8B accuracy (avg@8) and average reasoning token counts after cascade RL stages on each difficulty splits of LiveCodeBench v6 (2408-2505). Curves indicate the improvements of reasoning capability on solving algorithmic coding problems after each stage.",
                "position": 3208
            }
        ]
    },
    {
        "header": "6Deep Dive on RLHF",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x11.png",
                "caption": "Figure 9:RLHF training results for unified 8B SFT model using the 72B reward model with different training strategies. Training RLHF in bothnon-thinkingandthinkingmodes, with an equal split of prompts allocated to each mode within every batch (“Half-Half”), is significantly better than training the unified model in thenon-thinkingmode only (“Non-thinking”) and thethinkingmode only (“Thinking”), although the evaluation of ArenaHard, AIME, and LiveCodeBench is in thethinkingmode only.",
                "position": 3234
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x12.png",
                "caption": "Figure 10:RLHF training results for AceReason-Nemotron-1.0-7B(Chen et al.,2025b)using reward models ranging from 7B to 72B. Corresponding RewardBench scores for the reward models are provided in Table3. Using the largest reward model yields the best ArenaHard performance under style control, while smaller reward models lead to noticeable degradation in ArenaHard scores as well as math and code capabilities.",
                "position": 3243
            }
        ]
    },
    {
        "header": "7Deep Dive on SWE",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13607/x13.png",
                "caption": "(a)Nemotron-Cascade-8B",
                "position": 3408
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x13.png",
                "caption": "(a)Nemotron-Cascade-8B",
                "position": 3411
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x14.png",
                "caption": "(b)Nemotron-Cascade-14B-Thinking",
                "position": 3416
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x15.png",
                "caption": "(a)Nemotron-Cascade-8B",
                "position": 3611
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x15.png",
                "caption": "(a)Nemotron-Cascade-8B",
                "position": 3614
            },
            {
                "img": "https://arxiv.org/html/2512.13607/x16.png",
                "caption": "(b)Nemotron-Cascade-14B-Thinking",
                "position": 3619
            }
        ]
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "Appendix AAcknowledgments",
        "images": []
    },
    {
        "header": "Appendix BBenchmarks and Evaluation Setups",
        "images": []
    },
    {
        "header": "Appendix CPrompt Templates",
        "images": []
    },
    {
        "header": "Appendix DTraining Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix EELO Rating Analysis",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]