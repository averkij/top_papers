[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13683/x1.png",
                "caption": "",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13683/x2.png",
                "caption": "Figure 2:Overview.I-Scenehas two branches: (i) spatial guidance branch takes scene RGB as input and provides spatial anchor for each instance generation. (2) Instance branch takes instance RGB and scene context tokens and output the instance in view centric space.",
                "position": 217
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13683/fig/view-centric-space.png",
                "caption": "(a)View-centric space",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2512.13683/fig/view-centric-space.png",
                "caption": "(a)View-centric space",
                "position": 318
            },
            {
                "img": "https://arxiv.org/html/2512.13683/fig/rand-scene-example.png",
                "caption": "(b)Non-Semantic scene",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13683/x3.png",
                "caption": "Figure 4:Qualitative comparison with all baselines on synthetic scenes. We might slightly rotate the view to better illustrate the error patterns. More details can be found inAppendix.",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2512.13683/x4.png",
                "caption": "Figure 5:Qualitative comparison with scenes in-the -wild. We compare the generalization ability of different methods in different style and various spatial relations. To better illustrate the error pattern, we might slightly rotate the view.",
                "position": 700
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Overview",
        "images": []
    },
    {
        "header": "7Method",
        "images": []
    },
    {
        "header": "8Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13683/x5.png",
                "caption": "Figure 6:We present the multi-view evaluation results using real-world /stylized image as input (example 1). The testing scenes contain various layouts includingfront, back, right, left, small on large, behind, and etc. Baselines includes PartCfrater[lin2025partcrafter], Gen3DSR[ardelean2024gen3dsr], MIDI-3D[huang2025midi], and SceneGen[meng2025scenegen]",
                "position": 1244
            },
            {
                "img": "https://arxiv.org/html/2512.13683/x6.png",
                "caption": "Figure 7:We present the multi-view evaluation results using real-world /stylized image as input (example 2). The testing scenes contain various layouts includingfront, back, right, left, small on large, behind, and etc. Baselines includes PartCfrater[lin2025partcrafter], Gen3DSR[ardelean2024gen3dsr], MIDI-3D[huang2025midi], and SceneGen[meng2025scenegen]",
                "position": 1247
            },
            {
                "img": "https://arxiv.org/html/2512.13683/x7.png",
                "caption": "Figure 8:We present the multi-view evaluation results using synthetic scenes as input. The testing scenes contain various layouts includingfront, back, right, left, small on large, behind, and etc. Baselines includes PartCfrater[lin2025partcrafter], Gen3DSR[ardelean2024gen3dsr], MIDI-3D[huang2025midi], and SceneGen[meng2025scenegen]",
                "position": 1284
            },
            {
                "img": "https://arxiv.org/html/2512.13683/x8.png",
                "caption": "Figure 9:Ablation study on scene-context attention (SCA), view-centric space (VC), and non-semantic scenes (NS). With only SCA, the model often fails to maintain a coherent global layout and produces frequent object collisions. Adding the VC component substantially improves the overall arrangement of objects, but instance quality remains limited, as seen in the distorted cat, cow, and the chair under the toy bear. Incorporating NS further enhances both instance fidelity and global layout coherence.",
                "position": 1287
            },
            {
                "img": "https://arxiv.org/html/2512.13683/x9.png",
                "caption": "Figure 10:instance quality is bad when the input instance mask is small in the image.",
                "position": 1290
            }
        ]
    },
    {
        "header": "9Qualitative results.",
        "images": []
    }
]