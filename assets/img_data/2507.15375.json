[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.15375/x1.png",
                "caption": "Figure 1:The timing diagram during generation forStitch-R.\nThe model first generates the firstNreasonsubscriptùëÅreasonN_{\\text{reason}}italic_N start_POSTSUBSCRIPT reason end_POSTSUBSCRIPTCoT reasoning tokens,NtextsubscriptùëÅtextN_{\\text{text}}italic_N start_POSTSUBSCRIPT text end_POSTSUBSCRIPTtext tokens, andNspeechsubscriptùëÅspeechN_{\\text{speech}}italic_N start_POSTSUBSCRIPT speech end_POSTSUBSCRIPTspeech tokens.\nOnce the firstNspeechsubscriptùëÅspeechN_{\\text{speech}}italic_N start_POSTSUBSCRIPT speech end_POSTSUBSCRIPTspeech tokens are generated, the speech decoder synthesizes the output audio that laststchunksubscriptùë°chunkt_{\\text{chunk}}italic_t start_POSTSUBSCRIPT chunk end_POSTSUBSCRIPTseconds.\nWhen the speech waveform is synthesized and played to the user, the SLM uses this time to generate the nextNreasonsubscriptùëÅreasonN_{\\text{reason}}italic_N start_POSTSUBSCRIPT reason end_POSTSUBSCRIPTreasoning tokens,NtextsubscriptùëÅtextN_{\\text{text}}italic_N start_POSTSUBSCRIPT text end_POSTSUBSCRIPTtext tokens, andNspeechsubscriptùëÅspeechN_{\\text{speech}}italic_N start_POSTSUBSCRIPT speech end_POSTSUBSCRIPTspeech tokens and synthesize the speech output.\nThe durationtchunksubscriptùë°chunkt_{\\text{chunk}}italic_t start_POSTSUBSCRIPT chunk end_POSTSUBSCRIPTis much longer than the time for generating the text tokens and speech tokens corresponding toSisubscriptùëÜùëñS_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and we use the remaining time to generate the reasoning tokens.",
                "position": 102
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method: Simultaneous Thinking and Talking with Chunked Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.15375/x2.png",
                "caption": "Figure 2:Different generation method explored in this paper.\nThe arrow represents the timeline for the SLM to generate the tokens; this timeline shouldnot be confusedwith the timeline that the end user receives the audio, i.e., the upper timeline in Figure1.\nWe plot tokens of the same type in a chunk using the same color.\n(a) GLM-4-Voice: Interleaving between text and speech token chunks (Section2.1).\nThis is the design of the original interleaved SLMs.\n(b) TBS: Generating a complete reasoning span and then interleaving between text and speech token chunks (Section3.1).\n(c)Stitch-R: Alternating between reasoning token chunks, text token chunks, and speech token chunks (Section3.2).\n(d)Stitch-S: Alternating between text token chunks, speech token chunks, and reasoning token chunks (Section3.3).",
                "position": 255
            }
        ]
    },
    {
        "header": "4Experiment Setup",
        "images": []
    },
    {
        "header": "5Main Results",
        "images": []
    },
    {
        "header": "6Adjusting the Length of the Reasoning Chunk During Inference",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.15375/x3.png",
                "caption": "(a)",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2507.15375/x3.png",
                "caption": "(a)",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2507.15375/x4.png",
                "caption": "(b)",
                "position": 828
            },
            {
                "img": "https://arxiv.org/html/2507.15375/x5.png",
                "caption": "(c)",
                "position": 833
            }
        ]
    },
    {
        "header": "7Using Reasoning from Other Models",
        "images": []
    },
    {
        "header": "8Qualitative Results",
        "images": []
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset",
        "images": []
    },
    {
        "header": "Appendix BTraining Details",
        "images": []
    },
    {
        "header": "Appendix CDetailed Latency Calculation",
        "images": []
    },
    {
        "header": "Appendix DUnsuccessful Attempts",
        "images": []
    }
]