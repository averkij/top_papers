[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction & Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23759/extracted/6490694/figures/rebus-dataset-new.png",
                "caption": "Figure 1:Rebus Puzzles: Two example rebus puzzles along with the cognitive skills required to solve them In this short paper, we use a set of 432 hand-created and annotated rebus puzzles to map the capabilities and limitations of VLMs.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Dataset & Metrics",
        "images": []
    },
    {
        "header": "3Results & Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23759/x1.png",
                "caption": "Figure 2:Iterative refinement performance.In general, multiple attempts lead to nominal performance gains.",
                "position": 671
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ACode & Data",
        "images": []
    },
    {
        "header": "Appendix BDetailed Comparisons with related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23759/x2.png",
                "caption": "Figure B.1:Visual comparison between prior work datasets and our probe dataset(REBUS, COLUMBUS, Ours). COLUMBUS is automatically generated, and uses a limited set of figures and puzzle types. REBUS is hand-generated, but visually inconsistent, and requires a significant amount of world knowledge. Our dataset strikes a balance between the two - requiring challenging lateral thinking and visual understanding skills, but retaining a consistent style and simplified structure.",
                "position": 1386
            }
        ]
    },
    {
        "header": "Appendix CIn-Context Learning",
        "images": []
    },
    {
        "header": "Appendix DSkill-Guided Prompting",
        "images": []
    },
    {
        "header": "Appendix EIterative Refinement",
        "images": []
    },
    {
        "header": "Appendix FCaption-Only Performance",
        "images": []
    },
    {
        "header": "Appendix GImage Retrieval",
        "images": []
    },
    {
        "header": "Appendix HEvaluation Method",
        "images": []
    },
    {
        "header": "Appendix IPrompting",
        "images": []
    },
    {
        "header": "Appendix JModels",
        "images": []
    },
    {
        "header": "Appendix KQualitative Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23759/extracted/6490694/figures/qualitative_ex4.png",
                "caption": "Figure K.1:This figure shows qualitative examples for both successful (GPT-O3) and failed (Bottom: Qwen 2.5-VL (7B)/Top: Phi-4) cases of model prediction. Green indicates the correct cases, Red is the failure case.",
                "position": 2418
            }
        ]
    },
    {
        "header": "Appendix LDisclosure of AI Usage",
        "images": []
    }
]