[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/logo.png",
                "caption": "",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/benchmark.png",
                "caption": "Figure 1:Comparison of Model Performance on Reasoning Benchmarks",
                "position": 151
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data",
        "images": []
    },
    {
        "header": "3Reward",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.08311/x1.png",
                "caption": "Figure 2:Method Call And Standard Input/Output test case examples",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/json.png",
                "caption": "Figure 3:Validator Input Example",
                "position": 340
            }
        ]
    },
    {
        "header": "4Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.08311/x2.png",
                "caption": "Figure 4:Instance Level Distribution (left) and Token Level Distribution (right) during SFT. It is worth noting that the proportions are computed over responses, not queries, since a single query can correspond to multiple responses in our training set.",
                "position": 368
            },
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/am_rl_archi_graphs.png",
                "caption": "Figure 5:Detached Rollout and Upgrade with Streaming Load Balancing Architecture",
                "position": 455
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/param_vs_results.jpg",
                "caption": "Figure 6:Performance versus model size on AIME2024 (left) and LiveCodeBench (right).Each point represents a model, with the x-axis indicating model size (in number of parameters) and the y-axis indicating benchmark score.Models closer to the top-left corner achieve better performance with smaller size.",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/sft_loss_curve.png",
                "caption": "Figure 7:Supervised Fine-Tuning (SFT) training loss curves.",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2505.08311/extracted/6434266/generation_len_and_stop_ratio.png",
                "caption": "Figure 8:Variation in Average Generation Length (left) and Average Stop Ratio (right).",
                "position": 777
            }
        ]
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]