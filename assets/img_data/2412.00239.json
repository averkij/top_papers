[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIGenAI Design Patterns",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00239/x1.png",
                "caption": "(a)Task is decomposed into sub-tasks that are executed in parallel. Only the final output is shown to the user.",
                "position": 300
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x1.png",
                "caption": "(a)Task is decomposed into sub-tasks that are executed in parallel. Only the final output is shown to the user.",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x2.png",
                "caption": "(b)Task is decomposed into sequential sub-tasks whose output are shown to the user, so that users can see the result incrementally.",
                "position": 309
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x3.png",
                "caption": "(a)Vanilla RAG where one retrieval takes place per generation.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x3.png",
                "caption": "(a)Vanilla RAG where one retrieval takes place per generation.",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x4.png",
                "caption": "(b)FM decides when to request for environment data based on outputting special tokens, until an end token is reached; also known as adaptive RAG[21].",
                "position": 502
            }
        ]
    },
    {
        "header": "IVWorkflow Generation: A Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.00239/x5.png",
                "caption": "Figure 3:Sample workflow mapping to the user requirementWhen a P1 incident is created, look up the user assigned to the incident and if the user has a manager, send an email reminding them of the incident. Values coming from the system environment are in light green (prefixed by keyvalue).",
                "position": 595
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x6.png",
                "caption": "Figure 4:LabelingcreateFlowsamples involved writing the requirement (in red) given the basic workflow outline.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x7.png",
                "caption": "Figure 5:LabelingpopulateInputssamples involved writing oneannotation(in red) per step where the annotation contains enough detail to generate theinputsvalues (in light green).",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x8.png",
                "caption": "Figure 6:Example of how RAG was used in the training process. Textchoices:in blue is a special token that the FM uses to signal that it wants suggestions from the environment. Here, the retriever module offers four choices for the step name.",
                "position": 697
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x9.png",
                "caption": "Figure 7:System architecture with UI, AI, and data layers.",
                "position": 724
            },
            {
                "img": "https://arxiv.org/html/2412.00239/x10.png",
                "caption": "Figure 8:Tree mapping to the sample workflow in Figure3.",
                "position": 745
            }
        ]
    },
    {
        "header": "VDiscussion",
        "images": []
    },
    {
        "header": "VIConclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]