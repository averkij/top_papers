[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06424/img/dragmesh_logo.png",
                "caption": "",
                "position": 104
            },
            {
                "img": "https://arxiv.org/html/2512.06424/img/15.png",
                "caption": "",
                "position": 120
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06424/x1.png",
                "caption": "Figure 2:Bubble size indicates parameter count (core module only), color denotes generalization capability (Purple: generalizable; Orange: per-object training required). Our method achieves generalization with significantly lower computational cost than existing generalizable approaches.",
                "position": 207
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06424/x2.png",
                "caption": "Figure 3:The DragMesh pipeline fuses point cloud, joint, and drag inputs through a VAE and Transformer architecture to predict a physically-corrected dual quaternion.",
                "position": 230
            },
            {
                "img": "https://arxiv.org/html/2512.06424/x3.png",
                "caption": "Figure 4:The DragMesh Annotation-Free Inference Pipeline. Given a raw mesh and drag, a segmentation model identifies the movable part while a VLM predicts the joint type. Our KPP-Net then regresses the precise axis and origin, enabling the final DragMesh model to generate the Dual Quaternion animation.",
                "position": 443
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Efficiency",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.06424/img/image.png",
                "caption": "Figure 5:Qualitative Comparison. Our method (Ours) generates plausible interactions across all categories. Blank spaces for baselines (e.g., ArtGS, PartRm, DragApart) represent generation failures, where results are omitted due to unrecognizable outlines.",
                "position": 818
            }
        ]
    },
    {
        "header": "8Visualization Results",
        "images": []
    },
    {
        "header": "9Limitations and Future Work",
        "images": []
    }
]