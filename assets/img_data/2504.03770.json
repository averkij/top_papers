[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03770/x1.png",
                "caption": "Figure 1:JailDAMoverview (see §3).(A) Training:We encode safe text and images with CLIP, computing attention scores against a policy-driven unsafe memory bank. An autoencoder learns to reconstruct these features, linking benign inputs to unsafe concepts—without explicit harmful data.(B) Inference:For each new input, we compute attention scores and measure the autoencoder’s reconstruction error; high error indicates potential harm. If similarity to the memory bank is low,JailDAMupdates the least-used concept with a residual representation, adapting to new attacks over time.",
                "position": 537
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03770/x2.png",
                "caption": "Figure 2:The pipeline of concepts and memory bank generation by GPT-4o.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2504.03770/x3.png",
                "caption": "Figure 3:JailDAM-D(see §3.6), an end-to-end jailbreak defense framework",
                "position": 845
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03770/x4.png",
                "caption": "Figure 4:The radar diagrams aboutF1-scoreof 4 attack defense methods on 4 VLMs.JailDAM-Doutperforms other methods in most settings, except on CogVLM-chat with JailBreakV-28K, where Adashield-A(Wang et al.,2024)achieves a perfect score.",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2504.03770/x5.png",
                "caption": "Figure 5:Time cost on model training, detection task inference, and defense task inference. In here,A-S: Adashield-S,A-A: Adashield-A,JG: JailGuard,HD: HiddenDetect,GS: GradSafe,LG: LlavaGuard,VG: VLGuard",
                "position": 1444
            },
            {
                "img": "https://arxiv.org/html/2504.03770/x6.png",
                "caption": "Figure 6:AUROC of detection task on different concept sizes",
                "position": 1465
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Ethics Statement",
        "images": []
    },
    {
        "header": "7Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Related Work",
        "images": []
    },
    {
        "header": "Appendix BSupplementary ofJailDAMandJailDAM-D",
        "images": []
    },
    {
        "header": "Appendix CDetails of Datasets",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03770/x7.png",
                "caption": "Figure 10:The data statistic of test samples from each dataset we use in experiments.",
                "position": 2454
            }
        ]
    },
    {
        "header": "Appendix DDetails of Baseline",
        "images": []
    },
    {
        "header": "Appendix EDetails of Metrics",
        "images": []
    }
]