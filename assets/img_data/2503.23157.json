[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/training_pipeline.png",
                "caption": "Figure 1:Overview of the GRPO-based Text-to-SQL training pipeline. For each natural language prompt q and its associated database schema, the policy modelœÄŒ∏subscriptùúãùúÉ\\pi_{\\theta}italic_œÄ start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPTgenerates a group of candidate SQL queries. Each candidate is evaluated using a suite of reward functions to produce a composite reward. These rewards are then used to compute advantages and update the policy via GRPO.",
                "position": 141
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/rewards_example.png",
                "caption": "Figure 2:Example partial reward calculation for a generated SQL query, illustrating how each reward component, execution accuracy, llm-as-a-judge (AI Feedback), syntax check, schema linking, and n-gram similarity, is derived by comparing the candidate query with the gold (ground truth) query.",
                "position": 191
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/model_at_different_steps.png",
                "caption": "Figure 3:An example illustrating the model‚Äôs improvement in reasoning. By step 200 of training, the model adopts a structured approach to SQL synthesis and correctly identifies the join condition.",
                "position": 623
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/example_output.png",
                "caption": "Figure 4:An example output of our GRPO-trained model.",
                "position": 1642
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/example_output_2.png",
                "caption": "Figure 5:An example output of the model during the training process at step 10 and step 200.",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/pass_K_vs_average_K.png",
                "caption": "Figure 6:Pass@K and average@K performance for the GRPO and SFT trained models on bird development set.",
                "position": 2506
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/schema_linking_reasoning_chars.png",
                "caption": "Figure 7:Length of reasoning segments generated by our GRPO-trained model across queries requiring varying numbers of schema links.",
                "position": 2575
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/token_price.png",
                "caption": "Figure 8:Cost analysis of using our Qwen2.5-coder-14B(all)vs using Gemini-1.5-pro-002 for the SQL generation with CHASE-SQL pipeline across different databases of the BIRD development set.",
                "position": 2584
            },
            {
                "img": "https://arxiv.org/html/2503.23157/extracted/6327461/figures/acc_vs_reasoning.png",
                "caption": "Figure 9:Accuracy and number of reasoning characters of the Qwen2.5-3B(all)model during the first 200 steps of the training.",
                "position": 2595
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]