[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13795/x1.png",
                "caption": "Figure 1:(a) Post-LN layer; (b) Pre-LN layer; (c) Mix-LN layer.",
                "position": 97
            }
        ]
    },
    {
        "header": "2Hypothesis Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13795/x2.png",
                "caption": "Figure 2:Results of open-weight large-scale LLMs.Angular Distance (a, b): Each column represents the angular distance from the initial layer‚Ñì‚Ñì\\ellroman_‚Ñì(x-axis) and its subsequentnt‚Å¢hsuperscriptùëõùë°‚Ñén^{th}italic_n start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPTlayer (y-axis). The distance is scaled to the range [0, 1], where yellow indicates smaller distances and purple indicates larger distances.Performance Drop (c, d): (c): SQuAD v1.1 performance drop of removing each layer from BERT-large; (d): MMLU accuracy drop of removing each layer from LLaMa2-7B.",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2412.13795/x3.png",
                "caption": "Figure 3:Results of in-house small-scale LLaMa-130M.Angular Distance (a, b): Each column represents the angular distance from the initial layer‚Ñì‚Ñì\\ellroman_‚Ñì(x-axis) and its subsequentnt‚Å¢hsuperscriptùëõùë°‚Ñén^{th}italic_n start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPTlayer (y-axis). The distance is scaled to the range [0, 1], where yellow indicates smaller distances and purple indicates larger distances.Performance Drop (c, d): ARC-e performance drop of removing each single layer from LLaMa-130M.Gradient Norm (e): Gradient norm of each layer in LLaMa-130M.",
                "position": 285
            }
        ]
    },
    {
        "header": "3Mix-Layer Normalization (Mix-LN)",
        "images": []
    },
    {
        "header": "4Main Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13795/x4.png",
                "caption": "Figure 4:Training curve (eval perplexity) ofMix-LNand Pre-LN with LLaMa-7B.",
                "position": 392
            }
        ]
    },
    {
        "header": "5Analysis and More Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13795/x5.png",
                "caption": "Figure 5:Angular distance from initial layer‚Ñì‚Ñì\\ellroman_‚Ñì(x-axis) with block sizenùëõnitalic_n(y-axis) of LLaMA-130M.",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2412.13795/x6.png",
                "caption": "(a)Layer gradient norm of LLaMA-250M with various normalization techniques.",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2412.13795/x6.png",
                "caption": "(a)Layer gradient norm of LLaMA-250M with various normalization techniques.",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2412.13795/x7.png",
                "caption": "(b)Performance drop comparison of LLaMA-130M across layers for Pre-LN, Post-LN, and Mix-LN.",
                "position": 637
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Experiments",
        "images": []
    },
    {
        "header": "Appendix BCompatibility to Advanced",
        "images": []
    }
]