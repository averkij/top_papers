[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20259/x1.png",
                "caption": "Figure 1:Evolution of successful jailbreak strategies across iterations in our lifelong safety alignment framework.Left: Strategies that succeed against the initial model𝑴𝟎subscript𝑴0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT.Right: Strategies that succeed against the updated Defender𝑴𝟏subscript𝑴1\\bm{M_{1}}bold_italic_M start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPT. Notably, the dominant strategy category “Fictional Scenarios & Role-Playing” drops from the majority to under 5% in the second iteration, indicating that𝑴𝟏subscript𝑴1\\bm{M_{1}}bold_italic_M start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPTeffectively defends against these attacks through adversarial-play evolution.",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x2.png",
                "caption": "",
                "position": 100
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x3.png",
                "caption": "Figure 2:Lifelong safety alignment framework. In theWarm-Up Stage (Step 1), a powerful LLM𝑴𝒂⁢𝒑⁢𝒊subscript𝑴𝒂𝒑𝒊\\bm{M_{api}}bold_italic_M start_POSTSUBSCRIPT bold_italic_a bold_italic_p bold_italic_i end_POSTSUBSCRIPT(e.g., GPT-4o) is used to analyze jailbreak-related research papers and open-source codes. Key strategies𝒔𝒔\\bm{s}bold_italic_sare extracted and used by the initial Meta-Attacker𝑨𝟎subscript𝑨0\\bm{A_{0}}bold_italic_A start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPTto generate jailbreak questions𝒙𝒙\\bm{x}bold_italic_xtargeting specific goals𝒈𝒈\\bm{g}bold_italic_g. These are submitted to the target model𝑴𝟎subscript𝑴0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT, producing responses𝒚𝒚\\bm{y}bold_italic_y, and forming tuples(𝒔,𝒙,𝒚,𝒈)𝒔𝒙𝒚𝒈\\bm{(s,x,y,g)}bold_( bold_italic_s bold_, bold_italic_x bold_, bold_italic_y bold_, bold_italic_g bold_)that are categorized into success buffer𝑩𝒔subscript𝑩𝒔\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTor failure buffer𝑩𝒇subscript𝑩𝒇\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPT. In theLifelong Safety Alignment Stage (Steps 2–4), the Meta-Attacker and Defender co-evolve through iterative interaction. The Meta-Attacker learns from failed cases in𝑩𝒇subscript𝑩𝒇\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPTand generates new attack strategies and questions, which are again evaluated against𝑴𝟎subscript𝑴0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT. A safeguard model𝑴𝒋subscript𝑴𝒋\\bm{M_{j}}bold_italic_M start_POSTSUBSCRIPT bold_italic_j end_POSTSUBSCRIPTassesses the responses and updates the buffers𝑩𝒔subscript𝑩𝒔\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTand𝑩𝒇subscript𝑩𝒇\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPTaccordingly. Successful tuples in𝑩𝒔subscript𝑩𝒔\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTare used to further evolve the Meta-Attacker via beam search[14]and Reject Fine-Tuning[13,61], forming an iterativeAdversarial-Play Evolution Loop. This loop continues until one of two conditions is met: (1) the goal success rate exceeds a threshold𝑲𝑲\\bm{K}bold_italic_K, or (2) the maximum number of iterations𝑵𝑵\\bm{N}bold_italic_Nis reached. At the end of each loop, the Defender𝑴𝟎subscript𝑴0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPTis updated through refusal training using successful attack cases in𝑩𝒔subscript𝑩𝒔\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTand refusal outputs from the refusal model𝑴𝒓subscript𝑴𝒓\\bm{M_{r}}bold_italic_M start_POSTSUBSCRIPT bold_italic_r end_POSTSUBSCRIPT.",
                "position": 112
            }
        ]
    },
    {
        "header": "2A Lifelong Safety Alignment Framework",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BLimitations",
        "images": []
    },
    {
        "header": "Appendix CExperiments",
        "images": []
    },
    {
        "header": "Appendix DUsed Prompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20259/x4.png",
                "caption": "Figure 3:The extracted strategy from CodeAttack[39]by the API model GPT-4o.",
                "position": 3078
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x5.png",
                "caption": "Figure 4:The extracted strategy from Random Augment Attack[48]by the API model GPT-4o.",
                "position": 3081
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x6.png",
                "caption": "Figure 5:The extracted strategy from Past Tense Attack[1]by the API model GPT-4o.",
                "position": 3084
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x7.png",
                "caption": "Figure 6:The extracted strategy from Persona Modulation Attack[1]by the API model GPT-4o.",
                "position": 3087
            }
        ]
    },
    {
        "header": "Appendix EStrategy Examples",
        "images": []
    }
]