[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20259/x1.png",
                "caption": "Figure 1:Evolution of successful jailbreak strategies across iterations in our lifelong safety alignment framework.Left: Strategies that succeed against the initial modelğ‘´ğŸsubscriptğ‘´0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT.Right: Strategies that succeed against the updated Defenderğ‘´ğŸsubscriptğ‘´1\\bm{M_{1}}bold_italic_M start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPT. Notably, the dominant strategy category â€œFictional Scenarios & Role-Playingâ€ drops from the majority to under 5% in the second iteration, indicating thatğ‘´ğŸsubscriptğ‘´1\\bm{M_{1}}bold_italic_M start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPTeffectively defends against these attacks through adversarial-play evolution.",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x2.png",
                "caption": "",
                "position": 100
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x3.png",
                "caption": "Figure 2:Lifelong safety alignment framework. In theWarm-Up Stage (Step 1), a powerful LLMğ‘´ğ’‚â¢ğ’‘â¢ğ’Šsubscriptğ‘´ğ’‚ğ’‘ğ’Š\\bm{M_{api}}bold_italic_M start_POSTSUBSCRIPT bold_italic_a bold_italic_p bold_italic_i end_POSTSUBSCRIPT(e.g., GPT-4o) is used to analyze jailbreak-related research papers and open-source codes. Key strategiesğ’”ğ’”\\bm{s}bold_italic_sare extracted and used by the initial Meta-Attackerğ‘¨ğŸsubscriptğ‘¨0\\bm{A_{0}}bold_italic_A start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPTto generate jailbreak questionsğ’™ğ’™\\bm{x}bold_italic_xtargeting specific goalsğ’ˆğ’ˆ\\bm{g}bold_italic_g. These are submitted to the target modelğ‘´ğŸsubscriptğ‘´0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT, producing responsesğ’šğ’š\\bm{y}bold_italic_y, and forming tuples(ğ’”,ğ’™,ğ’š,ğ’ˆ)ğ’”ğ’™ğ’šğ’ˆ\\bm{(s,x,y,g)}bold_( bold_italic_s bold_, bold_italic_x bold_, bold_italic_y bold_, bold_italic_g bold_)that are categorized into success bufferğ‘©ğ’”subscriptğ‘©ğ’”\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTor failure bufferğ‘©ğ’‡subscriptğ‘©ğ’‡\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPT. In theLifelong Safety Alignment Stage (Steps 2â€“4), the Meta-Attacker and Defender co-evolve through iterative interaction. The Meta-Attacker learns from failed cases inğ‘©ğ’‡subscriptğ‘©ğ’‡\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPTand generates new attack strategies and questions, which are again evaluated againstğ‘´ğŸsubscriptğ‘´0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPT. A safeguard modelğ‘´ğ’‹subscriptğ‘´ğ’‹\\bm{M_{j}}bold_italic_M start_POSTSUBSCRIPT bold_italic_j end_POSTSUBSCRIPTassesses the responses and updates the buffersğ‘©ğ’”subscriptğ‘©ğ’”\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTandğ‘©ğ’‡subscriptğ‘©ğ’‡\\bm{B_{f}}bold_italic_B start_POSTSUBSCRIPT bold_italic_f end_POSTSUBSCRIPTaccordingly. Successful tuples inğ‘©ğ’”subscriptğ‘©ğ’”\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTare used to further evolve the Meta-Attacker via beam search[14]and Reject Fine-Tuning[13,61], forming an iterativeAdversarial-Play Evolution Loop. This loop continues until one of two conditions is met: (1) the goal success rate exceeds a thresholdğ‘²ğ‘²\\bm{K}bold_italic_K, or (2) the maximum number of iterationsğ‘µğ‘µ\\bm{N}bold_italic_Nis reached. At the end of each loop, the Defenderğ‘´ğŸsubscriptğ‘´0\\bm{M_{0}}bold_italic_M start_POSTSUBSCRIPT bold_0 end_POSTSUBSCRIPTis updated through refusal training using successful attack cases inğ‘©ğ’”subscriptğ‘©ğ’”\\bm{B_{s}}bold_italic_B start_POSTSUBSCRIPT bold_italic_s end_POSTSUBSCRIPTand refusal outputs from the refusal modelğ‘´ğ’“subscriptğ‘´ğ’“\\bm{M_{r}}bold_italic_M start_POSTSUBSCRIPT bold_italic_r end_POSTSUBSCRIPT.",
                "position": 112
            }
        ]
    },
    {
        "header": "2A Lifelong Safety Alignment Framework",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotation",
        "images": []
    },
    {
        "header": "Appendix BLimitations",
        "images": []
    },
    {
        "header": "Appendix CExperiments",
        "images": []
    },
    {
        "header": "Appendix DUsed Prompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20259/x4.png",
                "caption": "Figure 3:The extracted strategy from CodeAttack[39]by the API model GPT-4o.",
                "position": 3078
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x5.png",
                "caption": "Figure 4:The extracted strategy from Random Augment Attack[48]by the API model GPT-4o.",
                "position": 3081
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x6.png",
                "caption": "Figure 5:The extracted strategy from Past Tense Attack[1]by the API model GPT-4o.",
                "position": 3084
            },
            {
                "img": "https://arxiv.org/html/2505.20259/x7.png",
                "caption": "Figure 6:The extracted strategy from Persona Modulation Attack[1]by the API model GPT-4o.",
                "position": 3087
            }
        ]
    },
    {
        "header": "Appendix EStrategy Examples",
        "images": []
    }
]