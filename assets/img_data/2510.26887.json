[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2AI multi-agent systems",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26887/figures/AI_system2.png",
                "caption": "Figure 1:This cartoon shows the different components ofDenarioand their interplay. The system is shown as an orange circle, and it takes some input text and data (left side), and can generate one or several outputs (red icons on the right). The system is composed of different modules (yellow shapes), which can exchange messages among them (blue arrows outside modules). The modules are composed of multiple agents (bots icons), that can communicate with each other (blue arrows inside modules).",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2510.26887/x1.png",
                "caption": "Figure 2:Planning & Controlimplementation of “Deep Research” fromCmbagent. This is the essential orchestration strategy enabling the research analysis without human-in-the-loop. Additionally, it can be used for idea generation, method generation and data pre-processing.",
                "position": 461
            }
        ]
    },
    {
        "header": "3Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26887/x2.png",
                "caption": "Figure 3:This scheme shows the architecture ofDenario. The green hexagons represent the different modules inDenario. These modules are agentic systems that can 1) generate an idea for a research project, 2) check the literature to validate the novelty of the idea, 3) develop a plan to carry out the project, 4) implement the plan by writing and executing code, making plots, and describing the results, 5) write a scientific paper discussing the research and showing the plots, and 6) review the paper. Orange arrows indicate the input to the modules, while the green arrows show the output of them. The output of the modules are shown in the blue boxes. For details about the output, see Table1. At the top, in magenta, there is the input description, where the user describes the data, postulates the problem… etc.\nWe note thatDenariois fully modular, and human input can be added at any point. For instance,Denariocan be run as a standalone program and generate a paper from the input text file (by running the idea, methods, analysis, and paper modules sequentially), or can also be used as a standalone tool to create plots and results from an input text, idea, and methods provided by the user.",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2510.26887/figures/idea_den.png",
                "caption": "Figure 4:The Idea module is a propose-critique block consisting of two agents:idea_makerandidea_hater. The system first calls theidea_makeragent, that will generate an idea given the input text. Next, the idea is sent to theidea_hater, who will critique the generated idea. Theidea_makerwill then take the input text, the generated idea, and the critique and will improve the idea. This process is then repeated several times until the final idea is generated.",
                "position": 715
            },
            {
                "img": "https://arxiv.org/html/2510.26887/figures/literature2.png",
                "caption": "Figure 5:This diagram shows the semantic scholar implementation of the literature module. The module takes as input the input text and the idea. These files are then passed to anovelty agentwhose task is to determine if the idea is new or not. This agent can output 1) idea new, 2) idea not new, or 3) query. The agent will choose the later if it does not enough information to make a yes/no decision. In that case, it will generate a query that will be sent to thesemantic scholar agentwho will search the literature with it. This agent will then retrieve a series of papers (including titles and abstracts) and will send this information back to thenovelty agent. This process is repeated several times until the relevant literature is well sampled. If no relevant papers are found after a number of iterations, the novelty agent will conclude that the idea is new. Once thenovelty agenthas determined that the idea is new/not new, all the papers found, the queries, and the responses will be sent to asummary agentthat will write a report stating why the idea is new (or not new) and the most relevant papers.",
                "position": 863
            },
            {
                "img": "https://arxiv.org/html/2510.26887/figures/method.png",
                "caption": "Figure 6:The methods module.",
                "position": 889
            },
            {
                "img": "https://arxiv.org/html/2510.26887/figures/DenarioWritingModule.png",
                "caption": "Figure 7:This scheme shows the workflow of the paper writing module. Each node represents an agent (or a group of agents) in charge of a task. The preprocess agent is in charge of reading the input files and performing some basic operations, such as identifying duplicated plots. Later, a series of agents will identify keywords and write different sections of the paper draft. Next, an agent will process the plots, generating captions for them and outputting a preliminary version of the paper draft. Next, an agent will refine the results section to improve references to the plots and to polish the writing on it, generating a second version of the paper draft. Next, an agent will place citations in different sections of the paper, producing a third and fourth final version of the paper draft.",
                "position": 1089
            },
            {
                "img": "https://arxiv.org/html/2510.26887/figures/reviewer2.png",
                "caption": "Figure 8:This diagram shows how the reviewer module works. The input to the module is the input text together with the PDF of the document to be reviewed. The first step is to transform the pdf document into png images; each image corresponds to a different page of the paper. Next, the images and the input text are passed to a reviewer agent in charge of understanding and evaluating the document. The outcome of the agent is a report with the positive and negative aspects of the document.",
                "position": 1145
            }
        ]
    },
    {
        "header": "4Usage",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26887/figures/GUI.png",
                "caption": "Figure 9:This figure shows the Graphical User Interface (GUI) ofDenario. In the upper-left part, the user can set the API keys for the LLMs. Below that part, the user can upload data and download the files generated byDenario. In the central part, the user can choose which module to run and can tune the options available for it (e.g. LLM model). If the user wants to perform end-to-end research, she/he will have to run the different modules sequentially.",
                "position": 1359
            }
        ]
    },
    {
        "header": "5End-to-end research examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26887/figures/Materials_Science_Performance_Heatmap.png",
                "caption": "Figure 10:Performance heatmap showingDenario’s scores across 10 prompts and 4 evaluation metrics for materials science performance evaluation task. Darker blue indicates better performance (score of 3), while lighter colors indicate partial or limited performance. The heatmap reveals perfect context understanding (leftmost column) but declining performance in methods, insights, and novel analysis. Prompt 1-10 represent increasing level of specificity and higher levels of guidance. Prompts 4 and 8 resulted in complete system failures despite seemingly straightforward queries.",
                "position": 3788
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26887/figures/Expert_Evaluation.png",
                "caption": "Figure 11:We have assigned each of the papers in the Appendix to a domain expert for evaluation. Each expert, knowing that these are AI-generated papers, was tasked with providing a numerical score to quantify the quality of the paper, from 0 (really bad paper) to 10 (really good paper). This graph shows the distribution of the scores. As can be seen, while some papers are ranked below average, most papers are above average, and some of them were highly ranked.",
                "position": 4558
            }
        ]
    },
    {
        "header": "7Ethical implications and scientific challenges",
        "images": []
    },
    {
        "header": "8Summary and Conclusions",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExample papers",
        "images": []
    }
]