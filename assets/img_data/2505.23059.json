[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23059/x1.png",
                "caption": "Figure 1:Conceptual comparison between standard CoT reasoning, compressed CoT reasoning, and our proposed SMR framework. (a) Standard CoT performs token-level generation in a single forward pass, often leading to redundant intermediate states. (b) Compressed CoT shortens trajectories via reinforcement learning, at the risk of misaligned outputs. (c) SMR decomposes reasoning into structured state transitions(q,D)ùëûùê∑(q,D)( italic_q , italic_D )guided by IR-specific actions.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23059/x2.png",
                "caption": "Figure 2:Illustration of our proposed reasoning framework (SMR). Beginning from an initial query and its retrieved documents, SMR transitions through structured states via three actions:Refine(query rewriting),Rerank(document reordering), andStop(termination). At each step, the LLM selects an action with justification, and the document list is updated accordingly.",
                "position": 293
            }
        ]
    },
    {
        "header": "4Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23059/x3.png",
                "caption": "Figure 3:Distribution of reasoning actions selected by SMR on the BRIGHT benchmark.Redbars indicate the proportion ofRefineactions, andbluebars indicateRerankactions.",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2505.23059/x4.png",
                "caption": "Figure 4:Inference token usage across five representative datasets in the BRIGHT benchmark. SMR (greenbars) achieves significantly lower token consumption than Rank1, Rank-R1, and O1-Pruner, while improving retrieval performance. Full results including all datasets are presented in AppendixA.8.",
                "position": 822
            },
            {
                "img": "https://arxiv.org/html/2505.23059/x5.png",
                "caption": "Figure 5:Transition statistics of SMR on the BRIGHT benchmark. Thebluebars indicate the number of reasoning steps across all queries, computed cumulatively per transition depth. Theredcurve shows the average retrieval performance (nDCG@10) at each step.",
                "position": 841
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]