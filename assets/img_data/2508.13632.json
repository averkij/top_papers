[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/x1.png",
                "caption": "Figure 1:Try-on results of various wearable objects generated byOmniTry, which supports object images with white or natural backgrounds, and even try-on results as input.",
                "position": 121
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/x2.png",
                "caption": "Figure 2:The two-staged training pipeline ofOmniTry.The first stage is built on in-the-wild portrait images to add wearable object onto the person in mask-free manner. The second stage introduces in-shop paired images, and targets to control the consistency of object appearance.",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2508.13632/x3.png",
                "caption": "Figure 3:Study on traceless erasing.(a) Shortcuts learned by model with naive erasing, where the model recovers the same shape and position as the ground-truth.\n(b) The pipeline of traceless erasing, where image-to-image model is introduced to disturb the traces (indicated in the red boxes).",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2508.13632/x4.png",
                "caption": "Figure 4:Qualitative comparisonamongOmniTryand existing methods on multiple objects.",
                "position": 339
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/x5.png",
                "caption": "Figure 5:Ablation study on the two-staged training framework infew-shot settings. We show the evaluation metrics given varying amounts of paired training samples.",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2508.13632/x6.png",
                "caption": "Figure 6:Try-on results ofOmniTryfine-tuned on uncommon classes of wearable or holdable objects.",
                "position": 741
            }
        ]
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Benchmark and Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/x7.png",
                "caption": "Figure 7:The visualization of theOmniTry-Benchconstitution.",
                "position": 1695
            }
        ]
    },
    {
        "header": "Appendix BDetails of Training Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/figures/data_distribution.png",
                "caption": "Figure 8:The class distribution of training dataset.",
                "position": 1857
            }
        ]
    },
    {
        "header": "Appendix CDetails of Training and Model Architecture",
        "images": []
    },
    {
        "header": "Appendix DDetails of Compared Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13632/x8.png",
                "caption": "Figure 9:The samples of the model, the object, and the try-on person.",
                "position": 2352
            }
        ]
    },
    {
        "header": "Appendix EMore Visualization Results",
        "images": []
    }
]