[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x1.png",
                "caption": "",
                "position": 98
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/fox_in.jpg",
                "caption": "Figure 2:Existing methods often miss key features in voxelization.While IN2N[haque2023instruct], Vox-E[sella2023vox], and Blender (Geometry Nodes) generate outputs that are coarse, blurry, or semantically inconsistent, they frequently lose critical elements such as facial features. In contrast, our method preserves structural details and produces visually appealing voxel art with sharp abstraction.",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/fox_in2n.jpg",
                "caption": "",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/fox_ours.jpg",
                "caption": "",
                "position": 121
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/bear_in.jpg",
                "caption": "",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/bear_voxe.jpg",
                "caption": "",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/bear_ours.jpg",
                "caption": "",
                "position": 133
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/alien_in.jpg",
                "caption": "",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/alien_blender.jpg",
                "caption": "",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2512.07834/figs/motivation/alien_ours.jpg",
                "caption": "",
                "position": 145
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x2.png",
                "caption": "Figure 3:Our two-stage voxel art generation pipeline.(a)Coarse voxel grid training:Given a 3D mesh, we render multi-view images and optimize a voxel-based radiance field (DVGO[sun2022direct]) using MSE loss to learn coarse RGB and density.\n(b)Orthographic pixel art fine-tuning:We refine the voxel grid using six orthographic pixel art views, which also serve to extract a discrete color palette (e.g., via k-means). Optimization includes appearance, depth, and alpha losses.\n(c)CLIP-guided optimization:A CLIP loss computed over rendered patches and mesh images encourages semantic alignment while being memory-efficient.\n(d)Differentiable discrete color selection via Gumbel-Softmax:Each voxel stores palette logits. Gumbel-Softmax enables differentiable sampling for end-to-end color optimization, yielding coherent, stylized voxel art.",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x3.png",
                "caption": "Figure 4:Perspective vs. Orthographic.(Left) Six-view pixel art pipeline. (Right) Perspective views (red) misalign pixels, while six orthographic views (green) enable precise pixel–voxel alignment.",
                "position": 282
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x4.png",
                "caption": "Figure 5:Qualitative comparisons on character models from the Rodin[wang2022rodin]dataset.We compare our voxel art results with Pixel art to 3D extension, IN2N[haque2023instruct], Vox-E[sella2023vox], and Blender’s voxelization. Our method produces stylized yet consistent voxel representations with pixel art aesthetics.",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x5.png",
                "caption": "Figure 6:Effect of Palette Selection and Color Count.Each row corresponds to a different palette extraction method: K-means, Max-Min, Median Cut, and Simulated Annealing. Each column shows increasing color counts (2, 3, 4, 8). Each method produces unique color clustering effects.",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x6.png",
                "caption": "Figure 7:Ablation study on model components.We show outputs after removing key modules: pixel art supervision, orthographic projection, grid initialization, depth loss, CLIP loss, and Gumbel Softmax. Each row shows a different input; columns compare ablations. The full model yields coherent stylization, while removals cause distortions, color artifacts, or semantic loss.",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x7.png",
                "caption": "Figure 8:Fabrication: LEGO render.Rendered using KeyShot 2023. Our method extends to LEGO applications, where achieving rich visual results within the limited color palette is crucial for practical fabrication.",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x8.png",
                "caption": "Figure 9:Ablation user study of Gumbel.Four representative examples comparing results with and without Gumbel-Softmax. Without Gumbel-Softmax, voxel colors become blurred and features less distinct.",
                "position": 689
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x9.png",
                "caption": "Figure 10:Downsample vs. Pixel Art",
                "position": 754
            }
        ]
    },
    {
        "header": "Appendix CExperimental Information",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x10.png",
                "caption": "Figure 11:Greyscale examples.",
                "position": 1010
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x11.png",
                "caption": "Figure 12:User study UI.",
                "position": 1051
            }
        ]
    },
    {
        "header": "Appendix DAdditional Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07834/x12.png",
                "caption": "Figure 13:Additional qualitative comparisons with baselines.Eight representative examples compared with Pixel, IN2N, Vox-E, and Blender Geometry Nodes.",
                "position": 1094
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x13.png",
                "caption": "Figure 14:Results with varying palette settings.Examples using different palette extraction strategies and palette sizes.",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x14.png",
                "caption": "Figure 15:Results under different voxel sizes.",
                "position": 1110
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x15.png",
                "caption": "Figure 16:Comparison with Gemini 3[google_gemini].\nWhile Gemini 3 can generate voxel art through code, it lacks precise control over resolution, palette, and visual fidelity to input references.",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x16.png",
                "caption": "Figure 17:Comparison with Rodin[wang2022rodin].\nRodin excels at image-to-mesh but is not tailored for voxel art, often yielding non-voxel outputs (right) or flat geometry (left).",
                "position": 1117
            },
            {
                "img": "https://arxiv.org/html/2512.07834/x17.png",
                "caption": "Figure 18:Representative failure cases.Complex shapes with fine-grained geometric details are difficult to represent under limited voxel resolution, resulting in loss of intricate structures.",
                "position": 1121
            }
        ]
    },
    {
        "header": "Appendix EFailure cases and analysis",
        "images": []
    }
]