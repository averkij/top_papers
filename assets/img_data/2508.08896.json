[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08896/x1.png",
                "caption": "Figure 1:Performance comparision among UniDexGrasp(Xu et al.2023), UniDexGrasp++(Wan et al.2023), and our AffordDex, on the vision-based setting. we report human-likeness score (HLS) and affordance score (AS) across seen objects, unseen objects, and unseen categories. We also present a qualitative comparison, where AffordDex performs natural and safe grasping by avoiding the blade.",
                "position": 93
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08896/x2.png",
                "caption": "Figure 2:Pipeline of AffordDex. To generate grasps with affordance-aware positioning and human-like kinematics, crucial for facilitating downstream manipulation, we propose a novel two-stage framework. The first stage establishes a strong human motion prior by training a base policyπH\\pi^{H}, on a human motion dataset via imitation learning. This constrains the policy to a space of natural, human-like movements. Subsequently, the second stage employs reinforcement learning (RL) to refine this coarse policyπH\\pi^{H}for precise, functional interaction. We fine-tuneπH\\pi^{H}with a residual module that is guided by our Negative Affordance-aware Segmentation (NAA) module, which provides explicit constraints on where not to touch the object. The entire learning pipeline is further enhanced by a teacher-student distillation framework, leveraging privileged inputs to significantly boost the final grasping performance.",
                "position": 142
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08896/x3.png",
                "caption": "Figure 3:Visualizationof Negative Affordances Predicted by our NAA. The point cloud, highlighted in red, represents the negative affordances identified on various objects. These points denote regions that are functionally unsafe or inappropriate for grasping, such as a knife’s blade.",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2508.08896/x4.png",
                "caption": "Figure 4:Qualitative Comparisonon UniDexGrasp(Xu et al.2023)and OakiInk2(Zhan et al.2024). A comparison of grasps generated by our AffordDex with several baselines, including UniDexGrasp(Xu et al.2023), UniDexGrasp++(Wan et al.2023), and DexGrasp Anything(Zhong et al.2025).",
                "position": 236
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08896/x5.png",
                "caption": "Figure 5:Ablation Studyon Human Hand Trajectory Imitating (HTI). Without the human motion prior, the policy converges to a solution that, while potentially successful, is kinematically awkward and non-humanlike.",
                "position": 744
            },
            {
                "img": "https://arxiv.org/html/2508.08896/x6.png",
                "caption": "Figure 6:Ablation Studyon proposed NAA, which guides the policy to a correct and safte position. The higher Affordance Score (A​SAS) for the NAA-guided grasp confirms its superior functional quality.",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2508.08896/x7.png",
                "caption": "Figure 7:Ablation Studyon proposed NAA, which has capability to segment fine-grained negative affordance.",
                "position": 750
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Details about Our Method",
        "images": []
    },
    {
        "header": "7Details about Baselines",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.08896/x8.png",
                "caption": "Figure 8:Illustration of the simulation environment.",
                "position": 1479
            }
        ]
    },
    {
        "header": "8Experiment Details",
        "images": []
    }
]