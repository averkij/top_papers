[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12152/x1.png",
                "caption": "",
                "position": 140
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12152/x2.png",
                "caption": "Figure 2:HumanUPsystem overview.\nOur getting-up policy (SectionIII-A) is trained in simulation using two-stage RL training, after which it is directly deployed in the real world.\n(a) Stage I (SectionIII-B1) learns a discovery policyfùëìfitalic_fthat figures out a getting-up trajectory with minimal deployment constraints.\n(b) Stage II (SectionIII-B2) converts the trajectory discovered by Stage I into a policyœÄùúã\\piitalic_œÄthat is deployable, robust, and generalizable. This policyœÄùúã\\piitalic_œÄis trained by learning to track a slowed down version of the discovered trajectory under strong control regularization on varied terrains and from varied initial poses.\n(c) The two-stage training induces a curriculum (SectionIII-C). Stage I targets motion discovery in easier settings (simpler collision geometry, same starting poses, weak regularization, no variations in terrain), while Stage II solves the task of making the learned motion deployable and generalizable.",
                "position": 256
            }
        ]
    },
    {
        "header": "IIIHumanUP: Sim-to-Real Humanoid Getting Up",
        "images": []
    },
    {
        "header": "IVImplementation Details",
        "images": []
    },
    {
        "header": "VSimulation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12152/x3.png",
                "caption": "Figure 3:Real-world results. We evaluateHumanUP(ours) in several real-world setups that span diverse surface properties, including both man-made and natural surfaces, and cover a wide range of roughness (rough concrete to slippery snow), bumpiness (flat concrete to tiles), ground compliance (completely firm concrete to being swampy muddy grass), and slope (flat to about10‚àòsuperscript1010^{\\circ}10 start_POSTSUPERSCRIPT ‚àò end_POSTSUPERSCRIPT). We compareHumanUPwith G1‚Äôs built-in getting-up controller and ourHumanUPw/o posture randomization (PR).HumanUPsucceeds more consistently (78.3% vs 41.7%) and can solve terrains that the G1‚Äôs controller can‚Äôt.",
                "position": 839
            },
            {
                "img": "https://arxiv.org/html/2502.12152/x4.png",
                "caption": "Figure 4:Learning curve.\n(a) Termination height of the torso, indicating whether the robot can lift the body.\n(b) Body uprightness, computed as the projected gravity on thezùëßzitalic_z-axis, normalized to[0,1]01[0,1][ 0 , 1 ]for better comparison.\nThe overall number of simulation sampling steps is about 5B, normalized to[0,1]01[0,1][ 0 , 1 ].",
                "position": 879
            },
            {
                "img": "https://arxiv.org/html/2502.12152/x5.png",
                "caption": "Figure 5:Getting up comparison with G1 controller.\nG1 controller uses a handcrafted motion trajectory, which can be divided into three phases, while ourHumanUPlearns a continuous and more efficient whole-body getting-up motion.\nOurHumanUPenables the humanoid to get up within 6 seconds, half of the G1 controller‚Äôs 11 seconds of control.\n(a), (b), and (c) record the corresponding mean motor temperature of the upper body, lower body, and waist, respectively. G1‚Äôs default controller‚Äôs execution causes the arm motors to heat up significantly, whereas our policy makes more use of the leg motors that are larger (higher torque limit of 83N as opposed to 25N for the arm motors) and thus able to take more load.",
                "position": 886
            },
            {
                "img": "https://arxiv.org/html/2502.12152/x6.png",
                "caption": "Figure 6:Qualitative examples of failure modes on grass slope and snow field.G1 controller isn‚Äôt able to squat on the sloping grass and slips on the slow.HumanUPpolicy is able to partially get up on both the slope and the snow but falls due to unstable feet placement on the slope and slippage on the snow.",
                "position": 893
            }
        ]
    },
    {
        "header": "VIReal World Results",
        "images": []
    },
    {
        "header": "VIILimitations",
        "images": []
    },
    {
        "header": "VIIIDiscussion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12152/x7.png",
                "caption": "Figure 7:Getting-up from prone pose result visualization ofTao et¬†al. [65].\nThe motion generated by method[65]is highly unstable and unsafe, and it keeps jittering and jumping during the getting-up phase.",
                "position": 2020
            }
        ]
    },
    {
        "header": "Appendix AMaterial Statements",
        "images": []
    },
    {
        "header": "Rewards",
        "images": []
    },
    {
        "header": "Training Details",
        "images": []
    },
    {
        "header": "Additional Qualitative Simulation Baseline Results",
        "images": []
    }
]