[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Gym Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19736/figures/main.png",
                "caption": "Figure 1:The UserRL framework: Applying the standardized interact tool as interface, the policy model interacts with multiple Gym environments in the multi-turn rollout, generating groups of trajectories with turn-level rewards. A custom reward calculator remaps each trajectory into (i) a single trajectory-level score for advantage estimation and (ii) turn-level rewards, which are scaled and integrated to produce the final token-level advantages for policy updates.",
                "position": 268
            }
        ]
    },
    {
        "header": "4UserRL Exploration",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Discussions",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AGym Construction Details",
        "images": []
    },
    {
        "header": "Appendix BTraining Experiment Details",
        "images": []
    },
    {
        "header": "Appendix CAnalysis Details",
        "images": []
    }
]