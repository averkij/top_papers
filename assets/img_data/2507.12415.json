[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12415/x1.png",
                "caption": "Figure 1:The workflow of our SWE-Perf benchmark which evaluates code performance optimization capabilities of language models. The benchmark evaluates language models by providing source code and performance-related tests, challenging them to generate optimized patches. Model performance is evaluated by the runtime gains on the tests, with expert performance as reference.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SWE-Perf Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12415/x2.png",
                "caption": "Figure 2:The data collection pipeline of our SWE-Perf benchmark. The pipeline consists of: (1) collecting pull requests from popular repositories, (2) measuring performance of original and modified codebases using unit tests, (3) identifying performance-optimizing pull requests, (4) verifying stable performance improvements through statistical testing, and (5) extracting optimization targets for both oracle and realistic settings.",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x3.png",
                "caption": "Figure 3:Distribution of SWE-Perf across 9 open source popular GitHub repositories.",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x3.png",
                "caption": "Figure 3:Distribution of SWE-Perf across 9 open source popular GitHub repositories.",
                "position": 539
            }
        ]
    },
    {
        "header": "4Evaluation Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12415/x4.png",
                "caption": "Figure 4:Performance for different methods across the 9 repositories represented in SWE-Perf. The base model used in the Oracle setting is Claude-3.7-sonnet.",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x5.png",
                "caption": "Figure 5:Performance for correct examples. The expert performance calculated using only correct examples from the corresponding method. The base model in the Oracle setting is Claude-3.7.",
                "position": 835
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x6.png",
                "caption": "Figure 6:Performance for correct examples. The expert performance calculated using only correct examples from the corresponding method.",
                "position": 838
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x7.png",
                "caption": "Figure 7:Performance variation relative to the number of Oracle target functions. The base model in the Oracle setting is Claude-3.7-sonnet.",
                "position": 857
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x7.png",
                "caption": "Figure 7:Performance variation relative to the number of Oracle target functions. The base model in the Oracle setting is Claude-3.7-sonnet.",
                "position": 859
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x8.png",
                "caption": "Figure 8:Performance variation relative to the number of Realistic target functions.",
                "position": 863
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x9.png",
                "caption": "Figure 9:Performance variation relative to the runtime of the original codebase. The base model in the Oracle setting is Claude-3.7-sonnet.",
                "position": 886
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x10.png",
                "caption": "Figure 10:Word cloud of lines added in OpenHands patches.",
                "position": 911
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x10.png",
                "caption": "Figure 10:Word cloud of lines added in OpenHands patches.",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x11.png",
                "caption": "Figure 11:Word cloud of lines added in Expert patches.",
                "position": 917
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Safeguards:",
        "images": []
    },
    {
        "header": "Appendix BData Collections",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.12415/x12.png",
                "caption": "Figure 12:Word cloud of lines added in Agentless patches.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x12.png",
                "caption": "Figure 12:Word cloud of lines added in Agentless patches.",
                "position": 2154
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x13.png",
                "caption": "Figure 13:Word cloud of lines added in Oracle(Claude-3.7) patches.",
                "position": 2158
            },
            {
                "img": "https://arxiv.org/html/2507.12415/x14.png",
                "caption": "Figure 14:Oracle prompt.",
                "position": 2164
            }
        ]
    },
    {
        "header": "Appendix CBaselines",
        "images": []
    }
]