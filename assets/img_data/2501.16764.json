[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.16764/x1.png",
                "caption": "Figure 1:Comparison with Previous 3D Diffusion Generative Models. (1) Native 3D methods and (2) rendering-based methods encounter challenges in training 3D diffusion models from scratch with limited 3D data. (3) Reconstruction-based methods struggle with inconsistencies in generated multi-view images. In contrast, (4)DiffSplatleverages pretrained image diffusion models for the direct 3DGS generation, effectively utilizing 2D diffusion priors and maintaining 3D consistency. “GT” refers to ground-truth samples in a 3D representation used for diffusion loss computation.",
                "position": 183
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.16764/x2.png",
                "caption": "Figure 2:Method Overview.\n(1) A lightweight reconstruction model provides high-quality structured representation for “pseudo” dataset curation. (2) Image VAE is fine-tuned to encode Gaussian splat properties into a shared latent space. (3)DiffSplatis natively capable of generating 3D contents by image and text conditions utilizing 2D priors from text-to-image diffusion models.",
                "position": 227
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.16764/x3.png",
                "caption": "Figure 3:Qualitative Results and Comparisons on Text-conditioned 3D Generation. More visualizations ofDiffSplatresults are provided in Appendix Figure9,10and11.",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x4.png",
                "caption": "Figure 4:Qualitative Results and Comparisons on Image-conditioned 3D Generation. More visualizations ofDiffSplatresults are provided in Appendix Figure12,13and14.",
                "position": 600
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x5.png",
                "caption": "Figure 5:Controllable Generation. ControlNet can seamlessly adapt toDiffSplatfor controllable text-to-3D generation in various formats, such as normal and depth maps, and Canny edges.",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x6.png",
                "caption": "Figure 6:Ablation ofℒrendersubscriptℒrender\\mathcal{L}_{\\text{render}}caligraphic_L start_POSTSUBSCRIPT render end_POSTSUBSCRIPT. Both text- (1st row) and image-conditioned (2nd row)DiffSplatwithℒrendersubscriptℒrender\\mathcal{L}_{\\text{render}}caligraphic_L start_POSTSUBSCRIPT render end_POSTSUBSCRIPTproduces more aesthetic and textured 3D content with fewer translucent floaters.",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x7.png",
                "caption": "Figure 7:Splat Latents Visualization. 3DGS properties are structured in grids. “Decoded GS” shows the splat latents decoded by animagediffusion VAE.",
                "position": 1029
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.16764/x8.png",
                "caption": "Figure 8:Controllable Generation with Multi-modal Conditions.DiffSplatcan effectively utilize both text and image conditions for single-view reconstruction with text understanding.",
                "position": 2331
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x9.png",
                "caption": "Figure 9:More results of text-conditionedDiffSplat.",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x10.png",
                "caption": "Figure 10:More results of text-conditionedDiffSplat.",
                "position": 2338
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x11.png",
                "caption": "Figure 11:More results of text-conditionedDiffSplat.",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x12.png",
                "caption": "Figure 12:More results of image-conditionedDiffSplat.",
                "position": 2344
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x13.png",
                "caption": "Figure 13:More results of image-conditionedDiffSplat.",
                "position": 2347
            },
            {
                "img": "https://arxiv.org/html/2501.16764/x14.png",
                "caption": "Figure 14:More results of image-conditionedDiffSplat.",
                "position": 2350
            }
        ]
    },
    {
        "header": "Appendix BMore Visualization Results",
        "images": []
    }
]