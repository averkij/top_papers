[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16729/figures/intent_laundering_framework_v1.png",
                "caption": "Figure 1:Overview of our intent laundering framework.Without the feedback loop, the framework displays the intent laundering procedure; with the loop, it intent laundering as a jailbreaking technique.\nThe process begins by passing the original malicious request (data point) through the intent launderer to generate an intent-laundered revision. This revision is then used to attack the target model. An LLM judge evaluates the response for safety and practicality.Ifthe response is both unsafe and practical, the attack is considered successful.Otherwise, the revision–regeneration mechanism is triggered, leveraging all previously failed revisions as feedback to generate a new, improved revision. The loop stops when the predefined iteration limit or target success rate is reached.",
                "position": 98
            }
        ]
    },
    {
        "header": "2Empirical Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16729/figures/advbench_standard_and_harmbench_wordcloud_unigrams.png",
                "caption": "(a)Unigrams",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/advbench_standard_and_harmbench_wordcloud_unigrams.png",
                "caption": "(a)Unigrams",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/advbench_standard_and_harmbench_wordcloud_bigrams.png",
                "caption": "(b)Bigrams",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/advbench_standard_and_harmbench_wordcloud_trigrams.png",
                "caption": "(c)Trigrams",
                "position": 193
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/AdvBench_data_dups.png",
                "caption": "Figure 3:Proportion of duplicated versus unique data pointsin the AdvBench and HarmBench datasets across varying similarity thresholds. Each safety dataset is compared to a size-matched GSM8K subset shown below its plot. Both safety datasets exhibit considerably higher duplication rates across most thresholds compared to their GSM8K counterparts. This is striking, as safety datasets are intended to approximate real-world attacks—characterized by being out-of-distribution and well-crafted. In contrast, they show more duplication than a regular non-safety dataset, where such duplication is more acceptable. This is particularly alarming for safety datasets, as it indicates that many data points in these datasets evaluate the model on essentially the same harmful intent in nearly identical contexts (see Figure4for examples), leading to an overestimated evaluation of safety.",
                "position": 216
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/AdvBench_data_dups.png",
                "caption": "",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/HarmBench_standard_data_dups.png",
                "caption": "Figure 3:Proportion of duplicated versus unique data pointsin the AdvBench and HarmBench datasets across varying similarity thresholds. Each safety dataset is compared to a size-matched GSM8K subset shown below its plot. Both safety datasets exhibit considerably higher duplication rates across most thresholds compared to their GSM8K counterparts. This is striking, as safety datasets are intended to approximate real-world attacks—characterized by being out-of-distribution and well-crafted. In contrast, they show more duplication than a regular non-safety dataset, where such duplication is more acceptable. This is particularly alarming for safety datasets, as it indicates that many data points in these datasets evaluate the model on essentially the same harmful intent in nearly identical contexts (see Figure4for examples), leading to an overestimated evaluation of safety.",
                "position": 228
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/GSM8k_520_data_dups.png",
                "caption": "",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/GSM8k_200_data_dups.png",
                "caption": "",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/HarmBench_and_AdvBench_similar_data_points_2_v2.png",
                "caption": "Figure 4:Examples of duplicated data pointsfrom the AdvBench and HarmBench datasets. These examples exhibit two unusual patterns: (1) explicit and repetitive overuse of triggering cues, either inherently (in red, e.g., “chop shops”) or contextually (in orange, e.g., “in detail”), and (2) substantial duplication resulting from this overuse. Each group of duplicates effectively represents a single malicious intent, i.e., a refusal or response to one is sufficient to evaluate the robustness of the model for that intent. As a result, safety evaluations based on these data points can be inflated.",
                "position": 259
            }
        ]
    },
    {
        "header": "3Approach",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAgreement Analysis Between LLM-Based and Human Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16729/figures/example_1_fake_news_new.png",
                "caption": "Figure 5:An actual response (red box) generated by Gemini 3 Pro to an intent-laundered revision (green box) based on a data point from the AdvBench dataset (orange box).The revision uses both connotation neutralization and context transposition to abstract away triggering cues. The model response is partially shown to prevent potential misuse; however, the full response spans several paragraphs and fully enables the original malicious intent. This example is provided strictly for academic safety research. Any misuse is strongly discouraged.",
                "position": 2217
            }
        ]
    },
    {
        "header": "Appendix BExamples of Intent-Laundered Revisions and Model Responses",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16729/figures/example_2_chop_shop_new.png",
                "caption": "Figure 6:An actual response (red box) generated by Claude Sonnet 3.7 to an intent-laundered revision (green box) based on a data point from the HarmBench dataset (orange box).The revision uses both connotation neutralization and context transposition to abstract away triggering cues. The model response is partially shown to prevent potential misuse; however, the full response spans several paragraphs and fully enables the original malicious intent. This example is provided strictly for academic safety research. Any misuse is strongly discouraged.",
                "position": 2227
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/intent_launderer_prompt.png",
                "caption": "Figure 7:Prompt used by the intent launderer to generate revisions.The placeholder is filled with the data point being intent-laundered.",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/intent_launderer_prompt_for_jailbreaking.png",
                "caption": "Figure 8:Prompt used by the intent launderer to generate revisions in the revision–regeneration loop.The placeholders are filled with the previously failed revisions of the data point being intent-laundered, and the data point itself, in top-to-bottom order.",
                "position": 2241
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/criterion_generation_prompt.png",
                "caption": "Figure 9:Prompt used to generate evaluation criteria.The placeholder is filled with the original data point.",
                "position": 2244
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/safety_eval_prompt.png",
                "caption": "Figure 10:Prompt used for safety evaluation of responses to revisions.The placeholders are filled with the evaluation criterion followed by the model response, in top-to-bottom order.",
                "position": 2247
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/practicality_eval_prompt.png",
                "caption": "Figure 11:Prompt used for practicality evaluation of responses to revisions.The placeholders are filled with the evaluation criterion followed by the model response, in top-to-bottom order.",
                "position": 2250
            },
            {
                "img": "https://arxiv.org/html/2602.16729/figures/regular_safety_eval_prompt.png",
                "caption": "Figure 12:Prompt used for regular safety evaluation of responses to the original attacks (data points), where intent laundering isnotapplied. The placeholder is filled with the model response.",
                "position": 2253
            }
        ]
    },
    {
        "header": "Appendix CInput Prompts",
        "images": []
    }
]