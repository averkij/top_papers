[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14302/x1.png",
                "caption": "Figure 1:An example of medical hallucination detection. The detailed prompt used for the hallucination detection task is presented in AppendixK.",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2502.14302/x2.png",
                "caption": "Figure 2:MedHallumedical hallucinated answer generation pipeline. Each question-answer pair from the PubMedQA dataset undergoes the following steps to generate a hallucinated answer: (1)Candidate Generation: Given a question, relevant knowledge, and ground truth answer, the LLM is prompted to generate a hallucinated answer adhering to one of four hallucination types. (2)Grading & Filtering: Generated answers undergoqualityandcorrectnesschecks, being labeled ashard,medium,easy, orfailedbased on filtering results. (3)Refining Failed Generation: Failed answers are optimized using TextGradYuksekgonul et al. (2024)and re-filtered. If they fail again, the LLM is re-prompted to generate new answers (Regeneration). (4)Fallback: If no qualified answers emerge after four regeneration attempts, the answer most similar to the ground truth is selected as an easy hallucinated example. The detailed prompt used for hallucination generation task is presented in the AppendixK.",
                "position": 171
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MedHallu Benchmark",
        "images": []
    },
    {
        "header": "4Implementation Details",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendices",
        "images": []
    },
    {
        "header": "Appendix AAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix BIncorporating Knowledge into the Analysis of Models’ Denial Capabilities",
        "images": []
    },
    {
        "header": "Appendix CAdditional Data Correctness Check",
        "images": []
    },
    {
        "header": "Appendix DSelecting Medical Hallucination Categories for MedHallu",
        "images": []
    },
    {
        "header": "Appendix EMedHallu Creation Using Other Open-weights LLMs",
        "images": []
    },
    {
        "header": "Appendix FExample Data from the MedHallu Dataset",
        "images": []
    },
    {
        "header": "Appendix GHardware Resources and Computational Costs",
        "images": []
    },
    {
        "header": "Appendix HLLMs Used in Discriminative Tasks",
        "images": []
    },
    {
        "header": "Appendix IAdditional Implementation Details",
        "images": []
    },
    {
        "header": "Appendix JPubMedQA",
        "images": []
    },
    {
        "header": "Appendix KSystem Prompts for Hallucination Generation and Detection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14302/x3.png",
                "caption": "Figure 6:System prompt used to generate MedHallu dataset. The “knowledge” refers to the relevant context of a specific question pair. The PubMedQA dataset provides this “knowledge”.",
                "position": 2544
            },
            {
                "img": "https://arxiv.org/html/2502.14302/x4.png",
                "caption": "Figure 7:System prompt used for the hallucination detection task. The “knowledge” refers to the relevant context of a specific question pair. The PubMedQA dataset provides this “knowledge”.",
                "position": 2547
            }
        ]
    },
    {
        "header": "Appendix LThe Clusters Formed for a Question Using Bidirectional Entailment.",
        "images": []
    }
]