[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/pipeline.png",
                "caption": "Figure 1:Illustrates the sequential steps from data extraction to QSVM evaluation. The process begins with image data extraction, followed by class-balancedkkitalic_k-means clustering to distill representative samples. Vector embeddings are then extracted using ImageNet-pretrained models such as EfficientNet or ViT. To reduce dimensionality and match quantum hardware constraints, PCA is applied to compress the embeddings. These processed embeddings are used to design a Quantum Support Vector Machine (QSVM) using the TNSM framework, which constructs a quantum kernel via a data re-uploading and computeâ€“uncompute strategy. The model is trained and validated through cross-validation, then evaluated on a held-out test set.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/circuit.png",
                "caption": "Figure 2:Quantum circuit used in the QSVM pipeline using Qiskit. Each of the four qubits is initialized with a Hadamard gate, followed by data-encoding rotations using parameterizedRZR_{Z}italic_R start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPTandRYR_{Y}italic_R start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPTgates. A sequence of CNOT gates creates entanglement between adjacent qubits, after which a second layer ofRZR_{Z}italic_R start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPTgates is applied. This structure forms an embedding-aware quantum feature map for encoding classical input features.",
                "position": 219
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/MNIST_violinplot_test_accuracy.png",
                "caption": "Figure 3:Violin plots show the distribution of test accuracy across K-fold cross-validation for MNIST. The width of each violin indicates the density of results; wider sections reflect more frequent accuracy values, helping visualize consistency and variability in model performance.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/FMNIST_violinplot_test_accuracy.png",
                "caption": "Figure 4:Violin plots show the distribution of test accuracy across K-fold cross-validation for FashionMNIST. The width of each violin indicates the density of results; wider sections reflect more frequent accuracy values, helping visualize consistency and variability in model performance.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/Total_Time_vs_Test_Accuracy_mnist.png",
                "caption": "Figure 5:Comparison of total execution time and test accuracy for different QSVM models for MNIST. The x-axis represents the average test accuracy across K-folds, while the y-axis (log scale) shows the total runtime in seconds. Each point corresponds to a model variant, with horizontal and vertical lines indicating the standard deviation of accuracy and time, respectively.",
                "position": 497
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/Total_Time_vs_Test_Accuracy_fmnist.png",
                "caption": "Figure 6:Comparison of total execution time and test accuracy for different QSVM models for FMNIST. The x-axis represents the average test accuracy across K-folds, while the y-axis (log scale) shows the total runtime in seconds. Each point corresponds to a model variant, with horizontal and vertical lines indicating the standard deviation of accuracy and time, respectively.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_fold_mnist.png",
                "caption": "(a)Validation Fold (Best CV Model) for MNIST dataset",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_fold_mnist.png",
                "caption": "(a)Validation Fold (Best CV Model) for MNIST dataset",
                "position": 704
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_test_mnist.png",
                "caption": "(b)Held-out Test Set (Best CV Model) for MNIST dataset",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_fold_fmnist.png",
                "caption": "(a)Validation Fold (Best CV Model) for Fashion MNIST dataset",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_fold_fmnist.png",
                "caption": "(a)Validation Fold (Best CV Model) for Fashion MNIST dataset",
                "position": 723
            },
            {
                "img": "https://arxiv.org/html/2508.00024/imgs/conf_matrix_test_fmnist.png",
                "caption": "(b)Held-out Test Set (Best CV Model) for Fashion MNIST dataset",
                "position": 728
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Data and Code Availability",
        "images": []
    },
    {
        "header": "9Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]