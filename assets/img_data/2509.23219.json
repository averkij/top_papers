[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23219/x1.png",
                "caption": "Figure 1:WirelessMathLM achieves competitive performance through domain-specific GRPO training.(a)Our 7B model (39.5%) approaches GPT-4o (40.4%) on WirelessMathBench-XL while using far fewer parameters than top performers DeepSeek-R1 and GPT-5 (>>57%).(b)GRPO training from base models yields dramatic gains: doubling performance for 3B (+103%) and near-doubling for 7B (+81%), showing that verifiable rewards enable efficient domain specialization.",
                "position": 176
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2WirelessMathBench-XL: Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.23219/x2.png",
                "caption": "Figure 2:Overview of the WirelessMathBench-XL construction pipeline.Starting from  47,000 arXiv papers, GPT-4o filtering identifies 970 papers with substantial mathematical content. DeepSeek-R1 extracts 10-25 formulas per paper, generating multiple-choice questions, progressive fill-in-the-blank (25%-75% masking), and full equation completion problems. Quality assurance employs dual-layer screening: automated GPT-4o evaluation followed by expert validation, with 78% of questions meeting the quality threshold (scoreâ‰¥\\geq3/5).",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2509.23219/x3.png",
                "caption": "Figure 3:Distribution of the top 20 key techniques across the 970 source papers in WirelessMathBench-XL. Deep learning leads with 259 papers (14.0%), followed by convex optimization (206, 11.2%) and MIMO/Massive MIMO (192, 10.4%). The distribution spans from foundational techniques (beamforming, channel coding) to emerging paradigms (RIS/IRS, semantic communications, NOMA)",
                "position": 397
            }
        ]
    },
    {
        "header": "3Teaching Mathematical Reasoning with GRPO",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Use of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix ADataset Construction Details",
        "images": []
    },
    {
        "header": "Appendix BQuality Assessment Rubric For Human",
        "images": []
    },
    {
        "header": "Appendix CLarge Language Model-Assisted Quality Assessment",
        "images": []
    },
    {
        "header": "Appendix DPrompt Construction for Dataset Generation and Evaluation",
        "images": []
    },
    {
        "header": "Appendix ERepresentative System Model Extractions",
        "images": []
    },
    {
        "header": "Appendix FHuman Expert Evaluation Examples",
        "images": []
    },
    {
        "header": "Appendix GRepresentative Solution Examples from WirelessMathLM-7B",
        "images": []
    }
]