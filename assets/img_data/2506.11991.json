[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Visual Grounded Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11991/x1.png",
                "caption": "Figure 1:Overview framework of our method. In the left of the image, we crop the original image with AnyRes strategy to maintain the memory pool of visual details, when a replay signal is detected,VGRretrieves the image token from the memory pool, enrich visual clues in reasoning. In the right image, we show an example ofVGRin action,VGRenables the MLLM to check the key area on-demand.",
                "position": 182
            }
        ]
    },
    {
        "header": "4Visual Reasoning Data Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11991/x2.png",
                "caption": "Figure 2:Overview framework of our data pipeline. The blue arrow line indicates the cold-start data curation pipeline for the annotator and the green line indicates the data pipeline for training data.",
                "position": 298
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11991/x3.png",
                "caption": "Figure 3:Example of training data inVGR-SFT.",
                "position": 901
            },
            {
                "img": "https://arxiv.org/html/2506.11991/x4.png",
                "caption": "Figure 4:Example generated by our annotation model. We distill core information and the chain-of-thought from long redundant reasoning with reject sampling and rewriting.",
                "position": 999
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Results ofVGR",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11991/x5.png",
                "caption": "Figure 5:Example of training data inVGR-SFTin different formulations.",
                "position": 2038
            },
            {
                "img": "https://arxiv.org/html/2506.11991/x6.png",
                "caption": "Figure 6:Example of data from original data, cold-start model, annotator and training set.",
                "position": 2086
            },
            {
                "img": "https://arxiv.org/html/2506.11991/x7.png",
                "caption": "Figure 7:Example ofVGRresponse in MMStar and ChartQA benchmarks.",
                "position": 2089
            }
        ]
    },
    {
        "header": "Appendix BReasoning Data Pipeline",
        "images": []
    }
]