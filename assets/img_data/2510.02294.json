[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02294/w",
                "caption": "",
                "position": 51
            },
            {
                "img": "https://arxiv.org/html/2510.02294/x1.png",
                "caption": "Figure 1:(Left): MTEB performance comparison between LLM-based embedding models. (Right): F2LLM, trained solely on open-source non-synthetic data, achieves a strong balance between embedding performance, training data, and model size. Higher scores indicate better performance (left axis), fewer training data (right axis), and smaller model size (bottom axis).",
                "position": 62
            },
            {
                "img": "https://arxiv.org/html/2510.02294/x2.png",
                "caption": "",
                "position": 65
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3F2LLM",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": []
    }
]