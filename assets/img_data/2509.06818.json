[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06818/x1.png",
                "caption": "Figure 1:Showcase of our UMO model in different scenarios. The detailed prompts are listed inTable˜9.",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x2.png",
                "caption": "Figure 2:Our UMO unleashes multi-identity consistency and alleviates identity confusion. Existing image customization methods suffer low facial fidelity and severe identity confusion, while UMO can tackle these problems with results inblue boxes.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06818/x3.png",
                "caption": "Figure 3:Illustration of the training framework of UMO. UMO’s training process follows ReReFL inAlgorithm˜1with Multi-Identity Matching Reward.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x4.png",
                "caption": "(a)SIR scores of UNO[32].",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x4.png",
                "caption": "(a)SIR scores of UNO[32].",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x5.png",
                "caption": "(b)SIR scores of OmniGen2[31].",
                "position": 265
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06818/x6.png",
                "caption": "Figure 5:Qualitative comparison with different methods on XVerseBench[4].",
                "position": 345
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x7.png",
                "caption": "Figure 6:Qualitative comparison with different methods on OmniContext[31].",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x8.png",
                "caption": "Figure 7:Radar charts of user evaluation of methods on different dimensions.",
                "position": 639
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x9.png",
                "caption": "Figure 8:Visualization of ablation study. Zoom in for details.",
                "position": 755
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "FDetailed Quantitative Comparisons",
        "images": []
    },
    {
        "header": "GMore Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06818/x10.png",
                "caption": "Figure 9:Qualitative results on task type Single-Subject from XVerseBench[4].",
                "position": 1552
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x11.png",
                "caption": "Figure 10:Qualitative results on task type Multi-Subject from XVerseBench[4].",
                "position": 1555
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x12.png",
                "caption": "Figure 11:Qualitative results on task type SINGLE Character from OmniContext[31].",
                "position": 1558
            },
            {
                "img": "https://arxiv.org/html/2509.06818/x13.png",
                "caption": "Figure 12:Qualitative results on task type MULTI Character from OmniContext[31].",
                "position": 1561
            }
        ]
    },
    {
        "header": "HDiscussion",
        "images": []
    }
]