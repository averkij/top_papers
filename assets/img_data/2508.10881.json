[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10881/x1.png",
                "caption": "",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10881/x2.png",
                "caption": "Figure 2:Comparison between previous cartoon production workflow and ours. ToonComposer enables thepost-keyframingstage, seamlessly integrating inbetweening and colorization into a single automated process, streamlining cartoon production compared to previous traditional and existing AI-assisted workflows.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x3.png",
                "caption": "Figure 3:The model design of ToonComposer. A sparse sketch injection mechanism enables precise control using keyframe sketches, and a cartoon adaptation method incorporating a spatial low-rank adapter tailors the DiT-based video foundation model to the cartoon domain, preserving its temporal priors.",
                "position": 181
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10881/x4.png",
                "caption": "Figure 4:The structure of the Spatial Low-Rank Adapter (SLRA) used for cartoon adaptation in ToonComposer. The SLRA takes the hidden states before the spatial-temporal self-attention module as input and outputs a residual that is added after the self-attention operation.",
                "position": 309
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x5.png",
                "caption": "Figure 5:Examples of different sketch types used during training and evaluation. All variants except human-drawn sketches are included in the training set. The diversity of training sketches improves ToonComposer’s robustness to varying sketch styles in real-world use cases. Human-drawn sketches are reserved for evaluation in the real benchmark, as discussed inSection4.3.",
                "position": 502
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.10881/x6.png",
                "caption": "Figure 6:Comparison on the synthetic benchmark among AniDoc, LVCD, ToonCrafter, and our ToonComposer. Zoom-in patches of a randomly selected region are shown in the rightmost column. Our method demonstrates superior visual quality, smoother motion, and better style consistency with the input image. Evaluation scenes are sourced from movies with permission (Mr. MiaoandBig Fish & Begonia). Please refer to the supplementary video for additional results.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x7.png",
                "caption": "Figure 7:Comparison on the benchmark PKBench, using keyframe sketches drawn by the human artists. Zoom-in patches are shown in the rightmost column. Our method generates high-quality results from real sketch inputs, whereas other methods struggle to maintain visual consistency. Please refer to the supplementary video for additional examples.",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x8.png",
                "caption": "Figure 8:Ablation study of the Spatial Low-Rank Adapter (SLRA) in ToonComposer, comparing cartoon output frames produced using different adaptation methods. SLRA yields higher visual quality and better coherence with the input keyframe sketches compared to alternative approaches.",
                "position": 723
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x9.png",
                "caption": "Figure 9:Illustration of region-wise control in ToonComposer. Without region-wise control, blank areas in keyframe sketches are misinterpreted as textureless regions, producing a flat blue train (second row, highlighted with a dashed box). With region-wise control, users can specify areas for context-driven generation without explicit sketches, enabling the model to create plausible and detailed content, such as the dynamic train motion (third row, highlighted with a dashed box).",
                "position": 726
            },
            {
                "img": "https://arxiv.org/html/2508.10881/x10.png",
                "caption": "Figure 10:ToonComposer’s flexible controllability with varying keyframe sketches. Using only sketch #1 as the final keyframe and the prompt “an old man turns back,” ToonComposer generates a sequence where the old man turns directly (first row). Adding sketch #2 to control the middle keyframe, while keeping the prompt unchanged, results in a sequence where the old man first picks up a fruit before turning back (second row).",
                "position": 738
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]