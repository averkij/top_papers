[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/overview_a.png",
                "caption": "Figure 1:Comparing MegaHan97K with existing Chinese character datasets. The green and blue bubbles represent handwritten and historical datasets, respectively. The area of the bubble and the number in brackets denote categories in each dataset.",
                "position": 126
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MegaHan97K Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/ambiguous_characters.png",
                "caption": "Figure 2:The example of ambiguous Chinese characters.",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/all_data.png",
                "caption": "Figure 3:The visualization of the MegaHan97K dataset. HandWT-O (Original) and HandWT-A (Augmented) represent the pre-processed and post-processed versions of the handwritten subset, respectively. Zoom in for better view.",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/interface_pen.png",
                "caption": "Figure 4:The user interface of the data acquisition website.",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/data_process.png",
                "caption": "Figure 5:Illustration of data processing to simulate realistic scenarios.",
                "position": 277
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/iffont.png",
                "caption": "Figure 6:Comparison of challenging samples synthesized by FontDiffuser and IF-Font with ground truth (GT).Redboxes indicate errors, whilegreenboxes highlight correct components.",
                "position": 1135
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/eff_num.png",
                "caption": "Figure 7:Effects of increasing synthetic sample sizes on accuracy.",
                "position": 1138
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/sidebyside.png",
                "caption": "Figure 8:Comparison of prediction results with and without the use of MegaHan97K. “HWDB” represents predictions from the model trained only on the HWDB dataset, while “HWDB+Mega” represents predictions from the model trained on both the HWDB and MegaHan97K datasets.",
                "position": 1313
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/realbadcase.png",
                "caption": "Figure 9:Analysis of a damaged ancient document. The left side shows a sample of a damaged ancient document, while the right side provides a detailed qualitative analysis of specific regions. Highlighted cases include variant/rare characters (redboxes), completely damaged characters (blueboxes), and blurred or stroke-loss characters (greenboxes). Variant characters refer to characters that share the same meaning and pronunciation as their counterparts but differ in glyph, such as variations in radicals or strokes.",
                "position": 1330
            },
            {
                "img": "https://arxiv.org/html/2506.04807/extracted/6515028/fig/visualization.png",
                "caption": "Figure 10:Visualization analysis of the misclassified samples from the CCR-CLIP model. The misclassified components, such as radicals or strokes, are highlighted withredboxes, while the correctly recognized ones are marked withgreenboxes.",
                "position": 1333
            }
        ]
    },
    {
        "header": "6Visualization",
        "images": []
    },
    {
        "header": "7Limitation",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]