[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/title_icon.png",
                "caption": "",
                "position": 53
            },
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/huggingface_logo-noborder.png",
                "caption": "",
                "position": 61
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/motivation.png",
                "caption": "Figure 1:The key motivations.Left:Analysis for different navigation error types from LVLM-based VLN agents.Right:Examples of different error types.",
                "position": 77
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/framework.png",
                "caption": "Figure 2:Overview of SeeNav-Agent.Different from previous VLN works tend to use single view image as input and use method like GRPO or GiGPO for RFT, our SeeNav-Agent designs a dual-view input with visual prompt to enhance the visual module in a zero-shot manner, and proposes SRGPO to introduce process reward signals efficiently during the RFT stage by randomly grouping steps.",
                "position": 138
            },
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/VP_example.png",
                "caption": "Figure 3:Example of Dual-View Visual Prompt.The left part is the BEV, and the right part is the FV. The numbers 0 to 7 represent different action IDs. Yellow part of the agent marker indicates the left side, purple part indicates the right side, and the green arrow points to the front of the agent.",
                "position": 151
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/episode-success_rate-qwen3B.png",
                "caption": "Figure 4:Training Process of Qwen2.5-VL-3B-Instruct.The solid line and the shaded region represent the mean and standard deviation obtained from multiple training runs.",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/VP-case.png",
                "caption": "Figure 5:Case Comparison of vanilla-GPT 4.1 and GPT4.1 with VP.The bottom part shows the image and text feedback from the environment after taking actions. This case clearly shows that, with the dual-view VP technique, the visual hallucination can be reduced and the spatial understanding capability of the VLN agent can be enhanced.",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2512.02631/sec/figs/ood_val.png",
                "caption": "Figure 6:Success Rate on Testing Scenes. All RFT algorithms are trained on o.o.d. scenes and tested on base scenes of the EmbodiedBench-Navigation.",
                "position": 587
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    }
]