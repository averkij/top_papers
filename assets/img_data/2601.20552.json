[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20552/x1.png",
                "caption": "Figure 1:We substitute the CLIP component in DeepEncoder with an LLM-style architecture. By customizing the attention mask, visual tokens utilize bidirectional attention while learnable queries adopt causal attention. Each query token can thus attend to all visual tokens and preceding queries, allowing progressive causal reordering over visual information.",
                "position": 106
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20552/x2.png",
                "caption": "Figure 2:This figure shows two computer vision models with parallelized queries: DETR’s decoder[carion2020end]for object detection and BLIP2’s Q-former[li2023blip]for visual token compression. Both employ bidirectional self-attention among queries.",
                "position": 193
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20552/x3.png",
                "caption": "Figure 3:DeepSeek-OCR 2 adopts the visual token compression mechanism from DeepEncoder, employing an 80M-parameter image compressor that reduces visual tokens by a factor of 16. DeepEncoder V2 differs by replacing DeepEncoder’s CLIP module with a compact language model architecture. Through customized attention masks, this LM-style vision encoder acquires CLIP’s knowledge compression capabilities while initiating causal modeling of visual sequences.",
                "position": 224
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20552/x4.png",
                "caption": "Figure 4:Token count calculation in DeepEncoder V2. DeepEncoder V2 outputs 256−-1120 tokens per image using a multi-crop strategy with 0−-6 local views. With 0 local views, only the global view produces 256 tokens; with 6 local views, the count reaches 1120 (6×\\times144+256).",
                "position": 245
            },
            {
                "img": "https://arxiv.org/html/2601.20552/x5.png",
                "caption": "Figure 5:Attention mask architecture of DeepEncoder V2. Concatenation of bidirectional mask (vision tokens, ViT-like) and causal triangular mask (flow tokens, LLM decoder-style).",
                "position": 267
            }
        ]
    },
    {
        "header": "4Experimental Settings",
        "images": []
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6Discussion and Future Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]