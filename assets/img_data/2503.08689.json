[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08689/x1.png",
                "caption": "Figure 1:Comparative analysis of Video-MME[7]when implementing attention-based token assignment methods AIM[50]and FrameFusion[9], alongside our proposed query-oriented QuoTA within LLaVA-Video-7B[48]and LLaVA-OV-7B[13]across varied relative visual token budgets. QuoTA demonstrates superior efficacy while exhibiting consistent performance enhancement across diverse token budget configurations relative to the baseline.",
                "position": 84
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08689/x2.png",
                "caption": "Figure 2:The framework of QuoTA. Initially, a dynamic frame sampler extractsTùëáTitalic_Tframes from the video based on its duration, which are subsequently processed byViTto generate visual embeddingsùêÑùêÑ\\bm{\\mathrm{E}}bold_E. Then, the based LVLM decouples the input query using Chain-of-Thoughts[36]reasoning into a decoupled clue to generate frame-wise importance scores through scoring LVLM in parallel, thus evaluating the relevance to the query of each frame. Finally, a token assigner rescales the frame embeddings toùêÑ^bold-^ùêÑ\\bm{\\mathrm{\\hat{E}}}overbold_^ start_ARG bold_E end_ARGbased on these importance scores.",
                "position": 142
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08689/x3.png",
                "caption": "Figure 3:Qualitative result shown in Video-MME[7]benchmark when applying QuoTA with LLaVA-Video-7B[48]. The video frames with a blue border are query-oriented keyframes, and the bar chart shows the normalized scores of QuoTA for each frame.",
                "position": 999
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6CoT-Driven Decouple Prompt",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08689/x4.png",
                "caption": "Figure 4:CoT-driven decouple prompt for object list.",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2503.08689/x5.png",
                "caption": "Figure 5:CoT-driven decouple prompt for video event.",
                "position": 1812
            },
            {
                "img": "https://arxiv.org/html/2503.08689/x6.png",
                "caption": "Figure 6:Sub-task results shown in Video-MME[7]benchmark when applying distinct frame scoring strategy of LLaVA-Video-7B[48].",
                "position": 1815
            }
        ]
    },
    {
        "header": "7Effect of Different Frame Scoring Strategy",
        "images": []
    }
]