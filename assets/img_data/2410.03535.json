[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03535/x1.png",
                "caption": "Figure 1:Downsampled MNIST samples generated by the best generative models on this dataset.\nDespite this being a simple image dataset, it can be challenging for tabular generative models due to the high dimensionality and complex structure of correlations between features.\nWe find NRGBoost to be the only model that is able to generate passable samples.",
                "position": 198
            }
        ]
    },
    {
        "header": "2Energy Based Models",
        "images": []
    },
    {
        "header": "3NRGBoost",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03535/x2.png",
                "caption": "Figure 2:Density learned by NRGBoost at different boosting iterations (1, 3, 10 and 100), for a toy dataset (shown right), starting from a uniform distribution.\nWeak learners are trees with 16 leaves.",
                "position": 331
            }
        ]
    },
    {
        "header": "4Density Estimation Trees and Density Estimation Forests",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03535/x3.png",
                "caption": "Figure 3:Joint histogram for the latitude and longitude for the California Housing dataset.",
                "position": 869
            }
        ]
    },
    {
        "header": "7Discussion",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheory",
        "images": []
    },
    {
        "header": "Appendix BDensity Estimation Trees",
        "images": []
    },
    {
        "header": "Appendix CGreedy Tree-Based Multiplicative Boosting",
        "images": []
    },
    {
        "header": "Appendix DReproducibility",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.03535/x4.png",
                "caption": "Figure 4:Wall time required to train the best model for each method.",
                "position": 2928
            },
            {
                "img": "https://arxiv.org/html/2410.03535/x5.png",
                "caption": "Figure 5:Downsampled MNIST samples generated by Gibbs sampling from a NRGBoost model. Each row corresponds to an independent chain initialized with a sample from the initial modelf0subscriptùëì0f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT(first column). Each column represents a consecutive sample from the chain.",
                "position": 2940
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results",
        "images": []
    }
]