[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16618/x1.png",
                "caption": "Figure 1:Overview of SA-SV benchmark and SAM2S framework. (a) Dataset scale comparison. (b) SA-SV benchmark distribution. (c) SAM2 for natural videos. (d) SAM2S for surgical videos with enhanced long-term tracking and domain-specific modules.",
                "position": 69
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SA-SV Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16618/x2.png",
                "caption": "Figure 2:Overview of SAM2S for surgical video segmentation. DiveMem handles long-term tracking, TSL enhances semantic understanding, and ARL addresses annotation ambiguity.",
                "position": 383
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16618/x3.png",
                "caption": "Figure 3:Qualitative comparison between SAM2 (vanilla), SAM2 (FT), SAM2Long (FT), and SAM2S on RARP50. Frame indices indicate timestamps in seconds, spanning from 150s to 560s (410s duration).",
                "position": 2240
            },
            {
                "img": "https://arxiv.org/html/2511.16618/x4.png",
                "caption": "Figure 4:Qualitative comparison on EndoVis18 (140s duration).",
                "position": 2244
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]