[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08994/x1.png",
                "caption": "Figure 1:We propose Speculative Jacobi-Denoising Decoding to accelerate autoregressive text-to-image generation via multi-token prediction. On Lumina-mGPT, the number of model forward passes for inference (denoted assteps) is reduced.\nThe inference step for our decoding is marked ingreen.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08994/x2.png",
                "caption": "Figure 2:Overview of our decoding process. The noisy token embeddings with increasing noise levels undergo a parallel forward pass with a causal attention mask, predicting conditional probabilities and then sampling clean tokens. A probabilistic criterion selects a prefix of tokens for acceptance (green area). For unaccepted tokens, if clean, the next-token prediction performs on them (green solid arrows marked withAR). If noisy, they are denoised with one-position offset (blue solidx^0\\hat{x}^{0}arrows and dash arrows).",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x2.png",
                "caption": "Figure 2:Overview of our decoding process. The noisy token embeddings with increasing noise levels undergo a parallel forward pass with a causal attention mask, predicting conditional probabilities and then sampling clean tokens. A probabilistic criterion selects a prefix of tokens for acceptance (green area). For unaccepted tokens, if clean, the next-token prediction performs on them (green solid arrows marked withAR). If noisy, they are denoised with one-position offset (blue solidx^0\\hat{x}^{0}arrows and dash arrows).",
                "position": 227
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x3.png",
                "caption": "Figure 3:Overview of our training strategy and model process. The input token embedding sequence is randomly divided into segments and the adjacent segments are perturbed with the noise of consecutive levels. The noisy embeddings with timestep tokens are fed into transformer blocks and a prediction head. During training, the predicted probability is used to compute the cross-entropy loss for next-token prediction. During inference, the probability is for token sampling and then generating embeddings.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x4.png",
                "caption": "Figure 4:Correlation between denoising iterations and Jacobi window length on the latency. Circle areas represent absolute latency values, and the lowest latency (a difference within 3 seconds is allowed) is inorange.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x4.png",
                "caption": "Figure 4:Correlation between denoising iterations and Jacobi window length on the latency. Circle areas represent absolute latency values, and the lowest latency (a difference within 3 seconds is allowed) is inorange.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x5.png",
                "caption": "Figure 5:Study on embedding normalization for denoising process. Left: Denoising output without embedding normalization, failing to generate a coherent image. Right: Denoising output with embedding normalization, generating a semantically meaningful image.",
                "position": 409
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08994/x6.png",
                "caption": "Figure 6:The comparison of the original autoregressive decoding, SJD[6], and our method with Lumina-mGPT[11]as the baseline and on one RTX 4090.",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x6.png",
                "caption": "Figure 6:The comparison of the original autoregressive decoding, SJD[6], and our method with Lumina-mGPT[11]as the baseline and on one RTX 4090.",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x7.png",
                "caption": "Figure 7:The comparison of the original autoregressive decoding, SJD[6], and our method with Emu3[4]as the baseline and on one RTX 4090.",
                "position": 786
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BFurther Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08994/x8.png",
                "caption": "Figure 8:The trajectories of token difference.",
                "position": 2015
            }
        ]
    },
    {
        "header": "Appendix CLimitations and Future Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08994/x9.png",
                "caption": "Figure 9:Analysis of our denoising process. (a) Our denoising process without Jacobi iterations can generate reasonable images with few model forward passes and small latency. (b) The further Jacobi iterations refine the results of our denoising process, resulting in more details and fewer artifacts.",
                "position": 2033
            },
            {
                "img": "https://arxiv.org/html/2510.08994/x10.png",
                "caption": "",
                "position": 2042
            }
        ]
    },
    {
        "header": "Appendix DImpact Statement",
        "images": []
    }
]