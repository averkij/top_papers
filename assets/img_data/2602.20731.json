[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Communication Inspired Tokenization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20731/x1.png",
                "caption": "Figure 1:The overall training pipeline of COMiT. A sequence ofKKrandom crops is extracted from the input image and iteratively embedded into the latent messagemKm_{K}that is discretized via FSQ(Mentzeret al.,2024). The latter is decoded by the same model using the flow matching objective(Lipmanet al.,2023). Additionally, we use REPA(Yuet al.,2024b)to speed up the training and SREPA to inject more semantic priors into the latent message.",
                "position": 147
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20731/x2.png",
                "caption": "Figure 2:The effect of our attentive tokenization pipeline on the tokens’ visual grounding. The model that has been trained with attentive tokenization demonstrates much better token–object alignment compared to the variant of the model that has only seen global crops at training. The token sequences for both models were obtained from the 10th layer of COMiT-B, using the same cropping policy that embeds only the global crop.",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x3.png",
                "caption": "",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x4.png",
                "caption": "",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x5.png",
                "caption": "",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x6.png",
                "caption": "Figure 3:The difference between theadaptive(top) andglobal+adaptive(bottom) cropping policies. In both cases COMiT aggregates the crops of the input image (the leftmost column) into the latent message and decodes it to obtain the reconstructed image (the rightmost column, 10 NFE withCFG=7.5{\\rm CFG}=7.5). The columns in-between show which crops are selected together with immediate single step reconstructions (1 NFE withCFG=1.0{\\rm CFG}=1.0). The progressive ambiguity reduction as more crops are integrated in the latent message is particularly visible with the single step decoding.",
                "position": 544
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x7.png",
                "caption": "Figure 4:The way COMiT adds information to the latent message is inherently compositional.",
                "position": 772
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x8.png",
                "caption": "",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x9.png",
                "caption": "",
                "position": 782
            }
        ]
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20731/assets/nfe_rfid_plot.png",
                "caption": "(a)rFID vs. NFE withCFG=3.0{\\rm CFG}=3.0",
                "position": 1564
            },
            {
                "img": "https://arxiv.org/html/2602.20731/assets/nfe_rfid_plot.png",
                "caption": "(a)rFID vs. NFE withCFG=3.0{\\rm CFG}=3.0",
                "position": 1567
            },
            {
                "img": "https://arxiv.org/html/2602.20731/assets/cfg_rfid_plot.png",
                "caption": "(b)rFID vs. CFG withNFE=10{\\rm NFE}=10",
                "position": 1572
            },
            {
                "img": "https://arxiv.org/html/2602.20731/assets/voc_size.png",
                "caption": "(c)Ablation of the bottleneck size",
                "position": 1577
            }
        ]
    },
    {
        "header": "Appendix CAnalysis of the Attention Maps",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20731/x10.png",
                "caption": "Figure 6:Emergence of object-centric tokens in COMiT. We visualize the attention maps of specific tokens in one of the deep layers of the network during the decoding stage. One can see that the tokens naturally attend to the objects and their parts.",
                "position": 1606
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x11.png",
                "caption": "Figure 7:Generalization of COMiT to other domains, such as rendered animations or medical images. It can be seen that the model has certain symmetry bias that allows it to reduce the uncertainty about the right hand side of the image when the content on the left hand side is observed. Also notice how the adaptive cropping policy selects the most critical regions for reconstruction.",
                "position": 1615
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x12.png",
                "caption": "",
                "position": 1622
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x13.png",
                "caption": "",
                "position": 1625
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x14.png",
                "caption": "",
                "position": 1628
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x15.png",
                "caption": "Figure 8:Visualization of COMiT-XL’s attention maps. The attention maps of the tokens that yield the largest IoUs per sample are shown. With adjusting the thresholding percentage, a remarkable mIoU of 0.58 can be achieved. Note that the model has never seen any segmentation maps or class labels during training.",
                "position": 1634
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x16.png",
                "caption": "",
                "position": 1647
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x17.png",
                "caption": "",
                "position": 1654
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x18.png",
                "caption": "",
                "position": 1661
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x19.png",
                "caption": "",
                "position": 1668
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x20.png",
                "caption": "",
                "position": 1675
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x21.png",
                "caption": "Figure 9:Visualization of the nearest neighbors of a sample from the ImageNet100 validation set in the space of COMiT’s latent messages. One can see that despite unsupervised training and simple probing the learned messages tend to cluster into semantically meaningful groups.",
                "position": 1691
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x22.png",
                "caption": "",
                "position": 1705
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x23.png",
                "caption": "",
                "position": 1706
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x24.png",
                "caption": "",
                "position": 1707
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x25.png",
                "caption": "",
                "position": 1708
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x26.png",
                "caption": "",
                "position": 1711
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x27.png",
                "caption": "",
                "position": 1712
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x28.png",
                "caption": "",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x29.png",
                "caption": "",
                "position": 1714
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x30.png",
                "caption": "",
                "position": 1715
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x31.png",
                "caption": "",
                "position": 1718
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x32.png",
                "caption": "",
                "position": 1719
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x33.png",
                "caption": "",
                "position": 1720
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x34.png",
                "caption": "",
                "position": 1721
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x35.png",
                "caption": "",
                "position": 1722
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x36.png",
                "caption": "",
                "position": 1725
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x37.png",
                "caption": "",
                "position": 1726
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x38.png",
                "caption": "",
                "position": 1727
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x39.png",
                "caption": "",
                "position": 1728
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x40.png",
                "caption": "",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x41.png",
                "caption": "",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x42.png",
                "caption": "",
                "position": 1733
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x43.png",
                "caption": "",
                "position": 1734
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x44.png",
                "caption": "",
                "position": 1735
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x45.png",
                "caption": "",
                "position": 1736
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x46.png",
                "caption": "",
                "position": 1739
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x47.png",
                "caption": "",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x48.png",
                "caption": "",
                "position": 1741
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x49.png",
                "caption": "",
                "position": 1742
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x50.png",
                "caption": "",
                "position": 1743
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x51.png",
                "caption": "",
                "position": 1746
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x52.png",
                "caption": "",
                "position": 1747
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x53.png",
                "caption": "",
                "position": 1748
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x54.png",
                "caption": "",
                "position": 1749
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x55.png",
                "caption": "",
                "position": 1750
            },
            {
                "img": "https://arxiv.org/html/2602.20731/x56.png",
                "caption": "Figure 10:Additional results on the difference between theadaptive(even rows) andglobal+adaptive(odd rows) cropping policies. The first column depicts the ground truth input image. The last column corresponds to the final reconstruction with 10 NFE. The columns in-between demonstrate how COMiT refines its latent message with incoming information (1 NFE reconstructions are shown).",
                "position": 1759
            }
        ]
    },
    {
        "header": "Appendix DMore Visual Results",
        "images": []
    }
]