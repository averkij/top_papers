[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13344/x1.png",
                "caption": "Figure 1:Performance of UniMoE-Audio.Left:Comparison against specialized baselines reveals the failure of naive joint training, which causes a clear performance degradation on speech generation and more significant decline on music generation. In contrast, our UniMoE-Audio yields synergistic gains across both tasks.Right:Radar charts show UniMoE-Audio achieving the best comprehensive performance against leading models on a wide array of speech (a) and music (b) metrics.",
                "position": 91
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3UniMoE-Audio",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13344/x2.png",
                "caption": "Figure 2:An overview of the UniMoE-Audio framework.Left:UniMoE-Audio is a unified model capable of performing speech and music generation by leveraging multimodal conditional inputs, including Voice Cloning, Text-to-Speech (TTS), Text-to-Music (T2M), and Video-to-Music (V2M).Center:The core architecture of our model is a Transformer with Dynamic-Capacity MoE layers.Right:We propose a novel Top-P routing strategy, which dynamically selects the number of experts allocated to each token based on their complexity.",
                "position": 165
            }
        ]
    },
    {
        "header": "4Training",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13344/figures/Loss/tts_loss.png",
                "caption": "Figure 3:Training loss for the speech generation task (top) and music generation task (bottom). The plots show the transition from the Warmup Training Stage (blue) to the Synergistic Joint Training Stage (orange). The solid line represents the moving average of the loss.",
                "position": 895
            },
            {
                "img": "https://arxiv.org/html/2510.13344/figures/Loss/music_loss.png",
                "caption": "",
                "position": 899
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x3.png",
                "caption": "Figure 4:Visualization of the dynamic computational budget allocated by our Top-P routing mechanism. The figure illustrates the proportion of tokens activating a varying number of experts at each layer, revealing a ”rise-and-fall” pattern where more computational resources are adaptively assigned to the middle layers. For clarity, counts of activated experts are grouped into bins (e.g., ”Expert 2-3” represents tokens activating either 2 or 3 experts).",
                "position": 927
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x4.png",
                "caption": "Figure 5:Analysis of expert routing dynamics in UniMoE-Audio across transformer layers. The top-left ”All Experts” plot illustrates the routing frequency for each of the eight routed experts (E1-E8, colored) and the null expert (E9, gray). The subsequent nine plots provide a granular breakdown for each expert, showing the proportion of tokens routed from the Music (lighter shade) versus the TTS (darker shade) task.",
                "position": 930
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x5.png",
                "caption": "",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x6.png",
                "caption": "",
                "position": 934
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x7.png",
                "caption": "",
                "position": 935
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x8.png",
                "caption": "",
                "position": 936
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x9.png",
                "caption": "",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x10.png",
                "caption": "",
                "position": 939
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x11.png",
                "caption": "",
                "position": 940
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x12.png",
                "caption": "",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2510.13344/x13.png",
                "caption": "",
                "position": 942
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]