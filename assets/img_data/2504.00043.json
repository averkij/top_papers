[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/extracted/6322068/asset/logo_2.png",
                "caption": "",
                "position": 83
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 1:Performance gap between top-performing reasoning LLMs and non-reasoning LLMs/LVLMs onCrossWordBench. Reasoning LLMs achieve better overall performance vs. non-reasoning models, and follow crossing letter constraints significantly better.",
                "position": 111
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 2:Framework of CrossWordBench. (a) Dataset curation process and input templates for LLMs and LVLMs; (b) Zero-shot CoT evaluation; (c) Interactive Mode Evaluation.",
                "position": 168
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 3:Grid Parsing vs. Puzzle-Solving on7Ã—7English puzzles, measured with WCR.",
                "position": 1055
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 4:CDF of ISS on7x7English Puzzles.",
                "position": 1162
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 5:Crossing letter counts and average WCR on7x7English puzzles across LLMs.",
                "position": 1402
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 6:Self-reflection improvements on7x7English puzzles. Top row: reasoning LLMs. Bottom row: non-reasoning LVLMs.",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 7:o3-mini performance on7x7English puzzles across three distinct reasoning efforts.",
                "position": 1443
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "((a))Token Usage of VLMs.",
                "position": 3293
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "((a))Token Usage of VLMs.",
                "position": 3296
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "((b))Token Usage of LLMs.",
                "position": 3309
            },
            {
                "img": "https://arxiv.org/html/2504.00043/%5Cfinalfile",
                "caption": "Figure 9:WCR difference on two inputs formats for LVLMs.",
                "position": 3335
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    }
]