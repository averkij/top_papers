[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/x1.png",
                "caption": "",
                "position": 121
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x2.png",
                "caption": "",
                "position": 156
            },
            {
                "img": "https://arxiv.org/html/2602.16742/figures/ve3.png",
                "caption": "Figure 1:The number of different visual element types of training datasets.",
                "position": 161
            },
            {
                "img": "https://arxiv.org/html/2602.16742/figures/perf.png",
                "caption": "Figure 2:Performance on multimodal math and general multimodal benchmarks, we report averaged Pass@1 accuracy across benchmarks.",
                "position": 164
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Overview of DeepVision-103K",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/x3.png",
                "caption": "Figure 3:A data sample from DeepVision-103K.",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x4.png",
                "caption": "Figure 4:Visual elements in DeepVision-103K.",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x5.png",
                "caption": "Figure 5:Mathematical topics in DeepVision-103K.",
                "position": 467
            }
        ]
    },
    {
        "header": "3Construction of DeepVision-103K",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/figures/pipeline.png",
                "caption": "Figure 6:Curation pipeline for mathematical data in DeepVision-103K.",
                "position": 478
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/figures/imprv4.png",
                "caption": "Figure 7:Enhanced Capabilities",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x6.png",
                "caption": "Figure 8:DeepVision model correctly identifies the shaded region on the first attempt.",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x7.png",
                "caption": "Figure 9:DeepVision model actively re-examines visual content to correct errors, while the base model merely rephrases without genuine verification.",
                "position": 922
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x8.png",
                "caption": "Figure 10:DeepVision model systematically enumerates all possible angle combinations and concludes the type cannot be determined, while the Instruct model incorrectly assumes symmetry without justification.",
                "position": 931
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVisual Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/x9.png",
                "caption": "Figure 11:Solid Geometry & Analytic Plots.",
                "position": 1559
            },
            {
                "img": "https://arxiv.org/html/2602.16742/x10.png",
                "caption": "Figure 12:Planar Geometry & Solid Geometry & Real-World Item.",
                "position": 1562
            }
        ]
    },
    {
        "header": "Appendix BVisual Elements Annotation",
        "images": []
    },
    {
        "header": "Appendix CData Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/figures/recall1.png",
                "caption": "Figure 13:Top 10 Knowledge-based retrieval. The x-axis IDs correspond to knowledge domains listed in Table6.",
                "position": 1674
            }
        ]
    },
    {
        "header": "Appendix DTraining Details",
        "images": []
    },
    {
        "header": "Appendix EEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix FTraining Curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16742/figures/res.png",
                "caption": "Figure 14:Increasing response length.",
                "position": 2206
            },
            {
                "img": "https://arxiv.org/html/2602.16742/figures/critic.png",
                "caption": "Figure 15:Upward rewards.",
                "position": 2209
            },
            {
                "img": "https://arxiv.org/html/2602.16742/figures/entropy.png",
                "caption": "Figure 16:Stable entropy.",
                "position": 2212
            }
        ]
    },
    {
        "header": "Appendix GPotential Risks",
        "images": []
    }
]