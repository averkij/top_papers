[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/average_image.jpg",
                "caption": "Average Image",
                "position": 68
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/average_image.jpg",
                "caption": "Average Image",
                "position": 71
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_male.png",
                "caption": "Male",
                "position": 76
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_blond_hair.png",
                "caption": "Blond_Hair",
                "position": 82
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_wavy_hair.png",
                "caption": "Wavy_Hair",
                "position": 87
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x1.png",
                "caption": "",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird3.png",
                "caption": "Background Bias",
                "position": 150
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird3.png",
                "caption": "Background Bias",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird2.png",
                "caption": "Object Bias",
                "position": 158
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/bird4.png",
                "caption": "Depiction Bias",
                "position": 164
            }
        ]
    },
    {
        "header": "4Validating the metric",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/waterbird_heatmaps/waterbirds_mean_mask.png",
                "caption": "Figure 3:Average bird mask and average heatmaps for Waterbirds at increasing levels of bias.We see that the model attends less on the bird as the bias increases, as indicated by its mask.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/waterbird_heatmaps/waterbirds70.png",
                "caption": "",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/waterbird_heatmaps/waterbirds90.png",
                "caption": "",
                "position": 323
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/waterbird_heatmaps/waterbirds95.png",
                "caption": "",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/waterbird_heatmaps/waterbirds100.png",
                "caption": "",
                "position": 325
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x2.png",
                "caption": "Figure 4:Evaluation of mask score using GradCAM on Waterbirds test set.The X-axis represents the Attention-IoU mask score for the ground-truth masks of the bird and background. We note the dataset bias and the worst group accuracy (WGA) along the Y-axis. As the bias increases, the worst group accuracy decreases and the model attends less to the bird and more to the background.",
                "position": 338
            }
        ]
    },
    {
        "header": "5Analyzing CelebA",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/x3.png",
                "caption": "Figure 5:Evaluation of mask score using GradCAM on CelebA test set with attribute-specific feature masks, compared to worst group accuracy withMale.A mask score of 1 indicates perfect agreement between the attention map and feature mask, and 0 indicates perfect disagreement. Groups are considered based on ground-truth labels for the different combinations of target attribute andMale. If the number of images in a group is less than 1% of the test set, the group was excluded from consideration.",
                "position": 383
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x4.png",
                "caption": "Figure 6:Comparison of attributes with theMaleattribute heatmap. (Left) We compare Attention-IoU with the absolute value of the Matthews correlation coefficient between the predictions of the attribute andMale, noticing a strong positive trend. Some attributes are outliers to this trend, includingEyeglassesandMustache, which lie above this trend, andWavy_Hair, which lies below. (Right) We measure the mask score for a selection of attributes. We notice that the heatmap forMaleattends most strongly to the eye, eyebrows, and mouth region, which is closely mimicked byWearing_Lipstick.\nWe can also compare attributes likeBlond_HairandWavy_Hair, and find that the main difference between their heatmaps is in the¬†eye¬†region.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x4.png",
                "caption": "",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x5.png",
                "caption": "",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/mask_eyes.png",
                "caption": "Figure 7:Average heatmaps forMalewith average masks.We train models to predictMalewhenEyeglassesare absent (center-left) and present (center-right). There is a stark difference in the heatmaps, suggesting that the features used by the model for predictingEyeglassesare distinct from those used to predictMale, despite them being co-localized in the original models.",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/no_glasses_Male_heatmap.png",
                "caption": "",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/glasses_Male_heatmap.png",
                "caption": "",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/mask_eyeglasses.png",
                "caption": "",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x6.png",
                "caption": "Figure 8:Average heatmaps forMustache. We visualize average heatmaps forMustachefor images whereMustacheandMaleare labeled false (center-left), whereMustacheis labeled false andMaleis labeled true (center-right) and whereMustacheandMaleare labeled true (far right), and compare to theMaleheatmap (far left). WhenMaleis labeled as false,MustacheandMaleattention maps closely align but do not whenMaleis labeled true.",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x7.png",
                "caption": "",
                "position": 512
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x8.png",
                "caption": "",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x9.png",
                "caption": "",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x10.png",
                "caption": "Blond_HairœÑùúè\\tauitalic_œÑ: 0.073",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x10.png",
                "caption": "Blond_HairœÑùúè\\tauitalic_œÑ: 0.073",
                "position": 563
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x11.png",
                "caption": "Wavy_HairœÑùúè\\tauitalic_œÑ0.778",
                "position": 565
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AGradients for GradCAM",
        "images": []
    },
    {
        "header": "Appendix BProofs of Invariants",
        "images": []
    },
    {
        "header": "Appendix CSubsampling Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/x12.png",
                "caption": "Figure 10:Training set subgroup sizes under subsampling. Here we report subgroup sizes of the training set of varying MCCs forBlond_HairandWavy_HairwithMale, under our optimization scheme, to compute the results inSec.5.2andFig.9. Subgroup sizes are bounded to the smallest subsampled training set size. The legend shows the four different subgroups groups, with the first value indicating the target label and the secondMale.",
                "position": 2054
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x12.png",
                "caption": "",
                "position": 2057
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x13.png",
                "caption": "",
                "position": 2062
            }
        ]
    },
    {
        "header": "Appendix DAdditional CelebA Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_male.png",
                "caption": "Figure 11:Average heatmaps for CelebA attributes. We visualize average heatmaps for the selected attributes investigated inSec.5.2.",
                "position": 2075
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_wearing_lipstick.png",
                "caption": "",
                "position": 2084
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_eyeglasses.png",
                "caption": "",
                "position": 2088
            },
            {
                "img": "https://arxiv.org/html/2503.19846/extracted/6310543/figures/cam_mustache.png",
                "caption": "",
                "position": 2111
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x14.png",
                "caption": "Figure 12:Evaluation of mask score using GradCAM on CelebA test set with attribute-specific feature masks, compared to average precision. To compare per-attribute AP between attributes, we adopt Hoiemet al.‚Äôs normalized average precision (APNsubscriptAPN\\mathrm{AP_{N}}roman_AP start_POSTSUBSCRIPT roman_N end_POSTSUBSCRIPT) metric[25].",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x15.png",
                "caption": "Figure 13:EfficientNetV2 mask score on Waterbirds. The top bars indicate Attention-IoU mask scores for EfficientNetV2-S models, while the bottom bars are corresponding ResNet-50 scores from Fig.¬†3.\nWGA is for the EfficientNet model. As with ResNet, the EfficientNet models attend less to the bird and more to the background, mirroring the decrease in WGA.",
                "position": 2164
            },
            {
                "img": "https://arxiv.org/html/2503.19846/x16.png",
                "caption": "Figure 14:EfficientNetV2 heatmap scores on CelebA attributes.Orange/circle indicates results with EfficientNetV2-S models, and light blue/triangle are ResNet-50 results from Fig.¬†5. We observe a very similar trend in EfficientNetV2 to that of ResNet-50. Highlighted attributes maintain their relative position, with some movement owing to different architectures and pretraining weights.",
                "position": 2169
            }
        ]
    },
    {
        "header": "Appendix EEvaluating with EfficientNet",
        "images": []
    }
]