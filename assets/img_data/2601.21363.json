[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21363/figures/framework.png",
                "caption": "",
                "position": 144
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Large-scale Pretraining and Efficient Fine-tuning",
        "images": []
    },
    {
        "header": "5EXPERIMENTS",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21363/x1.png",
                "caption": "Figure 2:Results of finetuning Booster T1 robot with varying target speeds. The black dashed line represents the target velocity for each task. Results are averaged over 8 random seeds.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x2.png",
                "caption": "Figure 3:Real-world finetuning progression on the Booster T1 humanoid. A video demonstration is available on our project website.",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x3.png",
                "caption": "Figure 4:Ablation of the pretraining on Booster T1 (target forward speed=1.5=1.5\\,m/s).\nResults are averaged over 8 random seeds.",
                "position": 425
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x4.png",
                "caption": "Figure 5:Ablation of Physics informed World Model on Booster T1 (target speed=1.5=1.5\\,m/s). Results are averaged over 8 random seeds.",
                "position": 440
            }
        ]
    },
    {
        "header": "6Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.21363/x5.png",
                "caption": "Figure 6:Comparison of PPO and SAC in a preliminary fine-tuning experiment with the BoosterT1 robot, run for 48 hours on a single Brax simulation. The left figure shows the evaluation episode return, and the right figure shows the body’s linear velocity along thexx-axis. Curves represent the average over 8 random seeds, with evaluation performed in 128 parallel environments. PPO performance is highly sensitive to the initial action standard deviation (std). Replacing the PPO actor with a SAC-style actor that outputs both the mean and standard deviation improves stability, although SAC still requires fewer samples to achieve the same performance.",
                "position": 1018
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x6.png",
                "caption": "Figure 7:Pretraining performance comparison of LIFT (red), PPO (orange), and FastTD3 (blue) across six humanoid tasks (top row: rough terrain for the three robot configurations; bottom row: flat terrain for the three robot configurations). Results show the mean over 8 random seeds.",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x7.png",
                "caption": "Figure 8:Finetuning performance of LIFT in the Real-World. Across 3 random seeds, LIFT consistently improves episode return, forward velocity tracking, and angular-velocity tracking, while reducing the action-rate penalty. Note that the velocity tracking error (target at 0.6m/sm/s) might come from the noisy base-velocity estimation from the onboard IMU accelerator.",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x8.png",
                "caption": "Figure 9:Effect of pretraining hyperparameters on Low dimensional Booster T1. From left to right: UTD ratio, buffer size, and batch size. UTD values compared: 1, 5, 10, 15, 20; buffer sizes: 10,000, 100,000, 1,000,000; batch sizes: 256, 512, 1,024, 4,096, 8,192. Larger UTD and batch sizes accelerate convergence; increasing buffer size improves learning speed but at the cost of much higher GPU memory usage.",
                "position": 1041
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x9.png",
                "caption": "Figure 10:Impact of the entropy coefficientα\\alphaand autoregressive loss horizon on finetuning performance (Booster T1, target speed=1.5=1.5\\,m/s). Curves show evaluation episode return and body forward velocity. Largerα\\alphavalues degrade performance, leading to less stable convergence and lower final forward velocity. Using the pretrainingα\\alphagives reasonable results, while smallerα\\alphayields more stable learning. Horizon=1=1sometimes fails to reach the target velocity, while horizons=2=2and=4=4ensure stable convergence, indicating that multi-step autoregressive prediction improves world-model training and stabilizes policy finetuning.",
                "position": 1044
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x10.png",
                "caption": "Figure 11:Gaits of LIFT across different tasks in the MuJoCo Playground.",
                "position": 1052
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x11.png",
                "caption": "Figure 12:Sim-to-real reinforcement learning with LIFT.",
                "position": 1060
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x12.png",
                "caption": "Figure 13:Sim-to-real gait comparison in indoor and outdoor environments.",
                "position": 1063
            },
            {
                "img": "https://arxiv.org/html/2601.21363/figures/G1_brax.png",
                "caption": "Figure 14:Sim-to-sim transfer and fine-tuning results for the Unitree G1 in Brax with a target velocity of 1.5 m/s.Top:Policy before fine-tuning, exhibiting instability and shuffling gait.Bottom:Policy after fine-tuning, demonstrating a stable, human-like walking gait with reduced torso pitch.",
                "position": 1071
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x13.png",
                "caption": "Figure 15:Finetuning results on the Unitree G1 in Brax. LIFT consistently improves policy behavior and reward performance. At a target speed of 0.6 m/s, body oscillations are significantly reduced, while at 1.5 m/s, the policy initially exhibits unstable motion in sim2sim but, after finetuning, successfully stands and walks.",
                "position": 1074
            },
            {
                "img": "https://arxiv.org/html/2601.21363/x14.png",
                "caption": "Figure 16:Gaits of LIFT across different whole body motion tracking tasks in the MuJoCo Playground.",
                "position": 1088
            }
        ]
    },
    {
        "header": "Appendix BTraining Details",
        "images": []
    },
    {
        "header": "Appendix CEnvironment Setup",
        "images": []
    },
    {
        "header": "Appendix DLarge Language Model Usage",
        "images": []
    }
]