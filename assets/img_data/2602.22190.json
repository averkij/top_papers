[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/x1.png",
                "caption": "",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2602.22190/",
                "caption": "",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2602.22190/figs/UNC-NC-LOGO.png",
                "caption": "",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2602.22190/figs/main_idea.png",
                "caption": "Figure 1:Overview of GUI-Libra. Using only a subset of existing open-source GUI trajectories, we tackle key limitations of prior training pipelines through action-aligned reasoning data curation, action-aware SFT, and conservative RL, yielding consistent gains on online benchmarks.",
                "position": 264
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Reasoning Data Curation for GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/x3.png",
                "caption": "Figure 2:Example data format inGUI-Libra-81K. Each sample includes the current visual observation (screenshot) and textual context (system prompt, user instruction, and interaction history/previous actions). The model output is split into (1) a CoT reasoning trace and (2) a structured executable action (JSON), specifying the action type, a brief action description, the target element (if available), and action arguments such as text values or coordinates.",
                "position": 736
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x4.png",
                "caption": "Figure 3:(a)(b) Data source distribution for SFT and RL. (c) Action type distribution ofGUI-Libra-81K.\n(d) Comparison of step index distributions between our SFT and RL datasets.",
                "position": 785
            }
        ]
    },
    {
        "header": "5GUI-Libra",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/x5.png",
                "caption": "Figure 4:(a) Grounding accuracy on ScreenSpot-v2 versus response length for base models and CoT-SFT models, showing that overly long responses correlate with degraded grounding. (b) Average grounding accuracy under different SFT strategies, where excessively long reasoning traces lead to a substantial drop.",
                "position": 835
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x6.png",
                "caption": "Figure 5:Overall training framework of GUI-Libra: Stage 1 applies action-aware SFT with mixed supervision and token reweighting; Stage 2 performs KL-regularized GRPO with success-adaptive negative gradient scaling.",
                "position": 1197
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/x7.png",
                "caption": "Figure 6:Limitations of current offline benchmarks. (a) Symbolic action history not in natural language in MM-Mind2Web, (b) Action type mismatch and (c) coordinate mismatch in AndroidControl.",
                "position": 1236
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x8.png",
                "caption": "Figure 7:Trajectory Example of GUI-Libra-7B on AndroidWorld.",
                "position": 1735
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x9.png",
                "caption": "Figure 8:Grounding accuracy under different response lengths.\nAction-aware SFT strategies, including mixing direct-action data and weighted objectives, help preserve grounding accuracy under long CoT outputs.",
                "position": 2405
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x9.png",
                "caption": "Figure 8:Grounding accuracy under different response lengths.\nAction-aware SFT strategies, including mixing direct-action data and weighted objectives, help preserve grounding accuracy under long CoT outputs.",
                "position": 2407
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x10.png",
                "caption": "Figure 9:Comparison of training and evaluation metrics with and without KL regularization: (a) training reward, (b) policy entropy during training, (c) offline evaluation performance on AndroidControl-High, and (d) online evaluation performance on AndroidWorld.",
                "position": 2533
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x11.png",
                "caption": "Figure 10:(a) Correlation between offline and online performance. (b) Comparison of Pearson and Spearman correlations with and without KL regularization.",
                "position": 2546
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x12.png",
                "caption": "Figure 11:Ablation study of data filtering at the (a) SFT and (b) RL stages. Data filtering consistently improves both Pass@1 and Pass@4 performance across three benchmarks.",
                "position": 2556
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Related Works",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CBenchmark Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/x13.png",
                "caption": "Figure 12:RL for grounding exhibits stable improvements and strong cross-benchmark predictability. (a) ScreenSpot-V2 and (b) ScreenSpot-Pro performance over RL training. (c) Correlation between the two benchmark scores across checkpoints. (d) Pearson and Spearman correlations with and without KL regularization.",
                "position": 4711
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x14.png",
                "caption": "Figure 13:Performance comparison of different models for reasoning generation. All models are used to augment the same 30K web samples from AGUVIS and are fine-tuned on the same 3B base model. This controlled evaluation reveals substantial performance differences among generator models.",
                "position": 4714
            }
        ]
    },
    {
        "header": "Appendix EProofs for Theoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix FPrompt Templates",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.22190/figs/screenshot_1.png",
                "caption": "",
                "position": 6329
            },
            {
                "img": "https://arxiv.org/html/2602.22190/figs/screenshot2.png",
                "caption": "",
                "position": 6413
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x15.png",
                "caption": "Figure 14:Trajectory Example of GUI-Libra-7B for Task 18 ExpenseDeleteMultiple: Delete the following expenses from pro expense: School Supplies, Religious, Flight Tickets.",
                "position": 6501
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x16.png",
                "caption": "Figure 15:Trajectory Example of the base model Qwen2.5-VL-7B-Instruct for Task 18 ExpenseDeleteMultiple: Delete the following expenses from pro expense: School Supplies, Religious, Flight Tickets.",
                "position": 6504
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x17.png",
                "caption": "Figure 16:Trajectory Example of GUI-Libra-4B for WebArena-Lite-v2 Task:Follow [’lahwaacz’, ’Koushik’, ’Vinta Chen’] on Gitlab.",
                "position": 6507
            },
            {
                "img": "https://arxiv.org/html/2602.22190/x18.png",
                "caption": "Figure 17:Trajectory Example of Qwen3-VL-4B-Instruct for WebArena-Lite-v2 Task:Follow [’lahwaacz’, ’Koushik’, ’Vinta Chen’] on Gitlab.",
                "position": 6510
            }
        ]
    },
    {
        "header": "Appendix GLong-Horizon Trajectory Case Studies",
        "images": []
    }
]