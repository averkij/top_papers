[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13804/x1.png",
                "caption": "Figure 1:LEFT: In-context Transferability (ICT) reveals the clusters of benchmark tasks.We apply spectral clustering to ICT (arcs222Each arc connects a source task with a target task and has the same color as the source task.) between MMLU tasks (nodes), whose color denotes the cluster it belongs to. The discovered clusters are associated with explainable themes. The theme and tasks of each cluster are listed around the chord graph.\nOnly the top-7% arcs with the highest ICT values are shown in the graph, among which intra-cluster arcs are much more than inter-cluster arcs, implying a “sparse” topology captured by ICT.RIGHT: Evaluation accuracy of task reduction methods. Each method selects 3 out of the 57 tasks in MMLU to evaluate 9 LLMs (axes). The plot reports1−|σ−σ∗|/σ∗1𝜎superscript𝜎superscript𝜎1-\\nicefrac{{|\\sigma-\\sigma^{*}|}}{{\\sigma^{*}}}1 - / start_ARG | italic_σ - italic_σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT | end_ARG start_ARG italic_σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT end_ARGin log-scale whereσ𝜎\\sigmaitalic_σandσ∗superscript𝜎\\sigma^{*}italic_σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPTare the evaluation metrics on the reduced-benchmark and full-benchmark, respectively. Our method (BenTo-le) achieves 97% evaluation accuracy on average. The grey band reports the random selection baseline’s mean±standard variation. All baselines are defined inSection5.Table2reports the result when selecting different number of tasks.",
                "position": 67
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Task Transferability Analysis by In-Context Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13804/x2.png",
                "caption": "(a)S𝑆Sitalic_S, induced by ICL embeddingA𝐴Aitalic_A.",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2410.13804/x2.png",
                "caption": "(a)S𝑆Sitalic_S, induced by ICL embeddingA𝐴Aitalic_A.",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2410.13804/x3.png",
                "caption": "(b)S′superscript𝑆′S^{\\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, induced by LE embeddingA′superscript𝐴′A^{\\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT.",
                "position": 254
            }
        ]
    },
    {
        "header": "4Benchmark-Task Reduction (BenTo) by Facility Location",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13804/x4.png",
                "caption": "(a)ΔΔ\\Deltaroman_Δon MMLU.",
                "position": 639
            },
            {
                "img": "https://arxiv.org/html/2410.13804/x4.png",
                "caption": "(a)ΔΔ\\Deltaroman_Δon MMLU.",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2410.13804/x5.png",
                "caption": "(b)ΔΔ\\Deltaroman_Δon FLAN.",
                "position": 647
            },
            {
                "img": "https://arxiv.org/html/2410.13804/x6.png",
                "caption": "Figure 4:Ablation study on facility location (FL) vs. K-medoids: we report the best NRMSE (lower is better) achieved by each method on MMLU. KM denotes K-medoids. KM-raw, KM-sim and KM-le denote K-medoids on the raw feature matrixA𝐴Aitalic_A, similarity matrixS𝑆Sitalic_SandS′superscript𝑆′S^{\\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPTrespectively.",
                "position": 777
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BExperiment details",
        "images": []
    },
    {
        "header": "Appendix CStandard deviations of main results",
        "images": []
    },
    {
        "header": "Appendix DICL Prompts Example",
        "images": []
    },
    {
        "header": "Appendix EDetailed performance of each model",
        "images": []
    },
    {
        "header": "Appendix FResults on additional benchmarks",
        "images": []
    },
    {
        "header": "Appendix GPublicly reported results on MMLU and BBH",
        "images": []
    }
]