[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02368/x1.png",
                "caption": "Figure 1:Visualization of different decoding strategies in the output space. Given a query, the base policy generates outputs with suboptimal rewards (lighter regions). Guided decoding with an estimated value function shifts the distribution towards higher-reward regions, while the optimal value function would guide the policy to achieve maximum rewards (darkest regions).",
                "position": 188
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4IVO: Iterative Value Function Optimization",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02368/x2.png",
                "caption": "(a)Summarization",
                "position": 649
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x2.png",
                "caption": "(a)Summarization",
                "position": 652
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x3.png",
                "caption": "(b)Multi-turn Dialogue",
                "position": 657
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x4.png",
                "caption": "(a)Summarization",
                "position": 692
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x4.png",
                "caption": "(a)Summarization",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x5.png",
                "caption": "(b)Multi-turn Dialogue",
                "position": 700
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x6.png",
                "caption": "(c)Instruction Following",
                "position": 705
            }
        ]
    },
    {
        "header": "6Further Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02368/x7.png",
                "caption": "(a)Number of ST",
                "position": 787
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x7.png",
                "caption": "(a)Number of ST",
                "position": 790
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x8.png",
                "caption": "(b)Number of TI",
                "position": 795
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AValue Guided Blockwise Sampling For IVO",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02368/x9.png",
                "caption": "(a)Summarization",
                "position": 1649
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x9.png",
                "caption": "(a)Summarization",
                "position": 1652
            },
            {
                "img": "https://arxiv.org/html/2503.02368/x10.png",
                "caption": "(b)Multi-turn Dialogue",
                "position": 1657
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CGPT-4-as-the-judge Evaluation",
        "images": []
    },
    {
        "header": "Appendix DLimitations",
        "images": []
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    }
]