[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20172/x1.png",
                "caption": "",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20172/x2.png",
                "caption": "Figure 2:Overview Comparison.Among all types of works connecting LMM and diffusion model, ourDream Engineadopts the simplest design yet achieves the best performance.",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2502.20172/x3.png",
                "caption": "Figure 3:Dream Enginearchitecture.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20172/x4.png",
                "caption": "Figure 4:Performance demonstration on Natural Object Background Merging whereDream Enginecan understand complex text-image input. It can even set more than one object in the background (last line).",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2502.20172/x5.png",
                "caption": "Figure 5:Training stages and tasks ofDream Engine.",
                "position": 258
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20172/x6.png",
                "caption": "Figure 6:Performance demonstration on Object Driven Feature Mixing task.Dream Enginecan understand the complex instruction while Emu2-Gen fails on the task.",
                "position": 1199
            },
            {
                "img": "https://arxiv.org/html/2502.20172/x7.png",
                "caption": "Figure 7:Performance demonstration on Free Form Image Editing task.Dream Engineoutperforms the counterpart Emu2-Gen model in both instruction following and output image quality.",
                "position": 1202
            },
            {
                "img": "https://arxiv.org/html/2502.20172/x8.png",
                "caption": "Figure 8:Image reconstruction performance dynamics during training. We can see that there is a concept-to-detail transition during the training period.",
                "position": 1210
            },
            {
                "img": "https://arxiv.org/html/2502.20172/x9.png",
                "caption": "Figure 9:The ablation on visual blending ratio in the ViT module. It reveals that a higher blending ratio results in greater consistency during image reconstruction tasks.",
                "position": 1225
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]