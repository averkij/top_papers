[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/Figures/motivation.png",
                "caption": "Figure 1:Unifying Brain-Inspired and Generative Semantics for Episodic Memory ModelingThe hippocampal complex (DG, CA3, CA1) and neocortical regions (NC) inspire theReconciler(retrieval, workspace, update) andOperator(LLM-driven semantic role extraction), respectively. The neocortical complex, responsible for context-rich consolidation and predictive modeling, aligns with the Operator module’s functions. The hippocampal complex, which performs indexing, pattern separation, and sequence modeling, corresponds to the Reconciler. Together, the GSW framework offers a biologically inspired, interpretable model for simulating world knowledge from text inputs.",
                "position": 143
            }
        ]
    },
    {
        "header": "The Generative Semantic Workspace (GSW) Framework",
        "images": []
    },
    {
        "header": "Question Answering with GSW",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/x1.png",
                "caption": "Figure 2:Episodic Memory Creation and QA:Figure illustrates the end-to-end process of constructing a workspace and question answering from the workspace.(top)Large-scale text is segmented into semantically coherent chunks. Each chunk is processed by theOperatormodel to generate a local workspace instance, represented as a semantic graph. These instances are incrementally integrated by theReconcilerresulting in a unified Global Memory.(bottom)During question answering, the system retrieves relevant portions of this memory by matching named entities in the query to identifiers in the semantic network. For each match, it reconstructs episodic summaries—contextual recreations of past situations—which are re-ranked and passed to an LLM to generate the final answer.",
                "position": 329
            }
        ]
    },
    {
        "header": "Results and Discussion",
        "images": []
    },
    {
        "header": "Related Work",
        "images": []
    },
    {
        "header": "Concluding Remarks and Limitations",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix APrompts to the LLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/x2.png",
                "caption": "Figure 3:LLM prompt for Operator extraction.444Background context generated according to contextual chunking by Anthropic, seehttps://www.anthropic.com/news/contextual-retrieval.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x3.png",
                "caption": "Figure 4:LLM prompt for Space Time coupling.",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x4.png",
                "caption": "Figure 5:LLM prompt for QA reconciliation.",
                "position": 838
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x5.png",
                "caption": "Figure 6:LLM prompt for entity summary generation.",
                "position": 849
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x6.png",
                "caption": "Figure 7:LLM prompt for final Question Answering.",
                "position": 854
            }
        ]
    },
    {
        "header": "Appendix BExample GSW instance",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/x7.png",
                "caption": "Figure 8:Operator example:Operator instances of two different chunks, as the GSW framework processes a story.",
                "position": 867
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x8.png",
                "caption": "",
                "position": 872
            },
            {
                "img": "https://arxiv.org/html/2511.07587/x9.png",
                "caption": "",
                "position": 875
            }
        ]
    },
    {
        "header": "Appendix CGSW QA Example",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/x10.png",
                "caption": "Figure 11:Illustrative example of the GSW QA framework:First, NER is performed on the input query to identify key entities. In this version of QA implementation these extracted entities are matched to the relevant GSW instances of chapters via string matching, and the entity-specific summaries (see AppendixE) from the GSWs are retrieved. Subsequently, these retrieved entity summaries are re-ranked based on their semantic similarity to the input query—a score calculated using cosine similarity between their embeddings and the query’s embedding. The figure displays a selection of initially retrieved summaries followed by the top re-ranked summaries. Finally, these re-ranked summaries are passed to an answering LLM, which then produces the final answer. As our considerably smaller average token count shows, our entity summaries are already concise, and only entity-relevant chapters are retrieved. Future implementations could leverage several avenues for further reduction in token counts without compromising performance. For example, in a query involving multiple entities, GSWs that have all the entities could be retrieved and sent to the LLM for a final answer; currently our re-ranking step ranks them at the top but we send summaries from other chapters as well, which is not necessary.",
                "position": 886
            }
        ]
    },
    {
        "header": "Appendix DQualitative Analysis of GSW performance",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details",
        "images": []
    },
    {
        "header": "Appendix FAblation Studies",
        "images": []
    },
    {
        "header": "Appendix GRelated work on Memory Augmentation for LLMs",
        "images": []
    },
    {
        "header": "Appendix HComputational Costs and Resources for Building the GSW",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07587/Figures/operatorv2.png",
                "caption": "Figure 12:Annotator instructions for UpWork Task:Annotators are asked to compare the outputs of the Operator to the Semantic map output by a baseline framework (either GLEN, BertSRL, FST) given a shared input text context. During annotation, one random baseline map and the Operator output are presented in random order and the annotator is asked to pick the representation of the Semantics that best reflects the information in the context.",
                "position": 2123
            }
        ]
    },
    {
        "header": "Appendix IRelated Computational Models of Semantics",
        "images": []
    }
]