[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x1.png",
                "caption": "Figure 1:Top:\nTo answer the elementary school-level math problem, LRM (QwQ-32B) consumes altogether 1248 tokens, while the instruct LLM counterpart (Qwen2.5-32B-Instruct) only needs 30 tokens.Bottom: The distribution of generation length of two models on a mixed set of math problems sourced from GSM8K, MATH-500, and AIME 2024.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2503.21614/x2.png",
                "caption": "Figure 2:In this paper, we comprehensively study methods for efficient reasoning from the stages of Per-training, Supervised Fine-tuning (SFT), Reinforcement Learning (RL), and Inference.",
                "position": 197
            }
        ]
    },
    {
        "header": "2Reasoning Efficiency: Definition, Patterns, and Challenges",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x3.png",
                "caption": "Figure 4:To translate a single Chinese sentence (“How to think efficiently?”) into English, recent LRM consumes more than 2000 tokens to reason.",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2503.21614/x4.png",
                "caption": "Figure 5:Illustration of efficient reasoning during inference. (1)Length Budgetinglimits intermediate tokens to reduce overhead; (2)System Switchdynamically alternates between fast, intuitive and slow, deliberate reasoning; (3)Model Switchdirects queries to optimal models based on task difficulty; (4)Parallel Searchgenerates and prunes candidate outputs concurrently to cut latency.",
                "position": 733
            }
        ]
    },
    {
        "header": "3Efficient Reasoning during Inference",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x5.png",
                "caption": "Figure 6:Illustration of efficient reasoning during SFT. (a)Original SFT:Standard training with sequential token generation. (b)Reasoning Chain Compression:Training with token skipping to simplify reasoning. (c)Latent-Space SFT:Iterative training using continuous hidden states for more efficient reasoning.",
                "position": 860
            }
        ]
    },
    {
        "header": "4Efficient Reasoning with SFT",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x6.png",
                "caption": "Figure 7:Illustration of efficiency training during the RL phase. Sub-Figures (a) and (b) illustrate the representative approach using length reward and not using length reward, respectively.",
                "position": 917
            }
        ]
    },
    {
        "header": "5Efficient Reasoning with Reinforcement Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x7.png",
                "caption": "Figure 8:Illustration of efficient reasoning during pretraining: (a) Standard transformer pretraining utilizing text tokens; (b) Pretraining the transformer in latent space; (c) Employing linear models for pretraining instead of self-attention transformers; (d) Linearization methods that transform standard transformer models into linear models.",
                "position": 1177
            }
        ]
    },
    {
        "header": "6Efficient Reasoning during Pretraining",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21614/x8.png",
                "caption": "Figure 9:An example of multimodal reasoning where inefficiencies arise in the thought process. This problem involves reasoning with both a velocity-time graph and a map of towns and highways. Despite the multimodal inputs, the thought process is inefficient due to redundant repetition, unnecessary diversions, and excessive doubt, ultimately leading to a more complex and less efficient path to the correct answer.",
                "position": 1241
            }
        ]
    },
    {
        "header": "7Future Directions",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]