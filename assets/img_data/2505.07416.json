[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/1.jpg",
                "caption": "Table1:An illustrative example of the MRHP task and our ViMRHP dataset.",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/2.jpg",
                "caption": "",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/3.jpg",
                "caption": "",
                "position": 166
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/4.jpg",
                "caption": "",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/5.jpg",
                "caption": "",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/6.jpg",
                "caption": "",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/7.jpg",
                "caption": "",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/cry.jpg",
                "caption": "",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/t.png",
                "caption": "",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/R1_1.png",
                "caption": "",
                "position": 204
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/R2_1.png",
                "caption": "",
                "position": 211
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/R2_2.png",
                "caption": "",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/R3_1.jpg",
                "caption": "",
                "position": 219
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/R3_2.jpg",
                "caption": "",
                "position": 220
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Human-AI Collaborative Annotation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07416/x1.png",
                "caption": "Figure1:ViMRHP benchmark dataset annotation overview. The Human-AI collaborative annotation framework workflow includes two steps: (1) AI Annotation→→\\rightarrow→(2) Human Verification and Refinement. First, AI extracts the relevant context or gives a reason from the review based on the given instruction criteria and assigns a score. Then, human annotators verify and refine the final score to ensure data quality.",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/ExAnnot/Ex1.png",
                "caption": "Table4:Example annotation for ViMRHP Dataset",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/ExAnnot/Ex2.png",
                "caption": "",
                "position": 618
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/ExAnnot/Ex3.png",
                "caption": "",
                "position": 619
            }
        ]
    },
    {
        "header": "4ViMRHP Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/Plot/HelpfulnessScoreFashion.png",
                "caption": "(a)Fashion Category",
                "position": 858
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/Plot/HelpfulnessScoreFashion.png",
                "caption": "(a)Fashion Category",
                "position": 861
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/Plot/HelpfulnessScoreElectronic.png",
                "caption": "(b)Electronic Category",
                "position": 866
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/Plot/HelpfulnessScoreHomeLifestyle.png",
                "caption": "(c)Home & Lifestyle Category",
                "position": 872
            },
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/Plot/HelpfulnessScoreHealth_Beauty.png",
                "caption": "(d)Health & Beauty Category",
                "position": 877
            }
        ]
    },
    {
        "header": "5Experimental Setup",
        "images": []
    },
    {
        "header": "6Results",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "Appendix 0.ALabeling UI",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07416/extracted/6431125/Images/LabelingUI.png",
                "caption": "Figure3:Labeling UI for ViMRHP dataset",
                "position": 1366
            }
        ]
    },
    {
        "header": "Appendix 0.BInstruction",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]