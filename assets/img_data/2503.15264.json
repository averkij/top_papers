[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15264/x1.png",
                "caption": "Figure 1:Comparison with Existing Image Forgery Detection Methods. LEGION not only serves as aDefender, enabling multi-task forgery analysis, but also functions as aController, facilitating high-quality image generation.",
                "position": 114
            },
            {
                "img": "https://arxiv.org/html/2503.15264/x2.png",
                "caption": "Figure 2:SynthScars Datasets.(a)shows image cases across four diverse content types.(b)presents annotation cases across different fine-grained artifact types.(c)enumerates drawbacks of previous datasets, which SynthScars perfectly addresses.",
                "position": 168
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3SynthScars Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15264/x3.png",
                "caption": "Figure 3:Architecture Overview.(a)Our proposed framework for image forgery analysis, LEGION.(b)and(c)shows two pipelines for image generation. T2I in (b) is short fortext-to-image, and Loca. and Expla. in (c) denotesLocationandExplanation, respectively.",
                "position": 402
            }
        ]
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15264/x4.png",
                "caption": "Figure 4:Comparison of artifact segmentation and explanations across different methods: PAL4VST, InternVL2-8B, and our proposed LEGION, alongside the ground truth.",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2503.15264/x5.png",
                "caption": "Figure 5:Case studies of Image Regeneration.(Top)Style Distortion Adjustment,(Bottom)Detailed Structure Reshape.",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2503.15264/x6.png",
                "caption": "Figure 6:Case Study of Image Inpainting.",
                "position": 1800
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Appendix",
        "images": []
    },
    {
        "header": "Appendix ASynthScars Dataset",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    },
    {
        "header": "Appendix CRobustness Study",
        "images": []
    },
    {
        "header": "Appendix DMore Visual Examples",
        "images": []
    },
    {
        "header": "Appendix ELimitations and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15264/x7.png",
                "caption": "Figure 7:More Visualization of Artifact Segmentation Masks and Corresponding Explanations for Identified Artifacts. The figure illustrates a qualitative comparison between the ground truth (Top row) and the corresponding predictions obtained from our proposed model (Bottom row).",
                "position": 2478
            },
            {
                "img": "https://arxiv.org/html/2503.15264/x8.png",
                "caption": "Figure 8:Examples of failures in complex scenes and intricate small artifacts.Each case includes artifacts segmentation mask and corresponding explanations. The first row depicts the ground truth, while the second row shows the corresponding predictions generated by our model.",
                "position": 2481
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]