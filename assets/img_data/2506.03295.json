[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03295/x1.png",
                "caption": "Figure 1:One-shot CFT consistently improves mathematical and logical reasoning.Left:Average accuracy (%) on six mathematical reasoning benchmarks for Qwen and Llama models, comparing base, SFT, RLVR, and CFT with only one training example.Right:In-domain accuracy (%) on three logic reasoning benchmarks (BBEH subtasks) for Qwen2.5-Math-7B.\nAcross both domains, CFT with a single problem significantly outperforms standard supervised fine-tuning and matches or exceeds reinforcement learning with much lower compute.",
                "position": 139
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03295/extracted/6509550/figures/method_0601_1.png",
                "caption": "Figure 2:Overview of the 1-shot CFT dataset construction and the key difference between SFT and CFT training.Top:Candidate solutions to a single math problem are generated, critiqued, and filtered to form the training set.Bottom:Comparison of training paradigms:(left)SFT supervises the model to generate the reference solution;(right)CFT trains the model to critique a candidate solution, encouraging deeper reasoning and error analysis.",
                "position": 175
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03295/x2.png",
                "caption": "Figure 3:Comparison between Supervised Fine-Tuning (SFT) and Critique Fine-Tuning (CFT). SFT generates solutions directly, while CFT critiques candidate solutions for correctness.",
                "position": 235
            }
        ]
    },
    {
        "header": "4Experiments on Math Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03295/extracted/6509550/figures/7B_curve.png",
                "caption": "Figure 4:Comparing Model accuracy on Math-500, v.s. the training cost. For the Qwen2.5-Math-7B trained with 1-shot RL and 1-shot CFT.",
                "position": 909
            }
        ]
    },
    {
        "header": "5Experiments on Logic Reasoning",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]