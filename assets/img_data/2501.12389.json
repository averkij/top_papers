[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12389/x1.png",
                "caption": "Figure 1:Conceptual comparison ofmasked teacher forcingand our proposedcomplete teacher forcingmechanisms in auto-regressive video generation.The blocks here illustrate individual frames.\nThese two mechanisms differ in how history observation frames are used to condition next frame generation during training.(a):The observation frames aremasked frames[12,2]that arepartiallyobservable.(b):Every frame is generated conditioned onfullyobservable history frames.",
                "position": 231
            }
        ]
    },
    {
        "header": "2Background and Problem Statement",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12389/x2.png",
                "caption": "Figure 2:Overview of MAGI video generation framework. MAGI receives observation frames and corresponding masked frames as inputs, enabling autoregressive video generation with Complete Teacher Forcing (Sec.3).",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2501.12389/x3.png",
                "caption": "Figure 3:Temporal attention maskin our CTF during training.\nThe attention within observation framescausal, while the attention within masked frames areatrous.\nIn this fashion, each masked frame attends to itself and unmasked history observation frames. During inference, a standard causal mask is employed, where each frame attends only to previously generated frames.",
                "position": 357
            }
        ]
    },
    {
        "header": "4Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12389/x4.png",
                "caption": "Figure 4:Case Study of Proposed Training Techniques:This figure evaluates the impact of dynamic interval training and dynamic noise injection on CTF and MTF by: 1) visualizing CTF with and without these strategies; and 2) comparing CTF and MTF when both use them. All methods perform first-frame conditional video prediction on UCF-101[31]. The results demonstrate the efficacy of the proposed training strategies and the superior motion and temporal coherence of CTF.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2501.12389/x5.png",
                "caption": "(a)Speed comparison.",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2501.12389/x5.png",
                "caption": "(a)Speed comparison.",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2501.12389/x6.png",
                "caption": "(b)MTFv.s.CTF.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2501.12389/x7.png",
                "caption": "(c)Ablation on first-frame conditional generation.",
                "position": 444
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12389/x8.png",
                "caption": "Figure 6:Long-term Video Prediction. MAGI predicts over 100 frames from a single input frame, maintaining reasonable motion even when trained on only 16 frames.",
                "position": 779
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.12389/x9.png",
                "caption": "Figure 7:Case Study: Video Prediction on Kinetics-600. MAGI generates high-quality future frames conditioned on past frames.",
                "position": 1489
            }
        ]
    },
    {
        "header": "Appendix BFuture Work",
        "images": []
    }
]