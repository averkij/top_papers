[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x1.png",
                "caption": "Figure 1:(a)\\oursimplements image-caption synthesis pipelines for six composite image types. The composition of the curated\\ours-118K dataset are 42.3% Collage, 31.4% Image-Text, 18.7% Chart, 3.4% Table, 2.5% Diagram, and 1.7% Code.(b)Introducing\\ours-118K into the training data significantly improves MLLMsâ€™ performance on benchmarks comprising of composite images.",
                "position": 176
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x2.png",
                "caption": "Figure 2:MLLMs demonstrate poorer understanding on CIs compared to NIs.(a)Example of assessing caption accuracy of MLLMs on CI with the help of LLMs.(b)MLLMs generally understand NIs much better than CIs.(c)Errors generated during captioning are consistent with errors generated in VQA, highlighting the necessity of caption data for better vision-language alignment",
                "position": 199
            }
        ]
    },
    {
        "header": "2MLLMs Need Good CI Caption Data",
        "images": []
    },
    {
        "header": "3\\ours",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x3.png",
                "caption": "Figure 3:The\\oursFramework.The synthesis pipeline for different CI types implements\\oursdifferently.",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x4.png",
                "caption": "Figure 4:The Collage implementation.We sample raw data from image-caption datasets and randomly generate a layout for the selected images. The images are then arranged into a collage following this layout, while an LLM generates a caption for the collage given both the layout details and captions of the individual images.",
                "position": 335
            }
        ]
    },
    {
        "header": "4Training MLLMs with\\oursData",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x5.png",
                "caption": "",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x6.png",
                "caption": "Figure 6:Example of MLLMs on CI captioning:Informative content is highlighted in red if incorrect, in orange if correct but incomplete, and in blue if correct and complete.",
                "position": 955
            }
        ]
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACI Implementations of\\ours",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x7.png",
                "caption": "Figure 7:Layout examples of grid collage and auto collage.",
                "position": 1986
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x8.png",
                "caption": "Figure 8:Prompt design and response example for grid layout.",
                "position": 2008
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x9.png",
                "caption": "Figure 9:Prompt design and response example for auto layout.",
                "position": 2011
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x10.png",
                "caption": "Figure 10:The Image-Text implementation.",
                "position": 2014
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x11.png",
                "caption": "Figure 11:Prompt for generating related text from given image.",
                "position": 2039
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x12.png",
                "caption": "Figure 12:Prompt design and response example for bar chart.",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x13.png",
                "caption": "Figure 13:Prompt design and response example for line plot.",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x14.png",
                "caption": "Figure 14:Prompt design and response example for pie chart.",
                "position": 2345
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x15.png",
                "caption": "Figure 15:Prompt design and response example for choropleth map.",
                "position": 2349
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x16.png",
                "caption": "Figure 16:The Diagram implementation.",
                "position": 2361
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x17.png",
                "caption": "Figure 17:Caption design for code screenshot.",
                "position": 2425
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x18.png",
                "caption": "Figure 18:Caption design for table image.",
                "position": 2428
            }
        ]
    },
    {
        "header": "Appendix BExperiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/x19.png",
                "caption": "",
                "position": 2571
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x20.png",
                "caption": "Figure 20:Examples of ChartQA captions",
                "position": 2669
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.05243/extracted/6046541/images/s0.png",
                "caption": "Table 11:Ablation study on train data samplers.",
                "position": 3332
            },
            {
                "img": "https://arxiv.org/html/2412.05243/extracted/6046541/images/s1.png",
                "caption": "",
                "position": 3439
            },
            {
                "img": "https://arxiv.org/html/2412.05243/extracted/6046541/images/s5.png",
                "caption": "",
                "position": 3469
            },
            {
                "img": "https://arxiv.org/html/2412.05243/extracted/6046541/images/unif.png",
                "caption": "",
                "position": 3499
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x21.png",
                "caption": "Figure 21:Diversity analysis of captions for different CI types.",
                "position": 3700
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x22.png",
                "caption": "",
                "position": 3704
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x23.png",
                "caption": "",
                "position": 3711
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x24.png",
                "caption": "",
                "position": 3712
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x25.png",
                "caption": "",
                "position": 3719
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x26.png",
                "caption": "",
                "position": 3720
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x27.png",
                "caption": "Figure 22:Image and caption examples of collage in\\ours-118K",
                "position": 3736
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x28.png",
                "caption": "Figure 23:Image and caption examples of image-text in\\ours-118K",
                "position": 3739
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x29.png",
                "caption": "Figure 24:Image and caption examples of chart in\\ours-118K",
                "position": 3742
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x30.png",
                "caption": "Figure 25:Image and caption examples of diagram in\\ours-118K",
                "position": 3745
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x31.png",
                "caption": "Figure 26:Image and caption examples of table in\\ours-118K",
                "position": 3748
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x32.png",
                "caption": "Figure 27:Image and caption examples of code in\\ours-118K",
                "position": 3751
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x33.png",
                "caption": "Figure 28:More examples of MLLMs on CI captioning (part 1).",
                "position": 3763
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x34.png",
                "caption": "Figure 29:More examples of MLLMs on CI captioning (part 2).",
                "position": 3766
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x35.png",
                "caption": "Figure 30:More examples of MLLMs on CI captioning (part 3).",
                "position": 3769
            },
            {
                "img": "https://arxiv.org/html/2412.05243/x36.png",
                "caption": "Figure 31:More examples of MLLMs on CI captioning (part 4).",
                "position": 3772
            }
        ]
    },
    {
        "header": "Appendix DQualitative Examples",
        "images": []
    }
]