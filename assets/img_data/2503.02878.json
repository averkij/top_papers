[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02878/x1.png",
                "caption": "Figure 1:Self-taught lookahead self-improves the value model by learning from state-transition dynamics. During the data generation phase (top left), tree search is used to discover diverse states. For every observed statesğ‘ sitalic_sencountered during the search, successor states are expanded using base policyÏ€Î¸subscriptğœ‹ğœƒ\\pi_{\\theta}italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPTand the current value modelVÏ•ksubscriptğ‘‰subscriptitalic-Ï•ğ‘˜V_{\\phi_{k}}italic_V start_POSTSUBSCRIPT italic_Ï• start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT, and a formatted textual training example is formed using verbal representations of the next best action and successor state, as well asVÏ•ksubscriptğ‘‰subscriptitalic-Ï•ğ‘˜V_{\\phi_{k}}italic_V start_POSTSUBSCRIPT italic_Ï• start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPTâ€™s outputted value reasoning (rğ‘Ÿritalic_r) and numerical value (vğ‘£vitalic_v) (top middle). These examples are used to fine-tuneVÏ•k+1subscriptğ‘‰subscriptitalic-Ï•ğ‘˜1V_{\\phi_{k+1}}italic_V start_POSTSUBSCRIPT italic_Ï• start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT, which will be used in the next iteration of the algorithm (top right). Value models learned during self-taught lookahead can be used to evaluate unseen states encountered during search on unseen tasks by simulating a step of lookahead including the next best action and the best successor states~â€²superscript~ğ‘ â€²\\tilde{s}^{\\prime}over~ start_ARG italic_s end_ARG start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT(bottom).",
                "position": 154
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Better State-Value Estimation with Self-Taught Lookahead",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02878/x2.png",
                "caption": "Figure 2:Breadth-first search performance onGame-of-24task on sets of tasks both seen and unseen during the self-improvement.",
                "position": 791
            },
            {
                "img": "https://arxiv.org/html/2503.02878/x3.png",
                "caption": "Figure 3:Compute and environmental efficiency during evaluation onWebShopwith agpt-3.5-turbopolicy. Compute efficiency is measured in total (prompt and completion) tokens broken down by model type (closed and open source). Environmental efficiency is measured by the number of states expanded (webpages visited).",
                "position": 814
            }
        ]
    },
    {
        "header": "5Efficiency Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02878/x4.png",
                "caption": "Figure 4:Tradeoff between performance and efficiency onWebShopwith agpt-3.5-turbopolicy. Pareto frontiers of existing methods and baselines are shown, illustrating the optimality of STL when considering the tradeoff between cost and average reward(top), environmental usage and average reward(middle), and cost and success rate(bottom).",
                "position": 832
            },
            {
                "img": "https://arxiv.org/html/2503.02878/x5.png",
                "caption": "Figure 5:STL scaling trends onWebShopforllama-3andqwen-2.5model families when using agpt-3.5-turbopolicy with performance measured by average reward(top)and success rate(bottom).",
                "position": 854
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASelf-Taught Lookahead Algorithm",
        "images": []
    },
    {
        "header": "Appendix BSelf-Taught Lookahead onWebShop",
        "images": []
    },
    {
        "header": "Appendix CMath Tasks",
        "images": []
    },
    {
        "header": "Appendix DModel Fine-tuning and Serving",
        "images": []
    },
    {
        "header": "Appendix ESignificance Testing",
        "images": []
    }
]