[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16815/x1.png",
                "caption": "Figure 1:We introduce ThinkAct, a reasoning VLA framework capable of thinking before acting. Through reasoning reinforced by ouraction-aligned visual feedback, ThinkAct enables capabilities of few-shot adaptation, long-horizon planning, and self-correction in embodied tasks.",
                "position": 173
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16815/x2.png",
                "caption": "Figure 2:Overview of our ThinkAct.(a) Given observationotsubscriptùëúùë°o_{t}italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand instructionlùëôlitalic_l, ThinkAct advancesaction-alignedrewards derived from visual trajectoryœÑùúè\\tauitalic_œÑto incentivize embodied reasoning capability of Reasoning MLLM‚Ñ±Œ∏subscript‚Ñ±ùúÉ\\mathcal{F}_{\\theta}caligraphic_F start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPT. (b) Conditioned on the visual plan latentctsubscriptùëêùë°c_{t}italic_c start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, the DiT-based Action ModelœÄœïsubscriptùúãitalic-œï\\pi_{\\phi}italic_œÄ start_POSTSUBSCRIPT italic_œï end_POSTSUBSCRIPTlearns to predict executable action while keeping‚Ñ±Œ∏subscript‚Ñ±ùúÉ\\mathcal{F}_{\\theta}caligraphic_F start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPTfrozen. Note that, during inference,œÄœïsubscriptùúãitalic-œï\\pi_{\\phi}italic_œÄ start_POSTSUBSCRIPT italic_œï end_POSTSUBSCRIPTand‚Ñ±Œ∏subscript‚Ñ±ùúÉ\\mathcal{F}_{\\theta}caligraphic_F start_POSTSUBSCRIPT italic_Œ∏ end_POSTSUBSCRIPTcould operate asynchronously to enable slow thinking and fast control for VLA reasoning tasks.",
                "position": 248
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16815/x3.png",
                "caption": "Figure 3:Qualitative results of intermediate reasoning steps and visualized trajectory for robot manipulation tasks on SimplerEnv and LIBERO benchmarks.",
                "position": 988
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x4.png",
                "caption": "Figure 4:Qualitative comparison of reasoning process and the derived answer for our ThinkAct with and without RL for embodied reasoning tasks on RoboVQA and OpenEQA benchmarks.Reddenotes incorrect reasoning and answers, whilegreenindicates correct ones.",
                "position": 991
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x5.png",
                "caption": "Table 3:Quantitative ablation study for our proposed RL rewards in ThinkAct on SimplerEnv, EgoPlan-Bench2, and RoboVQA benchmarks.",
                "position": 1019
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x5.png",
                "caption": "Figure 5:Few-shot adaptation results on LIBERO. We use 10 demonstrations per task for fine-tuning.",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x6.png",
                "caption": "Figure 6:Demonstration of self-reflection and correction capability of ThinkAct. The robot accidentally drops the target object midway. The reasoning MLLM identifies the failure and generates a revised plan that guides the gripper back to regrasp the object.",
                "position": 1085
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experimental Setup",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16815/x7.png",
                "caption": "Figure A7:Qualitative comparison of reasoning process and the derived answer for our ThinkAct with and without RL for embodied reasoning tasks on EgoPlan-Bench2 benchmark.Reddenotes the incorrect reasoning and answer, whilegreenindicates the correct one.",
                "position": 1300
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x8.png",
                "caption": "Figure A8:More Demonstrations of self-reflection and correction capability of ThinkAct.",
                "position": 1323
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x9.png",
                "caption": "Table A6:Quantitative ablation study for our proposed RL rewards in ThinkAct on LIBERO and OpenEQA benchmarks.",
                "position": 1569
            },
            {
                "img": "https://arxiv.org/html/2507.16815/x9.png",
                "caption": "Figure A9:5-shot adaptation results on LIBERO.",
                "position": 1623
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]