[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12880/x1.png",
                "caption": "",
                "position": 138
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12880/x2.png",
                "caption": "Figure 2:An illustration of our guidance mechanism on the generation quality manifold.The current state of generation (MtM_{t}, orange wireframe) is guided towards the next state (Mt−1M_{t-1}). Original CFG provides a strong but suboptimal direction (gray arrow), failing to precisely target the high-quality region (yellow peak).S2S^{2}-Guidance refines this by computing a self-corrective prediction from a stochastically block-dropping strategy (Pred w/ Stoc. drop, blue arrow).\nThe resultingS2S^{2}-Guidance vector (purple arrow) steers the update towards the optimal region of the generation manifold, resulting in higher-fidelity outputs.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x3.png",
                "caption": "Figure 3:S2S^{2}-Guidance successfully balances guidance strength and distribution fidelity.Comparison on 1D (top) and 2D (bottom) toy examples.\nUnlike CFG, which distorts the sample distribution (see red boxes), or other methods that fail to separate modes,S2S^{2}-Guidance accurately captures both the location and shape of the ground truth distributions (semi-transparent).",
                "position": 192
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12880/x4.png",
                "caption": "Figure 4:S2S^{2}-Guidance resolves the critical trade-off between guidance strength and sample fidelity on CIFAR-10.This t-SNE visualization compares the feature distributions of generated samples (points) against the real data distribution (shaded contours).\nWhile standard CFG (b) achieves class separation at the cost of severe distributional collapse,S2S^{2}-Guidance (e) simultaneously ensures strong separation and preserves the high-fidelity structure of the real data distribution.\nSubfigure (f) provides corresponding qualitative visualizations, where each row (top to bottom) matches the methods in (a-e).",
                "position": 247
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12880/x5.png",
                "caption": "Figure 5:S2S^{2}-Guidance consistently generates superior images in both aesthetic quality and prompt coherence.While existing guidance methods like CFG, APG, CFG++, and Zero (CFG-Zero) often produce artifacts, distorted objects, or fail to follow complex prompts (see red boxes), our approach yields clean, coherent, and visually pleasing results without such flaws.",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x6.png",
                "caption": "Figure 6:S2S^{2}-Guidance generates temporally coherent and physically plausible videos, overcoming key failures of CFG.Top Row:CFG struggles with plausible motion, depicting a truck that unnaturally slides sideways instead of driving forward (red boxes). Our method renders a stable and realistic scene.Bottom Row:CFG fails to capture the full prompt, as the light does not weave “around her face” (red box) and lacks “glowing particles” (blue box).S2S^{2}-Guidance faithfully produces a dynamic, visually rich scene adhering to the complex description.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x7.png",
                "caption": "Figure 7:S2S^{2}-Guidance consistently improves aesthetic scores and is robust to the guidance scale.Left:Our method outperforms CFG across all guidance scales (λ\\lambda).Right:Analysis of the impact of our S2Scale (ω\\omega) on aesthetic scores.",
                "position": 787
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "Overview",
        "images": []
    },
    {
        "header": "Appendix BExtended Discussion and Analysis of Our Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.12880/x8.png",
                "caption": "Figure 8:Aesthetic score gains brought by increasing the number of forward passes with stochastic block dropping at each time step.",
                "position": 2005
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x9.png",
                "caption": "Figure 9:Visualization of Denoising Trajectories on the 1D Bimodal Gaussian Data.Each panel shows the paths taken by different guidance methods to generate samples targeting the ground truth modes at -4 and 4. The y-axis represents the denoising timestep (from start to end), and the x-axis shows the predicted sample value. While standard CFG and Autoguidance improve upon the unguided baseline, they consistently fail to reach the ground truth. In contrast, bothNaive S²-Guidanceand our finalS²-Guidancemethod successfully steer the generation process to the correct endpoints.\nThe more direct paths of our methods indicate a more efficient and accurate guidance signal throughout the entire denoising process.",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x10.png",
                "caption": "Figure 10:More Visual Comparisons of Naive S²-Guidance and S²-Guidance on the 2D Gaussian Mixture.Left: Naive S²-Guidance. Right: S²-Guidance. Each row corresponds to a different random seed. The generated sample distributions are virtually identical, demonstrating that the performance gain from the computationally intensive naive approach is minimal. This justifies our adoption of the more efficient S²-Guidance method.",
                "position": 2077
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x11.png",
                "caption": "Figure 11:Human preference evaluation results forS2S^{2}-Guidance against baseline methods.The bar charts show the percentage of times each method was selected as the best for three criteria: Detail Preservation, Color Consistency, and Image-Text Alignment, along with an Overall aggregated score. Our method,S2S^{2}-Guidance, is significantly preferred by human evaluators across all categories, achieving a preference rate of over 29% in every dimension and surpassing 30% overall. This demonstrates its robust ability to generate perceptually superior images.",
                "position": 2205
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x12.png",
                "caption": "Figure 12:Qualitative comparison ofS2S^{2}-Guidance with baseline methods.Our method consistently generates images with superior visual quality, better prompt alignment, and fewer artifacts across a variety of prompts.\nFor instance,S2S^{2}-Guidance excels at stylistic replication (row 4), complex concept combinations (row 5).",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2508.12880/x13.png",
                "caption": "Figure 13:Further qualitative comparisons ofS2S^{2}-Guidance against baseline methods.Our approach demonstrates robust improvements in both prompt fidelity and aesthetic quality.\nKey advantages include accurate attribute binding (e.g., ”oval sink and rectangular mirror” in row 2), faithful character and style generation (rows 3, 4, 5), and superior handling of lighting and composition (rows 6, 7).S2S^{2}-Guidance consistently avoids the conceptual blending and visual artifacts that affect other methods.",
                "position": 2348
            }
        ]
    },
    {
        "header": "Appendix CMore Details About Our Experiments",
        "images": []
    }
]