[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04884/x1.png",
                "caption": "Figure 1:Reinforced Attention Learningformulates internal attention distributions as a policy.Unlike traditional methods that optimize next-token probabilities (“what to generate”), our approach prioritizes the selective allocation of information (“where to focus”). By optimizing for the advantage, the model explores a high-reward attention policy that effectively isolates salient information from dense contexts.",
                "position": 158
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Reinforced Attention Learning",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04884/x2.png",
                "caption": "Figure 2:Sample data of the SFT and RL training stages.The SFT stage adapts the model to a “think-and-answer” paradigm, while the RL stage employs a reward function to verify the format and correctness of the rollout responses.",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2602.04884/x3.png",
                "caption": "Figure 3:RALimproves GRPO along the increasing video frames or image resolution.",
                "position": 808
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]