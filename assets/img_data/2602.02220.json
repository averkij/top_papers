[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02220/x1.png",
                "caption": "Figure 1:HieraNav requires agents to interpret natural language and navigate to goals across four semantic levels:scene,room,region, andinstance, where success means reaching a target that satisfies the instruction.\nInstruction-relevant targets are color-coded.",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2602.02220/x2.png",
                "caption": "Figure 2:Analysis of instance-level instructions in GOAT-Bench.",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2602.02220/x3.png",
                "caption": "Figure 3:HieraNav requires agents to interpret natural language instructions and navigate to scene-, room-, region-, and instance-level targets.\nLangMap establishes the first large-scale benchmark for rigorous and systematic evaluation, featuring single-goal tasks at different semantic levels and multi-goal tasks across mixed levels.\nTarget descriptions incorporate intrinsic attributes, spatial-relational context, and open-world semantics.",
                "position": 148
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Multi-Granularity Open-Vocabulary Goal Navigation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02220/x4.png",
                "caption": "Figure 4:Distribution of region labels in descending frequency.",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2602.02220/x5.png",
                "caption": "Figure 5:Contrastive region annotation.\nAnnotators are provided with region panoramas, corresponding labeled object views, and 3D scene models to compose one concise and one comprehensive description per region, distinguishing it from other same-category regions via visual comparison. A subsequent cross-check ensures clarity and quality.",
                "position": 397
            },
            {
                "img": "https://arxiv.org/html/2602.02220/x6.png",
                "caption": "Figure 6:Distribution analysis of LangMap.\n(a) Instance count per object category (sampled category names shown for readability).\n(b) Ground-truth geodesic distance distribution for navigation tasks across the four semantic levels.",
                "position": 403
            },
            {
                "img": "https://arxiv.org/html/2602.02220/x7.png",
                "caption": "Figure 7:Contrastive instance annotation. Using object views, region panoramas, verified region descriptions, and the 3D scene, annotators write concise and detailed descriptions to distinguish each instance from others of the same category. All annotations are cross-checked.",
                "position": 434
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]