[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x1.png",
                "caption": "Figure 1:Length-controlled win rate on AlpacaEval 2.0 improves with SynPO iterations, approaching GPT-4 level for the base versions of Llama3-8B and Mistral-7B.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x1.png",
                "caption": "Figure 1:Length-controlled win rate on AlpacaEval 2.0 improves with SynPO iterations, approaching GPT-4 level for the base versions of Llama3-8B and Mistral-7B.",
                "position": 198
            }
        ]
    },
    {
        "header": "2Self-Boosting LLM with Synthetic Preference Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x2.png",
                "caption": "Figure 2:Overview of SynPO in theğ­ğ­ğ¡superscriptğ­ğ­ğ¡\\mathbf{t^{th}}bold_t start_POSTSUPERSCRIPT bold_th end_POSTSUPERSCRIPTiteration.Starting with the previous iteration modelMtâˆ’1subscriptğ‘€ğ‘¡1M_{t-1}italic_M start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT, SynPO first learns a response improverRtsubscriptğ‘…ğ‘¡R_{t}italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTto identify discrepancies between model responses (ytâˆ’1âˆ—subscriptsuperscriptğ‘¦ğ‘¡1y^{*}_{t-1}italic_y start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT) and gold standard responses (yâˆ—superscriptğ‘¦y^{*}italic_y start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT) on seed data, and learns to refine model responses. Subsequently, on the self-generated promptsxğ‘¥xitalic_x(elaborated in Section2.1), SynPO employsRtsubscriptğ‘…ğ‘¡R_{t}italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTto refine theMtâˆ’1subscriptğ‘€ğ‘¡1M_{t-1}italic_M start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPTresponses (ytâˆ’1subscriptğ‘¦ğ‘¡1y_{t-1}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT) into improved responses (ytâˆ’1wsuperscriptsubscriptğ‘¦ğ‘¡1ğ‘¤y_{t-1}^{w}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT). The valid synthetic promptsxğ‘¥xitalic_x, refined responses (ytâˆ’1wsuperscriptsubscriptğ‘¦ğ‘¡1ğ‘¤y_{t-1}^{w}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT), and initial modelM0subscriptğ‘€0M_{0}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTresponses (y0subscriptğ‘¦0y_{0}italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) to form synthetic preference data. These data are incorporated into the synthetic preference dataset for preference optimization, resulting in an updatedMtsubscriptğ‘€ğ‘¡M_{t}italic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTfor the next iteration. The iterative process continually enhances LLM capabilities in instruction-following and task performance.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x3.png",
                "caption": "Figure 4:The top 25 most common topics (outer circle) and the top 12 most common intentions (inner circle) in SynPO generated prompts. We aggregate the other topics and intentions to the â€˜Othersâ€™ group.",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x3.png",
                "caption": "Figure 4:The top 25 most common topics (outer circle) and the top 12 most common intentions (inner circle) in SynPO generated prompts. We aggregate the other topics and intentions to the â€˜Othersâ€™ group.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x4.png",
                "caption": "Figure 5:Inter-prompt similarity distributions for 1,000 randomly sampled prompts from SynPO, UltraFeedback(Cui etÂ al.,2023), Self-Instruct(Wang etÂ al.,2022), and UltraChat(Ding etÂ al.,2023). We used SentenceTransformer(Reimers & Gurevych,2019)to compute sentence embeddings and calculated the cosine similarity between each prompt and all others, then averaged these values for each prompt. The results suggest that our method, SynPO, generates more diverse prompts with lower inter-prompt similarity.",
                "position": 391
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x5.png",
                "caption": "Table 3:Multi-turn evaluation on MT-Bench. An asterisk (*) denotes the best score across multiple iterations. For Sampling-Ranking, Llamaâ€™s best is from iteration 4 and Mistralâ€™s from iteration 3. For Self-Rewarding, both are from iteration 3.SynPOprogressively enhances the multi-turn instruction-following capabilities of LLMs.",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x5.png",
                "caption": "Figure 6:Radar chart for Llama3-8B-Base-SynPOon MT-Bench.SynPOachieves notable improvements across various prompt categories, particularly in RolePlay, STEM, Reasoning, and Coding tasks.",
                "position": 750
            }
        ]
    },
    {
        "header": "4Ablation Studies",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BPrompt for Response-refiner",
        "images": []
    },
    {
        "header": "Appendix CExperimental Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Details on Seed Data Ablation",
        "images": []
    },
    {
        "header": "Appendix EAPI Usage",
        "images": []
    },
    {
        "header": "Appendix FPrompt Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x6.png",
                "caption": "Figure 9:Topic and intention distribution bar plot for the synthetic prompts in SynPO and UltraFeedback.",
                "position": 2516
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x7.png",
                "caption": "Figure 10:MT-Bench scores on different prompt types. The left radar chart represents results from SynPO on Llama3 and the right comes from Mistral.",
                "position": 2600
            }
        ]
    },
    {
        "header": "Appendix GEvaluation Details",
        "images": []
    }
]