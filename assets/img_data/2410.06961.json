[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x1.png",
                "caption": "Figure 1:Length-controlled win rate on AlpacaEval 2.0 improves with SynPO iterations, approaching GPT-4 level for the base versions of Llama3-8B and Mistral-7B.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x1.png",
                "caption": "Figure 1:Length-controlled win rate on AlpacaEval 2.0 improves with SynPO iterations, approaching GPT-4 level for the base versions of Llama3-8B and Mistral-7B.",
                "position": 198
            }
        ]
    },
    {
        "header": "2Self-Boosting LLM with Synthetic Preference Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x2.png",
                "caption": "Figure 2:Overview of SynPO in the𝐭𝐭𝐡superscript𝐭𝐭𝐡\\mathbf{t^{th}}bold_t start_POSTSUPERSCRIPT bold_th end_POSTSUPERSCRIPTiteration.Starting with the previous iteration modelMt−1subscript𝑀𝑡1M_{t-1}italic_M start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT, SynPO first learns a response improverRtsubscript𝑅𝑡R_{t}italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTto identify discrepancies between model responses (yt−1∗subscriptsuperscript𝑦𝑡1y^{*}_{t-1}italic_y start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT) and gold standard responses (y∗superscript𝑦y^{*}italic_y start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT) on seed data, and learns to refine model responses. Subsequently, on the self-generated promptsx𝑥xitalic_x(elaborated in Section2.1), SynPO employsRtsubscript𝑅𝑡R_{t}italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTto refine theMt−1subscript𝑀𝑡1M_{t-1}italic_M start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPTresponses (yt−1subscript𝑦𝑡1y_{t-1}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT) into improved responses (yt−1wsuperscriptsubscript𝑦𝑡1𝑤y_{t-1}^{w}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT). The valid synthetic promptsx𝑥xitalic_x, refined responses (yt−1wsuperscriptsubscript𝑦𝑡1𝑤y_{t-1}^{w}italic_y start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT), and initial modelM0subscript𝑀0M_{0}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTresponses (y0subscript𝑦0y_{0}italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) to form synthetic preference data. These data are incorporated into the synthetic preference dataset for preference optimization, resulting in an updatedMtsubscript𝑀𝑡M_{t}italic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTfor the next iteration. The iterative process continually enhances LLM capabilities in instruction-following and task performance.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x3.png",
                "caption": "Figure 4:The top 25 most common topics (outer circle) and the top 12 most common intentions (inner circle) in SynPO generated prompts. We aggregate the other topics and intentions to the ‘Others’ group.",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x3.png",
                "caption": "Figure 4:The top 25 most common topics (outer circle) and the top 12 most common intentions (inner circle) in SynPO generated prompts. We aggregate the other topics and intentions to the ‘Others’ group.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x4.png",
                "caption": "Figure 5:Inter-prompt similarity distributions for 1,000 randomly sampled prompts from SynPO, UltraFeedback(Cui et al.,2023), Self-Instruct(Wang et al.,2022), and UltraChat(Ding et al.,2023). We used SentenceTransformer(Reimers & Gurevych,2019)to compute sentence embeddings and calculated the cosine similarity between each prompt and all others, then averaged these values for each prompt. The results suggest that our method, SynPO, generates more diverse prompts with lower inter-prompt similarity.",
                "position": 391
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x5.png",
                "caption": "Table 3:Multi-turn evaluation on MT-Bench. An asterisk (*) denotes the best score across multiple iterations. For Sampling-Ranking, Llama’s best is from iteration 4 and Mistral’s from iteration 3. For Self-Rewarding, both are from iteration 3.SynPOprogressively enhances the multi-turn instruction-following capabilities of LLMs.",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x5.png",
                "caption": "Figure 6:Radar chart for Llama3-8B-Base-SynPOon MT-Bench.SynPOachieves notable improvements across various prompt categories, particularly in RolePlay, STEM, Reasoning, and Coding tasks.",
                "position": 750
            }
        ]
    },
    {
        "header": "4Ablation Studies",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm",
        "images": []
    },
    {
        "header": "Appendix BPrompt for Response-refiner",
        "images": []
    },
    {
        "header": "Appendix CExperimental Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Details on Seed Data Ablation",
        "images": []
    },
    {
        "header": "Appendix EAPI Usage",
        "images": []
    },
    {
        "header": "Appendix FPrompt Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.06961/x6.png",
                "caption": "Figure 9:Topic and intention distribution bar plot for the synthetic prompts in SynPO and UltraFeedback.",
                "position": 2516
            },
            {
                "img": "https://arxiv.org/html/2410.06961/x7.png",
                "caption": "Figure 10:MT-Bench scores on different prompt types. The left radar chart represents results from SynPO on Llama3 and the right comes from Mistral.",
                "position": 2600
            }
        ]
    },
    {
        "header": "Appendix GEvaluation Details",
        "images": []
    }
]