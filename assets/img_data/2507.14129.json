[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14129/x1.png",
                "caption": "Figure 1:Our contributions in this work are three folds: 1) Open sourcing the pre-training and evaluation code for BEATs. 2) Scaling the training data and model to handle multiple sound domains like music (\\faMusic), environmental sound (\\faVolumeDown) and bioacoustics (\\faDog). 3) Fineâ€‘grained multi-domain evaluations that go beyond standard tasks, probing reasoning ability via audio entailment and question-answering.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3OpenBEATs",
        "images": []
    },
    {
        "header": "4Evaluation Setup",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgements",
        "images": []
    },
    {
        "header": "REFERENCES",
        "images": []
    }
]