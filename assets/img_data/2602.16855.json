[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16855/x1.png",
                "caption": "",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x2.png",
                "caption": "Figure 1:Performance overview on mainstream GUI task automation, grounding and knowledge benchmarks.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2602.16855/Mobile_agent_v3_5_images/fig1.v4.png",
                "caption": "Figure 2:Overview of our Mobile-Agent-v3.5. We illustrate our multi-platform environment supporting and our highlight\ncapability.",
                "position": 123
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Mobile-Agent-v3.5",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16855/images/fig2.v2.png",
                "caption": "Figure 3:Illustration of the interaction flow of GUI-Owl-1.5. The system message defines the available action space,\nthe user message contains the task instruction, compressed histories, and current observation, while the response\nmessage includes the agentâ€™s reasoning, action summaries, and the final action output.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x3.png",
                "caption": "Figure 4:Overview of our high-quality grounding data construction pipeline.",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x4.png",
                "caption": "Figure 5:Overview of our trajectory collection pipeline.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2602.16855/Mobile_agent_v3_5_images/fig5.v4.png",
                "caption": "Figure 6:Illustration of our agent capability enhancement pipeline.",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x5.png",
                "caption": "Figure 7:Overview of our reinforcement learning pipeline.",
                "position": 592
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16855/x6.png",
                "caption": "Figure 8:Ablation Study on Reinforcement Learning Training Strategies for GUI-Owl-1.5-8B-thinking: Task Selection and Multi-Platform Training Strategies.",
                "position": 3726
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x7.png",
                "caption": "Figure 9:A complete operation process on the Android platform, in which the user query requires the agent to search and summarize information on social media platforms.",
                "position": 3743
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x8.png",
                "caption": "Figure 10:A complete operation process on the Windows platform, in which the user query requires the agent to memorize key on-screen information.",
                "position": 3760
            },
            {
                "img": "https://arxiv.org/html/2602.16855/x9.png",
                "caption": "Figure 11:A case of a complete operation process on a desktop platform, which combining extended tools and computer use actions.",
                "position": 3763
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]