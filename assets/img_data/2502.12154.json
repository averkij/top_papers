[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/teaser/teaser.png",
                "caption": "Figure 1:We propose Model-guidance (MG), removing Classifier-free guidance (CFG) for diffusion models and achieving state-of-the-art on ImageNet with FID of1.341.34\\mathbf{1.34}bold_1.34.(a) Instead of running models twice during inference (green and red), MG directly learns the final distribution (blue).(b) MG requires only one line of code modification while providing excellent improvements. (c) Comparing to concurrent methods, MG yields lowest FID even without CFG.",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/toy-example/toy-grid-main.png",
                "caption": "Figure 2:We use a grid 2D distribution with two classes, marked with orange and gray regions, as example and train diffusion models on it. We plot the generated samples, trajectories, and probability density function (PDF) of conditional, unconditional, CFG-guided model, and our approach.(a)The first row indicates that although CFG improves quality by eliminating outliers, the samples concentrate in the center of data distributions, resulting the loss of diversity. In contrast, our method yields less outliers than the conditional model and a better coverage of data than CFG.(b)In the second row, the trajectories of CFG show sharp turns at the beginning,e.g.samples inside the red box, while our method directly drives the samples to the closet data distributions.(c)The PDF plots of the last row also suggest that our method predicts more symmetric contours than CFG, balancing both quality and diversity.",
                "position": 124
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/method/fig-method-1.png",
                "caption": "Figure 1:(a)Unconditional,Conditional, andClassifier-free Guidedscore.",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/method/fig-method-1.png",
                "caption": "Figure 1:(a)Unconditional,Conditional, andClassifier-free Guidedscore.",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/method/fig-method-3.png",
                "caption": "Figure 2:(b)The offsets of CFGpush update directions to the data.",
                "position": 320
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.12154/x1.png",
                "caption": "Figure 4:FID-50K and Inception Score results as the guidance scale increases during inference. Our method is compatible with and can be wrapped into vanilla CFG.",
                "position": 1620
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x2.png",
                "caption": "",
                "position": 1629
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x3.png",
                "caption": "",
                "position": 1635
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x4.png",
                "caption": "",
                "position": 1640
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x5.png",
                "caption": "Figure 5:FID-5K results during training. Our method is≥6.5×\\geq 6.5\\times≥ 6.5 ×faster and≈60%absentpercent60\\approx 60\\%≈ 60 %better than vanilla DiT and SiT, even surpassing the results of CFG.",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x6.png",
                "caption": "",
                "position": 1655
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x7.png",
                "caption": "Figure 6:FID-50Kvs.number of parameters and sampling flops of different models, where our models are highlighted.",
                "position": 1661
            },
            {
                "img": "https://arxiv.org/html/2502.12154/x8.png",
                "caption": "",
                "position": 1670
            },
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/results/concatenated_image_1.png",
                "caption": "Figure 7:Uncuratedsamples of SiT-XL/2+MG on ImageNet256×256256256256\\times 256256 × 256.",
                "position": 1698
            },
            {
                "img": "https://arxiv.org/html/2502.12154/extracted/6211015/figure/results/concatenated_image_2.png",
                "caption": "Figure 8:Uncuratedsamples of SiT-XL/2+MG on ImageNet512×512512512512\\times 512512 × 512.",
                "position": 1702
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]