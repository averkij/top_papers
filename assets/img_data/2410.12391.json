[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12391/extracted/5929604/graphics/exp_design-draft.png",
                "caption": "Figure 1:Overview of the experimental design. We start with a base model trained on BabyLM and Python code (1), which is fine-tuned (FT) on two new domains: the Lua programming language (2), and TinyStories (3). The fine-tuned models are merged into a single LuaStories model using spherical linear interpolation (SLERP) interpolation (4). For each of these models, we train a sparse auto-encoder on the MLP activations using the same data distribution as the original model.",
                "position": 132
            }
        ]
    },
    {
        "header": "4Empirical Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12391/x1.png",
                "caption": "Figure 2:Overview of the features persisting through fine-tuning and model merging, showing volumes and trajectories of extracted features that emerge, persist and disappear. This overview omits the features that don‚Äôt persist, and so the visual flows are scaled proportional to the persisting features. We note the share of features that persist from each model.",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2410.12391/x2.png",
                "caption": "Figure 3:Visualisation of the feature activation patterns of the universally extracted variable assignment features found in each model. Each token is highlighted according to the feature‚Äôs activation level, where darker background colour denotes higher level of activation. Additionally, we note the observed activation pattern correlations between each feature.",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2410.12391/x3.png",
                "caption": "Figure 4:Examples of observed activation patterns of theBabyPythonPython exception feature, and the closest matching feature in theLuamodel, qualitatively showing insufficient correlation between the two.",
                "position": 213
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASlerp Interpolation curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12391/x4.png",
                "caption": "Figure 5:Observed accuracy trends of a merged model consisting of weights spherically linear interpolated between the Lua model and the TinyStories model, as measured on the validation datasets of the Lua and TinyStories, respectively, at each interpolation step (slerptùë°titalic_t-value). The dashed baselines show the accuracy of the shared base model underlying the Lua and TinyStories model, on the same validation datasets.",
                "position": 606
            }
        ]
    },
    {
        "header": "Appendix BSparse Auto-Encoders and Universality",
        "images": []
    },
    {
        "header": "Appendix CAutomated Interpretability",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12391/x5.png",
                "caption": "Figure 6:Histograms showing the distribution of observed correlations between automatically generated explanations and the true feature activation patterns of features in the Lua and LuaStories model.",
                "position": 668
            }
        ]
    },
    {
        "header": "Appendix DLog-likelihood Ratio Feature Proxy",
        "images": []
    }
]