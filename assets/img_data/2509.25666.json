[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25666/x1.png",
                "caption": "Figure 1:GRPO yields substantial gains, but the improvements largely stem from extending the model‚Äôs ability within its comfort zone, i.e., if the model fails to solve a hard problem after numerous attempts, it is unable to learn from that problem. In NuRL, we address this by exploring various forms of hints (abstract cues, partial steps, explanations, or even the gold answer), which can be self-generated or teacher-generated. Both self- and teacher-generated abstract cues can expand the model‚Äôs comfort zone, effectively transforming previously unsolvable problems into solvable ones.",
                "position": 90
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25666/x2.png",
                "caption": "Figure 2:NuRL provides targeted guidance to the LLM policy during online GRPO training. Prior to training, we construct an offline collection of hints, defined as abstract problem-specific cues that reduce task difficulty. During the online training, whenever allùí¢\\mathcal{G}rollouts for a problem are incorrect, NuRL augmentsùí¢‚àí1\\mathcal{G}-1of the rollouts with the corresponding hint and regenerates the batch. This intervention facilitates the acquisition of non-zero rewards on instances that would otherwise yield uniformly zero rewards, thereby supplying informative training signals.",
                "position": 141
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25666/x3.png",
                "caption": "Figure 3:Compared to GRPO‚Äôs improvements with Self-Consistency (+7.6%+7.6\\%and+7.8%+7.8\\%on Llama and OctoThinker), NuRL obtains larger gains with+8.0%+8.0\\%and+9.4%+9.4\\%, respectively.",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2509.25666/x4.png",
                "caption": "Figure 4:Comparison of different types of hints. From left to right, the hints vary in how directly they disclose information about the ground-truth answer. At the leftmost end, abstract hints provide only high-level guidance without revealing details of the solution or answer, whereas at the rightmost end, the answer is given explicitly. Interestingly, more direct hints lead to worse performance.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2509.25666/x5.png",
                "caption": "Figure 5:When the base model (Llama) already has strong pre-trained knowledge (e.g., MATH 500), both GRPO and NuRL yield little improvement in pass@k. In contrast, on tasks with lower upper-bound performance (e.g., Date Understanding and GPQA, with pass@1024 of 85.4 and 67.2), GRPO provides no gains on pass@1024, while NuRL pushes it further.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2509.25666/x6.png",
                "caption": "Figure 6:The self-generated hints in NuRL effectively reduce the task difficulty and increase the portion of solvable problems.",
                "position": 597
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AThe Use of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CDataset Statistics and Licenses",
        "images": []
    },
    {
        "header": "Appendix DPrompts for Hint Generation",
        "images": []
    },
    {
        "header": "Appendix EQualitative Examples",
        "images": []
    }
]