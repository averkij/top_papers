[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.16745/imgs/fig1.png",
                "caption": "Figure 1:Learning One-dimensional Cellular Automata.(a)Update of state with local rule.(b)Orbit of 1dCA is a sequence of binary strings of sizeW=20W=20. The firstk=10k=10states marked by the red rectangle encode transformer input.(c)Given a part of the orbit a model learns to predict the next state (O-S).",
                "position": 162
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.16745/x1.png",
                "caption": "Figure 4:Depth — not width — drives multi-step accuracy.Exact-match accuracy for look-ahead horizonsk∈{1,2,3,4}k\\in\\{1,2,3,4\\}as a function of(a)transformer layer count and(b)embedding dimensiondmodeld_{\\text{model}}.\nDeeper networks boost performance sharply fork≥2k{\\geq}2and plateau beyond six layers, whereas widening the model yields only marginal gains across all horizons.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x2.png",
                "caption": "Figure 5:ACT significantly improves computational abilities of transformer-based models in multi-step prediction.Exact match of thex(T+k)x^{(T+k)}state prediction for look-ahead stepsk∈{1,2,3,4}k\\in\\{1,2,3,4\\}for O-S training objective. Different models are shown in different colors.",
                "position": 302
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x3.png",
                "caption": "Figure 6:Without supervision on intermediate reasoning steps RL training with GRPO allows the model to extrapolate reasoning on 3 steps forward.While model and layer ACT variants extend it to 2 steps forward. However, 4 steps remains a challenging task for all approaches. All models are trained from GPTNeox checkpoint trained on 1 step forward prediction task.",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x4.png",
                "caption": "Figure 7:With step-by-step supervision, the CoT approach significantly outperforms the in-depth approach of ACT.While the performance of the depth-based methods decreases with the increasing look-ahead steps, breadth-based CoT succeeds in predicting up to all 4 steps. However, among the models without autoregressive generation, GPTNeox and ARMT with both ACT and O-O supervision perform the best.",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x5.png",
                "caption": "Figure 8:ACT significantly reduces the required models’ depth for the majority of group multiplication tasks.Each chart contains the information about the minimal required number of layers for solving task of given length with 70% exact match accuracy. GPTNeox and Mamba beingT​C0TC^{0}-limited models require more layers for solving deeper (longer in this case) tasks, while ARMT and LSTM solve them with constant number of layers.",
                "position": 343
            }
        ]
    },
    {
        "header": "4Discussion and Conclusions",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.16745/x6.png",
                "caption": "Figure 9:With GRPO as well as with ACT and Orbit-Orbit training depth of reasoning can be significantly extended.AverageD​e​p​t​h​S​c​o​r​e=1+∑i=24a​c​c​(i)DepthScore=1+\\sum_{i=2}^{4}{acc(i)}, wherea​c​c​(i)acc(i)is the accuracy of predicting the(10+i)(10+i)th state based on the first1010states.",
                "position": 405
            }
        ]
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BModels Discussion",
        "images": []
    },
    {
        "header": "Appendix CAdaptive Computation Time formulation",
        "images": []
    },
    {
        "header": "Appendix DSamples examples",
        "images": []
    },
    {
        "header": "Appendix EMultiple Prediction Horizons Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.16745/x7.png",
                "caption": "Figure 10:ACT outperforms the base model on multiple prediction horizons task. Exact match accuracy (mean±\\pmstd) for cellular automata state prediction across different look-ahead horizons. Models receive initial 10 states followed by a special shift token (1-4) indicating prediction horizon.",
                "position": 1703
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x8.png",
                "caption": "Figure 11:Fixed Computation Time (FCT) with 3 iteration steps performs on par with Adaptive Computation Time (ACT) in Orbit-State task.Exact match accuracy (mean ± std) for cellular automata state prediction across different look-ahead horizons.",
                "position": 1733
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x9.png",
                "caption": "Figure 12:Fixed Computation Time (FCT) with 3 iteration steps underperforms Adaptive Computation Time (ACT) in Orbit-Orbit task.Exact match accuracy (mean ± std) for cellular automata state prediction across different look-ahead horizons.",
                "position": 1737
            },
            {
                "img": "https://arxiv.org/html/2508.16745/x10.png",
                "caption": "Figure 13:Layer-ACT performs similar or better compared to Model-ACT. Exact match on cellular automata state prediction task with look ahead 2.",
                "position": 1748
            }
        ]
    },
    {
        "header": "Appendix FAblation Studies",
        "images": []
    }
]