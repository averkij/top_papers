[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07986/x1.png",
                "caption": "",
                "position": 81
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07986/extracted/6526177/fig/obj-miss-example.png",
                "caption": "Figure 2:Object missing in text-to-image models. Even in SOTA models like FLUX.1 Dev, we can still observe cases with missing objects. Prompts: ‚ÄúThe square painting was next tothe round mirror‚Äù, ‚Äúa blue benchand a green car‚Äù.",
                "position": 96
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x2.png",
                "caption": "Figure 3:The denoising process. This figure shows the predictedùíô0subscriptùíô0\\boldsymbol{x}_{0}bold_italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTin each step of the denoising process for the prompt ‚ÄúTheblack chairis on the right of the wooden table‚Äù with FLUX.1 Dev. This observation leads to our hypothesis that visual-text cross-attention plays a more significant role than visual self-attention specifically during these initial steps where the image‚Äôs overall composition is determined. Additionally, as the temperature scaling factorŒ≥ùõæ\\gammaitalic_Œ≥increases in the cross-modal section of MM-DiT‚Äôs unified softmax function, the initial image composition progressively aligns more closely with the corresponding text.",
                "position": 105
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x2.png",
                "caption": "Figure 3:The denoising process. This figure shows the predictedùíô0subscriptùíô0\\boldsymbol{x}_{0}bold_italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTin each step of the denoising process for the prompt ‚ÄúTheblack chairis on the right of the wooden table‚Äù with FLUX.1 Dev. This observation leads to our hypothesis that visual-text cross-attention plays a more significant role than visual self-attention specifically during these initial steps where the image‚Äôs overall composition is determined. Additionally, as the temperature scaling factorŒ≥ùõæ\\gammaitalic_Œ≥increases in the cross-modal section of MM-DiT‚Äôs unified softmax function, the initial image composition progressively aligns more closely with the corresponding text.",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x3.png",
                "caption": "Figure 4:Relative magnitude of visual-text attention between the typical cross attention and MM-DiT full attention (averaged over 50 samples). The numerical asymmetry between the number of visual and text tokens suppresses the magnitude of cross attention, leading to weak alignment between the generated image and the given text prompt. We can amplify the cross-attention by boosting the coefficientŒ≥ùõæ\\gammaitalic_Œ≥, thereby strengthening the alignment between the image and text.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07986/x4.png",
                "caption": "Figure 5:Temperature scaling helps visual-text alignment. From this figure, we can see that as the temperature scaling factorŒ≥ùõæ\\gammaitalic_Œ≥increases, the characteristics of ‚Äúbrown backpack‚Äù, ‚Äúglass mirror‚Äù and ‚Äúblack stomach‚Äù become more obvious.",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x5.png",
                "caption": "Figure 6:Attention map differences. We conducted a visualization of the alterations in the visual-text attention map during the initial stages of the denoising process, as influenced by our proposed method. In contrast to the baseline, our approach substantially amplifies the attention directed toward the text in the early steps.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x6.png",
                "caption": "Figure 7:Comparison of samples generated by FLUX.1 Dev and Stable Diffusion 3.5 Medium with and without TACA. Our method enhances the semantic representation of the primary object within the text prompt, improves spatial relationships, and maintains image quality without degradation.",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x6.png",
                "caption": "",
                "position": 415
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x7.png",
                "caption": "",
                "position": 420
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07986/x8.png",
                "caption": "(a)",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x8.png",
                "caption": "(a)",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x9.png",
                "caption": "(b)",
                "position": 628
            }
        ]
    },
    {
        "header": "5Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACode Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BFurther Ablation Study on Text Alignment",
        "images": []
    },
    {
        "header": "Appendix CFull parameter fine-tuning vs. LoRA",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.07986/x10.png",
                "caption": "Figure 9:Visual comparisons on visual-text alignment (FLUX.1 Dev, short prompts)",
                "position": 1756
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x11.png",
                "caption": "Figure 10:Visual comparisons on visual-text alignment (FLUX.1 Dev, short prompts)",
                "position": 1759
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x12.png",
                "caption": "Figure 11:Visual comparisons on visual-text alignment (FLUX.1 Dev, short prompts)",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x13.png",
                "caption": "Figure 12:Visual comparisons on visual-text alignment (FLUX.1 Dev, short prompts)",
                "position": 1765
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x14.png",
                "caption": "Figure 13:Visual comparisons on visual-text alignment (SD3.5 Medium, short prompts)",
                "position": 1768
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x15.png",
                "caption": "Figure 14:Visual comparisons on visual-text alignment (SD3.5 Medium, short prompts)",
                "position": 1771
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x16.png",
                "caption": "Figure 15:Visual comparisons on visual-text alignment (FLUX.1 Dev, long prompts)",
                "position": 1774
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x17.png",
                "caption": "Figure 16:Visual comparisons on visual-text alignment (FLUX.1 Dev, long prompts)",
                "position": 1777
            },
            {
                "img": "https://arxiv.org/html/2506.07986/x18.png",
                "caption": "Figure 17:Visual comparisons on visual-text alignment (FLUX.1 Dev, long prompts)",
                "position": 1780
            }
        ]
    },
    {
        "header": "Appendix DMore Qualitative Results",
        "images": []
    }
]