[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16194/x1.png",
                "caption": "Figure 1:(a) The codeword clustering process, where token indices are grouped based on the similarity of their corresponding feature vectors in the codebook.\n(b) Visual demonstration of token redundancy: replacing each token with another randomly sampled from the same cluster produces images with only minor variations in detail, preserving the overall structure and content.\n(c) Illustration of our two-stage generation process: in the first stage, the model autoregressively predicts coarse labels (cluster indices) for each token in the sequence; then the second stage model predicts fine labels (indices in the codebook) for all tokens in a single step.",
                "position": 156
            }
        ]
    },
    {
        "header": "3Motivation and Findings",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16194/x2.png",
                "caption": "Figure 2:Model performance comparison on different epochs. When our method is applied, models achieve significantly better performance.",
                "position": 839
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16194/x3.png",
                "caption": "Figure 3:Generation results of our method (based on LlamaGen-XL) on ImageNet 256Ã—256 benchmark.",
                "position": 1203
            }
        ]
    },
    {
        "header": "7Conclustion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]