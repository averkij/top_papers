[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00168/x1.png",
                "caption": "",
                "position": 71
            },
            {
                "img": "https://arxiv.org/html/2602.00168/x2.png",
                "caption": "",
                "position": 71
            },
            {
                "img": "https://arxiv.org/html/2602.00168/x3.png",
                "caption": "Figure 1:Bird’s-eye diagram: simplified architecture of YOLOE-26 for open-vocabulary instance segmentation.",
                "position": 88
            }
        ]
    },
    {
        "header": "1INTRODUCTION",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00168/x4.png",
                "caption": "Figure 2:Performance comparison of YOLO26 under TensorRT FP16 on an NVIDIA T4 GPU (Source Link). (a) COCO mAP(50–95) versus inference latency (ms/image), comparing YOLO26 with earlier YOLO versions and other real-time detectors, highlighting its improved accuracy–speed trade-off. (b) COCO mAP(50–95) versus end-to-end latency, comparing YOLO26 with YOLOv10 and RT-DETR variants, illustrating its advantage in overall pipeline efficiency.",
                "position": 121
            },
            {
                "img": "https://arxiv.org/html/2602.00168/x5.png",
                "caption": "Figure 3:Comparison of performance, training cost, and inference efficiency between YOLOE and advanced YOLO-Worldv2 in terms of open text prompts. LVIS AP is evaluated on minival set and FPS w/ TensorRT and w/ CoreML is measured on T4 GPU and iPhone 12, respectively. The results highlight our superiority. (Source: YOLOE paperWanget al.(2025a)",
                "position": 133
            }
        ]
    },
    {
        "header": "2YOLOE-26 Architecture Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00168/x6.png",
                "caption": "Figure 4:Architectural diagram of YOLOE-26 for open-vocabulary instance segmentation. The upper part illustrates the core YOLOv26 end-to-end detection and segmentation pipeline, while the lower part depicts the YOLOE (Wanget al.(2025a)) components that enable text-prompted, visual-prompted, and prompt-free open-vocabulary learning.",
                "position": 147
            }
        ]
    },
    {
        "header": "3OPEN-VOCABULARY PROMPTING MECHANISMS",
        "images": []
    },
    {
        "header": "4TRAINING STRATEGY AND IMPLEMENTATION",
        "images": []
    },
    {
        "header": "5Conclusion and Future Roadmap",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]