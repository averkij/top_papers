[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04717/x1.png",
                "caption": "(a)Semantic clustering of relevant datasets.",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x1.png",
                "caption": "(a)Semantic clustering of relevant datasets.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x2.png",
                "caption": "(b)OSS-Alpaca mixture and test instructions.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x3.png",
                "caption": "(c)OSS-COT-Alpaca mixture and test instructions.",
                "position": 497
            }
        ]
    },
    {
        "header": "2Experiments with String Replacements",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04717/x4.png",
                "caption": "(a)Re-writing accuracy against the number of instructions with a fixed-size training set.",
                "position": 556
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x4.png",
                "caption": "(a)Re-writing accuracy against the number of instructions with a fixed-size training set.",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x5.png",
                "caption": "(b)Rewriting with no-op situation included.",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x6.png",
                "caption": "Figure 3:Effect of long-tail task distributions on modelâ€™s generalization ability.",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x7.png",
                "caption": "Figure 4:Modelâ€™s performance onk<3ð‘˜3k<3italic_k < 3when trained on the three classes of restricted semantics as in2.3.4. Models trained on 500 or less instructions never generalize to smaller k.",
                "position": 633
            }
        ]
    },
    {
        "header": "3Rewriting with Abstraction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04717/x8.png",
                "caption": "(a)Accuracy On Unseen Deduction Rules vs. Abstract Rule Diversity.D3:pattern with tree depth 3.ZS:Zero shot.FS: Few shot.",
                "position": 710
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x8.png",
                "caption": "(a)Accuracy On Unseen Deduction Rules vs. Abstract Rule Diversity.D3:pattern with tree depth 3.ZS:Zero shot.FS: Few shot.",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x9.png",
                "caption": "(b)Accuracy on unseen depths against number of diversification rules with the same in-domain / out-of-domain mixture.",
                "position": 718
            },
            {
                "img": "https://arxiv.org/html/2410.04717/x10.png",
                "caption": "(c)Accuracy on unseen depths vs. In-domain/out-of-domain combination.Diver-means number of diversification rules. X axis ticks are |â„›dâ¢iâ¢vâ¢eâ¢rsubscriptâ„›ð‘‘ð‘–ð‘£ð‘’ð‘Ÿ\\mathcal{R}_{diver}caligraphic_R start_POSTSUBSCRIPT italic_d italic_i italic_v italic_e italic_r end_POSTSUBSCRIPT|: |â„›sâ¢pâ¢eâ¢csubscriptâ„›ð‘ ð‘ð‘’ð‘\\mathcal{R}_{spec}caligraphic_R start_POSTSUBSCRIPT italic_s italic_p italic_e italic_c end_POSTSUBSCRIPT|.",
                "position": 723
            }
        ]
    },
    {
        "header": "4Fine-Tuning A Sepcialist Instruction-Follower: Case of Code Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04717/x11.png",
                "caption": "Figure 6:Sweet spots of Pass@1 with data mixture. Baseline is marked with dotted lines.",
                "position": 1073
            }
        ]
    },
    {
        "header": "5Fine-tuning Generalist LLMs",
        "images": []
    },
    {
        "header": "6Related works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComplement on Markov algorithms",
        "images": []
    },
    {
        "header": "Appendix BExperimental set-up",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.04717/x12.png",
                "caption": "Figure 7:The sorted percentage of each instruction following power-law distribution with different shape parameters. The y-axis is the percentage of the rules in the training mixture. The x-axis is the ranked index (by proportion of examples) of instructions.",
                "position": 2492
            }
        ]
    },
    {
        "header": "Appendix CMore Details On Evaluation",
        "images": []
    }
]