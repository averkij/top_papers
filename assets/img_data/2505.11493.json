[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11493/x1.png",
                "caption": "Figure 1:Overview of the proposed GIE-Bench pipeline for grounded and fine-grained evaluation of text-guided image editing models. GIE-Bench consists of two components: (iùëñiitalic_i) functional correctness evaluation; and (i‚Å¢iùëñùëñiiitalic_i italic_i) content preservation evaluation.",
                "position": 72
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Benchmark Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11493/x2.png",
                "caption": "Figure 2:Example image editing instructions and edited results by GPT-Image-1(gptimage1,), OmniGen(xiao2024omnigenunifiedimagegeneration,), and MGIE(fu2024mgie,).",
                "position": 217
            },
            {
                "img": "https://arxiv.org/html/2505.11493/x3.png",
                "caption": "Figure 3:Distribution of object mask size ratios.",
                "position": 247
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11493/x4.png",
                "caption": "Figure 4:Left: Functional correctness per edit type. Right: Model preservation rankings based on masked MSE (inverted), PSNR, and CLIP scores. We empirically observe that model ranking evaluated by masked CLIP differs from model ranking evaluated by CLIP.",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2505.11493/x5.png",
                "caption": "Figure 5:Examples showing three failure modes: functional failure, preservation failure, and combined failure, paired with correct editing.",
                "position": 883
            },
            {
                "img": "https://arxiv.org/html/2505.11493/x6.png",
                "caption": "Figure 6:Examples of GPT-Image-1‚Äôs failure modes.",
                "position": 989
            },
            {
                "img": "https://arxiv.org/html/2505.11493/extracted/6444661/img/merged_corr.png",
                "caption": "Figure 7:Left: Correlation between human and GPT-4o evaluated functional correctness scores.\nRight: Correlation between human-evaluated preservation and inverted calibrated MSE rank.",
                "position": 1011
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitation",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11493/x7.png",
                "caption": "Figure 8:Prompts used to generate editing instructions, multiple-choice questions, and true answers.",
                "position": 1828
            },
            {
                "img": "https://arxiv.org/html/2505.11493/x8.png",
                "caption": "Figure 9:Prompt used to summarize object to edit in the editing instructions.",
                "position": 1831
            },
            {
                "img": "https://arxiv.org/html/2505.11493/extracted/6444661/img/human_study.png",
                "caption": "Figure 10:The annotation guidance we provided to human annotators on how to assign scores.",
                "position": 2417
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]