[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x1.png",
                "caption": "((a))",
                "position": 78
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x1.png",
                "caption": "((a))",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x2.png",
                "caption": "((b))",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x3.png",
                "caption": "Figure 2:Overview ofWebRL.WebRLis a self-evolving online curriculum reinforcement learning framework for LLM-based web agents, yielding consistent continual improvements throughout the iterative self-evolution.",
                "position": 126
            }
        ]
    },
    {
        "header": "2WebRL: Self-Evolving Online Curriculum RL",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x4.png",
                "caption": "Figure 3:Distribution analysis of error types forWebRLand baseline methods.",
                "position": 1320
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x5.png",
                "caption": "Figure 4:Accuracy ofWebRLand baselines for tasks requiring different steps.",
                "position": 1332
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x5.png",
                "caption": "Figure 4:Accuracy ofWebRLand baselines for tasks requiring different steps.",
                "position": 1335
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x6.png",
                "caption": "Figure 5:Ablation study ofWebRLon replay buffer, KL-constrained policy update and curriculum strategy.",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x7.png",
                "caption": "Figure 6:Accuracy ofWebRLand baselines for tasks with different complexity.",
                "position": 1350
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x8.png",
                "caption": "Figure 7:The impact ofŒ≤ùõΩ\\betaitalic_Œ≤of KL-constrained policy update algorithm on the model‚Äôs performance.",
                "position": 1425
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x9.png",
                "caption": "Figure 8:Examples of instructions generated in different phases under self-evolving curriculum learning.",
                "position": 1525
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x10.png",
                "caption": "Figure 9:The input and output format ofWebRLand baselines, where the input is composed of task instruction (ingreen), action history (inblue), and HTML of the current webpage (inorange). The output (inred) is the action taken on the current webpage.",
                "position": 2279
            }
        ]
    },
    {
        "header": "Appendix BOther Quantitative Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x11.png",
                "caption": "Figure 10:Performance variation curves of Llama3.1-8B on each website underWebRLtraining.",
                "position": 2935
            }
        ]
    },
    {
        "header": "Appendix CPrompts Employed in WebRL",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.02337/x12.png",
                "caption": "Figure 11:The simple prompt employed in baselines.",
                "position": 2945
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x13.png",
                "caption": "Figure 12:Prompts for instruction generation.",
                "position": 2951
            },
            {
                "img": "https://arxiv.org/html/2411.02337/x14.png",
                "caption": "Figure 13:Prompts for‚Ñ≥ORMsubscript‚Ñ≥ORM\\mathcal{M}_{\\text{ORM}}caligraphic_M start_POSTSUBSCRIPT ORM end_POSTSUBSCRIPTto assess the completion of Instructions.",
                "position": 2957
            },
            {
                "img": "https://arxiv.org/html/2411.02337/extracted/5977238/figure/appendix/combined_image_cms.png",
                "caption": "Figure 14:CMS Example.",
                "position": 2967
            },
            {
                "img": "https://arxiv.org/html/2411.02337/extracted/5977238/figure/appendix/combined_image_gitlab.png",
                "caption": "Figure 15:Gitlab Example.",
                "position": 2970
            },
            {
                "img": "https://arxiv.org/html/2411.02337/extracted/5977238/figure/appendix/combined_image_map.png",
                "caption": "Figure 16:MAP Example.",
                "position": 2973
            },
            {
                "img": "https://arxiv.org/html/2411.02337/extracted/5977238/figure/appendix/combined_image_reddit.png",
                "caption": "Figure 17:Reddit Example.",
                "position": 2976
            },
            {
                "img": "https://arxiv.org/html/2411.02337/extracted/5977238/figure/appendix/combined_image_oss.png",
                "caption": "Figure 18:OSS Example.",
                "position": 2979
            }
        ]
    },
    {
        "header": "Appendix DQualitative Examples",
        "images": []
    }
]