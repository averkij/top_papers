[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.09138/figures/logo.png",
                "caption": "",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.09138/x1.png",
                "caption": "Figure 1:Illustration of temporal oscillation during sampling.(a) Across four datasets, a significant gap is observed between thefinal answer’s pass rate(denoted asPass⁡@​1\\operatorname{Pass}@1) and theever-pass rate at any intermediate step(denoted asEverPass⁡@​1∣t\\operatorname{EverPass}@1\\mid t). This gap reveals the phenomenon we refer to as temporal oscillation, where correct intermediate answers are sometimes overwritten as the generation proceeds.\n(b) Example of temporal oscillation: For a given math problem, the model initially gives the correct answer, 25, at an intermediate step (e.g., step 55), aligning with the ground truth.\nHowever, by the final step, this correct answer is replaced with an incorrect one: 2.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Explorations on dLLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.09138/x2.png",
                "caption": "Figure 2:Patterns of accuracy evolution over diffusion sampling steps.Responses are generated with a length of 128 tokens using 64 diffusion steps, based on the LLaDA-8B-Instruct model.Left:\nAccuracy generally improves with more sampling steps across all datasets. Simpler datasets like SVAMP start high, while harder ones like Countdown begin lower but steadily improve.Middle and Right: We compare the final pass rate,Pass⁡@​1\\operatorname{Pass}@1, with the cumulative “ever pass rate” over steps,EverPass⁡@​1∣t\\operatorname{EverPass}@1\\mid t.\nA consistent gap remains betweenPass⁡@​1\\operatorname{Pass}@1andEverPass⁡@​1∣t\\operatorname{EverPass}@1\\mid t, highlighted by the green shaded area in the figure.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2508.09138/x3.png",
                "caption": "Figure 3:Patterns of entropy evolution over diffusion sampling steps.Responses are generated with a length of 128 using 64 diffusion steps, based on the LLaDA-8B-Instruct model.Left:The average token-level entropy decreases steadily during the sampling process.\nGSM8K exhibits lower entropy than Countdown, consistent with the model’s better performance on GSM8K.Middle and Right:Both Intermediate-Correct and Always-Incorrect questions exhibit higher overall entropy compared to Finally-Correct ones. On GSM8K, Intermediate-Correct questions display lower entropy in the early steps than Always-Incorrect, indicating initial confidence, whereas on Countdown the entropy trend is less stable.\nNote that some points in Right are missing due to the inability to extract answers from generated responses at early diffusion steps for Countdown.",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2508.09138/figures/temporal_entropy.png",
                "caption": "Figure 4:Temporal semantic entropy across four mathematical benchmarks.This metric measures the uncertainty in the semantic content of answers throughout the decoding steps. Statistically, correctly answered questions exhibit lower entropy.",
                "position": 366
            }
        ]
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.09138/x4.png",
                "caption": "Figure 5:(a) Ablations onα\\alphavalue selection in temporal voting with exponential weighting.\n(b) Negative temporal semantic entropy reward curve during reinforcement fine-tuning.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2508.09138/x5.png",
                "caption": "Figure 6:Model attributes after reinforcement finetuning (RFT).(a) Temporal semantic entropy decreases across datasets after RFT, indicating improved semantic consistency in model outputs.\n(b) The ever pass rate remains higher than the final pass rate, suggesting room for continued enhancement.\n(c) The number of effective tokens per generation is reduced after RFT, reflecting more concise outputs. This brevity may contribute to reduced temporal oscillations, though further analysis is needed.",
                "position": 1015
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAppendix Overview",
        "images": []
    },
    {
        "header": "Appendix BMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix CMore Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.09138/x6.png",
                "caption": "Figure S1:Top Row:Pass⁡@​1\\operatorname{Pass}@1andPass⁡@​1∣t\\operatorname{Pass}@1\\mid tfor MATH500 and SVAMP are provided as supplementary results toFig.2, using the same experimental settings.\nA noticeable gap similar to that observed in GSM8K and Countdown betweenPass⁡@​1\\operatorname{Pass}@1andPass⁡@​1∣t\\operatorname{Pass}@1\\mid tis present across all sampling steps.Bottom Row:Answer Entropy for MATH500 and SVAMP are provided as supplementary results toFig.3, using the same experimental setups.\nMATH500 and SVAMP exhibit answer entropy patterns similar to those of GSM8K and Countdown.",
                "position": 1988
            },
            {
                "img": "https://arxiv.org/html/2508.09138/x7.png",
                "caption": "Figure S2:Temporal semantic entropy with varying generation lengths.Average temporal semantic entropy across datasets with generation lengths of 256 and 512, showing consistent patterns withFig.4.\nHigher entropy generally correlates with lower accuracy.",
                "position": 2021
            },
            {
                "img": "https://arxiv.org/html/2508.09138/x8.png",
                "caption": "Figure S3:Block-level entropy dynamics under semi-autoregressive sampling.During sampling, sequences are partitioned into fixed-length blocks, processed in a left-to-right order, with remasking and unmasking operations restricted to the current block.\nAverage token entropy within a block decreases with more sampling steps.\nA sharp entropy spike occurs when shifting to a new block, likely due to simultaneous decoding of multiple masked tokens increasing initial uncertainty.",
                "position": 2038
            },
            {
                "img": "https://arxiv.org/html/2508.09138/figures/temporal_accuracy.png",
                "caption": "Figure S4:Temporal accuracy across datasets.Temporal Accuracy on Sudoku remains consistently low (all below 5%) across different settings, indicating that the model rarely generates correct answers during the sampling process.\nThis scarcity of valid candidates severely limits the effectiveness of voting mechanisms, as there are insufficient correct outputs to reliably converge on the correct answer.",
                "position": 2599
            },
            {
                "img": "https://arxiv.org/html/2508.09138/figures/app_correctness_example1.png",
                "caption": "",
                "position": 2652
            },
            {
                "img": "https://arxiv.org/html/2508.09138/figures/app_correctness_example3.png",
                "caption": "",
                "position": 2680
            },
            {
                "img": "https://arxiv.org/html/2508.09138/figures/app_correctness_example2.png",
                "caption": "",
                "position": 2708
            }
        ]
    },
    {
        "header": "Appendix DMore Experimental Results",
        "images": []
    }
]