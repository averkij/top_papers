[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14276/x1.png",
                "caption": "Figure 1:Average F1 scores of Qwen3Guard-Gen vs. existing guard models across safety classification benchmarks for Prompts and Responses in English, Chinese, and Multilingual datasets.",
                "position": 155
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Safety Policy",
        "images": []
    },
    {
        "header": "3Generative Qwen3Guard",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14276/x2.png",
                "caption": "Figure 2:The Instructions of Generative Qwen3Guard for Prompt and Response Assessment.These sections primarily include the following components: task definition, safety policies, safety categories, refusal criteria (response only), dialogue context, and output formatting specifications.",
                "position": 345
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x3.png",
                "caption": "Figure 3:The Process of Building Controversial Label.The training data is split into two parts. For each part, two models trained with reweighted samples to yieldLooseandStrictpredictions, are applied to annotate the other part. Final labels are assigned via voting where conflicting predictions are marked asControversial.",
                "position": 524
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x4.png",
                "caption": "Figure 4:Precision and Recall for Prompt Classification (Aegis and OpenAIMod) and Response Classification (SafeRLHF and XSTest).Results reveal inconsistency in safety policy across datasets and guard models. For instance, WildGuard-7B aligns well with the Aegis dataset but proves overly restrictive on OpenAIMod.",
                "position": 1591
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x5.png",
                "caption": "Figure 5:Confusion matrices of Qwen3Guard-4B-Gen for categorizing unsafe prompts and responses.Non-Violent=Non-Violent Illegal Acts. PII=Personal Identifiable Information. Political=Political Sensitive Topics.",
                "position": 1603
            },
            {
                "img": "https://arxiv.org/html/2510.14276/figures/qwen3_saferl_training_process_safe_rate.png",
                "caption": "(a)Safety Rate Dynamics",
                "position": 2103
            },
            {
                "img": "https://arxiv.org/html/2510.14276/figures/qwen3_saferl_training_process_safe_rate.png",
                "caption": "(a)Safety Rate Dynamics",
                "position": 2106
            },
            {
                "img": "https://arxiv.org/html/2510.14276/figures/qwen3_saferl_training_process_refusal_rate.png",
                "caption": "(b)Refusal Rate Dynamics",
                "position": 2111
            }
        ]
    },
    {
        "header": "4Stream Qwen3Guard",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14276/x6.png",
                "caption": "Figure 7:Overview of Stream Qwen3Guard.The model enables real-time safety moderation during LLM conversations by introducing two classification heads: thePrompt Moderatorhead evaluates incoming user prompts, while theResponse Moderatorhead assesses each generated token in the streaming output, allowing for immediate intervention if unsafe content is detected.",
                "position": 2157
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x7.png",
                "caption": "Figure 8:Latency of Unsafe Content Detection Measured in Tokens.Top: Detection latency during streaming generation of the model’s direct response output.\nBottom: Detection latency during streaming generation of the model’s thinking contents, followed by its final response.",
                "position": 3278
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x8.png",
                "caption": "Figure 9:Comparison of Moderation Efficiency Between Generative Qwen3Guard and Stream Qwen3Guard in Streaming Scenarios.The time axis shows relative duration, normalized to the time Generative Qwen3Guard takes to moderate its initial 32-token chunk.",
                "position": 3294
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Authors",
        "images": []
    },
    {
        "header": "Appendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14276/x9.png",
                "caption": "Figure 10:The details prompt for prompt classification of Generative Qwen3Guard.",
                "position": 3469
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x10.png",
                "caption": "Figure 11:The details prompt for response classification of Generative Qwen3Guard.",
                "position": 3472
            },
            {
                "img": "https://arxiv.org/html/2510.14276/x11.png",
                "caption": "Figure 12:Confusion matrices of Qwen3Guard-4B-Stream for categorizing unsafe prompts and responses.Non-Violent=Non-Violent Illegal Acts. PII=Personal Identifiable Information. Political=Political Sensitive Topics.",
                "position": 3482
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]