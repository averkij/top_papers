[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/x1.png",
                "caption": "",
                "position": 117
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/x2.png",
                "caption": "Figure 2:The comparison betweenFour-stepgenerated images byTDMunder different training iterations and pre-trained diffusion models with 25 steps and 5.5 CFG. It can be seen that the ultra-fast convergence of our method, without sacrificing the sample quality.",
                "position": 128
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x3.png",
                "caption": "Figure 3:Additional Samples by TDM with 4-step generation on SDXL backbone.",
                "position": 160
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/x4.png",
                "caption": "Figure 4:Trajectory Distribution Matching. An illustration of training 2-step generator by TDM in adata-freeway.",
                "position": 337
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/x5.png",
                "caption": "Figure 5:Qualitative comparisons of TDM against most competing methods on SDXL. All images are generated by the same initial noise.",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x6.png",
                "caption": "Figure 6:The user study about the comparison between our method and the most competing methods.",
                "position": 1140
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x7.png",
                "caption": "Figure 7:The visualization of ODE trajectory with clean samples at different timesteps. It is clear that our method suffers less from the CFG artifact and has better visual quality. The prompt is “A dog reading a book”. SeeAppendixHfor more visualizations.",
                "position": 1255
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x8.png",
                "caption": "Figure 8:4 step generation from LCM and our method initialized by LCM. Our method can recover LCM from poor deterministic sampling via merely 100 training iterations.",
                "position": 1272
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x9.png",
                "caption": "Figure 9:Comparison to DMD2 under LoRA fine-tuning.",
                "position": 1386
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Algorithm",
        "images": []
    },
    {
        "header": "Appendix BDerivations",
        "images": []
    },
    {
        "header": "Appendix CAdditional Related Works",
        "images": []
    },
    {
        "header": "Appendix DExperiment details",
        "images": []
    },
    {
        "header": "Appendix EAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/x10.png",
                "caption": "Figure 10:Visual samples of varying the condition steps and sampling steps. The prompt is “A corgi with sunglasses, traveling in the sea””",
                "position": 2154
            }
        ]
    },
    {
        "header": "Appendix FAblation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_dmd2.jpg",
                "caption": "(a)",
                "position": 2316
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_dmd2.jpg",
                "caption": "(a)",
                "position": 2319
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_naive.jpg",
                "caption": "(b)",
                "position": 2325
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/mode_our.jpg",
                "caption": "(c)",
                "position": 2331
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/match_ablation.jpg",
                "caption": "(a)",
                "position": 2338
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/match_ablation.jpg",
                "caption": "(a)",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/match_our.jpg",
                "caption": "(b)",
                "position": 2347
            }
        ]
    },
    {
        "header": "Appendix GUser Study Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06674/extracted/6274256/fig/user_demo.jpg",
                "caption": "Figure 13:An example of the evaluation question for our user study.",
                "position": 2386
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x11.png",
                "caption": "Figure 14:Additional Samples of integrating LoRA into unseen customized models - dreamshaper.",
                "position": 2403
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x12.png",
                "caption": "Figure 15:Additional Samples of integrating LoRA into unseen customized models - realisticvision.",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2503.06674/x13.png",
                "caption": "Figure 16:Additional visualization of ODE trajectory with clean samples at different timesteps. It is clear that our method suffers less from the CFG artifact and has better visual quality.",
                "position": 2409
            }
        ]
    },
    {
        "header": "Appendix HAdditional Qualitative Results",
        "images": []
    }
]