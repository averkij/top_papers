[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02846/extracted/6251826/figures/teaser.png",
                "caption": "Figure 1:Comparison between DPO and Mask-DPO.Vanilla DPO (a) inadvertently encourages and penalizes all the content in the preferred and non-preferred samples, respectively, regardless of their correctness. Instead, Mask-DPO (b) incorporates sentence-level facticity into the mask signal, preventing incorrect reward signal, which resolves ambiguity in preference learning.",
                "position": 108
            }
        ]
    },
    {
        "header": "2Mask-DPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02846/extracted/6251826/figures/method.png",
                "caption": "Figure 2:The overview of Mask-DPO.First, we sample K candidate responses for each question from the policy model.\nThen, we use a fine-grained hallucination annotator to perform a sentence-level factuality annotation on each response. We use the proportion of correct sentences out of the total number of sentences as the factuality score. We select the responses with the highest and lowest scores as preferred and non-preferred samples, respectively.\nFinally, we perform fine-grained factuality alignment on the policy model using such fine-grained preference data, where the reward signals to the sentences,i.e., incorrect sentences in the preferred samples and correct sentences in the non-preferred samples, would be ignored.",
                "position": 140
            }
        ]
    },
    {
        "header": "3Experiment",
        "images": []
    },
    {
        "header": "4Analysis of Data Scaling",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": []
    },
    {
        "header": "Appendix CAdditional Discussion",
        "images": []
    },
    {
        "header": "Appendix DCase Study",
        "images": []
    },
    {
        "header": "Appendix ELimitation",
        "images": []
    }
]