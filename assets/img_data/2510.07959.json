[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07959/x1.png",
                "caption": "Figure 1:Imbalance. More evaluation budget is spent on less informative samples in test sets.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07959/x2.png",
                "caption": "Figure 2:Problem overview. We aim at selecting a much smaller evaluation dataset than the original evaluation dataset, while keeping the estimated performances as close as possible. Figure3details the selection algorithm and the performance predictor.",
                "position": 181
            }
        ]
    },
    {
        "header": "3Problem",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07959/x3.png",
                "caption": "Figure 3:DISCO overview. First, we select a subset of an evaluation dataset with the most informative samples. Second, we predict the performance of unseen models from their outputs on the selected samples.",
                "position": 198
            }
        ]
    },
    {
        "header": "4Solution",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07959/x4.png",
                "caption": "Figure 4:True and estimated performance on MMLU. Scatter plot of performances of 40 models.",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2510.07959/x5.png",
                "caption": "Figure 5:MMLU performance estimation vs. compression rates. Mean absolute error (MAE), measured in %p difference in accuracy, and the Spearman rank correlation between the true model ranking and the estimated model ranking are shown. At 100 samples, the results are identical to Table1.Main observations: DISCO hits a better efficiency-precision trade-off across all range of compression rates. For extreme compression rate, kNN is a better choice than random forest (RF).",
                "position": 593
            },
            {
                "img": "https://arxiv.org/html/2510.07959/x6.png",
                "caption": "Table 2:Factor analysis for DISCO on MMLU. Highlighted in bold are the default design choices for DISCO. All comparisons are based on 100 selected samples.",
                "position": 614
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Disclaimer for use of LLMs",
        "images": []
    },
    {
        "header": "Appendix AMutual Information and Jensen-Shannon Divergence",
        "images": []
    },
    {
        "header": "Appendix BBounds for Jensen-Shannon Divergence (JSD) via Predictive Diversity Score (PDS)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.07959/x7.png",
                "caption": "Figure 6:True and estimated accuracy on ImageNetfor 50 models.",
                "position": 1826
            },
            {
                "img": "https://arxiv.org/html/2510.07959/x8.png",
                "caption": "Figure 7:ImageNet performance estimation vs. compression rates. Mean absolute error (MAE), measured in %p difference in accuracy, and the Spearman rank correlation between the true model ranking and the estimated model ranking are shown. At 100 samples, the results are identical to Table3.Main observations: Same as for language experiments DISCO hits a better efficiency-precision trade-off across all range of compression rates.",
                "position": 1840
            }
        ]
    },
    {
        "header": "Appendix CVision results",
        "images": []
    }
]