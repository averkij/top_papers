[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15649/x1.png",
                "caption": "Figure 2:Long context understanding performance on VTCBench (first row) and VTCBench-Wild (second row). Under the VTC paradigm, existing VLMs show good textual perception ability, leading to relatively strong performance in simple retrieval tasks. However, they still exhibit weaker long-content comprehension (associative reasoning and long-term dialogue memory) compared to LLMs, highlighting a substantial opportunity to enhance VLMs—especially when processing vision-text compression-based information.",
                "position": 294
            }
        ]
    },
    {
        "header": "3VTCBench",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15649/x2.png",
                "caption": "(a)Performance on VTC-Retrieval MQ-NIAH.",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x2.png",
                "caption": "(a)Performance on VTC-Retrieval MQ-NIAH.",
                "position": 1420
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x3.png",
                "caption": "(b)Performance on VTC-Reasoning.",
                "position": 1425
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x4.png",
                "caption": "(a)MV-NIAH: 1 key, 2 values.",
                "position": 1526
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x4.png",
                "caption": "(a)MV-NIAH: 1 key, 2 values.",
                "position": 1529
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x5.png",
                "caption": "(b)MQ-NIAH: 2 keys, 1 value each.",
                "position": 1534
            }
        ]
    },
    {
        "header": "5VTCBench-Wild",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7VTCBench Description",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15649/x6.png",
                "caption": "Figure S1:Rendering pipeline of VTCBench.\\faIconmarkdownmarkdown‑itinterprets context as HTML.\\faIconchromeplaywrightis a browser-based rendering engine prints HTML to PDF, where styles are injected as CSS.\\faIconpastepymupdfconverts each page in PDF as an image.",
                "position": 1921
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x6.png",
                "caption": "Figure S2:Distribution of context length (in number of text tokens) versus number of images for VTC-Memory with rendering operatorℜconversation{\\mathfrak{R}_{\\texttt{conversation}}}. A strong correlation of approximately 2,000 tokens per image can be inferred.",
                "position": 1939
            },
            {
                "img": "https://arxiv.org/html/2512.15649/fig/ruler_sample.jpeg",
                "caption": "(a)VTC-Retrieval example with a context length of 2k.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2512.15649/fig/ruler_sample.jpeg",
                "caption": "(a)VTC-Retrieval example with a context length of 2k.",
                "position": 2155
            },
            {
                "img": "https://arxiv.org/html/2512.15649/fig/nolima_sample.jpeg",
                "caption": "(b)VTC-Reasoning example, with a context length of 2k.",
                "position": 2160
            },
            {
                "img": "https://arxiv.org/html/2512.15649/fig/locomo_sample.jpeg",
                "caption": "(c)VTC-Memory example (1st of 15), about 30,000 text tokens in total.",
                "position": 2165
            }
        ]
    },
    {
        "header": "8Calculation of Compression Ratio",
        "images": []
    },
    {
        "header": "9Experimental Details",
        "images": []
    },
    {
        "header": "10Prompts",
        "images": []
    },
    {
        "header": "11Limitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15649/x7.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3477
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x7.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x8.png",
                "caption": "(b)Gemma3-27B",
                "position": 3485
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x9.png",
                "caption": "(c)GLM-4.1V-9B-Thinking",
                "position": 3491
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x10.png",
                "caption": "(d)Glyph",
                "position": 3496
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x11.png",
                "caption": "(e)GPT-5",
                "position": 3502
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x12.png",
                "caption": "(f)InternVL3.5-8B",
                "position": 3507
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x13.png",
                "caption": "(g)InternVL3.5-38B",
                "position": 3513
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x14.png",
                "caption": "(h)Kimi-VL-A3B-Instruct",
                "position": 3518
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x15.png",
                "caption": "(i)Qwen2.5-VL-7B-Instruct",
                "position": 3524
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x16.png",
                "caption": "(j)Qwen2.5-VL-72B-Instruct",
                "position": 3529
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x17.png",
                "caption": "(k)Qwen3-VL-8B-Instruct",
                "position": 3535
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x18.png",
                "caption": "(l)Qwen3-VL-235B-A22B-Instruct",
                "position": 3540
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x19.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3547
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x19.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3550
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x20.png",
                "caption": "(b)Gemma3-27B",
                "position": 3555
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x21.png",
                "caption": "(c)GLM-4.1V-9B-Thinking",
                "position": 3561
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x22.png",
                "caption": "(d)Glyph",
                "position": 3566
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x23.png",
                "caption": "(e)GPT-5",
                "position": 3572
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x24.png",
                "caption": "(f)InternVL3.5-8B",
                "position": 3577
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x25.png",
                "caption": "(g)InternVL3.5-38B",
                "position": 3583
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x26.png",
                "caption": "(h)Kimi-VL-A3B-Instruct",
                "position": 3588
            },
            {
                "img": "https://arxiv.org/html/2512.15649/",
                "caption": "(i)Qwen2.5-VL-7B-Instruct",
                "position": 3594
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x28.png",
                "caption": "(j)Qwen2.5-VL-72B-Instruct",
                "position": 3599
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x29.png",
                "caption": "(k)Qwen3-VL-8B-Instruct",
                "position": 3605
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x30.png",
                "caption": "(l)Qwen3-VL-235B-A22B-Instruct",
                "position": 3610
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x31.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3617
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x31.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3620
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x32.png",
                "caption": "(b)Gemma3-27B",
                "position": 3625
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x33.png",
                "caption": "(c)GLM-4.1V-9B-Thinking",
                "position": 3631
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x34.png",
                "caption": "(d)Glyph",
                "position": 3636
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x35.png",
                "caption": "(e)GPT-5",
                "position": 3642
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x36.png",
                "caption": "(f)InternVL3.5-8B",
                "position": 3647
            },
            {
                "img": "https://arxiv.org/html/2512.15649/",
                "caption": "(g)InternVL3.5-38B",
                "position": 3653
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x38.png",
                "caption": "(h)Kimi-VL-A3B-Instruct",
                "position": 3658
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x39.png",
                "caption": "(i)Qwen2.5-VL-7B-Instruct",
                "position": 3664
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x40.png",
                "caption": "(j)Qwen2.5-VL-72B-Instruct",
                "position": 3669
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x41.png",
                "caption": "(k)Qwen3-VL-8B-Instruct",
                "position": 3675
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x42.png",
                "caption": "(l)Qwen3-VL-235B-A22B-Instruct",
                "position": 3680
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x43.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3687
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x43.png",
                "caption": "(a)Gemini-2.5-Pro",
                "position": 3690
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x44.png",
                "caption": "(b)Gemma3-27B",
                "position": 3695
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x45.png",
                "caption": "(c)GLM-4.1V-9B-Thinking",
                "position": 3701
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x46.png",
                "caption": "(d)Glyph",
                "position": 3706
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x47.png",
                "caption": "(e)GPT-5",
                "position": 3712
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x48.png",
                "caption": "(f)InternVL3.5-8B",
                "position": 3717
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x49.png",
                "caption": "(g)InternVL3.5-38B",
                "position": 3723
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x50.png",
                "caption": "(h)Kimi-VL-A3B-Instruct",
                "position": 3728
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x51.png",
                "caption": "(i)Qwen2.5-VL-7B-Instruct",
                "position": 3734
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x52.png",
                "caption": "(j)Qwen2.5-VL-72B-Instruct",
                "position": 3739
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x53.png",
                "caption": "(k)Qwen3-VL-8B-Instruct",
                "position": 3745
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x54.png",
                "caption": "(l)Qwen3-VL-235B-A22B-Instruct",
                "position": 3750
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x55.png",
                "caption": "(a)Qwen3-8B (LLM baseline)",
                "position": 3757
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x55.png",
                "caption": "(a)Qwen3-8B (LLM baseline)",
                "position": 3760
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x56.png",
                "caption": "(b)Gemini-2.5-Pro",
                "position": 3765
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x57.png",
                "caption": "(c)Gemma3-27B",
                "position": 3771
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x58.png",
                "caption": "(d)GLM-4.1V-9B-Thinking",
                "position": 3776
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x59.png",
                "caption": "(e)Glyph",
                "position": 3782
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x60.png",
                "caption": "(f)GPT-5",
                "position": 3787
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x61.png",
                "caption": "(g)InternVL3.5-8B",
                "position": 3793
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x62.png",
                "caption": "(h)InternVL3.5-38B",
                "position": 3798
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x63.png",
                "caption": "(i)Kimi-VL-A3B-Instruct",
                "position": 3804
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x64.png",
                "caption": "(j)Qwen2.5-VL-7B-Instruct",
                "position": 3809
            },
            {
                "img": "https://arxiv.org/html/2512.15649/x65.png",
                "caption": "(k)Qwen2.5-VL-72B-Instruct",
                "position": 3815
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]