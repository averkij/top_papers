[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15760/x1.png",
                "caption": "Figure 1:Construction and Evaluation framework of LiveMCP-101.",
                "position": 200
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3LiveMCP-101",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15760/x2.png",
                "caption": "Figure 3:Distribution of tool-chain lengths in the LiveMCP-101 execution plans.",
                "position": 375
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15760/x3.png",
                "caption": "(a)",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2508.15760/x3.png",
                "caption": "(a)",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2508.15760/x4.png",
                "caption": "(b)",
                "position": 680
            },
            {
                "img": "https://arxiv.org/html/2508.15760/x5.png",
                "caption": "Figure 5:Ablation study results.(a)TSR (%) vs. max iteration rounds: all models improve from 15 to around 25 rounds, then plateau.(b)Relative TSR change w.r.t. 15-round setting shows diminishing returns beyond about 25.(c)TSR (%) vs. number of MCP servers: top-tier models remain largely stable, while weaker or mid-tier models degrade as distractors grow.(d)Relative change w.r.t. 6-server setting shows that larger pools affect weaker models more, consistent with long-context sensitivity and tool-selection noise.",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2508.15760/x6.png",
                "caption": "Figure 6:Human–LLM agreement (Cohen’sκ\\kappa, %) on result and trajectory evaluation for six models. Blue bars denote scores for the result evaluation, and pink bars denote scores for the trajectory evaluation.",
                "position": 710
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15760/x7.png",
                "caption": "Figure 7:Error classification heatmap across models. The leftmost column (Correct) aligns with TSR, while the remaining columns decompose failures into 7 fine-grained subtypes.",
                "position": 774
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompts",
        "images": []
    }
]