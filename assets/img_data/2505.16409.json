[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16409/x1.png",
                "caption": "Figure 1:Overview of retrieval-augmented reasoning process.Left:FREESONperforms both reasoning and retrieval using a single generator model via token-levelCT-MCTS.Right:conventional RAR methods compute similarity scores between query and document embeddings using a separate retrieval model.FREESONfully leverages the LRM’s reasoning over document structure, enabling precise access to relevant information from the corpus at inference time without relying on memorization.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.16409/x2.png",
                "caption": "Figure 2:Impact of node granularity on system efficiency and performance (1 – 10 tokens per node).Left: Latency (s) sharply decreases with higher granularity, enabling faster search.Middle: As granularity increases, the retrieved path becomes longer (more informative), while the rollout count remains similar—indicating more efficient search per computation.Right: Higher granularity leads to better performance.",
                "position": 523
            }
        ]
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset Statistics & Retrieval Settings",
        "images": []
    },
    {
        "header": "Appendix BAnalysis on Varying Node Granularity",
        "images": []
    },
    {
        "header": "Appendix CLimitations of Ground-truth Annotations in QA Benchmarks",
        "images": []
    },
    {
        "header": "Appendix DPrompt Template forFREESON",
        "images": []
    }
]