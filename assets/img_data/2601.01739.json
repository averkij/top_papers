[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.01739/figures/EXAONE_Symbol_3d.png",
                "caption": "",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2601.01739/x1.png",
                "caption": "Figure 1:The main evaluation results of K-EXAONE across eight categories: world knowledge (MMLU-Pro), math (AIME 2025), coding (LiveCodeBench v6), agentic tool use (τ2\\tau^{2}-Bench), instruction following (IFBench), Korean (KoBALT), multilinguality (MMMLU), and safety (KGC-Safety). All models used in assessment are reasoning models.τ2\\tau^{2}-Benchscores are weighted average.",
                "position": 141
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Modeling",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.01739/x2.png",
                "caption": "Figure 2:An illustration of K-EXAONE model architecture.\nThe model comprises a stack of MoE blocks, with only the first layer implemented as a dense layer for training stability. In each MoE block, eight routed experts are selected from a pool of 128 experts, together with one shared expert, resulting in a total of nine concurrently utilized experts per routing decision. An MTP-based auxiliary objective is applied during training to supervise the prediction of an additional +1 future token.",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2601.01739/x3.png",
                "caption": "Figure 3:Comparison of tokenizer efficiency, measured in bytes per token, between K-EXAONE and EXAONE 4.0 across diverse text domains.",
                "position": 244
            }
        ]
    },
    {
        "header": "3Training",
        "images": []
    },
    {
        "header": "4Evaluation",
        "images": []
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Deployment",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Appendix AContributors",
        "images": []
    },
    {
        "header": "Appendix BModel License",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Setup Details",
        "images": []
    },
    {
        "header": "Appendix DIn-house Benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.01739/x4.png",
                "caption": "Figure 9:CodeUtilityBenchPerformance.",
                "position": 1624
            }
        ]
    },
    {
        "header": "Appendix EFurther Analysis",
        "images": []
    },
    {
        "header": "Appendix FSafety",
        "images": []
    }
]