[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/figures/supplementary/moonstep.png",
                "caption": "",
                "position": 117
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/x1.png",
                "caption": "Figure 1:Our proposed lightweightLatent Upscaler Adapter(LUA) integrates into diffusion pipelineswithoutretraining the generator/decoder andwithoutan extra diffusion stage. The example uses a FLUX[2]generator: it produces a64×6464{\\times}64latent for a512512px image (red dashed path decodes directly). Our path (green dashed) upsamples the same latent to128×128128{\\times}128(×2\\times 2) or256×256256{\\times}256(×4\\times 4) and decodes once to10241024px or20482048px, adding only+0.42+0.42s (1K) and+2.21+2.21s (2K) on an NVIDIA L40S GPU. LUA outperforms multi-stage high-resolution pipelines while avoiding their extra diffusion passes, and achieves efficiency competitive with image-space SR at comparable perceptual quality, all via a single final decode.",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x2.png",
                "caption": "Figure 2:Upscaling FLUX outputs[2]from10242→204821024^{2}{\\rightarrow}2048^{2}. Columns: (1) base decode, (2) bicubiclatent, (3) SwinIRimage-space SR, (4) LUAlatent-space SR. Top: runtime overhead vs. (1). Middle (8×8\\timescrops): bicubic blurs/aliases; SwinIR sharpens but adds noise/texture drift; LUA preserves eyelashes and skin with stable edges. Bottom: Laplacian-variance maps (darker = less noise) with means—LUA attains the lowest residual noise and the smallest overhead via single-decode latent upscaling.",
                "position": 156
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/x3.png",
                "caption": "Figure 3:Cross-model2×2\\timeslatent upscaling with a single adapter. For SDXL[28], SD3[11], and FLUX[2], a128×128128{\\times}128latent is upscaled to256×256256{\\times}256by the same LUA and decoded once by each model’s native VAE to yield204822048^{2}images. SD3 and FLUX shareC=16C{=}16latents; SDXL (C=4C{=}4) is supported by changing only the first convolution. Insets show artifact-free detail preservation; green boxes mark×8\\times 8zooms.",
                "position": 241
            }
        ]
    },
    {
        "header": "3Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/figures/figure_4.jpg",
                "caption": "Figure 4:Architecture of the Latent Upscaler Adapter (LUA). A SwinIR-style backbone[24]is shared across scales; a1×11{\\times}1input conv adapts the VAE latent width (C=16C{=}16for FLUX/SD3;C=4C{=}4for SDXL). Scale-specific pixel-shuffle heads output×2\\times 2or×4\\times 4latents. At inference, the path selects the input adapter, runs the shared backbone, and activates the requested head. The schematic shows FLUX/SD3×2\\times 2and SDXL×4\\times 4.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x4.png",
                "caption": "Figure 5:Effect of the three-stage curriculum on latent reconstruction and decoded appearance (FLUX backbone). The2×42{\\times}4grid showstop: latent feature maps (channel 10, min–max normalized);bottom: corresponding8×8{\\times}zoomed decodes. Columns: (1) original low-resolution latent (1282128^{2}) and decode; (2–4) LUA upscaled latents to2562256^{2}after Stage I–III with their decodes. Yellow boxes mark the zoomed region. From (2) to (4), decodes become less noisy and more structured; Stage III concentrates high-frequency energy around details, indicating that controlled latent noise aids faithful VAE decoding.",
                "position": 448
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/x5.png",
                "caption": "Figure 6:Qualitative comparison at204822048^{2}and409624096^{2}starting from the same102421024^{2}SDXL base generations. Each row uses identical seeds and prompts (GPT-generated captions from OpenImages validation). Red boxes indicate12×12\\timesmagnified crops; titles report per-image runtime. For visual clarity we show the DemoFusion+LSRNA variant in place of plain DemoFusion. The column withSDXL+LUA (ours)achieves the lowest latency and produces clean, stable textures without the high-resolution artifacts (e.g., repetition, gridding) seen in direct high-res sampling, and without the sharpening noise typical of pixel-space SR.",
                "position": 804
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining and Resource Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/x6.png",
                "caption": "Figure 7:Visualization of all losses in the three-stage curriculum:\nlatent reconstruction/frequency (Rows 1–2), downsample consistency and\nhigh-frequency residuals (Rows 3–4), and pixel reconstruction,\npixel frequency, and EAGLE texture (Rows 5–7). Columns show prediction,\nground truth, the corresponding error map, and the loss formula; brighter\nregions indicate larger gradient contributions.",
                "position": 1589
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x7.png",
                "caption": "Figure 8:Artifacts from a pixel-only baseline trained without latent\nnormalization. Decoded crops show saturated streaks and “broken”\npixels caused by out-of-range latents passed to the frozen VAE\ndecoder. These failures are avoided by the proposed three-stage\nlatent–pixel curriculum.",
                "position": 1665
            }
        ]
    },
    {
        "header": "Appendix BValidation Prompts and Captions",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/x8.png",
                "caption": "Figure 9:Caption-conditioned multi-resolution generation on the\nvalidation set. For each held-out photograph (left), we obtain a\nstructured caption via the procedure in\nSec.B.1(second column) and synthesize SDXL\nimages at102421024^{2},204822048^{2}, and409624096^{2}from the same prompt\n(right). While global semantics are preserved, native high-resolution\nsampling introduces hallucinations such as object multiplication and\nexaggerated detail, motivating the11K+upscaling strategy in\nSec.D.2.",
                "position": 1766
            }
        ]
    },
    {
        "header": "Appendix CBaseline and Reproduction Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10629/figures/supplementary/visualization_of_distributions.png",
                "caption": "Figure 10:KDEs of channel-aggregated mean and standard deviation in\nlatent (top) and pixel (bottom) domains for low-resolution inputs\n(blue), high-resolution targets (orange), and LUA outputs (green).\nLatent distributions are complex and multimodal, with low-resolution\nlatents collapsing high-resolution modes (red arrows), whereas pixel\ndistributions remain simple and stable.",
                "position": 1974
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x9.png",
                "caption": "Figure 11:Representative hallucinations in native high-resolution SDXL\nsampling. For SDXL generations at204822048^{2}and409624096^{2}, we show cropped\nexamples corresponding to the most frequent artifact types identified by\nthe auditor: Merged Objects, Incorrect Anatomy, Merged Limbs, Unnatural\nHighlights, Incorrect Limb Count, and Awkward Framing. These crops\nillustrate characteristic failure modes that become increasingly common\nas the native sampling resolution grows\n(Table6).",
                "position": 2036
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x10.png",
                "caption": "Figure 12:FLUX+LUA qualitative examples at204822048^{2}(set 1). For each\nprompt, FLUX generates a128×128128{\\times}128latent (12 denoising steps),\nLUA upsamples it to256×256256{\\times}256, and the native FLUX VAE decodes\nonce to a2048×20482048{\\times}2048image. Insets show×8\\times 8zooms\nhighlighting fine structures (hair, fabric, foliage) preserved by\nlatent upscaling. Timings (generation: 46.57 s; upscaling: 0.63 s;\ndecoding: 3.40 s) are measured on a single NVIDIA L40S GPU.",
                "position": 2336
            },
            {
                "img": "https://arxiv.org/html/2511.10629/x11.png",
                "caption": "Figure 13:FLUX+LUA qualitative examples at204822048^{2}(set 2). The\npipeline is identical to Fig.12:\nFLUX samples a128×128128{\\times}128latent with 12 denoising steps, LUA\nperforms a single2×2\\timeslatent upscaling step, and the FLUX\ndecoder produces the final2048×20482048{\\times}2048image. Examples cover\ndiverse content (portraits, indoor scenes, complex textures) and\nillustrate that theC=16C{=}16FLUX latents provide sufficient capacity\nfor LUA to add high-frequency detail with minimal runtime overhead.",
                "position": 2345
            }
        ]
    },
    {
        "header": "Appendix EAdditional FLUX-based Visualizations",
        "images": []
    }
]