[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1INTRODUCTION",
        "images": []
    },
    {
        "header": "2RELATED WORK",
        "images": []
    },
    {
        "header": "3PROBLEM DEFINITION",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Annotation_Framework_Overview.png",
                "caption": "Figure 1:Overall annotation processing framework.",
                "position": 408
            }
        ]
    },
    {
        "header": "4METHODOLOGY",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Model_Overview.png",
                "caption": "Figure 2:Overview of WAY architecture.",
                "position": 436
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Trajectory_Representation.png",
                "caption": "Figure 3:An example of reorganizing AIS trajectory in WAY. TheRedarrow indicates the very first observation in given trajectory, and theBluearrows show the sampled observations defining subsequences from each region.Δ\\Deltadenotes the time distance measured in days.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Spatial_Encoding_sample.png",
                "caption": "Figure 4:The example output of Spatial Encoding, given a sequence of grid coordinates from the above trajectory.",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Spatial_Encoding.png",
                "caption": "Figure 5:An example of Spatial Encoding result. (a) indicates the longitude-wise Euclidean distances between encoded vectors, (b) is the distance between vectors arranged in latitudes, and (c) visualizes the 3-dimensional PCA result of encoded vectors∈ℝd\\in\\mathbb{R}^{d}from the whole1×11\\times 1(∘2{}^{{\\circ}^{2}}) grids, where theBlueare sampled in (a) andRedas (b).",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Multihead_Channel_Attention.png",
                "caption": "Figure 6:Multi-head Channel Attention Module.",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Gradient_Dropout.png",
                "caption": "Figure 7:An example of Gradient Dropout learning technique. (a) shows the valid steps of instances in the training batch and (b) visualizes the same batch after the technique is applied.",
                "position": 737
            }
        ]
    },
    {
        "header": "5EXPERIMENTS",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-model_estimation_example.png",
                "caption": "Figure 8:The actual estimation result of each comparison model for the sample test trajectory. The trajectory proceeds from theRedmarker (Departure port) to theBluemarker (Destination port). The grids are coloredGreenif the estimation was correct at the respective steps, while theOrangedenotes the model has estimated the wrong destination.",
                "position": 1406
            }
        ]
    },
    {
        "header": "6DISCUSSION",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13190/authors/Auth-JinSobKim.png",
                "caption": "",
                "position": 2210
            },
            {
                "img": "https://arxiv.org/html/2512.13190/authors/Auth-HyunJoonPark.png",
                "caption": "",
                "position": 2216
            },
            {
                "img": "https://arxiv.org/html/2512.13190/authors/Auth-WooseokShin.png",
                "caption": "",
                "position": 2222
            },
            {
                "img": "https://arxiv.org/html/2512.13190/authors/Auth-DongIlPark.png",
                "caption": "",
                "position": 2228
            },
            {
                "img": "https://arxiv.org/html/2512.13190/authors/Auth-SungWonHan.png",
                "caption": "",
                "position": 2234
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Posterior_Validation_Candidates.png",
                "caption": "Figure 9:Visualization of posterior candidate validation in-process. The voyage proceeds from left to right, and colors denote observations with the port as one of the candidates. (a) and (b) are expanded images from the box regions above, illustrating the geo-polygons of each port and their thresholds around these areas.",
                "position": 2422
            },
            {
                "img": "https://arxiv.org/html/2512.13190/figures/Fig-Abnormal_Edge_Detection.png",
                "caption": "Figure 10:Examples of illogical movement detected using the DBSCAN algorithm. TheRededges are excluded as anomalies.",
                "position": 2436
            }
        ]
    },
    {
        "header": "7CONCLUSION",
        "images": []
    }
]