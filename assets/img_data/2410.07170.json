[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07170/x1.png",
                "caption": "Figure 1:Left:EVA performs singular value decomposition on activation vectors for the first few minibatches to obtain a suitable initialization for the LoRA matrixùë®ùë®\\bm{A}bold_italic_A.Right:After initializingùë®ùë®\\bm{A}bold_italic_A, we allocate ranks to maximize the explained variance throughout the model and continue the standard LoRA fine-tuning procedure, whereùëæùëæ\\bm{W}bold_italic_Wis kept frozen and onlyùë®ùë®\\bm{A}bold_italic_Aandùë©ùë©\\bm{B}bold_italic_Bare trained.",
                "position": 168
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07170/x2.png",
                "caption": "Figure 2:Left:Training loss for fine-tuningLlama-3.1-8Bon the MetaMathQA dataset. We compare EVA to recently proposed initialization methods OLoRA, PiSSA, and random initialization (LoRA). We show mean and standard deviation across three random seeds.Right:Mean and standard deviation of gradient norm for EVA, PiSSA, OLoRA and Random initialization of LoRA matrices. EVA exhibits significantly larger gradient norm leading to faster convergence.",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x3.png",
                "caption": "",
                "position": 255
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07170/x4.png",
                "caption": "Figure 3:Left:Time in seconds until convergence of incremental SVD components for different batch sizes forLlama-2-7Bon the MetaMathQA dataset. The dashed line indicates the total number of components.Right:Average cosine similarity between SVD components across 10 random seeds for permuting the batch order. The first 10 components remain mostly consistent across all permutations. While the remaining components vary, they strongly correlate with each other.",
                "position": 1581
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x5.png",
                "caption": "",
                "position": 1590
            }
        ]
    },
    {
        "header": "5Discussion and Limitations",
        "images": []
    },
    {
        "header": "6Conclusion and Broader Impact",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AReproducibility Statement",
        "images": []
    },
    {
        "header": "Appendix BNatural language generation",
        "images": []
    },
    {
        "header": "Appendix CNatural language understanding",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07170/x6.png",
                "caption": "Figure 4:Rank distribution after initialization with EVA on four tasks of the GLUE benchmark (CoLA, MRPC, RTE, STSB) forDeBERTav3BasesubscriptDeBERTav3Base\\text{DeBERTav3}_{\\text{Base}}DeBERTav3 start_POSTSUBSCRIPT Base end_POSTSUBSCRIPT(left) andRoBERTaLargesubscriptRoBERTaLarge\\text{RoBERTa}_{\\text{Large}}RoBERTa start_POSTSUBSCRIPT Large end_POSTSUBSCRIPT(right) with initial rankr=2ùëü2r=2italic_r = 2.",
                "position": 4679
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x7.png",
                "caption": "Figure 5:Rank distribution after initialization with EVA on four tasks of the GLUE benchmark (CoLA, MRPC, RTE, STSB) forDeBERTav3BasesubscriptDeBERTav3Base\\text{DeBERTav3}_{\\text{Base}}DeBERTav3 start_POSTSUBSCRIPT Base end_POSTSUBSCRIPT(left) andRoBERTaLargesubscriptRoBERTaLarge\\text{RoBERTa}_{\\text{Large}}RoBERTa start_POSTSUBSCRIPT Large end_POSTSUBSCRIPT(right) with initial rankr=4ùëü4r=4italic_r = 4.",
                "position": 4682
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x8.png",
                "caption": "Figure 6:Rank distribution after initialization with EVA on four tasks of the GLUE benchmark (CoLA, MRPC, RTE, STSB) forDeBERTav3BasesubscriptDeBERTav3Base\\text{DeBERTav3}_{\\text{Base}}DeBERTav3 start_POSTSUBSCRIPT Base end_POSTSUBSCRIPT(left) andRoBERTaLargesubscriptRoBERTaLarge\\text{RoBERTa}_{\\text{Large}}RoBERTa start_POSTSUBSCRIPT Large end_POSTSUBSCRIPT(right) with initial rankr=8ùëü8r=8italic_r = 8.",
                "position": 4685
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x9.png",
                "caption": "Figure 7:Rank distribution after initialization with EVA on four tasks of the GLUE benchmark (CoLA, MRPC, RTE, STSB) forDeBERTav3BasesubscriptDeBERTav3Base\\text{DeBERTav3}_{\\text{Base}}DeBERTav3 start_POSTSUBSCRIPT Base end_POSTSUBSCRIPT(left) andRoBERTaLargesubscriptRoBERTaLarge\\text{RoBERTa}_{\\text{Large}}RoBERTa start_POSTSUBSCRIPT Large end_POSTSUBSCRIPT(right) with initial rankr=16ùëü16r=16italic_r = 16.",
                "position": 4688
            }
        ]
    },
    {
        "header": "Appendix DImage Classification",
        "images": []
    },
    {
        "header": "Appendix EDecision Making",
        "images": []
    },
    {
        "header": "Appendix FSVD convergence analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07170/x10.png",
                "caption": "Figure 8:Average cosine similarity between components obtained via SVD on minibatches of activation vectors across different batch sizes. The components strongly correlate indicating that the SVD computation is mostly invariant to the batch size and returns mostly the same components.",
                "position": 6096
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x11.png",
                "caption": "Figure 9:The resulting rank allocation per weight matrix in each layer forLlama-2-7Bon the MetaMathQA dataset with different values ofœÅùúå\\rhoitalic_œÅ. The first row represents a uniform distribution where each weight matrix receives the same rankr=16ùëü16r=16italic_r = 16. The most change occurs forœÅ<1.5ùúå1.5\\rho<1.5italic_œÅ < 1.5. The re-distribution converges for larger values ofœÅùúå\\rhoitalic_œÅ.",
                "position": 6118
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x12.png",
                "caption": "Figure 10:Deltas between rank distributions per weight matrix in each layer forLlama-2-7Bon the MetaMathQA dataset with different values ofœÅùúå\\rhoitalic_œÅ. The first row represents a uniform distribution where each weight matrix receives the same rankr=16ùëü16r=16italic_r = 16. The most change occurs in the rangeœÅ‚àà[1,1.5]ùúå11.5\\rho\\in[1,1.5]italic_œÅ ‚àà [ 1 , 1.5 ]. Larger values ofœÅùúå\\rhoitalic_œÅdo not induce additional significant changes to the rank distribution.",
                "position": 6121
            },
            {
                "img": "https://arxiv.org/html/2410.07170/x13.png",
                "caption": "Figure 11:Accuracy for different values ofœÅùúå\\rhoitalic_œÅwhen fine-tuningLlama-2-7Bon the MetaMathQA dataset.",
                "position": 6124
            }
        ]
    },
    {
        "header": "Appendix GRank re-distribution analysis",
        "images": []
    }
]