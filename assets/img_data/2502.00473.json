[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x1.png",
                "caption": "Figure 1:W2SD leverages the gap between weak and strong models to approximate the gap between strong and ideal models.",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x2.png",
                "caption": "Figure 2:The qualitative results of W2SD demonstrate the effectiveness of our method in various aspects, such as text rendering, position, color, counting, and object co-occurrence. We present more cases in AppendixC.2.",
                "position": 184
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x3.png",
                "caption": "Figure 3:Visualizing the effectiveness of W2SD. When the weak-to-strong difference closely approximates the strong-to-ideal difference (e.g.,Î”2â¢(t)âˆ’Î”1â¢(t)subscriptÎ”2ð‘¡subscriptÎ”1ð‘¡\\Delta_{2}(t)-\\Delta_{1}(t)roman_Î” start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) - roman_Î” start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t )is small), the refined latent variablex~tsubscript~ð‘¥ð‘¡\\tilde{x}_{t}over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTconverges to the ideal latent variablextgtsuperscriptsubscriptð‘¥ð‘¡gtx_{t}^{\\mathrm{gt}}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_gt end_POSTSUPERSCRIPT.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x4.png",
                "caption": "Figure 4:Denoising trajectories across different settings (1-D Gauss). The weak model (blue) generates only right-peak data due to missing left-peak training samples, while the strong model (red) produces data between both peaks. W2SD balances the distribution by leveraging the reflective operatorâ„³invwâ¢(â„³sâ¢(â‹…))superscriptsubscriptâ„³invwsuperscriptâ„³sâ‹…\\mathcal{M}_{\\mathrm{inv}}^{\\mathrm{w}}(\\mathcal{M}^{\\mathrm{s}}(\\cdot))caligraphic_M start_POSTSUBSCRIPT roman_inv end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT ( caligraphic_M start_POSTSUPERSCRIPT roman_s end_POSTSUPERSCRIPT ( â‹… ) ).",
                "position": 368
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x5.png",
                "caption": "Figure 5:Probability contour plot and denoising trajectories across different settings (2-D Gauss). W2SD balances the learned distribution, bringing it closer to the real data distribution",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x6.png",
                "caption": "Figure 6:Qualitative results of W2SD based on dataset differences (CIFAR-10). Our method enhances the probability of generating â€œcarsâ€ and promote a more balanced generation distribution.",
                "position": 393
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x7.png",
                "caption": "Figure 7:The CLIP feature corresponding to the generated image (32Ã—\\timesÃ—32Ã—\\timesÃ—3) is projected into a 2D space. W2SD effectively disentangles the\nrepresentations of â€œcarâ€ and â€œhorseâ€ in the 2D space.(a)â„³ssuperscriptâ„³s\\mathcal{M}^{\\mathrm{s}}caligraphic_M start_POSTSUPERSCRIPT roman_s end_POSTSUPERSCRIPTdemonstrates the ability to generate cars;(b)â„³wsuperscriptâ„³w\\mathcal{M}^{\\mathrm{w}}caligraphic_M start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPTcan hardly generate cars;(c)W2SD balances the generation distribution, increasing the likelihood of generating cars;(d)S2WD (i.e.,â„³iâ¢nâ¢vsâ¢(â„³wâ¢(â‹…))superscriptsubscriptâ„³ð‘–ð‘›ð‘£ð‘ superscriptâ„³ð‘¤â‹…\\mathcal{M}_{inv}^{s}(\\mathcal{M}^{w}(\\cdot))caligraphic_M start_POSTSUBSCRIPT italic_i italic_n italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ( caligraphic_M start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT ( â‹… ) )) exacerbates the imbalance in data generation.",
                "position": 399
            }
        ]
    },
    {
        "header": "4Empirical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x8.png",
                "caption": "Figure 8:Qualitative comparisons with weak model (left), strong model (middle) and W2SD based on weight difference (right). Our method utilizes the differences between chosen strong and weak models (e.g., high-detail LoRA vs. standard model) to deliver improvements in various dimensions, including style, character, clothing, and beyond. We provide more qualitative results inSectionC.2.",
                "position": 419
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x9.png",
                "caption": "Figure 9:Quantitative Results of W2SD Based on the MoE Mechanism. Thefirst rowshows the results for DiT-MoE-S, while thesecond rowpresents W2SD. W2SD achieves significant improvements, even with small models featuring 71M activated parameters.",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x10.png",
                "caption": "Figure 10:Qualitative results of W2SD based on pipeline difference. We set ControlNet asâ„³ssuperscriptâ„³s\\mathcal{M}^{\\mathrm{s}}caligraphic_M start_POSTSUPERSCRIPT roman_s end_POSTSUPERSCRIPT, DDIM asâ„³wsuperscriptâ„³w\\mathcal{M}^{\\mathrm{w}}caligraphic_M start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT. W2SD improves alignment with reference images.",
                "position": 785
            }
        ]
    },
    {
        "header": "5More Detailed Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x11.png",
                "caption": "Figure 11:The magnitude of weak-to-strong difference is a key factor impacting the\neffects of improvements. The horizontal axis shows the magnitude of the weak-to-strong difference, while the vertical axis\nshows the average HPS v2 on the Pick-a-Pic. Whenâ„³ssuperscriptâ„³s\\mathcal{M}^{\\mathrm{s}}caligraphic_M start_POSTSUPERSCRIPT roman_s end_POSTSUPERSCRIPTis weaker thanâ„³wsuperscriptâ„³w\\mathcal{M}^{\\mathrm{w}}caligraphic_M start_POSTSUPERSCRIPT roman_w end_POSTSUPERSCRIPT, W2SD results in negative gains.",
                "position": 809
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x12.png",
                "caption": "Figure 12:When the weak-to-strong difference is greater than 0, W2SD yields positive gains. When it equals 0, the process degenerates into standard sampling. When it is less than 0, negative gains occurs, resulting in poor image quality.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x13.png",
                "caption": "Figure 13:W2SD outperforms standard sampling with identical time costs. The horizontal axis denotes the average generation time per image, the vertical axis represents the HPS v2 on Pick-a-Pic.",
                "position": 830
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BExperiment Settings",
        "images": []
    },
    {
        "header": "Appendix CSupplementary experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x14.png",
                "caption": "Figure 14:Qualitative results of W2SD based on weight differences (human preference). Here we select xlMoreArtFullV1 as the strong model and SDXL as the weak model. W2SD can effectively enhance the performance of human preference.",
                "position": 2108
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x15.png",
                "caption": "Figure 15:Qualitative results of W2SD based on weight differences (personalization). Here we set LoRA-based personalized model as strong model and the standard model as weak model",
                "position": 2111
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x16.png",
                "caption": "Figure 16:Qualitative results of W2SD based on semantic differences between prompts, which refines the generation process by placing greater emphasis on the fine-grained details.",
                "position": 2121
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x17.png",
                "caption": "Figure 17:Qualitative results of W2SD based on sampling pipeline difference. When the strong model employs Ip-adapter and the weak model utilizes DDIM , W2SD can enhance the alignment of the generated results with the reference image (e.g., style).",
                "position": 2130
            }
        ]
    },
    {
        "header": "Appendix DProofs",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.00473/x18.png",
                "caption": "Figure 18:Re-Sampling, which can be considered a specific instance of W2SD, demonstrates improved performance when the randomly sampled Gaussian noise aligns closely with the perturbation vector introduced by the W2SD reflection mechanism (e.g., cosine similarity>>>0)",
                "position": 2429
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x18.png",
                "caption": "Figure 18:Re-Sampling, which can be considered a specific instance of W2SD, demonstrates improved performance when the randomly sampled Gaussian noise aligns closely with the perturbation vector introduced by the W2SD reflection mechanism (e.g., cosine similarity>>>0)",
                "position": 2432
            },
            {
                "img": "https://arxiv.org/html/2502.00473/x19.png",
                "caption": "Figure 19:Qualitative results of advanced Re-Sampling demonstrate that the improvements effects vary depending on the strategy used to select Gaussian noise for Re-Sampling. It can be considered a specific instance of W2SD.",
                "position": 2437
            }
        ]
    },
    {
        "header": "Appendix EFurther analytical exploration",
        "images": []
    }
]