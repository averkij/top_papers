[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/Figures/logo_black.png",
                "caption": "",
                "position": 220
            },
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x1.png",
                "caption": "",
                "position": 265
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x2.png",
                "caption": "Figure 2:MediX-R1: Overall ArchitectureThe MediX-R1 reinforcement learning framework for open-ended medical reasoning. An input of a medical image and a natural language question is processed by MediX-R1. The modelâ€™s policy is trained using Group Based RL, which leverages a multi-faceted reward signal. This reward is composed of: a) an LLM-based reward for evaluating the overall quality and correctness of the output; b) an embedding-based reward to ensure semantic alignment; c) a format reward to enforce the desired output structure (<think>and<answer>blocks); and d) a modality reward to ensure the response is grounded in the specified imaging modality. This reward-guided approach encourages the model to generate accurate and interpretable reasoning paths.",
                "position": 372
            }
        ]
    },
    {
        "header": "2Open Ended Medical RL",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x3.png",
                "caption": "",
                "position": 393
            }
        ]
    },
    {
        "header": "3Evaluation Framework",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x4.png",
                "caption": "Figure 6:Qualitative examples of MediX-R1. (Top, Microscopy) Correctly identifies the optic tract in section G with interpretable reasoning. (Bottom, X-ray) Explains why heart size appears smaller in PA vs. AP view. MediX-R1 generates clinically grounded, open-ended answersacross modalities.",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x5.png",
                "caption": "",
                "position": 950
            },
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x6.png",
                "caption": "Figure 7:Overall validation reward vs training step across reward designs. Training with individual signals LLM-only or embedding-only shows volatility and reward hacking, while LLM+embedding reduces but does not eliminate instability. MediX-R1 uses a composite reward which stabilizes learning and delivers the highest final reward and best overall performance.",
                "position": 1132
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x7.png",
                "caption": "Figure 8:MediX-R1 - Report Generation: Case 2",
                "position": 1787
            },
            {
                "img": "https://arxiv.org/html/2602.23363/2602.23363v1/x8.png",
                "caption": "Figure 9:MediX-R1 - Report Generation: Case 1",
                "position": 1836
            }
        ]
    },
    {
        "header": "Instructions for reporting errors",
        "images": []
    }
]