[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/fig1.png",
                "caption": "Figure 1:An overview ofSARChat-Bench-2M.The left figure demonstrates the representative tasks realized with the SAR image-text dataset,SARChat-2M, constructed in this paper. Validating the datasetâ€™s efficacy and superiority in supporting multi-task applications. The right figure presents the correlation radar charts and quantitative line graphs derived from the performance evaluation of 16 VLMs basing on this dataset, establishing the benchmark (SARChat-Bench) within this domain.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2502.08168/x1.png",
                "caption": "Figure 2:Construction ofSARChat-2M dataset.On the left, ten existing SAR detection benchmark datasets. The middle part is the SARDet-100K dataset, formed by integrating the ten datasets on the left. On the right, six core tasks constructed based on the dataset are presented, with each task corresponding to different task identifiers, operation steps, and relevant templates.",
                "position": 153
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Data Construction and Description",
        "images": []
    },
    {
        "header": "4Evaluation Method and Settings",
        "images": []
    },
    {
        "header": "5Experiments and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08168/x2.png",
                "caption": "Figure 3:Evaluation examples onSARChat-Bench.VLM predictions are shown in green/red for correct/incorrect descriptions, with the ground truth in green and the predictions in red boxes. And [Human], [Bot], and [Check] denote user input, VLMs response, and standard output, respectively.",
                "position": 960
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/3.png",
                "caption": "Figure 4:Cloud Map of Word-frequency Distribution",
                "position": 1491
            },
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/4.png",
                "caption": "Figure 5:The Proportion Distribution of Samples in the Training Set",
                "position": 1494
            },
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/5.png",
                "caption": "Figure 6:The Proportion Distribution of Samples in the Testing Set",
                "position": 1497
            },
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/6.png",
                "caption": "Figure 7:Morphological distribution",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/7.png",
                "caption": "Figure 8:Train Task Distribution",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2502.08168/extracted/6182748/figures/8.png",
                "caption": "Figure 9:Test Task Distribution",
                "position": 1743
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]