[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04662/x1.png",
                "caption": "Figure 1:VeriCoTverification of aChain-of-Thoughtfor the SARA dataset(Holzenberger et al.,2020).\nEven if the final answer is correct, a CoT that contains an invalid step hurts user trust and raises questions of LLM faithfulness.\nAs shown in §2.1,VeriCoTautoformalizes each step of the CoT into symbolic logic, producing aformulathat ensures each one follows logically from adistilled list of NL premises, each of which itannotates with their source type(e.g. Commonsense or Context)\nIf the CoT cannot be represented this way, it is unverifiable.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Neuro-Symbolic CoT Verification Algorithm",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.04662/failure_case_analysis.png",
                "caption": "Figure 2:Proportional distribution of outcome scenarios before and after self-reflection (§3.4) underVeriCoT. Categories include successful verification (Valid) and failure cases: Contradiction, Ungrounded, Untranslatable as described in §2. Self-reflection significantly reduce errors.",
                "position": 687
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]