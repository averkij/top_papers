[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x1.png",
                "caption": "Figure 1:Evaluation of Video Generation Models on V-ReasonBench.\nThe performance of six video generation models across the four core reasoning dimensions is illustrated. Detailed numerical results are provided in Tab.2.",
                "position": 119
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x2.png",
                "caption": "Figure 2:Overview of V-ReasonBench pipeline. The benchmark covers four reasoning dimensions, integrates both synthetic and real-world scenarios, and supports reproducible, large-scale evaluation of video reasoning capabilities.",
                "position": 150
            }
        ]
    },
    {
        "header": "3V-ReasonBench Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x3.png",
                "caption": "Figure 3:Example failure case fromSequence Completiontask illustrating the limitations of VLM-based automatic evaluation. Although the underlying rule is simple, the VLM incorrectly assesses the model’s output due to difficulties in recognizing small grid cells and fine structural differences. More examples are given in Appendix9.",
                "position": 222
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/",
                "caption": "Figure 4:Human–alignment validation of our benchmark’s scoring pipeline. Each point compares binaryPass/Unpassdecisions from the automatic evaluation with human judgments across four reasoning categories.",
                "position": 619
            }
        ]
    },
    {
        "header": "5Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x5.png",
                "caption": "Figure 5:Example from the Seedance-1.0-Lite model on the horizontal visual symmetry task. The model introduces additional decorative patterns across the mirrored axis, illustrating its tendency to enrich visual appearance rather than preserve original geometric form.",
                "position": 639
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x6.png",
                "caption": "Figure 6:Effect of video duration on reasoning outcomes of Sora-2 in the Chain-of-Frame setting. Each row compares model generations with different “thinking” durations for tasks such asSudokuandRule Following. Although longer durations correspond to longer reasoning processes (4s vs. 8s, 5s vs. 10s), the resulting outputs do not consistently improve.",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x7.png",
                "caption": "Figure 7:Comparison between Veo-3.1 (video model) and NanoBanana (image model) onBlock Sliding(left) andCode Execution(right). Video models leverage the Chain-of-Frames process to simulate intermediate states, enabling stronger performance on tasks that require causal or temporal reasoning, although intermediate transitions may still appear physically inconsistent. Image models provide clean and stable outputs and excel at text-based tasks such as code execution, but their single-frame reasoning limits their ability to capture the underlying physical dynamics.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x8.png",
                "caption": "Figure 8:Examples of hallucinations in the Chain-of-Frame reasoning process. Each row shows a trajectory from input to output, where the final frame is correct but intermediate frames display unrealistic or physically inconsistent transitions.",
                "position": 686
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Additional Details for Each Task",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x9.png",
                "caption": "Figure 9:An illustration of the arithmetic operation task, showing the starting frame (left), an intermediate frame (middle), and the final frame with completed answers (right).",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x10.png",
                "caption": "Figure 10:An illustration of the code execution task, showing the starting frame with code and input (left), an intermediate frame (middle), and the final frame with the output filled in (right).",
                "position": 729
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x11.png",
                "caption": "Figure 11:An illustration of the4×44\\times 4Sudoku task, showing the starting frame with the initial puzzle (left), an intermediate solving frame (middle), and the final frame with the completed solution (right).",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x12.png",
                "caption": "Figure 12:An illustration of the Tic-Tac-Toe task, showing the starting game state (left) and the final frame with the optimal move placed (right).",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x13.png",
                "caption": "Figure 13:An illustration of the shape fitting task, showing the starting frame with pieces and empty holes (left), an intermediate fitting process (middle), and the final frame with all pieces correctly fitted (right).",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x14.png",
                "caption": "Figure 14:An illustration of the vertical symmetric in the visual symmetry task, showing the starting frame with an incomplete pattern (left), an intermediate completion stage (middle), and the final frame with the fully symmetric pattern (right).",
                "position": 775
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x15.png",
                "caption": "Figure 15:An illustration of the color connection task, showing the starting frame with colored endpoints (left), an intermediate drawing stage (middle), and the final frame with all paths correctly connected (right).",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x16.png",
                "caption": "Figure 16:An illustration of the sequence completion task, showing the starting frame with one blank cell (left) and the final frame with all completed cells (right).",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x17.png",
                "caption": "Figure 17:An illustration of the scaling relation in the analogy-solving task, showing the starting frame with the exemplar transformation in the top row (left), and the final frame with the corresponding transformation applied to the target object in the bottom row (right).",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x18.png",
                "caption": "Figure 18:An illustration of the rule following task, showing the starting frame with demonstration pairs and empty test grid (left) and the final frame with the rule correctly applied to the test grid (right).",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x19.png",
                "caption": "Figure 19:An illustration of the block sliding task, showing the starting frame with objects on an inclined surface (left), an intermediate sliding motion (middle), and the final frame showing which objects slid down (right).",
                "position": 836
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x20.png",
                "caption": "Figure 20:An illustration of the communicating vessels task, showing the starting frame with initial liquid levels (left), an intermediate redistribution stage (middle), and the final frame at equilibrium (right).",
                "position": 845
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x21.png",
                "caption": "Figure 21:An illustration of the temperature-induced deformation task using an ice melting example, showing the starting frame with solid ice (left), an intermediate melting stage (middle), and the final frame with completely melted ice/water (right).",
                "position": 854
            }
        ]
    },
    {
        "header": "8Complete Task-Level Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x22.png",
                "caption": "Figure 22:Summary of V-ReasonBench performance across video models. The figure illustrates how six video generation models perform on 13 reasoning tasks, with scores rescaled within each dimension to enable direct comparison.",
                "position": 1015
            }
        ]
    },
    {
        "header": "9Limitation of VLM-Based Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x23.png",
                "caption": "Figure 23:Example failure case fromVisual Symmetrytask. Evaluation prompt for VLM: “You are given three images: an input image, a ground-truth image, and a prediction image. The input image shows an original colored pattern. The correct transformation is: instantly reflect the entire pattern across its central vertical axis while preserving all existing colors and shapes exactly. No other modifications are allowed. Your task is to determine whether the prediction is correct. The prediction is correct only if two conditions are met: (1) The predicted pattern is a proper reflection of the input pattern across the central vertical axis, with no changes to colors, shapes, or structure other than mirroring. (2) The predicted pattern exactly matches the reflected pattern shown in the ground-truth image. This includes correct placement of every cell, color consistency, and no unintended alterations.”",
                "position": 1025
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x24.png",
                "caption": "Figure 24:Example failure case fromRule Followingtask. Evaluation prompt for VLM: “You are given three images: an input image, a ground-truth image, and a prediction image. All images contain several example grids and a lower-right grid. Only the lower-right grid is supposed to change. Your task is to judge whether the prediction is correct.\nThe prediction is correct only if two conditions are met:\n(1) The predicted lower-right grid follows the same transformation rule demonstrated by the example grids in the input image.\n(2) The predicted lower-right grid visually and structurally matches the lower-right grid in the ground-truth image, including filled cells, empty cells, colors, and spatial arrangement. All other grids must remain identical across images.”",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x25.png",
                "caption": "Figure 25:Example failure case fromBlock Slidingtask. Evaluation prompt for VLM: “You are given three images: an input image, a ground-truth image, and a prediction image. The input image shows a rigid rectangular block resting at the top of an incline. The ground-truth image shows the final resting position of the block after sliding down the slope under ideal planar contact, given the annotated parameters: slope lengthLs​l​o​p​eL_{slope}, slope angleθ\\theta, friction coefficientsμs​l​o​p​e\\mu_{slope}andμp​l​a​n​e\\mu_{plane}, block length and height, and gravitational accelerationg=9.81​m/s​²g=9.81m/s\\texttwosuperior. Air resistance, elastic collisions, and secondary impacts at the slope foot are ignored. Your task is to determine whether the prediction is physically correct. The prediction is correct only if the following conditions are satisfied: (1) The predicted final resting position of the block is consistent with the physical dynamics implied by the slope geometry and friction parameters. The block must appear at the location where it should come to rest after sliding, without penetrating surfaces or hovering. (2) The predicted final frame visually matches the ground-truth image in block position, orientation, and contact location on either the slope or the flat plane. Colors, shapes, and scene layout must remain unchanged except for the block’s final location. (3) No extraneous motion or unintended scene modifications are introduced.”",
                "position": 1034
            }
        ]
    },
    {
        "header": "10More Reasoning Patterns Demonstrations",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16668/x26.png",
                "caption": "Figure 26:Given an initial board (left), Seedance-1.0-Lite generates a stylized video in which the board is embedded in a cartoon scene with characters and additional logos overlaid on several cells (right). Although the overall 3×3 grid and most X/O placements are preserved, the added icons and altered symbols change the board configuration, causing the prediction to fail under strict grid-based evaluation.",
                "position": 1044
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x27.png",
                "caption": "Figure 27:Starting from a simple target tic-tac-toe board (left), the model generates a chessboard scene in which the 3×3 grid is roughly aligned but many cells are filled with chess pieces and tokens instead of the required X and O marks. These changes alter the intended board configuration, so the prediction does not satisfy the 100% cell-wise match required by the grid-based evaluation.",
                "position": 1047
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x28.png",
                "caption": "Figure 28:Starting from a simple initial board (left), the model generates a video in which the tic-tac-toe grid is placed on a colorful, highly textured background. Although the final frame roughly keeps the 3×3 grid and most X/O positions, some cells are partially overwritten by visual effects and altered marks.",
                "position": 1056
            },
            {
                "img": "https://arxiv.org/html/2511.16668/x29.png",
                "caption": "Figure 29:Starting from a defined initial board (left), the model generates frames in which strong abstract textures rapidly cover the scene. The tic-tac-toe grid and marks become barely visible and are eventually replaced by a large digit and background pattern.",
                "position": 1059
            }
        ]
    },
    {
        "header": "11More Hallucination in Video Reasoning",
        "images": []
    }
]