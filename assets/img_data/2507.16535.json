[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introduction",
        "images": []
    },
    {
        "header": "Related Work",
        "images": []
    },
    {
        "header": "Aerial-Earth3D Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/x1.png",
                "caption": "Figure 1:The overall data pipeline of Aerial-Earth3D.InstantNGP is utilized to achieve source meshes, which are refined with heuristic strategies. Multi-view Flux-VAE features and semantic maps are aggregated on meshes. Then, these featured meshes are voxelized as inputs to TexVAE.",
                "position": 349
            }
        ]
    },
    {
        "header": "Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/x2.png",
                "caption": "Figure 2:Overview of EarthCrafter.EarthCrafter separately models texture and structure in the latent space compressed by TexVAE and StructVAE as illustrated in (a) and (b), respectively.\nEarthCrafter also contains textural and structural flow-matching models,i.e., TexFM and StructFM, to model related latent presentations.\nWe show the overall pipeline of EarthCrafter in (c), while dashed boxes denote optional conditions.",
                "position": 356
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/net_structvae.png",
                "caption": "Figure 3:StructVAE.(a) Overview of encoder-decoder based StructVAE. (b) Pseudo-Sparse to Sparse (PSS) block is used to upsample voxels and then classify them from pseudo-sparse voxels into sparse outcomes as in (c).",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/structfm_cond_net.png",
                "caption": "Figure 4:Overview of the coarse-to-fine StructFM.(a) Condition branch of StructFM, which receives optional inputs: image, semantic, or empty conditions.\n(b) The coarse stage is devoted to classifying activated voxels.\n(c) The fine-grained stage focuses on refining voxel coordinates and predicting structural latents based on the outcome from the coarse stage.",
                "position": 430
            }
        ]
    },
    {
        "header": "Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/compare_to_others.png",
                "caption": "Figure 5:Qualitative Comparison.CityDreamer* means that showing results with similar camera distances compared to EarthCrafter.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/result_infinite_gen.png",
                "caption": "Figure 6:Infinite scene (412‚Å¢m2412superscriptùëö2412m^{2}412 italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT) generation under large semantic condition map.",
                "position": 512
            }
        ]
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "Diverse Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/diverse_overall_sem.png",
                "caption": "Figure 7:Diverse scene generation under semantic condition.",
                "position": 808
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/diverse_tex_sem.png",
                "caption": "Figure 8:Diverse texture generation under semantic condition.",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/diverse_tex_rand.png",
                "caption": "Figure 9:Diverse texture generation without condition.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2507.16535/x3.png",
                "caption": "Figure 10:Infinite scene (412‚Å¢m2412superscriptùëö2412m^{2}412 italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT) generation under semantic condition.",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/result_rgbd.png",
                "caption": "Figure 11:Scene generation under RGBD image condition.",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/result_overall_sem.png",
                "caption": "Figure 12:Scene generation under semantic condition.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/result_overall_rand.png",
                "caption": "Figure 13:Scene generation without condition.",
                "position": 826
            }
        ]
    },
    {
        "header": "Details of Model Architectures",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/structfm_cond_net.png",
                "caption": "Figure 14:StructFM architectures. (a) The condition branch of StructFM. (b) The coarse voxel classification stage, denoted as ClassSFM in SturctFM. (c) The voxel refinement and latent generation, called LatentSFM in StructFM.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/texfm_net.png",
                "caption": "Figure 15:TexFM architectures. (a) The condition branch of TexFM. (b) The main network of TexFM.",
                "position": 1217
            }
        ]
    },
    {
        "header": "Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/lpips_loss.png",
                "caption": "Figure 16:Results of texture reconstruction changing caused by mixed LPIPS-VGG and LPIPS-ALex loss.\nVGG means using pure LPIPS-VGG loss; Alex means using pure LPIPS-Alex loss; VGG+ALex means using mixed LPIPS loss.",
                "position": 1321
            }
        ]
    },
    {
        "header": "Data Preparation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/x4.png",
                "caption": "Figure 17:The illustration of data collection of Google Earth.Blue pointsdenote all 150k scenes originally captured from Google Earth, whilered pointsdenote the final 50k training scenes filtered for the EarthCrafter training. We employ DEM terrain(Models2001), MS-Building heights(GlobalMLBF2022), and driving road paths from OSM(OpenStreetMap2004)to build the 3D simulation for defining reasonable camera viewpoints.",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/voxel_visual.png",
                "caption": "Figure 18:Voxel data visualizations of Aerial-Earth3D.",
                "position": 1456
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/semanitc_compare.png",
                "caption": "Figure 19:Segmentation comparison between Florance2 and AIE-SEG.",
                "position": 1474
            },
            {
                "img": "https://arxiv.org/html/2507.16535/x5.png",
                "caption": "Figure 20:Pie chart of the class distribution of Aerial-Earth3D.",
                "position": 1477
            }
        ]
    },
    {
        "header": "Robust Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/jagged_ablation.png",
                "caption": "Figure 21:Results of appearance changing caused by jagged perturbation.\n(b) means conditional voxels from the conditional image‚Äôs depth. ; (d) denotes generated appearance by using jagged perturbation.",
                "position": 1680
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/compare_roughening.png",
                "caption": "Figure 22:Visualization comparison with and without roughening. (c) means without applying roughening, (d) means using voxel roughening.",
                "position": 1771
            },
            {
                "img": "https://arxiv.org/html/2507.16535/x6.png",
                "caption": "Figure 23:Results of geometry changing caused by normal drop augmentation.\n(b) means conditional voxels from the conditional image‚Äôs depth; (e) and (f) represent generated voxels after applying normal drop.",
                "position": 1844
            },
            {
                "img": "https://arxiv.org/html/2507.16535/extracted/6645432/normal_drop_visual.png",
                "caption": "Figure 24:Visualization of condition voxels with voxel normal drop.",
                "position": 1848
            }
        ]
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]