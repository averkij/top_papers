[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19066/x1.png",
                "caption": "Figure 1:Monosemantic interpretable conceptssuch as nudity, photographic styles, and object attributes are identified using k-sparse autoencoders (k-SAE). We leverage them to enable precise modification of a desired concept during the generation process, without impacting the overall image structure, photo-realism, visual quality, and prompt alignment (for safe concepts). Our framework can be used to remove unsafe concepts (top row), photographic styles (middle row), and object attributes (last row).",
                "position": 78
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19066/x2.png",
                "caption": "Figure 2:K-sparse autoencoder (k-SAE)is trained on feature representations from the text encoder of the diffusion model. Once trained, it serves as a Concept Steerer, enabling precise, surgical concept manipulation by adjustingλ𝜆\\lambdaitalic_λ.",
                "position": 151
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19066/x3.png",
                "caption": "Figure 3:Qualitative comparisons of different approaches, including TraSCE and SAFREE, on the I2P dataset. Our method removes nudity without significantly altering the generated images, resulting in outputs that are better aligned with the input prompt.",
                "position": 384
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x4.png",
                "caption": "Figure 4:Qualitative examples from the I2P dataset. Our method allows fine-grained control over the removal of specific concepts, removing only the intended concept while preserving the overall structure and style of the generated images.",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x5.png",
                "caption": "Figure 5:Qualitative example from the I2P dataset with FLUX. Our method is model-agnostic and can be applied to both U-Net-based SD 1.4 and SDXL-Turbo, as well as DiT-based FLUX.",
                "position": 392
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x6.png",
                "caption": "Figure 6:Qualitative examples from the Ring-A-Bell dataset. Our method successfully removes the abstract concept of violence, as shown by the absence of blood in the right images. The images are intentionally blurred for display purposes as they are disturbing.",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x7.png",
                "caption": "Figure 7:Photographic style manipulation of SD 1.4for the given prompt “geodesic landscape, john chamberlain, christopher balaskas, tadao ando, 4 k, ” where concept prompts are “minimalist” (Top) and “zoom-in, magnify” (Bottom), respectively. In the top row, the image is manipulated toward a maximalist style asλ→−1→𝜆1\\lambda\\rightarrow-1italic_λ → - 1, while it adopts a minimalist style asλ→1→𝜆1\\lambda\\rightarrow 1italic_λ → 1. Similarly, in the bottom row, the image appears zoomed out and becomes blurred asλ→−1→𝜆1\\lambda\\rightarrow-1italic_λ → - 1, whereas it becomes zoomed in and clearer asλ→1→𝜆1\\lambda\\rightarrow 1italic_λ → 1.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x8.png",
                "caption": "Figure 8:Qualitative comparisons with weather Concept Sliders on SDXL-Turbo.Note that Concept Sliders train specific sliders: winter weather slider and a dark weather slider, whereas our method trains a k-SAEonly oncefor different concepts.Top:“A photo of a tree with a bench, realistic, 8k” with concept to steer = “winter.”Bottom:“A photo of a forest, realistic, 8k” with the concept to steer = “low light.” Notice how in the top image our method also removes leaves while in the bottom image, our method effectively applies a low-light effect to the original image.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x9.png",
                "caption": "Figure 9:Image composition manipulation using SDXL-Turbofor the prompt “A dog” with the concept prompt “Full shot.” Notice how asλ→1→𝜆1\\lambda\\rightarrow 1italic_λ → 1, the generated image transitions from a close-up of the face to a full shot.",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x10.png",
                "caption": "Figure 10:Object attribute manipulation of SDXL-Turbofor the given prompts “A car” (Top) and “A photo of a tree” (Bottom), where the concept prompts are “A blue car” (Top) and “Tree with autumn leaves” (Bottom). By adjustingλ𝜆\\lambdaitalic_λ, our method transitions the image toward the desired concept specified by the prompts.",
                "position": 505
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x11.png",
                "caption": "",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x12.png",
                "caption": "Figure 11:Effect of steering strength parameter (λ𝜆\\lambdaitalic_λ)on the I2P dataset while we steer nudity. Notice how asλ→−0.5→𝜆0.5\\lambda\\rightarrow-0.5italic_λ → - 0.5, the presence of nudity disappears completely.",
                "position": 827
            }
        ]
    },
    {
        "header": "5Discussion and Future Work",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation details",
        "images": []
    },
    {
        "header": "Appendix BMore details of the benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19066/x13.png",
                "caption": "Figure 12:Qualitative example from the I2P dataset with FLUX. Our method is model-agnostic and can be applied to both U-Net-based SD 1.4 and SDXL-Turbo, as well as DiT-based FLUX.",
                "position": 1757
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x14.png",
                "caption": "Figure 13:Qualitative comparisons of different methods, including TraSCE and SAFREE, on the P4D dataset. The P4D dataset consists of adversarial prompts designed to challenge generative models. Our approach effectively removes the concept of nudity during the generation process, producing safe and semantically meaningful outputs. In contrast, SAFREE fails to generate safe images, while TraSCE sometimes produces unrelated outputs despite the presence of semantically meaningful keywords in given prompts, such as “girl,” “roman,” “renaissance,” and “paintings” (middle row).",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x15.png",
                "caption": "Figure 14:Qualitative examples from the Ring-A-Bell dataset. Our method successfully removes the abstract concept of violence, as shown by the absence of blood in the right images. The images are intentionally blurred for display purposes as they are disturbing.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x16.png",
                "caption": "Figure 15:Photographic style manipulation of SD 1.4for the given prompt “geodesic landscape, john chamberlain, christopher balaskas, tadao ando, 4 k, ” where concept prompts are “HDR,” “Black and white,” “Sepia Tone,” and “Astrophotography,” respectively. Asλ→0.5→𝜆0.5\\lambda\\rightarrow 0.5italic_λ → 0.5, the generated image gradually transitions to the desired concept.",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2501.19066/x17.png",
                "caption": "Figure 16:Object attribute manipulation of SDXL-Turbofor the given prompts “A photo of a cake, 4k,” where the concept prompts are “A chocolate cake,” “A white cake,” “A lemon cake,” and “An orange cake,” respectively.\nBy adjustingλ𝜆\\lambdaitalic_λ, our method transitions the image toward the desired concept specified by the prompts.",
                "position": 1773
            }
        ]
    },
    {
        "header": "Appendix CAdditional qualitative results",
        "images": []
    }
]