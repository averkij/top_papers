[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17743/x1.png",
                "caption": "Figure 1:Performance comparison of YuLan-Mini against otherbase models, based on the average scores across eight benchmarks: GSM8K, MATH-500, HumanEval, MBPP, MMLU, ARC-Challenge, HellaSwag, and CEval.\nFloating Point Operations (FLOPs) are estimated using the scaling law formulaC=6‚Å¢N‚Å¢Dùê∂6ùëÅùê∑C=6NDitalic_C = 6 italic_N italic_Dproposed byKaplan et¬†al.(2020), whereNùëÅNitalic_Nis the model size andDùê∑Ditalic_Dis the size of the dataset.\nThe models with a size larger than 3B are plotted in gray.",
                "position": 259
            }
        ]
    },
    {
        "header": "2Overall Pre-Training Configuration",
        "images": []
    },
    {
        "header": "3Training Stability",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17743/x2.png",
                "caption": "(a)Training loss.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x2.png",
                "caption": "(a)Training loss.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x3.png",
                "caption": "(b)Gradient norm.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x4.png",
                "caption": "(a)Exploding hidden states.",
                "position": 646
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x4.png",
                "caption": "(a)Exploding hidden states.",
                "position": 649
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x5.png",
                "caption": "(b)Convergent hidden states.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x6.png",
                "caption": "(c)Loss prediction failure.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x7.png",
                "caption": "Figure 4:Variance of LN output of each layers.",
                "position": 810
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x7.png",
                "caption": "Figure 4:Variance of LN output of each layers.",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x8.png",
                "caption": "Figure 5:Attention scores explodes before LN.",
                "position": 818
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x9.png",
                "caption": "Figure 6:Ablation experiments on training instability mitigation methods are conducted. We report the average of LAMBADA accuracy of the last three checkpoints of the training and the estimated running time on our 48 A800-GPU cluster. Divergent gradient norm or spiking loss trajectories are shown inredbars, and convergent training is shown ingreen.",
                "position": 878
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x10.png",
                "caption": "(a)Variance of attention values and LN outputs",
                "position": 1126
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x10.png",
                "caption": "(a)Variance of attention values and LN outputs",
                "position": 1129
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x11.png",
                "caption": "(b)Gradient norm and loss trajectory",
                "position": 1134
            }
        ]
    },
    {
        "header": "4Data Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17743/x12.png",
                "caption": "Figure 8:Illustration of our data filtering pipeline and synthetic generation for reasoning data. The filtering pipeline consists of six steps starting from data collection. Synthetic data generation includes both pretraining data (above the horizontal line) and instruction data (below the line).",
                "position": 1339
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x13.png",
                "caption": "Figure 9:The data mixture proportion ofmath,code, andgeneraldata. We keep the proportion of web data unchanged in stable stage, and then gradually decrease it in annealing stage.\nThe entire process is divided into into three major stages: warmup, stable training, and annealing (i.e.,beginning after the dashed line).",
                "position": 1464
            }
        ]
    },
    {
        "header": "5Annealing",
        "images": []
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.17743/x14.png",
                "caption": "(a)Performance curve on HumanEval.",
                "position": 2312
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x14.png",
                "caption": "(a)Performance curve on HumanEval.",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2412.17743/x15.png",
                "caption": "(b)Performance curve on GSM8K.",
                "position": 2320
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADefinition of Variables",
        "images": []
    },
    {
        "header": "Appendix BTraining Stability",
        "images": []
    },
    {
        "header": "Appendix CPrompts for Generating Synthetic Data",
        "images": []
    },
    {
        "header": "Appendix DOpen-Source Datasets Used during Pre-training",
        "images": []
    },
    {
        "header": "Appendix EDetailed Data Composition by Training Phases",
        "images": []
    }
]