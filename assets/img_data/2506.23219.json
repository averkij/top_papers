[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x1.png",
                "caption": "Figure 1:Existing works vs. ourUrbanLLaVAin urban research.",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x2.png",
                "caption": "Figure 2:The framework ofUrbanLLaVA, includingUData,UTrainandUBench.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x3.png",
                "caption": "Figure 3:The thorough composition ofUDatain Beijing.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x4.png",
                "caption": "Figure 4:UTrain: three-stage training pipeline.",
                "position": 184
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x5.png",
                "caption": "(a)The performance of three-stage tuning, gray part is the default tuning method for MLLMs.",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x5.png",
                "caption": "(a)The performance of three-stage tuning, gray part is the default tuning method for MLLMs.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x6.png",
                "caption": "(b)The effects of the order between knowledge learning and task alignment in two-stage tuning.",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x7.png",
                "caption": "(c)The effects of the order between knowledge learning and task alignment in three-stage tuning.",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x8.png",
                "caption": "Figure 6:Learning from one city (Beijing) can be directly generalized to other cities (London and New York). In this figure, Baseline is VILA1.5-8b, and ourUrbanLLaVAis only trained with the urban instruction data from Beijing.",
                "position": 717
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x9.png",
                "caption": "Figure 7:An example of the SceneFunc¬†task, where correct answers are in green, wrong ones in red.",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x10.png",
                "caption": "Figure 8:An example of the STV-Outlier¬†task.",
                "position": 964
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitation and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Data Example for Three Stages",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/examples-3-stages-v2.png",
                "caption": "Figure 9:Input data examples for three-stage training.",
                "position": 1762
            }
        ]
    },
    {
        "header": "8Comparing with models for single-modality urban tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x11.png",
                "caption": "(a)The changes in training loss under the settings of learning rates1‚Å¢e‚àí41ùëí41e-41 italic_e - 4and1‚Å¢e‚àí51ùëí51e-51 italic_e - 5.",
                "position": 1819
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x11.png",
                "caption": "(a)The changes in training loss under the settings of learning rates1‚Å¢e‚àí41ùëí41e-41 italic_e - 4and1‚Å¢e‚àí51ùëí51e-51 italic_e - 5.",
                "position": 1822
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x12.png",
                "caption": "(b)Results onUBenchwhenUDatais divided into text data and vision data.",
                "position": 1827
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x13.png",
                "caption": "(c)Results onUBenchfrom experiments using different training components.",
                "position": 1832
            }
        ]
    },
    {
        "header": "9Additional Detailed Results of Three Cities",
        "images": []
    },
    {
        "header": "10Additional Results for Training Strategies",
        "images": []
    },
    {
        "header": "11Effects of Training Data Size",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x14.png",
                "caption": "Figure 11:Scaling law from training data size to performance.",
                "position": 2583
            }
        ]
    },
    {
        "header": "12Effects of Base Model",
        "images": []
    },
    {
        "header": "13Effects of Model Size",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x15.png",
                "caption": "Figure 12:Results onUrbanLLaVAwith different model sizes.",
                "position": 2640
            }
        ]
    },
    {
        "header": "14Additional Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23219/x16.png",
                "caption": "Figure 13:An example of the SAT-LandUse task. The correct answers from model are denoted with green color. The response from ours is in bold. Explanation is written by human for this question and answer.",
                "position": 2647
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x17.png",
                "caption": "Figure 14:An example of the STV-Landmark task. The correct answers from model are denoted with green color. The response from ours is in bold. Explanation is written by human for this question and answer.",
                "position": 2653
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x18.png",
                "caption": "Figure 15:Example of a SAT-Address task.",
                "position": 2659
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x19.png",
                "caption": "Figure 16:Example of a STV-Address task.",
                "position": 2665
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x20.png",
                "caption": "Figure 17:An example of a SceneComp task.",
                "position": 2671
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x21.png",
                "caption": "Figure 18:An example of an ImagRetrieval task.",
                "position": 2677
            },
            {
                "img": "https://arxiv.org/html/2506.23219/x22.png",
                "caption": "Figure 19:An example of a CameraLoc task.",
                "position": 2683
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/basic_sat_desc_0.png",
                "caption": "Figure 20:An example of global view training instances of Image Content.",
                "position": 3032
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/basic_sat_landuse_0.png",
                "caption": "Figure 21:An example of global view training instances of Landuse Inference.",
                "position": 3044
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/basic_stv_address_0.jpg",
                "caption": "Figure 22:An example of local view training instances of Location Address.",
                "position": 3056
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/basic_stv_desc_0.jpg",
                "caption": "Figure 23:An example of local view training instances of Image Description.",
                "position": 3068
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/basic_stv_landmark_0.jpg",
                "caption": "Figure 24:An example of local view training instances of Landmark Details.",
                "position": 3082
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_locationing_0.png",
                "caption": "Figure 25:An example of local view training instances of Cross Modality Reasoning.",
                "position": 3094
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_locationing_1.jpg",
                "caption": "",
                "position": 3106
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_mapping_0.jpg",
                "caption": "Figure 26:An example of global view training instances of Cross Modality Reasoning.",
                "position": 3115
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_mapping_1.png",
                "caption": "",
                "position": 3127
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_mapping_2.png",
                "caption": "",
                "position": 3129
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_mapping_3.png",
                "caption": "",
                "position": 3131
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/cot_mapping_4.png",
                "caption": "",
                "position": 3133
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/sat_address_cot_0.png",
                "caption": "Figure 27:An example of global view training instances of Image Content.",
                "position": 3144
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/sat_count_cot_0.png",
                "caption": "Figure 28:An example of global view training instances of Cross Modality Reasoning.",
                "position": 3158
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/stv_address_cot_0.jpg",
                "caption": "Figure 29:An example of local view training instances of Cross Modality Reasoning.",
                "position": 3173
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/sat_address_mc_0.png",
                "caption": "Figure 30:An example of global view training instances of Location Address.",
                "position": 3188
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/sat_landuse_mc_0.png",
                "caption": "Figure 31:An example of global view training instances of Landuse Inference.",
                "position": 3206
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/stv_address_mc_0.jpg",
                "caption": "Figure 32:An example of local view training instances of Location Address.",
                "position": 3224
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/stv_landmark_mc_0.jpg",
                "caption": "Figure 33:An example of local view training instances of Landmark Details.",
                "position": 3242
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/locationing_mc_0.png",
                "caption": "Figure 34:An example of global view training instances of Cross View Data.",
                "position": 3260
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/locationing_mc_1.jpg",
                "caption": "",
                "position": 3272
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/mapping_mc_0.jpg",
                "caption": "Figure 35:An example of global view training instances of Multiple SAT Comparison.",
                "position": 3279
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/mapping_mc_1.png",
                "caption": "",
                "position": 3291
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/mapping_mc_2.png",
                "caption": "",
                "position": 3293
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/mapping_mc_3.png",
                "caption": "",
                "position": 3295
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/train_examples_figs/mapping_mc_4.png",
                "caption": "",
                "position": 3297
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/map_beijing.jpg",
                "caption": "(a)Beijing",
                "position": 3304
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/map_beijing.jpg",
                "caption": "(a)Beijing",
                "position": 3307
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/map_london.jpg",
                "caption": "(b)London",
                "position": 3312
            },
            {
                "img": "https://arxiv.org/html/2506.23219/extracted/6572699/figs/map_newyork.jpg",
                "caption": "(c)New York",
                "position": 3317
            }
        ]
    },
    {
        "header": "15Urban Instruction Data",
        "images": []
    }
]