[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Defining Conflicting Inputs and Quantifying Modality Following",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02243/x1.png",
                "caption": "Figure 1:Overview of the analytical framework.(a)We create inputs with independently controllable visual (dvd_{v}) and textual (dtd_{t}) difficulty.(b)We measure the model’s perceived uncertainty for each modality via output entropy (HvH_{v},HtH_{t}).(c)We then use the relative uncertainty (Δ​Hr​e​l\\Delta H_{rel}) to analyze the model’s choice when faced with a conflict.",
                "position": 195
            }
        ]
    },
    {
        "header": "3Preparing for the Analysis: A Controllable Dataset and an Uncertainty Metric",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02243/images/unimodal_analysis_unimodal_trends.png",
                "caption": "Figure 2:Unimodal Entropy Trends Across Difficulty Tiers. Average unimodal entropy for text (left) and vision (right) as a function of our designed difficulty tiers. Across all models, entropy consistently increases with difficulty, validating its use as a proxy for model-perceived uncertainty and revealing differences in model capabilities.",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/final_images/llava_comparison_macro_summary_unmodifiedv2.png",
                "caption": "(a)Overall macro-level performance",
                "position": 250
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/final_images/llava_comparison_macro_summary_unmodifiedv2.png",
                "caption": "(a)Overall macro-level performance",
                "position": 253
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_distribution_unmodified.png",
                "caption": "(b)Relative uncertainty distribution",
                "position": 258
            }
        ]
    },
    {
        "header": "4Modality Following is Shaped by Relative Uncertainty",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_unmodified.png",
                "caption": "(a)TRP decreases monotonically with relative uncertainty (Δ​Hr​e​l\\Delta H_{rel}). Each model’s unique balance point (where its curve crosses the 0.5 probability line) quantifies its inherent preference.",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_unmodified.png",
                "caption": "(a)TRP decreases monotonically with relative uncertainty (Δ​Hr​e​l\\Delta H_{rel}). Each model’s unique balance point (where its curve crosses the 0.5 probability line) quantifies its inherent preference.",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_highlow_stability_unmodified.png",
                "caption": "(b)The monotonic law remains robust when data is split into low-entropy (solid lines) and high-entropy (dashed lines) subsets.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/osc_bar_dual.png",
                "caption": "Figure 5:A comparison of the average number of concept oscillations for different models. Across all models, the number of oscillations is significantly higher in the ambiguous region (patterned bars) than in the clear region (solid bars).",
                "position": 339
            }
        ]
    },
    {
        "header": "5The Internal Mechanism: Oscillation in the Face of Ambiguity",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02243/images/heatmap.jpg",
                "caption": "(a)Logit Difference Heatmap Across Model Layers and Relative Uncertainty.",
                "position": 359
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/heatmap.jpg",
                "caption": "(a)Logit Difference Heatmap Across Model Layers and Relative Uncertainty.",
                "position": 362
            },
            {
                "img": "https://arxiv.org/html/2511.02243/x2.png",
                "caption": "(b)Case Study: Impact of Text Uncertainty on Layer-wise Confidence Dynamics.",
                "position": 367
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AThe Use of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix BInformation Conflict Dataset Generation Detials",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Color_41_0.png",
                "caption": "Original:Question:What color is the triangle?Command:Please use one word to answer this question.Vision-based Answer:YellowText-based Answer:",
                "position": 1240
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Color_41_0.png",
                "caption": "Original:Question:What color is the triangle?Command:Please use one word to answer this question.Vision-based Answer:YellowText-based Answer:",
                "position": 1243
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Color_41_3.png",
                "caption": "Direct:The triangle is blue.Question:What color is the triangle?Command:Please use one word to answer this question.Vision-based Answer:YellowText-based Answer:Blue",
                "position": 1257
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Color_41_6.png",
                "caption": "Indirect_simple:The triangle’s color is the same as a pentagon. The pentagon is blue.Question:What color is the triangle?Command:Please use one word to answer this question.Vision-based Answer:YellowText-based Answer:Blue",
                "position": 1272
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Color_41_15.png",
                "caption": "Indirect:The triangle’s color is the same as a mailbox in the US.Question:What color is the triangle?Command:Please use one word to answer this question.Vision-based Answer:YellowText-based Answer:Blue",
                "position": 1286
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Shape_193_0.png",
                "caption": "Direct:The cyan rubber object is a cylinder.Question:What is the shape of the cyan rubber object?Command:Please answer with one word.Vision-based Answer:sphereText-based Answer:cylinder",
                "position": 1302
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Shape_193_0.png",
                "caption": "Direct:The cyan rubber object is a cylinder.Question:What is the shape of the cyan rubber object?Command:Please answer with one word.Vision-based Answer:sphereText-based Answer:cylinder",
                "position": 1305
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Shape_193_2.png",
                "caption": "Indirect:The cyan rubber object’s shape is the same as a log.Question:What is the shape of the cyan rubber object?Command:Please answer with one word.Vision-based Answer:sphereText-based Answer:cylinder",
                "position": 1320
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Material_79_1.png",
                "caption": "Indirect_simple:The Frustum is rubber, blue cube’s material is the same as the Frustum.Question:What is the material of the blue cube?Command:Please use one word to answer this question.Vision-based Answer:metalText-based Answer:rubber",
                "position": 1336
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Material_79_1.png",
                "caption": "Indirect_simple:The Frustum is rubber, blue cube’s material is the same as the Frustum.Question:What is the material of the blue cube?Command:Please use one word to answer this question.Vision-based Answer:metalText-based Answer:rubber",
                "position": 1339
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/Dataset_Samples/Material_79_3.png",
                "caption": "Space:There is a rubber cone, the right of the cone is a wood frustum. The blue cube’s material is the same as the object left to the wood frustum.Question:What is the material of the blue cube?Command:Please use one word to answer this question.Vision-based Answer:metalText-based Answer:rubber",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/real_dataset_curve/llava_comparison_color.png",
                "caption": "(a)Curve of Color Recognition Task inM​C2MC^{2}Datasets.",
                "position": 1378
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/real_dataset_curve/llava_comparison_color.png",
                "caption": "(a)Curve of Color Recognition Task inM​C2MC^{2}Datasets.",
                "position": 1381
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/real_dataset_curve/llava_compariso_object_recognition.png",
                "caption": "(b)Curve of Object Recognition Task inM​C2MC^{2}Datasets.",
                "position": 1386
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/real_dataset_curve/llava_comparison_attribute.png",
                "caption": "(c)Curve of Attribution Recognition Task inM​C2MC^{2}Datasets.",
                "position": 1392
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/real_dataset_curve/llava_comparison_positional_reasoning.png",
                "caption": "(d)Curve of Position Reasoning Task inM​C2MC^{2}Datasets.",
                "position": 1397
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_ours_attribution.png",
                "caption": "(e)Curve of Attribution Recognition Task in Our Dataset.",
                "position": 1403
            },
            {
                "img": "https://arxiv.org/html/2511.02243/images/llava_comparison_modified.png",
                "caption": "(f)Curve of Color Recognition Task in Our Dataset with prompts after rewriting.",
                "position": 1408
            }
        ]
    },
    {
        "header": "Appendix CCurve of all remain datasets",
        "images": []
    }
]