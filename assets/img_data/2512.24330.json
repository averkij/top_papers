[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x1.png",
                "caption": "Figure 1:Overall performance of SenseNova-MARS-8B compares to other models across six benchmarks. All\nother models are evaluated under agentic workflow. SenseNova-MARS-8B demonstrates exceptional performance on the search-oriented benchmarks such as MMSearch[jiang2024mmsearch], HR-MMSearch and FVQA[wu2025mmsearch], surpassing leading proprietary models such as Gemini-3-Flash[gemini3flash]and GPT-5[openai2025gpt5].\nFor the high-resolution perception benchmark such as V* Bench[wu2024v]and\nHR-Bench[wang2025divide], SenseNova-MARS-8B also outperforms existing open-source models, including DeepEyesV2[hong2025deepeyesv2]and Mini o3[lai2025mini].",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x2.png",
                "caption": "Figure 2:Reasoning trajectory of SenseNova-MARS. SenseNova-MARS tackles the challenging visual task by leveraging an integrated suite of text search, image search, and image crop tools within the reasoning process.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x3.png",
                "caption": "Figure 3:The illustration of SenseNova-MARS RL training pipeline. SenseNova-MARS adaptively invokes the image search, text search and image crop tools in the multi-turn reasoning process to obtain the final answer. The policy VLM is optimized by the BN-GSPO algorithm, driven by the format reward and answer reward.",
                "position": 259
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x4.png",
                "caption": "Figure 4:Cold-start data generation pipeline. It consists of data mining, trajectory synthesis and quality verification.",
                "position": 379
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x5.png",
                "caption": "Figure 5:Statistics of our proposed HR-MMSearch benchmark. HR-MMSearch is characterized by the high-resolution images and knowledge-intensive question, covering areas such as Sports, Leisure&Culture, Science&Technology, Business&Finance, Games, and Academic Research.",
                "position": 401
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x6.png",
                "caption": "Figure 6:Distribution of tool calls across different benchmarks for Qwen3-VL-8B and SenseNova-MARS-8B.",
                "position": 954
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Additional Details on Training Data",
        "images": []
    },
    {
        "header": "7Additional Details on Evaluation Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x7.png",
                "caption": "Figure 7:Overview of the proposed HR-MMSearch dataset. This figure details the methodology used to construct the dataset and presents the resulting distribution of categories and difficulties. The colorbar uses a gradation of dark, medium, and light to denote the number of total, hard, and easy samples, respectively.",
                "position": 1140
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x8.png",
                "caption": "Figure 8:Overview of our Text Search Pipeline. The pipeline utilizes separate retrieval modes for training and inference. Local retrieval from a Wikipedia knowledge base is used during RL training to avoid the prohibitive cost of live web searches, while live web search (via Serper API) is used exclusively during inference. Crucially, the retrieved passages from both separate modes are uniformly processed by a Qwen3-32B summarizer before being passed to the main model.",
                "position": 1190
            }
        ]
    },
    {
        "header": "8Additional Implementation Details",
        "images": []
    },
    {
        "header": "9Additional Exprimental Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x9.png",
                "caption": "Figure 9:Analysis of tool use behavior. Top: Distribution of tool calls across different benchmarks. Bottom Left: The tool use number in different benchmarks. Bottom Right: Evolution of tool call frequency in the RL training process, indicating that SenseNova-MARS learns more efficient tool invocation strategies.",
                "position": 1275
            }
        ]
    },
    {
        "header": "10Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24330/x10.png",
                "caption": "Figure 10:Case study 1 of SenseNova-MARS.",
                "position": 1310
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x11.png",
                "caption": "Figure 11:Case study 2 of SenseNova-MARS.",
                "position": 1313
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x12.png",
                "caption": "Figure 12:Case study 3 of SenseNova-MARS.",
                "position": 1316
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x13.png",
                "caption": "Figure 13:Case study 4 of SenseNova-MARS.",
                "position": 1319
            },
            {
                "img": "https://arxiv.org/html/2512.24330/x14.png",
                "caption": "Figure 14:Case study 5 of SenseNova-MARS.",
                "position": 1322
            }
        ]
    },
    {
        "header": "11Limitations",
        "images": []
    }
]