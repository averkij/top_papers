[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000150.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000155.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000160.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000163.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000165.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2512.01031/figs/teaser/frame_000170.png",
                "caption": "",
                "position": 148
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01031/x1.png",
                "caption": "Figure 2:Prediction-execution misalignment in asynchronous inference.Due to inference delayΔ\\Delta, the model predicts actions for theprediction interval[t,t+K)[t,t+K)but they execute during theexecution interval[t+Δ,t+Δ+K)[t+\\Delta,t+\\Delta+K).",
                "position": 172
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01031/x2.png",
                "caption": "Figure 3:Comparison between VLASH and existing methods.(a) Synchronous inference: the robot stalls during inference, introducing slow reactions. (b) Naive async: the model predicts based on stale states1s_{1}while execution begins at future states3s_{3}, causing misalignment and discontinuity. (c) VLASH rolls forward the robot state (s3=s1+a1+a2s_{3}=s_{1}+a_{1}+a_{2}) and condition on the execution-time state, achieving fast reaction and smooth actions.",
                "position": 219
            }
        ]
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4VLASH",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01031/x3.png",
                "caption": "Figure 4:Attention pattern for efficient fine-tuning with shared observation.We pack one shared observationoto_{t}and multiple offset branches(st+δ,At+δ)(s_{t+\\delta},A_{t+\\delta})into a single sequence. Blue and yellow cells indicate allowed attention, while gray cells indicate masked attention. Positional encodings of each offset branch are reassigned to start at the same index, equal to the length of observation tokens.",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2512.01031/x4.png",
                "caption": "Figure 5:Action quantization for efficient execution.We group consecutivefine-grainedmicro-actions intocoarsermacro-actions to accelerate robot motion.\nThe original trajectory with fine-grained actionsa0,a1,a2,…a_{0},a_{1},a_{2},\\dots(gray) is quantized into a shorter trajectory with macro-actionsa^0,a^1,a^2,a^3\\hat{a}_{0},\\hat{a}_{1},\\hat{a}_{2},\\hat{a}_{3}(black), where each macro-action summarizesqqconsecutive fine-grained actions (e.g.,a^0=a0+a1+a2\\hat{a}_{0}=a_{0}+a_{1}+a_{2}for quantization factorq=3q=3).",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2512.01031/x5.png",
                "caption": "Figure 6:Performance on Kinetix benchmark.We evaluate the success rate under different execution horizonsKKand inference delaysΔ\\Delta.Left:Fixed inference delayΔ=1\\Delta=1with varying execution horizonKK.Right:Execution horizon adapts to inference delay, i.e.,K=max⁡(Δ,1)K=\\max(\\Delta,1), with varyingΔ\\Delta. For theSyncbaseline, inference delay is alwaysΔ=0\\Delta=0, but the execution horizonKKfollows the same settings as other baselines for fair comparison.",
                "position": 438
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.01031/x6.png",
                "caption": "Figure 7:Real-world evaluation results on manipulation tasks.We evaluateπ0.5\\pi_{0.5}[intelligence2025pi_]on three tasks with different inference methods.Left: Score percentages (based on 2-point scoring: 1 for success of picking up the object, 1 for task completion) of VLASH and baselines across three tasks.Right: Task completion times with green arrows indicating speedup of VLASH (qq=2) relative to synchronous baseline. VLASH (qq) applies action quantization with quantization ratioqq.",
                "position": 677
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "7Appendix",
        "images": []
    }
]