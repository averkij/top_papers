[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x1.png",
                "caption": "Figure 1:An overview of our work. We propose theconcept encoding-decoding mechanismto explain why and how task vectors emerge in pretrained LLMs. We demonstrate that transformers concurrently learn to map latent concepts into separable representations and develop context-specific decoding algorithms. We validate the generality of this finding across model families and scales, and show that the quality of concept encoding-decoding can predict ICL task performance.",
                "position": 184
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Understanding In-context Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x2.png",
                "caption": "Figure 2:Coupled emergence of concept encoding and conditional decoding algorithms in mixture of sparse linear regression. The loss curve on the left-hand side shows different convergence dynamics per basis and show three phases of descent, which we mark with (a), (b), and (c). On the right-hand side, we plot the geometric changes in the representations and how they separate by basis at these marked points. These points coincide with the algorithmic switching behavior.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x3.png",
                "caption": "Figure 3:Causal analysis by perturbation. On the left are perturbation results at epoch 20, when the latent concepts‚Äô representations are semi-separate (B1subscriptùêµ1B_{1}italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTandB2,3,4subscriptùêµ234B_{2,3,4}italic_B start_POSTSUBSCRIPT 2 , 3 , 4 end_POSTSUBSCRIPT). Intracluster refers toB2,3,4subscriptùêµ234B_{2,3,4}italic_B start_POSTSUBSCRIPT 2 , 3 , 4 end_POSTSUBSCRIPT. At this stage of training when there are only two clusters of representations, there only exists two decoding algorithms as well. On the right are results at convergence, when the latent concepts‚Äô representations are fully separable. In this case, eachBisubscriptùêµùëñB_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTfollows a different algorithm and patching the activations of any other basis than itself increases the loss noticeably. On the other hand,self-perturbationimproves ICL performance.",
                "position": 345
            }
        ]
    },
    {
        "header": "4Towards Natural Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x4.png",
                "caption": "(a)POS Tagging",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x4.png",
                "caption": "(a)POS Tagging",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x5.png",
                "caption": "(b)Bitwise Arithmetic",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x6.png",
                "caption": "(a)CD Scores By Layers",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x6.png",
                "caption": "(a)CD Scores By Layers",
                "position": 468
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x7.png",
                "caption": "(b)POS Tagging",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x8.png",
                "caption": "(c)Bitwise Arithmetic",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x9.png",
                "caption": "(a)POS Tagging",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x9.png",
                "caption": "(a)POS Tagging",
                "position": 497
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x10.png",
                "caption": "(b)Bitwise Arithmetic",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x11.png",
                "caption": "(a)",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x11.png",
                "caption": "(a)",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x12.png",
                "caption": "(b)POS Tagging",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x13.png",
                "caption": "(a)POS Tagging",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x13.png",
                "caption": "(a)POS Tagging",
                "position": 563
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x14.png",
                "caption": "(b)Bitwise Arithmetic",
                "position": 568
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInvestigating Predictability of ICL Task Performance in Large-Scale Pretraining",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x15.png",
                "caption": "Figure 9:Test accuracy and CD scores of POS Tagging across OLMo-7B(Groeneveld et¬†al.,2024)checkpoints, from 1000 to 500000.\n.",
                "position": 1442
            }
        ]
    },
    {
        "header": "Appendix BConcept Encoding",
        "images": []
    },
    {
        "header": "Appendix CSynthetic ICL Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x16.png",
                "caption": "(a)Replicate 1",
                "position": 1593
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x16.png",
                "caption": "(a)Replicate 1",
                "position": 1596
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x17.png",
                "caption": "(b)Replicate 2",
                "position": 1601
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x18.png",
                "caption": "(c)Replicate 3",
                "position": 1606
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x19.png",
                "caption": "Figure 11:CD score of synthetic experiments in Figure2over training. (a), (b), (c) denote the same training points in Figure2.",
                "position": 1627
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x20.png",
                "caption": "Figure 12:CD score across layers at epoch 10, 20, 100 from the synthetic experiment in Figure2.",
                "position": 1630
            },
            {
                "img": "https://arxiv.org/html/2412.12276/extracted/6069900/Figures/rep_umap_epochs_5_y.png",
                "caption": "Figure 13:UMAP visualization of representations across the layers over training in the synthetic sparse linear regression task. We visualize the UMAP at epochs 5, 20, and 100 across all the layers. Note that the plot uses zero-based indexing, but we use one-based indexing to refer to the layers in all of the text.",
                "position": 1639
            },
            {
                "img": "https://arxiv.org/html/2412.12276/extracted/6069900/Figures/rep_umap_epochs_5_y.png",
                "caption": "",
                "position": 1642
            },
            {
                "img": "https://arxiv.org/html/2412.12276/extracted/6069900/Figures/rep_umap_epochs_20_y.png",
                "caption": "",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2412.12276/extracted/6069900/Figures/rep_umap_epochs_100_y.png",
                "caption": "",
                "position": 1650
            }
        ]
    },
    {
        "header": "Appendix DIncreasing complexity in synthetic experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x21.png",
                "caption": "Figure 14:Loss curve over training 300 epochs",
                "position": 1662
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x22.png",
                "caption": "(a)UMAP of representations (layer 10) at epoch = 5,10,20,50",
                "position": 1665
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x22.png",
                "caption": "(a)UMAP of representations (layer 10) at epoch = 5,10,20,50",
                "position": 1668
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x23.png",
                "caption": "(b)CD score across layers at epoch = 5,10,20,50",
                "position": 1674
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x24.png",
                "caption": "Figure 16:Loss curve over training 50 epochs",
                "position": 1691
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x25.png",
                "caption": "(a)UMAP of representations (layer 6) at epoch = 5,10,20,50",
                "position": 1694
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x25.png",
                "caption": "(a)UMAP of representations (layer 6) at epoch = 5,10,20,50",
                "position": 1697
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x26.png",
                "caption": "(b)CD score across layers at epoch = 5,10,20,50",
                "position": 1703
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x27.png",
                "caption": "(c)CD score between nonoverlapping bases sets(btw basis 1,2,3,4 and 5,6,7,8) at epoch = 5,10,20,50",
                "position": 1709
            }
        ]
    },
    {
        "header": "Appendix ENatural ICL Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12276/x28.png",
                "caption": "(a)POS Tagging",
                "position": 1773
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x28.png",
                "caption": "(a)POS Tagging",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x29.png",
                "caption": "(b)Bitwise Arithmetic",
                "position": 1782
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x30.png",
                "caption": "(a)Bitwise: Gemma-2 2B",
                "position": 1794
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x30.png",
                "caption": "(a)Bitwise: Gemma-2 2B",
                "position": 1797
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x31.png",
                "caption": "(b)Bitwise: Gemma-2 9B",
                "position": 1802
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x32.png",
                "caption": "(c)Bitwise: Gemma-2 27B",
                "position": 1807
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x33.png",
                "caption": "(d)Bitwise: Llama-3.1 70B",
                "position": 1812
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x34.png",
                "caption": "(e)POS: Gemma-2 2B",
                "position": 1818
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x35.png",
                "caption": "(f)POS: Gemma-2 9B",
                "position": 1823
            },
            {
                "img": "https://arxiv.org/html/2412.12276/",
                "caption": "(g)POS: Gemma-2 27B",
                "position": 1828
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x37.png",
                "caption": "(h)POS: Llama-3.1 70B",
                "position": 1833
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x38.png",
                "caption": "(a)",
                "position": 1847
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x38.png",
                "caption": "(a)",
                "position": 1850
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x39.png",
                "caption": "(b)",
                "position": 1855
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x40.png",
                "caption": "(a)POS Tagging",
                "position": 1879
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x40.png",
                "caption": "(a)POS Tagging",
                "position": 1882
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x41.png",
                "caption": "(b)Bitwise Arithmetic",
                "position": 1887
            },
            {
                "img": "https://arxiv.org/html/2412.12276/x42.png",
                "caption": "Figure 22:CD score across layers for POS tagging and bitwise arithemetic in Llama-3.1-8B for the prompting experiments. We include the true labels of the latent concept (i.e. ‚ÄúFind the first noun in the sentence.‚Äù). We detail the experimental setup in AppendixF.",
                "position": 1894
            }
        ]
    },
    {
        "header": "Appendix FPrompting Experiments",
        "images": []
    }
]