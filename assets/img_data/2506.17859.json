[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.17859/x1.png",
                "caption": "Figure 1:Why Does a Model Learn Different Strategies for Performing ICL?To answer this question, we analyze three distinct settings where a model is trained to learn a mixture of tasks.(a) Model Behavior Transitions Between Memorizing and Generalizing Predictors.We first make the observation that across settings, as diversity of data distribution and amount of training are increased, model behavior transitions between two Bayesian predictors: a memorizing predictor,Mğ‘€Mitalic_M, which assumes a discrete prior over seen tasks, and a generalizing predictor,GğºGitalic_G, which assumes a continuous prior over the true distribution.\nThis recapitulates prior results on task-diversity thresholds[25]and transient generalization[24]in a unifying language.(b)A Hierarchical Bayesian Framework Provides an Explanatory and Predictive Account of ICL.The consistency of these transitions motivates a hierarchical Bayesian model of ICL, where a modelâ€™s inference-time behavior is framed as a posterior-weighted interpolation in the Bayesian predictorsMğ‘€Mitalic_MandGğºGitalic_G, while pretraining is seen as a process of updating the preference (posterior probability) toward different predictors.\nWe find that under reasonable assumptions regarding neural network learning dynamics, our framework is highly predictive of model behaviorthroughouttraining,withoutaccess to model weights (bottom panel). Additionally, our framework provides an explanatory account of ICL phenomena via a tradeoff between thelossand thecomplexityof learned solutions (top panel).",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x2.png",
                "caption": "Figure 2:Experimental Settings: Learning a Finite Mixture of Tasks.(a) General Formulation.Popularly studied experimental settings in the literature on ICL can be seen as training a model to learn a distribution defined using a mixture of tasks (denotedğ’¯trainsubscriptğ’¯train\\mathcal{T}_{\\text{train}}caligraphic_T start_POSTSUBSCRIPT train end_POSTSUBSCRIPT), where each task is a parameterized latent function whose parameters are sampled from a distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT.(b) Considered Settings.We analyze three distinct instantiations of this general formulation:Balls & Urns, which captures the belief update interpretation of ICL and is a simplification of the Markov modeling setting from prior work[26,52], and two popularly studied settings from the literature that capture the few-shot learning interpretation of ICL, i.e., in-contextlinear regression[25,14]andClassification[20,24,28,29].",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x3.png",
                "caption": "Figure 3:Predictors in Different Experimental Settings.(a) Memorizing and Generalizing Predictors.We compare model behavior to two idealized Bayesian predictors: (i)Memorizing predictor(Mğ‘€Mitalic_M), which assumes a discrete prior over the mixture distributionğ’¯trainsubscriptğ’¯train\\mathcal{T}_{\\text{train}}caligraphic_T start_POSTSUBSCRIPT train end_POSTSUBSCRIPT, and (ii)Generalizing predictor(GğºGitalic_G), which assumes a prior overğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT, the distribution from which tasks are sampled.(b)Task-Specific Instantiations.These predictors yield closed-form solutions (App.G); e.g., in Balls & Urns, the memorizing predictor computes a posterior-weighted average over urns seen in training, whereas the generalizing predictor uses empirical unigram statistics with pseudo-counts.",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x4.png",
                "caption": "Figure 4:Relative Distance Captures Transitions in Model Behavior.We show the relative distance between model outputs and the two predictors. Marginals report the absolute distance values (e.g., symmetrized KL between model and predictor outputs for the Balls & Urns setting), holdingNğ‘Nitalic_Nconstant (for the right plot), orDğ·Ditalic_Dconstant (for the top plot), and varying the other variable (denoted with the dotted line). Across all settings, we see model behavior decomposes into two phases, explained by either the memorizing or generalizing predictor. In this figure, we use context length of 128, task dimensionality of 8, and MLP width of 256 for balls and urns. Linear regression has similar parameters except context length of 32, and classification has similar parameters other than MLP width of 512.",
                "position": 379
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x5.png",
                "caption": "Figure 5:Our Bayesian Model Captures Transitions Between Strategies Explaining Model Behavior.We plot the posterior probability of the memorizing predictor given by our theoretical model (Eq.4). Across three broad experimental settingsâ€”(a)Balls & Urns,(b)Linear Regression, and(c)Classificationâ€”we find our model identifies the phases best explained by a given predictor and the boundary between them, hence capturing the transition between solutions seen in a Transformerâ€™s training (as shown by the relative distance maps).\nImportantly, we find our model is highly predictive of the pretrained Transformerâ€™s behavior (next-token predictions) across conditions used for fitting the three free parameters of our model and unseen ones. Max color bar value for Balls & Urns and Classification is determined by the performance of a baseline predictor that always outputs the mean of the distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT.\nIn this figure, we use context length of 256, task dimensionality of 8 and MLP width of 256 for balls and urns. Linear regression and classification have similar parameters except context length of 64 and 384, respectively.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x6.png",
                "caption": "Figure 6:Novel predictions from our framework.(a)Our framework predicts that the posterior probability of the memorized predictor (and hence the relative distance, which can be thought of as an empirical estimate of this quantity) will show sub-linear scaling with respect toNğ‘Nitalic_N, and sigmoidal growth with respect toN1âˆ’Î±superscriptğ‘1ğ›¼N^{1-\\alpha}italic_N start_POSTSUPERSCRIPT 1 - italic_Î± end_POSTSUPERSCRIPT(holdingDğ·Ditalic_Dconstant). This is clearly shown in the figure, with dark lines representing parameterized logistic fits inN1âˆ’Î±superscriptğ‘1ğ›¼N^{1-\\alpha}italic_N start_POSTSUPERSCRIPT 1 - italic_Î± end_POSTSUPERSCRIPTspace.(b)We predict a rapid change in model behavior for intermediate values ofNğ‘Nitalic_NandDğ·Ditalic_D, yielding a crossover-like boundary between the predictor that best explains model outputs. This can be seen via the magnitude of the second derivative of the relative distance near the boundary. Marginal plots show the second derivative of the relative distance with respect toNğ‘Nitalic_NorDğ·Ditalic_D, with the data shown in these plots denoted on the vector map by the dotted lines.(c)Finally, our analysis predicts super-linear scaling of the time of transienceNâˆ—superscriptğ‘N^{*}italic_N start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT(the time at which relative distancedrâ¢eâ¢l=0.5subscriptğ‘‘ğ‘Ÿğ‘’ğ‘™0.5d_{rel}=0.5italic_d start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT = 0.5) as diversityDğ·Ditalic_Dincreases.",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x7.png",
                "caption": "Figure 7:Intuition Elicited by The Bayesian Model.(a)Our framework suggests Transformers have a prior preference for learning simpler solutions, which often generalize better. However, throughout training, preference is updated towards solutions that better explain the data (i.e., have greater likelihood). This happens even at the expense of higher complexity, which in our case, yields a transition toward a memorizing predictor.(b, c)Our framework captures the tradeoff between solutions, showing that theboundarybetween the two phases corresponds toequal posterior probabilitiesof the two predictors.",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x8.png",
                "caption": "Figure 8:Increased memorization with MLP width is captured by Bayesian model as reduced complexity penalty.(a)We find relative distance to memorizing predictor decreases with MLP width.(b)This transition is closely captured by our Bayesian model, in which the â€˜complexity penaltyâ€™Î²ğ›½\\betaitalic_Î², and hence the differenceÎ”â¢KÎ²Î”superscriptğ¾ğ›½\\Delta K^{\\beta}roman_Î” italic_K start_POSTSUPERSCRIPT italic_Î² end_POSTSUPERSCRIPT, decays exponentially with MLP width, yielding a reduced prior preference toward the generalizing predictor.",
                "position": 570
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x9.png",
                "caption": "Figure 9:Two-Hypotheses Threshold.Defining an â€˜optimalâ€™ interpolation between the memorizing and generalizing predictors towards minimizing the Euclidean distance to the trained Transformerâ€™s predictions, we report the loss between this optimal interpolation and the Transformerâ€™s predictions. We observe a minimum amount of training is necessary for this loss to become sufficiently small such that our hierarchical Bayesian model, which implicitly assumes the Transformer can be functionally decomposed into the two predictors, will become applicable. The dotted lines demarcate this threshold, which we call the â€œtwo-hypotheses thresholdâ€. Mean-squared error (MSE) in the figure above is normalized by dimension. KL in this figure indicates forward KL from the Transformerâ€™s next token predictions to the interpolation of predictors.",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x10.png",
                "caption": "Figure 10:General Abstraction Capturing our Experimental Settings and their Predictors.Each setting involves a mixture of parameterized functions (called a â€œtaskâ€), withDğ·Ditalic_Dfunctions (the â€œtask diversity\"). Task consist of predicting the next element in a sequence, and vary based on whether models are trained in a standard auto-regressive fashion (like Balls & Urns) or whether they are only trained to predict some elements in the sequence (only function outputs in Linear Regression, and only the last label in Classification). Across settings, the solutions learned by Transformers can be characterized asmemorizing predictorsorgeneralizing predictors. A memorizing predictor is defined as the Bayesian posterior predictive distribution withğ’¯trainsubscriptğ’¯train\\mathcal{T}_{\\text{train}}caligraphic_T start_POSTSUBSCRIPT train end_POSTSUBSCRIPT, the distribution of seen tasks, as its prior. A generalizing predictor is defined as the Bayesian posterior predictive with the true task distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPTas its prior.",
                "position": 2495
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x11.png",
                "caption": "Figure 11:Visualizing the setup for Balls and Urns.Each task involves an â€œurnâ€ that outputs a â€œballâ€ of a specific type every time it is sampled from. The task then involves seeing samples from an urn, concatenated to form a sequence. A memorizing predictor for this setting involves computing the sequence-level unigram statistics, i.e., the counts for each ball type, and comparing them with distributions from urns seen during training. Meanwhile, a generalizing predictor simply assumes the distribution of balls follows a uniform Dirichlet prior, thus predicting simply based on computing the unigram statistics from the sequence and adding a 1 pseudo-count for each ball type. Thus, this predictor generalizes to novel urns not seen by the model during training.",
                "position": 2524
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x12.png",
                "caption": "Figure 12:Visualizing the setup for Linear Regression.Each task involves a linear regression problem, defined by parametersğ’˜ğ’˜\\bm{w}bold_italic_w, that outputs a pair(ğ’™,ğš¢)ğ’™ğš¢(\\bm{x},\\mathtt{y})( bold_italic_x , typewriter_y ), whereğš¢=ğ’˜âŠºâ¢ğ’™+Ïµğš¢superscriptğ’˜âŠºğ’™italic-Ïµ\\mathtt{y}=\\bm{w}^{\\intercal}\\bm{x}+\\epsilontypewriter_y = bold_italic_w start_POSTSUPERSCRIPT âŠº end_POSTSUPERSCRIPT bold_italic_x + italic_Ïµis a noisy linear transformation of the vectorğ’™ğ’™\\bm{x}bold_italic_x. The task then involves seeing a sequence of such pairs, concatenated to form a sequence. A memorizing predictor for this setting involves computing the likelihood of the pairs seen in context under the parameters of each task seen during training, using this result to compute a posterior over said tasks and a posterior-weighted average with a discrete prior over seen tasks. Meanwhile, the generalizing predictor is merely the ridge regression operation, which is equivalent to performing a Bayesian average operation assuming a continuous Gaussian prior. Correspondingly, this predictor generalizes to novel regression tasks that were not seen by the model during training.",
                "position": 2532
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x13.png",
                "caption": "Figure 13:Visualizing the setup for Classification.Each task involves noisy item-label pairsğ’˜~âŠ•ğ’direct-sum~ğ’˜ğ’\\tilde{\\bm{w}}\\oplus\\bm{l}over~ start_ARG bold_italic_w end_ARG âŠ• bold_italic_l, and ends with a noisy query itemğ’˜~querysubscript~ğ’˜query\\tilde{\\bm{w}}_{\\text{query}}over~ start_ARG bold_italic_w end_ARG start_POSTSUBSCRIPT query end_POSTSUBSCRIPTwhich comes from the same true itemğ’˜ğ’˜\\bm{w}bold_italic_was one of the items in the sequence. Items are noised viağ’˜~=ğ’˜+Ïƒâ¢Ïµ1+Ïƒ2~ğ’˜ğ’˜ğœitalic-Ïµ1superscriptğœ2\\tilde{\\bm{w}}=\\frac{\\bm{w}+\\sigma\\epsilon}{\\sqrt{1+\\sigma^{2}}}over~ start_ARG bold_italic_w end_ARG = divide start_ARG bold_italic_w + italic_Ïƒ italic_Ïµ end_ARG start_ARG square-root start_ARG 1 + italic_Ïƒ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG end_ARG, withÏµâˆˆğ’©â¢(0,ğ‘°m/m)italic-Ïµğ’©0subscriptğ‘°ğ‘šğ‘š\\epsilon\\in\\mathcal{N}(0,\\bm{I}_{m}/m)italic_Ïµ âˆˆ caligraphic_N ( 0 , bold_italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT / italic_m )sampled from the same distribution as the true itemğ’˜ğ’˜\\bm{w}bold_italic_w. A memorizing predictor knows the true items in the training distribution, computes the likelihood that the noisy query item comes from each true item, and accordingly computes a posterior-weighted average using the labels for each true item. Note that this predictor completely ignores the context, and hence was described as an â€˜in-weights learningâ€™ solution in previous works[24,28]. In contrast, the generalizing predictor implements a noisy copy operation. It estimates the likelihood that the query head and each item seen in context come from the same true item. Then, it predicts via a posterior-weighted average according to the labels of each item seen in context. Therefore, this predictor works for OOD settings containing novel items that were not previously seen during training.",
                "position": 2589
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x14.png",
                "caption": "Figure 14:Task Diversity Effects Across Balls & Urns Conditions.Red dashed line indicates the memorizing solutionMğ‘€Mitalic_M, blue dashed line indicates the generalizing solutionGğºGitalic_G, and black solid line indicates Transformer behavior at the end of training (100100100100K steps).",
                "position": 2674
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x15.png",
                "caption": "Figure 15:Task Diversity Effects Across Linear Regression Conditions.Red dashed line indicates the memorizing solutionMğ‘€Mitalic_M, blue dashed line indicates the generalizing solutionGğºGitalic_G, and black solid line indicates Transformer behavior at the end of training (100100100100K steps).",
                "position": 2682
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x16.png",
                "caption": "Figure 16:Task Diversity Effects Across Classification Conditions.Red dashed line indicates the memorizing solutionMğ‘€Mitalic_M, blue dashed line indicates the generalizing solutionGğºGitalic_G, and black solid line indicates Transformer behavior at the end of training (100100100100K steps). IWL evaluation presented.",
                "position": 2690
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x17.png",
                "caption": "Figure 17:Transience Across Balls & Urns Conditions.OOD performance presented. Blue Dashed line indicates OOD performance of generalizing solutionGğºGitalic_G.",
                "position": 2706
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x18.png",
                "caption": "Figure 18:Transience Across Linear Regression Conditions.OOD performance presented. Blue Dashed line indicates OOD performance of generalizing solutionGğºGitalic_G.",
                "position": 2714
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x19.png",
                "caption": "Figure 19:Transience Across Classification Conditions.OOD performance presented. Blue Dashed line indicates OOD performance of generalizing solutionGğºGitalic_G. Note that in the case of classification, it is often the case that only one or two task diversity conditions show transient generalization, as can be seen more clearly from the absolute distance maps in the next section.",
                "position": 2722
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x20.png",
                "caption": "Figure 20:Absolute and Relative Distance from Predictors Across Balls & Urns Conditions.Distance from the generalizing solutionGğºGitalic_Gshown in the dashed black line, while distance from the memorizing solutionMğ‘€Mitalic_Mis shown in the solid line. KL indicates symmetrized KL divergence (average of forward and backward KL).",
                "position": 2738
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x21.png",
                "caption": "Figure 21:Absolute and Relative Distance from Predictors Across Linear Regression Conditions.Distance from the generalizing solutionGğºGitalic_Gshown in the dashed black line, while distance from the memorizing solutionMğ‘€Mitalic_Mis shown in the solid line.",
                "position": 2746
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x22.png",
                "caption": "Figure 22:Absolute and Relative Distance from Predictors Across Classification Conditions.Distance from the generalizing solutionGğºGitalic_Gshown in the dashed black line, while distance from the memorizing solutionMğ‘€Mitalic_Mis shown in the solid line. KL indicates symmetrized KL divergence (average of forward and backward KL).",
                "position": 2754
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x23.png",
                "caption": "Figure 23:Bayesian Model Predictions Across Balls & Urns Conditions.Red indicates closeness to memorizing predictorMğ‘€Mitalic_M, while blue indicates closeness to generalizing predictorGğºGitalic_G. Shown is a comparison between the posterior probability of the memorizing solutionMğ‘€Mitalic_Mgiven by our Bayesian model (left) and the relative distance from the Transformer (top right), as well as heatmaps indicating similarity with Transformer next-token predictions (bottom right). Max color bar value is determined by the performance of a baseline predictor that always outputs the mean of the distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT.",
                "position": 2770
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x24.png",
                "caption": "Figure 24:Bayesian Model Predictions Across Balls & Urns Conditions with Varying MLP Expansion Factors.Red indicates closeness to memorizing predictorMğ‘€Mitalic_M, while blue indicates closeness to generalizing predictorGğºGitalic_G. Shown is a comparison between the posterior probability of the memorizing solutionMğ‘€Mitalic_Mgiven by our Bayesian model (left) and the relative distance from the Transformer (top right), as well as heatmaps indicating similarity with Transformer next-token predictions (bottom right). Context length is 128, task dimensionality is 8, and hidden size is 64 in all conditions shown. MLP width is given by hidden size times MLP expansion factor. Max color bar value is determined by the performance of a baseline predictor that always outputs the mean of the distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT.",
                "position": 2774
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x25.png",
                "caption": "Figure 25:Bayesian Model Predictions Across Linear Regression Conditions.Red indicates closeness to memorizing predictorMğ‘€Mitalic_M, while blue indicates closeness to generalizing predictorGğºGitalic_G. Shown is a comparison between the posterior probability of the memorizing solutionMğ‘€Mitalic_Mgiven by our Bayesian model (left) and the relative distance from the Transformer (top right), as well as heatmaps indicating similarity with Transformer next-token predictions (bottom right).",
                "position": 2782
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x26.png",
                "caption": "Figure 26:Bayesian Model Predictions Across Classification Conditions.Red indicates closeness to memorizing predictorMğ‘€Mitalic_M, while blue indicates closeness to generalizing predictorGğºGitalic_G. Shown is a comparison between the posterior probability of the memorizing solutionMğ‘€Mitalic_Mgiven by our Bayesian model (left) and the relative distance from the Transformer (top right), as well as heatmaps indicating similarity with Transformer next-token predictions (bottom right). Max color bar value is determined by the performance of a baseline predictor that always outputs the mean of the distributionğ’¯truesubscriptğ’¯true\\mathcal{T}_{\\text{true}}caligraphic_T start_POSTSUBSCRIPT true end_POSTSUBSCRIPT. The conditions where task dimensionality equals 16 in this setting (bottom row) reveal a limitation of our complexity measure: since the memorizing and generalizing predictors are very close in performance in low task diversities for these conditions, the loss term does not strongly bias the Transformer towards the memorizing predictor. However, the Transformer, is very close to the memorizing predictor for low task diversities, which would indicate according to our framework that memorizing few items is substantially simpler than implementing a copy operation. However, this is not captured by our complexity measure, since the compressed size of the code for the memorizing and generalizing predictors is roughly the same, thus we are unable to capture the bias toward the memorizing predictor in low task diversity settings. To overcome this, in these 3 conditions only, we heuristically multiply the bit size of the code for the generalizing predictor by5555, and with that fix, we find good performance (though as can be seen, the model still under-weights the memorizing solution for some low task diversity conditions).",
                "position": 2790
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x27.png",
                "caption": "Figure 27:Power laws over complexity measure and sample efficiency are necessarily for explaining ICL phenomenology.By ablating our functional form, we see that the free parametersÎ±,Î²,Î³ğ›¼ğ›½ğ›¾\\alpha,\\beta,\\gammaitalic_Î± , italic_Î² , italic_Î³are required for the performance of the model. In particular, the simplicity bias derived fromKğ¾Kitalic_Kwithout aÎ²ğ›½\\betaitalic_Î²term is much too sharp and over-penalizes complexity compared to the Transformer. Additionally, memorization proceeds much too rapidly without theÎ±ğ›¼\\alphaitalic_Î±term, pointing toward the necessity of assuming sub-linear sample efficiency for capturing Transformer training dynamics.",
                "position": 2803
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x28.png",
                "caption": "Figure 28:Relative distance continues to rise throughout training, even after the task diversity threshold.The figure displays relative distance, as well as absolute distance from the memorizing and generalizing solutions, for the linear regression setting with context length of 32, MLP expansion factor of 4, and 8 dimensions.",
                "position": 2814
            },
            {
                "img": "https://arxiv.org/html/2506.17859/x29.png",
                "caption": "Figure 29:Learning Rate Annealing Can Increase Adherence to Bayes-Optimal Trajectories.(a) Balls & Urns setting uses context length of 128, MLP width of 256, and 8 dimensions. Linear regression uses similar variables except a context length of 16. (b) Effect is highly sensitive to training conditions: e.g., Training in the Linear regression setting with5000500050005000warmup steps failed, but succeeds with500500500500warmup steps (the number used for the experiment in panel (a)).",
                "position": 2825
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]