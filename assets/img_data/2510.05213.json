[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/teaser.png",
                "caption": "Figure 1:A comparison between our VER and previous distillation framework.Our method not only enhances knowledge distillation from vision foundation models (VFMs) into vision experts but also offers two key advantages over previous works(Ranzinger et al.,2024; Shang et al.,2024).\nFirst, VER trains a lightweight router that dynamically selects vision experts for downstream robot policies.\nSecond, VER allows the integration of additional trainable experts, enabling the adaptation to robot-specific domain knowledge to further improve robotic performance.",
                "position": 132
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05213/x1.png",
                "caption": "Figure 2:Overall structure of VER.VER comprises two key components: the Base Vision Transformer (BVT), which processes images into unified representations; the Vision Expert Library (VEL), which stores a diverse set of specialized vision experts and selectively utilizes the experts to mimic teacher vision foundation models and enhance performance in downstream robotic tasks. Our framework consists of two phases: (1) Pretraining, where we distill multiple foundation models (DINOv2(Oquab et al.,2024), ViT(Caron et al.,2021), CLIP(Radford et al.,2021)) into VER; (2) Downstream Robotic Tasks, where we freeze the experts and train a lightweight Robot Router (<0.4%<0.4\\%parameters) that dynamically selects task-relevant visual features to guide the policy head in generating appropriate robotic actions. This two-stage approach enables efficient knowledge distillation from diverse vision foundation models and adaptive feature selection for robotic tasks.",
                "position": 176
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/vfmoe_vs_theia_cosine_loss.png",
                "caption": "Figure 3:Cosine loss for DINOv2 distillation.Circle size indicates total parameters (TP).",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/vfmoe_vs_theia_cosine_loss.png",
                "caption": "Figure 3:Cosine loss for DINOv2 distillation.Circle size indicates total parameters (TP).",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/exp_freq_base_compact.png",
                "caption": "Figure 4:Expert utilization frequency across three MoE layers.Heatmap shows how each teacher model activates experts (1–6) during distillation on ImageNet-1K.",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/realworld.png",
                "caption": "Figure 5:Visualization of real world experiments.We find with human interference (not in the training dataset), our VER can successfully complete the task.",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/cta.png",
                "caption": "Figure 6:Feature visualization of PER with and without CTA (seed = 0).Row 1:pen; Row 2:relocate. Without CTA, the Robot Router attends broadly to the dexterous hand, objects, and task signals (e.g., target pen pose, target ball region). With CTA, the Robot Router suppresses task-irrelevant patches and concentrates on task-related, object-centric regions throughout execution.",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/task_mi.png",
                "caption": "Figure 7:Mutual information between patch features before and after the Vision Expert Library.Row 1:pen; Row 2:relocate. PER+CTA suppresses information in background patches while preserving information in task-relevant regions, yielding a more compact visual representation (lower average per-patch mutual information). For example, inpen, the left-middle region containing the target pen pose exhibits higher mutual information.",
                "position": 610
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/multiobj.png",
                "caption": "Figure 8:Feature visualization compared with Theia(Shang et al.,2024)onplace the cross into the bin.Both Theia and our featuresbeforethe Robot Router tend to attend broadly to other objects, the robot itself, and background regions, resulting in noisy feature norm.Afterrouting, VER concentrates on task-relevant objects and suppresses robot-related and background patches.",
                "position": 613
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/vfmoe_vs_theia_trainable_params.png",
                "caption": "Figure 9:Trainable parameters vs average success rates.Performance is evaluated onpenandrelocatetasks.",
                "position": 616
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics statement",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALLM Usage Disclosure",
        "images": []
    },
    {
        "header": "Appendix BRouting Network",
        "images": []
    },
    {
        "header": "Appendix CPretrain Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/pickandplacevisualization.png",
                "caption": "Figure 10:Performance onPick and Place.. We find that when the first attempt fails, the VER-equipped policy can retry and complete the task, as shown in the images with red boundaries.",
                "position": 1694
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/mi_vs_sr.png",
                "caption": "Figure 11:Mutual information vs. success rate.For each method (CLIP, DINOv2, ViT, FTR, LTR, PER, PER+CTA), we report the mean ± s.d. over 10 random seeds. The dashed line is an ordinary least-squares fit on 70 points (7 methods × 10 seeds) summarizing the overall trend.",
                "position": 1704
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/cta_10seeds_pen.png",
                "caption": "Figure 12:Mutual information between patch features before and after the Vision Expert Library onpen.We plot the image across 10 random seeds for training.",
                "position": 1710
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/relocate_cta_10_seed.png",
                "caption": "Figure 13:Feature visualization of PER with and without CTA across 10 seeds.Without CTA, the Robot Router attends broadly to the background and generates extreme feature-norm outliers, and its behavior is strongly influenced by the training random seed. With CTA, the Robot Router robustly suppresses task-irrelevant patches and concentrates on task-related regions across all the seeds.",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/pen_exp_freq.png",
                "caption": "Figure 14:Expert utilization frequency with and without CTA onpen(10 seeds).Without CTA, expert utilization frequency varies substantially across random seeds. With CTA, it is more consistent across seeds, indicating improved training robustness and a more stable Robot Router.",
                "position": 1716
            },
            {
                "img": "https://arxiv.org/html/2510.05213/sec/images/relocate_exp_freq.png",
                "caption": "Figure 15:Expert utilization frequency with and without CTA onrelocate(10 seeds).Without CTA, expert utilization frequency varies substantially across random seeds. With CTA, it is more consistent across seeds, indicating improved training robustness and a more stable Robot Router.",
                "position": 1719
            }
        ]
    },
    {
        "header": "Appendix DRobot Task Evaluation",
        "images": []
    }
]