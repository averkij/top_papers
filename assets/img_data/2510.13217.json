[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13217/x1.png",
                "caption": "Figure 1:(Left) Recall@100 on BRIGHT’s StackExchange subsets. Comparison between zero-shot LATTICE (Gemini-2.5-flash) against a BM25 retriever (with GPT-4 query expansion) and a fine-tuned dual-encoder ReasonIR-8B(Shao et al.,2025)(with GPT-4 query expansion). LATTICE yields the highest average recall (74.8%) and substantially outperforms BM25 across all subsets (avg +9.5 pp) and ReasonIR-8B on average (+4.0 pp), with particularly large gains on some datasets like Economics and Robotics.\n(Right) LLM cost (measured in avg. number of input tokens given to LLM) vs. ranking quality (nDCG@10) on the Robotics subset. Reranking baselines (BM25+rerank, ReasonIR-8B+rerank) with varying top-k shortlist use same Gemini-2.5-flash as reranker exhibit early gains but quickly plateau. LATTICE starts with a shallow flat region (cost of traversing tree levels) but then scales more effectively—surpassing the baselines and continuing to improve to a higher final nDCG—demonstrating that guided hierarchical traversal using LLM can be more compute efficient.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2510.13217/x1.png",
                "caption": "",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2510.13217/x2.png",
                "caption": "",
                "position": 177
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13217/x3.png",
                "caption": "Figure 2:A high-level overview of our proposed framework,LATTICE. The process consists of two stages. (Left) In the offline stage, we organize an unstructured document corpus into a semantic tree. (Right) In the online stage, a search LLM performs a best-first traversal over calibrated path relevance scores to find documents relevant to a user query. The path relevance score is defined as the exponentially moving average of calibrated scores of nodes on the path. Score calibration is achieved by comparing nodes against high-relevance candidates from sibling branches and previously seen leaves, ensuring a globally coherent search.",
                "position": 199
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13217/x4.png",
                "caption": "Figure 3:An illustration of the search process ofLATTICEfor a real query from the BRIGHT benchmark. The color of each node corresponds to its computed path relevance; the highlighted yellow path shows the path to ground-truth documents. The search LLM makes a step-by-step decision at each internal node to determine which branch to explore next. The expanded callout provides a \"glass box\" view into one such decision, detailing the LLM’s explicit reasoning process as it scores the child nodes.",
                "position": 287
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13217/x5.png",
                "caption": "Figure 4:nDCG@10 vs.ℓ\\ell.",
                "position": 1005
            },
            {
                "img": "https://arxiv.org/html/2510.13217/x6.png",
                "caption": "Figure 5:nDCG@10 vs. beam-size.",
                "position": 1090
            }
        ]
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CSubjective Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13217/x7.png",
                "caption": "Figure 6:Search failing due to dynamically excluded search corpus,red edgesdenote excluded leaf nodes,gold edgesdenote ground-truth path",
                "position": 2073
            }
        ]
    },
    {
        "header": "Appendix DPrompts",
        "images": []
    }
]