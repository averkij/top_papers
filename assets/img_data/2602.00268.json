[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x1.png",
                "caption": "Figure 1:Text-to-video results before and after applying TokenTrim on Rolling Forcingliu2025rollingand Self Forcinghuang2025self.",
                "position": 109
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x2.png",
                "caption": "Figure 2:TokenTrim overview at autoregressive steptt.(a)Given the candidate batchùí≥t\\mathcal{X}_{t}and the previous batchùí≥t‚àí1\\mathcal{X}_{t-1}, we encode each frame and form latent summariesZtZ_{t}andZt‚àí1Z_{t-1}by averaging latents over theFFframes in each batch.\nWe compute per-token driftdi=‚à•Zt‚Äã(i)‚àíZt‚àí1‚Äã(i)‚à•2d_{i}=\\lVert Z_{t}(i)-Z_{t-1}(i)\\rVert_{2}and select the top-p‚ÄãNpNlargest drifts to form the unstable setStS_{t}, from which we compute the drift severityDtD_{t}.(b)We compareDtD_{t}to the adaptive thresholdŒºt+Œª‚ÄãœÉt\\mu_{t}+\\lambda\\sigma_{t}. IfDt‚â§Œºt+Œª‚ÄãœÉtD_{t}\\leq\\mu_{t}+\\lambda\\sigma_{t}, the KV cache(K,V)(K,V)is left unchanged and the batch is accepted. Otherwise, we mask the selected token positions in the temporal KV cache to obtain(K~,V~)(\\tilde{K},\\tilde{V})and regenerate the current batch conditioned on the pruned cache. Running statistics and the cache are updated using the accepted batchùí≥t‚ãÜ\\mathcal{X}_{t}^{\\star}.",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2602.00268/x3.png",
                "caption": "Figure 3:Qualitative results.Text-to-video results before and after applying TokenTrim on Rolling Forcingliu2025rollingand Self Forcinghuang2025self. TokenTrim mitigates degradation over time, e.g., color shifts (c - background and girl, d - background and bear), artifacts (b - light lens flare) and unnatural motion (a - Pikatchu). For additional qualitative results see App.Dand App.E.",
                "position": 146
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries: Self-Attention in Autoregressive Text-to-Video Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x4.png",
                "caption": "Figure 4:Text-to-video results from FlowMoShaulov et¬†al. (2025)and TokenTrim.\nFor additional qualitative results see App.F.",
                "position": 222
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x5.png",
                "caption": "Figure 5:Human preference study conducted on Rolling Forcingliu2025rolling(left) and Self Forcinghuang2025self(right) using VideoJAM-benchchefer2025videojam. TokenTrim is consistently preferred in terms of drift reduction, motion quality, and overall visual quality, while preserving text‚Äìvideo alignment. Error bars indicate 95% confidence intervals computed via Dirichlet sampling with Laplace smoothing.",
                "position": 462
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x6.png",
                "caption": "Figure 6:Human preference study on VideoJAM-Benchchefer2025videojam. Win rates comparing TokenTrim against FlowMoShaulov et¬†al. (2025)under Rolling Forcing. Error bars: 95% CIs via Dirichlet sampling with Laplace smoothing.",
                "position": 589
            }
        ]
    },
    {
        "header": "6Limitations & Future Work",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "8Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVBench Metrics Breakdown",
        "images": []
    },
    {
        "header": "Appendix BUser Study: Instructions Provided to Participants",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x7.png",
                "caption": "Figure 7:Screenshot of the Google Form used in the user study.",
                "position": 1746
            }
        ]
    },
    {
        "header": "Appendix CAblation Study - VBench Metrics Breakdown",
        "images": []
    },
    {
        "header": "Appendix DAdditional Qualitative Experiments: TokenTrim vs Self Forcing",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x8.png",
                "caption": "Figure 8:Additional Qualitative Results comparison between TokenTrim and Self Forcing[19].",
                "position": 1773
            }
        ]
    },
    {
        "header": "Appendix EAdditional Qualitative Experiments: TokenTrim vs Rolling Forcing",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00268/x9.png",
                "caption": "Figure 9:Additional Qualitative Results comparison between TokenTrim and Rolling Forcing[18].",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2602.00268/x10.png",
                "caption": "Figure 10:Additional Qualitative Results comparison between TokenTrim and FlowMo[20].",
                "position": 1793
            }
        ]
    },
    {
        "header": "Appendix FAdditional Qualitative Experiments: TokenTrim vs FlowMo",
        "images": []
    }
]