[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09024/x1.png",
                "caption": "Figure 1:The proposed BAR achieves a superior quality-cost trade-off (generation FIDvs. throughput) on ImageNet-256.",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09024/x2.png",
                "caption": "Figure 2:Best discrete and continuous generator comparison.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09024/x3.png",
                "caption": "Figure 3:A unified view for comparing discrete and continuous tokenizers.By measuring information capacity in bits, we enable a direct comparison. The continuous tokenizer MAR-VAE(Liet al.,2024)outperforms the discrete tokenizer LlamaGen-VQ(Sunet al.,2024)in reconstruction quality, a result directly attributable to its substantially higher bit allocation.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x4.png",
                "caption": "Figure 4:Scaling BAR’s discrete tokenizer (BAR-FSQ) with Bit Budget.Standard discrete methods (green circles) historically lag behind continuous baselines (blue circles) primarily due to restricted bit allocation. By systematically scaling the codebook size, BAR-FSQ (red curve) demonstrates that discrete tokenizer’s reconstruction performance is not inherently bounded; it matches and further surpasses continuous reconstruction fidelity with increased bit budget, challenging the assumption that continuous latent spaces are required for high-fidelity reconstruction.",
                "position": 201
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x5.png",
                "caption": "Figure 5:Overview of the proposed BAR framework.We decompose autoregressive visual generation into two stages: context modeling and token prediction.\n(a) For context modeling, we employ an autoregressive transformer to generate latent conditions via causal attention.\nFor the subsequent token prediction stage, we contrast our method with two baselines:\n(b) A standard linear head predicts logits over the full codebook. While effective for small vocabularies (<218<2^{18}), it fails to scale to larger sizes due to computational bottlenecks.\n(c) A bit-based head predicts bits directly; while scalable, it results in inferior generation quality.\n(d) The proposed Masked Bit Modeling (MBM) head generates bits via a progressive unmasking mechanism conditioned on the autoregressive transformer’s output. Unlike the baselines, MBM achieves both exceptional scalability and superior generation quality.",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x6.png",
                "caption": "Figure 6:Reconstruction and generation quality as a function of BAR tokenizer’s vocabulary size.Unlike the linear head, the proposedmasked bit modeling headscales to arbitrary codebook sizes. Furthermore, it achieves a superior reconstruction–generation trade-off compared to the bit head.",
                "position": 263
            }
        ]
    },
    {
        "header": "4Experimental Results",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "Appendix BHyper-parameters for Final BAR Models",
        "images": []
    },
    {
        "header": "Appendix CMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09024/x7.png",
                "caption": "Figure 7:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 1: “goldfish, Carassius auratus”.",
                "position": 3296
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x8.png",
                "caption": "Figure 8:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 33: “loggerhead, loggerhead turtle, Caretta caretta”.",
                "position": 3301
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x9.png",
                "caption": "Figure 9:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 90: “lorikeet”.",
                "position": 3306
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x10.png",
                "caption": "Figure 10:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 107: “jellyfish”.",
                "position": 3312
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x11.png",
                "caption": "Figure 11:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 207: “golden retriever”.",
                "position": 3317
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x12.png",
                "caption": "Figure 12:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 250: “Siberian husky”.",
                "position": 3322
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x13.png",
                "caption": "Figure 13:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 417: “balloon”.",
                "position": 3328
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x14.png",
                "caption": "Figure 14:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 562: “fountain”.",
                "position": 3333
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x15.png",
                "caption": "Figure 15:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 928: “ice cream, icecream”.",
                "position": 3338
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x16.png",
                "caption": "Figure 16:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 933: “cheeseburger”.",
                "position": 3344
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x17.png",
                "caption": "Figure 17:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 971: “bubble”.",
                "position": 3349
            },
            {
                "img": "https://arxiv.org/html/2602.09024/x18.png",
                "caption": "Figure 18:Visualization samples from BAR models.BAR is capable of generating high-fidelity image samples with great diversity. class idx 980: “volcano”.",
                "position": 3354
            }
        ]
    },
    {
        "header": "Appendix DVisualization on Generated Samples",
        "images": []
    }
]