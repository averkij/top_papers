[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17195/extracted/6157738/figures/Fig1.png",
                "caption": "Figure 1:Atla Selene Mini outperforms current state-of-the-art SLMJs: a) Overall task-average performance, comparing Atla Selene Mini (black) with the best and most widely used SLMJs. b) Breakdown of performance by task type and benchmark – seeTable1for full comparison.",
                "position": 85
            }
        ]
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17195/extracted/6157738/figures/Fig2.png",
                "caption": "Figure 2:Data curation strategy: The process of transforming a candidate dataset (left) into the final training mix (right). Yellow boxes indicate filtering steps, purple represents synthetic generation of chosen and rejected pairs (blue and red) for preference optimization, and red circles highlight ablation-informed decisions, such as reward thresholds and dataset inclusion.",
                "position": 95
            }
        ]
    },
    {
        "header": "3Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17195/extracted/6157738/figures/Fig3.png",
                "caption": "Figure 3:Real-world evaluation: a) Performance on domain-specific industry benchmarks of Atla Selene Mini (black) compared to base model (orange) measured in accuracy. Trained model shows higher expert agreement on FinanceBench, a financial benchmark, and CRAFT-MD, a medical dataset. b) Performance on RewardBench of Atla Selene Mini compared to base model, when prompt format is changed. Trained model shows consistent improvement across formats. c) Performance measured by ELO scores, based on head-to-head comparisons in Judge Arena. An early snapshot of Atla Selene Mini (bold) beats all other evaluators as of Jan 22, 2025. Error bars indicate 95% CI.",
                "position": 346
            }
        ]
    },
    {
        "header": "4Discussion",
        "images": []
    },
    {
        "header": "5Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining dataset embedding",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17195/extracted/6157738/figures/nomic.png",
                "caption": "Figure 4:Training dataset map: Topic-stratified, two-dimensional embedding representation of Atla Selene Mini’s training dataset generated using Nomic Atlas[33].",
                "position": 879
            }
        ]
    },
    {
        "header": "Appendix BPrompt template with example data point",
        "images": []
    },
    {
        "header": "Appendix CImpact of reward model filtering",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.17195/extracted/6157738/figures/rm-ablation-report.png",
                "caption": "Figure 6:Reward model filtering: Effects of reward model (RM) filtering on single dataset ablations. Bars show difference on accuracy (black) and Pearson correlation (green) metrics between RM-filtered and random subsets of data. We observed that effects were dataset-dependent, informing our decision on which datasets to filter.",
                "position": 995
            }
        ]
    },
    {
        "header": "Appendix DDetailed performance breakdown across model sizes",
        "images": []
    },
    {
        "header": "Appendix EPrompt templates for robustness experiments",
        "images": []
    }
]