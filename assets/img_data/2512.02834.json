[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/imgs/taco_good.png",
                "caption": "",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/x1.png",
                "caption": "Figure 1:Illustrative Example:We fix the initial noise for the denoising process ofπ0\\pi_{0}tonoise1{\\rm noise}_{1}and evaluate the success rate. Then we fix the initial noise for the denoising process ofπ0\\pi_{0}to another noise valuenoise2{\\rm noise}_{2}and evaluate the success rate under the same scenarios. We plot the two resulting success rates using a floating bar chart. The same procedure is applied to RDT.",
                "position": 135
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/x2.png",
                "caption": "Figure 2:Overview of TACO.In the training stage (Stage 1), we sample data from the SFT dataset, add a certain amount of noise to the expert actions, and feed them into the VLA to denoise the actions while extracting internal representations.\nThese representations are then used to train the CFN.\nDuring inference (Stage 2), the VLA generates multiple candidate actions along with their corresponding internal representations, and the CFN serves as a selector to select the action with the highest count for execution.",
                "position": 250
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/x3.png",
                "caption": "Figure 3:We performed 100 action samples for a single observation from the test set in each of thestamp seal(left),move can pot(right) tasks, and scored them using the pseudo-counter. The red points indicate the actions with the highest Count values, which generally correspond to the actions with the smallestL2L_{2}distance to the action labels.",
                "position": 446
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x4.png",
                "caption": "",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x5.png",
                "caption": "Figure 4:(Left) Efficiency improvement from KV cache optimization. For each number of action samples, we repeated the inference 50 times and reported the average inference time.\n(Right) A key moment from thePaper and Pentask, where the robot needs to pick up a marker. The base policyπ0\\pi_{0}often falls into a suboptimal mode, causing the arm to swing back and forth and hesitate before grasping, which leads to task failure. In contrast, our method enablesπ0\\pi_{0}to completely avoid such oscillations and hesitation during grasping.",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x6.png",
                "caption": "",
                "position": 1005
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x7.png",
                "caption": "Figure 5:Success rate (%) in real-world experiments. On our self-builtRealMan 75dual-arm robotic platform, applying the proposed test-time scaling method improves both task accuracy and safety, resulting in an average 16% increase in success rate.",
                "position": 1018
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAlgorithmic Description of TACO during Inference",
        "images": []
    },
    {
        "header": "Appendix BAlgorithmic Description of TACO during Training",
        "images": []
    },
    {
        "header": "Appendix CAdditional Preliminary",
        "images": []
    },
    {
        "header": "Appendix DTraining Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/x8.png",
                "caption": "Figure 6:During training, each internal representation undergoes a search process that selects the best one fromNNcandidates to maximally preserve the information of the ground-truth action.",
                "position": 1286
            }
        ]
    },
    {
        "header": "Appendix ETraining Procedure Details",
        "images": []
    },
    {
        "header": "Appendix FAdditional Simulation Experiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.02834/x9.png",
                "caption": "Figure 7:Illustration of the benchmarks.",
                "position": 1516
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x10.png",
                "caption": "(a)CNN + MLP Encoder",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x10.png",
                "caption": "(a)CNN + MLP Encoder",
                "position": 1545
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x11.png",
                "caption": "(b)Internal Representation",
                "position": 1548
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x12.png",
                "caption": "(c)Internal Representation with High-Fidelity Feature Search",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2512.02834/x13.png",
                "caption": "Figure 9:Schematic illustration of our real-world robotic platform (left), and the task execution pipeline for the three real-world tasks (right).",
                "position": 1623
            }
        ]
    },
    {
        "header": "Appendix GAdditional Real-World Experiment Details",
        "images": []
    }
]