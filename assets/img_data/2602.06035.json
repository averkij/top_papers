[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06035/x1.png",
                "caption": "Figure 2:Overview of the proposed InterPrior framework. It consists of: (I) full-reference imitation expert training on large-scale human-object interaction data; (II) distillation of the expert into a variational policy with a structured latent space for skill embeddings; and (III) post-training of the variational policy to enhance generalization. Blue modules denote the final policy used at inference; green and red modules are trainingâ€‘only components, and red arrows denote supervision signals (rewards/losses).",
                "position": 146
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06035/x2.png",
                "caption": "Figure 3:Qualitative comparisonof same reference imitation between InterMimic[86](top) and our InterMimic+ (bottom). InterMimic strictly follows the reference humanoid motion but fails to grasp the thin cloth stand when initialized with perturbations.",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2602.06035/fig/long-term.png",
                "caption": "Figure 4:Qualitative resultson a multi-object task. The model input is shifted to the second object once the first object is released.",
                "position": 357
            },
            {
                "img": "https://arxiv.org/html/2602.06035/x3.png",
                "caption": "Figure 5:Zero-shot qualitative results.A single InterPrior model trained from OMOMO[28]demonstrates generalization tounseenobjects and interactions from BEHAVE[3]and HODome[96].",
                "position": 383
            },
            {
                "img": "https://arxiv.org/html/2602.06035/x4.png",
                "caption": "Figure 6:Qualitative resultson sim-to-sim from IsaacGym[41]to MuJoCo[61]with object trajectory as condition, showing a sustained interaction involving box pickup, pushing, and kicking.",
                "position": 386
            },
            {
                "img": "https://arxiv.org/html/2602.06035/x5.png",
                "caption": "Figure 7:Qualitative comparisonbetween InterMimic[86](left, full reference), MaskedMimic[57](middle), and our InterPrior (right) on unseen and imperfect interactions from the BEHAVE[3]dataset. InterPrior can recover from data imperfection and continue the rollout.",
                "position": 389
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Contents",
        "images": []
    },
    {
        "header": "ADemo Video",
        "images": []
    },
    {
        "header": "BSimulation",
        "images": []
    },
    {
        "header": "CGoal Formulation",
        "images": []
    },
    {
        "header": "DAdditional Details on Methodology",
        "images": []
    },
    {
        "header": "EImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06035/x6.png",
                "caption": "Figure A:Additional qualitative comparisonswith baseline method[57,58](Top). Our InterPrior shows higher success rate under the same task goal.",
                "position": 2462
            }
        ]
    },
    {
        "header": "FAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06035/x7.png",
                "caption": "Figure B:Qualitative resultsgiven the same goal. Our framework produces multiple valid yet distinct interaction trajectories.",
                "position": 2485
            },
            {
                "img": "https://arxiv.org/html/2602.06035/x8.png",
                "caption": "Figure C:Qualitative resultsof InterPrior following the targets generated by InterDiff[85](yellowandreddots). InterPrior adaptively completes the task without strictly adhering to the targets, using only sparse inputs of wrist, feet, and object target.",
                "position": 2488
            }
        ]
    },
    {
        "header": "GDiscussion",
        "images": []
    }
]