[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x1.png",
                "caption": "Figure 1:We presentC3C^{3}, the first method for training video models that know when they don’t know. Using proper scoring rules,C3C^{3}generates dense confidence predictions at the subpatch (channel) level that are physically interpretable and aligned with observations.",
                "position": 112
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Uncertainty Quantification of Action-Conditioned Video Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x2.png",
                "caption": "Figure 2:Model Architecture.C3C^{3}enables simultaneous video generation and uncertainty quantification (visualized as a heatmap), quantifying the model’s confidence in its accuracy using a UQ probe acting on the video latents.",
                "position": 163
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x3.png",
                "caption": "Figure 3:Latent space error.We visualize the latent-space video error in the RGB space, showing the observable range of the errors.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x4.png",
                "caption": "Figure 4:(a)Average calibration error.All three architectures have very low ECE, and relatively low MCE. (b)Aggregated reliability diagrams.All methods are well-calibrated, closely tracking the line of perfect calibration.",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x5.png",
                "caption": "Figure 5:Reliability diagrams for FSC and CS-BC.At the same thresholdεv\\varepsilon_{v}(0.50.5), both models achieve the similarly well-calibrated confidence predictions.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x6.png",
                "caption": "Figure 6:Reliability diagram for each threshold.C3C^{3}is well-calibrated across all accuracy thresholds, with some degree of conservativeness at very low thresholds.",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x7.png",
                "caption": "Figure 7:Confidence heatmap visualization.We show the ground-truth and generated video frames, along with the composited confidence map and the full confidence map at higher error thresholds. The video model is more uncertain about the robot’s motion compared to the video background at these error thresholds, which is well-aligned with human intuition.",
                "position": 444
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x8.png",
                "caption": "Figure 8:Capturing Hallucinations.The boxed areas highlight severe hallucination of the video generation model, whereC3C^{3}is able to capture the sub-patch level high uncertainty content.",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x9.png",
                "caption": "Figure 9:Uncertainty in Object Interactions.The video model is uncertain about the object dynamics during interaction, resulting in high uncertainty.",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x9.png",
                "caption": "Figure 9:Uncertainty in Object Interactions.The video model is uncertain about the object dynamics during interaction, resulting in high uncertainty.",
                "position": 454
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x10.png",
                "caption": "Figure 10:Occlusions.The internal content of the cabinet is occluded, resulting in high uncertainty of the interior area when the cabinet door is opened.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x11.png",
                "caption": "Figure 11:Reliability diagram in OOD conditions.C3C^{3}provides calibrated uncertainty estimates in OOD scenes.",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x12.png",
                "caption": "Figure 12:OOD detection.C3C^{3}is able to accurately localize hallucinations (identified as regions of low confidence) in OOD scenarios where the model is presented with inputs outside of its training distribution.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x13.png",
                "caption": "Figure 13:Reliability diagram on the DROID dataset.C3C^{3}remains well-calibrated on the more diverse DROID dataset compared to the Bridge dataset.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x14.png",
                "caption": "Figure 14:Hallucination.C3C^{3}identifies hallucinations in the generated videos from the DROID dataset as areas of high uncertainty.",
                "position": 532
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations and Future Work",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Video Diffusion/Flow-Based Models",
        "images": []
    },
    {
        "header": "8Proper Scoring Rule",
        "images": []
    },
    {
        "header": "9Proofs",
        "images": []
    },
    {
        "header": "10Additional Results on Interpretability on the Bridge Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x15.png",
                "caption": "Figure 15:Confidence heatmap visualization.We show the ground-truth and generated video frames, along with the composited confidence map and the full confidence map at lower error thresholdsεv\\varepsilon_{v}. At low error thresholds, the video model is uncertain about theaccuracyof the background but confident in theinaccuracyof the robot’s motion.",
                "position": 1365
            }
        ]
    },
    {
        "header": "11Detecting OOD Inputs at Inference",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x16.png",
                "caption": "Figure 16:OOD detection.We show additional OOD settings, demonstrating the interpretability ofC3C^{3}’s confidence estimates.",
                "position": 1378
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x17.png",
                "caption": "Figure 17:Extreme Lighting condition.C3C^{3}identifies artificially edited pixels where the video model attempts to reset the lighting of the scene to match the training data distribution.",
                "position": 1385
            }
        ]
    },
    {
        "header": "12Experiment Results on the DROID Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x18.png",
                "caption": "Figure 18:Object Interaction.C3C^{3}localizes uncertainty from multiple sources, e.g., from the robot’s motion, object dynamics, and scene background.",
                "position": 1401
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x19.png",
                "caption": "Figure 19:Occlusions.Our method captures the uncertainty\nassociated with the robot parts that were occluded in the first frame.",
                "position": 1408
            }
        ]
    },
    {
        "header": "13Additional Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05927/x20.png",
                "caption": "Figure 20:Reliability diagram for ablation on proper scoring rules.C3C^{3}remains well-calibrated with the BCE and Brier scores.",
                "position": 1432
            },
            {
                "img": "https://arxiv.org/html/2512.05927/x21.png",
                "caption": "Figure 21:Reliability diagram for ablation on diffusion forcing.Diffusion forcing increases underconfidence ofC3C^{3}, degrading calibration.",
                "position": 1439
            }
        ]
    },
    {
        "header": "14Additional Implementation Details",
        "images": []
    }
]