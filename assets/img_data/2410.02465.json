[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02465/x1.png",
                "caption": "Figure 1:Comparison of IT and RT.In both methods, the loss is computed exclusively on the response tokens. Unlike IT, RT does not involve instruction conditioning and focuses solely on learning the distribution of responses.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Response Tuning (RT)",
        "images": []
    },
    {
        "header": "4Instructability of RT Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02465/x2.png",
                "caption": "(a)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x2.png",
                "caption": "(a)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x3.png",
                "caption": "(b)Base LLM: Gemma-2-9B(Riviere et al.,2024)",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x4.png",
                "caption": "(a)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x4.png",
                "caption": "(a)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x5.png",
                "caption": "(b)Base LLM: Gemma-2-9B(Riviere et al.,2024)",
                "position": 256
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x6.png",
                "caption": "(a)Human evaluation results",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x6.png",
                "caption": "(a)Human evaluation results",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x7.png",
                "caption": "(b)GPT-4 judge evaluation results",
                "position": 271
            }
        ]
    },
    {
        "header": "5Refining Response Distribution for Preference Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02465/x8.png",
                "caption": "(a)AdvBench",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x8.png",
                "caption": "(a)AdvBench",
                "position": 538
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x8.png",
                "caption": "(a)AdvBench",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x9.png",
                "caption": "(b)HarmBench",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x10.png",
                "caption": "(c)MaliciousInstruct",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x11.png",
                "caption": "(d)XSTest (unsafe)",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x11.png",
                "caption": "(d)XSTest (unsafe)",
                "position": 563
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x12.png",
                "caption": "(e)XSTest (benign)",
                "position": 568
            }
        ]
    },
    {
        "header": "6Embedding Behavioral Guidance in Response Space for Safety Alignment",
        "images": []
    },
    {
        "header": "7In-Context Response Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02465/x13.png",
                "caption": "(f)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x13.png",
                "caption": "(f)Base LLM: Llama-3.1-8B(Dubey et al.,2024)",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x14.png",
                "caption": "(g)Base LLM: Gemma-2-9B(Riviere et al.,2024)",
                "position": 648
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Limitations & Future Work",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Setup",
        "images": []
    },
    {
        "header": "Appendix BExperimental Setup",
        "images": []
    },
    {
        "header": "Appendix CFull Experimental Results",
        "images": []
    },
    {
        "header": "Appendix DData Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02465/x15.png",
                "caption": "Figure 8:Annotation interface for human evaluators. Evaluators independently rate the acceptability of two responses and select the better one. Model indices are randomly assigned each turn to avoid bias.",
                "position": 2329
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x16.png",
                "caption": "(a)Llama-3.1-8B(Dubey et al.,2024)",
                "position": 2687
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x16.png",
                "caption": "(a)Llama-3.1-8B(Dubey et al.,2024)",
                "position": 2690
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x17.png",
                "caption": "(b)Gemma-2-9B(Riviere et al.,2024)",
                "position": 2695
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x18.png",
                "caption": "(c)Gemma-2-2B(Riviere et al.,2024)",
                "position": 2701
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x19.png",
                "caption": "(d)Mistral-7B-v0.3(Jiang et al.,2023)",
                "position": 2706
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x20.png",
                "caption": "(a)Llama-3.1-8B(Dubey et al.,2024)",
                "position": 3313
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x20.png",
                "caption": "(a)Llama-3.1-8B(Dubey et al.,2024)",
                "position": 3316
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x21.png",
                "caption": "(b)Gemma-2-9B(Riviere et al.,2024)",
                "position": 3321
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x22.png",
                "caption": "(c)Gemma-2-2B(Riviere et al.,2024)",
                "position": 3327
            },
            {
                "img": "https://arxiv.org/html/2410.02465/x23.png",
                "caption": "(d)Mistral-7B-v0.3(Jiang et al.,2023)",
                "position": 3332
            }
        ]
    },
    {
        "header": "Appendix EModel Output Examples",
        "images": []
    }
]