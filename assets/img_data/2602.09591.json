[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09591/x1.png",
                "caption": "Figure 1:Score vs. average output length.Qwen3-1.7B-Base (top) shows a monotonically increasing trend, while DeepSeek-R1-Distill-Qwen-1.5B (bottom) exhibits a non-monotonic relationship with optimal performance at intermediate lengths.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x2.png",
                "caption": "Figure 2:Decomposition of accuracy into mode accuracy and dispersion metricsfor DeepSeek-R1-Distill-Qwen-1.5B on AMC and MATH-500. In the long-output regime, degradation is driven by increased dispersion; in the short-output regime, both central tendency and dispersion are affected.",
                "position": 331
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09591/x3.png",
                "caption": "Figure 3:Effect of batch size configuration on training dynamics.Top left: response length during training. Top right: absolute difference between rollout and training token probabilities.\nBottom: validation scores on MATH-500 and AIME 2024.\nThe 512/32 setting (generation batch size 512, mini-batch size 32) leads to decreasing response length and validation performance, while the 64/64 setting maintains stable training.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x4.png",
                "caption": "Figure 4:Effect of precision and TIS on training dynamics for DeepSeek-R1-Distill-Qwen-1.5B.Comparison of BF16 with TIS, FP16 with TIS, FP16 without TIS, and ALP (β=1​e−4\\beta=1\\mathrm{e}{-4}) in FP16 without TIS.\nNote that the maximum response length differs between the ALP experiment and the precision ablation experiments, so response lengths should not be directly compared across these settings.",
                "position": 442
            }
        ]
    },
    {
        "header": "Appendix BDetails of Length Control Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09591/x5.png",
                "caption": "Figure 5:GFPO reproduction attempt on two base models.Average output length during training for GFPO (G=16G=16,k=8k=8) compared to the DAPO baseline. Both Qwen3-1.7B-Base and DeepSeek-R1-Distill-Qwen-1.5B show increasing output length under GFPO, particularly in later training stages.",
                "position": 591
            }
        ]
    },
    {
        "header": "Appendix CGRPO and DAPO Objectives",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09591/x6.png",
                "caption": "Figure 6:Evolution of output length during training(20-step moving average).\nLeft: average output length. Right: length bias (normalized difference between correct and incorrect response lengths).\nOn Qwen3-1.7B-Base, Sample Avg (GRPO) and DRPO exhibit large negative length bias, indicating that incorrect responses tend to be longer than correct ones.",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x7.png",
                "caption": "Figure 7:Score vs. average output length for DeepSeek-R1-Distill-Qwen-1.5B at equal wall-clock training timeThe non-monotonic relationship persists, indicating that performance degradation with short outputs is not due to reduced training tokens.",
                "position": 704
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x8.png",
                "caption": "Figure 8:Score vs. average output length for DeepSeek-R1-Distill-Qwen-1.5B with 64K evaluation context length.The non-monotonic pattern is consistent with the 32K evaluation (Figure1), confirming that performance degradation at long output lengths is not an artifact of response truncation.",
                "position": 727
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x9.png",
                "caption": "Figure 9:Truncation rate at 32K vs. 64K evaluation context length for DeepSeek-R1-Distill-Qwen-1.5B.Each point represents a method with a specific hyperparameter configuration.\nPoints close to the diagonal indicate that extending the context length does not substantially reduce truncation.",
                "position": 733
            },
            {
                "img": "https://arxiv.org/html/2602.09591/x10.png",
                "caption": "Figure 10:Mode accuracy, answer entropy, and mode share vs. average output length for DeepSeek-R1-Distill-Qwen-1.5Bacross all benchmarks after 480 training steps.\nThis figure extends Figure2to include AIME 2024 and AIME 2025.",
                "position": 752
            }
        ]
    },
    {
        "header": "Appendix DAdditional Experimental Results",
        "images": []
    }
]