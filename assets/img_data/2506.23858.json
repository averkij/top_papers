[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23858/x1.png",
                "caption": "Figure 1:(a) VMoBA performs better than Full Attention while reducing training time. (b) VMoBA is faster when the sequence length goes higher. The ‘x’ points represent tested latencies, and the lines are fitted with quadratic functions. (c) VMoBA is an efficient and effective adaptation of MoBA.",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23858/x2.png",
                "caption": "Figure 2:The overall pipeline of VMoBA.We first partition key blocks with Layer-wise Recurrent BLock Partition, then select the blocks using Global Block Selection and Threshold-based Block Selection. Finally, the attention is computed only with the selected blocks.",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2506.23858/x3.png",
                "caption": "Figure 3:The query-key block attention map shows 1-2-3D distinct patterns.",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2506.23858/x4.png",
                "caption": "Figure 4:Summation of top 25% query-key similarities. Different queries have varying importance.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2506.23858/x5.png",
                "caption": "Figure 5:Sorted query-key block similarity and top 30%/50% cutoff lines. The right parts of the cutoff lines contain corresponding cumulative summations of query-key block similarity.",
                "position": 260
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23858/x6.png",
                "caption": "Figure 6:Qualitative comparisonof VMoBA and baseline methods.",
                "position": 678
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experiments",
        "images": []
    },
    {
        "header": "Appendix CPre-training Loss Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.23858/x7.png",
                "caption": "(a)11k sequence length.",
                "position": 1892
            },
            {
                "img": "https://arxiv.org/html/2506.23858/x7.png",
                "caption": "(a)11k sequence length.",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2506.23858/x8.png",
                "caption": "(b)46k sequence length.",
                "position": 1900
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Work",
        "images": []
    }
]