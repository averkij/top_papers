[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Explainability Across Static and Agentic AI Paradigms",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06841/x1.png",
                "caption": "Figure 2:Agent execution loop with explicit state–action–observation semantics. The architecture separates agent execution from interpretability and verification, showing how traces are reconstructed and analyzed to produce Minimal Explanation Packets (MEPs) for auditing and diagnosis.",
                "position": 280
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06841/XAI_Figures/lime-edited.png",
                "caption": "Figure 3:Comparison of local (LIME) (a), and global (SHAP) (b) interpretability.",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2602.06841/XAI_Figures/shap_global.png",
                "caption": "",
                "position": 1427
            },
            {
                "img": "https://arxiv.org/html/2602.06841/XAI_Figures/taubench_airline_shap_beeswarm.png",
                "caption": "Figure 4:SHAP summary (beeswarm) plot for rubric-level features. Each point is a run; the x-axis shows the SHAP value (contribution to predicted success), and color indicates feature value (low vs. high). Features are ordered by mean absolute SHAP value.",
                "position": 1876
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]