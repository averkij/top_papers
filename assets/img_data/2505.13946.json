[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background, Related Work, and Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13946/x1.png",
                "caption": "Figure 1:Illustration of distribution shifts for an MLLM (a) and performance degeneration and embedding shifts of the MLLM (b).An MLLM (LLaVA-v1.5-7B) receives arbitrary queries that might be visually and/or textually perturbed by unexpected noise. These distribution shifts result in performance drops, as shown in the middle bar plot. A visualization of intermediate layer representations of the MLLM on LLaVA-Bench-COCO and its variants indicates that MLLM fails to learn a proper level of invariance to generalize multimodal queries in the representation space.",
                "position": 164
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13946/x2.png",
                "caption": "Figure 2:Vittlearchitecture. We insert a learnable bottleneck layergœï={gœïv,gœït}subscriptùëîitalic-œïsubscriptùëîsubscriptitalic-œïùë£subscriptùëîsubscriptitalic-œïùë°g_{\\phi}=\\{g_{\\phi_{v}},g_{\\phi_{t}}\\}italic_g start_POSTSUBSCRIPT italic_œï end_POSTSUBSCRIPT = { italic_g start_POSTSUBSCRIPT italic_œï start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_œï start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT }on top oflùëôlitalic_lblocks of LLM backbone (i.e., LLM-stemfŒ∏lsubscriptùëìsuperscriptùúÉùëôf_{\\theta^{l}}italic_f start_POSTSUBSCRIPT italic_Œ∏ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_POSTSUBSCRIPT) to estimate posterior distributions of token embeddings. After obtaining a sample per token{z~v,z~t}subscript~ùëßùë£subscript~ùëßùë°\\{\\tilde{z}_{v},\\tilde{z}_{t}\\}{ over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT }from posteriors, we interpolate it with a pre-bottlenecked token representation{zv,zt}subscriptùëßùë£subscriptùëßùë°\\{z_{v},z_{t}\\}{ italic_z start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT }and pass it through the remaining LLM blocks (i.e., LLM-headfŒ∏l+subscriptùëìsuperscriptùúÉlimit-fromùëôf_{\\theta^{l+}}italic_f start_POSTSUBSCRIPT italic_Œ∏ start_POSTSUPERSCRIPT italic_l + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT).",
                "position": 328
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13946/x3.png",
                "caption": "Figure 3:Object hallucination detection performance on POPE variants. We enumerate the hallucination detection accuracy of each method on nine versions of perturbed samples, and observe consistent gains byVittle(highlighted by green numbers of relative improvement from baseline).",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x4.png",
                "caption": "Figure 4:Open-ended QA performance on LB-COCO variants. We enumerate the relative preference score of responses from each model on 18 version of perturbed samples, and observe consistent gains byVittle(especially for theVittle(F)) on most of the textual (top), and joint (bottom) perturbations (results on visual perturbations are deferred to AppendixB).",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x5.png",
                "caption": "Figure 5:Evaluation under varying perturbation severity.Vittleachieves better performance, especially on severe perturbations.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x6.png",
                "caption": "",
                "position": 638
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x7.png",
                "caption": "Figure 7:Case study on LB-COCO under perturbations.Although LLaVA-v1.5 produces a reasonable response for clean samples, the response and its quality vary under perturbations. Meanwhile,Vittlemaintains the consistency for the responses.",
                "position": 657
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x8.png",
                "caption": "",
                "position": 708
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Experiment Setup and Implementation Detail",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13946/x9.png",
                "caption": "Figure 10:Examples of visual perturbations.",
                "position": 2781
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x10.png",
                "caption": "Figure 11:Examples of textual perturbations.",
                "position": 2784
            }
        ]
    },
    {
        "header": "Appendix BAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13946/x11.png",
                "caption": "Figure 12:Ablation study for the bottleneck layer index (left) and KLD regularization magnitude parameterŒ≤ùõΩ\\betaitalic_Œ≤(right).",
                "position": 2938
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x12.png",
                "caption": "Figure 13:Pair-wise cosine distance of\nintermediate representations between clean LB-COCO and 27 versions of perturbed LB-COCO datasets.Vittle(F) consistently reduces the representation gap between the clean samples and their semantically equivalent perturbed ones.",
                "position": 3006
            },
            {
                "img": "https://arxiv.org/html/2505.13946/x13.png",
                "caption": "Figure 14:Object hallucination detection performance on POPE perturbation datasets (top), and Open-ended QA performance on LB-COCO perturbation datasets (three below) of Prism-7B. We enumerate the accuracy for the object hallucination detection task and relative preference score for the open-ended QA task of each method on perturbed datasets, where we observe consistent performance gains byVittle.",
                "position": 3152
            }
        ]
    },
    {
        "header": "Appendix CDerivation of Variational Bound for IB in MLLM",
        "images": []
    },
    {
        "header": "Appendix DMissing Proof",
        "images": []
    },
    {
        "header": "Appendix EExtended Literature Review",
        "images": []
    },
    {
        "header": "Appendix FLimitation and Future Work",
        "images": []
    },
    {
        "header": "Appendix GImpact Statement",
        "images": []
    }
]