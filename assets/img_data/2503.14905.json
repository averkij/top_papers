[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F1.png",
                "caption": "Figure 1:FakeVLM is a specialized large multimodal model designed for both DeepFake and general synthetic image detection tasks across multiple domains.",
                "position": 85
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F2.png",
                "caption": "Figure 2:Construction pipeline of FakeClue dataset, including data collection from open source and self-synthesized datasets, pre-processing with categorization, label prompt design based on category knowledge, and multiple LMMs annotation with result aggregation.",
                "position": 139
            }
        ]
    },
    {
        "header": "3Dataset",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F2.jpg",
                "caption": "Figure 3:Comparison of synthetic image detection approaches on LOKI and FakeClue datasets: (1) QA with Frozen LMMs (no training), (2) Frozen backbone + linear probe (only linear layer trained), (3) Direct Real/Fake QA tuning, and (4) VQA with artifact explanations tuning.",
                "position": 274
            },
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F3.jpg",
                "caption": "Figure 4:Overview of FakeVLM, our proposed framework for detecting synthetic images and explaining their artifacts. Built upon LLaVA, FakeVLM integrates multiple captioning models to assess key visual aspects.",
                "position": 277
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F4.png",
                "caption": "Figure 5:Comparative case analysis of synthetic image detection, covering animals, people, objects, documents, and remote sensing. FakeVLM outperforms GPT in precision, comprehensiveness, and relevance, indicating its superior detection and interpretation capabilities.",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F9.png",
                "caption": "Figure 6:Typical cases on DD-VQA dataset. Our model accurately identifies and explains the synthetic artifacts, demonstrating its effectiveness in fine-grained DeepFake detection and interpretation.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2503.14905/extracted/6292265/figure/F6.png",
                "caption": "Figure 7:Performance of FakeVLM on real images.",
                "position": 779
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]