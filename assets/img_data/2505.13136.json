[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13136/x1.png",
                "caption": "Figure 1:Performance on SuperGLEBer benchmark.∙∙\\bullet∙markers: encoders,▲▲\\blacktriangle▲markers: decoders.\nDashed arrows: LLM2Vec conversion gains.\nModels of the same family are colored in the same color.",
                "position": 124
            },
            {
                "img": "https://arxiv.org/html/2505.13136/extracted/6454259/pics/modernGBERT-emoj.png",
                "caption": "",
                "position": 160
            }
        ]
    },
    {
        "header": "2Datasets",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Evaluation Setup",
        "images": []
    },
    {
        "header": "5Evaluation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13136/x2.png",
                "caption": "Figure 2:Intermediate checkpoint evaluation of ModernGBERT 1B during pre-training, on the SuperGLEBer tasks: NLI (top) and PAWSX (bottom).\nTo improve trend visibility, we adjusted the y-axis scale and plotted every second checkpoint.",
                "position": 397
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AModel Architecture and Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13136/x3.png",
                "caption": "Figure 3:Intermediate Checkpoint Evaluation.\nNote that the solid line represents the mean of the six tasks selected for the intermediate checkpoint evaluation (NLI, FactClaiming Comments, DB Aspect, WebCAGe, EuroParl, PAWSX Similarity). The box plots show the distribution of scores for those checkpoints evaluated across all 29 SuperGLEBer tasks. We compared each pair of these checkpoints using Wilcoxon signed-rank tests, and highlighted significant increases with brackets. Brackets of pairs without significant increases are not displayed. (Accordingly, all pairs of 134M checkpoints show no significant increase.)\nFour checkpoints failed to converge during fine-tuning on some task, leading to the visible outliers.\nSimilar behavior has been observed byAntoun et al. (2025).",
                "position": 2257
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Results",
        "images": []
    }
]