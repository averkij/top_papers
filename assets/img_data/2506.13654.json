[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x1.png",
                "caption": "",
                "position": 115
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Egocentric Long Video Reasoning via Dynamic Tool-Calling",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x2.png",
                "caption": "",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2506.13654/x3.png",
                "caption": "",
                "position": 288
            },
            {
                "img": "https://arxiv.org/html/2506.13654/x4.png",
                "caption": "",
                "position": 292
            }
        ]
    },
    {
        "header": "4Ego-R1 Data: Chain-of-Tool-Thought (CoTT) for Video Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x5.png",
                "caption": "Figure 2:Data generation pipeline of the Ego-R1 Data.We first obtained raw QA pairs from both AI-generated and human-annotated sources based on 6 raw videos collected from 6 participants and the corresponding log. The verified and processed Multiple Choice Questions (MCQs) serve as the foundation of the Ego-R1 Data (left). We take questions without answers for Chain-of-Tool-Thought (CoTT) generation, which involves creating reasoning chains that include explicit thinking steps and dynamic tool-calling sequences (right).",
                "position": 304
            }
        ]
    },
    {
        "header": "5Ego-R1 Agent: Towards Tools Integrated Video Understanding Agent",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x6.png",
                "caption": "Figure 3:Overview of the two-stage training strategies in Ego-R1.Ego-R1 employs a two-stage training approach: Stage 1 utilizes supervised fine-tuning with CoTT data to establish structured tool-calling capabilities, while Stage 2 applies multi-turn reinforcement learning with rule-based rewards to optimize iterative reasoning and tool execution across diverse question types.",
                "position": 360
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": []
    },
    {
        "header": "7Conclusion and Outlook",
        "images": []
    },
    {
        "header": "8Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AHierarchical RAG",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x7.png",
                "caption": "Figure 4:Overview of the Hierarchical RAG system.Based on the raw video and its 30-second clips, we generate the memory bank for each video from its 30-second-level summaries to day-level summaries. During the keywords retrieval, the system searches efficiently by starting with day-level summaries and drilling down to 10-minute segments as needed.",
                "position": 1874
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13654/x8.png",
                "caption": "Figure 5:Qualitative results comparison with Video-R1.Case 1-3 illustrate successful examples where Ego-R1 outperforms Video-R1 by producing more detailed, interpretable step-by-step reasoning chains through dynamic tool-calling. In contrast, Case 4 highlights a failure case from Ego-R1 Agent. Although the observation in Step 1 correctly identified relevant information near timestampDAY2_15500000, the subsequent tool call failed to adjust the temporal range accordingly, resulting in an incorrect or suboptimal retrieval in the next step, leading to the final error answer.",
                "position": 1982
            }
        ]
    },
    {
        "header": "Appendix DFuture Works",
        "images": []
    }
]