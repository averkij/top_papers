[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x1.png",
                "caption": "Figure 1:Illustration of Dual-Factorization. The arrow line indicates CausalFusion‚Äôs generation path, moving from one state to the next by jointly generating along the sequential and noise-level dimension at each step.\nCompared to DiT, our In-context DiT substantially improves results with fewer parameters. CausalFusion further enhances performance without changing the architecture or parameter count. Results were trained on IN1K for 240 epochs. CausalFusion adopts arbitrary AR steps for image generation, but each step only diffuses partial tokens, resulting in similar (or slightly lower) computational complexity.",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x2.png",
                "caption": "(a)Samples generated by CausalFusion-XL/2, ImageNet 512√ó\\times√ó512, 800 epoch, DDPM 250 steps, CFG=4.0",
                "position": 106
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x2.png",
                "caption": "(a)Samples generated by CausalFusion-XL/2, ImageNet 512√ó\\times√ó512, 800 epoch, DDPM 250 steps, CFG=4.0",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x3.png",
                "caption": "(b)Zero-shot image editingresults generated by CausalFusion-XL/2, ImageNet 512√ó\\times√ó512, 800 epoch. We first generate the original image (those on the left), then mask out its centre region, top-half, or bottom-half, and regenerate the image with new class conditions. Details are discussed in Sec6.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3CausalFusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x4.png",
                "caption": "Figure 3:Conceptual comparison between the DiT and CausalFusion architectures. a) DiT incorporates conditioning via adaptive layer normalization, processing a fixed-size set of entire image tokens as input. All the noise tokensxtsubscriptùë•ùë°x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTare fed into DiT with full attention observation, enabling comprehensive modeling of the input during processing.\nb) CausalFusion treats all input modalities equally in an in-context manner, denoising a random subset of image tokensxt,Œ∫ssubscriptùë•ùë°subscriptùúÖùë†x_{t,\\kappa_{s}}italic_x start_POSTSUBSCRIPT italic_t , italic_Œ∫ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUBSCRIPTat each step while causally conditioning on previously denoised tokensx0,1:Œ∫s‚àí1subscriptùë•:01subscriptùúÖùë†1x_{0,1:\\kappa_{s-1}}italic_x start_POSTSUBSCRIPT 0 , 1 : italic_Œ∫ start_POSTSUBSCRIPT italic_s - 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT, and other contextual inputs. This approach enforces the model to reconstruct the image with partial observation, embodying the spirit of masked feature prediction models[24,67,35].",
                "position": 238
            }
        ]
    },
    {
        "header": "4Initial studies on CausalFusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x5.png",
                "caption": "(a)",
                "position": 346
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x5.png",
                "caption": "(a)",
                "position": 349
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x6.png",
                "caption": "(b)",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x7.png",
                "caption": "(c)",
                "position": 359
            }
        ]
    },
    {
        "header": "5Shaping task difficulties in CausalFusion",
        "images": []
    },
    {
        "header": "6Performance comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x8.png",
                "caption": "(a)Samples on Text-to-Image generation.",
                "position": 1234
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x8.png",
                "caption": "(a)Samples on Text-to-Image generation.",
                "position": 1237
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x9.png",
                "caption": "(b)Samples on Image Caption generation.",
                "position": 1243
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Appendix AGeneralized Causal Attention",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x10.png",
                "caption": "Figure 7:Generalized causal mask.In this case, the input sequence is organized to have 3 AR-stepsŒ∫1subscriptùúÖ1\\kappa_{1}italic_Œ∫ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,Œ∫2subscriptùúÖ2\\kappa_{2}italic_Œ∫ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, andŒ∫3subscriptùúÖ3\\kappa_{3}italic_Œ∫ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, containing 2, 2, and 3 tokens, respectively.ùê±0,Œ∫1subscriptùê±0subscriptùúÖ1\\mathbf{x}_{0,\\kappa_{1}}bold_x start_POSTSUBSCRIPT 0 , italic_Œ∫ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPTandùê±0,Œ∫2subscriptùê±0subscriptùúÖ2\\mathbf{x}_{0,\\kappa_{2}}bold_x start_POSTSUBSCRIPT 0 , italic_Œ∫ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPTare the clean tokens at the first two AR steps, whileùê±t,Œ∫1subscriptùê±ùë°subscriptùúÖ1\\mathbf{x}_{t,\\kappa_{1}}bold_x start_POSTSUBSCRIPT italic_t , italic_Œ∫ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT,ùê±t,Œ∫2subscriptùê±ùë°subscriptùúÖ2\\mathbf{x}_{t,\\kappa_{2}}bold_x start_POSTSUBSCRIPT italic_t , italic_Œ∫ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT, andùê±t,Œ∫3subscriptùê±ùë°subscriptùúÖ3\\mathbf{x}_{t,\\kappa_{3}}bold_x start_POSTSUBSCRIPT italic_t , italic_Œ∫ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPTare noised tokens. White and gray blocks denote the masked and unmasked attention, respectively. Note that, eachùê±t,Œ∫ssubscriptùê±ùë°subscriptùúÖùë†\\mathbf{x}_{t,\\kappa_{s}}bold_x start_POSTSUBSCRIPT italic_t , italic_Œ∫ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUBSCRIPTonly attends to itself and the clean tokens from previous AR stepsùê±0,Œ∫1:s‚àí1subscriptùê±0subscriptùúÖ:1ùë†1\\mathbf{x}_{0,\\kappa_{1:s-1}}bold_x start_POSTSUBSCRIPT 0 , italic_Œ∫ start_POSTSUBSCRIPT 1 : italic_s - 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT.",
                "position": 1389
            }
        ]
    },
    {
        "header": "Appendix BMore Analyses",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Samples",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12095/x11.png",
                "caption": "Figure 8:Zero-shot editing samples.CausalFusion-XL, resolution 512√ó\\times√ó512, 800 epoch, Classifier-free guidance scale = 3.0.",
                "position": 2101
            },
            {
                "img": "https://arxiv.org/html/2412.12095/x12.png",
                "caption": "Figure 9:Zero-shot editing samples.CausalFusion-XL, resolution 256√ó\\times√ó256, 800 epoch, Classifier-free guidance scale = 1.5.",
                "position": 2104
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_360_cfg4.0.jpg",
                "caption": "Figure 10:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúotter‚Äù (360)",
                "position": 2108
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_387_cfg4.0.jpg",
                "caption": "Figure 11:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúred panda‚Äù (387)",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_817_cfg4.0.jpg",
                "caption": "Figure 12:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúsports car‚Äù (817)",
                "position": 2118
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_972_cfg4.0.jpg",
                "caption": "Figure 13:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúcliff‚Äù (972)",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_279_cfg2.0.jpg",
                "caption": "Figure 14:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúarctic fox‚Äù (279)",
                "position": 2128
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_975_cfg2.0.jpg",
                "caption": "Figure 15:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúlakeshore‚Äù (975)",
                "position": 2133
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_89_cfg1.5.jpg",
                "caption": "Figure 16:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúsulphur-crested cockatoo‚Äù (89)",
                "position": 2138
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl512_974_cfg1.5.jpg",
                "caption": "Figure 17:Uncurated512√ó512512512512\\times 512512 √ó 512CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúgeyser‚Äù (974)",
                "position": 2143
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_88_cfg4.0.jpg",
                "caption": "Figure 18:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúmacaw‚Äù (88)",
                "position": 2148
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_980_cfg4.0.jpg",
                "caption": "Figure 19:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 4.0Class label = ‚Äúvolcano‚Äù (980)",
                "position": 2153
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_388_cfg2.0.jpg",
                "caption": "Figure 20:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 2.0Class label = ‚Äúgiant panda‚Äù (388)",
                "position": 2158
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_979_cfg2.0.jpg",
                "caption": "Figure 21:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 2.0Class label = ‚Äúvalley‚Äù (979)",
                "position": 2163
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_928_cfg1.5.jpg",
                "caption": "Figure 22:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 1.5Class label = ‚Äúice cream‚Äù (928)",
                "position": 2168
            },
            {
                "img": "https://arxiv.org/html/2412.12095/extracted/6070175/figs/xl256_973_cfg1.5.jpg",
                "caption": "Figure 23:Uncurated256√ó256256256256\\times 256256 √ó 256CausalFusion-XL samples.Classifier-free guidance scale = 1.5Class label = ‚Äúcoral reef‚Äù (973)",
                "position": 2173
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]