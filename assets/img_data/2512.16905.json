[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16905/figures/logo.png",
                "caption": "",
                "position": 43
            },
            {
                "img": "https://arxiv.org/html/2512.16905/x1.png",
                "caption": "",
                "position": 76
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16905/x2.png",
                "caption": "Figure 2:Overall pipeline of Alchemist.In the initial data rating stage (a), the rater predicts a classification score for each image based on gradient extracted from a T2I proxy model.\nThe rater and the proxy model are jointly optimized through weighted loss and total loss.\nIn the data pruning stage (b), we introduce the Shift-Gsample strategy to efficiently retain informative samples while filtering out redundant data and outliers.\nThe resulting Alchemist-selected dataset enables highly efficient training of downstream text-to-image models.",
                "position": 164
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16905/x3.png",
                "caption": "Figure 3:Loss and gradient norm across different rating score ranges.For each training sample, we record its instantaneous loss and gradient norm\nat each training step during STAR-0.3B training.\nWe track the evolution of loss and gradient norm over epochs.",
                "position": 339
            },
            {
                "img": "https://arxiv.org/html/2512.16905/x4.png",
                "caption": "Figure 4:Representative examples of data distribution across score regions.The head region mainly containsplainsamples, the middle-to-late region containsinformativesamples, and the tail region containschaoticsamples.\nAlchemist-selected data aligns with human intuition, filtering out most plain and chaotic samples.",
                "position": 347
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16905/x5.png",
                "caption": "Figure 5:Image distribution of Alchemist-selected LAION data subsets.Samples are sorted from high to low scores.\nThe early portion mainly contains images with white or plain backgrounds,\nthe middle portion is more informative and content-rich,\nand the tail portion gradually becomes noisier, containing unclear content, multiple objects, or visually dense regions.",
                "position": 405
            },
            {
                "img": "https://arxiv.org/html/2512.16905/x6.png",
                "caption": "Figure 6:Performance of models trained on 6M and 15M data vs training time. Evaluations are conducted on MJHQ-30K benchmark.",
                "position": 816
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    }
]