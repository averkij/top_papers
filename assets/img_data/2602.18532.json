[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18532/x1.png",
                "caption": "Figure 1:Performance comparison on the LIBERO and LIBERO-plus benchmarks. We compare VLANeXt with representative VLA baselines across model scales. Despite its smaller model size, VLANeXt achieves higher success rates than prior methods on both standard task performance (LIBERO) and robustness/generalization (LIBERO-plus), demonstrating the effectiveness of the design recipe distilled in this work.",
                "position": 102
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x2.png",
                "caption": "Figure 2:Ablation trajectory across the VLA design space (spatial suite). We progressively evolve a baseline VLA through changes in foundational components, perception, and action modeling. Results are reported on LIBERO initially, and on LIBERO-plus once LIBERO performance saturates, providing a more sensitive test of robustness and generalization. The trajectory culminates in the final VLANeXt model (2.5B) vs. OpenVLA-OFT (7B).",
                "position": 115
            }
        ]
    },
    {
        "header": "2Recipes for Building Strong VLA Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18532/x3.png",
                "caption": "Figure 3:Design choices for the policy module.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x4.png",
                "caption": "Figure 4:Design choices for the VLM-Policy connection.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x5.png",
                "caption": "Figure 5:Design choices for proprioception conditioning.",
                "position": 669
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x6.png",
                "caption": "Figure 6:Augmenting action prediction with an auxiliary world modeling objective.",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x7.png",
                "caption": "Figure 7:VLANeXt architecture. Multi-view visual inputs, language instructions, and proprioception are tokenized and processed by a multimodal LLM, with meta queries enabling soft interaction with the policy module. Action chunks are predicted using flow matching and further regularized by a frequency-domain objective.",
                "position": 736
            }
        ]
    },
    {
        "header": "3Benchmarks Evaluations",
        "images": []
    },
    {
        "header": "4Real-World Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18532/x8.png",
                "caption": "Figure 8:Our single-arm and bimanual arm tasks for the real-world experiments.",
                "position": 1162
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18532/x9.png",
                "caption": "Figure 9:Qualitative experiments of our method in real-world tasks.",
                "position": 2352
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x10.png",
                "caption": "Figure 10:Qualitative experiments of our method in the four suites of the LIBERO benchmark.",
                "position": 2358
            },
            {
                "img": "https://arxiv.org/html/2602.18532/x11.png",
                "caption": "Figure 11:Qualitative experiments of our method in the 7 types of perturbations in the same task in the LIBERO-plus benchmark.",
                "position": 2365
            }
        ]
    },
    {
        "header": "Appendix BDetailed Experimental Settings",
        "images": []
    },
    {
        "header": "Appendix CRevisiting Robot Learning and VLA Models",
        "images": []
    }
]