[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3video-SALMONN-o1",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x1.png",
                "caption": "Figure 1:video-SALMONN-o1 model structure. The input video is processed by the visual and audio branches, generating encodings from the visual and audio frame sequences respectively. Two encoding streams are combined in an interleaved fashion to synchronize across time before sending to LLM.",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x2.png",
                "caption": "Figure 2:Acquisition pipeline of reasoning-intensive SFT data. The question, answer and reasoning paths are generated by Gemini-1.5-pro taking the video with paired audio as inputs. GPT4o is employed for quality checks to ensure the QA-pair and the reasoning steps are valid and require logical thinking.",
                "position": 219
            }
        ]
    },
    {
        "header": "4Training to Enhance Reasoning Abilities",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x3.png",
                "caption": "Figure 3:Illustration of the contrastive step selection (top) and pairwise rollout (bottom) to construct per-step expected correctness score for pDPO. Contrastive step selection: Top 2 steps,s2subscriptùë†2s_{2}italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTands5subscriptùë†5s_{5}italic_s start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPTare selected in this example, and fors2subscriptùë†2s_{2}italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, an alternative step,s2‚Ä≤subscriptsuperscriptùë†‚Ä≤2s^{\\prime}_{2}italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, is sampled to form the preference pair. Pairwise rollout: Three rollouts are shown for each step ands2subscriptùë†2s_{2}italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTands2‚Ä≤subscriptsuperscriptùë†‚Ä≤2s^{\\prime}_{2}italic_s start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTare step pairs with the same prefix solution. The answer correctness is checked using GPT-4o by comparing it against the reference answer.",
                "position": 230
            }
        ]
    },
    {
        "header": "5Audio-visual Reasoning Benchmark",
        "images": []
    },
    {
        "header": "6Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x4.png",
                "caption": "Figure 4:Distributions of the numbers of reasoning steps in SFT data. Left: Distribution of the entire SFT data. Right: Distribution on the reasoning-intensive subset of SFT data. Due to the difficulty of the reasoning-intensive subset, more reasoning steps are required in general for samples in this set.",
                "position": 403
            }
        ]
    },
    {
        "header": "7Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x5.png",
                "caption": "Figure 5:Comparison between different top T steps selected for pDPO. Pairs of full solution paths are always used in addition to pairs of intermediate steps.",
                "position": 745
            }
        ]
    },
    {
        "header": "8Conclusions",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AReasoning SFT Data Example",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x6.png",
                "caption": "Figure 6:Example of reasoning SFT data",
                "position": 1657
            }
        ]
    },
    {
        "header": "Appendix BStandUp Data Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x7.png",
                "caption": "Figure 7:Example of StandUp part of the RivaBench.",
                "position": 1667
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x8.png",
                "caption": "Figure 8:Example of StandUp part of the RivaBench.",
                "position": 1670
            }
        ]
    },
    {
        "header": "Appendix CAcademic Data Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x9.png",
                "caption": "Figure 9:Example of Academic part of the RivaBench.",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x10.png",
                "caption": "Figure 10:Example of Academic part of the RivaBench.",
                "position": 1684
            }
        ]
    },
    {
        "header": "Appendix DSynthetic Video Detection Data Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x11.png",
                "caption": "Figure 11:Example video clip of the SynthDec part of RivaBench.",
                "position": 1694
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x12.png",
                "caption": "Figure 12:Example video clip of the SynthDec part of RivaBench.",
                "position": 1697
            }
        ]
    },
    {
        "header": "Appendix EPrompt Templates",
        "images": []
    },
    {
        "header": "Appendix FCase Studies: Solution with Reasoning Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x13.png",
                "caption": "Figure 13:Example video and solutions from the StandUp test set.",
                "position": 1792
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x14.png",
                "caption": "Figure 14:Example video and solutions from videoMME test set.",
                "position": 1795
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x15.png",
                "caption": "Figure 15:Example video and solutions from videoMME test set.",
                "position": 1798
            }
        ]
    },
    {
        "header": "Appendix GCase Studies: Zero-shot Synthetic Video Detection",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11775/x16.png",
                "caption": "Figure 16:Example output from video-SALMONN-o1, GPT-4o and Gemini-1.5-pro for synthetic video detection.",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x17.png",
                "caption": "Figure 17:Example output from video-SALMONN-o1, GPT-4o and Gemini-1.5-pro for synthetic video detection.",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2502.11775/x18.png",
                "caption": "Figure 18:Example of the contrastive step selection process where two sampled paths are shown and the scoresdsksubscriptùëësubscriptùë†ùëòd_{s_{k}}italic_d start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPTare given for each reasoning steps. The 3rd step in the first solution is wrong due to visual hallucination, and as a result, a very high score is assigned to that step and that step will be used to perform rollout.",
                "position": 1816
            }
        ]
    },
    {
        "header": "Appendix HExamples of Contrastive Step Selection Process",
        "images": []
    }
]