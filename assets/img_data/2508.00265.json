[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00265/x1.png",
                "caption": "Figure 1:Multimodal Referring Segmentation.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2508.00265/x2.png",
                "caption": "Figure 2:Overview of this survey.Different colors represent specific sections. Best viewed in color.",
                "position": 154
            }
        ]
    },
    {
        "header": "2Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00265/x3.png",
                "caption": "Figure 5:Classic Referring Expression\nSegmentation (RES) and Comprehension (REC) handle expressions that refer to a single target object, as shown in example (1). In contrast, Generalized Referring Expression\nSegmentation (GRES)[2]and Comprehension (GREC)[30,31]support expressions referring to any number of target objects, including multi-target expressions like (2) and (3), as well as no-target expressions such as (4), thereby enhancing their applicability in complex and diverse real-world scenarios.",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2508.00265/x4.png",
                "caption": "Figure 6:Examples from 17 commonly used referring segmentation datasets, including image, video, and 3D scene data.",
                "position": 722
            }
        ]
    },
    {
        "header": "3Meta Architecture",
        "images": []
    },
    {
        "header": "4Referring Expression Segmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00265/x5.png",
                "caption": "Figure 7:Architecture Overview of Referring Expression Segmentation.(a)Two-stage methoduses an off-the-shelf instance segmentation model to generate region proposals, followed by vision-language feature matching and ranking to select the top-1 mask.\n(b)One-stage methodfuses image and text features, performing pixel-level segmentation directly on the fused features.",
                "position": 901
            }
        ]
    },
    {
        "header": "5Referring Video Object Segmentation",
        "images": []
    },
    {
        "header": "6Referring Audio-Visual Segmentation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00265/x6.png",
                "caption": "Figure 8:Comparison of different audio-visual segmentation tasks.",
                "position": 1228
            }
        ]
    },
    {
        "header": "73D Referring Expression Segmentation",
        "images": []
    },
    {
        "header": "8Generalized Referring Expression",
        "images": []
    },
    {
        "header": "9Related Tasks and Applications",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00265/x7.png",
                "caption": "Figure 9:Illustration of Several Applications.",
                "position": 1335
            }
        ]
    },
    {
        "header": "10Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Appendix: Performance Comparison",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]