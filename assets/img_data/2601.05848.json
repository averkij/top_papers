[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05848/figures/mini-teaser-v3.png",
                "caption": "Figure 1:Given a force-conditioned task,goal forceenables video models to generate the antecedent action to accomplish the task.",
                "position": 79
            },
            {
                "img": "https://arxiv.org/html/2601.05848/x1.png",
                "caption": "Figure 2:Goal Force: A user provides an input image and agoal force, and the model generates a video containing a force that locally causes the goal force.\nOur model generalizes to diverse objects and interactions and enables visual planning, respecting the physical properties of the objects and their environments.",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05848/x2.png",
                "caption": "Figure 3:Force prompt and goal force prompt result in different behaviors.With adirect forceapplied to the red block (top), the effect is directly materialized (i.e. the block falls over).\nThe force in this case is encoded in the red channel of the control signal as a moving Gaussian blob.\nIn contrast, with agoal forceapplied to the red block (bottom), the model must find the antecedent motion to achieve the goal force (i.e. the pendulum swings to knock over the block).\nThe force in this case is encoded in the green channel of the control signal as a moving Gaussian blob.\nWe visualize the control signal overlaid on top of the video via alpha blending.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method: Prompting with Goal Force",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05848/x3.png",
                "caption": "Figure 4:In prior methods (right), the user provides a force, and the model directly applies the force to the target object.\nIn our method (left), the user provides a goal force, and the model generates the causes that achieve the desired effect on the target object.\nThe top three methods (PhysGen[38], PhysDreamer[66], and Force Prompting[17]) all accept forces as conditioning; the fourth method, Tora[67], accepts trajectories rather than forces, so we condition on an acceptable trajectory.",
                "position": 191
            }
        ]
    },
    {
        "header": "4Experimental Comparisons",
        "images": []
    },
    {
        "header": "5Goal Force Enables Visual Planning",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05848/x4.png",
                "caption": "Figure 5:Given a goal force prompt, the model chooses the physically correct way to execute it.Top: even though there exist multiple plausible initiators, the model correctly selects the white ball as the initiator to achieve the desired force on the target.\nBottom: With multiple plausible rubber ducks that could initiate the force, the model selects the initiator that is not blocked by a physical barrier.",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2601.05848/x5.png",
                "caption": "Figure 6:Visual plans take advantage of mass information.We test goal force prompting on in-distribution (left) and out-of-distribution (right) scenarios. In both scenarios, our model can adjust the moving speed of the projectile accordingly when the object masses are changed to cause the desired force magnitude. The direction of the “<<” sign indicates the desired numerical relationship;greenindicates satisfaction,redindicates violation.",
                "position": 567
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Experiment Details",
        "images": []
    }
]