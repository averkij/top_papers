[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02268/x1.png",
                "caption": "",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02268/x2.png",
                "caption": "Figure 2:Overview of the LLM-based GUI agent baseline.At each step, the agent captures the current screen of the device and analyzes the interface to select an appropriate action from the predefined action space. The chosen action is then executed to interact with the GUI.",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2503.02268/x3.png",
                "caption": "Figure 3:Overview of the proposed framework.(a) The trajectory of a task execution is decomposed into multiple overlapping triples. Based on these triples, the LLM generates functional descriptions of both pages and UI elements. Descriptions of pages that are repeatedly generated are then merged. The entire interaction history is recorded using a chain of nodes. (b) The proposed evolutionary mechanism and execution process. The evolutionary mechanism generates shortcut nodes, which allow the agent to execute a series of actions efficiently without reasoning step by step. (c) An example of the content of nodes within the chain. Each node records essential information, including descriptions of pages, UI elements, and high-level actions, to facilitate understanding of the agentâ€™s interactions.",
                "position": 213
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02268/x4.png",
                "caption": "Figure 4:Task Completion Times Across Different Task Lengths.This figure shows the distribution of task completion times for short, medium, and long tasks. Each violin plot represents the density of completion times, with wider sections indicating higher data concentration. AppAgentX consistently outperforms the baseline, particularly for longer tasks.",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2503.02268/x5.png",
                "caption": "Figure 5:Qualitative Task Evaluation.This figure presents the qualitative results of path execution utilizing shortcuts on different applications (Gmail and Apple Music). It demonstrates the efficiency of AppAgentX in decreasing the utilization of LLM for per-step reasoning.",
                "position": 625
            },
            {
                "img": "https://arxiv.org/html/2503.02268/x6.png",
                "caption": "",
                "position": 629
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02268/x7.png",
                "caption": "Figure 6:Overall Execution Process.This figure illustrates the flowchart from the input of the task to the final execution result after we then add the shortcut route.",
                "position": 1257
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]