[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04827/x1.png",
                "caption": "",
                "position": 80
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04827/x2.png",
                "caption": "Figure 2:We compare the results of our MultiConDiffusion process against MultiDiffusion and progressive inpainting. The green bar shows the location of the input image.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2412.04827/x3.png",
                "caption": "Figure 3:We show the results of MultiConDiffusion during different iterations of the optimization.",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2412.04827/x4.png",
                "caption": "Figure 4:We compare the result of our method, PanoDepthFusion, against applying Depth Anything V2 (DA V2)[32]on the full image. The results obtained by DA V2 lacks details and is geometrically inconsistent. Our approach, on the other hand, produces highly detailed and consistent depth maps.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2412.04827/x5.png",
                "caption": "Figure 5:On the top left, we show the result of averaging the patch depth estimates. As seen, since the depth maps are relative, the depth from different patches are not consistent, producing results with clear edges. Since we initializeGŒ∏isubscriptùê∫subscriptùúÉùëñG_{\\theta_{i}}italic_G start_POSTSUBSCRIPT italic_Œ∏ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPTwith identity line, patchwise average results are indeed our initial depth estimate during the optimization of Eq.7. We also show our results after one, two, and four iterations of optimization. After only four iterations, the seems disappear.",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2412.04827/x6.png",
                "caption": "Figure 6:We compare the panoramas generated by MultiConDiffusion with those from other methods. Other approaches often result in sharp discontinuities and contextual inconsistencies. For instance, in the top example, the MultiDiffusion result shows a mismatch between the generated sky and the input sky.",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2412.04827/x7.png",
                "caption": "Figure 7:We show the results of our approach on the same input image across multiple runs. As shown, our approach produces diverse yet consistent results.",
                "position": 368
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04827/x8.png",
                "caption": "Figure 8:We compare renderings of PanoDreamer with LucidDreamer[3]and WonderJourney[36]. The input image and camera are at the leftmost column. For each methods, we render 3D scene from two novel views (orange and green cameras). As is shown in the figure, LucidDreamer and WonderJourney results are inconsistent, suffering severe seam-artifacts for novel views. In comparison, PanoDreamer is capable of generating coherent renderings from novel views. For more visual results and video comparison, please refer to our supplementary materials.",
                "position": 509
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]