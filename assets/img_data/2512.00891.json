[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00891/x1.png",
                "caption": "Figure 1:Inference time breakdown across components in various vision-language understanding scenarios.ViT encoding typically accounts for a substantial fraction of the inference time in video understanding, about2-3 timesthat in image understanding.",
                "position": 89
            },
            {
                "img": "https://arxiv.org/html/2512.00891/x2.png",
                "caption": "Figure 2:Temporal redundancy in adjacent frames in ViT encoding.Streaming videos (“online”) tend to show higher similarity than offline videos, indicating higher temporal redundancy.",
                "position": 99
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00891/x3.png",
                "caption": "Figure 3:Overview of Streaming Token Compression (STC).Our framework accelerates streaming Video-LLMs in two stages.STC-Cacheremploys selective recomputation to reduce computational redundancy in the ViT.STC-Prunerthen reduces the token sequence to alleviate the prefilling latency for the LLM.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2512.00891/x4.png",
                "caption": "Figure 4:Visualization of cache-aware selective computation by STC-Cacher.For reference frames, STC-Cacher computes and caches all tokens. For subsequent frames, only dynamic tokens are computed, while static tokens reuse cached features from reference frames.",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2512.00891/x5.png",
                "caption": "Figure 5:The Mechanism of STC-Cacher.Instead of a full forward pass, STC-Cacher identifies novel tokens by comparing their Key projections (KcurrK_{\\text{curr}}) to a cached reference (KrefK_{\\text{ref}}). It then selectively recomputes only the Query and Value representations for these dynamic tokens andscattersValue into the cached Value matrix for an efficient, low-rank update attention mechanism.",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2512.00891/x6.png",
                "caption": "Figure 6:The Mechanism of STC-Pruner.To accelerate LLM prefilling, STC-Pruner scores each token based on its novelty. Novelty is measured as the joint dissimilarity to aTemporal Context Anchor(TCA), representing historical context, and aSpatial Context Anchor(SCA), representing the current frame’s global context. Only tokens with high novelty scores are retained.",
                "position": 290
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00891/x7.png",
                "caption": "Figure 7:Effects of Different Token Evaluation Strategies in STC-Cacher.(i)Compares various features for dynamic token evaluation to identify the optimal dynamic token set for feature caching and reuse.(ii)Further compares different metrics for token dynamics evaluation, with \"Cos Sim\" referring to cosine similarity (smaller values indicate higher dynamics), \"L1\" and \"L2\" representing L1 and L2 distances (smaller values indicate higher dynamics), and \"DP\" denoting the dot product (smaller values indicate higher dynamics), respectively. The yellow line represents the average performance gap with ToMe[3], indicating that STC-Cacher significantly outperforms ToMe.",
                "position": 1044
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experiment Settings",
        "images": []
    },
    {
        "header": "Appendix BAdditional Ablation Studies",
        "images": []
    },
    {
        "header": "Appendix CAlgorithm Pseudocode",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00891/x8.png",
                "caption": "Figure 8:More visualization of cache-aware selective computation by STC-Cacher.",
                "position": 2286
            }
        ]
    },
    {
        "header": "Appendix DMore Visualizations by STC-Cacher",
        "images": []
    }
]