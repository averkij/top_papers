[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14980/x1.png",
                "caption": "Figure 1:The task of compositional machine design is illustrated in ourBesiegeFieldenvironment. The figure shows a high-level sketch of the agentic workflow (w/ Gemini Pro 2.5), along with the resulting machines and their simulated performance. The design objective is to create a machine that throws boulders long distances.",
                "position": 145
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x2.png",
                "caption": "Figure 2:Demonstration of the machine design tasks in our experiments. (Left:car; Right:catapult).",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x3.png",
                "caption": "Figure 3:Demonstration of the default XML representation and our construction tree representation. Parent block info is in blue and child info is in red.",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x4.png",
                "caption": "Figure 4:Example CoT of inspector agents (w/ Gemini 2.5 Pro). Blue text highlights the moderate capability of LLMs in spatial reasoning and imagined physical simulation.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x5.png",
                "caption": "Figure 5:Example CoT of inspector agents (w/ OpenAI o3). Red text highlights reasoning errors.",
                "position": 276
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x6.png",
                "caption": "Figure 6:Our agentic machine design workflow.",
                "position": 289
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x7.png",
                "caption": "Figure 7:Machines produced by agentic systems with different LLMs (Top:car; Bottom:catapult).",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x8.png",
                "caption": "Figure 8:Designs at RL finetuning stages.",
                "position": 1380
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/game_editor_view.png",
                "caption": "Figure 9:Besiege editor view.",
                "position": 4556
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/block_stats.png",
                "caption": "Figure 10:Common useful blocks in constructing standard machines inBesiegeField.",
                "position": 4559
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/movement_rocky.png",
                "caption": "Figure 11:Illustration of the taskcar/movementon a rocky terrain, a more difficult setting compared to the environment used for thecartask in our experiments.",
                "position": 4815
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/throw.png",
                "caption": "Figure 12:Illustration of the taskcatapult/throw.",
                "position": 4818
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/pick.png",
                "caption": "Figure 13:Illustration of the taskpick.",
                "position": 4821
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/delivery.png",
                "caption": "Figure 14:Illustration of the taskdeliverywith a bump on the track.",
                "position": 4824
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/thru_ring.png",
                "caption": "Figure 15:Illustration of the taskcatapult/Throwwith the objective of throwing the boulder through the target ring.",
                "position": 4827
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/tasks/curved_track.png",
                "caption": "Figure 16:Illustration of the taskcar/movementwith a curved track.",
                "position": 4830
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/search_strategy.png",
                "caption": "Figure 17:The variation in machine average scores with the increasing number of LLM node expansion operations under different search strategies.",
                "position": 5526
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x9.png",
                "caption": "Figure 18:Examples to illustrate failure patterns. In each example, the original machine is shown on the left and the modified machine on the right. Failure patterns are sampled from Qwen3-Coder-480B-A35B-Instruct.",
                "position": 5703
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x10.png",
                "caption": "Figure 19:Illustration of how machines built with feasible high-level designs may fail due to inaccurate part placement. Machine sampled from Gemini 2.5 Pro. Left: designed machines; Right: simulation results.",
                "position": 5713
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x11.png",
                "caption": "Figure 20:Boulder-throwing trajectories for various machine designs generated by Gemini 2.5 Pro. From left to right, each row first shows the machine design, followed by a time-lapsed bird’s-eye view of its throw.",
                "position": 5723
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x12.png",
                "caption": "Figure 21:Examples of Gemini-synthesized machines.",
                "position": 5778
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x13.png",
                "caption": "Figure 22:Construction guidance comparison ofMeta DesignerandDetailed Meta Designer, sampled with Gemini 2.5 Pro.",
                "position": 6535
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Catapult/score_max.png",
                "caption": "Figure 23:Catapulttask machine scores across RL steps. KL regularization helps the model discover better structure designs. Pass@64 is greatly more efficient at uncovering powerful machine designs. Pass@8 (roll-out 8) outperforms Pass@1 (roll-out 64) in efficiency and matches its performance with fewer roll-outs. No cold start models lack the advanced knowledge needed to find better machines.",
                "position": 7198
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Car/score_max.png",
                "caption": "Figure 24:Carmachine scores across RL steps. The RL finetuning hyperparameter setting is the same as the base hyperparameter setting ofCatapult. Machine performance slightly rises as training steps increase.",
                "position": 7201
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Catapult/MachineValid_Reward.png",
                "caption": "Figure 25:Catapult taskmachine validity rate and reward non-zero rate across RL steps. The machine validity rate refers to the proportion of machines that can successfully run simulations. The reward non-zero rate represents the ratio of machines that can simulate with a non-zero reward. LLM constructs more legal machines as training steps increase, and rewards non-zero machines. Pass@8 and Pass@1 converge early. “No KL” fills roll-outs with failure cases, slowing performance gains. “No cold start” lacks design knowledge, encounters more failures than no KL, and improves validity rate most slowly. The base setting balances convergence and performance improvement.",
                "position": 7204
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Car/MachineValid_Reward.png",
                "caption": "Figure 26:Car taskmachine validity rate and reward non-zero rate across RL steps. The machine validity converges early and remains stable during further training.",
                "position": 7207
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Catapult/Val_Best.png",
                "caption": "Figure 27:Catapult task. Average Best@N metric. At each test step, the LLM generates 64 samples, selects the topNNsamples, and records the maximum score. This process is repeated 1,000 times, and the mean value is calculated. Base settings (both seeds) dominates Best@N performance; excluding base settings, “no KL” dominates the rest. Pass@1 and Pass@8 spawn only a handful of high-performance machines. No cold start produces machines of more average quality.",
                "position": 7210
            },
            {
                "img": "https://arxiv.org/html/2510.14980/figures/RL_Metrics/Car/Val_Best.png",
                "caption": "Figure 28:Car task. Mean Best@N metrics. Similar to the machine validity rate, the Best@N performance increases quickly and remains stable in rest training periods.",
                "position": 7213
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x14.png",
                "caption": "Figure 29:Qwen2.5-14B-Instruct cold started RL modelcatapulttask sample from roll-out. Throwing distances are labeled on the bottom-right corner of the image.",
                "position": 7228
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x15.png",
                "caption": "Figure 30:The LLM inference gallery of machine-generated samples. The rows, from top to bottom, were inferred by the following models, respectively: Claude 4 Opus, Gemini 2.5 Pro, o3, Doubao Seed 1.6, and Qwen3-Coder-480B-A35B-Instruct. Throwing distances are labeled on the bottom-right corner of the image.",
                "position": 7236
            },
            {
                "img": "https://arxiv.org/html/2510.14980/x16.png",
                "caption": "Figure 31:Comparison between generated machines conditioned on their own CoT or Gemini-generated CoT.",
                "position": 7251
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]