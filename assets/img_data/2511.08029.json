[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08029/x1.png",
                "caption": "Figure 1:Our four-stage data generation and training pipeline.Stage 1:A query is synthetically generated from a positive documentâ€™s abstract using a T5 model.Stage 2:A 2-hop citation neighborhood is constructed by retrieving papers cited by the positive document (1-hop) and papers cited by them (2-hop) via the PubMed API.Stage 3:Hard negatives are mined via semantic graph traversal. First, similarities are computed between the query and 1-hop documents. Second, a dense, pairwise similarity graph is built for all 1-hop and 2-hop documents. Third, a 5-step greedy traversal is initiated from the 1-hop document most similar to the query, creating a path of five hard negatives.Stage 4:The resulting (Query, Positive Document, Hard Negatives) triplet is used to fine-tune the GTE model using the multiple negative ranking loss.",
                "position": 93
            }
        ]
    },
    {
        "header": "Introduction",
        "images": []
    },
    {
        "header": "Related Work",
        "images": []
    },
    {
        "header": "Methodology",
        "images": []
    },
    {
        "header": "Experiments",
        "images": []
    },
    {
        "header": "Evaluation",
        "images": []
    },
    {
        "header": "Effect of Traversal Parameters",
        "images": []
    },
    {
        "header": "Robustness and Scalability",
        "images": []
    },
    {
        "header": "Performance of Different Architectures",
        "images": []
    },
    {
        "header": "Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Appendix AImprovement over GTE Models",
        "images": []
    },
    {
        "header": "Appendix BData Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.08029/semantic_distribution_plot.png",
                "caption": "(a)Embedding distributions of the entire corpus (yellow) vs the selected 20,000 documents (blue) to build our training corpus.",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2511.08029/semantic_distribution_plot.png",
                "caption": "(a)Embedding distributions of the entire corpus (yellow) vs the selected 20,000 documents (blue) to build our training corpus.",
                "position": 1649
            },
            {
                "img": "https://arxiv.org/html/2511.08029/x2.png",
                "caption": "(b)nDCG@10 scores on the validation set using an 80%/20% split of the constructed corpus. Evaluation is done every 10 steps, with peak performance observed at step 20 selected for full fine-tuning on the entire corpus followed by zero-shot evaluation on BEIR.",
                "position": 1655
            }
        ]
    },
    {
        "header": "Appendix CChoice of fine tuning steps",
        "images": []
    },
    {
        "header": "Appendix DDataset Details",
        "images": []
    }
]