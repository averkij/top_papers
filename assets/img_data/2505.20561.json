[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20561/x1.png",
                "caption": "Figure 1:An example of reflective reasoning.",
                "position": 294
            }
        ]
    },
    {
        "header": "4The Necessity of Bayes-Adaptive RL for Reflective Reasoning",
        "images": []
    },
    {
        "header": "5Method",
        "images": []
    },
    {
        "header": "6How Bayes-Adaptive RL Helps Generalization: A Didactic Example",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20561/x2.png",
                "caption": "Figure 2:Setup: repeating the prompt token (orange) three times receives a1111reward.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x3.png",
                "caption": "Figure 3:Illustration of the difference between Markovian RL and BARL in this didactic example.",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x4.png",
                "caption": "Figure 4:(Left)Markovian RL (REINFORCE) memories training solutions and poorly generalizes.(Middle)BARL generalizes well at test time and(Right)improves with more informative candidate sets that strike a better balance betweendiversityandplausibility.",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x5.png",
                "caption": "",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x6.png",
                "caption": "",
                "position": 593
            }
        ]
    },
    {
        "header": "7Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20561/x7.png",
                "caption": "Figure 5:BARL is more token efficient, achieving higher accuracies with fewer total numbers of tokens.",
                "position": 741
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x8.png",
                "caption": "",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x9.png",
                "caption": "",
                "position": 755
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x10.png",
                "caption": "",
                "position": 760
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x11.png",
                "caption": "Figure 6:Results on GSM8K (dashed) and MATH (solid).",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x12.png",
                "caption": "Figure 7:Ablation on how effective the CoTs explore and exploit, measured by the Bayesian values.",
                "position": 788
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x13.png",
                "caption": "",
                "position": 797
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x14.png",
                "caption": "",
                "position": 802
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x15.png",
                "caption": "",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x16.png",
                "caption": "Figure 8:(Left)Training accuracy.(Middle)Training response length.(Right)Final evaluation results.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x17.png",
                "caption": "",
                "position": 832
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x18.png",
                "caption": "",
                "position": 837
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof of Theorem4.2",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20561/x19.png",
                "caption": "Figure 9:Average evaluation accuracies over training iterations for Qwen2.5-Math-1.5B models.",
                "position": 1723
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x20.png",
                "caption": "",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x21.png",
                "caption": "",
                "position": 1737
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x22.png",
                "caption": "",
                "position": 1743
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x23.png",
                "caption": "",
                "position": 1748
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x24.png",
                "caption": "",
                "position": 1753
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x25.png",
                "caption": "Figure 10:Average evaluation accuracies over training iterations for Qwen2.5-Math-7B models.",
                "position": 1759
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x26.png",
                "caption": "",
                "position": 1768
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x27.png",
                "caption": "",
                "position": 1773
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x28.png",
                "caption": "",
                "position": 1779
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x29.png",
                "caption": "",
                "position": 1784
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x30.png",
                "caption": "",
                "position": 1789
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x31.png",
                "caption": "Figure 11:Average evaluation accuracies over training iterations for R1-Distill-Llama-8B models.",
                "position": 1795
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x32.png",
                "caption": "",
                "position": 1804
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x33.png",
                "caption": "",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x34.png",
                "caption": "",
                "position": 1815
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x35.png",
                "caption": "",
                "position": 1820
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x36.png",
                "caption": "",
                "position": 1825
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x37.png",
                "caption": "Figure 12:Average evaluation response lengths over training iterations for Qwen2.5-Math-1.5B models.",
                "position": 1839
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x38.png",
                "caption": "",
                "position": 1848
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x39.png",
                "caption": "",
                "position": 1853
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x40.png",
                "caption": "",
                "position": 1859
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x41.png",
                "caption": "",
                "position": 1864
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x42.png",
                "caption": "",
                "position": 1869
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x43.png",
                "caption": "Figure 13:Average evaluation response lengths over training iterations for Qwen2.5-Math-7B models.",
                "position": 1875
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x44.png",
                "caption": "",
                "position": 1884
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x45.png",
                "caption": "",
                "position": 1889
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x46.png",
                "caption": "",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x47.png",
                "caption": "",
                "position": 1900
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x48.png",
                "caption": "",
                "position": 1905
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x49.png",
                "caption": "Figure 14:Average evaluation response lengths over training iterations for R1-Distill-Llama-8B models.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x50.png",
                "caption": "",
                "position": 1920
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x51.png",
                "caption": "",
                "position": 1925
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x52.png",
                "caption": "",
                "position": 1931
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x53.png",
                "caption": "",
                "position": 1936
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x54.png",
                "caption": "",
                "position": 1941
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x55.png",
                "caption": "Figure 15:Results of BARL fine-tuned on Llama-3.2-3B-Instruct.(Left)Training accuracy and(Middle)response length.(Right)Evaluation results.",
                "position": 1951
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x56.png",
                "caption": "",
                "position": 1960
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x57.png",
                "caption": "Figure 16:Ablation on token efficiency and pass@k accuracies with sampling temperature=1absent1=1= 1. GRPO and the base models are less robust to temperatures.",
                "position": 2012
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x58.png",
                "caption": "",
                "position": 2021
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x59.png",
                "caption": "",
                "position": 2026
            },
            {
                "img": "https://arxiv.org/html/2505.20561/x60.png",
                "caption": "",
                "position": 2031
            }
        ]
    },
    {
        "header": "Appendix BExperiment Details",
        "images": []
    }
]