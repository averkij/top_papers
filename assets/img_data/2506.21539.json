[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21539/extracted/6572069/figures/logo.png",
                "caption": "",
                "position": 87
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21539/x1.png",
                "caption": "Figure 1:(a) Action model generates actions based on image understanding; (b) World model generates the image based on image and action understanding; (c) Action World Model unifies both image and action understanding and generation.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21539/x2.png",
                "caption": "Figure 2:Overview of WorldVLA. WorldVLA integrates two distinct but complementary functional components: an action model and a world model. The action model is responsible for generating actions conditioned on both textual and visual data. The world model functions to predict the subsequent environmental state (e.g., the next visual frame) by leveraging textual information, current image, and current action.",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2506.21539/x3.png",
                "caption": "Figure 3:Attention mask mechanism of (a) default action model, (b) our proposed action model, and (c) world model.",
                "position": 310
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.21539/x4.png",
                "caption": "Figure 4:Visualization of action model. Top: action model. Bottom: our action world model.",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2506.21539/x5.png",
                "caption": "Figure 5:Visualization of world model. Top: world model. Bottom: our action world model.",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2506.21539/x6.png",
                "caption": "Figure 6:Ablation study of action chucking length.",
                "position": 795
            },
            {
                "img": "https://arxiv.org/html/2506.21539/x7.png",
                "caption": "Figure 7:Comparison between action world model and action video prediction model.",
                "position": 798
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]