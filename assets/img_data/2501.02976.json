[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02976/x1.png",
                "caption": "",
                "position": 113
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02976/x2.png",
                "caption": "Figure 2:Overview of the proposed¬†STAR.",
                "position": 163
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02976/x3.png",
                "caption": "Figure 3:Motivation of LIEM.Left:schematic diagram illustrating the impact of using only global structure versus a combination of local and global structures.Right:visual comparison on real-world and synthetic videos. (Zoom-in for best view)",
                "position": 201
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x4.png",
                "caption": "Figure 4:Motivation of DF Loss.Left: PSNR curves of low- and high-frequency components relative to ground truth across diffusion steps. The low-frequency PSNR increases during the early diffusion steps, while the high-frequency PSNR rises in the later diffusion steps.Right: visual results of low- and high-frequency components at different diffusion stage. (Zoom-in for best view)",
                "position": 204
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x5.png",
                "caption": "Figure 5:Dynamic Frequency Loss.Left: curves of weighting functionc‚Å¢(t)ùëêùë°c(t)italic_c ( italic_t )for differentŒ±ùõº\\alphaitalic_Œ±.Right: details of DF loss.",
                "position": 582
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02976/x6.png",
                "caption": "Figure 6:Qualitative comparisons on synthetic LR videos from OpenVid30 and REDS30[35].(Zoom-in for best view)",
                "position": 638
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x7.png",
                "caption": "Figure 7:Qualitative comparisons on real-world test videos in VideoLQ[11]dataset.(Zoom-in for best view)",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x8.png",
                "caption": "Figure 8:Qualitative comparisons on temporal consistency in REDS30[35]and OpenVid dataset.(Zoom-in for best view)",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x9.png",
                "caption": "Figure 9:Ablation study about LIEM.Left:illustration of different insertion positions of LIEM and the structure of LIEM.Right:visual comparison on real-world and synthetic videos with different LIEM positions.",
                "position": 740
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x10.png",
                "caption": "Figure 10:Illustration on scaling up with larger t2v models on a real-world low-quality video.(Zoom-in for best view)",
                "position": 908
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APerception-Distortion Trade-Off",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.02976/extracted/6113603/figure_of_supp/bt_ablation.png",
                "caption": "Figure 11:Ablation onb‚Å¢(t)ùëèùë°b(t)italic_b ( italic_t ). Higher hyper-parameterŒ≤ùõΩ\\betaitalic_Œ≤produces results with greater fidelity, while lowerŒ≤ùõΩ\\betaitalic_Œ≤emphasizes more perceptual quality.",
                "position": 1985
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x11.png",
                "caption": "Figure 12:User study results. Our STAR¬†is preferred by human evaluators for both visual quality and temporal consistency.",
                "position": 2071
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x12.png",
                "caption": "Figure 13:Qualitative comparisons on synthetic datasets. Our¬†STAR¬†generates more detailed and realistic results.(Zoom-in for best view)",
                "position": 2074
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x13.png",
                "caption": "Figure 14:Qualitative comparisons on real-world datasets. Our¬†STAR¬†produces the clearest facial details and the most accurate text structure.(Zoom-in for best view)",
                "position": 2077
            },
            {
                "img": "https://arxiv.org/html/2501.02976/x14.png",
                "caption": "Figure 15:Qualitative comparisons on synthetic and real-world datasets with larger T2V models. Scaling up the T2V model enhances detail and realism in video super-resolution results.(Zoom-in for best view)",
                "position": 2080
            }
        ]
    },
    {
        "header": "Appendix BMore Results",
        "images": []
    }
]