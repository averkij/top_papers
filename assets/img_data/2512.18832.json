[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.18832/figures/github_logo.png",
                "caption": "",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2512.18832/figures/main.png",
                "caption": "Figure 1:LLMs as text-based world models for agent learning.(A) We formulate world modeling as next-state prediction under a fixed text-based interaction protocol.\n(B) Assess world-model capability along three axes: fidelity/consistency, scalability/robustness, and agent utility.\n(C) World model exhibits high fidelity and consistency in both single-step predictions and long-horizon rollouts.\n(D) Performance scales predictably with increased training data across text environments.\n(E) Faithful world models enhance agents via verification, synthetic data generation, and improved reinforcement learning through stronger initialization.",
                "position": 185
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.18832/figures/idea-bulb.png",
                "caption": "",
                "position": 206
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3LLM as Text-based World Models",
        "images": []
    },
    {
        "header": "4World Model Training and Evaluation",
        "images": []
    },
    {
        "header": "5Fidelity & Consistency",
        "images": []
    },
    {
        "header": "6Scalability & Robustness",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.18832/x1.png",
                "caption": "Figure 2:Next-state prediction accuracy under varying training data sizes on Qwen2.5-7B. Structured settings saturate with modest data (~20K), whereas open-ended settings continue to benefit from larger datasets.Note.We apply a nonlinear y-axis transformf​(y)=100−20​log10⁡(max⁡(100−y,0.01)+1)f(y)=100-20\\log_{10}(\\max(100-y,0.01)+1)to better reveal growth trends.",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2512.18832/x2.png",
                "caption": "Figure 3:Next-state prediction accuracy on Qwen2.5 family. Smaller models (~1.5B) capture structured dynamics effectively, whereas more complex settings benefit markedly from increased model capacity.",
                "position": 983
            },
            {
                "img": "https://arxiv.org/html/2512.18832/x3.png",
                "caption": "Figure 4:Task success rate (%) in ALFWorld under different OOD settings. Success rate averaged over different agents, with full results provided in Table10of AppendixC. World models maintain strong performance even when layouts or room types change.",
                "position": 1006
            },
            {
                "img": "https://arxiv.org/html/2512.18832/x4.png",
                "caption": "Figure 5:Next-state prediction accuracy under mixed and separate training on Qwen2.5-7B, with 1K samples per environment. We begin by mixing structured environments (ALFWorld, SciWorld, TextWorld) and then progressively incorporate open-ended environments (WebShop, StableToolBench), yielding the Mix3, Mix4, and Mix5 settings.",
                "position": 1017
            }
        ]
    },
    {
        "header": "7Agent Utility",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.18832/x5.png",
                "caption": "Figure 6:Task success rate (%) of Qwen2.5-7B-Instruct SFT trained agents with different data synthesis strategies in SciWorld and WebShop.",
                "position": 1285
            },
            {
                "img": "https://arxiv.org/html/2512.18832/x5.png",
                "caption": "Figure 6:Task success rate (%) of Qwen2.5-7B-Instruct SFT trained agents with different data synthesis strategies in SciWorld and WebShop.",
                "position": 1287
            },
            {
                "img": "https://arxiv.org/html/2512.18832/x6.png",
                "caption": "Figure 7:Task success rate (%) of Qwen2.5-7B-Instruct RL trained agents with and without early experience in ALFWorld and SciWorld.",
                "position": 1291
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BTask Examples and Case Studies",
        "images": []
    },
    {
        "header": "Appendix CDetailed Results",
        "images": []
    },
    {
        "header": "Appendix DSystem Prompts for Agent Trajectory Collection",
        "images": []
    }
]