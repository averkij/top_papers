[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05862/x1.png",
                "caption": "Figure 1:Comparative overview ofmodel performanceon real-world long-context tasks andperformance gain per billion tokensamong different training methods. The bubble size indicates the relative training data volume.",
                "position": 164
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05862/x2.png",
                "caption": "Figure 2:Task format of our preliminary study, which requires models to predict the final answer by reasoning through multi-hop Supporting Facts and distinguishing from the Interference Facts. Simultaneously, the model should also resist the influence of Irreverent Documents and Low-Frequency Words. More details are shown in AppendixB.",
                "position": 228
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x3.png",
                "caption": "(a)Attention distribution reflected by FR score.",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x3.png",
                "caption": "(a)Attention distribution reflected by FR score.",
                "position": 275
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x4.png",
                "caption": "(b)Information flow reflected by average IG score.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x5.png",
                "caption": "Figure 4:Attention distributions before and after manual context denoising. After context denoising, attention scores on critical tokens boost×10\\times 10times, and show a reduction on irrelevant tokens.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x5.png",
                "caption": "Figure 4:Attention distributions before and after manual context denoising. After context denoising, attention scores on critical tokens boost×10\\times 10times, and show a reduction on irrelevant tokens.",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x6.png",
                "caption": "Figure 5:Relationship between attention IG score and L2-normalized embedding gradients on different types of tokens. It shows a proportional correlation.",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x7.png",
                "caption": "Figure 6:Our proposed CDT (context denoising training) method. It consists of two steps: (1) detecting critical tokens within the long context, and (2) utilizing the denoised context for further emphasizing training. Notably, CDT can be understood as anExpectation Maximization (EM)process, where the model detects noise based on information flow and improves the training by diminishing the noise, thereby enhancing the information flow.",
                "position": 345
            }
        ]
    },
    {
        "header": "4Context Denoising Training",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": []
    },
    {
        "header": "6Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05862/x8.png",
                "caption": "Figure 7:Comparison of critical token detection capability among different methods on our synthetic task. CDT achieves best performance.",
                "position": 962
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x8.png",
                "caption": "Figure 7:Comparison of critical token detection capability among different methods on our synthetic task. CDT achieves best performance.",
                "position": 965
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x9.png",
                "caption": "Figure 8:Impact of context denoising and comparison of the effect of learning rate on attention scores assigned to critical tokens in CDT.",
                "position": 970
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x10.png",
                "caption": "Figure 9:The performance improvement and training duration for every interval of 50 steps. With only a modest cost in training time, CDT significantly boosts the performance of LCM.",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x10.png",
                "caption": "Figure 9:The performance improvement and training duration for every interval of 50 steps. With only a modest cost in training time, CDT significantly boosts the performance of LCM.",
                "position": 999
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x11.png",
                "caption": "Figure 10:Illustration ofEMprocess of our CDT method, where both the information flow and attention distribution progressively improve within the training steps.",
                "position": 1004
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AIllustration of Training Efficiency of Current Methods",
        "images": []
    },
    {
        "header": "Appendix BPreliminary Study Details",
        "images": []
    },
    {
        "header": "Appendix CDerivation of Relation between Information Flow and Embedding Gradients",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    },
    {
        "header": "Appendix EMore Evaluation Results",
        "images": []
    },
    {
        "header": "Appendix FAnalysis of Attention Map Before and After CDT",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.05862/x12.png",
                "caption": "(a)Attention map of 24th layer before CDT.",
                "position": 3126
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x12.png",
                "caption": "(a)Attention map of 24th layer before CDT.",
                "position": 3129
            },
            {
                "img": "https://arxiv.org/html/2510.05862/x13.png",
                "caption": "(b)Attention map of 24th layer after CDT.",
                "position": 3134
            }
        ]
    },
    {
        "header": "Appendix GLimitation and Future Work",
        "images": []
    },
    {
        "header": "Appendix HUse of LLMs",
        "images": []
    },
    {
        "header": "Appendix IError Analysis",
        "images": []
    }
]