[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Model and Tokenizer",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02550/extracted/6423690/model_upscaling-Bv3.png",
                "caption": "Figure 1:Bielik 4.5B v3 model upscaling via Depth Up-Scaling (n=36ùëõ36n=36italic_n = 36,m=8ùëö8m=8italic_m = 8,s=56ùë†56s=56italic_s = 56) with tokenizer replacement and outermost layer duplication.",
                "position": 266
            }
        ]
    },
    {
        "header": "3Pre-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02550/extracted/6423690/v3-confusion_matrix.png",
                "caption": "Figure 2:Confusion matrix showing test and validation results for the XGBoost classifier.",
                "position": 795
            },
            {
                "img": "https://arxiv.org/html/2505.02550/extracted/6423690/category_v3.png",
                "caption": "Figure 3:Distribution of major thematic categories in the Polish text dataset (‚â•0.9%absentpercent0.9\\geq 0.9\\%‚â• 0.9 %)",
                "position": 989
            }
        ]
    },
    {
        "header": "4Synthetic Data Generation for Instruction Tuning",
        "images": []
    },
    {
        "header": "5Post-training",
        "images": []
    },
    {
        "header": "6Evaluation",
        "images": []
    },
    {
        "header": "7Limitations and Biases",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]