[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x1.png",
                "caption": "Figure 1:The General Application of YuE. The YuE model takes meta information and lyrics of the generated song in text and arbitrary audio as condition.\nThe model can control outputs in multiple dimensions such as genre, emotion and languages.",
                "position": 445
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work and Prelimenaries",
        "images": []
    },
    {
        "header": "3YuE",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x2.png",
                "caption": "Figure 2:Overview of YuE framework: two-stage lyrics-to-song generation with audio/text tokenizers and two language models. Stage-1: music language modeling. Stage-2: residual modeling.Blue: vocal tokens,orange: accompaniment tokens, andgrey: residual tokens.",
                "position": 627
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x3.png",
                "caption": "Figure 3:Δ⁢WERΔWER\\Delta\\text{WER}roman_Δ WERacross different music genres for mixture / vocal-only tracks.Δ⁢WER∝LLATproportional-toΔWERLLAT\\Delta\\text{WER}\\propto\\text{LLAT}roman_Δ WER ∝ LLAT.",
                "position": 672
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x4.png",
                "caption": "Figure 4:The Stage-1 Framework of YuE. Dotted lines: Dual-NTP (Section3.2.1). Text interleave: CoT (Section3.2.2). Green tokens: ICL (Section3.2.3). Multitask learning (Section4.1).",
                "position": 777
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x5.png",
                "caption": "Figure 5:The Stage-2 Framework of YuE.",
                "position": 936
            }
        ]
    },
    {
        "header": "4Training and Inference Strategies",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x6.png",
                "caption": "Figure 6:Human evaluation comparing YuE to 4 proprietary systems. YuE matches two of it (Tiangong, Udio) and outperforms one (Hailuo). Left: Average human preference on all aspects (warmer colors / larger numbers indicate higher preference); Right: win-tie-loss on musicality.",
                "position": 1268
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x6.png",
                "caption": "",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x7.png",
                "caption": "",
                "position": 1275
            }
        ]
    },
    {
        "header": "6Main Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x8.png",
                "caption": "Figure 7:Normalized human preference on different music aspects. Left: scores across 6 musical aspects; Right: performance on 5 types of control.",
                "position": 1308
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x8.png",
                "caption": "",
                "position": 1311
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x9.png",
                "caption": "",
                "position": 1315
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x10.png",
                "caption": "Figure 8:Song-level vocal range on different systems. Higher values indicates better vocal agility, e.g. range=12 means the vocal only span through an octave in a given song. YuE’s vocal range is among the top close-source systems.",
                "position": 1337
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x11.png",
                "caption": "Figure 9:Duration range on different systems. YuE generates the longest audio.",
                "position": 1347
            }
        ]
    },
    {
        "header": "7Fine-tuning To More Languages",
        "images": []
    },
    {
        "header": "8Analysis and Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x12.png",
                "caption": "Figure 10:Comparison of WER-VAR plot for mixture and vocal tracks, including their tokenizer reconstructions, over 1K samples.",
                "position": 1806
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x12.png",
                "caption": "Figure 10:Comparison of WER-VAR plot for mixture and vocal tracks, including their tokenizer reconstructions, over 1K samples.",
                "position": 1809
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x13.png",
                "caption": "Figure 11:Training Loss over Consumed Train Tokens for NTP and Dual-NTP.",
                "position": 1814
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x14.png",
                "caption": "Figure 12:WER over time. Both CoT and model scaling significantly enhance lyrics-following capability.",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x15.png",
                "caption": "Figure 13:Human preference overall win rates for Musicality and Lyrics-following across model scales (0.5B, 2B, and 7B) in pairwise A/B tests. Larger models consistently achieve higher preferences.",
                "position": 1843
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x16.png",
                "caption": "Figure 14:Human preference win rates for Musicality across different test-time tricks.",
                "position": 1862
            }
        ]
    },
    {
        "header": "9Representation Quality",
        "images": []
    },
    {
        "header": "10Emergent Abilities",
        "images": []
    },
    {
        "header": "11Memorization Effect",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x17.png",
                "caption": "Figure 15:Box-plot comparison of cosine similarity across three scenarios: Covers80,Ref-Gen(our training vs. generated sets), and GTZAN. The black bar denotes the median, and the diamond denotes the mean.",
                "position": 2021
            }
        ]
    },
    {
        "header": "12Unsuccessful Attempts",
        "images": []
    },
    {
        "header": "13Conclusion and Future Work",
        "images": []
    },
    {
        "header": "14Ethics and Responsibility",
        "images": []
    },
    {
        "header": "15Contributions and Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASubjective Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x18.png",
                "caption": "Figure 16:Subjective evaluation platform.",
                "position": 3316
            }
        ]
    },
    {
        "header": "Appendix BQwen2Audio-Instruct Tagging Prompt",
        "images": []
    },
    {
        "header": "Appendix CMultilingual Subjective Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08638/x19.png",
                "caption": "(a)Chinese - Lyrics Following",
                "position": 3497
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x19.png",
                "caption": "(a)Chinese - Lyrics Following",
                "position": 3500
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x20.png",
                "caption": "(b)Chinese - Musicality",
                "position": 3505
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x21.png",
                "caption": "(c)Korean - Lyrics Following",
                "position": 3511
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x22.png",
                "caption": "(d)Korean - Musicality",
                "position": 3516
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x23.png",
                "caption": "(e)Japanese - Lyrics Following",
                "position": 3522
            },
            {
                "img": "https://arxiv.org/html/2503.08638/x24.png",
                "caption": "(f)Japanese - Musicality",
                "position": 3527
            }
        ]
    },
    {
        "header": "Appendix D15 English Prompts From GPT",
        "images": []
    }
]