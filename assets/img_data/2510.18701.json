[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18701/x1.png",
                "caption": "",
                "position": 77
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18701/x2.png",
                "caption": "Figure 2:Benchmark Statistics.(a) Word clouds for English and Chinese prompts in both short and long forms; (b) overall prompt length distribution; and (c) distribution of testpoint counts per prompt for short versus long versions.",
                "position": 262
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIBenchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18701/x3.png",
                "caption": "Figure 3:Qualitative Results of Evaluation Dimensions.We present qualitative examples of T2I models evaluated across our specified dimensions.",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2510.18701/x4.png",
                "caption": "Figure 4:Pipeline of Benchmark Construction and Offline Evaluation Model Training.(a) Benchmark construction pipeline; (b) Offline evaluation model training; (c) Offline evaluation cases.",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2510.18701/x5.png",
                "caption": "Figure 5:Evaluation Accuracy Comparison.Our dedicated evaluation model demonstrates a significant improvement in evaluation accuracy across all test points compared to the commonly used offline evaluation VLM,i.e.,Qwen2.5-VL-72b.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE II:Overall Benchmarking Results of T2I models onUniGenBench++using English short prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/medal.png",
                "caption": "",
                "position": 988
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/winner.png",
                "caption": "",
                "position": 1004
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE III:Overall Benchmarking Results of T2I models onUniGenBench++using English long prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE IV:Overall Benchmarking Results of T2I models onUniGenBench++using Chinese short prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 2079
            }
        ]
    },
    {
        "header": "IVExperiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE V:Overall Benchmarking Results of T2I models onUniGenBench++using Chinese long prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 2620
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE VII:Detailed Benchmarking Results of T2I models onUniGenBench++using English short prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 3947
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE VIII:Detailed Benchmarking Results of T2I models onUniGenBench++using English long prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 5492
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE IX:Detailed Benchmarking Results of T2I models onUniGenBench++using Chinese short prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 6975
            },
            {
                "img": "https://arxiv.org/html/2510.18701/figs/bro_medal.png",
                "caption": "TABLE X:Detailed Benchmarking Results of T2I models onUniGenBench++using Chinese long prompts.Gemini-2.5-Prois used as the MLLM for evaluation. Best scores are inbold, second-best inunderlined.",
                "position": 8148
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]