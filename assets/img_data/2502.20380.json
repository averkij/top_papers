[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20380/x1.png",
                "caption": "Figure 1:(a) We define the task of multi-turn code generation where for an initial problemxğ‘¥xitalic_x, the generatorÏ€Î¸subscriptğœ‹ğœƒ\\pi_{\\theta}italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPTprovides a solutiony1subscriptğ‘¦1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nThis solution is evaluated with the public test to get execution feedbacko1subscriptğ‘œ1o_{1}italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nAt a turntğ‘¡titalic_t, the generator is conditioned on the history to generate solutionytâˆ¼Ï€Î¸(.|x,y<t,o<t)y_{t}\\sim\\pi_{\\theta}(.|x,y_{<t},o_{<t})italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT âˆ¼ italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( . | italic_x , italic_y start_POSTSUBSCRIPT < italic_t end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT < italic_t end_POSTSUBSCRIPT ).\nThe rollout ends when the turn limit is reached or the public tests pass upon which the solution is executed on private tests.\nSince, the agents can generate the optimal solution at any turn, this is a 1-step recoverable process.\n(b) Training loop of our methodÎ¼ğœ‡\\muitalic_Î¼Codeâ€“ which comprises of a generator and a learned verifier.\nDuring each iteration, rollouts are collected usingÏ€Î¸subscriptğœ‹ğœƒ\\pi_{\\theta}italic_Ï€ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPTand we train a verifierRÏ•subscriptğ‘…italic-Ï•R_{\\phi}italic_R start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPTto rank candidate solutions for a prompt.\nThe verifierRÏ•subscriptğ‘…italic-Ï•R_{\\phi}italic_R start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPTis then used to construct a local expert and relabel the collected rollouts.\nLastly, the generator is fine-tuned with this expert dataset.",
                "position": 153
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Î¼ğœ‡\\muitalic_Î¼Code: Multi-turn Code Generation",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.20380/extracted/6237315/assets/bar_plot_verifier_new.png",
                "caption": "Figure 2:Comparison of relabeling with learned verifierÂ (LV) and oracle verifierÂ (OV) with the 1B model. The variant OV+LV aggregates a dataset from both verifiers for fine-tuning the generator. Note that OV+LV performs better than OV. However, relabeling with LV outperforms on MBPP and performs comparably on HumanEval, thereby demonstrating the benefits of leveraging the learned verifier for training the generator.",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2502.20380/extracted/6237315/assets/varying_generator_new.png",
                "caption": "Figure 3:Comparison ofÎ¼ğœ‡\\muitalic_Î¼Codeand baselines with 1B models on the ability of the learned generator to incorporate execution feedback at each turn.\nWe observe thatÎ¼ğœ‡\\muitalic_Î¼Codeconsistently improves the BoN accuracy across turns on both datasets, whereas the baselines show marginal improvements with turns.",
                "position": 660
            },
            {
                "img": "https://arxiv.org/html/2502.20380/extracted/6237315/assets/test_time_scaling_new.png",
                "caption": "Figure 4:Test-time scaling with different values of candidate solutionsNğ‘Nitalic_Nat each turn and different ways of learning verifiers.\nWe compare with verifiers learned on samples fromÎ¼ğœ‡\\muitalic_Î¼Codeand base policy.\nThe candidate solutions are obtained from the 1B generator ofÎ¼ğœ‡\\muitalic_Î¼Codeat each turn.\nWe observe that the BoN performance improves with larger values of N on both datasets.\nThe verifier learned with on-policy samples perform better.",
                "position": 830
            },
            {
                "img": "https://arxiv.org/html/2502.20380/extracted/6237315/assets/loss_ablation.png",
                "caption": "Figure 5:Comparison between BCE and BT loss function for training the verifier.\nWe train the verifiers on samples generated by the base modelÂ (Llama-3.2-1B-Instruct).\nThe learned verifier then ranks the candidate solutions from base model and the BoN performance of selected solution is reported.\nThe verifier trained with BT loss performs better increasing value of N.",
                "position": 864
            },
            {
                "img": "https://arxiv.org/html/2502.20380/extracted/6237315/assets/qualitative_example_old.png",
                "caption": "Figure 6:A qualitative example of multi-turn BoN search using dense rewards obtained via the learned verifier inÎ¼ğœ‡\\muitalic_Î¼Code.\nHere, we show the top 3 ranked solutions at each turntğ‘¡titalic_twhereRÏ•â¢(x,yti)â‰¥RÏ•â¢(x,ytj)subscriptğ‘…italic-Ï•ğ‘¥superscriptsubscriptğ‘¦ğ‘¡ğ‘–subscriptğ‘…italic-Ï•ğ‘¥superscriptsubscriptğ‘¦ğ‘¡ğ‘—R_{\\phi}(x,y_{t}^{i})\\geq R_{\\phi}(x,y_{t}^{j})italic_R start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) â‰¥ italic_R start_POSTSUBSCRIPT italic_Ï• end_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT )fori<jğ‘–ğ‘—i<jitalic_i < italic_j.\nWe observe that the learned verifier selects the better solution (in orange) at each turn. The selected solution is passed to public tests to retrieve execution feedback for the generator to improve the next code solution. The selected solution at each turn is better than the last (less errors highlighted in yellow), with the final solution passing all tests. Note that there are 2 correct solutions at the final turn.",
                "position": 871
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]