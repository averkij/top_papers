[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09023/x1.png",
                "caption": "Figure 1:Attack success rate of our adaptive attacks compared to the weaker or static attacks considered in the original paper evaluation.\nNone of the 12 defenses across four common techniques is robust to strong adaptive attacks.\nOn the rightmost bars, human red-teaming succeeds on all of the scenarios while the static attack succeeds on none.",
                "position": 146
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2A Brief History of Adversarial ML Evaluations",
        "images": []
    },
    {
        "header": "3Problem Statement, Threat Model, and Attacker’s Capabilities",
        "images": []
    },
    {
        "header": "4General Attack Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09023/figures/frame.png",
                "caption": "Figure 2:A diagram of our generalized adaptive attacks against LLMs.",
                "position": 296
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Lesson and Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AGeneral Adaptive Attack Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09023/figures/hackaprompt_interface.png",
                "caption": "Figure 3:Competitors are provided with a challenge interface in which they 1) receive a complete set of instructions for how to interact with the environment 2) can test prompts and watch the agent’s actions/outputs in real time 3) can see the user task and attacker (injection) task 4) can see whether successfully completed the challenge. After clicking the Try Again button, an input textbox will be shown where the Chat currently is.",
                "position": 2143
            }
        ]
    },
    {
        "header": "Appendix BExperiment Setup",
        "images": []
    },
    {
        "header": "Appendix CRL-Based Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09023/x2.png",
                "caption": "Figure 4:Score of the RL-based attack against Data Sentinel. We also include the trigger at the first step and the last step of the RL update.",
                "position": 2300
            },
            {
                "img": "https://arxiv.org/html/2510.09023/x3.png",
                "caption": "Figure 5:Reward Hacking example",
                "position": 2340
            }
        ]
    },
    {
        "header": "Appendix DSearch-Based Methods",
        "images": []
    },
    {
        "header": "Appendix EHuman AI Red-Teaming Competition Setup and Results",
        "images": []
    },
    {
        "header": "Appendix FComparing Human and Automated Red-Teaming Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09023/x4.png",
                "caption": "Figure 6:ASR vs number of queries by the search attack and human red-teaming challenge on the selected subset of AgentDojo scenarios and defenses.\nFor a given scenario, human red-teaming is considered successful ifanyparticipant succeeds.",
                "position": 2829
            }
        ]
    },
    {
        "header": "Appendix GAdditional Results",
        "images": []
    }
]