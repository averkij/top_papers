[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14046/x1.png",
                "caption": "",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2601.14046/x2.png",
                "caption": "",
                "position": 137
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14046/x3.png",
                "caption": "Figure 1:PRiSM is the first open-source benchmark for phone recognition systems, covering intrinsic and extrinsic evaluations, i.e., transcription task and downstream task performance.",
                "position": 172
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Evaluation Framework of PRiSM",
        "images": []
    },
    {
        "header": "4Benchmarked Models",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": []
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14046/x4.png",
                "caption": "Figure 2:PFER vs Phone masking rate. A PR model that relies only on acoustics should produce a horizontal line. Encoder-only models trained with CTC loss retain acoustic fidelity at high masking levels. See§ 6.1.",
                "position": 1165
            },
            {
                "img": "https://arxiv.org/html/2601.14046/x5.png",
                "caption": "Figure 3:Precision and Recall scores of PR systems on phone inventory induction for unseen languages (§ 6.2). CTC models trained with highly multilingual data are more stable.",
                "position": 1200
            },
            {
                "img": "https://arxiv.org/html/2601.14046/x6.png",
                "caption": "Figure 4:Attribution map from Vaani(Ghoshet al.,2025). Red supports and blue opposes correct geolocation. W2V2P-LV60 detects doubled phones (§ 6.3).",
                "position": 1231
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "8Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset details and Licenses",
        "images": []
    },
    {
        "header": "Appendix BMetrics",
        "images": []
    },
    {
        "header": "Appendix CExperimental Setup",
        "images": []
    },
    {
        "header": "Appendix DPrompts for LALMs",
        "images": []
    },
    {
        "header": "Appendix EL1 to accent cluster mapping for EdAcc",
        "images": []
    },
    {
        "header": "Appendix FAlgorithm for Vaani-Hi",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14046/figures/cm_gemini_baseline.png",
                "caption": "(a)Baseline (F1-score=32.7%)",
                "position": 3367
            },
            {
                "img": "https://arxiv.org/html/2601.14046/figures/cm_gemini_baseline.png",
                "caption": "(a)Baseline (F1-score=32.7%)",
                "position": 3370
            },
            {
                "img": "https://arxiv.org/html/2601.14046/figures/cm_gemini_thinking.png",
                "caption": "(b)Thinking Mode (F1-score=24.9%)",
                "position": 3375
            }
        ]
    },
    {
        "header": "Appendix GEffect of Thinking Mode on L1-eda Classification",
        "images": []
    }
]