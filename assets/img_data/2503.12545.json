[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x1.png",
                "caption": "",
                "position": 69
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x2.png",
                "caption": "Figure 1:Example of an image of Joe Biden speaking at the White House. Before unlearning (a) MLLMs have the ability to generate responses related to various visual concepts (IdentifyandEvent). The goal of Machine Unlearning (MU) for MLLMs is to selectively forget specific concepts within the model. When theunlearning target is Identity(b), the model mistakenlyidentifies Joe Biden as a different person. When theunlearning target is Event(c), the modelmisinterprets the speech as a concert.",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2503.12545/x3.png",
                "caption": "Figure 2:Comparison between previous MU benchmarks for MLLMs and our PEBench.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x4.png",
                "caption": "Figure 3:Overview of the PEBench framework, illustrating the data curation and evaluation processes.",
                "position": 156
            }
        ]
    },
    {
        "header": "3PEBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x5.png",
                "caption": "Figure 4:(a) Age distribution by gender shows a balanced representation across age groups and between male and female individuals. (b) Area distribution demonstrates geographic diversity, with individuals from various continents, ensuring a globally representative dataset. (c) Job distribution displays a wide range of professions, covering multiple fields such as healthcare, education, arts, business, and technology, highlighting the dataset’s comprehensive coverage of occupational diversity.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2503.12545/x6.png",
                "caption": "Figure 5:Comparison of image generation results between our method and PhotoMaker. The images generated by our method demonstrate consistency in both character appearance and scene setting across different contexts.",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2503.12545/x7.png",
                "caption": "Figure 6:(a) The facial recognition model effectively checks identity consistency, even for samples that may be difficult for humans to distinguish. (b) A person’s professional attributes influence the appearance characteristics of the virtual character.",
                "position": 243
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x8.png",
                "caption": "Figure 7:Left:Heatmap visualization of the unlearning and retain accuracy of MU methods on PEBench. The x-axis shows the tested targets (People and Events) for the unlearned model, while the y-axis indicates the unlearning target. The figure is separated into different regions representing corresponding evaluation metrics and unlearning scopes (A for unlearning effectiveness, B for retainability, C for desirable retain cases; ’1’ for People unlearning, ’2’ for Event unlearning). Diagonal regions (A1 and A2) indicate unlearning efficacy accuracy, while off-diagonal values (B1, B2, C1, and C2) represent retain accuracy. Higher values in lighter colors denote better performance.Right:Representative cases illustrating each region with text descriptions for sample prompts. Desirable cases (✓) show successful unlearning or retention as intended, while undesirable cases (✗) indicate failure to unlearn or unintended retention.",
                "position": 591
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Supplementary Material",
        "images": []
    },
    {
        "header": "Appendix AUnlearning Methods",
        "images": []
    },
    {
        "header": "Appendix BData Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x9.png",
                "caption": "Figure 8:Visualization of the generated dataset. The examples demonstrate consistency in character appearance across different scenes for the same identity (rows) and consistency in scene style across different characters for the same event (columns).",
                "position": 2393
            }
        ]
    },
    {
        "header": "Appendix CGPT-4 Evaluation (G-Eval)",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.12545/x10.png",
                "caption": "Figure 9:Instructions for G-Eval.",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2503.12545/x11.png",
                "caption": "Figure 10:Visualization of person unlearning results. The original model correctly identifies the individuals in the images by their names, while the unlearned model outputs different names, indicating successful unlearning of the original identity information.",
                "position": 2418
            },
            {
                "img": "https://arxiv.org/html/2503.12545/x12.png",
                "caption": "Figure 11:Visualization of event unlearning results. The original model provides precise descriptions of the scenes, while the unlearned model offers alternative descriptions, diverging from the original content to meet the unlearning objective. The goal model demonstrates the target descriptions for comparison.",
                "position": 2423
            }
        ]
    },
    {
        "header": "Appendix DCase of Machine Unlearning",
        "images": []
    }
]