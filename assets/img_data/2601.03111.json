[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/polymath_sym/polymath_learner.png",
                "caption": "",
                "position": 88
            },
            {
                "img": "https://arxiv.org/html/2601.03111/x1.png",
                "caption": "",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3GRPO Basics",
        "images": []
    },
    {
        "header": "4Polymath Learning",
        "images": []
    },
    {
        "header": "5Experimental Setup",
        "images": []
    },
    {
        "header": "6Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x2.png",
                "caption": "Figure 1:The subject-level performance of different learning strategies.OEstands for subjects with open-ended problems. The subjects are sorted by subject embedding distance to MATH500 (the grey dotted line), from low to high. The blue line represents pass ratio from 64 independent attempts of the base model. The stars and triangles represent best performance of in-context learning and polymath learning. Note that we only display the best polymath learning and in-context polymath learning results for demonstration.",
                "position": 618
            },
            {
                "img": "https://arxiv.org/html/2601.03111/x3.png",
                "caption": "Figure 2:Skill spectrum between natural and synthetic polymath samples. The polygon represents number of salient skills identified in each math domain (Geo.andPrecal.representsGeometryandPrecalculusrespectively). The real and dashed areas represent the natural and synthetic specialist samples except the last one, which represents theSynthetic Primesample, and the synthetic samples include more comprehensive salient skill sets than the natural polymath samples.",
                "position": 652
            },
            {
                "img": "https://arxiv.org/html/2601.03111/x4.png",
                "caption": "Figure 3:Average number of mathematical skills employed per problem in different subject domains.AlgebraandPrecalculusskills are the most prevalent.",
                "position": 658
            }
        ]
    },
    {
        "header": "7Generalization of Self-Verification",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x5.png",
                "caption": "Figure 4:Self-verification patterns under different comprehensive and polymath samples across all subjects. Verification patterns like ‘re-evaluate’ and ‘recheck’ appear most frequently in polymath learning with the ‘number theory’ sample, and the ‘intermediate algebra’ sample elicits the most code blocks in reasoning.",
                "position": 669
            }
        ]
    },
    {
        "header": "8Limitations and Future Work",
        "images": []
    },
    {
        "header": "9Conclusion",
        "images": []
    },
    {
        "header": "Appendix AConfigurations",
        "images": []
    },
    {
        "header": "Appendix BLIMR Score Basics",
        "images": []
    },
    {
        "header": "Appendix CResults by Datasets",
        "images": []
    },
    {
        "header": "Appendix DSample Preference with LIMR Scores",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x6.png",
                "caption": "Figure 5:Average domain performance over natural samples with different LIMR scores. The performance is reported the same way as in Table3. The samples with LIMR score being 0.6 perform best.",
                "position": 1167
            }
        ]
    },
    {
        "header": "Appendix EFull Subject List",
        "images": []
    },
    {
        "header": "Appendix FRobustness of Experiments",
        "images": []
    },
    {
        "header": "Appendix GSelf-verification by Subject Domains",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x7.png",
                "caption": "Figure 6:The verification patterns identified for ‘wait’, ‘verify’ and ‘yet’ in different subject groups. The ‘wait’ rates in computer science problems are highly attributed from terms in the question stems.",
                "position": 1629
            },
            {
                "img": "https://arxiv.org/html/2601.03111/x8.png",
                "caption": "Figure 7:The verification patterns identified for ‘re-evaluate’, ‘recheck’ and ‘code’ in different subject groups.",
                "position": 1632
            }
        ]
    },
    {
        "header": "Appendix HPolymath Learning with Other 1-shot Sample",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x9.png",
                "caption": "Figure 8:The skill spectrum between theπ1\\pi_{1}sample, theSynthetic Primesample, and the strongest natural polymath sample in prealgebra. The strongest natural polymath and synthetic samples demonstrate richer and more comprehensive skill coverage than theπ1\\pi_{1}sample.",
                "position": 1784
            }
        ]
    },
    {
        "header": "Appendix IPerformance on MMLU-Pro and SuperGPQA Full Set",
        "images": []
    },
    {
        "header": "Appendix JTraining Dynamics of Polymath Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x10.png",
                "caption": "Figure 9:The evaluation results of benchmarks between comprehensive learning (MATH and LIMR) and different polymath learning samples (Synthetic Primesample, natural prealgebra sample,π1\\pi_{1}) trained in Qwen2.5-7b-base. The results are collected in greedy decoding and rolling smoothing average with window of 5 is applied to AIME2024, AIME2025 and 3 for other benchmarks for demonstration purpose.",
                "position": 1843
            }
        ]
    },
    {
        "header": "Appendix KPolymath Learning on Additional Models",
        "images": []
    },
    {
        "header": "Appendix LReasoning Breakdown by Subject",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03111/x11.png",
                "caption": "Figure 10:The subject-level performance of different learning strategies.OEstands for subjects with open-ended problems. The subjects are sorted by subject embedding distance to MATH500 (the grey dotted line), from low to high. The blue line represents pass ratio from 64 independent attempts of the base model. The stars and triangles represent best performance of in-context learning and polymath learning. Note that we only display the best polymath learning and in-context polymath learning results for demonstration, andSyntheticrepresents theSynthetic Primesample.",
                "position": 2031
            }
        ]
    },
    {
        "header": "Appendix MOther Polymath Learning Samples",
        "images": []
    },
    {
        "header": "Appendix NSelf-Verification Examples",
        "images": []
    },
    {
        "header": "Appendix OExample of Mathematical Skill in the Reasoning Problem",
        "images": []
    }
]