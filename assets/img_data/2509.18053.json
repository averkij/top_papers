[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18053/x1.png",
                "caption": "Figure 1:Illustration of our proposed graph-of-thoughts reasoning framework for cooperative autonomous driving.\nAll Connected Autonomous Vehicles (CAVs) share their perception features with the Multimodal Large Language Model (MLLM), as illustrated by the grey arrows. Any CAV can ask the MLLM to provide a suggested future trajectory or answer perception or prediction questions. The MLLM fuses the perception features from all CAVs and performs inference by following the graph-of-thoughts.\nIf two QA nodes are connected by a directed edge in the graph, as illustrated by black arrows, the answer of the parent node QA is used as the input context of the child node QA.\nOther colored curved arrows illustrate the predicted or suggested future trajectories.\nColor stars represent current locations of objects, predicted or suggested future waypoints.",
                "position": 95
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18053/x2.png",
                "caption": "(a)Q1: Visible Notable Objects.",
                "position": 167
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x2.png",
                "caption": "(a)Q1: Visible Notable Objects.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x3.png",
                "caption": "(b)Q2: Occluding Objects.",
                "position": 175
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x4.png",
                "caption": "(c)Q3: Invisible Notable Objects.",
                "position": 180
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x5.png",
                "caption": "(d)Q4: Overall Notable Objects.",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x6.png",
                "caption": "(e)Q5: Prediction by Perception.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x7.png",
                "caption": "(f)Q6: Prediction by Planning.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x8.png",
                "caption": "(g)Q7: Overall Prediction.",
                "position": 202
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x9.png",
                "caption": "(h)Q8: Suggested Action Classification.",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x10.png",
                "caption": "(i)Q9: Suggested Trajectory.",
                "position": 212
            }
        ]
    },
    {
        "header": "IIIV2V-GoT-QA Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18053/x11.png",
                "caption": "Figure 3:Model architecture of V2V-GoT.",
                "position": 290
            }
        ]
    },
    {
        "header": "IVV2V-GoT Model",
        "images": []
    },
    {
        "header": "VExperiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18053/x12.png",
                "caption": "(a)Our proposed graph-of-thoughts.",
                "position": 483
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x12.png",
                "caption": "(a)Our proposed graph-of-thoughts.",
                "position": 486
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x13.png",
                "caption": "(b)Simplified perception graph.",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x14.png",
                "caption": "(c)Simplified prediction graph.",
                "position": 496
            }
        ]
    },
    {
        "header": "VICommunication Cost",
        "images": []
    },
    {
        "header": "VIIQualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18053/x15.png",
                "caption": "Figure 5:Qualitative testing sample result of V2V-GoT on Q4. Overall Notable Objects (Figure2(d)). The context information is from the testing inference output of parent question Q3. Invisible Notable Objects (Figure2(c)) and Q1. Visible Notable Objects (Figure2(a)).Magenta×\\times: current location of the asking CAV.Magenta curve: reference trajectory in the question.Yellow×\\times: model output.Green∘\\circ: ground-truth answer.",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x16.png",
                "caption": "Figure 6:Qualitative testing sample result of V2V-GoT on Q7. Overall Prediction (Figure2(g)). The context information is from the testing inference output of parent question Q5. Prediction by Perception (Figure2(e)) and Q6. Prediction by Planning (Figure2(f)).Magenta×\\times: current location of the asking CAV.Blue line and×\\times: model output of the predicted future trajectories, starting, and ending waypoints of notable objects.Green line and∘\\circ: ground-truth answer.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2509.18053/x17.png",
                "caption": "Figure 7:Qualitative testing sample result of V2V-GoT on Q9. Suggested Trajectory (Figure2(i)). The context information is from the testing inference output of parent question Q8. Suggested Action Classification (Figure2(h)).Magenta×\\times: current location of the asking CAV.Blue curve and×\\times: model output of the suggested future trajectory and the ending waypoint.Green curve and∘\\circ: ground-truth answer.",
                "position": 657
            }
        ]
    },
    {
        "header": "VIIIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]