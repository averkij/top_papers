[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x1.png",
                "caption": "",
                "position": 85
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x2.png",
                "caption": "",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x3.png",
                "caption": "",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x4.png",
                "caption": "Figure 1:Comparison between R-4B-RL and frontier open-source MLLMs, including non-thinking MLLMs (e.g., InternVL3-8B, Qwen2.5-VL 7B), thinking MLLMs (e.g., Kimi-VL-A3B-Thinking-2506) and auto-thinking MLLMs (e.g., Keye-VL-8B), on different benchmarks.",
                "position": 105
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x5.png",
                "caption": "Figure 2:Non-thinking and thinking mode response examples (left); Auto-thinking triggering rates across multiple benchmarks (right).",
                "position": 121
            }
        ]
    },
    {
        "header": "2The design of Bi-Mode Annealing",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x6.png",
                "caption": "Figure 3:Framework of heuristic-driven strategy for bi-mode data curation.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x7.png",
                "caption": "Figure 4:Distributions of bi-mode data. Darker regions represent items with thinking mode, while lighter correspond to items without thinking.",
                "position": 181
            }
        ]
    },
    {
        "header": "3Auto-Thinking Incentivization via Bi-mode Policy Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x8.png",
                "caption": "Figure 5:Comparison of R-4B-Base and R-4B-RL in auto-thinking mode on OpenCompass Multimodal Reasoning Benchmarks. The R-4B-RL achieves better auto-thinking inference performance.",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x9.png",
                "caption": "Figure 6:The Bi-mode Policy Optimization (BPO) framework. For each input query, the policy model is conditioned to generate two distinct groups of responses (thinking and non-thinking).",
                "position": 348
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x10.png",
                "caption": "Figure 7:Comparison of average output tokens per query across non-thinking, auto-thinking, and thinking modes on different benchmarks. The auto-thinking mode achieves a trade-off between efficiency and performance.",
                "position": 690
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/x11.png",
                "caption": "Figure 8:Average thinking triggering rate (%) across training steps for non-reasoning benchmarks, and reasoning benchmarks.",
                "position": 812
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x11.png",
                "caption": "Figure 8:Average thinking triggering rate (%) across training steps for non-reasoning benchmarks, and reasoning benchmarks.",
                "position": 815
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x12.png",
                "caption": "Figure 9:Average accuracy (%) across RL training steps for non-reasoning benchmarks, and reasoning benchmarks.",
                "position": 820
            },
            {
                "img": "https://arxiv.org/html/2508.21113/x13.png",
                "caption": "Figure 10:The average thinking and non-thinking items across training steps on vanilla GRPO.",
                "position": 920
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AContributions",
        "images": []
    },
    {
        "header": "Appendix BPre-training Stage",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21113/cases/case_count.jpg",
                "caption": "Figure I:An example demonstrating R-4B-RL solves object counting problem.",
                "position": 1541
            },
            {
                "img": "https://arxiv.org/html/2508.21113/cases/case_image_understanding.jpg",
                "caption": "Figure II:An example demonstrating R-4B-RL solves image understanding problem.",
                "position": 1573
            },
            {
                "img": "https://arxiv.org/html/2508.21113/cases/OCR_1.jpg",
                "caption": "Figure III:An example demonstrating R-4B-RL solves OCR tasks.",
                "position": 1605
            },
            {
                "img": "https://arxiv.org/html/2508.21113/cases/case_math1.jpg",
                "caption": "Figure IV:An example demonstrating R-4B-RL solves complex geometry problem.",
                "position": 1637
            },
            {
                "img": "https://arxiv.org/html/2508.21113/cases/case_logic_1.jpg",
                "caption": "Figure V:An example demonstrating R-4B-RL solves logic reasoning tasks.",
                "position": 1679
            },
            {
                "img": "https://arxiv.org/html/2508.21113/cases/case_pie_chart.jpg",
                "caption": "Figure VI:An example demonstrating R-4B-RL solves pie chart description problem.",
                "position": 1727
            }
        ]
    },
    {
        "header": "Appendix CCase Study",
        "images": []
    }
]