[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/x2.png",
                "caption": "Figure 2:Overview of our system.Our system mainly consists of four parts: the humanoid robot platform, the data collection system, the visuomotor policy learning method, and the real-world deployment. For the learning part, we develop Improved 3D Diffusion Policy (iDP3) as a visuomotor policy for general-purpose robots.",
                "position": 84
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": []
    },
    {
        "header": "IIIImproved 3D Diffusion Policy",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/x3.png",
                "caption": "Figure 3:iDP3 utilizes 3D representations in the camera frame,while the 3D representations of other recent 3D policies including DP3[17]are in the world frame, which relies on accurate camera calibration and can not be extended to mobile robots.",
                "position": 167
            }
        ]
    },
    {
        "header": "IVHumanoid Manipulation with Improved 3D Diffusion Policy",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/extracted/5924301/figures/compare_2d_and_3d_v2.png",
                "caption": "Figure 4:Visualization of egocentric 2D and 3D observations.This figure highlights the complexity of diverse real-world scenes. Videos are available onour website.",
                "position": 229
            }
        ]
    },
    {
        "header": "VExperiments and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/x4.png",
                "caption": "Figure 5:Trajectories of our three tasks in the training scene,including Pick&Place, Pour, and Wipe. We carefully select daily tasks so that they are useful across scenes.",
                "position": 255
            },
            {
                "img": "https://arxiv.org/html/2410.10803/x5.png",
                "caption": "Figure 6:Failure cases of image-based methods in new scenes.Here DP corresponds toDP (✶R3M)in TableI, which is the strongest image-based baseline we have. We find that even added with color augmentation during training, image-based methods still struggle in the new scene/object.",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2410.10803/x6.png",
                "caption": "Figure 7:Training time.Due to using 3D representations, iDP3 saves training time compared to Diffusion Policy (DP), even after we scale up the 3D vision input. This advantage becomes more evident when the number of demonstrations gets large.",
                "position": 261
            }
        ]
    },
    {
        "header": "VICapabilities",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10803/x7.png",
                "caption": "Figure 8:View invariance of iDP3.We find that egocentric 3D representations are surprisingly view-invariant.\nHere DP corresponds toDP (✶R3M)in TableI, which is the strongest image-based baseline we have.",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2410.10803/extracted/5924301/figures/object2.png",
                "caption": "Figure 9:Objects used in Pick&Place and Pour.We only use the cups as the training objects, while our method naturally handles other unseen bottles/cups.",
                "position": 658
            }
        ]
    },
    {
        "header": "VIIConclusions and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]