[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14245/x1.png",
                "caption": "Figure 1:An illustration of our perspective:RLVR implicitly incentivizes correct reasoning in base LLMs.\nWe visualize how different explanation frameworks lead to varying reasoning paths being activated, with our perspective shown in the lower left and a recent popular hypothesis explainingP⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_Kobservations(Yue et al.,2025)summarized in the upper left.\nIn this diagram, the line width represents the sampling probability of a reasoning path, while the color distinguishes correct paths (green) from incorrect ones (red).\nIf all reasoning paths after applying RLVR are already present in the base model, the reasoning model merely adjusts the sampling probabilities of these existing paths (visualized in dashed lines).\nThis hypothesis effectively accounts for the key observation shown in the upper-right part, where, for a moderately largeK𝐾Kitalic_K, a base LLM can catch up to the reasoning model after RLVR using theP⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_Kmetric.\nHowever, we challenge this hypothesis using a refined metric,C⁢o⁢T𝐶𝑜𝑇CoTitalic_C italic_o italic_T-P⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_K, which emphasizes both the correctness of answers and the validity of the reasoning chains.\nAs demonstrated by experimental evidence in the lower right, we observe that RLVR improvesC⁢o⁢T𝐶𝑜𝑇CoTitalic_C italic_o italic_T-P⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_Kfor all values ofK𝐾Kitalic_K, suggesting thatthe direction of incentivization is improving the CoT correctness fromP⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_Kof a very largeK𝐾Kitalic_K.",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3A Theoretical Foundation of RLVR for LLMs",
        "images": []
    },
    {
        "header": "4Revisiting Pass@K Experiments with CoT-Pass@K",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14245/x2.png",
                "caption": "Figure 2:Comparisons ofP⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_K(the top row) andC⁢o⁢T𝐶𝑜𝑇CoTitalic_C italic_o italic_T-P⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_K(the bottom row) on five math benchmarks (different columns) to show different observations of how RLVR incentivizes reasoning in LLMs. Here the base LLM is Qwen2.5-32B, and the post-RLVR model is DAPO-Qwen-32B. ForC⁢o⁢T𝐶𝑜𝑇CoTitalic_C italic_o italic_T-P⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_K, we perform multiple verifications for each CoT using DeepSeek-R1-0528-Qwen3-8B, and display the results determined byany-correct,all-correct, andmajority-correctstrategies, which constitute the shaded area in lower subplots.",
                "position": 732
            }
        ]
    },
    {
        "header": "5Analyzing the Training Dynamics of RLVR",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14245/x3.png",
                "caption": "(a)Distributions ofP⁢(C⁢A)(q)𝑃superscript𝐶𝐴𝑞P(CA)^{(q)}italic_P ( italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTandP⁢(C⁢C|C⁢A)(q)𝑃superscriptconditional𝐶𝐶𝐶𝐴𝑞P(CC|CA)^{(q)}italic_P ( italic_C italic_C | italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTforeasytraining questions in DAPO.",
                "position": 749
            },
            {
                "img": "https://arxiv.org/html/2506.14245/x3.png",
                "caption": "(a)Distributions ofP⁢(C⁢A)(q)𝑃superscript𝐶𝐴𝑞P(CA)^{(q)}italic_P ( italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTandP⁢(C⁢C|C⁢A)(q)𝑃superscriptconditional𝐶𝐶𝐶𝐴𝑞P(CC|CA)^{(q)}italic_P ( italic_C italic_C | italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTforeasytraining questions in DAPO.",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2506.14245/x4.png",
                "caption": "(b)Distributions ofP⁢(C⁢A)(q)𝑃superscript𝐶𝐴𝑞P(CA)^{(q)}italic_P ( italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTandP⁢(C⁢C|C⁢A)(q)𝑃superscriptconditional𝐶𝐶𝐶𝐴𝑞P(CC|CA)^{(q)}italic_P ( italic_C italic_C | italic_C italic_A ) start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPTforhardtraining questions in DAPO.",
                "position": 760
            },
            {
                "img": "https://arxiv.org/html/2506.14245/x5.png",
                "caption": "(c)Generalization performance on AIME 2024 across different training steps.",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2506.14245/x6.png",
                "caption": "Figure 4:RevisitingP⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_KandC⁢o⁢T𝐶𝑜𝑇CoTitalic_C italic_o italic_T-P⁢a⁢s⁢s⁢@⁢K𝑃𝑎𝑠𝑠@𝐾Pass@Kitalic_P italic_a italic_s italic_s @ italic_Kexperiments on AIME 2024 and AIME 2025 using early and mid-stage checkpoints of our DAPO reproduction.\nThe base LLM and post-RLVR model are Qwen2.5-32B and DAPO-Qwen-32B, respectively.",
                "position": 811
            }
        ]
    },
    {
        "header": "6Discussions",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.14245/x7.png",
                "caption": "Figure 5:An intuitive diagram to illustrate the benefits of our multi-verification system: simultaneously consideringany-correct,all-correct, andmajority-correcthelps us to mitigate false positives and false negatives within individual verifications.",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2506.14245/extracted/6548052/figures/aime24-15.png",
                "caption": "",
                "position": 1895
            },
            {
                "img": "https://arxiv.org/html/2506.14245/extracted/6548052/figures/aime25-2.png",
                "caption": "",
                "position": 2060
            },
            {
                "img": "https://arxiv.org/html/2506.14245/extracted/6548052/figures/aime25-11.png",
                "caption": "",
                "position": 2113
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]