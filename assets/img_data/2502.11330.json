[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11330/extracted/6208615/figure/motivation_figure.png",
                "caption": "Figure 1:OurSysGenpipeline provides two main points: system message generation and newly-generated answer.\nWe manually select eight key fuctionalities of system messages and generate phrases with specific tags to original SFT datasets that lack of system messages.\nOur pipeline generates better aligned assistant responses with system messages given user-oriented instruction.",
                "position": 148
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11330/x1.png",
                "caption": "Figure 2:OverallSysGendata construction pipeline. Our pipeline consists of four phases:\n(Phase 1) We gather SFT datasets which do not contain system messages and use open-source models to generate system messages with manually selected eight key fuctionality tags.\n(Phase 2) We then remove incorrectly generated tag tokens and reorganize tags with phrases in a predefined order for consistency.\n(Phase 3) We use a LLM-as-a-judge approach with self-model feedback to filter out empty, overly specific, and unnatural phrases.\n(Phase 4) We finally remove tags to create natural system messages and generate new responses along with the user instructions.",
                "position": 212
            }
        ]
    },
    {
        "header": "3SysGen: Pipeline of System and Assistant Response Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11330/x2.png",
                "caption": "Figure 3:A statistic that verifies whether the newly-generated answer is more suitable for the user query than the original answer.\nIt records the probability that GPT-4o would respond with the newly-generated answer being better than the original answer (the probability should ideally exceed 50%).",
                "position": 363
            }
        ]
    },
    {
        "header": "4Experimental Settings",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.11330/x3.png",
                "caption": "Figure 4:The GPT4o LLM-as-a-judge results of measuring the alignment between generated system messages and new assistant responses. We use 20 samples for each data source which sums up to 100 samples in total per models.",
                "position": 1212
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AData Statistics",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    },
    {
        "header": "Appendix CQualitative analysis of generated instances",
        "images": []
    },
    {
        "header": "Appendix DPrompts",
        "images": []
    }
]