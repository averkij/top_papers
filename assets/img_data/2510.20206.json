[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20206/x1.png",
                "caption": "Figure. 1:Overview of RAPO++.The framework couples training-data–aligned prompt refinement with test-time scaling to enhance Text-to-Video (T2V) generation without altering the generative backbone.Stage 1 RAPO: Retrieval-Augmented Prompt Optimization (Sec.3).User prompts are augmented via a retrieval-based relation graph and refactored by a fine-tuned LLM, while a frozen LLM provides alternative rewrites. A discriminator then selects the best candidate, ensuring prompts align with training distributions while preserving intent.Stage 2 SSPO: Sample-Specific Prompt Optimization at Test-time (Sec.4).Multiple candidates are evaluated by VLM verifiers and task-specific metrics, with misalignments guiding iterative refinement. This process enhances temporal coherence, fidelity, and semantic alignment during inference, and also yields prompt pairs for LLM fine-tuning.Stage 3: LLM Fine-Tuning & Evaluation (Sec.4.2&5).The prompt pairs collected from Stage 2 are used to fine-tune the LLM, further enhancing its generalization and robustness across models. The fine-tuned LLM is then validated across different benchmarks, demonstrating consistent and transferable improvements in T2V generation.",
                "position": 85
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20206/pic/teaser_promptscale.png",
                "caption": "Figure. 2:Generation results under different iterations of prompt refinement at inference utilizing SSPO.The initial prompt is “valkyrie riding flying horses through the clouds”. As the number of iterations increases (from left to right), the generated video becomes more detailed and vivid, and more consistent with the user’s intent.",
                "position": 110
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3RAPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20206/x2.png",
                "caption": "Figure. 3:The construction of relation graph.Relation graph consists of multiple nodes (scenes acting as core nodes with modifiers connected as sub-nodes). For each prompt in database, LLM extracts scene and related modifiers. Based on whether the extracted scene is already in the graph or not, different methods are used to incorporate the new information into the graph.",
                "position": 157
            }
        ]
    },
    {
        "header": "4RAPO++",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20206/x3.png",
                "caption": "Figure. 4:Qualitative comparisons across dynamic and static dimensions.This figure showcases videos generated using LaVie with short prompts, GPT-4 and Open-sora prompt optimizations, and our RAPO method. Videos produced with RAPO exhibit significantly sharper spatial details, smoother temporal transitions, and a closer semantic alignment with the input text.",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2510.20206/pic/rapo_plus_results_vis.png",
                "caption": "Figure. 5:Qualitative comparisons using LaVie with initial prompts (left) and optimized prompts from RAPO++ (right).We present qualitative comparisons from the dynamic and static dimension. The videos generated by RAPO++ exhibit sharper details, smoother temporal transitions, and better alignment with the input text.",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2510.20206/x4.png",
                "caption": "Figure. 6:Qualitative examples illustrating the limitation of RAPO++ in numeracy-related compositional tasks.Given prompts ”Five colorful parrots perch on a tree branch” (left) and ”Three majestic giraffes graze on the leaves of tall trees in the African savannah, their long necks reaching high, Salvador Dali style” (right), the generated frames fail to accurately match the specified object counts, highlighting persistent challenges in precise numeracy understanding.",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2510.20206/pic/attn_map.png",
                "caption": "Figure. 7:Visualization on attention map on multiple objects from different prompts.Adding description of the relative spatial position between objects can improve multi-object generation.",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2510.20206/pic/prompt_length.png",
                "caption": "Figure. 8:Prompt length distribution comparison among various methods.The distribution of RAPO-optimized prompts is more closer to the training prompts.",
                "position": 1437
            },
            {
                "img": "https://arxiv.org/html/2510.20206/pic/finetuned-llm.png",
                "caption": "Figure. 9:A complex unusual example (a panda bear in a red apron and name tag works as a cashier in a Chinese New Year-themed supermarket) generated by initial prompt (left) or optimized prompt (right). The generated video from optimized prompt is more consistent with initial prompt and user intention.",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2510.20206/pic/IFS.png",
                "caption": "Figure. 10:Inference-time scaling performance tested on temporal consistency, visual quality, T2V alignment, and factual consistency.We conduct experiments using LaVie[27]and utilize 2.2k T2V prompts provided in[7]. Each metric exhibits a consistent upward trajectory as iteration count increases, underscoring the effectiveness of RAPO++ in enhancing generative performance.",
                "position": 1449
            }
        ]
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]