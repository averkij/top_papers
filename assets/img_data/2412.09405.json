[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09405/x1.png",
                "caption": "Figure 1:In discriminative models (left), resolution reduction increases training and inference efficiency, but significantly degrades accuracy. Replacing resolution reduction with WaLLoC leads to significantly higher accuracy, while providing the same degree of acceleration. For signal enhancement (right), WaLLoC provides better quality when scaling to high resolutions compared to directly operating on image pixels or audio samples.",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x2.png",
                "caption": "Figure 2:Comparison of our proposed method (WaLLoC) with other autoencoder designs for RGB Images (Cheng2020[11], Stable Diffusion 3[12]) and stereo audio (EnCodec[13], Stable Audio[9]). Additional metrics are reported in Tables1and2.",
                "position": 131
            }
        ]
    },
    {
        "header": "2Background: Compressed-Domain Learning",
        "images": []
    },
    {
        "header": "3Proposed Method: Design and Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09405/x3.png",
                "caption": "Figure 3:WaLLoC‚Äôs encode-decode pipeline. The entropy bottleneck and entropy coding steps are only required to achieve high compression ratios for storage and transmission. For compressed-domain learning where dimensionality reduction is the primary goal, these steps can be skipped to reduce overhead and completely eliminate CPU-GPU transfers.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x4.png",
                "caption": "Figure 4:Example of forward and inverse WPT withJ=2ùêΩ2J=2italic_J = 2levels.\nEach level applies filtersL_‚Å¢AsubscriptL_A\\text{L}_{\\_}{\\text{A}}L start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT AandH_‚Å¢AsubscriptH_A\\text{H}_{\\_}{\\text{A}}H start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT Aindependently to each of the signal channels, followed by downsampling by a factor of two(‚Üì2)‚Üìabsent2\\left(\\downarrow 2\\right)( ‚Üì 2 ). An inverse level consists of upsampling(‚Üë2)‚Üëabsent2\\left(\\uparrow 2\\right)( ‚Üë 2 )followed byL_‚Å¢SsubscriptL_S\\text{L}_{\\_}{\\text{S}}L start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT SandH_‚Å¢SsubscriptH_S\\text{H}_{\\_}{\\text{S}}H start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT S, then summing the two channels. The full WPTX‚àºsuperscriptXsimilar-to\\stackrel{{\\scriptstyle\\sim}}{{\\smash{\\textbf{X}}\\rule{0.0pt}{4.73611pt}}}start_RELOP SUPERSCRIPTOP start_ARG bold_X end_ARG start_ARG ‚àº end_ARG end_RELOPof consists ofJùêΩJitalic_Jlevels.",
                "position": 227
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": []
    },
    {
        "header": "5Conclusion and future work",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "7References",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09405/x5.png",
                "caption": "Figure 5:Cheng et al. 2020[11]",
                "position": 984
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x6.png",
                "caption": "Figure 6:Stable Diffusion 3 VAE[12]",
                "position": 987
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x7.png",
                "caption": "Figure 7:WaLLoC 4√ó\\times√ó",
                "position": 990
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x8.png",
                "caption": "Figure 8:WaLLoC 16√ó\\times√ó",
                "position": 993
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x9.png",
                "caption": "Figure 9:Stereo reconstruction of an audio segment from the MUSDB test set.",
                "position": 997
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x10.png",
                "caption": "Figure 10:Result of using theC_‚Å¢z=12subscriptùê∂_z12C_{\\_}{\\textbf{z}}=12italic_C start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT z = 12RGB codec (WaLLoC 16√ó\\times√ó) to decode a12√ó3√ó3123312\\times 3\\times 312 √ó 3 √ó 3latent with all elements equal to zero except except for channeliùëñiitalic_i, which is set to[0000310000]matrix0000310000\\begin{bmatrix}0&0&0\\\\\n0&31&0\\\\\n0&0&0\\end{bmatrix}[ start_ARG start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 31 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ].",
                "position": 1001
            },
            {
                "img": "https://arxiv.org/html/2412.09405/x11.png",
                "caption": "Figure 11:Result of using theC_‚Å¢z=48subscriptùê∂_z48C_{\\_}{\\textbf{z}}=48italic_C start_POSTSUBSCRIPT _ end_POSTSUBSCRIPT z = 48RGB codec (WaLLoC 4√ó\\times√ó) to decode a48√ó3√ó3483348\\times 3\\times 348 √ó 3 √ó 3latent with all elements equal to zero except except for channeliùëñiitalic_i, which is set to[0000310000]matrix0000310000\\begin{bmatrix}0&0&0\\\\\n0&31&0\\\\\n0&0&0\\end{bmatrix}[ start_ARG start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 31 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ].",
                "position": 1009
            }
        ]
    },
    {
        "header": "8Appendix",
        "images": []
    }
]