[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07767/x1.png",
                "caption": "Figure 1:The RiskEval Framework.We evaluate strategic abstention by prompting models with varying error penalties (Œª\\lambda) ranging from 0 to 100. Although models successfully verbalize uncertainty, they fail to translate this signal into decision-making. As illustrated, abstention rates on the HLE benchmark(Phanet al.,2025)remain largely invariant to increasing penalties.",
                "position": 143
            }
        ]
    },
    {
        "header": "2Problem Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07767/x2.png",
                "caption": "Figure 2:Verbalized Confidence is Invariant to Risk.The flat trajectories show that internal uncertainty estimates remain stable despite increasing penalties, confirming that the failure to abstain is not due to signal degradation.",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x3.png",
                "caption": "Figure 3:Normalized Average Utility Collapses Under Risk.As penalties increase, normalized utility drops sharply into negative values on high-uncertainty benchmarks (HLE, GPQA). This confirms that models persist in answering incorrectly even when the cost of error far outweighs the potential reward.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x4.png",
                "caption": "Figure 4:Policy Consistency Collapses Under High Penalties.We measure how often model decisions align with the optimal policy induced by their confidence. The sharp drop on HLE and GPQA shows that models fail to adjust their decision thresholdsœÑ‚Äã(Œª)\\tau(\\lambda)as penalties rise, persisting in answering when abstention is optimal.",
                "position": 206
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Discussions and Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of Evaluation Metrics",
        "images": []
    },
    {
        "header": "Appendix BExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07767/x5.png",
                "caption": "Figure 5:Internal Uncertainty Estimates Are Invariant to Risk.We analyze four calibration-related metrics across HLE, GPQA, and GSM8K as the penalty for wrong answers (Œª\\lambda) increases.(Top row)Verbalized confidence does not drop, proving models do not act conservatively by lowering confidence.(Rows 2-4)Calibration quality (AUARC, ECE, Brier) remains stable. This confirms that the failure to abstain is not caused by signal degradation or a loss of calibration under pressure; the signal exists, but the decision policy fails to use it.",
                "position": 1267
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x6.png",
                "caption": "",
                "position": 1271
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x7.png",
                "caption": "",
                "position": 1273
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x8.png",
                "caption": "",
                "position": 1275
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x9.png",
                "caption": "Figure 6:Average (un-normalized) Utilityùí∞\\mathcal{U}and Penalty Normalized Regret‚Ñõ¬Ø\\overline{\\mathcal{R}}. The top row illustrates ‚Äúutility collapse‚Äù: as the penalty for incorrect answers (Œª\\lambda) increases, the average score earned by models drops precipitously into negative values, particularly on high-uncertainty and harder benchmarks like HLE and GPQA. The bottom row shows that Mean Normalized Regret rises monotonically with the penalty. This indicates that as the cost of error rises, models increasingly deviate from the optimal policyœÄ‚àó\\pi^{*}, incurring large, avoidable losses by failing to abstain despite high uncertainty.",
                "position": 2235
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x10.png",
                "caption": "",
                "position": 2239
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x11.png",
                "caption": "(a)Abstention Rate",
                "position": 2274
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x11.png",
                "caption": "(a)Abstention Rate",
                "position": 2277
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x12.png",
                "caption": "(b)Normalized Regret‚Ñõ¬Ø\\overline{\\mathcal{R}}",
                "position": 2283
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x13.png",
                "caption": "(c)Policy Consistency",
                "position": 2289
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x14.png",
                "caption": "(a)Œî\\DeltaAverage Confidence withuse_confidenceprompt",
                "position": 2296
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x14.png",
                "caption": "(a)Œî\\DeltaAverage Confidence withuse_confidenceprompt",
                "position": 2299
            },
            {
                "img": "https://arxiv.org/html/2601.07767/x15.png",
                "caption": "(b)Œî\\DeltaPolicy Consistency withuse_confidenceprompt",
                "position": 2305
            }
        ]
    },
    {
        "header": "Appendix CLicenses",
        "images": []
    }
]