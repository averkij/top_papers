[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x1.png",
                "caption": "Figure 1:Visualization of Frame2Frame’s editing process.Temporal progression of our video-based approach.\nStarting from the source image (leftmost), frames illustrate the natural evolution toward the target edit (rightmost).\nOur method produces temporally coherent intermediate states while preserving fidelity to both the source content and the editing intent.",
                "position": 114
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x2.png",
                "caption": "Figure 2:Editing Manifold Pathway.Given an input image and target caption ”A happy person making a heart shape with their hands”, our method generates a continuous path on the natural image manifold.\nEach generated frame (indicated by black arrows) represents a plausible intermediate state between the source and target, maintaining temporal consistency throughout the transformation.\nAs a result, in contrast to the competing approach, F2F achieves the desired edit while preserving the ”AI” text on the person’s shirt.",
                "position": 173
            }
        ]
    },
    {
        "header": "2Related Efforts",
        "images": []
    },
    {
        "header": "3Frame2Frame",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x3.png",
                "caption": "Figure 3:Frame2Frame Overview. Given a source image and editing prompt, our pipeline proceeds in three steps. First, a Vision-Language Model generates a temporal caption describing the transformation. Next, this caption guides a video generator to create a natural progression of the edit. Finally, our frame selection strategy identifies the optimal frame that best realizes the desired edit, producing the final image of the cat mid-leap.",
                "position": 293
            }
        ]
    },
    {
        "header": "4Editing Manifold Pathway",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x4.png",
                "caption": "Figure 4:Qualitative Results on TEdBench.Comparison with other methods across various editing tasks. Our approach consistently produces edits that better align with the target prompt while preserving the source image’s content and structure. For instance, in the teddy bear example, our method uniquely achieves complex structural modifications while maintaining high visual quality.",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2411.16819/x5.png",
                "caption": "Figure 5:Qualitative Results on PosEdit.Comparison between our Frame2Frame method and LEDITS++ on human motion editing tasks. For each example, we show the source image, edited results from both methods, and the ground-truth target image. Our method better preserves subject identity while achieving more natural pose transitions.",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2411.16819/x6.png",
                "caption": "Figure 6:Additional Vision Tasks.Qualitative results of our image-to-video-to-image editing approach on selected traditional tasks.",
                "position": 603
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Editing Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x7.png",
                "caption": "Figure S7:TEdBench Editing Examples.",
                "position": 1298
            },
            {
                "img": "https://arxiv.org/html/2411.16819/x8.png",
                "caption": "Figure S8:TEdBench Editing Examples.",
                "position": 1301
            }
        ]
    },
    {
        "header": "Appendix BTemporal Editing Captions",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x9.png",
                "caption": "Figure S9:In Context Learning Examples.",
                "position": 1330
            }
        ]
    },
    {
        "header": "Appendix CFrame Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x10.png",
                "caption": "Figure S10:Frame Selection Collage.The target editing caption for this example is: “A photo of a cat yawning.”.",
                "position": 1407
            }
        ]
    },
    {
        "header": "Appendix DEditing Manifold Pathway",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x11.png",
                "caption": "Figure S11:Flux.1-dev Generations",
                "position": 1462
            }
        ]
    },
    {
        "header": "Appendix EPosEdit",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x12.png",
                "caption": "Figure S12:PosEdit Examples.",
                "position": 1476
            },
            {
                "img": "https://arxiv.org/html/2411.16819/x13.png",
                "caption": "Figure S13:PosEdit Examples.",
                "position": 1479
            }
        ]
    },
    {
        "header": "Appendix FHuman Survey",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16819/x14.png",
                "caption": "Figure S14:Survey Example",
                "position": 1492
            },
            {
                "img": "https://arxiv.org/html/2411.16819/x15.png",
                "caption": "Figure S15:Survey Example",
                "position": 1495
            }
        ]
    },
    {
        "header": "Appendix GAdditional Vision Tasks Captions",
        "images": []
    }
]