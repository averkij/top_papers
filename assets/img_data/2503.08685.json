[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/teaser.jpg",
                "caption": "",
                "position": 130
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08685/x1.png",
                "caption": "(a)Semantic-spectrum coupling.Comparison of the frequency-power spectra for different tokenizers. Here, we decompose the tokens from the tokenizers to demonstrate their contribution to the spectrum of the generated image.\nThe VQ-VAE tokenizer[48]is decomposed by performing PCA in its latent token space, and the 1D TiTok[60]is decomposed by replacing all but the firstkùëòkitalic_ktokens with a mean token.\nForSemanticist, on the other hand, we can clearly see that with any number of tokens, the spectrum remains closely matched with the original image, demonstrating thatSemanticistcan decouple semantics and spectrum in its tokenization process.",
                "position": 150
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x1.png",
                "caption": "(a)Semantic-spectrum coupling.Comparison of the frequency-power spectra for different tokenizers. Here, we decompose the tokens from the tokenizers to demonstrate their contribution to the spectrum of the generated image.\nThe VQ-VAE tokenizer[48]is decomposed by performing PCA in its latent token space, and the 1D TiTok[60]is decomposed by replacing all but the firstkùëòkitalic_ktokens with a mean token.\nForSemanticist, on the other hand, we can clearly see that with any number of tokens, the spectrum remains closely matched with the original image, demonstrating thatSemanticistcan decouple semantics and spectrum in its tokenization process.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x2.png",
                "caption": "(b)Our tokenizer decomposes the image into visual concepts following a PCA-like coarse-to-fine structure where first few tokens capture most semantic information and the rest refine the details.",
                "position": 162
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08685/x3.png",
                "caption": "Figure 3:Semanticisttokenizer architecture.\nThe ViT encoder resamples the 2D image patch tokens into a 1D causal sequence of concept tokens.\nThese concept tokens are then used as conditions to the DiT decoder to reconstruct the original image.\nTo induce a PCA-like structure in the concept tokens, we apply nested CFG.",
                "position": 292
            }
        ]
    },
    {
        "header": "4SemanticistArchitecture",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08685/x4.png",
                "caption": "Figure 4:The explained variance ratio fromSemanticist‚Äôs PCA-like structure and the linear probing accuracy on the tokens.",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/spectral_titok_ours.jpg",
                "caption": "Figure 5:Reconstructed images and their corresponding power-frequency plots, illustratingsemantic-spectrum coupling. Each column shows reconstructions using only the firstkùëòkitalic_ktokens, increasing from left to right, alongside a plot of the reconstructed image‚Äôs frequency power (blue) overlaid on the ground-truth (red) image.",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x5.png",
                "caption": "Figure 6:Scaling behavior of different sized DiT decoder (qualitative results can be found inFig.14in the Appendix).",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/ar_examples.jpg",
                "caption": "Figure 7:Examples of the intermediate generation results ofœµitalic-œµ\\epsilonitalic_œµLlamaGen-L trained onSemanticisttokens (see more fromFig.18).",
                "position": 789
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations and Broader Impacts",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "Author Contribution Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof for PCA-like structure",
        "images": []
    },
    {
        "header": "Appendix BAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix CAdditional Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.08685/x6.png",
                "caption": "Figure 8:The preference score from the human perception test, all models and test configurations obtained a score close to 0.5, indicatingSemanticistcan encode image as effectively as how human language encodes the image.",
                "position": 2049
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x7.png",
                "caption": "Figure 9:CLIP zero-shot accuracy on reconstructed images.",
                "position": 2063
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x8.png",
                "caption": "Figure 10:Frequency-power spectra of Titok decomposed with PCA at feature dimensions. The learning of semantic contents and spectral information are coupled.",
                "position": 2075
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x9.png",
                "caption": "Figure 11:Ablation on the use of REPA (with d64√ó\\times√ó64 concept tokens, DiT-L/2 decoder, see qualitative results inFig.16). REPA improves the information density in preceding tokens.",
                "position": 2088
            },
            {
                "img": "https://arxiv.org/html/2503.08685/x10.png",
                "caption": "Figure 12:Reconstruction performance of different encoder configurations on ImageNet val 50K benchmark. A larger number of lower-dimensional tokens is more friendly for reconstruction tasks.",
                "position": 2091
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_dim_comparison.jpg",
                "caption": "Figure 13:Qualitative results of different token dimensions. Higher dimensional tokens encode more information, and lower dimensional tokens achieve clearer semantic decoupling and achieve better reconstruction.",
                "position": 2094
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_scale.jpg",
                "caption": "Figure 14:Qualitative results of different DiT decoder scales (DiT-B/2, DiT-L/2, and DiT-XL/2) with d16√ó\\times√ó256 tokens. The quality of images generated with fewer tokens improves consistently as the decoder scales up.",
                "position": 2097
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_xl_cfg.jpg",
                "caption": "Figure 15:Qualitative results of different CFG guidance scales for DiT decoder, which clearly controls image aesthetics.",
                "position": 2100
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_64dim_repa.jpg",
                "caption": "Figure 16:Qualitative results on effects of REPA (with d64√ó\\times√ó64 concept tokens). Instead of improving final reconstruction much, the benefit of REPA is mainly attributed to more faithful semantics in intermediate results.",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/recon_16dim_xl_other.jpg",
                "caption": "Figure 17:More reconstruction results ofSemanticistautoencoder (with d16√ó\\times√ó256 concepts tokens and DiT-XL/2 decoder).",
                "position": 2129
            },
            {
                "img": "https://arxiv.org/html/2503.08685/extracted/6266389/figs/ar_more.jpg",
                "caption": "Figure 18:More visualization of intermediate results of auto-regressive image generation.",
                "position": 2132
            }
        ]
    },
    {
        "header": "Appendix DAdditional Experiment Results",
        "images": []
    }
]