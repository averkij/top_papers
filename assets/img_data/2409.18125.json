[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/llava-3d-teaser-combine-v2.png",
                "caption": "",
                "position": 121
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/llava3d-method-v13.png",
                "caption": "Figure 2:LLaVA-3D Architecture.Based on LLaVA, we directly add the corresponding 3D position embeddings to 2D patch visual tokens of multi-view images to construct the 3D Patches, then the 3D Patches will undergo 3D pooling and be sent into the projection layer of LLaVA to map into the LLM space and align with the LLM using 3D-visual-language data.",
                "position": 170
            }
        ]
    },
    {
        "header": "4Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/llava-3d-data-v2.png",
                "caption": "Figure 3:LLaVA-3D-Instruct-1M.The hybrid 2D and 3D Dataset Collection. Left: Distribution of data across categories, with the outer circle representing all categories and the inner circle illustrating data subset distribution. Right: Detailed dataset quantities.",
                "position": 258
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/llava-3d-cases-v3.png",
                "caption": "Figure 4:LLaVA-3D enables the user-friendly interaction with the 3D scene across various 3D understanding and reasoning tasks. It allows the users to just click on the 2D images or the video frame to simply conduct the interactive 3D question answering and 3D dense captioning.",
                "position": 1048
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/demo1.png",
                "caption": "Figure 5:LLaVA-3D could perform 2D Click-based 3D dense captioning, generating the corresponding object caption and 3D bounding box.",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/demo2.png",
                "caption": "Figure 6:LLaVA-3D could perform 2D Click-based 3D question answering, now users could click on the 2D images and ask the question.",
                "position": 2126
            },
            {
                "img": "https://arxiv.org/html/2409.18125/extracted/5881411/imgs/demo3.png",
                "caption": "Figure 7:LLaVA-3D exhibits powerful 3D visual grounding capability, enabling accurate 3D bounding boxes output.",
                "position": 2129
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]