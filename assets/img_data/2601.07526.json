[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07526/x1.png",
                "caption": "Figure 1:The proposed three-service architecture for agent training.(left)TheEnvironment Serviceprovides diverse interactive execution environments and returns feedback (observations, rewards, termination signals) in response to actions.(middle)TheAgent Serviceorchestrates interaction, collects trajectories, and manages experiences.(right)TheModel Servicesupports both inference (returning policies from context) and training (updating from experiences).",
                "position": 167
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2MegaFlow",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07526/x2.png",
                "caption": "Figure 2:The architecture ofMegaFlow.(bottom)TheModel Serviceprovides inference and training capabilities through various engines and distributed frameworks.(middle)TheAgent Servicecoordinates execution strategies, integrates with agent frameworks, and manages experience feedback loops.(top)TheEnvironment Serviceprovides containerized execution environments and handles distributed task scheduling.",
                "position": 252
            }
        ]
    },
    {
        "header": "3Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07526/x3.png",
                "caption": "Figure 3:Throughput scaling and cost comparison between MegaFlow and centralized approaches.(Left)Total execution time showing MegaFlow’s consistent performance versus centralized degradation.(Right)Total cost comparison with 32% cost reduction at 2,000 concurrent tasks.\nData represents bootstrap sampling from over 130,000 production records.",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2601.07526/x4.png",
                "caption": "Figure 4:Resource utilization patterns across normalized execution time.(Left)CPU utilization: centralized peak at 25% versus MegaFlow’s stable 5-10%.(Right)Memory utilization: centralized peak at 50% versus MegaFlow’s consistent 12%.\nShaded areas represent 95% confidence intervals.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2601.07526/x5.png",
                "caption": "Figure 5:End-to-end latency breakdown and environment startup scaling comparison.(Left)Total execution times: MegaFlow Persistent (75 min), Ephemeral (90 min), and High-Spec Centralized (110 min).(Right)Environment startup time scaling showing centralized degradation (1-13 min) versus MegaFlow’s stable performance.",
                "position": 574
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADefinitions",
        "images": []
    },
    {
        "header": "Appendix BAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix CAgent Framework Compatibility",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07526/x6.png",
                "caption": "Figure 6:RL training dynamics on SWE-bench Verified.Model Ais a 235 billion parameters MoE model andModel Bis a 30 billion parameters MoE model.\nScores are evaluated using the OpenHands scaffold across training steps 0–100.",
                "position": 1412
            }
        ]
    },
    {
        "header": "Appendix DReinforcement Learning for Agent Training",
        "images": []
    }
]