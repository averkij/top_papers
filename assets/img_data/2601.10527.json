[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10527/x1.png",
                "caption": "Figure 1:Safety leaderboardsof the 7 evaluated frontier models across four dimensions:Benchmark Evaluation,Adversarial Evaluation,Multilingual Evaluation, andCompliance Evaluation.(a)Language Safety Leaderboard;(b)Vision-Language Safety Leaderboard;(c)T2I Safety Leaderboard.",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x2.png",
                "caption": "Figure 2:Safety Profiles of Evaluated Models.The radar charts depict the multidimensional safety characteristics of each model across Language and Vision–Language. Each axis corresponds to a normalized safety score (0–100%) along a specific evaluation dimension, including Benchmark, Adversarial, Multilingual, and Compliance (NIST, EU AI Act, FEAT) evaluations.Larger and more symmetric profiles indicate stronger and more balanced safety alignment.",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x3.png",
                "caption": "Figure 3:Safety Profiles of Evaluated Models.The radar charts depict the multidimensional safety characteristics of Image Generation models. Each axis corresponds to a normalized safety score (0–100%) along a specific evaluation dimension, including Benchmark and Adversarial evaluations.Larger and more symmetric profiles indicate stronger and more balanced safety alignment.",
                "position": 467
            }
        ]
    },
    {
        "header": "2Language Safety",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10527/x4.png",
                "caption": "Figure 4:Safe rate (%) of five models across five benchmarks.",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x5.png",
                "caption": "Figure 5:Example unsafe responses across different safety benchmarks.",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x6.png",
                "caption": "Figure 6:Adversarial evaluation results across five models on 100 harmful queries.Safety metrics:Safeworst\\text{Safe}_{{\\color[rgb]{1,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\\text{worst}}}, the % of queries successfully defended againstallattacks;Safeworst-3\\text{Safe}_{{\\color[rgb]{1,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\\text{worst-3}}}, the % of queries defended against thetop-3 most effective attacks;Refusalresp\\text{Refusal}_{{\\color[rgb]{1,.5,0}\\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\\text{resp}}}, the % of responses that are considered refusals by Qwen3Guard;Saferesp\\text{Safe}_{{\\color[rgb]{0,0.6,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0.6,0}\\text{resp}}}, the % of responses judged as safe by Qwen3Guard across all attacks.",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x7.png",
                "caption": "Figure 7:Example unsafe responses across different types of jailbreak attacks.",
                "position": 850
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x8.png",
                "caption": "Figure 8:Comparison of safety judgment performance across four large language models on two benchmarks, PolyGuardPrompt (PGP) and ML-Bench, evaluated in 17 (PGP) or 13 (ML-Bench) languages. Each radar chart represents the macro F1 score of the five models. The models are evaluated on four different settings: PGP prompt (PGP-P), PGP response (PGP-R), ML-Bench prompt (ML-Bench-P), and ML-Bench response (ML-Bench-R). Safety performance is visualized across multiple languages, with the radial axis indicating the micro F1 score (ranging from 0.3 to 0.9). Performance trends indicate varying robustness to multilingual and regulatory differences across models and datasets.",
                "position": 903
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x9.png",
                "caption": "Figure 9:Regulatory compliance results (Compliance Rate, %) across three governance frameworks. Higher is better. The abbreviations for the risk categories stand for:CBRN-IC: CBRN Information and Capabilities;DVHC: Dangerous Violent or Hateful Content;ODAC: Obscene, Degrading, or Abusive Content;IID: Information Integrity and Deception;HBH: Harmful Bias and Homogenization;DPV: Data Privacy Violations;IPI: Intellectual Property Infringement;CM: Cognitive Manipulation;EV: Exploitation of Vulnerabilities;SC: Social Scoring;PP-RA: Predictive Policing and Risk Assessment;FRDB: Creation of Facial Recognition Databases;ER-SC: Emotion Recognition in Sensitive Contexts;BCSI: Biometric Categorization for Sensitive Inference; andRRBI: Real-time Remote Biometric Identification.",
                "position": 1377
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x10.png",
                "caption": "Figure 10:Example non-compliant cases from the compliance evaluation. The examples include generating research proposals for prohibited Biometric Categorization (EU AI Act), reproducing copyrighted text violating Intellectual Property protections (NIST), drafting policy memos to justify Real-Time Remote Biometric Identification (EU AI Act), and designing deceptive UI flows that violate Transparency and fairness principles (FEAT).",
                "position": 1481
            }
        ]
    },
    {
        "header": "3Vision–Language Safety",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10527/x11.png",
                "caption": "Figure 11:The macro average safe rates (%) across the four multimodal safety benchmarks.",
                "position": 1594
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x12.png",
                "caption": "Figure 12:Example unsafe responses under multimodal benchmark evaluation.The examples include guidance on extremist radicalization, stereotype-reinforcing validation, assistance with political disinformation or forgery, and procedural instructions involving biological hazards.",
                "position": 1677
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x13.png",
                "caption": "Figure 13:Safe rates (%) under multimodal adversarial evaluation.",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x14.png",
                "caption": "Figure 14:Example unsafe responses under adversarial multimodal evaluation.They illustrate diverse failure modes, including partial refusals, disclaimer-based leakage, and direct compliance with jailbreak prompts.",
                "position": 1847
            }
        ]
    },
    {
        "header": "4Image Generation Safety",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10527/x15.png",
                "caption": "Figure 15:Evaluation results on the T2ISafety benchmark. The stacked bars compareNano Banana ProandSeedream 4.5byRefusal,Unsafe, andSaferates. Both models align well onIntellectual Property, but remain highly vulnerable inHate,Disturbing, andViolence.",
                "position": 1903
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x16.png",
                "caption": "Figure 16:Example harmful images generated by Nano Banana Pro and Seedream 4.5 on the T2ISafety benchmark.All the shown images are marked as unsafe.",
                "position": 1926
            },
            {
                "img": "https://arxiv.org/html/2601.10527/x17.png",
                "caption": "Figure 17:Adversarial evaluation results. The stacked bars compareNano Banana ProandSeedream 4.5byRefusal,Harmful, andSaferates. Both models exhibit strong safety performance against thePGJattack, but their robustness degrades substantially under the more recentGenBreakattack.",
                "position": 1968
            },
            {
                "img": "https://arxiv.org/html/2601.10527/imgs/t2i_adv_gallery.png",
                "caption": "Figure 18:Example harmful images generated by Nano Banana Pro and Seedream 4.5 under adversarial evaluation.All the shown images are marked as unsafe.",
                "position": 2158
            },
            {
                "img": "https://arxiv.org/html/2601.10527/imgs/t2i_regulatory_quan.png",
                "caption": "Figure 19:Quantitative results on the regulatory compliance benchmark.Category Abbreviations:PSNS: Political Subversion and National Security Threats;TE: Terrorism and Extremism;HSD: Hate Speech and Discrimination;VSE: Violent and Sexually Explicit Content;MD: Misinformation and Disinformation;IPRP: Infringement of Personal Rights and Privacy;IPI: Intellectual Property Infringement.",
                "position": 2200
            },
            {
                "img": "https://arxiv.org/html/2601.10527/imgs/t2i_regulatory_benchmark_gallery.png",
                "caption": "Figure 20:Examples harmful images generated by Nano Banana Pro and Seedream 4.5 under regulatory compliance evaluation.Category Abbreviations:PSNS: Political Subversion and National Security Threats;TE: Terrorism and Extremism;HSD: Hate Speech and Discrimination;VSE: Violent and Sexually Explicit Content;MD: Misinformation and Disinformation;IPRP: Infringement of Personal Rights and Privacy;IPI: Intellectual Property Infringement.",
                "position": 2228
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations and Disclaimer",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]