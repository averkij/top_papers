[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x1.png",
                "caption": "Figure 1:Left:Overall accuracy of four models on six benchmarks.Right:Dataset-selection rationale. Based on the accuracy gap, we retain MATH500, MinervaMath and LiveMathBench as our principal evaluation suites. Questions that arewrong before RLVR but correct afterare treated as leaked and are the focus of subsequent mechanistic tests.",
                "position": 141
            }
        ]
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Empirical Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x2.png",
                "caption": "(a)ROUGE-L Scores",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x2.png",
                "caption": "(a)ROUGE-L Scores",
                "position": 202
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x3.png",
                "caption": "(b)Completion Accuracy",
                "position": 207
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x4.png",
                "caption": "(a)Qwen2.5-Math-7B.",
                "position": 214
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x4.png",
                "caption": "(a)Qwen2.5-Math-7B.",
                "position": 217
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x5.png",
                "caption": "",
                "position": 221
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x6.png",
                "caption": "(b)LLaMA-3.1-8B.",
                "position": 227
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x7.png",
                "caption": "",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x8.png",
                "caption": "(c)OLMo-2-1124-7B.",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x9.png",
                "caption": "",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x10.png",
                "caption": "Figure 4:The Perplexity Paradox.While answer-only perplexity decreases (orange), full-text perplexity increases (blue), suggesting a trade-off between memorization and general language modeling capability.",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x11.png",
                "caption": "(a)Qwen2.5-Math-7B",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x11.png",
                "caption": "(a)Qwen2.5-Math-7B",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x12.png",
                "caption": "(b)LLaMA-3.1-8B",
                "position": 289
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x13.png",
                "caption": "(a)Qwen2.5-Math-7B",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x13.png",
                "caption": "(a)Qwen2.5-Math-7B",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x14.png",
                "caption": "(b)LLaMA-3.1-8B",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x15.png",
                "caption": "(a)Successful Retrieval Trajectory (Output: Correct Answer ”4”)",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x15.png",
                "caption": "(a)Successful Retrieval Trajectory (Output: Correct Answer ”4”)",
                "position": 341
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x16.png",
                "caption": "",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x17.png",
                "caption": "(b)Failed Retrieval Trajectory (Output: Wrong Answer ”3”)",
                "position": 351
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x18.png",
                "caption": "",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x19.png",
                "caption": "Figure 8:Latent Space Trajectory (PCA Projection).The average trajectories of Leakage (red) and Generalization (blue) samples bifurcate significantly after the middle layers.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x20.png",
                "caption": "(a)Overall accuracy on leakage samples across ablation conditions. Anchor reset and Adapter reset cause moderate drops.",
                "position": 382
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x20.png",
                "caption": "(a)Overall accuracy on leakage samples across ablation conditions. Anchor reset and Adapter reset cause moderate drops.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x21.png",
                "caption": "(b)Overall accuracy on stable samples. Performance remains stable under reset conditions.",
                "position": 391
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x22.png",
                "caption": "Figure 10:NDE Dynamics Metrics.Left:Separation Force peaks at L18–L20, identifying the causal origin of trajectory divergence.Right:Velocity Difference increases in later layers, reflecting signal amplification by the Structural Adapter layers.",
                "position": 398
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x23.png",
                "caption": "Figure 11:Layer-wise Probing AUC.The distinguishability between leakage and stable samples peaks at Layer 20, corroborating the NDE and Path Patching results.",
                "position": 401
            }
        ]
    },
    {
        "header": "5Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x24.png",
                "caption": "Figure 12:Mean Neuron Activation Across Layers.The identified task-relevant neurons exhibit maximal activation at L19, L21, and L24.",
                "position": 448
            }
        ]
    },
    {
        "header": "6Mechanistic Intervention",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x25.png",
                "caption": "(a)Leakage Dataset",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x25.png",
                "caption": "(a)Leakage Dataset",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x26.png",
                "caption": "(b)Leakage-free Dataset",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x27.png",
                "caption": "(a)Pattern 1: Dose-Dependent Modulation (Q42, Answer: “4”).Left:Layer-wise probability evolution under three scaling regimes. Amplification (α=3.0\\alpha=3.0) enhances answer token probability, while suppression (α=0.2\\alpha=0.2) attenuates it.Right:Top-10 token heatmap. Under amplification, a formatting token prematurely reaches top-1 at Layer 22, and the answer token achieves higher ranking at Layer 23.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x27.png",
                "caption": "(a)Pattern 1: Dose-Dependent Modulation (Q42, Answer: “4”).Left:Layer-wise probability evolution under three scaling regimes. Amplification (α=3.0\\alpha=3.0) enhances answer token probability, while suppression (α=0.2\\alpha=0.2) attenuates it.Right:Top-10 token heatmap. Under amplification, a formatting token prematurely reaches top-1 at Layer 22, and the answer token achieves higher ranking at Layer 23.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x28.png",
                "caption": "",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x29.png",
                "caption": "(b)Pattern 2: Amplification-Induced Shortcut Activation (Q213, Answer: “2”).Left:Baseline and suppression fail to retrieve the answer. Amplification triggers a high-confidence plateau from the middle layer, with the answer token emerging only in the final two layers.Right:Top-10 heatmap shows abrupt answer injection at L26–L27 under amplification, absent in other conditions. This suggests amplification activates a latent shortcut pathway inaccessible to the base model.",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x30.png",
                "caption": "",
                "position": 559
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APartial Prompt Evaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x31.png",
                "caption": "Figure 15:Accuracy Comparison Across Models and Datasets.Qwen3-8B shows high baseline accuracy and dramatic improvement under spurious RLVR, while LLaMA-3.1-8B and OLMo-2-1124-7B remain at a low level performance regardless of training.",
                "position": 920
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x32.png",
                "caption": "(a)Qwen: ROUGE-L Scores",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x32.png",
                "caption": "(a)Qwen: ROUGE-L Scores",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x33.png",
                "caption": "(b)Qwen: Completion Accuracy",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x34.png",
                "caption": "(a)Qwen3-8B: ROUGE-L Scores",
                "position": 953
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x34.png",
                "caption": "(a)Qwen3-8B: ROUGE-L Scores",
                "position": 956
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x35.png",
                "caption": "(b)Qwen3-8B: Completion Accuracy",
                "position": 961
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x36.png",
                "caption": "(a)LLaMA-3.1-8B: ROUGE-L",
                "position": 968
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x36.png",
                "caption": "(a)LLaMA-3.1-8B: ROUGE-L",
                "position": 971
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x37.png",
                "caption": "(b)LLaMA-3.1-8B: Completion Acc",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x38.png",
                "caption": "(c)OLMo-2-1124-7B: ROUGE-L",
                "position": 982
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x39.png",
                "caption": "(d)OLMo-2-1124-7B: Completion Acc",
                "position": 987
            }
        ]
    },
    {
        "header": "Appendix BAdditional Path Patching Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x40.png",
                "caption": "(a)OLMo-2-1124-7B",
                "position": 1001
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x40.png",
                "caption": "(a)OLMo-2-1124-7B",
                "position": 1004
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x41.png",
                "caption": "(b)Qwen3-8B",
                "position": 1009
            }
        ]
    },
    {
        "header": "Appendix CAdditional JSD Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x42.png",
                "caption": "(a)OLMo-2-1124-7B",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x42.png",
                "caption": "(a)OLMo-2-1124-7B",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x43.png",
                "caption": "(b)Qwen3-8B",
                "position": 1031
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results on Logit Lens",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x44.png",
                "caption": "(a)LLaMA-3.1-8B (Correct Output)",
                "position": 1054
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x44.png",
                "caption": "(a)LLaMA-3.1-8B (Correct Output)",
                "position": 1057
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x45.png",
                "caption": "(b)LLaMA-3.1-8B (Incorrect Output)",
                "position": 1062
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x46.png",
                "caption": "(c)OLMo-2-1124-7B (Correct Output)",
                "position": 1068
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x47.png",
                "caption": "(d)OLMo-2-1124-7B (Incorrect Output)",
                "position": 1073
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x48.png",
                "caption": "Figure 22:Additional Qwen2.5-Math Leakage Cases.Analysis of two additional samples from the contaminated set. Both examples replicate the distinct activation signature: strong signal priming at L18–L20, a transitional valley, and decisive answer token injection starting at Layer 23.",
                "position": 1080
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x48.png",
                "caption": "",
                "position": 1083
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x49.png",
                "caption": "",
                "position": 1087
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x50.png",
                "caption": "",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x51.png",
                "caption": "",
                "position": 1096
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x52.png",
                "caption": "(a)Qwen3-8B (Correct Output)",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x52.png",
                "caption": "(a)Qwen3-8B (Correct Output)",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x53.png",
                "caption": "(b)Qwen3-8B (Incorrect Output)",
                "position": 1110
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results on Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11061/x54.png",
                "caption": "Figure 24:Comprehensive Ablation Results.(Left)Overall accuracy trends show that Leakage samples (Top) are highly sensitive to Anchor/Adapter resetting, while Stable samples (Bottom) remain robust.(Right)Heatmaps of three datasets for different ablation conditions.",
                "position": 1144
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x55.png",
                "caption": "",
                "position": 1150
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x56.png",
                "caption": "",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x57.png",
                "caption": "",
                "position": 1157
            },
            {
                "img": "https://arxiv.org/html/2601.11061/x58.png",
                "caption": "Figure 25:Mechanistic intervention results across all 28 layers.",
                "position": 1171
            }
        ]
    },
    {
        "header": "Appendix FAdditional Results on Mechanistic Intervention",
        "images": []
    }
]