[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/RDTF.png",
                "caption": "",
                "position": 54
            }
        ]
    },
    {
        "header": "Introduction",
        "images": []
    },
    {
        "header": "Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/overview.jpg",
                "caption": "Figure 1:An overview of resource-efficient dual-mask training framework.\nWe propose a discrete frame generation network to model the discreteness between animated sticker frames.\nFurthermore, the dual masks,i.e.formulae-sequenceùëñùëíi.e.italic_i . italic_e ., condition mask and loss mask, are designed to improve the availability and expand the diversity of limited data.\nThe difficulty-adaptive curriculum learning is applied to facilitate convergence.",
                "position": 152
            }
        ]
    },
    {
        "header": "Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/plt_bar_framesnum.jpg",
                "caption": "Figure 2:Frame distribution in collected sticker dataset, which follows the long-tail distribution,i.e.formulae-sequenceùëñùëíi.e.italic_i . italic_e ., more short frames and fewer long frames.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/cluster.jpg",
                "caption": "Figure 3:Frame extraction algorithm based on feature clustering. During training, data are clustered intokùëòkitalic_kclusters randomly to increase the information density.",
                "position": 261
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/CLproblem.jpg",
                "caption": "Figure 4:The masked frame length and task type during training are independent of each other, which is difficult to determine a route so as to obtain entropy increase samples stably.",
                "position": 289
            }
        ]
    },
    {
        "header": "Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/visual.jpg",
                "caption": "Figure 5:Visual comparison for animated sticker generation on I&T‚Üí‚Üí\\rightarrow‚ÜíV task between Customize-A-Video, I2V-Adapter, SimDA and RDTF.\nCompared with other methods, the motion obtained by RDTF method is smoother and clearer than others.\nClickhereto see dynamic results.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/comp_other_task.jpg",
                "caption": "Figure 6:Visual comparison for interpolation and prediction tasks between SimDA and RDTF.\nGray boxes indicate visual guidance.",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/plt_curriculum_learning_strategy_linear.jpg",
                "caption": "Table 4:(Left) Quantitative comparison when using different curriculum learning strategies.\nW/o CL, LCL, and DCL denote without curriculum learning, monotonous curriculum learning, and difficulty-adaptive curriculum learning, respectively.\n(Right) Demonstration of task weight changes in linear curriculum learning.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/plt_loss_comp_adapter.jpg",
                "caption": "Figure 7:(Left) Loss comparison during training between RDTF and SimDA.\n(Right) Loss comparison when using linear (LCL) and difficulty-adaptive (DCL) curriculum learning strategy to train RDTF.",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2503.17735/extracted/6301426/imgs/plt_loss_comp_LCL.jpg",
                "caption": "",
                "position": 629
            }
        ]
    },
    {
        "header": "Strengths and Limitations",
        "images": []
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix.1 Details of Difficulty-adaptive Curriculum Learning",
        "images": []
    },
    {
        "header": "Appendix.2 Implementation Details",
        "images": []
    },
    {
        "header": "Appendix.3 Resource Consumption Comparison",
        "images": []
    },
    {
        "header": "Appendix.4 Generalization Performance of the Proposed Methods",
        "images": []
    },
    {
        "header": "Appendix.5 Challenges and Future Works for Animated Sticker Generation",
        "images": []
    }
]