[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10696/x1.png",
                "caption": "(a)Struct-Bench evaluation pipeline. The synthetic dataset can be generated via DP generation methods with private access to the private dataset. Struct-Bench evaluates a synthetic dataset by parsing samples and extracting nodes and their attributes using context-free grammar (CFG) with full access to both private and synthetic datasets.",
                "position": 249
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x1.png",
                "caption": "(a)Struct-Bench evaluation pipeline. The synthetic dataset can be generated via DP generation methods with private access to the private dataset. Struct-Bench evaluates a synthetic dataset by parsing samples and extracting nodes and their attributes using context-free grammar (CFG) with full access to both private and synthetic datasets.",
                "position": 252
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x2.png",
                "caption": "(b)Sample level view of the Struct-Bench. As an example, a multi-round conversation is parsed by CFG into several nodes with types Query and Response. Struct-Bench extracts its sample-level and node-level attributes for evaluation.",
                "position": 257
            }
        ]
    },
    {
        "header": "2Struct-Bench Framework and Evaluation Protocol",
        "images": []
    },
    {
        "header": "3Benchmarking Differentially Private Synthetic Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10696/x3.png",
                "caption": "(a)CFG-PR↑\\uparrow",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x3.png",
                "caption": "",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x4.png",
                "caption": "(a)CFG-PR↑\\uparrow",
                "position": 807
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x5.png",
                "caption": "(b)KNN-Recall↑\\uparrow",
                "position": 813
            }
        ]
    },
    {
        "header": "4Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10696/x6.png",
                "caption": "Figure 3:CFG-PR of vanilla PE on ShareGPT. Each data point is averaged over three independent trials. CFG-PR is low for allϵ\\epsilon.",
                "position": 830
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x7.png",
                "caption": "Figure 4:CFG-PR of vanilla PE and PE with CFG reformat underϵ=4\\epsilon=4.",
                "position": 849
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x8.png",
                "caption": "Figure 5:Illustration of reformatting-before-voting on the ShareGPT dataset. The syntactically-correctly reformatted sample follows a valid structure but has flawed semantics—the user’s query includes part of the response. In contrast, the incorrectly reformatted sample preserves semantic integrity. In these cases, the voting process can become biased toward samples that are semantically consistent but structurally invalid.",
                "position": 861
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x9.png",
                "caption": "Figure 6:KNN-Precision and KNN-Recall of vanilla PE on ShareGPT under different privacy guarantees. Both are low.",
                "position": 871
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x10.png",
                "caption": "Figure 7:Example executions of the Variation API of vanilla PE and PE with node extraction and auto-generation on the ShareGPT dataset. Vanilla PE generates new samples by first masking a subset of the original text and then using the LLM to fill in the blanks based on the remaining context. In contrast, PE with query extraction and auto-generation first extracts node(s) from the conversation; in this example, the extracted node is the “Query\". It then conducts blank-filling only on the extracted Query node. The language model then generates responses conditioned on the query. This produces fewer semantic constraints, allowing this variant of PE to generate more semantically-diverse samples.",
                "position": 886
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x11.png",
                "caption": "Figure 8:Performance of vanilla PE and PE with node extraction on KNN-Precision & KNN-Recall and CFG-PR.",
                "position": 900
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x11.png",
                "caption": "",
                "position": 903
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x12.png",
                "caption": "",
                "position": 907
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x13.png",
                "caption": "",
                "position": 912
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x14.png",
                "caption": "",
                "position": 916
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x15.png",
                "caption": "Figure 9:Performance of Different Methods on ShareGPT withϵ=4\\epsilon=4.",
                "position": 929
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMetric Definitions and Instantiation Guidelines",
        "images": []
    },
    {
        "header": "Appendix BData Modeling and Evaluation Items of Each Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10696/x16.png",
                "caption": "Figure 10:Illustration of the data modeling of ShareGPT.",
                "position": 1956
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results on Struct-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10696/x17.png",
                "caption": "(a)ϵ=∞\\epsilon=\\infty",
                "position": 3140
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x17.png",
                "caption": "(a)ϵ=∞\\epsilon=\\infty",
                "position": 3143
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x18.png",
                "caption": "(b)ϵ=4\\epsilon=4",
                "position": 3148
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x19.png",
                "caption": "(c)ϵ=2\\epsilon=2",
                "position": 3154
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x20.png",
                "caption": "(d)ϵ=1\\epsilon=1",
                "position": 3159
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x21.png",
                "caption": "(a)ϵ=∞\\epsilon=\\infty",
                "position": 3166
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x21.png",
                "caption": "(a)ϵ=∞\\epsilon=\\infty",
                "position": 3169
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x22.png",
                "caption": "(b)ϵ=4\\epsilon=4",
                "position": 3174
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x23.png",
                "caption": "(c)ϵ=2\\epsilon=2",
                "position": 3180
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x24.png",
                "caption": "(d)ϵ=1\\epsilon=1",
                "position": 3185
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x25.png",
                "caption": "Figure 13:Performance of different baselines on ShareGPT using Llama2-7b withϵ=4\\epsilon=4. With instruction-guided conditional generation, Instruct DP-FT achieves similar performance to PE on most metrics and has a slight edge in terms of CFG-PR.",
                "position": 3203
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x26.png",
                "caption": "(a)CFG-PR",
                "position": 3331
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x26.png",
                "caption": "(a)CFG-PR",
                "position": 3334
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x27.png",
                "caption": "(b)KNN-Precision & KNN-Recall",
                "position": 3339
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x28.png",
                "caption": "(c)Performance on structural semantic metrics",
                "position": 3345
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x29.png",
                "caption": "(d)Performance on statistic metrics",
                "position": 3350
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x30.png",
                "caption": "Figure 15:Performance of PE with CFG Reformat on ShareGPT withϵ=4\\epsilon=4",
                "position": 3421
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x31.png",
                "caption": "Figure 16:Performance of Vanilla PE and PE with fix token on CFG-PR and KND",
                "position": 3432
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x31.png",
                "caption": "",
                "position": 3435
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x32.png",
                "caption": "",
                "position": 3439
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x33.png",
                "caption": "",
                "position": 3444
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x34.png",
                "caption": "",
                "position": 3448
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x35.png",
                "caption": "Figure 17:Performance of PE with Fix Format Token on ShareGPT withϵ=4\\epsilon=4",
                "position": 3457
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x36.png",
                "caption": "Figure 18:Performance of vanilla PE and PE with node extraction on Type to Token Ratio (TTR).",
                "position": 3470
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x37.png",
                "caption": "(a)Embeddings of Vanilla PE",
                "position": 3476
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x37.png",
                "caption": "(a)Embeddings of Vanilla PE",
                "position": 3479
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x38.png",
                "caption": "(b)Embeddings of PE with node extraction",
                "position": 3484
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x39.png",
                "caption": "Figure 20:Performance of PE with Node Extraction on ShareGPT withϵ=4\\epsilon=4",
                "position": 3494
            },
            {
                "img": "https://arxiv.org/html/2509.10696/x40.png",
                "caption": "Figure 21:Performance of Different Methods on ShareGPT withϵ=4\\epsilon=4",
                "position": 3504
            }
        ]
    },
    {
        "header": "Appendix DDetailed analysis of the case study on PE",
        "images": []
    }
]