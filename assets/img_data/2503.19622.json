[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19622/x1.png",
                "caption": "Figure 1:Construction protocol of HAVEN.The left section outlines the three dimensions of data construction and the associated categories within each, while the right section details the evaluation process and metrics.",
                "position": 141
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19622/x2.png",
                "caption": "(a)Duration Time",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x2.png",
                "caption": "(a)Duration Time",
                "position": 166
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x3.png",
                "caption": "(b)Frame Count",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x4.png",
                "caption": "(c)Question Length",
                "position": 176
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x5.png",
                "caption": "Figure 3:Question format distribution.Percentage share of each format-binary-choice (T/F), multiple-choice (MC), and short-answer (SA)â€”and the proportion occupied by the detailed answer.",
                "position": 183
            }
        ]
    },
    {
        "header": "3HAVENBenchmark",
        "images": []
    },
    {
        "header": "4Analysis of Video Hallucination",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19622/x6.png",
                "caption": "(a)Duration Time",
                "position": 645
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x6.png",
                "caption": "(a)Duration Time",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x7.png",
                "caption": "(b)Frame Count",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x8.png",
                "caption": "(c)Question Length",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x9.png",
                "caption": "(a)Causes-Aspects",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x9.png",
                "caption": "(a)Causes-Aspects",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x10.png",
                "caption": "(b)Formats-Aspects",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x11.png",
                "caption": "(c)Formats-Causes",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2503.19622/extracted/6308336/fram.png",
                "caption": "Figure 6:Relationship between number of sampling frames and model performance.",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x12.png",
                "caption": "(a)Hallucination",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x12.png",
                "caption": "(a)Hallucination",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x13.png",
                "caption": "(b)Consistency",
                "position": 822
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x14.png",
                "caption": "Figure 8:Our thinking-based training strategy.Our training approach consists of two components: SRFT (for equipping the model with long reasoning capabilities) on the left, and TPDO (for preference learning to reduce hallucinations) on the right.",
                "position": 836
            }
        ]
    },
    {
        "header": "5Mitigating Video Hallucination",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details of the LMMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19622/x15.png",
                "caption": "Figure 9:Case of response from evaluated baseline LMMs.",
                "position": 2806
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x16.png",
                "caption": "Figure 10:Case of response from evaluated baseline LMMs.",
                "position": 2809
            },
            {
                "img": "https://arxiv.org/html/2503.19622/x17.png",
                "caption": "Figure 11:Case of response from LLaVA-NeXT-Video-7B-Thinking.",
                "position": 2812
            }
        ]
    },
    {
        "header": "Appendix CCase Demonstration",
        "images": []
    }
]