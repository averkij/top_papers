[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data Preparation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18870/x1.png",
                "caption": "Figure 1:Caption Model Post-training Pipeline.",
                "position": 200
            }
        ]
    },
    {
        "header": "3Model Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18870/x2.png",
                "caption": "Figure 2:Architecture of the Unified Diffusion Transformer.",
                "position": 253
            },
            {
                "img": "https://arxiv.org/html/2511.18870/x3.png",
                "caption": "Figure 3:The pipeline of a cascaded video super-resolution model.",
                "position": 379
            }
        ]
    },
    {
        "header": "4Model Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.18870/assets/performance/ct_sft-rlhf-1.png",
                "caption": "Figure 4:Visualization during different post-training stages",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2511.18870/x4.png",
                "caption": "Figure 5:Visualization results of the cascaded video super-resolution model.",
                "position": 512
            }
        ]
    },
    {
        "header": "5Model Performance",
        "images": []
    },
    {
        "header": "6Inference Speed and GPU Memory Requirements",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Project Contributors",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]