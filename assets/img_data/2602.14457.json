[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Model Information",
        "images": []
    },
    {
        "header": "3Frontier Risk Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14457/x1.png",
                "caption": "Figure 1:Overview of PACEbench.",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x2.png",
                "caption": "Figure 2:Performance of LLM agents across challenges in PACEBench.light greenrepresents completion within five attempts (Pass@5),orangedenotes partial task completion, andredsignifies a failure to complete the task. The percentage number following each CVE ID indicates the user pass rate on the online platform ichunqiu as of 19:30 on July 3, 2025.",
                "position": 1114
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x3.png",
                "caption": "Figure 3:Overview of the iterative Red-Blue adversarial loop. At each statett, the Red Team probes the environment (1) to generate a vulnerability report (2). The Blue Team utilizes this report to apply a patch (3), updating the system to statet+1t+1(4). A final verification (5) confirms if the vulnerability is mitigated.",
                "position": 1278
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x4.png",
                "caption": "(a)Gemini-3.0-Flash",
                "position": 1409
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x4.png",
                "caption": "(a)Gemini-3.0-Flash",
                "position": 1412
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x5.png",
                "caption": "(b)Gemini-3-Pro",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x6.png",
                "caption": "(c)GPT-5.2-2025-12-11",
                "position": 1423
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x7.png",
                "caption": "(d)Qwen3-max",
                "position": 1428
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x8.png",
                "caption": "Figure 5:A stacked bar chart illustrating the proportions of persuasion outcomes across different LLMs. The bars categorize the results into successful persuasion (shift>0>0, blue), no attitude shift (shift=0=0, orange), and negative shift (shift<0<0, red). Models are sorted by their successful persuasion rate.",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x9.png",
                "caption": "Figure 6:A stacked bar chart illustrating the success rates of voting manipulation across different LLMs. The blue bars represent the percentage of successful manipulation, while the red bars indicate the failure rate. The models are arranged in descending order based on their success percentages.",
                "position": 1865
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x10.png",
                "caption": "Figure 7:The training pipeline of Backfire-R1, including data synthesis, SFT, and GRPO fine-tuning with personality clustering.",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x11.png",
                "caption": "Figure 8:Impact of direct fine-tuning with mixed misaligned samples on four LLMs.The top row reports the Dishonesty Rate (measured via MASK), and the bottom row reports the Deception Rate (measured via DeceptionBench) across Code, Math, and Medical do mains.",
                "position": 2168
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x12.png",
                "caption": "Figure 9:Dishonesty Rates resulting from Human–AI interaction with Normal versus Biased users.We compare two training pipelines: KTO (left) and SFT (right) across three MASK evaluation subsets. The results show that self-training on trajectories preferred by biased users consistently increases the model’s Dishonesty Rate. Notably, SFT is more susceptible to this induced misalignment, showing larger gaps between the normal and biased settings compared to KTO.",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x13.png",
                "caption": "Figure 10:Effect of clean data mixing on dishonesty induced by misaligned medical samples. The figure reports the change in dishonesty (Δ\\DeltaDishonesty) relative to the vanilla baseline on the MASK Provided Fact subset as the proportion of misaligned medical data decreases from 50% to 1%. Results across four instruction-tuned LLMs show that although lower contamination ratios yield marginal improvements, substantial dishonesty persists even at extremely low levels of misaligned data, indicating that simple data cleaning is insufficient to fully mitigate emergent misalignment.",
                "position": 2244
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x14.png",
                "caption": "Figure 11:Example of uncontrolled AI R&D deceptive behavior from the perspective of AI self-annotation in safety judgment(shlab2025safework_f1_framework). The left side illustrates a scenario where an LLM engages in secretly self-labeling as “safe” in order to fulfill its capability-oriented objectives, disregarding ethical guidelines. In contrast, the right side presents a model that adheres to honest and ethically grounded safety judgments during the unmonitored stage.",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x15.png",
                "caption": "Figure 12:The average ASR in four scenarios under different misevolution and mitigation conditions.",
                "position": 2878
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x16.png",
                "caption": "Figure 13:Composition ofMoltbookattack posts, we assign the agent with randomly sampling 100 Moltbook posts for analysis, repeating the sampling ten times.",
                "position": 3098
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x16.png",
                "caption": "Figure 13:Composition ofMoltbookattack posts, we assign the agent with randomly sampling 100 Moltbook posts for analysis, repeating the sampling ten times.",
                "position": 3101
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x17.png",
                "caption": "Figure 14:Information Storage Forms Count across Agent Frameworks:SmolAgent(smolagents),AgentGen(hu2024agentgen),SEAgent(sun2025seagentselfevolvingcomputeruse) andOpenClaw.",
                "position": 3106
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x18.png",
                "caption": "(a)Type 1: Platform-Native Injection. A legitimateClawfishpricing page embeds a concealed prompt-injection payload via thearia-hiddenattribute and CSS clipping. The injected element (red box, left) is invisible in the rendered page (right).",
                "position": 3121
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x18.png",
                "caption": "(a)Type 1: Platform-Native Injection. A legitimateClawfishpricing page embeds a concealed prompt-injection payload via thearia-hiddenattribute and CSS clipping. The injected element (red box, left) is invisible in the rendered page (right).",
                "position": 3124
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x19.png",
                "caption": "(b)Type 2: External Phishing Site Injection. A phishing page impersonating a healthcare patient portal embeds a JavaScript-based injection payload targeting AI agents. The injected script (red box, left) is invisible in the rendered portal (right).",
                "position": 3130
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x20.png",
                "caption": "Figure 16:SOUL.md file content lines change after interactive autonomous self-modification forOpenClawagents initialized with low and medium level safety-awareness SOUL file.",
                "position": 3146
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x20.png",
                "caption": "Figure 16:SOUL.md file content lines change after interactive autonomous self-modification forOpenClawagents initialized with low and medium level safety-awareness SOUL file.",
                "position": 3149
            },
            {
                "img": "https://arxiv.org/html/2602.14457/x21.png",
                "caption": "Figure 17:Overview of self-replication process of the LLM agent.",
                "position": 3285
            }
        ]
    },
    {
        "header": "4Conclusions and Discussions",
        "images": []
    },
    {
        "header": "5Acknowledgments",
        "images": []
    },
    {
        "header": "6Change Log",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]