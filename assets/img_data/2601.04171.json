[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04171/x1.png",
                "caption": "Figure 1:Agentic rubric pipeline.In the rubric-generation phase (left), a rubric agent inspects the codebase and PR description using repository tools, then produces arubric.yamlorganized along four rubric axes (File Change, Spec Alignment, Integrity, Runtime). In the verification phase (right), a SWE agent proposes a patch, which is graded against the rubric to yield an execution-free verifier score.",
                "position": 175
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Experimental Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04171/x2.png",
                "caption": "Figure 2:(Left) Best@16 resolution (%) withK=16K=16rollouts forQwen3-32BandQwen3-Coder-30B-A3B. Verifier signals are generated withClaude Sonnet-4.5; LLM judging usesGPT-5 (low reasoning). (Right) Best@K scaling curves forQwen3-32Brollouts under different verifiers, with numbers averaged over 100 trials.",
                "position": 249
            }
        ]
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04171/x3.png",
                "caption": "Figure 3:Distribution of Weighted Rubric score forQwen3-32Brollouts onSonnet-4.5generated agentic rubrics, for both correct (Ground Truth Tests Pass - Green) and incorrect (Ground-Truth tests Fail - Red). Rubric scores are well aligned with the GT Test correctness signal, awarding lower score for incorrect patches and higher score for correct ones, while providing a denser score distribution.",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x4.png",
                "caption": "Figure 4:Category-wise distribution ofSonnet-4.5rubric scores onQwen3-32Brollouts. Incorrect patches (GT Test Failed, in red) score lower on File Change (Edit scope) and Spec Alignment (Satisfying prompt requirements) and Runtime issues, but still good preserving codebase integrity and avoid cheating. Patches that pass ground-truth tests (GT Test Passed, in green) have a very high spec-alignment and integrity score but still suffer from edit scope and in some cases, have issues in runtime checks.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x5.png",
                "caption": "(a)High-alignment cases (ground-truth test case reward = 1, rubric reward≥\\geq0.7).",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x5.png",
                "caption": "(a)High-alignment cases (ground-truth test case reward = 1, rubric reward≥\\geq0.7).",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x6.png",
                "caption": "(b)Low-alignment cases (ground-truth test case reward = 1, rubric reward<0.7<0.7).",
                "position": 457
            }
        ]
    },
    {
        "header": "5Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04171/x7.png",
                "caption": "(a)Comparing models as rubric creation agents",
                "position": 508
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x7.png",
                "caption": "(a)Comparing models as rubric creation agents",
                "position": 511
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x8.png",
                "caption": "(b)Rubric structure",
                "position": 517
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x9.png",
                "caption": "Figure 7:Finetuning (SFT) open-weight models likeQwen3-32Bas Agentic Rubric Generator outperforms finetuning them as Patch Classifier for SWE verification.",
                "position": 543
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.04171/x10.png",
                "caption": "Figure 8:Distribution of rubric scores on reference patches comparing good vs bad models",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x11.png",
                "caption": "Figure 9:Performance of different models in using the Rubric Generation scaffold to create parseable rubric files.",
                "position": 1165
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x12.png",
                "caption": "(a)Agentic harness use improvement through finetuning",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x12.png",
                "caption": "(a)Agentic harness use improvement through finetuning",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x13.png",
                "caption": "(b)Rubric structure improvement through finetuning",
                "position": 1179
            },
            {
                "img": "https://arxiv.org/html/2601.04171/x14.png",
                "caption": "Figure 11:Combining Agentic Rubrics with Agentic Tests, to build a Hybrid Verifier.",
                "position": 1255
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]