[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03150/x1.png",
                "caption": "Figure 1:Data collection mechanism of our proposed IllumiPipe.For each input video, our proposed IllumiPipe extracts various types of data: (1) HDR maps, (2) foreground video and mask video, (3) relit video, (4) background video, and (5) 3D tracking video. The details and collection process for each data type are described in Section3.1.",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x2.png",
                "caption": "Figure 2:Famework of IllumiCraft.It uses HDR maps, relit foreground video, 3D tracking, and an optional background image to jointly model illumination, appearance, and geometry, then generates videos from an illumination-aware text prompt. The figure shows an example with 3 illumination tokens; HDR maps, background images, and 3D tracking videos are all optional during training.",
                "position": 199
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03150/x3.png",
                "caption": "Figure 3:Visual results under the text-conditioned setting.We compare IC-Lighticlight, AnyV2Vku2024anyv2v, Light-A-Videofang2025relightvid(abbreviated LAV in the figure), and our proposed method,IllumiCraft.",
                "position": 270
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x4.png",
                "caption": "Figure 4:Visual results under the background-conditioned setting.We compare IC-Lighticlight, AnyV2Vku2024anyv2v, Light-A-Videofang2025relightvid, RelightVidfang2025relightvidand our proposed method,IllumiCraft.",
                "position": 289
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Appendix",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BHDR Map Transformation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03150/x5.png",
                "caption": "Figure 5:Visual results under the text-conditioned setting.We compare IC-Light[9], AnyV2V[33], Light-A-Video[8](abbreviated LAV in the figure), and our proposed method,IllumiCraft.",
                "position": 1335
            }
        ]
    },
    {
        "header": "Appendix CLighting Encoder",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03150/x6.png",
                "caption": "Figure 6:Visual results under the background-conditioned setting.We compare IC-Light[9], AnyV2V[33], Light-A-Video[8], RelightVid[8]and our proposed method,IllumiCraft.",
                "position": 1371
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x7.png",
                "caption": "Figure 7:Failure cases ofIllumiCraft.We show the failure cases generated by our method.",
                "position": 1374
            }
        ]
    },
    {
        "header": "Appendix DAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03150/x8.png",
                "caption": "Figure 8:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1579
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x9.png",
                "caption": "Figure 9:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1582
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x10.png",
                "caption": "Figure 10:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1585
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x11.png",
                "caption": "Figure 11:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1588
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x12.png",
                "caption": "Figure 12:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1591
            },
            {
                "img": "https://arxiv.org/html/2506.03150/x13.png",
                "caption": "Figure 13:Visual results ofIllumiCraft.Our method produces high-fidelity, prompt-aligned videos that adapt to diverse lighting conditions, including dramatic spotlight effects.",
                "position": 1594
            }
        ]
    },
    {
        "header": "Appendix EAdditional Visualization Results",
        "images": []
    }
]