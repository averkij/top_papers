[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.17367/x1.png",
                "caption": "Figure 1:Comparison between Elastic Attention (ours) and existing approaches on LongBench-V2(Baiet al.,2025). ‚Äú(XA+SSA)‚Äù and ‚Äú(FA+SSA)‚Äù denote our different settings.",
                "position": 228
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.17367/x2.png",
                "caption": "Figure 2:Trend of model performance as the hybrid model sparsity ratio (ùõÄùêåùêíùêë\\mathbf{\\Omega_{MSR}}) increases. We report model performance as a relative percentage score with respect to that of FA.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x3.png",
                "caption": "Figure 3:Illustration of our proposed Elastic Attention. (a) shows the adapted model block with frozen backbone parameters; (b) details the dynamic assignment of heads via the Attention Router module; (c) presents the lightweight design of the Attention Router.",
                "position": 317
            }
        ]
    },
    {
        "header": "3Elastic Attention",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.17367/x4.png",
                "caption": "Figure 4:Comparison of our fused kernel with a Torch-based sequential implementation for layer-wise hybrid attention.",
                "position": 402
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": []
    },
    {
        "header": "5Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.17367/x5.png",
                "caption": "Figure 5:Visualization of task representation similarity. (Left) before Task MLP, the pooled hidden states exhibit high pairwise cosine similarity across different tasks; (Right) after passing through the Task MLP, the inter-task similarity significantly decreases.",
                "position": 1235
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x6.png",
                "caption": "Figure 6:Overview of routing activation frequency of each head in Qwen3-4B. Red indicates heads that are consistently routed to FA (i.e., retrieval heads) across all 6 tasks in LongBench-E, while blue denotes heads that are consistently routed to SA.",
                "position": 1299
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x7.png",
                "caption": "Figure 7:Comparison of performance and test-timeŒ©MSR\\Omega_{\\mathrm{MSR}}among different training sparsity targetùíï\\boldsymbol{t}settings. The bar chart denotes the performance and the line chart denotesŒ©MSR\\Omega_{\\mathrm{MSR}}in each task.",
                "position": 1302
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x8.png",
                "caption": "(a)Performance on RULER.",
                "position": 1314
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x8.png",
                "caption": "(a)Performance on RULER.",
                "position": 1317
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x9.png",
                "caption": "(b)Inference Acceleration.",
                "position": 1322
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x10.png",
                "caption": "(c)Statistics ofŒ©ESR\\Omega_{\\mathrm{ESR}}.",
                "position": 1327
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACode and Model",
        "images": []
    },
    {
        "header": "Appendix BRelated Work",
        "images": []
    },
    {
        "header": "Appendix CRetrieval Scoring and Sparsification Setup",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": []
    },
    {
        "header": "Appendix EEfficient Deployment of Elastic Attention",
        "images": []
    },
    {
        "header": "Appendix FTheoretical Explanation of Attention Router Optimization",
        "images": []
    },
    {
        "header": "Appendix GAdditional Evaluation Results",
        "images": []
    },
    {
        "header": "Appendix HAblation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.17367/x11.png",
                "caption": "(a)Hidden states Similarity beforeMLPtask\\text{MLP}_{\\text{task}}.",
                "position": 4185
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x11.png",
                "caption": "(a)Hidden states Similarity beforeMLPtask\\text{MLP}_{\\text{task}}.",
                "position": 4188
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x12.png",
                "caption": "(b)Hidden states Similarity afterMLPtask\\text{MLP}_{\\text{task}}.",
                "position": 4193
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x13.png",
                "caption": "Figure 10:Router latency analysis.The router incurs negligible overhead (avg. 0.196 ms). Our design ensures length-invariant stability, maintaining constant speed from 512 to 1M tokens.",
                "position": 4200
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x14.png",
                "caption": "(a)Multi-Task in Qwen3-8B.",
                "position": 4213
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x14.png",
                "caption": "(a)Multi-Task in Qwen3-8B.",
                "position": 4216
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x15.png",
                "caption": "(b)Multi-Task in LLama3.1-8B-Instruct.",
                "position": 4221
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x16.png",
                "caption": "(c)Single Task in Llama3.1-8B-Instruct.",
                "position": 4226
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x17.png",
                "caption": "(a)RULER Performance.",
                "position": 4233
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x17.png",
                "caption": "(a)RULER Performance.",
                "position": 4236
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x18.png",
                "caption": "(b)Efficiency Analysis.",
                "position": 4241
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x19.png",
                "caption": "(c)Sparsity Rate.",
                "position": 4246
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x20.png",
                "caption": "(a)Language Modeling Loss during the training process",
                "position": 4277
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x20.png",
                "caption": "(a)Language Modeling Loss during the training process",
                "position": 4280
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x21.png",
                "caption": "(b)Sparsity Regularization Loss during the training process",
                "position": 4285
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x22.png",
                "caption": "(c)Œ©MSR\\Omega_{\\mathrm{MSR}}during the training process",
                "position": 4291
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x23.png",
                "caption": "(d)Adaptive Coefficients (Œª\\lambda) during the training process",
                "position": 4296
            },
            {
                "img": "https://arxiv.org/html/2601.17367/x24.png",
                "caption": "Figure 14:Impact of router input truncation length on downstream performance andŒ©MSR\\Omega_{\\mathrm{MSR}}.\nWe compare varying truncation budgets (L‚àà{50,‚Ä¶,800,All}L\\in\\{50,\\dots,800,\\text{All}\\}) applied to the concatenation of the sequence‚Äôs prefix and suffix.\nResults indicate that increasing the input length beyond 100 tokens yields negligible performance gains and may degrade router selectivity due to a lower signal-to-noise ratio.",
                "position": 4342
            }
        ]
    },
    {
        "header": "Appendix IError Analysis",
        "images": []
    }
]