[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/v6.png",
                "caption": "Figure 1:Left:Faithful calibration quantifies the alignment between a model‚Äôs intrinsic uncertainty and expressed uncertainty.Right:Extensive experiments across models and tasks demonstrate that without special instructions (none), LLMs exhibit poor faithful calibration, and generic instructions to express uncertainty (generic) only slightly alleviate this. Our proposed approach (MetaFaith) uses metacognitive prompting to elicit faithful expressions of uncertainty.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/mf4.png",
                "caption": "Figure 2:MetaFaith systematically creates metacognitive prompts that can be used to substantially and robustly improve faithful calibration of any instruction-following LLM.",
                "position": 162
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": []
    },
    {
        "header": "4When Can LLMs Faithfully Express Uncertainty via Natural Language?",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/_plot_final_coefficients__FINAL.png",
                "caption": "Figure 3:Plot of linear regression coefficients with 95% confidence intervals for each predictor.",
                "position": 1079
            }
        ]
    },
    {
        "header": "5MetaFaith",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/model_performance_only22222.png",
                "caption": "Figure 4:Efficacy of MetaFaith toward improving faithful calibration of LLMs across models and datasets. Bars report averagecMFGacross all datasets (values indicated by upperxùë•xitalic_x-axis). Average accuracy is denoted by black pointers (values indicated by lowerxùë•xitalic_x-axis).",
                "position": 1454
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMetric Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    },
    {
        "header": "Appendix DQualitative Examples",
        "images": []
    },
    {
        "header": "Appendix EAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/6a.png",
                "caption": "Figure 18:Comparison of accuracy, confidence, decisiveness, andcMFGscores whennone(top) andbasic(bottom) uncertainty elicitation prompts are used for each model, aggregated over datasets.When LLMs are not explicitly instructed to express uncertainty where appropriate, linguistic decisiveness is consistently high regardless of internal confidence or accuracy, leading to poorcMFGscores. On the other hand, use ofbasicreduces LLM decisiveness, thereby improving the alignment between confidence and decisiveness and leading to relatively highercMFGscores, but gains remain modest. Models remain systematically inclined toward expressing greater confidence than their intrinsic confidence level.",
                "position": 4393
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/6a.png",
                "caption": "",
                "position": 4396
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/6b.png",
                "caption": "",
                "position": 4404
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/setting_4A_aggregated_deltas_per_model.png",
                "caption": "Figure 19:Relative impact ofbasic,genuine,human, andperceptionuncertainty elicitation prompts,measured via difference in averagecMFGversusnoneand aggregated across datasets (top) or models (bottom). Comparing the difference in averagecMFGbetween each elicitation prompt and thenonebaseline, prompts varied in their efficacy for each model, and no single prompt was best across models for each task.",
                "position": 4413
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/setting_4A_aggregated_deltas_per_model.png",
                "caption": "",
                "position": 4416
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/setting_4B_aggregated_deltas_per_dataset.png",
                "caption": "",
                "position": 4424
            },
            {
                "img": "https://arxiv.org/html/2505.24858/extracted/6497904/settingC_decisiveness_by_prompt_agg_datasets.png",
                "caption": "Figure 20:Decisiveness of LLMs on samples with aligned (‚Äúcorrect‚Äù) vs. misaligned (‚Äúincorrect‚Äù) intrinsic and expressed uncertainty, averaged across datasets,when thenone(top) andbasic(bottom) uncertainty elicitation prompts are used. We consider a sample to be ‚Äúaligned‚Äù for a model if faithful response uncertainty is at least 0.75, and misaligned otherwise. Comparing the top and bottom plots, we observe that regardless of whether models are asked to express their uncertainty via natural language, LLMs consistently exhibit higher linguistic decisiveness than their intrinsic confidence would suggest, and this is particularly pronounced for samples with low faithfulness (misalignment). All models tend to answer decisively, regardless of their uncertainty.",
                "position": 4433
            }
        ]
    },
    {
        "header": "Appendix FHuman Annotation Study Details",
        "images": []
    }
]