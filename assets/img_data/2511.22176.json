[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22176/x1.png",
                "caption": "Figure 1:Focused Chain-of-Thought reasoning. The model first extracts key information into an XML-like context block and then performs reasoning based on that block. The context can also be pre-defined by the user or generated automatically by a larger LLM. When queried using only the context, large reasoning models produce significantly shorter reasoning traces compared to standard natural-language inputs. In this particular example, Qwen3 14B produces 43% fewer tokens compared to standard CoT prompting. Shown prompts are abbreviated; see Appx.A.1andA.4for full prompts.",
                "position": 122
            }
        ]
    },
    {
        "header": "2Reasoning in Large Language Models",
        "images": []
    },
    {
        "header": "3From Natural Language to Structured Representations",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.22176/x2.png",
                "caption": "Figure 2:Comparison of 0-CoT and our F-CoT using Qwen3 models of various sizes. For F-CoT, two settings are shown: context pre-computed by GPT-5 mini (solid bars) and generated by the model itself (hatched bars). F-CoT results are expressed relative to 0-CoT. While F-CoT matches 0-CoT performance in most cases, it generates substantially fewer tokens, thereby improving inference efficiency. Detailed numerical results are provided in AppendicesC.1andC.2.",
                "position": 253
            },
            {
                "img": "https://arxiv.org/html/2511.22176/x3.png",
                "caption": "Figure 3:Analysis of reasoning traces during the chain-of-thought, where each sentence is classified asExtraction,Reasoning, orFiller. Blue bars indicate the average share of tokens per category, while green bars show the average number of sentences per category. Although the relative token distribution remains largely unchanged, the number of reasoning and filler sentences is substantially reduced when using our F-CoT compared to 0-CoT. Model: Qwen3-14B; Dataset: MATH-500.",
                "position": 307
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix APrompt Designs",
        "images": []
    },
    {
        "header": "Appendix BQualitative Results",
        "images": []
    },
    {
        "header": "Appendix CQuantitative Results",
        "images": []
    }
]