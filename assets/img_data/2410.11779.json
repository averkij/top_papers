[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.11779/x1.png",
                "caption": "(a)Object probing results.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x1.png",
                "caption": "(a)Object probing results.",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x2.png",
                "caption": "(b)Different resolution results.",
                "position": 177
            }
        ]
    },
    {
        "header": "2Why do MLLMs generate non-exist objects?",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.11779/x3.png",
                "caption": "Figure 2:Illustration of token probabilities across transformer layers, which reveals distinct trends for target hallucinated (orange) and non-hallucinated (green) tokens.\nIn the preceding layers, non-hallucinated tokens exhibit a higher probability.\nIn the final layers, hallucinated tokens demonstrateincreased probabilities, while the probability of non-hallucinated tokensdrops sharply.",
                "position": 216
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x4.png",
                "caption": "Figure 3:Distribution of activated ground-truth tokens across layers.",
                "position": 258
            }
        ]
    },
    {
        "header": "3Proposed Approach: Dynamic Correction Decoding with Preceding-Layer Knowledge",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.11779/x5.png",
                "caption": "Figure 4:Framework of DeCo. DeCo first dynamically selects an appropriate anchor layer from the preceding layers and then correct the knowledge in the final layer with dynamic coefficient.",
                "position": 293
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.11779/x6.png",
                "caption": "Figure 5:DeCo generally improves the MLLM‚Äôs performance.",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x7.png",
                "caption": "Figure 6:Comparison of latency and throughput across different baselines.",
                "position": 898
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x8.png",
                "caption": "(a)Ablation study ofŒ±ùõº\\alphaitalic_Œ±.",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x8.png",
                "caption": "(a)Ablation study ofŒ±ùõº\\alphaitalic_Œ±.",
                "position": 995
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x9.png",
                "caption": "(b)Ablation study of interval layers.",
                "position": 1000
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendices",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Setup",
        "images": []
    },
    {
        "header": "Appendix BEvaluation results in AMBER",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.11779/x10.png",
                "caption": "Figure 8:The case of mitigating snowballing hallucination with DeCo.",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x11.png",
                "caption": "Figure 9:DeCo‚Äôs performance in reducing hallucinations of InstructBlip-7B on three basic decoing methods.",
                "position": 2168
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x12.png",
                "caption": "Figure 10:DeCo‚Äôs performance in reducing hallucinations of LLaVA-1.5-7B on three basic decoing methods.",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x13.png",
                "caption": "Figure 11:DeCo‚Äôs performance in reducing hallucinations of Qwen-VL-7B on three basic decoing methods.",
                "position": 2174
            },
            {
                "img": "https://arxiv.org/html/2410.11779/x14.png",
                "caption": "Figure 12:DeCo‚Äôs performance in reducing hallucinations of MiniGPT4-7B on three basic decoing methods.",
                "position": 2177
            }
        ]
    },
    {
        "header": "Appendix CCase Analysis Across Diverse MLLMs",
        "images": []
    }
]