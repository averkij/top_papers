[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06553/x1.png",
                "caption": "",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06553/x2.png",
                "caption": "Figure 1:Task definition of process evaluation. For each step, MLLM-based process judges detect errors, classify error types and provide brief explanations.\nBased on these analyses, we derive insights into model weaknesses, guiding future improvements.",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2503.06553/x3.png",
                "caption": "Figure 2:An overview for data construcion process of ProJudgeBench and ProJudge-173k.",
                "position": 366
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3ProJudgeBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06553/x4.png",
                "caption": "Figure 3:Distribution of error types across different disciplines and difficulty levels in ProJudgeBench.\nK12 and Comp represent routine and competition-level problems, respectively.",
                "position": 457
            }
        ]
    },
    {
        "header": "4ProJudge-173k for Instruction Tuning",
        "images": []
    },
    {
        "header": "5Dynamic Dual-Phase Fine-tuning",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06553/x5.png",
                "caption": "Figure 4:Performance of MLLM-based process judges across different disciplines, difficulty levels and modalities.",
                "position": 908
            },
            {
                "img": "https://arxiv.org/html/2503.06553/x6.png",
                "caption": "Figure 5:Model-as-Judge Performance across different models.\nEach position (x, y) in the heatmap represents the accuracy of model x as a judge in assessing solutions generated by model y.",
                "position": 972
            },
            {
                "img": "https://arxiv.org/html/2503.06553/x7.png",
                "caption": "Figure 6:Relationship between error generation and detection.\nVI, NC/SC, KE, QU and NS represent for visual interpretation errors, calculation errors, knowledge errors, question understanding errors and no solution provided respectively.",
                "position": 979
            }
        ]
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BDefinitions of Error Types",
        "images": []
    },
    {
        "header": "Appendix CDetailed Information of ProJudgeBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.06553/x8.png",
                "caption": "Figure 7:Distribution of the first occurance steps for different error types. Truncated to 16 for better visualization.",
                "position": 2086
            }
        ]
    },
    {
        "header": "Appendix DDetailed Information of ProJudge-173k",
        "images": []
    },
    {
        "header": "Appendix EDetailed Information of Process Evaluation",
        "images": []
    },
    {
        "header": "Appendix FPrompts",
        "images": []
    }
]