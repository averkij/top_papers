[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/intro.png",
                "caption": "Figure 1:Comparison among (a) video generative DiT, (b) restoration DiT, and (c) our Stable Video Infinity regarding the scheme (row 1), training-test hypothesis gap (row 2), and outcome (row 3).",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/pre_error.png",
                "caption": "Figure 2:Training-test hypotheses gap.(a) Training assumes historical trajectories and an intermediate stage free of errors, which are easily broken in test by two errors. (b) Predictive error caused by the regressive nature affects the trajectory endXvidX_{\\mathrm{vid}}. (c) Conditional error caused by error-included images also affects startX~noiimg\\tilde{X}_{\\mathrm{noi}}^{\\mathrm{img}}.",
                "position": 131
            }
        ]
    },
    {
        "header": "3Preliminaries and Motivation",
        "images": []
    },
    {
        "header": "4Stable Video Infinity",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/overall.png",
                "caption": "Figure 3:Stable Video Infinity. We (a) inject errors into clean latent to break the error-free hypothesis, (b) approximate predictions via one-step integration to calculate bidirectional errors, and (c) dynamically bank and resample errors from memory for clean inputs, in a closed-loop cycling.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/error_cal.png",
                "caption": "Figure 4:Error calculation.In different cases, the latent errorEvidE_{\\mathrm{vid}}and noise errorEnoiE_{\\mathrm{noi}}are calculated by the one-step integration in the forward (top) and backward direction (bottom), respectively.",
                "position": 259
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/sen.png",
                "caption": "Figure 5:Stability comparison about video length. SVI is more stable without an obvious decrease.",
                "position": 651
            },
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/error.png",
                "caption": "Table 4:Ablation study on each error term.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/error.png",
                "caption": "Figure 6:Error correction comparison.",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/show.png",
                "caption": "Figure 7:Qualitative comparison with the best specific-domain methods (see videos in AppxE).",
                "position": 766
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmark Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/Figure/film.png",
                "caption": "Figure 8:Overview of the proposed end-to-end automatic pipeline, which is able to generate infinite short films from user-given keywords. This engine is used to generate the prompt streams according to a specific storyline for our creative video generation benchmarks.",
                "position": 1443
            }
        ]
    },
    {
        "header": "Appendix BDiscussion",
        "images": []
    },
    {
        "header": "Appendix CQuantitative Experiments",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.09212/x1.png",
                "caption": "Figure 9:Qualitative results about airplane landing story.",
                "position": 2002
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x2.png",
                "caption": "Figure 10:Qualitative results about the cat story.",
                "position": 2005
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x3.png",
                "caption": "Figure 11:Qualitative results about the motorcycle story.",
                "position": 2008
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x4.png",
                "caption": "Figure 12:Qualitative results about the zoo story.",
                "position": 2011
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x5.png",
                "caption": "Figure 13:Qualitative results about the baby story.",
                "position": 2014
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x6.png",
                "caption": "Figure 14:Qualitative results about the dancing.",
                "position": 2017
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x7.png",
                "caption": "Figure 15:Qualitative results about the talking face.",
                "position": 2020
            },
            {
                "img": "https://arxiv.org/html/2510.09212/x8.png",
                "caption": "Figure 16:Qualitative results about the clips of Tom and Jerry.",
                "position": 2023
            }
        ]
    },
    {
        "header": "Appendix EAdditional Qualitative Comparison",
        "images": []
    }
]