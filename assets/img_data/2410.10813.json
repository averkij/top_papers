[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10813/x1.png",
                "caption": "Figure 1:Examples of the seven diverse question types inLongMemEval. For each example, we show the associated evidence statements on the left and the question with the answer on the right.",
                "position": 329
            }
        ]
    },
    {
        "header": "3LongMemEval",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10813/x2.png",
                "caption": "Figure 2:Data creation pipeline ofLongMemEval. The question construction process is performed by human experts (a), and the evidence sessions are LLM-simulated and human-edited (b). The history construction process (c) is performed at test time and is freely configurable.",
                "position": 396
            },
            {
                "img": "https://arxiv.org/html/2410.10813/x3.png",
                "caption": "(a)Distribution of question types inLongMemEval.",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2410.10813/x3.png",
                "caption": "(a)Distribution of question types inLongMemEval.",
                "position": 402
            },
            {
                "img": "https://arxiv.org/html/2410.10813/x4.png",
                "caption": "(b)Distribution of the number of evidence sessions. Most questions emphasize multi-session reasoning, requiring reading up to six sessions to answer.",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2410.10813/x5.png",
                "caption": "(c)Distribution of the location of the evidence statement within the evidence sessions. Most evidence statements are located at the beginning of the chat.",
                "position": 412
            }
        ]
    },
    {
        "header": "4A Unified View of Long-Term Memory Assistants",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10813/x6.png",
                "caption": "Figure 5:A unified view of a chat assistant with long-term memory in operation. We formulate three stages and four control points (CP). We provide further examples inAppendixC.",
                "position": 632
            }
        ]
    },
    {
        "header": "5Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10813/x7.png",
                "caption": "Figure 6:QA performance onLongMemEvalMwith different value designs. Decomposing sessions into rounds improves the QA performance. For the multi-session reasoning questions, further representing the values with the extracted facts improves the QA accuracy.",
                "position": 647
            },
            {
                "img": "https://arxiv.org/html/2410.10813/x8.png",
                "caption": "Figure 7:Question answering performance under the oracle retrieval setting. CoN with JSON format outperforms the other three parameter combinations by a large margin.",
                "position": 975
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASupplemental Details forLongMemEval",
        "images": []
    },
    {
        "header": "Appendix BA Human Study on Commercial Memory Chatbots",
        "images": []
    },
    {
        "header": "Appendix CExisting Memory Systems from the Unified View",
        "images": []
    },
    {
        "header": "Appendix DMemory Optimizations: Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10813/x9.png",
                "caption": "Figure 14:An analysis of the error distribution of different reader models. We use R and G to indicate correct Recall@10 and correct answer based on the top-10 retrieved results.",
                "position": 2970
            }
        ]
    },
    {
        "header": "Appendix EExtended Analyses",
        "images": []
    }
]