[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/figure/motivation.png",
                "caption": "Figure 1:Comparison of previous works andLightMem.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/figure/human.png",
                "caption": "Figure 2:Human memory system.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2510.18866/figure/Lightmem.png",
                "caption": "Figure 3:TheLightMemarchitecture. Our LightMem consists of three modules:a)implements an efficientSensory Memory Modulethat selectively preserves salient information from raw input,b)realizes a conciseSTM Modulefor transient information processing, andc)provides anLTM moduledesigned to minimize retrieval latency.",
                "position": 196
            }
        ]
    },
    {
        "header": "3lightmem architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/x1.png",
                "caption": "Table 1:Effectiveness and efficiency comparison. The token usage is in thousands. – indicates no value for the metric.Bolddenotes the best result,underlinethe second-best.rrdenotes the compression rate.t​hthdenotes the capacity threshold of the STM buffer, measured in tokens. Each pair ofrrandt​hthcorresponds to two rows: one for online soft update and one for offline update. OP-update denotes the offline parallel update process ofLightMem.",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x2.png",
                "caption": "",
                "position": 511
            }
        ]
    },
    {
        "header": "4experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/x3.png",
                "caption": "Table 2:The impact ofLightMemcompression ratiorrand STM buffer thresholdt​hthis reported here. Due to space limitations, we only present a subset of representative results of the online soft update results, with more results provided in the Appendix4.",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x4.png",
                "caption": "",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x5.png",
                "caption": "Figure 4:Analysis and Ablation Study of Key Modules.\nFig.(a) depicts the QA accuracy when using prompts compressed at different ratios (rr) as in-contexts to query the LLM directly.\nFig.(b) compares the accuracy of different topic segmentation methods under these varying compression ratios.\nFig.(c1) and Fig.(c2) present the ablation study for the topic segmentation module, evaluating its impact on both performance and efficiency for the GPT and Qwen models.",
                "position": 941
            }
        ]
    },
    {
        "header": "5related work",
        "images": []
    },
    {
        "header": "6conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AUsage of LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/x6.png",
                "caption": "Figure 5:Impact of the STM buffer threshold (t​hth) on performance and efficiency across different compression ratios (rr).\nEach radar chart represents a specific configuration of a model (GPT-4o-mini or Qwen3) and a fixed compression ratio.\nThe axes measure six key metrics: Accuracy (ACC), token consumption (Input, Output, Total), API Calls, and Runtime.\nTo facilitate comparison, all values are normalized for visualization on the chart.",
                "position": 2001
            }
        ]
    },
    {
        "header": "Appendix BMethodology Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18866/figure/Attention_Matrix1.png",
                "caption": "Figure 6:Example of Topic Segment Attention Matrix.",
                "position": 2025
            },
            {
                "img": "https://arxiv.org/html/2510.18866/figure/Attention_Matrix2.png",
                "caption": "",
                "position": 2028
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x7.png",
                "caption": "Table 3:Category-wise Accuracy. Accuracy (%) by method across question types. Parentheses indicate category proportion and sample size. For GPT, LightMem is configured with parametersr=0.7r=0.7andth=512\\text{th}=512; for Qwen, LightMem is configured withr=0.4r=0.4andth=768\\text{th}=768.",
                "position": 2044
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x8.png",
                "caption": "",
                "position": 2206
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x9.png",
                "caption": "Table 4:The impact of LightMem’s compression ratio (rr) and STM buffer threshold (t​hth).",
                "position": 2282
            },
            {
                "img": "https://arxiv.org/html/2510.18866/x10.png",
                "caption": "",
                "position": 2540
            }
        ]
    },
    {
        "header": "Appendix CExperiment Details",
        "images": []
    },
    {
        "header": "Appendix DPrompts",
        "images": []
    }
]