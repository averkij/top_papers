[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24698/x1.png",
                "caption": "",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2510.24698/figures/tongyi.jpg",
                "caption": "",
                "position": 101
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Pilot Observation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24698/x2.png",
                "caption": "Figure 1:KDE-smoothed distribution of steps with top-4 uncertainty on the BrowseComp subset (truncated to earlier steps as later ones are typically more certain). DeepSeek-V3.1-T denotes DeepSeek-V3.1-Terminus, and Tongyi-DR denotes Tongyi-DeepResearch-30B-A3B.",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2510.24698/x3.png",
                "caption": "Figure 2:Average entity count per task and per model, where entities are extracted by GPT-4.1 based on the complete reasoning trajectory and ground-truth answer.",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2510.24698/x4.png",
                "caption": "Figure 3:Workflow ofParallelMuse, including (Left) the Functionality-Specified Partial Rollout, where theGet Branchshows the selection of top-kksteps based on (exploration) tool-call uncertainty (just as an example of branching criterion), and (Right) the Compressed Reasoning Aggregation.",
                "position": 250
            }
        ]
    },
    {
        "header": "3ParallelMuse",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.24698/x5.png",
                "caption": "Figure 4:Performance gains from different answer generation methods, with sampling fixed to 8 from-scratch rollouts to isolate sampling (exploration) effects.",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2510.24698/x6.png",
                "caption": "Figure 5:Efficiency gains usingParallelMuse.\n(i) (Left) Token reduction through context reuse in our partial rollout method.\nWe take the token consumption per trajectory of the from-scratch rollout as the baseline.\nThe green bars represent the token cost after applying partial rollout (the numbers above indicate the ratio relative to the baseline), while the remaining blue bars show the proportion of tokens saved.\n(ii) (Right) Comparison of context token usage before and after trajectory compression.",
                "position": 794
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]