[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10781/x1.png",
                "caption": "",
                "position": 95
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10781/x2.png",
                "caption": "Figure 2:Overview of Proposed FOFPred:(Left & Center) We present the unified VLM-Diffusion architecture used in FOFPred. Only the DiT module is trained while the VAE and VLM remain frozen.\n(Right) We illustrate two distinct pipelines constructed with FOFPred for two orthogonal tasks in control and generation. Each task specific head is first finetuned prior to inference on the downstream task.",
                "position": 163
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10781/x3.png",
                "caption": "Figure 3:Relative Optical Flow Calculation:We illustrate the key stages of the algorithm for calculating optical flow targets for our training.",
                "position": 261
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Contributions",
        "images": []
    },
    {
        "header": "Appendix Contents",
        "images": []
    },
    {
        "header": "Appendix AAdditional Architectural Details",
        "images": []
    },
    {
        "header": "Appendix BOptical Flow Representation",
        "images": []
    },
    {
        "header": "Appendix COptical Flow Calculation",
        "images": []
    },
    {
        "header": "Appendix DMotion-Guided Frame Sampling",
        "images": []
    },
    {
        "header": "Appendix EAdditional Ablations",
        "images": []
    },
    {
        "header": "Appendix FDetailed Limitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10781/figures/app_vis/limitation_02.jpeg",
                "caption": "Figure A.1:Sensitivity to seed:We visualize 4 FOFPred predictions for the same image and prompt,\"Moving the bowl from left to right\", but using 4 different starting noise vectors for the reverse diffusion process.\nNotice how the upper-right corner conflates the object motion with a camera motion instead; however this camera motion does correspond to the object motion described in the provided prompt.\nIn the lower left image, in addition to the desired object motion, we again observe a slight amount of corresponding camera motion.",
                "position": 2875
            },
            {
                "img": "https://arxiv.org/html/2601.10781/x4.png",
                "caption": "Figure A.2:Visualization of success and failure cases for Text-to-Video (T2V) generation:We visualize some success and failure cases for our framework over the baseline, CogVideoX[98].\nExamples are drawn from the SSv2 validation split.\nWe note that our method consistently improves motion adherence over the baseline.\nHowever, in some cases our framework distorts the visual appearance of objects although they undergo correct movement\n(e.g., see “toy car” in Row 2).\nCheckout ourFOFPred.github.iofor more visualizations.",
                "position": 2882
            },
            {
                "img": "https://arxiv.org/html/2601.10781/x5.png",
                "caption": "",
                "position": 2886
            },
            {
                "img": "https://arxiv.org/html/2601.10781/x6.png",
                "caption": "",
                "position": 2888
            },
            {
                "img": "https://arxiv.org/html/2601.10781/x7.png",
                "caption": "",
                "position": 2890
            }
        ]
    },
    {
        "header": "Appendix GVisualizations",
        "images": []
    }
]