[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06221/metric1.png",
                "caption": "Figure 1.Performance of VibeThinker-1.5B versus competing models on representative benchmarks.",
                "position": 63
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06221/metric2.png",
                "caption": "Figure 2.VibeThinker-1.5B demonstrates remarkable efficiency, surpassing much larger and stronger models on the challenging AIME25 benchmark. It achieves a score of 74.4, outperforming strong baselines such as GPT-OSS-20B-Medium (72.1/20B), DeepSeek-R1-0120 (70.0/671B), and Seed-Thinking v1.5 (74.0/200B).",
                "position": 78
            }
        ]
    },
    {
        "header": "2.Preliminaries",
        "images": []
    },
    {
        "header": "3.Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06221/fw2.png",
                "caption": "Figure 3.The Training Pipeline of VibeThinker-1.5B",
                "position": 174
            }
        ]
    },
    {
        "header": "4.Evaluation and Analysis",
        "images": []
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]