[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09969/x1.png",
                "caption": "Figure 1:Overview of NN-CIFT. The first step consists of using established influence functions tocollect datafor training the InfluenceNetwork. Next, the data from Step (1) is used totrain the InfluenceNetworkand, subsequently,estimate the influence valuesfor the rest of the data. Finally, the data selection algorithm corresponding to the original influence function is used toselect a subset of IFT datato fine-tune a model on.",
                "position": 122
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/ICL_InfluenceNetwork.png",
                "caption": "Figure 2:MSE versus InfluenceNetwork training data size (u) plotted for 8 different training sizes, broken down by the quadrant. These results are for learning DELIFT influence values. Error rates on each quadrant correspond to losses across different sets: Q1 for training, Q2/Q3 for validation, and Q4 for testing. As shown, the InfluenceNetwork achieves MSE of merely 0.05% starting fromu=0.05ùë¢0.05u=0.05italic_u = 0.05and always outperforms the baselines.",
                "position": 280
            },
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/influencenet_sizes.png",
                "caption": "Figure 3:MSE versus InfluenceNetwork sizes (measured by the number of parameters). We try 1-5 layers with 46 different combinations of hidden layer sizes from {5, 10, 20, 50, 100, 200, 500, 1000, 2000, 3000, 4000, 5000}.",
                "position": 283
            }
        ]
    },
    {
        "header": "4Learning Influence Estimation",
        "images": []
    },
    {
        "header": "5Subset Selection Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/icl_delift.png",
                "caption": "Figure 4:Hyperparameter study foruùë¢uitalic_uandvùë£vitalic_von MixInstruct with DELIFT‚Äôs influence function. Lighter colors indicate better BGE performance.",
                "position": 1063
            },
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/icl_nn.png",
                "caption": "",
                "position": 1066
            },
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/peft_delift.png",
                "caption": "",
                "position": 1068
            },
            {
                "img": "https://arxiv.org/html/2502.09969/extracted/6211093/figures/peft_nn.png",
                "caption": "",
                "position": 1069
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEvaluation on smaller subsets",
        "images": []
    },
    {
        "header": "Appendix BInfluence Functions",
        "images": []
    },
    {
        "header": "Appendix CLicense",
        "images": []
    }
]