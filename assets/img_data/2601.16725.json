[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/Technical_Report/figs/main_graph_exp.png",
                "caption": "Figure 1:Benchmark performance of LongCat-Flash-Thinking-2601.",
                "position": 151
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Pre-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/Technical_Report/figs/midtrain_pass_at_k.png",
                "caption": "Figure 2:The comparison of agentic capability (pass@k. “Baseline” represents the model undergoing the old mid-training recipe, while “Enhanced“ represents the model undergoing the agentic-enhanced mid-training recipe.",
                "position": 320
            }
        ]
    },
    {
        "header": "3Scaling Reinforcement Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/x1.png",
                "caption": "Figure 3:Automated construction of executable domain graph.\nStarting from a high-level domain specification, the pipeline synthesizes domain-specific tools, generates corresponding databases schema and tool schema implementations. Building on these we construct a verified tool dependency graph that serves as the foundation for environment scaling.",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x2.png",
                "caption": "Figure 4:Verifiability-preserving environment expansion.\nEnvironment is progressively expanded from a seed executable tool chain through controlled graph growth.",
                "position": 369
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x3.png",
                "caption": "Figure 5:The Execution Workflow of Our Scalable Asynchronous Agentic RL Framework.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x4.png",
                "caption": "Figure 6:Workflow of Prefill-Decode Disaggregation with KV-cache Swapping. The rollout manager coordinates prefill (P) and decode (D) instances and collects final results from D instances. Upon receiving a new request, P and D perform an initial handshake and launch asynchronous chunked KV-cache transfers. When the device KV-cache usage reaches a given watermark, swapping is triggered and can be executed concurrently across both P and D instances.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x5.png",
                "caption": "Figure 7:Pass@1 accuracy of BrowseComp with different context management strategies.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x6.png",
                "caption": "Figure 8:Training reward of LongCat-Flash-Thinking-2601 during large-scale multi-environment agentic RL.",
                "position": 793
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x7.png",
                "caption": "Figure 9:Agentic benchmark performance of LongCat-Flash-Thinking-2601 during RL training using exclusively synthetic general agentic data.",
                "position": 796
            }
        ]
    },
    {
        "header": "4Test-Time Scaling Through Heavy Thinking",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/x8.png",
                "caption": "Figure 10:Framework of heavy thinking mode.",
                "position": 886
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x9.png",
                "caption": "Figure 11:The context message management for parallel reasoning and heavy thinking.",
                "position": 911
            }
        ]
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6One More Thing: Zig-Zag Attention Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/x10.png",
                "caption": "(a)Prefill.",
                "position": 1495
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x10.png",
                "caption": "(a)Prefill.",
                "position": 1498
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x11.png",
                "caption": "(b)Decode.",
                "position": 1503
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x12.png",
                "caption": "Figure 13:The performance versus relative cost. The percentages attached to arrows indicate the reduced cost when benchmarking the performance on the concerned datasets.",
                "position": 1537
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOptimal Hyperparameter Prediction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.16725/x13.png",
                "caption": "Figure 14:Scaling curves of optimal batch size and learning rate. The circles and squares represent MoE-1.8B and MoE-100M models respectively. The dashed lines show the power-law fitting with confidence intervals. The scaling laws are first validated on MoE-3B and MoE-6B models, then extrapolated to predict optimal configurations for MoE-26B.",
                "position": 2991
            },
            {
                "img": "https://arxiv.org/html/2601.16725/x14.png",
                "caption": "Figure 15:Pass@1 accuracy of BrowseComp with varying summary context token lengths.",
                "position": 3027
            }
        ]
    },
    {
        "header": "Appendix BToken Threshold Context Management Performance Evaluation",
        "images": []
    }
]