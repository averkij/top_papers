[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x1.png",
                "caption": "(a)Overall diagram of DRAGON, a versatile on-policy learning framework for media generation models that can optimize various types of reward functions.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x2.png",
                "caption": "",
                "position": 164
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Distributional Reward Optimization For Diffusion Models",
        "images": []
    },
    {
        "header": "4Reward Functions",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x3.png",
                "caption": "Figure 2:DPO versus KTO loss function; paired versus unpaired demonstrations.",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x3.png",
                "caption": "Figure 2:DPO versus KTO loss function; paired versus unpaired demonstrations.",
                "position": 615
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x4.png",
                "caption": "Figure 3:DRAGON with different demonstration diffusion steps and inference steps.",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x5.png",
                "caption": "Figure 4:Vendi score of models optimized for each reward type.\nPoint height represents Vendi score and point size represents aesthetics win rate.\nEach per-song/dataset FAD point train with a different reference statistic.\nBar height averages point height.",
                "position": 975
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALoss Functions for Learning from Demonstrations",
        "images": []
    },
    {
        "header": "Appendix BDetails and Ablations for Human Aesthetics Preference Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x6.png",
                "caption": "Figure 5:Ablation study on aesthetics model settings.\nHigher correlation with human ratings means better aesthetics model performance.",
                "position": 2577
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x6.png",
                "caption": "Figure 5:Ablation study on aesthetics model settings.\nHigher correlation with human ratings means better aesthetics model performance.",
                "position": 2579
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x7.png",
                "caption": "Figure 6:Histograms of human-rated and predicted aesthetics score over the DMA dataset after global label normalization.",
                "position": 2584
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x8.png",
                "caption": "(a)Aesthetics score before vs after DRAGON.",
                "position": 2682
            }
        ]
    },
    {
        "header": "Appendix CFAD Details and Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x9.png",
                "caption": "Figure 8:Correlation between per-song FAD with various reference statistics and aesthetics score. All numbers are negative because smaller is better for FAD whereas larger is better for aesthetics.",
                "position": 2844
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x10.png",
                "caption": "(a)Between FADTK and MA embeddings of SDNV music.",
                "position": 2976
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x10.png",
                "caption": "",
                "position": 2979
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x11.png",
                "caption": "",
                "position": 2984
            }
        ]
    },
    {
        "header": "Appendix DComparison with Open-Source Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x12.png",
                "caption": "Figure 10:Comparing DRAGON and its pre-trained baseline model with open-source music generators.",
                "position": 3045
            }
        ]
    },
    {
        "header": "Appendix EModel Details and Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix FTraining Loop Pseudocode Walkthrough",
        "images": []
    },
    {
        "header": "Appendix GExample Spectrograms",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15217/x13.png",
                "caption": "Figure 11:Spectrograms of example generations (part 1).",
                "position": 3499
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x14.png",
                "caption": "Figure 12:Spectrograms of example generations (part 2).",
                "position": 3502
            },
            {
                "img": "https://arxiv.org/html/2504.15217/x15.png",
                "caption": "Figure 13:Spectrograms of example generations (part 3).",
                "position": 3505
            }
        ]
    },
    {
        "header": "Appendix HFull Result Tables",
        "images": []
    }
]