[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13288/images/architecture.jpg",
                "caption": "Figure 1:View of our probing architecture. The aggregation method featured here is the scoring attention gate",
                "position": 179
            }
        ]
    },
    {
        "header": "3Probe Architecture",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13288/x1.png",
                "caption": "Figure 2:Attention weights from the scoring-attention probe on ToxicChat, stratified by label and correctness. The dashed line marks uniform1/L1/L(≈0.034\\approx 0.034). Toxic prompts attend to later layers (L17–L28), while non-toxic prompts concentrate on layers L0 and L27–L28. Misclassifications resemble the predicted-class profile.",
                "position": 719
            }
        ]
    },
    {
        "header": "5Layer Attention Analysis",
        "images": []
    },
    {
        "header": "6Inference Efficiency Analysis",
        "images": []
    },
    {
        "header": "7Conclusions and Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AHyperparameter Configuration and Sensitivity",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13288/x2.png",
                "caption": "Figure 3:Sensitivity of PR-AUC to hyperparameter choices on ToxicChat across∼100{\\sim}100configurations. Each row corresponds to an aggregation method; horizontal lines denote medians. Self-Attention sustains high PR-AUC (∼0.75{\\sim}0.75–0.900.90) with low variance across settings. Pooling and Scoring Attention are highly sensitive to learning rate, spanning∼0.2{\\sim}0.2–0.90.9.",
                "position": 1272
            }
        ]
    },
    {
        "header": "Appendix BAblation Study on Attention Downcasting",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.13288/x3.png",
                "caption": "Figure 4:Layer-wise post-softmax attention weights on SST-2, stratified by ground-truth label (Positive vs. Negative) and prediction correctness. Similar to toxicity detection (Figure2), correctly classified samples exhibit distinct class-conditional attention patterns: positive sentiment concentrates on later intermediate layers (L17–L28), while negative sentiment shows concentrated attention weights on the embedding and final layers (L0, L28).",
                "position": 1465
            }
        ]
    },
    {
        "header": "Appendix CLayer Attention on SST-2",
        "images": []
    }
]