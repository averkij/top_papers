[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16043/x1.png",
                "caption": "Figure 1:TheAgent0autonomous co-evolution framework. The Curriculum Agent (left) uses RL to generate frontier tasks, rewarded by the Executor Agent‚Äôs uncertainty and tool-use frequency. The Executor Agent (right) learn to solve them by RL. This shared tool integration drives a virtuous cycle, spiraling up task complexity and agent capability entirely from scratch.",
                "position": 108
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16043/x2.png",
                "caption": "Figure 2:TheAgent0co-evolutionary loop. (1) Curriculum Evolution: The Curriculum AgentœÄŒ∏\\pi_{\\theta}is trained via RL to generate tasks, maximizing a rewardRCR_{C}based on executor UncertaintyRuncR_{\\text{unc}}, Tool UseRtoolR_{\\text{tool}}and Repetition PenaltyRrepR_{\\text{rep}}. (2) Executor Evolution: Tasks are filtered by self-consistency scorep^\\hat{p}to create a challenging datasetùíü(t)\\mathcal{D}^{(t)}. The Executor AgentœÄœï\\pi_{\\phi}is then trained onùíü(t)\\mathcal{D}^{(t)}via ADPO, an ambiguity-aware RL method using majority-vote pseudo-labelsy~\\tilde{y}.",
                "position": 131
            }
        ]
    },
    {
        "header": "3TheAgent0Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16043/images/high_clip.png",
                "caption": "Figure 3:Up-clipped token probabilities. Most up-clipped tokens have low probabilities, implying standard clipping limits exploration.",
                "position": 397
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16043/images/tool.png",
                "caption": "Table 1:Comprehensive results on mathematical reasoning benchmarks. The peak performance achieved during each model‚Äôs training process is highlighted inbold.",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2511.16043/images/openai.png",
                "caption": "",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2511.16043/images/tool.png",
                "caption": "Table 2:Results on general-domain reasoning benchmarks.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2511.16043/images/co_evo.png",
                "caption": "Figure 4:Performance on mathematical and general reasoning benchmarks, showing consistent improvement for both Qwen3-4B and Qwen3-8B across three co-evolutionary iterations.",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2511.16043/x3.png",
                "caption": "Figure 5:Qualitative Case Analysis. Left: Examples of generated questions showing a clear increase in complexity and diversity from Iter 1 to Iter 3. Right: A demonstration of Agent0‚Äôs solving process, utilizing a hybrid approach of mathematical reasoning and Python code execution to solve a standard MATH problem.",
                "position": 1000
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": []
    },
    {
        "header": "Appendix BOverview of the Baselines",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Benchmarks",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.16043/images/tool.png",
                "caption": "Table 10:Comprehensive results on mathematical reasoning benchmarks. The peak performance achieved during each model‚Äôs training process is highlighted inbold.",
                "position": 2510
            },
            {
                "img": "https://arxiv.org/html/2511.16043/images/tool.png",
                "caption": "Table 11:Results on general-domain reasoning benchmarks.",
                "position": 2686
            }
        ]
    },
    {
        "header": "Appendix ECase Analysis",
        "images": []
    }
]