[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00418/x1.png",
                "caption": "Figure 1:Illustration of the distortion-perception tradeoff, where distortion is measured by MSE. Many photo-realistic image restoration methods aim for posterior sampling. Theoretically, this approach achieves a perfect perceptual index (pX^=pXsubscriptùëù^ùëãsubscriptùëùùëãp_{\\hat{X}}=p_{X}italic_p start_POSTSUBSCRIPT over^ start_ARG italic_X end_ARG end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT) but its MSE is twice the MMSE. In contrast, we aim for the estimatorX^0subscript^ùëã0\\smash{\\hat{X}_{0}}over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTthatminimizes the MSEunder a perfect perceptual index constraint (Eq.¬†(3)), which typically achieves asmallerMSE than posterior sampling.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x2.png",
                "caption": "Figure 2:Visual results of PMRF (our method) on theCelebA-Testblind face image restoration data set. Our algorithm produces sharp and visually appealing details while maintaining incredibly low distortion according to a variety of measuressimultaneously. SeeTable1.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Posterior-Mean Rectified Flow",
        "images": []
    },
    {
        "header": "4Related work",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00418/x3.png",
                "caption": "Figure 3:Real-world face image restoration.Top: Qualitative results on inputs from theWIDER-Testdata set.Bottom: Comparison on the ‚Äúdistortion‚Äù-perception plane (IndRMSEvs.FID), where IndRMSEindicatesthe RMSE of each method (the true distortion cannot be computed as there is no access to the ground-truth images). Our algorithm outperforms all other methods in IndRMSE, while achieving on-par perceptual quality compared to the state-of-the-art.",
                "position": 788
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x4.png",
                "caption": "",
                "position": 792
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x5.png",
                "caption": "Figure 4:A controlled experiment comparing PMRF (our method) with several baseline methods, where the models are trained with the same architecture, hyper-parameters,etc. (seeSection5.2).Top: Qualitative comparison of PMRF and the baseline methods on several tasks.Bottom: Quantitative comparison on the distortion-perception plane (RMSEvs.FID). DOT is not a flow model, but rather another approach that attempts to approximateX^0subscript^ùëã0\\smash{\\hat{X}_{0}}over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT(like PMRF).\nThese experiments demonstrate that PMRF is either superior or is on-par with previous frameworks (i.e., posterior sampling or flowing fromYùëåYitalic_Y) on a variety of image restoration tasks. SeeSection5.2for more details.",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x6.png",
                "caption": "",
                "position": 821
            }
        ]
    },
    {
        "header": "6Conclusion and limitations",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASupplementary explanations for PMRF",
        "images": []
    },
    {
        "header": "Appendix BSupplementary details and experiments in blind face image restoration",
        "images": []
    },
    {
        "header": "Appendix CSupplementary details onSection5.2",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.00418/x7.png",
                "caption": "Figure 5:Comparison with state-of-the-art blind face restoration methods on inputs from theCelebA-Testdata set. Our method produces high perceptual quality while achieving lower distortion overall.Zoom in for best view.",
                "position": 3633
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x8.png",
                "caption": "Figure 6:Qualitative results on the real-worldLFW-Testdata set. Our algorithm produces reconstructions with either better or on-par perceptual quality compared to the state-of-the-art, while maintaining very high consistency with the input measurements.Zoom in for best view.",
                "position": 3636
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x9.png",
                "caption": "Figure 7:Qualitative results on the real-worldWebPhoto-Testdata set. Our algorithm produces reconstructions with either better or on-par perceptual quality compared to the state-of-the-art, while maintaining very high consistency with the input measurements.Zoom in for best view.",
                "position": 3639
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x10.png",
                "caption": "Figure 8:Qualitative results on the real-worldCelebAdult-Testdata set. Our algorithm produces reconstructions with either better or on-par perceptual quality compared to the state-of-the-art, while maintaining very high consistency with the input measurements.Zoom in for best view.",
                "position": 3642
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x11.png",
                "caption": "Figure 9:A controlled experiment comparing PMRF with previous methodologies, where we vary the number of stepsKùêæKitalic_Kin each algorithm (AppendicesD,3,DandD).\nSpecifically, we useK‚àà{5,10,20,50,100}ùêæ5102050100\\smash{K\\in\\{5,10,20,50,100\\}}italic_K ‚àà { 5 , 10 , 20 , 50 , 100 }, where a larger marker size corresponds to a larger value ofKùêæKitalic_K.\nSeeSection5.2for more details.",
                "position": 3645
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x12.png",
                "caption": "Figure 10:Visual results on the imagecolorizationtask fromSection5.2. Our method outperforms all baselines for any number of inference stepsKùêæKitalic_K.Zoom in for best view.",
                "position": 3890
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x13.png",
                "caption": "Figure 11:Visual results on the imagedenoisingtask fromSection5.2. Our method is on-par with flow fromYùëåYitalic_Y, and outperforms the posterior sampling methods for any number of inference stepsKùêæKitalic_K.Zoom in for best view.",
                "position": 3893
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x14.png",
                "caption": "Figure 12:Visual results on the imageinpaintingtask fromSection5.2. Our method outperforms all baselines for any number of inference stepsKùêæKitalic_K.Zoom in for best view.",
                "position": 3896
            },
            {
                "img": "https://arxiv.org/html/2410.00418/x15.png",
                "caption": "Figure 13:Visual results fromSection5.2on the imagesuper-resolutiontask. Our method is on-par with flow fromYùëåYitalic_Y, and outperforms the posterior sampling methods for any number of inference stepsKùêæKitalic_K.Zoom in for best view.",
                "position": 3899
            }
        ]
    },
    {
        "header": "Appendix DIndicator RMSE (IndRMSE) derivation",
        "images": []
    }
]