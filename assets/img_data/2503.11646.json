[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11646/x1.png",
                "caption": "Figure 1:Comparative Analysis of the Real-Data Collection Loop in Robotic Manipulation. (a) Traditional Approach: A tele-operator executes tasks via fixed linguistic instructions in static visual environments.\n(b) Adversarial Data Collection (ADC) Framework: Employs a Two-Humans-in-the-Loop approach, where a secondary operator intervenes to perturb the primary’s execution dynamically when the tele-operator is executing a task.\n(c) ADC Loop: The adversarial operator introduces visual (backgrounds, object positions/poses) and linguistic (task goals) perturbations, shifting environmental context and target objects within a single episode.",
                "position": 98
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11646/x2.png",
                "caption": "Figure 2:The overview ofADC. During training data collection, we introduce several adversarial perturbations, including dynamic visual perturbations and adaptive linguistic challenges. These perturbations increase information density, expand state space coverage, and provide more complete observations of target objects. The resulting high-quality dataset enables the trained policy model to achieve strong robustness and generalization, outperforming models trained with conventional data collection strategies.",
                "position": 118
            }
        ]
    },
    {
        "header": "IIIApproach",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11646/x3.png",
                "caption": "Figure 3:Hardware setup used inADCfor both data collection and evaluation experiments. The Aloha robot is employed for conventional robotic policy experiments, which include various visual distractors. The AgiBot G1 robot is utilized for the VLA policy experiments, where different dynamic perturbations are applied.",
                "position": 267
            }
        ]
    },
    {
        "header": "IVResults and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11646/x4.png",
                "caption": "Figure 4:Comparison of attention maps when one camera is masked. Models trained withADCfocus more precisely on functional cameras, demonstrating superior attention concentration compared to models trained with traditional data collection pipelines.",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2503.11646/x5.png",
                "caption": "Figure 5:Comparison of observation coverage for the task ”Grasp the orange.” In the traditional data collection process, the target object (orange) is observed from similar viewpoints, resulting in limited visual diversity. In contrast,ADCintroduces dynamic perturbations, allowing the orange to be observed from a wider range of viewpoints. This leads to greater visual variation in theADCdataset, improving model robustness and generalization.",
                "position": 681
            },
            {
                "img": "https://arxiv.org/html/2503.11646/x6.png",
                "caption": "Figure 6:Dynamic Human-Robot Interaction (HRI) scenarios. The robot is tasked with grasping the target fruit from the human hand, where the human’s hand may move during the manipulation tasks. Evaluation experiments are conducted across different scenes.",
                "position": 687
            },
            {
                "img": "https://arxiv.org/html/2503.11646/x7.png",
                "caption": "Figure 7:Autonomous Failure Recovery in ADC-Trained Robotic Grasping: Real-time demonstration of failure recovery after empty grasp. Following initial contact loss during peach acquisition, the system autonomously recalibrates grip pose parameters and executes a precision-aligned regrasp to complete the task.",
                "position": 693
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]