[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/images/icons/finger.png",
                "caption": "",
                "position": 27
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/web.png",
                "caption": "",
                "position": 163
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/x1.png",
                "caption": "Figure 1:Overview of theGroundCUAdataset andGroundNextmodels. Human demonstrations of computer-use tasks are recorded as screenshots (example from FreeCAD) with UI metadata, which are processed into high-quality natural language instruction tasks for UI grounding.GroundNextis trained in two stages: SFT (700K samples) followed by RL (10K samples), achieving state-of-the-art grounding performance with efficient training.",
                "position": 172
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3GroundCUADataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/gimp.png",
                "caption": "(a)GIMP",
                "position": 419
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/gimp.png",
                "caption": "(a)GIMP",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/freecad.png",
                "caption": "(b)FreeCAD",
                "position": 427
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/LibreOfficeCalc.png",
                "caption": "(c)LibreOffice Calc",
                "position": 432
            }
        ]
    },
    {
        "header": "4TrainingGroundNextModels onGroundCUA",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/x2.png",
                "caption": "Figure 3:Mean SFT scores (orange) across benchmarks, with RL gains from1010kGroundCUAsamples shown in blue.",
                "position": 921
            }
        ]
    },
    {
        "header": "6Conclusion & Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AGroundCUAâ€“ Creation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/x3.png",
                "caption": "(a)Number of annotations in different software categories",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x3.png",
                "caption": "(a)Number of annotations in different software categories",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x4.png",
                "caption": "(b)Number of screenshots in different software categories",
                "position": 2345
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x5.png",
                "caption": "(c)Pixel distribution of images",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x6.png",
                "caption": "(d)Relative bounding box area",
                "position": 2362
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x7.png",
                "caption": "(e)Distribution of number of annotations in an image",
                "position": 2376
            },
            {
                "img": "https://arxiv.org/html/2511.07332/x8.png",
                "caption": "(f)Desktop application across different categories",
                "position": 2385
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/pixel_distribution.png",
                "caption": "Figure 5:Comparison across different datasets. (Left) Pixel distribution for different datasets. (Right) Relative bounding box area in log scale.",
                "position": 2404
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/bounding_box_areas.png",
                "caption": "",
                "position": 2407
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/7zip.png",
                "caption": "(a)7-Zip",
                "position": 2419
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/7zip.png",
                "caption": "(a)7-Zip",
                "position": 2422
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/gimp.png",
                "caption": "(b)GIMP",
                "position": 2427
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/brave.png",
                "caption": "(c)Brave",
                "position": 2432
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/audrino.png",
                "caption": "(d)Audrino",
                "position": 2438
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/freecad.png",
                "caption": "(e)FreeCAD",
                "position": 2443
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/octave.png",
                "caption": "(f)GNU Octave",
                "position": 2448
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/cryptomator.png",
                "caption": "(g)Cryptomator",
                "position": 2454
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/openshot.png",
                "caption": "(h)OpenShot",
                "position": 2459
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/frappe_books.png",
                "caption": "(i)Frappe Books",
                "position": 2464
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/emby.png",
                "caption": "(j)Emby",
                "position": 2470
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/LibreOfficeCalc.png",
                "caption": "(k)Mastadon",
                "position": 2475
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/mastadon.png",
                "caption": "(l)LibreOffice Calc",
                "position": 2480
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/r_studio.png",
                "caption": "(m)R Studio",
                "position": 2486
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/vlc.png",
                "caption": "(n)VLC Media Player",
                "position": 2491
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/examples_platforms/zotero.png",
                "caption": "(o)Zotero",
                "position": 2496
            }
        ]
    },
    {
        "header": "Appendix BInstruction Tuning Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_1.png",
                "caption": "Figure 7:Instruction tuning data examples.",
                "position": 2643
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_2.png",
                "caption": "",
                "position": 2646
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_3.png",
                "caption": "",
                "position": 2648
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_4.png",
                "caption": "",
                "position": 2649
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_5.png",
                "caption": "",
                "position": 2651
            },
            {
                "img": "https://arxiv.org/html/2511.07332/images/instruction/ins_6.png",
                "caption": "",
                "position": 2652
            }
        ]
    },
    {
        "header": "Appendix CTraining",
        "images": []
    },
    {
        "header": "Appendix DEvaluation",
        "images": []
    },
    {
        "header": "Appendix EGroundNextError Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.07332/x9.png",
                "caption": "Figure 8:Four examples of mistakes ofGroundNext-7B (RL) on ScreenSpot-V2. The ground truth bounding box (green box) and predicted coordinates (red circle) are shown along with the instruction.",
                "position": 4352
            }
        ]
    },
    {
        "header": "Appendix FLimitations",
        "images": []
    }
]