[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x1.png",
                "caption": "",
                "position": 125
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x2.png",
                "caption": "Figure 2:VBench-2.0 Evaluation Results of SOTA Models.The figure presents the evaluation results of four recent state-of-the-art video generation models across 18 VBench-2.0 dimensions. The results are normalized per dimension for a clearer comparison. For detailed numerical results, refer to Table2.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3VBench-2.0 Suite for Intrinsic Faithfulness",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x3.png",
                "caption": "Figure 3:Overview of Prompt Suite Statistics.Left:distribution of words in the prompt suites.Right:number of prompts per evaluation dimension.",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x3.png",
                "caption": "Figure 3:Overview of Prompt Suite Statistics.Left:distribution of words in the prompt suites.Right:number of prompts per evaluation dimension.",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2503.21755/extracted/6315755/figures/fig_paper_interface.jpg",
                "caption": "Figure 4:Interface for Human Preference Annotation.Top:Question descriptions.Right:Choices available to annotators.Bottom left:Controls for stopping and playback.",
                "position": 437
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x4.png",
                "caption": "Figure 5:Human Alignment of VBench-2.0 Evaluation.Each plot represents the alignment verification for a specific VBench-2.0 dimension. In each plot, a dot corresponds to the human preference win ratio (horizontal axis) and the VBench-2.0 evaluation win ratio (vertical axis) for a given video generation model. A linear fit is applied to visualize the correlation, and Spearman‚Äôs correlation coefficient (œÅùúå\\rhoitalic_œÅ) is computed for each dimension. Experiments show that VBench-2.0 evaluations closely align with human judgement in all dimensions.",
                "position": 880
            }
        ]
    },
    {
        "header": "5Insights and Discussions",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "GDetails on Evaluation Dimension and Method Suite",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x5.png",
                "caption": "Figure S6:Example for Mechanics.",
                "position": 2289
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x6.png",
                "caption": "Figure S7:Example for Material.",
                "position": 2292
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x7.png",
                "caption": "Figure S8:Example for Thermotics.",
                "position": 2295
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x8.png",
                "caption": "Figure S9:Example for Multi-View Consistency.",
                "position": 2298
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x9.png",
                "caption": "Figure S10:Example for Diversity.",
                "position": 2326
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x10.png",
                "caption": "Figure S11:Example for Composition.",
                "position": 2394
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x11.png",
                "caption": "Figure S12:Example for Dynamic Spatial Relationship.",
                "position": 2404
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x12.png",
                "caption": "Figure S13:Example for Dynamic Attribute.",
                "position": 2410
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x13.png",
                "caption": "Figure S14:Example for Motion Order Understanding.",
                "position": 2416
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x14.png",
                "caption": "Figure S15:Example for Human Interaction.",
                "position": 2456
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x15.png",
                "caption": "Figure S16:Example for Complex Plot.",
                "position": 2459
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x16.png",
                "caption": "Figure S17:Example of Dynamic Camera Motion.",
                "position": 2465
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x17.png",
                "caption": "Figure S18:Example for Plot Consistency.",
                "position": 2471
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x18.png",
                "caption": "Figure S19:Example for Complex Landscape.",
                "position": 2477
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x19.png",
                "caption": "Figure S20:Example for Human Anatomy.",
                "position": 2510
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x20.png",
                "caption": "Figure S21:Example for Human Identity.",
                "position": 2516
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x21.png",
                "caption": "Figure S22:Example for Human Clothes.",
                "position": 2525
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x22.png",
                "caption": "Figure S23:Example for Motion Rationality.",
                "position": 2550
            },
            {
                "img": "https://arxiv.org/html/2503.21755/x23.png",
                "caption": "Figure S24:Example for Instance Preservation.",
                "position": 2556
            }
        ]
    },
    {
        "header": "HMore Details on Prompt Suite",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.21755/x24.png",
                "caption": "Figure S25:VBench-2.0 System Prompt for different backend models.",
                "position": 2603
            }
        ]
    },
    {
        "header": "IHuman Preference Annotation Details",
        "images": []
    },
    {
        "header": "JVideo Generation Models in Evaluation",
        "images": []
    }
]