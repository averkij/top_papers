[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10098/x1.png",
                "caption": "Figure 1:VLA-JEPA model architecture",
                "position": 182
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10098/x2.png",
                "caption": "Figure 2:VLA-JEPA supports cross-domain training on both human videos and robot data, where human videos are trained using an alignment loss under the latent world modeling objective, while robot data are trained with a joint objective consisting of an alignment loss and a robot action prediction loss.",
                "position": 251
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10098/x3.png",
                "caption": "Figure 3:Experiments setup on LIBERO, LIBERO-Plus, SimplerEnv and real-world Franka robot. We evaluate VLA-JEPA on 3 simulation benchmarks and 1 real-world environment.",
                "position": 353
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10098/Figures/experiments/realworld_figure.png",
                "caption": "Figure 4:Real World Experimental Results",
                "position": 990
            },
            {
                "img": "https://arxiv.org/html/2602.10098/Figures/experiments/human_video_proportion.png",
                "caption": "Figure 5:Effect of the proportion of human video data in pre-training on success rates across different perturbation dimensions on the LIBERO-Plus benchmark.",
                "position": 1013
            },
            {
                "img": "https://arxiv.org/html/2602.10098/x4.png",
                "caption": "Figure 6:Visualization of the attention weight matrix of latent action tokens attending to image tokens.",
                "position": 1025
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.10098/x5.png",
                "caption": "Figure 7:Comparison of three models (π0\\pi_{0},π0.5\\pi_{0.5}, VLA-JEPA) under the object-layout OOD setting.",
                "position": 1226
            }
        ]
    },
    {
        "header": "Appendix BReal-world Experiments Details",
        "images": []
    }
]