[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14949/x1.png",
                "caption": "",
                "position": 59
            },
            {
                "img": "https://arxiv.org/html/2502.14949/x2.png",
                "caption": "",
                "position": 93
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14949/x3.png",
                "caption": "Figure 1:Overview of the core domains and sub-domains in KITAB-Bench. Our benchmark spans nine major domains (e.g., OCR, charts to JSON, table recognition) and 36 sub-domains (e.g., scanned text, handwritten text, various chart types), providing a comprehensive evaluation framework for modern Arabic document processing and analysis.",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2502.14949/x4.png",
                "caption": "Figure 2:Overview of different tasks in our benchmark: Eight key components illustrating the task inputs and outputs for table recognition, chart understanding, text recognition, diagram analysis, VQA, line detection, layout analysis, and PDF-to-Markdown conversion, complete with input/output examples for each task.",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2502.14949/x5.png",
                "caption": "Figure 3:Comparison of model performance across four document understanding tasks (Table Recognition, Image to Text, Diagram to JSON, and Layout Detection) showing successful and failed cases for different models including Ground Truth, EasyOCR, GPT-4, Qwen, Surya, Tesseract, Yolo, and DETR on Arabic document benchmark data.",
                "position": 357
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3KITAB-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14949/x6.png",
                "caption": "Figure 4:Synthetic Data Generation Pipeline: A 5-stage process using LLMs to generate topics, create raw data, produce visualization code, render charts, and perform human evaluation for quality control.",
                "position": 470
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations and Future Directions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASource of the Existing Dataset Collection",
        "images": []
    },
    {
        "header": "Appendix BDetailed Performance Comparison",
        "images": []
    },
    {
        "header": "Appendix CData Analysis",
        "images": []
    },
    {
        "header": "Appendix DTasks Models and Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14949/x7.png",
                "caption": "Figure 5:Prompts for Different Task Categories.",
                "position": 3676
            },
            {
                "img": "https://arxiv.org/html/2502.14949/x8.png",
                "caption": "Figure 6:Prompts for Diagrams and Tables.",
                "position": 3680
            }
        ]
    },
    {
        "header": "Appendix ESCRM and CODM",
        "images": []
    }
]