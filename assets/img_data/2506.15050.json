[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/front.jpeg",
                "caption": "Figure 1:AIME 2024 scores ofT-PPOon the Qwen2.5-32B base model, reduces training time by 60% compared to the previous state-of-the-art (SOTA) method. The values shown are pass@1 scores, averaged over 32 samples per question.",
                "position": 88
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3T-PPO: Truncated Proximal Policy Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig1.png",
                "caption": "Figure 2:Successive batching strategy of T-PPO. Gray: prefill (computing input tokens), blue and red: decode (generating new response tokens). In step 0, sequences S2 and S3 emit an end-of-sequence token (red), so in step 1 we insert new prompts in their place (i.e. sequences S5 and S6), while the unfinished sequences continues in the next iteration. Each sequence finishes at different iterations.",
                "position": 288
            },
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig2.png",
                "caption": "Figure 3:Plots showing one step (i.e. step 1) of the training tokens for policy model (top side) and value model (bottom side).",
                "position": 294
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig3.png",
                "caption": "Figure 4:Algorithm comparison in terms of time efficiency on the AIME benchmark. Each boxplot is drawn based on the execution mean of 1000 steps.",
                "position": 499
            },
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig3.png",
                "caption": "Figure 4:Algorithm comparison in terms of time efficiency on the AIME benchmark. Each boxplot is drawn based on the execution mean of 1000 steps.",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig4.png",
                "caption": "Figure 5:Demonstration of the Roofline model of Nvidia H800 GPU. The computation is in BF16.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2506.15050/extracted/6549757/figures/fig5.jpeg",
                "caption": "Figure 6:The metric curves of response length.",
                "position": 527
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]