[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01844/extracted/6502349/logos/sorbonne_logo.png",
                "caption": "",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x1.png",
                "caption": "",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x2.png",
                "caption": "",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x3.png",
                "caption": "",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x4.png",
                "caption": "",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x5.png",
                "caption": "",
                "position": 138
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x6.png",
                "caption": "",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x7.png",
                "caption": "",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x8.png",
                "caption": "",
                "position": 141
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x9.png",
                "caption": "",
                "position": 142
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x10.png",
                "caption": "",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x11.png",
                "caption": "",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x12.png",
                "caption": "",
                "position": 146
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x13.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x14.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x15.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x16.png",
                "caption": "Figure 1:SmolVLA.SmolVLA consists of a compact pretrained vision-language model, discarding the lastL‚àíNùêøùëÅL-Nitalic_L - italic_Nlayers (scissors icon). The remaining layers embed three inputs: (i) language instruction, (ii) RGB image(s), and (iii) robot sensorimotor state. Their merged tokens feed an Action Expert of alternating cross-attention (gold) and self-attention (light yellow) blocks, trained with flow matching to outputnùëõnitalic_nlow-level actions chunkat,‚Ä¶,at+nsubscriptùëéùë°‚Ä¶subscriptùëéùë°ùëõa_{t},\\dots,a_{t+n}italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , ‚Ä¶ , italic_a start_POSTSUBSCRIPT italic_t + italic_n end_POSTSUBSCRIPT. SmolVLA is pretrained on public community datasets and evaluated on low-cost robots.",
                "position": 164
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3SmolVLA: small, efficient and capable",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01844/x17.png",
                "caption": "Figure 2:Asynchronous inference. Illustration of the asynchronous inference stack. Note that the policy can be run on a remote server, possibly with GPUs.",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2506.01844/x18.png",
                "caption": "Figure 3:Action queue size evolution at runtime for various levels ofgùëîgitalic_gwhen (A) not filtering out observation based on joint-space similarity and (B) filtering out near-duplicates observation, measuring their similarity in joint-space.",
                "position": 516
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01844/x19.png",
                "caption": "Figure 4:Illustrations of the four real-world tasks we benchmark SmolVLA against, presenting starting and terminal frame for each of the dataset considered, for both SO100 embodiments (A) and SO101 (B). For SO100, we use top and wrist cameras, where for SO101 we use top and side cameras (as seen in the images).",
                "position": 574
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Aknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]