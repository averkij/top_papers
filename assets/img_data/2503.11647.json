[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/x1.png",
                "caption": "",
                "position": 121
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Multi-Cam Video: A High-Quality Multi-Camera Synchronized Video Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/x2.png",
                "caption": "Figure 2:Illustration of the dataset construction process.We build the multi-camera synchronized training dataset by rendering in Unreal Engine 5. This is achieved using 3D environments, characters, animations collected from the internet, and our designed massive camera trajectories.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2503.11647/x3.png",
                "caption": "Figure 3:Overview of ReCamMaster.Left:The training pipeline of ReCamMaster. A latent diffusion model is optimized to reconstruct the target videoVtsubscriptùëâùë°V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, conditioned on the source videoVssubscriptùëâùë†V_{s}italic_V start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, target camera posec‚Å¢a‚Å¢mtùëêùëésubscriptùëöùë°cam_{t}italic_c italic_a italic_m start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and target promptptsubscriptùëùùë°p_{t}italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.Right:Comparison of different video condition techniques. (a) Frame-dimension conditioning used in our paper; (b) Channel-dimension conditioning used in baseline methods[43,5]; (c) View-dimension conditioning in[3]. We omit the text promptptsubscriptùëùùë°p_{t}italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTin (a)-(c) for simplicity.",
                "position": 210
            }
        ]
    },
    {
        "header": "4Camera-Controlled Video Re-Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/x4.png",
                "caption": "Figure 4:Comparison with state-of-the-art methods.It shows that ReCamMaster generates videos that maintain appearance consistency and temporal synchronization with the source video.",
                "position": 361
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/x5.png",
                "caption": "Figure 5:Ablation on video conditioning techniques.We compared the channel-/view- concatenation schemes proposed by previous methods and frame-concatenation in ReCamMaster. We observed that both channel-conditioning and view-conditioning schemes suffer from significant artifacts, content inconsistency and asynchronous dynamics with respect to the original video.",
                "position": 701
            }
        ]
    },
    {
        "header": "6Applications of ReCamMaster",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/x6.png",
                "caption": "Figure 6:Applications of ReCamMaster.From top to bottom:video stabilization, video super-resolution, and video outpainting.",
                "position": 787
            }
        ]
    },
    {
        "header": "7Conclusion and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/extracted/6281232/figures/fig_basemodel.jpg",
                "caption": "Figure 7:Overview of the base text-to-video generation model.",
                "position": 1691
            }
        ]
    },
    {
        "header": "Appendix AIntroduction of the Base Text-to-Video Generation Model",
        "images": []
    },
    {
        "header": "Appendix BDetails of Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.11647/extracted/6281232/figures/fig_render_data.jpg",
                "caption": "Figure 8:Rendered multi-camera synchronized dataset.",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2503.11647/x7.png",
                "caption": "Figure 9:Unify camera-controlled tasks with ReCamMaster.ReCamMaster supports T2V, I2V, and V2V camera-controlled generation.",
                "position": 1897
            },
            {
                "img": "https://arxiv.org/html/2503.11647/x8.png",
                "caption": "Figure 10:Visualization of failure cases.",
                "position": 1900
            },
            {
                "img": "https://arxiv.org/html/2503.11647/x9.png",
                "caption": "Figure 11:More synthesized results of ReCamMaster.",
                "position": 1903
            },
            {
                "img": "https://arxiv.org/html/2503.11647/x10.png",
                "caption": "Figure 12:More comparison with state-of-the-art methods.",
                "position": 1913
            }
        ]
    },
    {
        "header": "Appendix CMore Results",
        "images": []
    }
]