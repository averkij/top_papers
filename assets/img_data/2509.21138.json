[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21138/x1.png",
                "caption": "Figure 1:Average accuracy (banking77Casanueva et al. (2020), massiveFitzGerald et al. (2022), minds14Gerz et al. (2021), hwu64Liu et al. (2019)) and training duration (on minds14) of AutoIntent presets (orange) and baseline AutoML tools (blue).",
                "position": 107
            }
        ]
    },
    {
        "header": "2Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21138/x2.png",
                "caption": "Figure 2:(Left)AutoIntent’s three levels of hyperparameter optimization: at the module level, the embedding, scoring, and decision models are optimized sequentially; at the model level, each classification approach is tested against each other to select the best one; at the instance level, hyperparameters for each model is tuned individually with optuna samplers.(Right)Inference pipeline as a result of AutoIntent’s hyperparameter optimization.",
                "position": 396
            }
        ]
    },
    {
        "header": "3AutoIntent",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21138/x3.png",
                "caption": "Figure 3:Performance comparison in a scenario of scarce training data. Baseline AutoML frameworks: AutoGluonTang et al. (2024)with non-HPO presetmedium_quality, H2OLeDell and Poirier (2020)with their word2vec; and AutoIntent presetclassic-light.",
                "position": 650
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21138/x4.png",
                "caption": "Figure 4:Encoders ranking: (Left) precise ranking obtained via training full AutoML pipeline with only this model, (Right) approximate ranking based on retrieval quality (NDCG).",
                "position": 1728
            }
        ]
    },
    {
        "header": "Appendix AComputational Efficiency",
        "images": []
    }
]