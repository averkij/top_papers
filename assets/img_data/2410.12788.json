[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/yinru.png",
                "caption": "Figure 1:Overview of RAG pipeline, as well as examples based on rules, similarity, and PPL segmentation. The same background color represents being located in the same chunk.",
                "position": 101
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/abcd.png",
                "caption": "Figure 2:Overview of the entire process of Meta-Chunking. Each circle represents a complete sentence, and the sentence lengths are not consistent. The vertical lines indicate where to segment. The two sides at the bottom of the figure reveal Margin Sampling Chunking and Perplexity Chunking. Circles with the same background color represent a meta-chunk, which is dynamically combined to make the final chunk length meet user needs.",
                "position": 167
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": []
    },
    {
        "header": "5RESULTS AND ANALYSIS",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/analysis4.png",
                "caption": "Figure 3:Performance of different methods on single-hop query in the CRUD QA dataset.pplrepresents direct PPL Chunking, with a threshold of 0.5.comb.indicates PPL Chunking with dynamic combination, with a threshold of 0 when performing PPL Chunking. Precise chunk length results and performance of remaining multi-hop scenarios are included in AppendixA.3.",
                "position": 762
            },
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/analysis1.png",
                "caption": "Figure 4:Performance of different methods on CUAD QA datasets.pplindicates direct PPL Chunking, with a threshold of 0.",
                "position": 772
            },
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/analysis2.png",
                "caption": "Figure 5:Performance of different methods in four long-text QA datasets of LongBench is evaluated based on F1, F1, F1, and ROUGE-L.pplrepresents direct PPL Chunking, andcomb.indicates PPL Chunking with dynamic combination.Multirepresents threshold values of the parallel method in four datasets, which are 0.5, 0.5, 1.34, and 0.5 respectively, resulting in chunk lengths of 87, 90, 71, and 262 in sequence.",
                "position": 775
            },
            {
                "img": "https://arxiv.org/html/2410.12788/extracted/6023136/pic/analysis3.png",
                "caption": "Figure 6:Performance of re-ranking strategies combined with different chunking methods in the MultiHop-RAG benchmark.pplrepresents direct PPL Chunking, with a threshold of 0.5. The base reveals not utilizing re-ranking strategy. Precise chunk length results are included in AppendixA.5.",
                "position": 788
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]