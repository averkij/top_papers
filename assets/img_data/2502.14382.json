[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14382/x1.png",
                "caption": "Figure 1:Performance improvement withSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTin LiveCodeBench (v2)(Jain etÂ al.,2024).Sâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTconsistently improves models across different sizes, allowing non-reasoning models to surpass reasoning models and open models to be competitive with o1 (high reasoning effort). \"Qwen-Coder\" denotes \"Qwen2.5-Coder-Instruct,\"(Hui etÂ al.,2024)and \"R1-Distill\" denotes \"DeepSeek-R1-Distill-Qwen.\"(Guo etÂ al.,2025).",
                "position": 183
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x2.png",
                "caption": "Figure 2:Overview ofSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT.Stage 1: Generationâ€”Sâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTenhances parallel samples through iterative debugging. Each sample is tested using public test cases executed via an interpreter, with outputs and/or error messages used to guide the next round of sample generation.Stage 2: Selectionâ€”Sâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTselects the best sample by prompting an LLM to generate inputs that differentiate between paired samples, then leveraging actual execution results to inform the LLM to determine the optimal choice.",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x3.png",
                "caption": "Figure 3:Ablation ofSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTperformance benefits: Qwen2.5-Coder-14B-Instruct (denoted as Qwen-Coder-14B)(Hui etÂ al.,2024)withSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPTcan surpass o1-preview withoutSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT. DeepSeek-R1-Distill-Qwen-14B (denoted as R1-Distill-14B)(Guo etÂ al.,2025)withSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPToutperforms o1-mini withoutSâˆ—superscriptğ‘†S^{*}italic_S start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT.",
                "position": 230
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Evaluation",
        "images": []
    },
    {
        "header": "5Ablation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14382/x4.png",
                "caption": "Figure 4:The effect of hyper-parameters. Left: The impact of temperature. A moderate temperature (0.7) balances diversity and quality, leading to higher Pass@N. In contrast, a higher temperature (0.95) does not further improve Pass@N, potentially degrading code quality. Right: The effect of increasing the number of samples. Performance improves log-linearly.",
                "position": 644
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x5.png",
                "caption": "Figure 5:Performance with in-context examples across different numbers of parallel samples (Nğ‘Nitalic_N), for GPT-4o mini, Qwen2.5-Coder-7B-Instruct, and Qwen2.5-Coder-32B-Instruct.",
                "position": 666
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x6.png",
                "caption": "Figure 6:Comparison of three iterative debugging approaches:Public Tests,+ Generated TestsandLast Round Context. Results are obtained withN=8ğ‘8N=8italic_N = 8,temperature=0.7temperature0.7\\text{temperature}=0.7temperature = 0.7and up to four rounds of debugging.",
                "position": 686
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14382/x7.png",
                "caption": "Figure 7:The prompt for iterative debugging.",
                "position": 1611
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x8.png",
                "caption": "Figure 8:The prompt for generating test cases.",
                "position": 1614
            },
            {
                "img": "https://arxiv.org/html/2502.14382/x9.png",
                "caption": "Figure 9:The prompt for code generation.",
                "position": 1617
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]