[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16968/x1.png",
                "caption": "",
                "position": 59
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16968/x2.png",
                "caption": "Figure 2:Main idea: dynamic tokenization during denoising. Current methods use the same patch size foralldenoising steps during inference time.\nInstead,DDiTadapts the patch size at each timestep according to the latent complexity, allocating fewer tokens for certain timesteps and more tokens for certain others. While DiT divides VAE latents into patches, for illustrative purposes, we use a real image in pixel space.",
                "position": 131
            }
        ]
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16968/x3.png",
                "caption": "Figure 3:Revised patch-embedding layer to support patches of varied resolutions.We modify the standard patch-embedding layer, designed for a fixed patch sizepp, to additionally support patch sizespnewp_{\\text{new}}.",
                "position": 174
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x4.png",
                "caption": "Figure 4:Inference speed vs. patch size.Inference speed measured over5050denoising steps for generating1024Ã—10241024\\times 1024images using FLUX-1.Dev[54], where every timestep uses a fixed patch size. As the patch size increases fromppâ†’\\rightarrow2â€‹p2pâ†’\\rightarrow4â€‹p4p, the number of tokens decreases quadratically (4096â†’\\rightarrow1024â†’\\rightarrow256), resulting in approximately3Ã—3\\timesand4Ã—4\\timesfaster inference for2â€‹p2pand4â€‹p4p, respectively, compared topp.",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x5.png",
                "caption": "Figure 5:GivenÎ”(3)â€‹ğ³tâˆ’1\\Delta^{(3)}\\mathbf{z}_{t-1}, we divide it into patches of sizepiÃ—pip_{i}\\times p_{i}, compute within-patch standard deviationğˆtâˆ’1pi\\boldsymbol{\\sigma}_{t-1}^{p_{i}}of the acceleration.",
                "position": 226
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x6.png",
                "caption": "Figure 6:Visualization ofÏƒtâˆ’12â€‹p,(Ï)\\boldsymbol{\\sigma}_{t-1}^{2p,(\\rho)}for two prompts (log scale).Prompt 1: â€œSeveral zebras are standing together behind a fence.â€Prompt 2: â€œA simple red apple on a black background.â€Prompts requiring different levels of spatial granularity exhibit distinctğˆtâˆ’12â€‹p,(Ï)\\boldsymbol{\\sigma}_{t-1}^{2p,(\\rho)}patterns across timesteps.\nFor the fine-grained zebra pattern,ğˆtâˆ’12â€‹p,(Ï)\\boldsymbol{\\sigma}_{t-1}^{2p,(\\rho)}remains higher, indicating higher detail sensitivity,\nwhereas for the simpler apple scene,ğˆtâˆ’12â€‹p,(Ï)\\boldsymbol{\\sigma}_{t-1}^{2p,(\\rho)}is lower, thus we can seamlessly use larger patch sizes during generation.",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x7.png",
                "caption": "Figure 7:Qualitative comparisons with the base model[54], TeaCache[61], TaylorSeer[62], and DDiT under similar speedups on DrawBench.DDiTeffectively preserves fine-grained details, pose, spatial layout, and overall color distribution of the generated images.",
                "position": 502
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16968/x8.png",
                "caption": "Figure 8:Qualitative comparison on DrawBenchwith the baseline and TaylorSeer[62]. Our method remains robust even for complex prompts that require a deeper understanding of semantic content.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x9.png",
                "caption": "Figure 9:Qualitative comparison of text-to-video generation between DDiT and the baseline.DDiT produces videos with comparable visual quality to the baseline while achieving significant speedup.",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2602.16968/x10.png",
                "caption": "Figure 10:Sample patch schedulesfor 3 different prompts. Our dynamic patch scheduler seamlessly adapts to each promptâ€™s complexity and detail, thereby allocating more computation (aka higher percentage of smaller patch sizes) to images with highly detailed textures compared to simpler ones, thereby balancing efficiency and visual quality.",
                "position": 662
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]