[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/img/github_sign.png",
                "caption": "",
                "position": 102
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/figures/overview.png",
                "caption": "Figure 1:Overview of EntroPIC. The method calculates a correction factor based on historical and current entropy values relative to the target entropy and adjusts the weights of high-probability positive and negative samples to achieve entropy control.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Adjust Entropy via PI Control",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/x1.png",
                "caption": "Figure 2:Investigating how masking positive/negative and high/low-probability tokens affects entropy during training. Left: Entropy variation after masking different token groups (P↑: high-prob. positive, P↓: low-prob. positive, N↑: high-prob. negative, N↓: low-prob. negative). Right: Comparison of entropy changes between high- and low-probability tokens.",
                "position": 360
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x1.png",
                "caption": "",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x2.png",
                "caption": "",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x3.png",
                "caption": "Figure 3:Schematic of entropy control via weight modulation. Modulating weights for high-probability tokens results in better performance than for low-probability ones.",
                "position": 399
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/x4.png",
                "caption": "Figure 4:On-policy training results.Left: entropy stabilization process.Right: variation of adaptive coefficientα\\alpha.",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x4.png",
                "caption": "",
                "position": 468
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x5.png",
                "caption": "",
                "position": 475
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x6.png",
                "caption": "Figure 5:Off-policy training results. Only PI control successfully stabilizes entropy at the target value.",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x6.png",
                "caption": "",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x7.png",
                "caption": "",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x8.png",
                "caption": "Figure 6:Left: Entropy change curves of different methods during training.Middle: Accuracy on the training set.Right: Accuracy on the validation set. EntroPIC stabilizes entropy at the target value throughout training, ensuring steady growth on both training and validation sets, ultimately achieving long-term stable performance.",
                "position": 522
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x8.png",
                "caption": "",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x9.png",
                "caption": "",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x10.png",
                "caption": "",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x11.png",
                "caption": "Figure 7:Plug-and-play experiment. EntroPIC stabilizes entropy during the late training phase, improving model performance.",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x11.png",
                "caption": "",
                "position": 781
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x12.png",
                "caption": "",
                "position": 788
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x13.png",
                "caption": "",
                "position": 795
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof",
        "images": []
    },
    {
        "header": "Appendix BExperiment Details",
        "images": []
    },
    {
        "header": "Appendix CCode",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/figures/code.png",
                "caption": "Figure 8:The code change for using EntroPIC method.",
                "position": 2614
            }
        ]
    },
    {
        "header": "Appendix DMore Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.15248/x14.png",
                "caption": "Figure 9:Off-policy training experiment. The entropy of the GRPO method drops significantly, while the EntroPIC method stabilizes entropy at the target value, continuously improving model performance.",
                "position": 2628
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x14.png",
                "caption": "",
                "position": 2631
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x15.png",
                "caption": "",
                "position": 2638
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x16.png",
                "caption": "",
                "position": 2645
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x17.png",
                "caption": "Figure 10:Temperature setting of 1.0. EntroPIC demonstrates better stability and higher performance than GRPO.",
                "position": 2654
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x17.png",
                "caption": "",
                "position": 2657
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x18.png",
                "caption": "",
                "position": 2664
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x19.png",
                "caption": "",
                "position": 2671
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x20.png",
                "caption": "Figure 11:Controlα\\alphaof EntroPIC method in training stage.",
                "position": 2688
            },
            {
                "img": "https://arxiv.org/html/2511.15248/x21.png",
                "caption": "Figure 12:Frequency of reflective words during training.",
                "position": 2701
            }
        ]
    },
    {
        "header": "Appendix ECase Study",
        "images": []
    }
]