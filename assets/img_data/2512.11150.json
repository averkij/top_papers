[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Setup",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11150/figs/pipeline_overview.jpg",
                "caption": "Figure 1:CJE pipeline overview.A small oracle slice (5‚Äì25%) provides expensive oracle labels to train a calibration model (S‚ÜíYS\\to Y). The learned mapping is then applied to bulk evaluation data where oracle labels are unavailable, enabling policy evaluation at a fraction of the cost. (In experiments, the oracle is GPT-5; in production this would typically be human raters or downstream KPIs.)",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2512.11150/figs/monotone_vs_two_stage.png",
                "caption": "Figure 2:AutoCal-R: monotone vs. two-stage calibration.Left: standard isotonic regression enforces monotonicity but cannot capture non-monotonic patterns inùîº‚Äã[Y‚à£S]\\mathbb{E}[Y\\mid S]. Right: two-stage calibration (spline index‚Üí\\toisotonic) can fit flexible patterns while preserving the mean. AutoCal-R automatically selects the mode via cross-validation.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2512.11150/figs/weight_dashboard_per_policy.png",
                "caption": "Figure 3:SIMCal-W weight stabilization across Arena policies(n=4,961n{=}4{,}961samples with complete logprobs for all four target policies). Raw importance weights (blue dots) span10‚àí13010^{-130}to10210^{2};SS-monotone projection (green line) stabilizes weights while preserving unit-mean. ESS improvements range from 4.6√ó\\times(clone) to>>3000√ó\\times(parallel_universe_prompt). Thepremiumpolicy shows weights spanning 130 orders of magnitude before stabilization. Note:Table3reports ablation-averaged ESS across experimental conditions.",
                "position": 710
            }
        ]
    },
    {
        "header": "4Theory: EIF, Design-by-Projection, and Efficiency",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11150/figs/forest_plot_n1000_oracle25.png",
                "caption": "Figure 4:CJE output: policy value estimates atn=1000n{=}1000, 25% oracle.Red diamonds show oracle ground truth; blue circles show CJE estimates with 95% CIs. CIs capture the true value for policies satisfying transportability;unhelpful(which violates transportability) shows slight miscoverage, a failure mode flagged by the transportability test (Figure6). This is representative of what a practitioner would see when applying CJE to their own evaluation data.",
                "position": 1563
            },
            {
                "img": "https://arxiv.org/html/2512.11150/figs/oua_vs_base_variance.png",
                "caption": "Figure 5:Uncertainty decomposition atn=1000n{=}1000fordirect+cov.Yellow: base sampling uncertainty (constant‚àº\\sim0.014). Orange: oracle uncertainty (dominates at 5% oracle fraction, vanishes at 100%).\nAt 5% oracle fraction, OUA contributes 55% of total variance; ignoring it produces invalid CIs.",
                "position": 1566
            },
            {
                "img": "https://arxiv.org/html/2512.11150/figs/transportability_statistical_5k.png",
                "caption": "Figure 6:Policy-wise mean transport test at 25% oracle fraction.TestingH0,œÄ‚Ä≤:ùîºœÄ‚Ä≤‚Äã[Y‚àíf‚Äã(S,X)]=0H_{0,\\pi^{\\prime}}:\\mathbb{E}_{\\pi^{\\prime}}[Y-f(S,X)]=0per policy (Bonferroni-correctedŒ±=0.0125\\alpha{=}0.0125).\nClone, Parallel Universe, and Premium pass (residuals centered at zero).\nUnhelpful fails (mean residual=‚àí0.31=-0.31): the surrogateoverestimatesoracle scores for adversarial responses by+0.31+0.31in absolute level.",
                "position": 1571
            },
            {
                "img": "https://arxiv.org/html/2512.11150/figs/mde_direct_cov.png",
                "caption": "Figure 7:Sample size planning fordirect+cov.(A) RMSE by sample size and oracle fraction.\n(B) Standard errors including OUA.\n(C) MDE contours showing the smallest effect detectable at 80% power.\nDashed lines show common detection thresholds; cells with MDE<0.02<0.02enable detecting 2-point quality differences.Example:To detect a 3% improvement with 80% power requiresn‚â•1,000n{\\geq}1{,}000with‚â•10%{\\geq}10\\%oracle fraction.",
                "position": 1596
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Related Work",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix ANotation and Formal Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.11150/figs/two_stage_with_cov.png",
                "caption": "Figure 8:Two-stage calibration with covariates.Left: first-stage spline on judge score (response length fixed at mean). Center: first-stage effect of response length (judge score fixed). Right: second-stage isotonic mapping on the risk index (Stage 1 output) enforces monotonicity while preserving flexibility from the first stage.",
                "position": 2153
            }
        ]
    },
    {
        "header": "Appendix BAlgorithms (extended)",
        "images": []
    },
    {
        "header": "Appendix CProofs and Technical Lemmas",
        "images": []
    },
    {
        "header": "Appendix DDiagnostics, Gates, and Reporting (details)",
        "images": []
    },
    {
        "header": "Appendix EImplementation, Engineering, and Reproducibility",
        "images": []
    },
    {
        "header": "Appendix FEfficient Budget Allocation",
        "images": []
    }
]