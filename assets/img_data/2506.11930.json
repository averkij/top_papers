[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x1.png",
                "caption": "Figure 1:Top:Accuracy of varioussolvermodels when iteratively exposed to feedback of afeedbackmodel (GPT-4.1 mini) with access to ground-truth answers.\nThe horizontal dotted linerepresents the target accuracy models could theoretically attain if they successfully incorporated all feedback\n(details in ¬ß4.1).\nDespite receiving high-quality feedback,solver models consistently plateau below their target accuracy.Bottom:Breakdown of questions that remained unsolved by the strongest solver model tested (Claude 3.7 Thinking) after multiple correction attempts.Feedback resistance, rather than feedback quality issues, is responsible for the majority of persistent errors.",
                "position": 199
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2A controlled framework to surfaceFeedback Friction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x2.png",
                "caption": "Figure 2:Iterative self-improvement loop.The process involves: (1) asolvermodel generating an answer, (2) afeedbackmodel generating feedback given incorrect responses and the ground-truth correct answer, and (3) thesolverattempting again with this feedback. This cycle repeats for up to 10\niterations or until a correct answer is produced.",
                "position": 262
            }
        ]
    },
    {
        "header": "3Experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x3.png",
                "caption": "Figure 3:The performance of frontier models we tested with Strong-Model Reflective Feedback (F3subscriptùêπ3F_{3}italic_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) across nine different tasks. Models are given multiple attempts with feedback that incorporates both the final answer and complete solution (when available). The dotted linerepresents the target accuracy that models could theoretically achieve if they fully incorporated all feedback (details in ¬ß4.1).Results demonstrate that despite strong feedback, models consistently plateau below their target accuracy across all tasks.",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x4.png",
                "caption": "Figure 4:Performance comparison across benchmark datasets using different feedback mechanisms with Llama-3.3, Llama-4-Scout and Llama-4-Maverick.Model performance progressively improves as feedback quality increases from Binary Correctness Feedback (F1subscriptùêπ1F_{1}italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT) to Strong-Model Reflective Feedback (F3subscriptùêπ3F_{3}italic_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT).",
                "position": 398
            }
        ]
    },
    {
        "header": "4Analysis ofFeedback Friction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x5.png",
                "caption": "Figure 5:Results of using progressively increasing temperature and rejection sampling with Llama-4-Scout and Llama-4-Maverick.Rejection sampling can provide additional improvements over temperature-based sampling alone across both multiple-choice and non-multiple-choice tasks.",
                "position": 520
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x6.png",
                "caption": "Figure 6:Accuracy of Llama4 Scout (top) and Llama4 Maverick (bottom) on 5-digit multiplication.",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x7.png",
                "caption": "",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x8.png",
                "caption": "Figure 7:Accuracy of Llama3.3 on PopQA with respect to s_pop and o_pop",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x9.png",
                "caption": "",
                "position": 567
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompts and evaluation details for problem solving and feedback generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x10.png",
                "caption": "Figure 8:System prompts used for the solver model across all tasks.",
                "position": 1593
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x11.png",
                "caption": "Figure 9:Prompt used for iterative self-improvement",
                "position": 1599
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x12.png",
                "caption": "Figure 10:Prompt used for generating the feedback.",
                "position": 1622
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x13.png",
                "caption": "Figure 11:Error Categorization",
                "position": 1651
            }
        ]
    },
    {
        "header": "Appendix BError categorization examples from iterative self-improvement",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x14.png",
                "caption": "Figure 12:Llama-4-Scout resisting feedback from GPT-4.1 mini in MMLU",
                "position": 1662
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x15.png",
                "caption": "Figure 13:Wrong feedback provided by GPT-4.1 mini judged by o4-mini",
                "position": 1665
            }
        ]
    },
    {
        "header": "Appendix CSynthetic digit multiplication task details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x16.png",
                "caption": "Figure 14:Templates for 5-digit multiplication solution.",
                "position": 1690
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x17.png",
                "caption": "Figure 15:Hexadecimal 5-Digit Multiplication process solution.",
                "position": 1709
            }
        ]
    },
    {
        "header": "Appendix DAnalysis of model confidence andFeedback Friction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x18.png",
                "caption": "(a)GPQA confidence vs. accuracy",
                "position": 1800
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x18.png",
                "caption": "(a)GPQA confidence vs. accuracy",
                "position": 1803
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x19.png",
                "caption": "(b)MMLU confidence vs. accuracy",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x20.png",
                "caption": "(c)MMLU Pro confidence vs. accuracy",
                "position": 1814
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x21.png",
                "caption": "(d)TriviaQA confidence vs. accuracy",
                "position": 1819
            }
        ]
    },
    {
        "header": "Appendix EAnalysis of data familiarity andRigid Thinking",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x22.png",
                "caption": "(a)GPQA in-domain performance",
                "position": 1840
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x22.png",
                "caption": "(a)GPQA in-domain performance",
                "position": 1843
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x23.png",
                "caption": "(b)TriviaQA in-domain performance",
                "position": 1848
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x24.png",
                "caption": "(c)5-digit multiplication in-domain",
                "position": 1854
            },
            {
                "img": "https://arxiv.org/html/2506.11930/x25.png",
                "caption": "(d)MMLU Pro in-domain performance",
                "position": 1859
            }
        ]
    },
    {
        "header": "Appendix FAnalysis of reasoning complexity andFeedback Friction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.11930/x26.png",
                "caption": "Figure 18:Comparison of the Improvement for 5-digit and 6-digit multiplication with GPT-4.1 mini as feedback model",
                "position": 1877
            }
        ]
    },
    {
        "header": "Appendix GAnalysis of model type andFeedback Friction",
        "images": []
    }
]