[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIRelated work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17779/x1.png",
                "caption": "Figure 1:Comparison of different vision-language tuning frameworks: (a) Methods that directly extend the input space of the language model with extracted vision features. (b) Methods that fuse vision information into the language model via cross-attention. (c) Our proposed ADEM-VL framework, which incorporates parameter-free cross-attention, multiscale visual prompting, and adaptive multimodal fusion designs. This approach ensures both parameter and computational efficiency while delivering promising performance.",
                "position": 219
            }
        ]
    },
    {
        "header": "IIIMethod",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17779/x2.png",
                "caption": "",
                "position": 392
            }
        ]
    },
    {
        "header": "IVExperiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17779/x3.png",
                "caption": "Figure 2:Comparison of different hyperparameter settings in the ADEM-VL with LLaMA-7B as the language model.",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2410.17779/x4.png",
                "caption": "Figure 3:Visualization of image captioning results with LLaMA-7B. In each row, the left figure is the original image, while the middle and right figures demonstrate the dropping decisions for features at two different scales.",
                "position": 1525
            },
            {
                "img": "https://arxiv.org/html/2410.17779/x5.png",
                "caption": "Figure 4:Examples of zero-shot instruction-following tasks with LLaMA-7B.",
                "position": 1595
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]