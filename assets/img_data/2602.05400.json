[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05400/figs/SJTU.png",
                "caption": "",
                "position": 85
            },
            {
                "img": "https://arxiv.org/html/2602.05400/figs/qwen.png",
                "caption": "",
                "position": 88
            },
            {
                "img": "https://arxiv.org/html/2602.05400/figs/uw.png",
                "caption": "",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2602.05400/figs/UIUC.png",
                "caption": "",
                "position": 93
            },
            {
                "img": "https://arxiv.org/html/2602.05400/figs/Mila.png",
                "caption": "",
                "position": 96
            },
            {
                "img": "https://arxiv.org/html/2602.05400/x1.png",
                "caption": "Figure 1:OPUS outperforms random selection by an average of 2.2% accuracy across 10 benchmarks and achieves 8Ã—\\timesreduction in computation on GPT-XL using FineWeb dataset.",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05400/x2.png",
                "caption": "Figure 2:Comparison of different data selection methods.",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2602.05400/x3.png",
                "caption": "Figure 3:Overview of OPUS pipeline.",
                "position": 152
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Optimizer-induced Preconditioners",
        "images": []
    },
    {
        "header": "5Methodology: OPUS",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05400/x4.png",
                "caption": "Figure 4:Validation-loss curves on GPT-2 XL and GPT-2 Large pre-trained from scratch on FineWeb-Edu dataset. Left: Results on GPT-2 XL. OPUS compared with representative baselines trained on the high-quality pool, with Random 60B shown as a non compute-matched reference. Curves are shown up to 30B update tokens for compute-matched comparison. Right: Results on GPT2-Large.",
                "position": 2523
            },
            {
                "img": "https://arxiv.org/html/2602.05400/x5.png",
                "caption": "Figure 5:CPT domain breakdown on SciencePedia.Domain-level accuracy of Qwen3-8B-Base and CPT baselines across three token budgets 0.5B, 1B, and 1.5B.\nRows correspond to the CPT token budget. Columns show (a) OlympicArena domains with an appended Avg. and (b) SciAssess domains.\nFor each panel, we compare Qwen3-8B-Base, Full CPT (3B), Random, DCLM, and OPUS. All results use the official benchmark metrics.",
                "position": 3076
            },
            {
                "img": "https://arxiv.org/html/2602.05400/x6.png",
                "caption": "Figure 6:Continued pre-training results on SciencePedia.",
                "position": 3090
            },
            {
                "img": "https://arxiv.org/html/2602.05400/x7.png",
                "caption": "Figure 7:Efficiency and computational cost analysis.Time (minutes) and total compute (PFLOPs) are evaluated on GPT-2 XL after pre-training on FineWeb (30B tokens) with Muon.",
                "position": 3398
            }
        ]
    },
    {
        "header": "7Conclusion and Future work",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AQualitative Results",
        "images": []
    }
]