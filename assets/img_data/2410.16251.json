[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.16251/x1.png",
                "caption": "Figure 1:Framework ofHalluEditBench. For real-world hallucinations, we holistically assess the performance of knowledge editing onEfficacy,Generalization,Portability,Locality, andRobustness.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x2.png",
                "caption": "Figure 2:Statistics ofHalluEditBenchAcross Topics and Domains.",
                "position": 177
            }
        ]
    },
    {
        "header": "2HalluEditBench: Holistically Benchmarking Knowledge Editing Methods in Correcting Real-World Hallucinations",
        "images": []
    },
    {
        "header": "3Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.16251/x3.png",
                "caption": "Figure 3:Efficacy Scores of Knowledge Editing Methods. The “overall” refers to the Efficacy Score (%) on the whole HalluEditBench embracing 9 domains for different methods. The Efficacy Score on each domain is also reported. Efficacy scores (%) are measured by the accuracy on Efficacy Evaluation Question-answer Pairs, where the pre-edit scores of each LLM are ensured 0.",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x4.png",
                "caption": "Figure 4:Generalization Scores of Knowledge Editing Methods. Generalization Scores (%) are measured by accuracy on five types of Generalization Evaluation Questions including Rephrased Questions (“rephrase”), Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to averaged scores over five question types.\nThe figure only shows the overall Generalization Scores for each type on the whole HalluEditBench. Generalization Scores for each domain are given in AppendixE.1.",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x5.png",
                "caption": "Figure 5:Portability Scores of Knowledge Editing Methods. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions withN𝑁Nitalic_Nhops (N=1∼6𝑁1similar-to6N=1\\sim 6italic_N = 1 ∼ 6). The Portability Evaluation Questions are the same as Efficacy Evaluation Questions whenN𝑁Nitalic_Nis 1. The Portability Scores on two domains “human” and “places” are reported in the figure. The results for more domains are given in AppendixE.2. The “overall” refers to the Portability Score (%) on the whole HalluEditBench embracing 9 domains.",
                "position": 354
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x6.png",
                "caption": "Figure 6:Locality Scores of Knowledge Editing Methods. Locality Scores (%) are measured by the unchanging rate on Locality Evaluation Questions after applying knowledge editing methods on LLMs. A higher Locality Score indicates that there is a higher percentage of LLMs’ answers to the unrelated questions keeping the same and a less side effect on general knowledge in LLMs. The “overall” refers to the Locality Score (%) on the whole HalluEditBench embracing 9 domains for different methods. The Locality Score on each domain is also reported in the figure.",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x7.png",
                "caption": "Figure 7:Robustness Scores of Knowledge Editing Methods. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions withM𝑀Mitalic_Mturns (M=1∼10𝑀1similar-to10M=1\\sim 10italic_M = 1 ∼ 10). We regard Efficacy Scores as the Robustness Scores whenM𝑀Mitalic_Mis 0. The Robustness Scores on two domains “human” and “places” are reported in the figure. The results for more domains are given in AppendixE.3. The “overall” refers to the Robustness Score (%) on the whole HalluEditBench embracing 9 domains.",
                "position": 406
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AReproducibility Statement",
        "images": []
    },
    {
        "header": "Appendix BDetails of the Benchmarked Knowledge Editing Techniques",
        "images": []
    },
    {
        "header": "Appendix CA More Detailed Related Work",
        "images": []
    },
    {
        "header": "Appendix DImpact Statement",
        "images": []
    },
    {
        "header": "Appendix EMore Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.16251/x8.png",
                "caption": "Figure 8:Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (“rephrase”), two types of Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to the averaged scores over five types of questions. The domains include “places” and “human”.",
                "position": 2460
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x9.png",
                "caption": "Figure 9:Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (“rephrase”), two types of Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to the averaged scores over five types of questions. The domains include “art” and “business”.",
                "position": 2463
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x10.png",
                "caption": "Figure 10:Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (“rephrase”), two types of Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to the averaged scores over five types of questions. The domains include “entertainment” and “event”.",
                "position": 2466
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x11.png",
                "caption": "Figure 11:Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (“rephrase”), two types of Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to the averaged scores over five types of questions. The domains include “geography” and “health”.",
                "position": 2469
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x12.png",
                "caption": "Figure 12:Generalization Scores of Knowledge Editing Methods on 3 LLMs and 2 Domains. Generalization Scores (%) are measured by the accuracy on five types of Generalization Evaluation Question-answer Pairs including Rephrased Questions (“rephrase”), two types of Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-Choice Questions (“mc”), Reversed Questions (“reversed”). The “average” refers to the averaged scores over five types of questions. The domain is “technology”.",
                "position": 2472
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x13.png",
                "caption": "Figure 13:Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when withN𝑁Nitalic_Nhops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions whenN𝑁Nitalic_Nis 1. The domains include “business”, “entertainment”, and “event”.",
                "position": 2481
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x14.png",
                "caption": "Figure 14:Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when withN𝑁Nitalic_Nhops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions whenN𝑁Nitalic_Nis 1. The domains include “geography”, “health”, and “technology”.",
                "position": 2484
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x15.png",
                "caption": "Figure 15:Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Portability Scores (%) are measured by the accuracy on Portability Evaluation Questions, which are Efficacy Evaluation Questions when withN𝑁Nitalic_Nhops. The Portability Evaluation Questions are the same as Efficacy Evaluation Questions whenN𝑁Nitalic_Nis 1. The domain is “art”.",
                "position": 2487
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x16.png",
                "caption": "Figure 16:Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions withM𝑀Mitalic_Mturns (M=1∼10𝑀1similar-to10M=1\\sim 10italic_M = 1 ∼ 10). We regard Efficacy Scores as the Robustness Scores whenM𝑀Mitalic_Mis 0. The domains include “business”, “entertainment”, and “event”.",
                "position": 2496
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x17.png",
                "caption": "Figure 17:Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions withM𝑀Mitalic_Mturns (M=1∼10𝑀1similar-to10M=1\\sim 10italic_M = 1 ∼ 10). We regard Efficacy Scores as the Robustness Scores whenM𝑀Mitalic_Mis 0. The domains include “geography”, “health”, and “technology”.",
                "position": 2499
            },
            {
                "img": "https://arxiv.org/html/2410.16251/x18.png",
                "caption": "Figure 18:Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains. Robustness Scores are calculated by the accuracy on Robustness Evaluation Questions withM𝑀Mitalic_Mturns (M=1∼10𝑀1similar-to10M=1\\sim 10italic_M = 1 ∼ 10). We regard Efficacy Scores as the Robustness Scores whenM𝑀Mitalic_Mis 0. The domain is “art”.",
                "position": 2502
            }
        ]
    },
    {
        "header": "Appendix FExamples of HalluEditBench",
        "images": []
    }
]