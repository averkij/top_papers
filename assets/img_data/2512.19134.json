[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19134/x1.png",
                "caption": "Figure 1:Comparison of retrieval triggering mechanisms. (a) DRAGIN relies on model-internal signals, incorrectly assigning high uncertainty to “Il” (a token from the question) while showing low uncertainty on the hallucinated director name. (b) QuCo-RAG correctly detects the hallucination through zero entity co-occurrence in the pre-training corpus.",
                "position": 184
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19134/x2.png",
                "caption": "Figure 2:Overview of QuCo-RAG Framework.",
                "position": 207
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19134/x3.png",
                "caption": "Figure 3:Efficiency-performance trade-off analysis on HotpotQA with OLMo-2-13B-Instruct. (a) EM score versus Token consumption. (b) EM score versus LLM calls. (c) Performance versus Retrieval frequency. QuCo-RAG achieves the highest EM with moderate token usage and LLM calls.",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2512.19134/x4.png",
                "caption": "Figure 4:Average runtime breakdown per question for QuCo-RAG components across OLMo-2 model sizes on 2WikiMultihopQA.",
                "position": 756
            }
        ]
    },
    {
        "header": "6Analysis and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19134/x5.png",
                "caption": "Figure 5:Performance stratified by entity frequency bins on 2WikiMultihopQA (OLMo-2-7B).",
                "position": 897
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.19134/x6.png",
                "caption": "Table 6:Examples of triplet extractor training data. The model extracts factual triplets from declarative sentences, partial triplets from questions (since the answer is unknown), and returns empty for non-factual statements.",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2512.19134/x6.png",
                "caption": "Figure 6:Threshold sensitivity analysis on 2WikiMultihopQA with OLMo-2-7B.",
                "position": 1114
            },
            {
                "img": "https://arxiv.org/html/2512.19134/x7.png",
                "caption": "",
                "position": 1123
            },
            {
                "img": "https://arxiv.org/html/2512.19134/x8.png",
                "caption": "Figure 7:Performance comparison of QuCo-RAG with different retrievers (Qwen3-Embedding, SGPT, and BM25) on 2WikiMultihopQA using OLMo-2-7B.",
                "position": 1720
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]