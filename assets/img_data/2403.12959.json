[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x1.png",
                "caption": "Figure 1:WHAC synergizes human-camera (camera-frame SMPL-X estimation), camera-world (visual odometry), and human-world (our proposed MotionVelocimeter) modeling for constructing world-grounded human and camera trajectories.",
                "position": 131
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x2.png",
                "caption": "Figure 2:Overview ofWHAC. SMPL-X estimator extracts camera-frame SMPL-X with dummy depth, which is recovered inSec.3.2. The scaleless camera trajectory estimated by VO is then used to canonicalize the human trajectory to estimate its velocity and thus scale inSec.3.3. A camera trajectory is then derived for alignment and scale recovery, which subsequently updates the human trajectory inSec.3.4.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2403.12959/x3.png",
                "caption": "Figure 3:a) Human trajectoriesHùêªHitalic_Hderived from camera trajectoriesCùê∂Citalic_Cof different scales can be vastly different in both shape and direction, despite that the same camera-frame human root depthdtsubscriptùëëùë°d_{t}italic_d start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand translationsthcsubscriptsuperscriptùë°ùëê‚Ñét^{c}_{h}italic_t start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPTare used. b) Different pairs of focal lengthfùëìfitalic_fandtzsubscriptùë°ùëßt_{z}italic_t start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPTcan correspond to the same image.",
                "position": 201
            }
        ]
    },
    {
        "header": "4WHAC-A-Mole Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x4.png",
                "caption": "Figure 4:Visualization of WHAC-A-Mole sample sequences, animated with a) AMASS, b-c) DLP-MoCap, and d-e) DD100. In each sample, the first row depicts the overview (note the camera trajectory shown in bright rays), and the second and the third rows show the camera view and overlaid SMPL-X annotations.",
                "position": 521
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x5.png",
                "caption": "Figure 5:Visualizationon in-the-wild hard cases. WHAC leverages human-camera-scene collaboration to resolve cases where motion prior alone would fail: a) Skateboarding and b) Treadmill. c) WHAC can also handle fast cases.",
                "position": 1109
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOverview",
        "images": []
    },
    {
        "header": "Appendix BResults Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x6.png",
                "caption": "Figure 6:Visualizationof world space results on the EMDB dataset. a1) and b1) depict camera trajectories, while a2) and b2) illustrate human trajectories. Notably, in sequence b, the human is descending stairs, and WHAC effectively captures the global trajectory, indicating a downward direction besides recovering the absolute trajectory scale in the world space. The grid size in the plots is 2m.",
                "position": 1784
            },
            {
                "img": "https://arxiv.org/html/2403.12959/x7.png",
                "caption": "Figure 7:Visualizationof camera space results on WHAC-A-Mole dataset. Each sample comprises two rows: the first row displays the original input frames from the sequence, while the second row overlays the SMPL-X results. This visualization showcases WHAC‚Äôs performance on challenging scenes, including sequences with severe occlusions, intricate human interactions, and dynamic dancing poses.",
                "position": 1787
            }
        ]
    },
    {
        "header": "Appendix CMotionVelocimeter",
        "images": [
            {
                "img": "https://arxiv.org/html/2403.12959/x8.png",
                "caption": "Figure 8:Illustration of MotionVelocimeter module. The inputs are canonicalized 3D joints regressed from SMPL-X meshes, and the outputs are root velocities in the canonical space.",
                "position": 1800
            }
        ]
    },
    {
        "header": "Appendix DInference speed",
        "images": []
    },
    {
        "header": "Appendix ETraining Details",
        "images": []
    },
    {
        "header": "Appendix FAdaptations for camera frame EHPS methods",
        "images": []
    },
    {
        "header": "Appendix GComprehensive Formulations",
        "images": []
    }
]