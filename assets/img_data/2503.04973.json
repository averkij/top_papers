[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04973/x1.png",
                "caption": "Figure 1:Overlap match of the words between ground truth and predictions of various KV cache compression methods compared to RAG on a synthetic corpus with 32k tokens. Our Few-Shot compression approach achieves results exceeding RAG when the context length is much smaller than the corpus size.",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x2.png",
                "caption": "Figure 2:An illustration of our compression strategy that reduces the original context (C) from a KV cache of 128k tokens to 16k. This process is guided by task instructions (T) and few-shot examples (FS), condensing the essential information needed for factual QA on the corpus documents. At inference time, the LLM can answer multiple questions as if it had access to the entire (uncompressed) corpus.",
                "position": 114
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04973/x3.png",
                "caption": "Figure 3:We examine how the model attends to context tokens when conditioned on the last token, a task description, a description with few-shot examples, and a description with both few-shot examples and a question. As we increase the information in the prompt, the cross attention between the prompt and the context better discriminates the context tokens that are relevant for decoding the answer. The perplexity is calculated on the loss for the answer.",
                "position": 352
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04973/extracted/6258356/images/data_overview.png",
                "caption": "Figure 4:Overview of our synthetic dataset. In this example, the connectivity level is set to 2.",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2503.04973/extracted/6258356/images/questions_data.png",
                "caption": "Figure 5:Overview of our questions. In this example, the connectivity level is set to 2.",
                "position": 461
            }
        ]
    },
    {
        "header": "6Synthetic Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04973/x4.png",
                "caption": "Figure 6:Performance by increasing target context length (64x to 8x compression rate) and connectivity level for Join-like questions in the synthetic dataset. The dashed line\nindicates for which connectivity level RAG gets the needed chunk for a given context length.",
                "position": 479
            }
        ]
    },
    {
        "header": "7Results and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04973/x5.png",
                "caption": "Figure 7:Performance by retrieval context length size (128x to 16x compression rate) for Direct Retrieval questions with highly similar entity names in the synthetic\ndataset.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x6.png",
                "caption": "Figure 8:Performance by retrieval context length size (64x to 8x compression rate) for the Hard Questions in\nLongBench v2.",
                "position": 576
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x7.png",
                "caption": "Figure 9:Performance results on Longbench. Our FS variant is reported when examples are available (QA tasks). For the QA tasks, the examples used in KVCompress FSt are taken (and removed) at random from the test set.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x8.png",
                "caption": "Figure 10:Performance by connectivity level (64x compression rate) for the Direct Retrieval questions in the synthetic dataset.",
                "position": 596
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x9.png",
                "caption": "Figure 11:Comparison against query-agnostic compressors on our synthetic dataset for Join-like queries with connectivity level=8 across decreasing compression levels (64x to 8x).",
                "position": 707
            },
            {
                "img": "https://arxiv.org/html/2503.04973/x10.png",
                "caption": "Figure 12:Time to first token with increasing corpus length (context length=8192 and question length=512).",
                "position": 750
            }
        ]
    },
    {
        "header": "8Efficiency",
        "images": []
    },
    {
        "header": "9Conclusion and Future work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]