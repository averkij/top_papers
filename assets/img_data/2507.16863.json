[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16863/extracted/6641717/ICLR/imgs/abs.png",
                "caption": "",
                "position": 62
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16863/x1.png",
                "caption": "Figure 1:Evaluation cases for each category, including the four tasks: HiddenText, 3DCaptcha, ColorBlind, and ChineseLigatures. The text beneath each image in every subset represents the corresponding ground truth. The third line ofchinese characters, read from left to right, symbolizesmarital bliss, a serendipitous union, a perfect match, dreams fulfilled, and flawless.",
                "position": 110
            }
        ]
    },
    {
        "header": "2Empirical Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16863/x2.png",
                "caption": "Figure 2:Pass@k Results.Mean and variance curves of pass@k on four tasks ofTET.",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x3.png",
                "caption": "Figure 3:Model response on question of HiddenText.The goal is to identify the hidden word in an image. Gemini-2.5-Pro-0506 answers the hidden word as “castle”.",
                "position": 353
            }
        ]
    },
    {
        "header": "3Preliminary Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16863/x4.png",
                "caption": "Figure 4:Grad-CAM of Qwen2.5-VL Series Models on HiddenText subset.",
                "position": 364
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x5.png",
                "caption": "Figure 5:Grad-CAM of Qwen2.5-VL Series Models on 3DCaptcha.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x6.png",
                "caption": "Figure 6:Grad-CAM of Qwen2.5-VL Series Models on ChineseLigature subset.",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x7.png",
                "caption": "Figure 7:Grad-CAM of Qwen2.5-VL Series Models on ColorBlind.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x8.png",
                "caption": "(a)ColorBlind",
                "position": 403
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x8.png",
                "caption": "(a)ColorBlind",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x9.png",
                "caption": "(b)3DCaptcha",
                "position": 411
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x10.png",
                "caption": "(c)HiddenText",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x11.png",
                "caption": "(d)OCRVQA",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x12.png",
                "caption": "(e)GEOQA",
                "position": 427
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x13.png",
                "caption": "(f)CLEVR",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x14.png",
                "caption": "(a)Downsampling",
                "position": 628
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x14.png",
                "caption": "(a)Downsampling",
                "position": 631
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x15.png",
                "caption": "(b)Blurring",
                "position": 636
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16863/x16.png",
                "caption": "Figure 10:Grad-CAM of Qwen2.5-VL-7B before and after visual fine-tuning on HiddenText.",
                "position": 1645
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x17.png",
                "caption": "Figure 11:Grad-CAM of Qwen2.5-VL-7B before and after visual fine-tuning on ColorBlind.",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x18.png",
                "caption": "Figure 12:Grad-CAM of Qwen2.5-VL-7B before and after visual fine-tuning on 3DCaptcha.",
                "position": 1651
            },
            {
                "img": "https://arxiv.org/html/2507.16863/x19.png",
                "caption": "Figure 13:Example responses from the Gemini model on the four tasks of TET. For each task, the model fails to provide correct analysis and conclusion based on its flawed initial perception.",
                "position": 1673
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]