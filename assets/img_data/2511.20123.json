[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x1.png",
                "caption": "(a)Extending T2V models up to4×4\\times, where existing method yields nearly static, low-quality videos.",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x1.png",
                "caption": "(a)Extending T2V models up to4×4\\times, where existing method yields nearly static, low-quality videos.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x2.png",
                "caption": "(b)Generalization to downstream tasks at3×3\\times. See more tasks in AppendixC.4.",
                "position": 136
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x3.png",
                "caption": "Figure 2:Failure modes of video length extrapolation.Some models exhibitperiodic content repetition, whilequality degradationoccurs universally. Both failure modes intensify with longer extrapolations. “extra.” denotes extrapolation. See AppendixC.1for additional models.",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x4.png",
                "caption": "",
                "position": 192
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x5.png",
                "caption": "",
                "position": 211
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x6.png",
                "caption": "",
                "position": 215
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x7.png",
                "caption": "",
                "position": 234
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x8.png",
                "caption": "Figure 3:Periodic attention patterns as cause of content repetition.Left: unlike Wan, HunyuanVideo exhibits row-wise periodic attention during4×4\\timesextrapolation, causing repeated outputs.\nRight: statistical row-wise attention can be expressed as a linear combination of trigonometric functions of RoPE frequencies, whose properties govern this periodicity. Hun. denotes HunyuanVideo.",
                "position": 310
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x9.png",
                "caption": "",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x10.png",
                "caption": "",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x11.png",
                "caption": "",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x12.png",
                "caption": "Figure 4:Fixing repetition reveals attention dispersion as the fundamental cause.Left: our intervention, initially targeting repetition, surprisingly enhances video quality in both models. Right: the shared mechanism is revealed, where the intervention refocuses diffuse baseline attention toward the central training window. This suggests attention dispersion as the unified cause.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x13.png",
                "caption": "",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x14.png",
                "caption": "",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x15.png",
                "caption": "",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x16.png",
                "caption": "(a)Quantitative results.",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x16.png",
                "caption": "(a)Quantitative results.",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x17.png",
                "caption": "(b)Qualitative results.",
                "position": 514
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x18.png",
                "caption": "Figure 6:Qualitative results on HunyuanVideo. The baselines produce nearly static videos with poor visual quality, whereas our method achieves significantly better quality by addressing extrapolation failure modes. Additional qualitative results for other models are in AppendixC.4.",
                "position": 906
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x19.png",
                "caption": "Figure 7:Ablation studies.Top row: different decay strategies have minor impact, suggesting simple constant decay suffices. Bottom row:\nsmallα\\alphaharms consistency while largeα\\alphaoffers limited gains. An intermediate value (α=0.9\\alpha=0.9) enhances quality while preserving consistency.",
                "position": 909
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x19.png",
                "caption": "",
                "position": 912
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x20.png",
                "caption": "",
                "position": 917
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x21.png",
                "caption": "Figure 8:Illustration of the hyperparameter sensitivity curve.(a) Whenα≥0.9\\alpha\\geq 0.9, motion dynamics improve while consistency stays stable; below 0.9, consistency drops sharply. (b) Whenβ≥0.6\\beta\\geq 0.6, dynamics remain high with comparable consistency; below0.60.6, consistency degrades significantly.",
                "position": 937
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x22.png",
                "caption": "(a)Performance of the video-continuation baseline alone.",
                "position": 1024
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x22.png",
                "caption": "(a)Performance of the video-continuation baseline alone.",
                "position": 1027
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x23.png",
                "caption": "(b)Illustration of combining UltraViCo with the video-continuation method.",
                "position": 1033
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethics STATEMENT",
        "images": []
    },
    {
        "header": "Reproducibility STATEMENT",
        "images": []
    },
    {
        "header": "Use of Large Language Models",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BMore Details of Our Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x24.png",
                "caption": "(a)Statistics of HunyuanVideo.",
                "position": 1329
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x24.png",
                "caption": "(a)Statistics of HunyuanVideo.",
                "position": 1332
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x25.png",
                "caption": "(b)Statistics of Wan.",
                "position": 1338
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x26.png",
                "caption": "Figure 11:Attention logits under actual variance.Even with standard deviation across layers, heads, and query positions, HunyuanVideo retains clear periodic peaks while Wan 2.1 remains non-periodic, confirming the general validity of the mean-based analysis in Sec.3.2.1.",
                "position": 1354
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x27.png",
                "caption": "Figure 12:Periodic attention patterns of CogVideoX.The RoPE frequencies of CogVideoX approximately satisfy the harmonic condition, which amplifies the largest-amplitude component and thereby induces periodic attention patterns.",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x28.png",
                "caption": "",
                "position": 1461
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x29.png",
                "caption": "Figure 13:Comparison of attention concentration strategies on Wan ats=3s=3.Concentrating on the leading or trailing1s\\frac{1}{s}of each row collapses the video, and top–1s\\frac{1}{s}yields poor quality with little dynamics. Restricting attention to the training window proves most effective.",
                "position": 1492
            }
        ]
    },
    {
        "header": "Appendix CMore Details of Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20123/x30.png",
                "caption": "Figure 14:Failure modes of CogVideoX under3×3\\timesextrapolation.The generated videos show degraded visual quality, reduced dynamics, and clear content repetition, consistent with the failure modes discussed in Sec.3.1.",
                "position": 1506
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x31.png",
                "caption": "Figure 15:Qualitative results on Wan. The baselines produce nearly static videos with poor visual quality, whereas our method achieves significantly better quality and much more motion.",
                "position": 2051
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x32.png",
                "caption": "Figure 16:Qualitative results on CogVideoX. The baselines produce nearly static videos with poor visual quality, whereas our method generates realistic results with rich details and fluid motion.",
                "position": 2054
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x33.png",
                "caption": "Figure 17:Our method for pose-guided video generation. Our method closely aligns with the given pose conditions, while ensuring high dynamic range and excellent visual quality.",
                "position": 2057
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x34.png",
                "caption": "(a)Schematic diagram of theα\\alphasensitivity curve.",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x34.png",
                "caption": "(a)Schematic diagram of theα\\alphasensitivity curve.",
                "position": 2147
            },
            {
                "img": "https://arxiv.org/html/2511.20123/x35.png",
                "caption": "(b)Schematic diagram of theβ\\betasensitivity curve.",
                "position": 2153
            }
        ]
    },
    {
        "header": "Appendix DFurther details of UltraViCo",
        "images": []
    }
]