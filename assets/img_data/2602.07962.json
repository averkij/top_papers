[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07962/x1.png",
                "caption": "Figure 1:Overview of results.Left: Accuracy changes across models as the environment description length increases.Right: Accuracy gains from different context engineering strategies for Gemini-3-Flash and GPT-5.2-Medium at 128K environment description length.",
                "position": 108
            }
        ]
    },
    {
        "header": "2LOCA-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07962/x2.png",
                "caption": "Figure 2:Illustration of the task generation pipeline. The figure shows an example of constructing a task that involves reading final-exam information from Canvas and email. From left to right, it shows how benchmark users set environment configuration parameters, such as the number of courses and the proportion of Canvas announcements versus email notifications. A programmatic generator then uses predefined templates for courses, exams, announcements, and emails to instantiate matching environment states – such as specific Canvas course pages, announcements, and email messages – and inserts them into the server.",
                "position": 133
            }
        ]
    },
    {
        "header": "3Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07962/x3.png",
                "caption": "Figure 3:Impact of environment description length on(a)trajectory length,(b)number of tool calls, and(c)tool output length.",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2602.07962/x4.png",
                "caption": "Figure 4:An example of insufficient exploration. The task is to identify all products that satisfy the criteria and save them to a CSV file in the workspace. However, the agent fetches only the first 100 products and finds no matches in that subset. It then stops without checking the remaining catalog, writes nothing to the CSV, and the output does not match the ground-truth CSV, causing the evaluation to fail. We highlight the failed goal, the failure-related tool call, and the mismatched final workspace in red.",
                "position": 337
            }
        ]
    },
    {
        "header": "4Context Engineering for Agents",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AStatistics across environment description lengths",
        "images": []
    },
    {
        "header": "Appendix BTool Sets Used in Tasks",
        "images": []
    },
    {
        "header": "Appendix CFailure Mode Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07962/x5.png",
                "caption": "Figure 5:An example of declining complex reasoning. The task requires the model to gather final exam details from both Canvas announcements and email notifications, then link each exam to its corresponding course in Canvas. However, the model ignores the exam information contained in emails and never consults the Canvas dashboard for course identifiers. As a result, it writes only the exams mentioned in Canvas announcements into the Excel file. Since the ground truth includes exam information from both announcements and emails, this omission causes the evaluation to fail. We highlight the failed goal, the failure-related tool call, and the mismatched final workspace in red.",
                "position": 1763
            },
            {
                "img": "https://arxiv.org/html/2602.07962/x6.png",
                "caption": "Figure 6:An example of weaker instruction following. This task requires the model to analyze data in BigQuery and record the calculated conversion rate in CSV format. The ground truth requires the CSV column names to be A_conversion % and B_conversion %, but the model ultimately created a new CSV file with column names A_conversion_pct and B_conversion_pct, which caused the evaluation to fail. We highlight the failed goal, the failure-related tool call, and the mismatched final workspace in red.",
                "position": 1768
            },
            {
                "img": "https://arxiv.org/html/2602.07962/x7.png",
                "caption": "Figure 7:An example of hallucination. This task requires the model to read the real-time sensor data of factory machines recorded in BigQuery and identify data that exceeds the normal range. The model queries the correct data for M006, but when writing Python code, it records incorrect data in the code. This ultimately causes the generated CSV file to include M006 data that was originally within the normal range, leading to evaluation failure. We highlight the failed goal, the failure-related tool call, and the mismatched final workspace in red.",
                "position": 1773
            },
            {
                "img": "https://arxiv.org/html/2602.07962/x8.png",
                "caption": "Figure 8:An example of programmatic tool calling. This task requires the model to find products in WooCommerce that have stock below the threshold. After examining the format of the tool’s outptu, the model chooses programmatic tool calling that invokes the WooCommerce tool to detect products with stock below the threshold, and explicitly accounts for operations such as pagination in the code.",
                "position": 1778
            }
        ]
    },
    {
        "header": "Appendix DProgrammatic Tool Calling Examples",
        "images": []
    }
]