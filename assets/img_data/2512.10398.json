[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10398/assets/logo.png",
                "caption": "",
                "position": 113
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10398/x1.png",
                "caption": "Figure 1:Confucius SDK overview.The SDK unifies an orchestrator for iterative reasoning and action execution, long-term memory for continual learning, and modular extensions for tool use and interacting with the external environment.",
                "position": 184
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10398/x2.png",
                "caption": "Figure 2:An illustration for AX, UX, and DX.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2512.10398/x3.png",
                "caption": "Figure 3:Context compression overview.When the context window approaches configurable thresholds, theArchitectagent summarizes earlier turns into a structured plan containing goals, decisions, errors, and open TODOs. These compressed summaries replace original large spans of history while preserving a short window of recent interactions, enabling the agent to sustain multi-step reasoning over long trajectories without exceeding context limits.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2512.10398/x4.png",
                "caption": "Figure 4:Meta-agent build–test–improve loop.The Meta-agent synthesizes agent configurations, wires together orchestrator components and extensions, evaluates candidate agents on representative tasks, and iteratively refines prompts and tool-use policies based on observed failures.",
                "position": 527
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Future Work — Toward an End-to-End Reinforcement Learning Framework for Agentic Software Engineering",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Thinking Budget Scaling on SWE-bench-Verified",
        "images": []
    },
    {
        "header": "8Example Notes",
        "images": []
    },
    {
        "header": "9Case Studies: Comparison with Claude Code",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10398/x5.png",
                "caption": "Figure 5:Simplified traces for CCA and CC on PyTorch issue #161356",
                "position": 1840
            },
            {
                "img": "https://arxiv.org/html/2512.10398/x6.png",
                "caption": "Figure 6:CCA Trace UI with call stack visualization and tool invocation details.",
                "position": 1875
            }
        ]
    },
    {
        "header": "10Trace UI",
        "images": []
    }
]