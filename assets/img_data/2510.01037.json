[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01037/x1.png",
                "caption": "Figure 1:Illustration of our theoretical and practical contributions. The first part presents our theoretical analysis, which establishes the relationship between the gradient efficiency and models’ question-answering accuracy, denoted aspθ​(x)p_{\\theta}(x). Building upon these insights, we develop CurES, a practical method that initially estimatespθ​(x)p_{\\theta}(x)using a small rollout quantity, then reallocates prompt sampling probabilities and rollout quantities based on the estimated accuracy.\nWe progressively enhance the confidence of these accuracy estimates through posterior estimation. The figure further contrasts CurES with existing approaches, highlighting differences in managing prompt sampling distributions of Speed-RL(Zhang et al.,2025)and rollout quantities of GVM(Yao et al.,2025).",
                "position": 86
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01037/x2.png",
                "caption": "Figure 2:Comparison of learning curves between CurES and GVM across different backbone models and advantage estimators. CurES consistently outperforms GVM under the same number of training steps, demonstrating more efficient utilization of samples.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x3.png",
                "caption": "Figure 3:The evolution of the estimated accuracy distributions for the Qwen2.5-Math-1.5B (left) and 7B (right) models across 15 iterations. Each violin shows the distribution of accuracy across samples: the width reflects density, the central line marks the median.",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x4.png",
                "caption": "Figure 4:Allocation of rollout quantities with respect to accuracy in CurES at different training iterations. CurES concentrates more rollouts on moderately difficult prompts.",
                "position": 844
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x5.png",
                "caption": "Figure 5:Performance convergence of CurES on MATH500 with different sampling configurations.",
                "position": 862
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x6.png",
                "caption": "Figure 6:Efficiency comparison of CurES against baselines on MATH500. Gray dashed lines indicate the steps required for CurES and the baseline to reach the highest average accuracy of the baseline during the entire training period.",
                "position": 865
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMathematical Derivations",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.01037/x7.png",
                "caption": "Figure 7:Comparison of Average Gradient Norms. This figure compares the average gradient norms among CurES-GRPO, CurES-RPP, GRPO, and RPP. The CurES variants consistently exhibit higher gradient norms in three out of the four algorithm-and-model-scale combinations, suggesting that the CurES effectively selects more informative prompts, thereby accelerating the training process.",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x8.png",
                "caption": "Figure 8:Distribution of rollout quantities with respect to accuracy in CurES base on Qwen2.5-Math-7B at different training iterations.CurES concentrates more rollouts on moderately difficult prompts.",
                "position": 2345
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x9.png",
                "caption": "Figure 9:Performance convergence of Qwen2.5-Math-CurES-7B on MATH500 with different sampling configurations.",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2510.01037/x10.png",
                "caption": "Figure 10:Efficiency comparison of CurES against baselines on MATH500 with Qwen2.5-Math-7B. Gray dashed lines indicate the steps required for CurES and the baseline to reach the highest average accuracy of the baseline during the entire training period.",
                "position": 2363
            }
        ]
    },
    {
        "header": "Appendix BAlgorithmic Implementation",
        "images": []
    }
]