[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11747/assets/problem_formulation.png",
                "caption": "Figure 1:A user provides a design to improve and a natural language instruction.PRISMleverages existing design data to generate diverse improvements that align with the requested style. In contrast, approaches that solely rely on VLMs’ pretrained knowledge on styles produce outputs that fail to match the design data.",
                "position": 96
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/approach.png",
                "caption": "Figure 2:PRISMOverview.Given design data with a style “abstract,” the (1) Style Space Partitioning stage identifies visually distinctive clusters. Then, (2) Knowledge Extraction focuses on learning concise, actionable knowledge from these clusters.\nUnder a contrastive framework, the VLM compares and contrast positive and negative examples before generating the knowledge.\nWe highlight two examples of how positive/negative designs influence specific lines in the guideline.\nDuring inference, (3) Prior-Informed Edits proportionally retrieves relevant design knowledge based on the original design data distribution, thereby outputting diverse improvements that also align with data.",
                "position": 158
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/main_average_results.png",
                "caption": "Figure 3:Main Results.We report the average fidelity and diversity with standard error across 15 styles.PRISMachieve the highest value for both metrics. On the left, we also visualize different methods’ input/output.",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/qualitative.png",
                "caption": "Figure 4:Qualitative Results.We show 3 styles, each representative ofPRISM’s different performance. “abstract” is one wherePRISMachieves the highest rank for both fidelity and diversity. “artistic” is where one is high (fidelity). “modern” is where both ranks are lower.",
                "position": 261
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/fidelity_diversity_ranks.png",
                "caption": "Figure 5:Expected Ranks.We report the expected ranks across all styles.PRISMachieves the best rank in both fidelity and diversity, showing its ability to balance the two metrics.",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/fidelity_analysis_example.png",
                "caption": "Figure 6:Qualitative Comparison of Knowledge Learned by Different Data-Driven Approaches.BaselinesData2OneandData2Diverseuse randomly sample designs as input, which results in high variance. Conditioning on these,Data2Onelearns a design knowledge that is too general and lacks detail.Data2Diverseinfers subsets from the noisy data, resulting in knowledge that contrast on arbitrary decisions. In contrast,PRISMreceive inputs that have less variance because of its data curation step, allowing it to learn meaningfully diverse knowledge that results in diverse outputs.",
                "position": 353
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/fidelity_analysis_metric.png",
                "caption": "Figure 7:Quantitative Analysis on Data-Drive Baselines’ Low Fidelity.(Left) computes the average GRAD distance between input examples. Lower intra-distance means that there is less variance in the input. (Right) We run K-medoids on each set of input before computing the silhouette score. A higher silhouette suggests that input contains more meaningful subsets.",
                "position": 356
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/iterative_improvement.png",
                "caption": "Figure 8:Knowledge Refinement Results.We ran 3 round of knowledge refinement. We report the average fidelity and diversity across 7 styles wherePRISM’s fidelity is close to baselines’.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/user_study_main_results.png",
                "caption": "Figure 9:Aggregated User Study Results.We report the average user preference on each option. The first three questions ask the users which approach’s design improvement aligns to the design style in terms of color scheme/decorations/text layouts. The last one ask the user which approach’s output look more diverse.",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/user_study_examples.png",
                "caption": "Figure 10:User Study Qualitative Examples.For each style, we show the quantitative metric as well as the average user preferences across different questions. Below each shows the original design, the language instruction, two approach’s output (during the study, the user does not know which output corresponds to what approach), and representative examples of a style.",
                "position": 1467
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/user_study_per_style.png",
                "caption": "Figure 11:User Study Per-Style Preferences.We report the average user preferences for each design style.",
                "position": 1485
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/full_main_results.png",
                "caption": "Figure 12:Per-Style Average Fidelity and Diversity.We report the bootstrapped average fidelity and diversity for each of the 15 styles. We categorize the styles into 3 categories: (1)PRISMhas the highest fidelity and diversity (2)PRISMonly has the highest fidelity (but not diversity) (3) other baselines have the highest fidelity and diversity.",
                "position": 1537
            },
            {
                "img": "https://arxiv.org/html/2601.11747/assets/iterative_improvement_example.png",
                "caption": "Figure 13:Iterative Knowledge Refinement Qualitative Example.Left shows design knowledge learned duringPRISMiteration 0. It fails to distinguish a negative example. From these failure cases, we generate feedback that is used to refine the knowledge. Right shows iteration 1’s refined knowledge, where additional details and new guidelines are added. Iteration 1 succeeds in distinguish the same negative example. Bottom row shows qualitative example of improved designs guided by knowledge from different iterations. For the two design knowledge, similarities are highlighted in gray, while edits are highlighted in green.",
                "position": 1540
            }
        ]
    },
    {
        "header": "",
        "images": []
    }
]