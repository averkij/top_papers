[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00473/x1.png",
                "caption": "",
                "position": 85
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00473/figures/RealGEN-Comparison.jpg",
                "caption": "Figure 2:From Synthetic Artifacts to Photorealism.Contrasting the common \"fake-feel\" AI artifacts in previous T2I methods , our proposed RealGen achieves enhanced photorealism by progressively evading semantic and feature-level detectors.",
                "position": 107
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3RealGen",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00473/figures/fig3_new.jpg",
                "caption": "Figure 3:Overview of the RealGen Method.(a) The architecture of RealGen, consisting of an LLM component and a Diffusion component. (b) Our detector-based reward model, which evaluates images based on visible artifacts, feature-level artifacts, and text-image alignment. (c) The two-stage post-training process guided by this reward model, which respectively optimizes the LLM and Diffusion components.",
                "position": 172
            }
        ]
    },
    {
        "header": "4RealBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00473/x2.png",
                "caption": "Figure 4:Overview of the RealBench.The left shows the categorical data composition. The right details its evaluation protocol.",
                "position": 278
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.00473/x3.png",
                "caption": "Figure 5:Qualitative comparison of different methods on RealBench.",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2512.00473/x4.png",
                "caption": "Figure 6:Pairwise Realism Comparison Matrix of Open-Sourced Text-to-Image Models.",
                "position": 570
            },
            {
                "img": "https://arxiv.org/html/2512.00473/x5.png",
                "caption": "Figure 7:Ablation experiments on different key components.",
                "position": 687
            },
            {
                "img": "https://arxiv.org/html/2512.00473/x6.png",
                "caption": "Figure 8:Illustration of the key advantages of synthetic images.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2512.00473/x7.png",
                "caption": "Figure 9:Visualization of the effects of different reward functions.",
                "position": 751
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    }
]