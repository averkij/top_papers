[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05551/images/lightening.png",
                "caption": "",
                "position": 48
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x1.png",
                "caption": "",
                "position": 75
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05551/x2.png",
                "caption": "Figure 2:Motivation of our method. Training-free video motion transfer can benefit from redundancies, both at the level of the DiT architecture and of the iterative diffusion process.(a) Motion redundancy: Video motion is small and locally consistent, so a motion token in one frame will only ever match tokens in the next frame within a local neighborhood.(b) Gradient redundancy: Gradient updates in consecutive optimization steps are mostly similar (visualized here with PCA). There is no need to recompute them at every single step.",
                "position": 101
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05551/x3.png",
                "caption": "Figure 3:Illustration of step-skipping gradient optimization. We observe that skipping some steps in the gradient optimization step does not degrade the motion transfer performance.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x4.png",
                "caption": "Figure 4:Overview of our method.Left: Given a reference video, we first leverage the sliding window to extract motion embedding from attention during the inversion stage. At the denoising stage, we calculate the total loss and leverage the step-skipping gradient optimization to guide the video generation.Right:The Step-skipping gradient optimization is proposed to improve gradient redundancy. Additionally, we introduce the corresponding-window loss to boost the motion consistency of generated videos.",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x5.png",
                "caption": "Figure 5:Illustration of attention motion flow extraction with sliding window. Without the sliding window, attention tokens are prone to incorrect correspondences (middle). Incorporating a sliding window improves alignment, leading to better motion consistency (right).",
                "position": 309
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x6.png",
                "caption": "Figure 6:Gallery of our method.Given a reference video, our FastVMT is capable of generating high-quality video clips that faithfully preserve diverse motion patterns.",
                "position": 345
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.05551/x7.png",
                "caption": "Figure 7:Illustration of token correspondence performance across different attention layers of DiT. We extract correspondence maps from multiple attention layers. The middle layers exhibit stronger matching quality.",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x8.png",
                "caption": "Figure 8:Qualitative ablation of the proposed modules. The reference video is shown at the top-left. The prompt is“A white cat is running on the ground”.",
                "position": 392
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x9.png",
                "caption": "Figure 9:Qualitative comparison with baselines.We perform the visual comparison with various baselines using various kinds of motions. Our method obtains better performance in various motions.",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2602.05551/x10.png",
                "caption": "Figure 10:Quantitative ablation comparison on VBench metrics.\nWe select seven metrics to evaluate the effectiveness of the proposed strategy.",
                "position": 568
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]