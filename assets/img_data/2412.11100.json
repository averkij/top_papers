[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11100/x1.png",
                "caption": "",
                "position": 68
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11100/x2.png",
                "caption": "Figure 2:Our pipeline is divided into two stages: low-resolution stage establishes a coarse motion structure, 360-degree setting(the yellow block) involves Panoramic Projecting Denoise to initialize motion that fits to spherical panorama, while the regular perspective setting(the blue block) utilizes Offset Shifting with overlap for the early denoise steps, then the remaining denoise steps are completed by our Offset Shifting Denoise. The up-scaling stage(the green block) utilizes more shift windows to produce a refined, high-resolution panorama with Global Motion Guidance from the low-resoltuion video.",
                "position": 76
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11100/x3.png",
                "caption": "Figure 3:The purposed Offset Shifting Window mechanism, which involves shifting denoising windows both vertically and horizontally between denoise steps to denoise the whole panorama video latent with arbitrary aspect ratio an resolution.\nGenerally, all denosing windows are shifted vertically and horizontally every step, with different ways to handle the windows that cross the spatial boundary.",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2412.11100/x4.png",
                "caption": "Figure 4:Results showcasing the scalability of our model across various resolutions, including 360Â° and rectangular panorama settings as well as both text conditioned and image conditioned generation. For more results please refer to our project page.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2412.11100/x5.png",
                "caption": "Figure 5:The purposed Panoramic Projecting Denoise, where spherical panorama videos (represented as equirectangular projections) are denoised by projecting them into perspective view windows, followed by re-projection back to the equirectangular format, which allowed denoising 360 degree panoramic video with diffusion models trained in regular (perspective) views dataset.",
                "position": 225
            },
            {
                "img": "https://arxiv.org/html/2412.11100/extracted/6070283/Figure/fig6-a.png",
                "caption": "Figure 6:Example frames from a panorama video at the 0th, 16th, 32th, 48th, 64th and 80th frames. Despite the increasing video length, the visual quality of the panorama remains consistent, demonstrating the effectiveness of our method in generating long videos.",
                "position": 259
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.11100/extracted/6070283/Figure/fig5-a.png",
                "caption": "Figure 7:This figure demonstrates the seamlessness of generated panorama videos by horizontally concatenating frames, showcasing continuity across the left and right boundaries.",
                "position": 751
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]