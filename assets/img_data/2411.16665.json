[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16665/x1.png",
                "caption": "Figure 1:EdgeCape.Given a support image, keypoints definition, and skeletal relations(purple), our model localizes the keypoints on a query image(green).\nPrevious methods treat keypoints as isolated (CapeFormer) or use unweighted graphs (GraphCape). We, in contrast, predict weighted graphs that lead to better localization.",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x2.png",
                "caption": "",
                "position": 124
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x3.png",
                "caption": "",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x4.png",
                "caption": "",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/1_skeleton/part1.png",
                "caption": "Figure 2:Graph Definition:(a) Graph structure serves as a strong prior, representing an object‚Äôs 3D structure/anatomy, and remains valid across viewing angles for both rigid and non-rigid objects.\n(b) As Edge placement can be ambiguous, we aim to learn the optimal graph for keypoint localization. We visualize different input graphs(left)and unnormalized output predicted graphs(right).\nOur network disconnects symmetric parts, which can hurt localization, and converges to similar refined skeletons for both inputs.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/1_skeleton/part2.png",
                "caption": "",
                "position": 165
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16665/x5.png",
                "caption": "Figure 3:Framework Overview.Our model consists of three main components: a feature extraction module, a skeleton predictor, and a graph-based keypoint predictor. The feature extraction module processes multi-scale image features, while the skeleton predictor refines the prior graph input by predicting residual connections. The graph-based keypoint predictor then utilizes the keypoint relations based on the refined structure, improving keypoint localization across diverse object geometries.",
                "position": 282
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16665/x6.png",
                "caption": "Figure 4:Skeleton Predictor Model.Our skeleton predictor contains a feature refinement module that uses the prior input graphAp‚Å¢r‚Å¢i‚Å¢o‚Å¢rsubscriptùê¥ùëùùëüùëñùëúùëüA_{prior}italic_A start_POSTSUBSCRIPT italic_p italic_r italic_i italic_o italic_r end_POSTSUBSCRIPTand the support image featuresFssubscriptùêπùë†F_{s}italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTto enhance the keypoint featuresFsksuperscriptsubscriptùêπùë†ùëòF_{s}^{k}italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. Self-attention is then applied to predict the residual adjacency outputŒî‚Å¢AŒîùê¥\\Delta Aroman_Œî italic_A.",
                "position": 375
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/yellow/support/Pileated_Woodpecker_0004_180307_Pileated_Woodpecker_0004_180307_0.png",
                "caption": "Figure 5:Qualitative Comparison.We visualize keypoint predictions for the 1-shot setting.\nThe left column shows the support data, followed by ground-truth query keypoints, and results from different methods.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/gt/American_Three_Toed_Woodpecker_0019_179870_American_Three_Toed_Woodpecker_0019_179870_0.png",
                "caption": "",
                "position": 442
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/capeformer/Pileated_Woodpecker_0004_180307_American_Three_Toed_Woodpecker_0019_179870_2.png",
                "caption": "",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/scape/Pileated_Woodpecker_0004_180307_American_Three_Toed_Woodpecker_0019_179870_2.png",
                "caption": "",
                "position": 446
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/GraphCape/Pileated_Woodpecker_0004_180307_American_Three_Toed_Woodpecker_0019_179870_2.png",
                "caption": "",
                "position": 447
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative/ours/Pileated_Woodpecker_0004_180307_American_Three_Toed_Woodpecker_0019_179870_2.png",
                "caption": "",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x7.png",
                "caption": "",
                "position": 452
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x8.png",
                "caption": "",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x9.png",
                "caption": "",
                "position": 454
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x10.png",
                "caption": "",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x11.png",
                "caption": "",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x12.png",
                "caption": "",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x13.png",
                "caption": "",
                "position": 462
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x14.png",
                "caption": "",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x15.png",
                "caption": "",
                "position": 466
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x16.png",
                "caption": "",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x17.png",
                "caption": "",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x18.png",
                "caption": "",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x19.png",
                "caption": "",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x20.png",
                "caption": "",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x21.png",
                "caption": "",
                "position": 478
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_samples/table_0.png",
                "caption": "Figure 6:Predicted Skeleton.We visualize the unnormalized graph outputs. The left column denotes the inputAp‚Å¢r‚Å¢i‚Å¢o‚Å¢rsubscriptùê¥ùëùùëüùëñùëúùëüA_{prior}italic_A start_POSTSUBSCRIPT italic_p italic_r italic_i italic_o italic_r end_POSTSUBSCRIPTand the right column is the refined adjacency matrix. Line width corresponds to edge weight. The model disconnects symmetric parts and creates new connections that are helpful for localization.",
                "position": 767
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_samples/table_1.png",
                "caption": "",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_samples/2882152593_1_2533221503_1_0.png",
                "caption": "",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_samples/2882152593_1_2533221503_1_1.png",
                "caption": "",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_pca/klipspringer_66_comp_Original_Query.png",
                "caption": "Figure 7:Feature Extraction.PCA visualization comparing different feature extraction models. Our approach captures fine-grained details and asymmetrical features that aid localization.",
                "position": 798
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_pca/swin/klipspringer_66_comp_Query.png",
                "caption": "",
                "position": 812
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_pca/dino/klipspringer_66_original_vs_finetuned.png_Original.png",
                "caption": "",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_pca/dino/klipspringer_66_original_vs_finetuned.png_Finetuned.png",
                "caption": "",
                "position": 814
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASupplementary Index",
        "images": []
    },
    {
        "header": "Appendix BFurther Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.16665/x22.png",
                "caption": "Figure 8:Adjacency Matrix Change Histogram.A histogram showing the weight changes of our predicted weighted graph. We show the change given differentAp‚Å¢r‚Å¢i‚Å¢o‚Å¢rsubscriptùê¥ùëùùëüùëñùëúùëüA_{prior}italic_A start_POSTSUBSCRIPT italic_p italic_r italic_i italic_o italic_r end_POSTSUBSCRIPTinputs. The x-axis shows the change and the y-axis is the log-frequency. The dashed red line shows no change in edge weight.",
                "position": 2079
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x23.png",
                "caption": "",
                "position": 2084
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x24.png",
                "caption": "",
                "position": 2085
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x25.png",
                "caption": "Figure 9:Handling Occlusions.Quantitative results when masking the query image. Our method consistently surpasses GraphCape, leveraging cues provided by the weighted graph structure to overcome information gaps in the query images.",
                "position": 2147
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x26.png",
                "caption": "Figure 10:Instance Adaptability.We visualize an example of instance adaptability.\nThe left column denotes the inputAp‚Å¢r‚Å¢i‚Å¢o‚Å¢rsubscriptùê¥ùëùùëüùëñùëúùëüA_{prior}italic_A start_POSTSUBSCRIPT italic_p italic_r italic_i italic_o italic_r end_POSTSUBSCRIPTand the right column is the refined adjacency matrix.\nIn the top row, we see a graph input of a panda body, where all keypoints are visible.\nIn the bottom row, as some keypoints are occluded (node 15), the input graph includes isolated nodes (node 16). Our predicted graph connects this isolated node to enhance localization.",
                "position": 2163
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x27.png",
                "caption": "",
                "position": 2173
            },
            {
                "img": "https://arxiv.org/html/2411.16665/",
                "caption": "",
                "position": 2174
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x29.png",
                "caption": "",
                "position": 2177
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x30.png",
                "caption": "",
                "position": 2178
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x32.png",
                "caption": "Figure 11:Predicted Skeleton.We visualize the unnormalized graph outputs. The left column denotes the inputAp‚Å¢r‚Å¢i‚Å¢o‚Å¢rsubscriptùê¥ùëùùëüùëñùëúùëüA_{prior}italic_A start_POSTSUBSCRIPT italic_p italic_r italic_i italic_o italic_r end_POSTSUBSCRIPTand the right column is the refined adjacency matrix. Line width corresponds to edge weight. The model disconnects symmetric parts and creates new connections that are helpful for localization.",
                "position": 2200
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x33.png",
                "caption": "",
                "position": 2212
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x34.png",
                "caption": "",
                "position": 2214
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x35.png",
                "caption": "",
                "position": 2215
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x36.png",
                "caption": "",
                "position": 2218
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x37.png",
                "caption": "",
                "position": 2220
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/klipspringer_28_klipspringer_117_0.png",
                "caption": "",
                "position": 2222
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/klipspringer_28_klipspringer_117_1.png",
                "caption": "",
                "position": 2223
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x40.png",
                "caption": "",
                "position": 2230
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x41.png",
                "caption": "",
                "position": 2231
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/050647_033812_0.png",
                "caption": "",
                "position": 2234
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/050647_033812_1.png",
                "caption": "",
                "position": 2236
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/000000006845_000000007064_0.png",
                "caption": "",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_adj_supp/000000006845_000000007064_1.png",
                "caption": "",
                "position": 2239
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x44.png",
                "caption": "",
                "position": 2246
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x45.png",
                "caption": "",
                "position": 2247
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/support/dassie_27_dassie_174_0.png",
                "caption": "Figure 12:Qualitative Comparison.We visualize keypoints predictions for the 1-shot setting.\nThe left column denotes the support image with its corresponding skeleton.\nThe second column is the ground-truth query keypoints. The following columns are results from CapeFormer, SCAPE, GraphCape, and our method.",
                "position": 2254
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/gt/dassie_27_dassie_174_2.png",
                "caption": "",
                "position": 2273
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/capeformer/dassie_27_dassie_174_2.png",
                "caption": "",
                "position": 2274
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/scape/dassie_27_dassie_174_2.png",
                "caption": "",
                "position": 2275
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/graphcape/dassie_27_dassie_174_2.png",
                "caption": "",
                "position": 2276
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/ours/dassie_27_dassie_174_2.png",
                "caption": "",
                "position": 2277
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/support/klipspringer_57_klipspringer_74_0.png",
                "caption": "",
                "position": 2280
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/gt/klipspringer_57_klipspringer_74_2.png",
                "caption": "",
                "position": 2281
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/capeformer/klipspringer_57_klipspringer_74_2.png",
                "caption": "",
                "position": 2282
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/scape/klipspringer_57_klipspringer_74_2.png",
                "caption": "",
                "position": 2283
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/graphcape/klipspringer_57_klipspringer_74_2.png",
                "caption": "",
                "position": 2284
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/ours/klipspringer_57_klipspringer_74_2.png",
                "caption": "",
                "position": 2285
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x46.png",
                "caption": "",
                "position": 2288
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/gt/Pileated_Woodpecker_0027_179956_Red_Bellied_Woodpecker_0089_181907_2.png",
                "caption": "",
                "position": 2289
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/capeformer/Pileated_Woodpecker_0027_179956_Red_Bellied_Woodpecker_0089_181907_2.png",
                "caption": "",
                "position": 2290
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/scape/Pileated_Woodpecker_0027_179956_Red_Bellied_Woodpecker_0089_181907_2.png",
                "caption": "",
                "position": 2291
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/graphcape/Pileated_Woodpecker_0027_179956_Red_Bellied_Woodpecker_0089_181907_2.png",
                "caption": "",
                "position": 2292
            },
            {
                "img": "https://arxiv.org/html/2411.16665/extracted/6023788/Figures/4_qualitative_supp/ours/Pileated_Woodpecker_0027_179956_Red_Bellied_Woodpecker_0089_181907_2.png",
                "caption": "",
                "position": 2293
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x59.png",
                "caption": "",
                "position": 2312
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x60.png",
                "caption": "",
                "position": 2313
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x61.png",
                "caption": "",
                "position": 2314
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x62.png",
                "caption": "",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x63.png",
                "caption": "",
                "position": 2316
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x64.png",
                "caption": "",
                "position": 2317
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x65.png",
                "caption": "",
                "position": 2320
            },
            {
                "img": "https://arxiv.org/html/2411.16665/x71.png",
                "caption": "Figure 13:Graph Decoder Prediction Layer.Overview of the Transformer decoder architecture, adapted from the GraphCape design. The decoder consists of self-attention, cross-attention, and a graph-based feed-forward network.\nWe incorporate a Markovian Attention Bias into the self-attention mechanism to encourage structural keypoint interactions.\nSelf-attention facilitates adaptive interactions among support keypoints, while cross-attention extracts localization information from the input features. Finally, the decoder refines keypoint features and outputs location predictions.",
                "position": 2436
            }
        ]
    },
    {
        "header": "Appendix CMethod Details",
        "images": []
    }
]