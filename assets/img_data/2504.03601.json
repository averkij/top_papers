[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03601/x1.png",
                "caption": "",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2504.03601/x2.png",
                "caption": "",
                "position": 114
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03601/x3.png",
                "caption": "Figure 1:Comparative performance of largerxLAM-2-fc-rmodels (8B-70B, trained withAPIGen-MTdata) against state-of-the-art baselines on function-calling (BFCL v3[43]) and agentic (Ï„ğœ\\tauitalic_Ï„-bench[47]) capabilities.",
                "position": 128
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3APIGen-MTMethod for Synthesizing High-Quality Multi-Turn Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03601/x4.png",
                "caption": "Figure 2:Overview of theAPIGen-MTframework. Phase 1 generates task configurations and groundtruth actions through an agentic process with feedback loops. Phase 2 collects human-agent-environment interaction trajectories by simulating realistic conversations between a human user and a test agent in an executable environment.",
                "position": 214
            }
        ]
    },
    {
        "header": "4A Case Study ofAPIGen-MTonÏ„ğœ\\tauitalic_Ï„-bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03601/x5.png",
                "caption": "Figure 3:Realization ofAPIGen-MTframework forÏ„ğœ\\tauitalic_Ï„-bench. We first generate realistic task instances by random walk down the API graph and sampling. Next the tasks are validated following a multi-stage pipeline. Instances which fail are sent back to the Generator to be refined based on the validation feedback. Finally, trajectories are generated by a simulated human user that interacts with a test agent by supplying the query details in a turn-wise manner. Trajectories which pass state- and output- based evaluations are collected.",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2504.03601/x6.png",
                "caption": "Figure 4:Statistics for the dataset generated usingAPIGen-MT. Success rates (S.R.) are reported for the task configuration (w. and w/o agentic feedback in Phase 1) and trajectory simulation (Phase 2) stages.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2504.03601/x6.png",
                "caption": "Figure 5:Density distribution of assistant and user turns in collected trajectories.",
                "position": 542
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.03601/x7.png",
                "caption": "Figure 6:Pass^k curves measuring the probability that all 5 independent trials succeed for a given task, averaged across all tasks forÏ„ğœ\\tauitalic_Ï„-retail (left) andÏ„ğœ\\tauitalic_Ï„-airline (right) domains. Higher value indicates consistency of the models.",
                "position": 1010
            },
            {
                "img": "https://arxiv.org/html/2504.03601/x8.png",
                "caption": "Figure 7:Performance and efficiency comparisons ofxLAM-2-70b-fc-rwith frontier models onÏ„ğœ\\tauitalic_Ï„-bench.",
                "position": 1090
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmarks Description",
        "images": []
    },
    {
        "header": "Appendix BPrompts",
        "images": []
    }
]