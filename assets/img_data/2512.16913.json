[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16913/x1.png",
                "caption": "",
                "position": 57
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16913/x2.png",
                "caption": "Figure 2:Overview of the proposed progressive three-stage pipeline. Stage 1 trains aScene-Invariant Labeleron high-quality synthetic indoor and outdoor data to provide strong initialization.\nStage 2 introduces aRealism-Invariant Labeler, where a PatchGAN-based discriminator selects 300K indoor and 300K outdoor high-confidence pseudo-labeled samples to mitigate domain gaps between synthetic and real data.\nStage 3 performsDAPtraining on all labeled and pseudo-labeled data, enabling large-scale semi-supervised learning and strong generalization across real-world panoramic scenes.",
                "position": 217
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16913/x3.png",
                "caption": "Figure 3:Architecture of the proposedDAP network.\nBuilt upon DINOv3-Large[simeoni2025dinov3]as the visual backbone, our model adopts a distortion-aware depth decoder and a plug-and-play range mask head for adaptive distance control across diverse scenes.\nTraining is guided by multi-level geometric and sharpness-aware losses, includingℒS​I​L​o​g\\mathcal{L}_{SILog},ℒD​F\\mathcal{L}_{DF},ℒg​r​a​d\\mathcal{L}_{grad},ℒn​o​r​m​a​l\\mathcal{L}_{normal}, andℒp​t​s\\mathcal{L}_{pts}losses, ensuring metric accuracy, edge fidelity, and geometric consistency in panoramic depth estimation.",
                "position": 273
            },
            {
                "img": "https://arxiv.org/html/2512.16913/x4.png",
                "caption": "Figure 4:Qualitative comparison across diverse real-world indoor and outdoor scenes.\nOur DAP produces sharper object boundaries, smoother global geometry, and superior robustness in distant and sky regions compared to DAC[DepthAnyCamera]and Unik3D[piccinelli2025unik3d].",
                "position": 351
            },
            {
                "img": "https://arxiv.org/html/2512.16913/x5.png",
                "caption": "Figure 5:Qualitative comparison on Stanford2D3D. Our method preserves fine structural details and demonstrates superior scale-awareness.",
                "position": 432
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]