[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/extracted/6294081/figures/ladder-2.png",
                "caption": "",
                "position": 126
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/x1.png",
                "caption": "Figure 1:Left: Pretraining context window of LLMs grows over time. Right: Average performance across nine downstream tasks for 1B-parameter models with varying pretrained context window sizes. Increasing the context window size degrades the overall performance.",
                "position": 155
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/x2.png",
                "caption": "Figure 2:Schematic comparison of training-time context window scheduling.",
                "position": 185
            }
        ]
    },
    {
        "header": "3How Context Window Affects Pretraining",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/x3.png",
                "caption": "Figure 3:An illustration of the workflow for pretraining data preparation highlights several critical decisions. Key considerations include the method of data packing, the type of attention mask to employ (causal mask and intra-doc mask), and determining the appropriate context window length denoted asLùêøLitalic_L.",
                "position": 215
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x4.png",
                "caption": "Figure 4:Ablation studies of different factors on different context window sizes. Note that the validation PPL is obtained on the validation documents with a sliding window size of 512 tokens.",
                "position": 306
            }
        ]
    },
    {
        "header": "4SkyLadder: Context Window Scheduling",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/x5.png",
                "caption": "Figure 5:An illustration of Random and IntraDoc along with SkyLadder. The example shows a packed sequence (lengthLùêøLitalic_L) consisting of two documents. For SkyLadder, the context windowwùë§witalic_wstarts from a small value and dynamically adjusts during training, eventually converging to the masking patterns of Random and IntraDoc, respectively.",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x6.png",
                "caption": "Figure 6:Validation PPL on 512 and 8k contexts of models with different expansion rateŒ±ùõº\\alphaitalic_Œ±(left) and initial window lengthwssubscriptùë§ùë†w_{s}italic_w start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT(right).",
                "position": 798
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x7.png",
                "caption": "",
                "position": 801
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x8.png",
                "caption": "Figure 7:Dynamics of attention sink and entropy during pretraining 1B models with an 8K context. SkyLadder delays the emergence of attention sink while lowering the overall entropy, indicating a more effective attention pattern.",
                "position": 916
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15450/x9.png",
                "caption": "Figure 8:Validation perplexity (evaluated on a sliding window of 512) on models with different context lengths.",
                "position": 2059
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x10.png",
                "caption": "",
                "position": 2062
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x11.png",
                "caption": "",
                "position": 2064
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x12.png",
                "caption": "Figure 9:Left: Evaluation perplexity of models with different packing or masking strategies. Right: Downstream performance over 9 tasks of different models.",
                "position": 2068
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x12.png",
                "caption": "Figure 9:Left: Evaluation perplexity of models with different packing or masking strategies. Right: Downstream performance over 9 tasks of different models.",
                "position": 2071
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x13.png",
                "caption": "Figure 10:Validation perplexity v.s. training tokens with different context windows and base of RoPE,Œ∏ùúÉ\\thetaitalic_Œ∏. Evaluation is done on a sliding window of varying length (x-axis) on the validation documents.",
                "position": 2076
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x14.png",
                "caption": "Table 15:Functions for different context window schedule types. We setws=32subscriptùë§ùë†32w_{s}=32italic_w start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 32andwe=32768subscriptùë§ùëí32768w_{e}=32768italic_w start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = 32768in our experiments. Therùëüritalic_rfor rounding is set to1024102410241024.",
                "position": 2237
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x14.png",
                "caption": "Figure 11:Plot of various scheduling types.",
                "position": 2271
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x15.png",
                "caption": "Figure 12:An illustration of the effect of differentŒ±ùõº\\alphaitalic_Œ±. Dashed lines represent the current context windowwùë§witalic_wfor each step, and solid lines are the loss evaluated at 8K length.",
                "position": 2278
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x15.png",
                "caption": "Figure 12:An illustration of the effect of differentŒ±ùõº\\alphaitalic_Œ±. Dashed lines represent the current context windowwùë§witalic_wfor each step, and solid lines are the loss evaluated at 8K length.",
                "position": 2281
            },
            {
                "img": "https://arxiv.org/html/2503.15450/x16.png",
                "caption": "Figure 13:An illustration of the cyclic schedules with gradual increases or jumps. Dashed lines represent the context length for each step, and solid lines are the loss evaluated at 8K length.cùëêcitalic_crepresents the number of cycles.",
                "position": 2286
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]