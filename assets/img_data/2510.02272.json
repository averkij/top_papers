[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Observational Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02272/x1.png",
                "caption": "Figure 1:Cross-lingual reasoning transferability across open-source LRMs.Thetop subfigureshows the average Multilingual Transferability Index (MTI) of various English-centric LRMs across four benchmarks and eleven languages, with the x-axis representing the base models. Thebottom subfigurepresents the average Transferability Index (TI) performance of SFT- and RL-tuned models on individual languages on the MATH500 benchmark.",
                "position": 389
            }
        ]
    },
    {
        "header": "3Interventional Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02272/x2.png",
                "caption": "Figure 2:The Impact of Different Initial Model Families on Interventional Study.Multilingual reasoning performance across languages on MATH500 benchmark, comparing the influence of model family using Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct as initial models.“Base”represents the performance of the initial model, while“+GRPO”denotes performance after fine-tuning with GRPO on English data. The light red area denotes the improvement in accuracy between the “Base” and “+GRPO” models, while the light gray area represents the reduction in the off-target rate between the two.",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x3.png",
                "caption": "Figure 3:The Impact of Different Model Size on Interventional Study.Performance on various benchmarks across models of different sizes. “Δ​Performance\\Delta\\text{Performance}” denotes the average difference in accuracy performance between the trained model and its initial model, averaged across both the training language and unseen languages, respectively.",
                "position": 602
            }
        ]
    },
    {
        "header": "4Parallel Training Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02272/x4.png",
                "caption": "Figure 4:The Parallel Scaling Law in Multilingual Reasoning Performance.The x-axisNumber of Training Languagesis defined as English plus the specified number of parallel languages.“Experimental Data”shows the performance metrics of the model under different training numbers of parallel languages. The curves are fitted to theExperimental Data.“Monolingual Baseline”refers to fine-tuning on English data only, without parallel data.“First-Parallel Leap”denotes the performance difference between a model with one parallel language and the Monolingual Baseline.",
                "position": 630
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x5.png",
                "caption": "Figure 5:Accuracy difference comparison across parallel and unparallel data training.",
                "position": 683
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x6.png",
                "caption": "Figure 6:Multilingual reasoning performance across different parallel languages. “Only en” denotes only fine-tuned on English data. “en&LANGUAGE” indicates the model was fine-tuned on English and a parallel language, withLANGUAGErepresentingru, bn, de, zh, respectively.",
                "position": 693
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix BThe Usage of Large Language Model",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Details and Setup",
        "images": []
    },
    {
        "header": "Appendix DImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02272/x7.png",
                "caption": "(a)",
                "position": 1535
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x7.png",
                "caption": "(a)",
                "position": 1538
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x8.png",
                "caption": "(b)",
                "position": 1543
            }
        ]
    },
    {
        "header": "Appendix EDetailed Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02272/x9.png",
                "caption": "(a)SFT-tuned Models",
                "position": 2414
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x9.png",
                "caption": "(a)SFT-tuned Models",
                "position": 2417
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x10.png",
                "caption": "(b)RL-tuned Models",
                "position": 2422
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x11.png",
                "caption": "(a)MATH500",
                "position": 3316
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x11.png",
                "caption": "(a)MATH500",
                "position": 3319
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x12.png",
                "caption": "(b)AIME24",
                "position": 3325
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x13.png",
                "caption": "(c)AIME25",
                "position": 3331
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x14.png",
                "caption": "(d)GPQA-Diamond",
                "position": 3337
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x15.png",
                "caption": "(a)MATH500",
                "position": 3969
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x15.png",
                "caption": "(a)MATH500",
                "position": 3972
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x16.png",
                "caption": "(b)AIME24",
                "position": 3978
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x17.png",
                "caption": "(c)AIME25",
                "position": 3984
            },
            {
                "img": "https://arxiv.org/html/2510.02272/x18.png",
                "caption": "(d)GPQA-Diamond",
                "position": 3990
            }
        ]
    },
    {
        "header": "Appendix FPrompts Template",
        "images": []
    }
]