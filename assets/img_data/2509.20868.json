[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/x1.png",
                "caption": "(a)Small Models Average Accuracy on each task",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x1.png",
                "caption": "(a)Small Models Average Accuracy on each task",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x2.png",
                "caption": "(b)Medium Models Average Accuracy on each task",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x3.png",
                "caption": "(c)Large Models Average Accuracy on each task",
                "position": 463
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/x4.png",
                "caption": "(a)AIME token usage results.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x4.png",
                "caption": "(a)AIME token usage results.",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x5.png",
                "caption": "(b)Game24 token usage results.",
                "position": 515
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AThinking Styles",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/x6.png",
                "caption": "(a)Chain-of-Thought (CoT): Linear step-by-step reasoning",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x6.png",
                "caption": "(a)Chain-of-Thought (CoT): Linear step-by-step reasoning",
                "position": 1026
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x7.png",
                "caption": "(b)Chain-of-Draft (CoD): Iterative refinement process",
                "position": 1032
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x8.png",
                "caption": "(a)Algorithm-of-Thought (AoT): Backtracking exploration",
                "position": 1039
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x8.png",
                "caption": "(a)Algorithm-of-Thought (AoT): Backtracking exploration",
                "position": 1042
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x9.png",
                "caption": "(b)Tree-of-Thought (ToT): Branching and pruning",
                "position": 1048
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x10.png",
                "caption": "Figure 6:Sketch-of-Thought (SoT): Router-based paradigm selection with exemplar retrieval. The method classifies the input problem, retrieves relevant examples from a paradigm cache, applies targeted prompts, and generates responses through structured LLM processing.",
                "position": 1055
            }
        ]
    },
    {
        "header": "Appendix BOverall Accuracy Score",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/x11.png",
                "caption": "(a)Accuracy boxplot for small models",
                "position": 1063
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x11.png",
                "caption": "(a)Accuracy boxplot for small models",
                "position": 1066
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x12.png",
                "caption": "(b)Accuracy Heatmap for medium models",
                "position": 1072
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x13.png",
                "caption": "(c)Accuracy Heatmap for small models",
                "position": 1078
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x14.png",
                "caption": "Figure 8:Accuracy Heatmap for small models",
                "position": 1085
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x15.png",
                "caption": "Figure 9:Accuracy Heatmap for medium models",
                "position": 1088
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x16.png",
                "caption": "Figure 10:Accuracy Heatmap for large models",
                "position": 1091
            }
        ]
    },
    {
        "header": "Appendix CSample Prompts by Reasoning Style",
        "images": []
    },
    {
        "header": "Appendix DSample Response",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/x17.png",
                "caption": "Figure 11:Token Usage on GSM8k",
                "position": 1651
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x18.png",
                "caption": "Figure 12:Token Usage on CommonsenseQA",
                "position": 1654
            },
            {
                "img": "https://arxiv.org/html/2509.20868/x19.png",
                "caption": "Figure 13:Token Usage on LogiQA",
                "position": 1657
            }
        ]
    },
    {
        "header": "Appendix ECross-Model Comparison",
        "images": []
    },
    {
        "header": "Appendix FExperiment Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20868/style_bench/figures/sft/qwen_25_7b_sft_training_metrics.png",
                "caption": "Figure 15:Training dynamics for Qwen-7B with LoRA fine-tuning. Left panel shows training loss convergence over steps. Right panel shows gradient norm evolution, indicating stable optimization throughout training.",
                "position": 2677
            },
            {
                "img": "https://arxiv.org/html/2509.20868/style_bench/figures/sft/qwen_7b_full_ft_training_metrics.png",
                "caption": "Figure 16:Training dynamics for Qwen-7B with full parameter fine-tuning. Left panel shows training loss convergence over steps. Right panel shows gradient norm evolution, demonstrating higher gradient magnitudes compared to LoRA fine-tuning.",
                "position": 2680
            }
        ]
    },
    {
        "header": "Appendix GSFT Experimental Setup (Dataset, Training, and Evaluation)",
        "images": []
    }
]