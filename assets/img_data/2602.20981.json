[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20981/x1.png",
                "caption": "Figure 1:Long-Video to Audio (LV2A) task overview. The challenge is framed as training models on fixed-length segments while requiring them to generalize to variable-length (long-form) audio outputs during inference.",
                "position": 71
            }
        ]
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20981/x2.png",
                "caption": "Figure 2:We analyze the role of positional embeddings in V2A models such as MMAudio[4], built on MMDiT[24]. Without positional embeddings (a), MMAudio fails to capture temporal structure, producing redundant audio dominated by prominent visual objects (e.g., car crashing). With adjusted positional embeddings (b), alignment improves but sound quality degrades over long sequences (see scene C). (c) On UnAV100[10], both configurations show performance drops across durations, with MMAudio without positional embeddings performing worst in distribution matching (FD↓P​A​N​N{}_{PANN}\\downarrow) and multimodal alignment (IB-Score↑\\uparrow).",
                "position": 128
            }
        ]
    },
    {
        "header": "3Pilot Study",
        "images": []
    },
    {
        "header": "4Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20981/x3.png",
                "caption": "Figure 3:Overview of our proposed framework. Left: A comprehensive end-to-end flow-matching model that operates across both multimodal and single-modal blocks, handling inputs in both compressed and original spaces. Middle: A temporal routing mechanism designed to efficiently process tokens in a time-aware manner. Right: A multimodal routing strategy that leverages strong correlations between the two modalities for enhanced integration.",
                "position": 217
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20981/x4.png",
                "caption": "Figure 4:Visualization of audio spectogram from MMHNet and competing methods on UnAV100.",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2602.20981/x5.png",
                "caption": "(a)",
                "position": 988
            },
            {
                "img": "https://arxiv.org/html/2602.20981/x5.png",
                "caption": "(a)",
                "position": 991
            },
            {
                "img": "https://arxiv.org/html/2602.20981/x6.png",
                "caption": "(b)",
                "position": 997
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Datasets and Settings",
        "images": []
    },
    {
        "header": "8The Details of MMHNet",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.20981/x7.png",
                "caption": "Figure A6:Visualization of heatmaps for activation matrices in Causal Mamba-2 and Non-Causal Mamba-2 within MMHNet:\n(a) Causal Mamba-2, used as a Transformer replacement, shows activation scores in the transition matrix that gradually decay during extended audio generation (up to 5 minutes).\n(b) Non-Causal Mamba-2 maintains visible activation scores in the transition matrix prior to routing.\n(c) After routing, the transition matrix becomes more pronounced in the compressed representation space.",
                "position": 1819
            }
        ]
    },
    {
        "header": "9Additional Experiments",
        "images": []
    }
]