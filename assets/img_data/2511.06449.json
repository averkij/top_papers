[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/front_pic.png",
                "caption": "",
                "position": 186
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Forward Learning with Experience",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/fig-mdp.png",
                "caption": "Figure 2:Illustration of the Meta-MDP formulation ofFLEX.\nThe Base-level MDP performs intra-sample exploration and experience distillation, while the Meta-level MDP integrates these experiences to evolve the global experience library through forward updates.",
                "position": 507
            }
        ]
    },
    {
        "header": "3Concrete Instantiation ofFLEX",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/fig-fl.png",
                "caption": "Figure 3:Concrete Instantiation ofFLEX. The refinement loop of actor-critic iteratively explores and refines experiences, then the meta-level updater dynamically organizes the distilled experiences into the evolving experience library.",
                "position": 647
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/scaling_law.png",
                "caption": "Figure 4:Training dynamics and scaling laws ofFLEXon the GSM8K dataset across 5 epochs. Training accuracy and test accuracy both show strong scalability with the size of the experience library. Experience library also exhibits scaling law with the epochs.",
                "position": 891
            },
            {
                "img": "https://arxiv.org/html/2511.06449/figs/case_study.png",
                "caption": "Figure 5:Qualitative case studies in Mathematics, Chemistry, and Biology demonstrating the effectiveness ofFLEX. In each domain, baseline agents (LLM Response, ReAct Response) fail due to critical reasoning errors (marked with✗). In contrast, by retrieving and applying distilled knowledge (e.g., Golden rules and Warnings) from its experience library,FLEXsuccessfully refines its strategy, overcomes the initial failures, and arrives at the correct solution (marked with✓).",
                "position": 1003
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/inheritance.png",
                "caption": "Figure 6:The process of inheriting the experience library across diverse agents. The experience library acts as a plug-and-play module that can boost agents’ performance with a single training procedure.",
                "position": 1036
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.06449/figs/proteingym_all.png",
                "caption": "Figure 7:ProteinGym Results from both protein language model and large language model.",
                "position": 2920
            }
        ]
    },
    {
        "header": "8Experimental Details",
        "images": []
    }
]