[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18537/x1.png",
                "caption": "Figure 1:TTS-VARgenerates several samples concurrently like Best-of-N (BoN). InTTS-VAR, we adopt an adaptive descending batch size schedule to make the most of AR efficiency, with feature clustering at early scales to ensure diversity, and resampling according to potentials at late scales for more valuable samples. (1-3) are overviews showing the difference between raw inference, BoN, andTTS-VAR. (a) is a detailed example of the generation process of our method.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminary: Visual Auto-Regressive Modeling",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18537/x2.png",
                "caption": "Figure 2:Different Batch Size Schedules.We visualize the memory usage in (a) and computation complexity in (b) for 13 scales during the generation of Infinity, with fixed batch size 1 and adaptive batch size. Specifically, the adaptive batch size here is [8,8,6,6,6,4,2,2,2,1,1,1,1]. This batch size schedule enables more possibilities with little additional consumption.",
                "position": 186
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18537/x3.png",
                "caption": "Table 1:Quantitative evaluation on GenEval.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x3.png",
                "caption": "Figure 3:Score Curves over Sample NumberNùëÅNitalic_N.",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x4.png",
                "caption": "",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x5.png",
                "caption": "",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x6.png",
                "caption": "Figure 4:Qualitative Comparison.Each line shows results generated by Stable Diffusion 3 (SD3)[61], Infinity, and Infinity with test-time scaling strategies, with objects marked blue and relationships marked green.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x7.png",
                "caption": "Figure 5:Resample choices.The left graph shows the variation in ImageReward Score when executing resampling-based potential selection at different scales (0-11). The right graph shows the consistency between scores of intermediate states and those of final results at each scale. It demonstrates that in VAR, not all scales are suitable for selection, and some may lead to degradation.",
                "position": 676
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x8.png",
                "caption": "Figure 6:Consistency of Different Potentials.We visualize the consistency between different pairs of potential scores and final results. Accordingly, VALUE and MAX can better indicate the potentials.",
                "position": 773
            },
            {
                "img": "https://arxiv.org/html/2507.18537/x9.png",
                "caption": "Figure 7:Visualization of Generation Process.The text prompt here is \"a photo of a bottle and a bicycle\". The left is one final generated image. The right is the corresponding generation process and visualized DINOv2 features extracted from different scales. It demonstrates that features captured in early scales can indicate the structural information.",
                "position": 880
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm ofTTS-VAR",
        "images": []
    },
    {
        "header": "Appendix BDetailed Main Results",
        "images": []
    },
    {
        "header": "Appendix CPerformance over Computational Consumption",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18537/x10.png",
                "caption": "Figure 8:Performance over Flops.This figure shows the variant curves of different methods with computational consumption as the x-axis, demonstrating the efficiency of our method.",
                "position": 1388
            }
        ]
    },
    {
        "header": "Appendix DAblation Study",
        "images": []
    },
    {
        "header": "Appendix EMore Visualization Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.18537/x11.png",
                "caption": "Figure 9:More Visualization Results.Samples are generated from GenEval prompts, with \"IS\" meaning Importance Sampling, \"BoN\" meaning Best-of-N, and our methodTTS-VAR. We display various cases, including the single object, two objects, counting, colors, position, and color attributes.",
                "position": 1781
            }
        ]
    },
    {
        "header": "Appendix FSocietal Impact",
        "images": []
    },
    {
        "header": "Appendix GLimitation and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]