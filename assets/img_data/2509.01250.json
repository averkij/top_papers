[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01250/x1.png",
                "caption": "Figure 1:Comparison between self-reconstruction (Point-MAE[39]and other methods based on it) and cross-reconstruction (Ours) paradigms. In the self-reconstruction paradigm, part of the input data is masked, and the autoencoder is trained to recover the missing patches. In contrast, the cross-reconstruction paradigm generates decoupled views first, with one view leveraging cross-view information to reconstruct the other, using an autoencoder backbone.",
                "position": 76
            },
            {
                "img": "https://arxiv.org/html/2509.01250/x2.png",
                "caption": "Figure 2:Pipeline of Point-PQAE. The input point cloud is randomly cropped followed by the rotation to generate views. Then, we feed the views to the patch embedding layer and the transformer encoder, followed by the proposed positional query block. The View-Relative Positional Embedding (VRPE) is obtained through the VRPE module by extracting relative geometric relations, which is taken as “Query” in the cross-attention mechanism. The queried hidden embeddings are then fed to the decoder to predict the inputs of the other view.",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3The proposed Point-PQAE",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01250/x3.png",
                "caption": "Figure 3:Cross-reconstruction results on ShapeNet. The arrow points from source point clouds to cross-reconstruction results. Point-PQAE generalizes well to other crop ratios though with minimum crop ratiorm=0.6r_{m}=0.6when pre-training.",
                "position": 356
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AComparisons to more peer methods",
        "images": []
    },
    {
        "header": "Appendix BRelated cross-reconstruction works",
        "images": []
    },
    {
        "header": "Appendix CDiscussion on the view-relative positional embedding and positional query",
        "images": []
    },
    {
        "header": "Appendix DAdditional experimental details",
        "images": []
    },
    {
        "header": "Appendix EAdditional ablation study",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01250/x4.png",
                "caption": "Figure 4:Ablation study on different minimum crop ratiosrmr_{m}, where the results (%) of three variants: OBJBG, OBJONLY, PTT50RS on ScanObjectNN are reported.",
                "position": 1975
            },
            {
                "img": "https://arxiv.org/html/2509.01250/x5.png",
                "caption": "",
                "position": 1984
            },
            {
                "img": "https://arxiv.org/html/2509.01250/x6.png",
                "caption": "",
                "position": 1989
            }
        ]
    },
    {
        "header": "Appendix FLimitations and future work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]