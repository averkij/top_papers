[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x1.png",
                "caption": "",
                "position": 119
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x2.png",
                "caption": "Figure 2:Linear probingresults for scene intrinsics (base color, depth, and normals) and RGB with respect to timesteps and blocks. We use a single linear layer with MSE loss (cosine loss for normals). Predictive power from features to scene intrinsics saturates quickly both across blocks and across timesteps‚Äîaround the 5th‚Äì15th of 50 timesteps and the 10th‚Äì20th of 30 blocks. Depth and normals are more easily predicted at earlier stages, whereas RGB prediction quality increases monotonically with both layer depth and timestep. Similar patterns are observed in nonlinear analyses (see the supplementary material), confirming that scene intrinsics can be captured quickly.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x3.png",
                "caption": "",
                "position": 203
            }
        ]
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Interactive Preview Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x4.png",
                "caption": "Figure 3:Diffusion models trained on a toy 4-frame tri-modal datasetreveal severe hallucination and superposition problems at low NFE settings (low total number of steps, distilled few-step model, or early preview) for models trained with MSE. In contrast, our multi-branch decoder architecture correctly produces a clean tri-modal distribution and remains artifact-free. For our results, the samples are randomly extracted from different branches, which learned to favor different modes in the data.",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x5.png",
                "caption": "Figure 4:Our multi-branch multi-loss decoderis trained with intermediate diffusion features. Grounded by branch-wise loss and an aggregated ensemble loss, it is designed to reduce the superposition problem.",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x6.png",
                "caption": "Figure 5:Qualitatively, the proposed MB decoder improves mode selection and reduces artifacts due to multimodal ambiguity.Red boxes highlight high-uncertainty regions that caused blurred patches in the naive single-branch decoder.",
                "position": 368
            }
        ]
    },
    {
        "header": "5Generating Variations Using Previews",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x7.png",
                "caption": "Figure 6:Timestep-wise evolution of base color, normal, and albedo. Coarse geometry and recognizable structures appear around the 5th timestep, with details refined progressively thereafter.",
                "position": 414
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x8.png",
                "caption": "Figure 7:Block-wise evolution of base color, normal, and albedo. Intrinsics are best predicted from mid-level features, slightly degrading in the final layers.",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x9.png",
                "caption": "Figure 8:Rubber-like 4D visualizationcan be derived from the intrinsic previews from our model. Interestingly, at only 10% of the denoising schedule, a clear structural representation of the scene has already emerged.",
                "position": 528
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x10.png",
                "caption": "Figure 9:Examples of variation generation via stochasticity injectionshow coarse details being preserved at lower noise levels, while the injected stochasticity changes several details in the video highlighted by the red boxes.",
                "position": 543
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x11.png",
                "caption": "Figure 10:Steering base colorat 10% of the total denoising steps allows users to generate variations in the same context. The text prompt is ‚ÄúA car driving on a sunny road‚Äù.",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x12.png",
                "caption": "Figure 11:Examples of variation generation via steeringshow meaningful steered base color, depth, and normal results.",
                "position": 562
            }
        ]
    },
    {
        "header": "7Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x13.png",
                "caption": "Figure 12:Failure case in intrinsic steering. The sphere added at the 20th layer gradually dissolves and deforms in subsequent timesteps.",
                "position": 648
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "S1Analysis: Diffusion Features and Intrinsic Previews",
        "images": []
    },
    {
        "header": "S2Synthetic Training Data Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x14.png",
                "caption": "Figure 13:Even when pseudo-GT data predicted with DiffusionRenderer[32]contains incorrect geometry, our decoder predicts plausible and consistent structure from diffusion features.",
                "position": 1393
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x15.png",
                "caption": "Figure 14:Nonlinear probing comparisons across timesteps and blocks. The reported loss is the last-epoch validation loss,‚Ñì1\\ell_{1}+ perceptual. The results show a similar trend to linear decoding.",
                "position": 1396
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x16.png",
                "caption": "",
                "position": 1400
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x17.png",
                "caption": "Figure 15:Rubber-like 4D reconstruction results. Even at 10% of the timestep, each reconstruction represents the composition, geometry, and dynamics of the scene, while at the 20% timestep, a refined reconstruction result is produced.",
                "position": 1404
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x18.png",
                "caption": "Figure 16:PSNR comparison betweenùê±0\\mathbf{x}_{0}-pred (the VAE decoder), Linear, and our method. In the high-noise regime, the linear and our decoders perform similarly, with the gap increasing as the denoising process progresses. The PSNR of theùê±0\\mathbf{x}_{0}-pred decoder and our method crosses at 16% of the denoising steps, suggesting that early previews benefit substantially from our decoder.",
                "position": 1407
            }
        ]
    },
    {
        "header": "S3Analysis: More on the Toy Problem",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x19.png",
                "caption": "Figure 17:Toy experiment. Multi-branch predictions recover separate modes without superposition. The green boxes represent the prediction of each branch, and the red box represents the averaged prediction of the branches.",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x20.png",
                "caption": "Figure 18:Without ensemble loss, the reduced diversity results in collapse to a fewer number of modes and causes artifacts.",
                "position": 1446
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x21.png",
                "caption": "Figure 19:Failure modes for different modalities. We steered each of the maps at 10% of the denoising steps.",
                "position": 1449
            }
        ]
    },
    {
        "header": "S4Details on Latent Steering",
        "images": []
    },
    {
        "header": "S5Benefits of Multi-Modal Previews",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13690/x22.png",
                "caption": "Figure 20:Comparison between RGB (fromùê±0\\mathbf{x}_{0}-pred) and base color (from our decoder) previews at 4% and 10% of the denoising steps. Our base color preview reveals structural components and color layout more clearly than the latent.",
                "position": 1626
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x23.png",
                "caption": "",
                "position": 1629
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x24.png",
                "caption": "Figure 21:Timestep-wise evolution of base color, normal, and albedo. Coarse geometry appears early and refines through denoising.",
                "position": 3016
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x25.png",
                "caption": "",
                "position": 3020
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x26.png",
                "caption": "Figure 22:Timestep-wise evolution of base color, normal, and albedo. Coarse geometry appears early and refines through denoising.",
                "position": 3025
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x27.png",
                "caption": "",
                "position": 3029
            },
            {
                "img": "https://arxiv.org/html/2512.13690/x28.png",
                "caption": "Figure 23:Timestep-wise evolution of base color, normal, and albedo. Coarse geometry appears early and refines through denoising.",
                "position": 3034
            }
        ]
    },
    {
        "header": "S6User Study Setup",
        "images": []
    }
]