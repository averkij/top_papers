[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x1.png",
                "caption": "",
                "position": 68
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x2.png",
                "caption": "Figure 1:Performance of best and worse models on different reasoning benchmarks. Theredfrontier shows the performance of the worse model. Thegreenfrontier shows the performance of the best model, indicating the best known result with current technology. Thebluehorizon between the best model and the maximum performance shows the room for improvement for mastering the capability. The best performance sets indicated in the green border include all models that perform within 2% of the best observed result.",
                "position": 86
            }
        ]
    },
    {
        "header": "2Benchmarks and Methods",
        "images": []
    },
    {
        "header": "3Experiments and Findings",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x3.png",
                "caption": "Figure 2:Overall Avg Pass@1 model performance across eight reasoning tasks.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x3.png",
                "caption": "",
                "position": 274
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x4.png",
                "caption": "",
                "position": 278
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x5.png",
                "caption": "",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x6.png",
                "caption": "",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x7.png",
                "caption": "",
                "position": 291
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x8.png",
                "caption": "",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x9.png",
                "caption": "",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x10.png",
                "caption": "",
                "position": 303
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x11.png",
                "caption": "Figure 3:Results on 3SAT, GPQA, Maze, and SpatialMap with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy. Notably, there is a significant performance gap in 3SAT, where some models achieve high accuracy with aggregation, whereas others struggle even at their best-of-5 runs. The narrow conventional-to-reasoning gap between the two on GPQA (3.5%) and SpatialMap (5.5%) shows that the best reasoning model is only slightly more accurate than a hypothetical model that can potentially be trained to verify and select the best outcome from the model with the lowest best-of-5 (i.e. GPT-4o).",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x11.png",
                "caption": "",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x12.png",
                "caption": "",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x13.png",
                "caption": "",
                "position": 326
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x14.png",
                "caption": "",
                "position": 330
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/agg_legend.png",
                "caption": "",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x15.png",
                "caption": "Figure 4:Pareto tradeoff between accuracy and token usage for all benchmarks. The standard deviation for accuracy (vertical, filled line) is computed across 5 different repetitions. The standard deviation for token usage (horizontal, dotted line) is computed by first taking the standard deviation per data instance, and then averaging by the size of the benchmark, to show the variability per instance.",
                "position": 357
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x15.png",
                "caption": "",
                "position": 360
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x16.png",
                "caption": "",
                "position": 364
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x17.png",
                "caption": "",
                "position": 368
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x18.png",
                "caption": "",
                "position": 372
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x19.png",
                "caption": "",
                "position": 377
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x20.png",
                "caption": "",
                "position": 381
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x21.png",
                "caption": "",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x22.png",
                "caption": "",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/accuracy_tokens_legend_2lines.png",
                "caption": "",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x23.png",
                "caption": "Figure 5:Distributions of the standard deviations of token usage within the same instance (5 repeats), shown for instances where the models are always correct, always incorrect, or mixed (figure is continued in Figure34for more models). Models often have high standard deviation of token usage even when all the retrieved answers are correct.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x23.png",
                "caption": "",
                "position": 404
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x24.png",
                "caption": "",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x25.png",
                "caption": "",
                "position": 412
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x26.png",
                "caption": "",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x27.png",
                "caption": "Figure 6:Distributions of average token usage, shown for instances where the models are always correct, always incorrect, or mixed (figure is continued in Figure35for more models). O1 has a higher concentration of “all correct” instances towards the shorter lengths, while for other models the “all correct” instances are more spread out indicating more unpredictability of token usage across instances even when the model is always correct.",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x27.png",
                "caption": "",
                "position": 425
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x28.png",
                "caption": "",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x29.png",
                "caption": "",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x30.png",
                "caption": "",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x31.png",
                "caption": "Figure 7:TSP and BA-Calendar accuracy and token usage with difficulty levels. Standard deviation for token usage is computed across different parallel repeats.",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x31.png",
                "caption": "",
                "position": 446
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x32.png",
                "caption": "",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x33.png",
                "caption": "",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x34.png",
                "caption": "",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x35.png",
                "caption": "Figure 8:Parallel and sequential scaling on AIME 2025 and TSP (best-of-n). The effectiveness of each approach highly depends on the downstream task. On AIME 2025, parallel scaling is more efficient than sequential scaling. On TSP however, sequential scaling appears to be more efficient. Scaling up is not helpful when the questions are extremely difficult.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x35.png",
                "caption": "",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x36.png",
                "caption": "",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x37.png",
                "caption": "",
                "position": 499
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAIME - High-School Exam for Olympiad Qualification",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x38.png",
                "caption": "Figure 9:Overall model performance for AIME 2025 and AIME 83-24.",
                "position": 1410
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x38.png",
                "caption": "",
                "position": 1413
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x39.png",
                "caption": "",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x40.png",
                "caption": "Figure 10:Results on AIME 2025 with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1428
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x41.png",
                "caption": "Figure 11:Results on AIME 83-24 with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1431
            }
        ]
    },
    {
        "header": "Appendix BOmni-MATH - Olympiad Math",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x42.png",
                "caption": "Figure 12:Omni-MATH overall performance and token usage.",
                "position": 1465
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x42.png",
                "caption": "",
                "position": 1468
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x43.png",
                "caption": "",
                "position": 1472
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/accuracy_tokens_legend_2lines.png",
                "caption": "",
                "position": 1477
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x44.png",
                "caption": "Figure 13:Results on Omni-MATH with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1489
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x45.png",
                "caption": "Figure 14:Omni-MATH performace and token usage by problem difficulty level.",
                "position": 1497
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x45.png",
                "caption": "",
                "position": 1500
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x46.png",
                "caption": "",
                "position": 1504
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 1509
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x47.png",
                "caption": "Figure 15:Omni-MATH topic-level accuracy.",
                "position": 1520
            }
        ]
    },
    {
        "header": "Appendix CGPQA Diamond - Scientific Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x48.png",
                "caption": "Figure 16:Results on GPQA with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1550
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x49.png",
                "caption": "Figure 17:GPQA accuracy and token usage by high-level domain. Standard deviations for token usage are computed across five repeats, within the same high-level domain.",
                "position": 1558
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x49.png",
                "caption": "",
                "position": 1561
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x50.png",
                "caption": "",
                "position": 1565
            }
        ]
    },
    {
        "header": "Appendix D3SAT - Satisfiability",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x51.png",
                "caption": "Figure 18:SAT overall performance and token usage. The left figure shows overall model performance across nine models. The right figure shows pareto tradeoff between accuracy and token usage for all benchmarks.",
                "position": 1681
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x52.png",
                "caption": "",
                "position": 1684
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x53.png",
                "caption": "Figure 19:SAT accuracy and token usage by difficulty level. There are four levels corresponding to: easy_1 (easy overconstrained), easy_2 (easy underconstrained), hard_1 (hard multiple solutions), and hard_2 (hard single solution). The left figure shows accuracy, while the right figure shows token usage at each level. Note that test-time scaling models consistently outperform non-test-time scaling models across all four difficulty levels. Moreover, non-test-time scaling models perform worse on easy overconstrained problems than on easy underconstrained problems. A possible explanation is that non-test-time scaling models often produce a true/false result even when the problem is unsatisfiable.",
                "position": 1693
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x54.png",
                "caption": "",
                "position": 1696
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x55.png",
                "caption": "Figure 20:Results on 3SAT with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1705
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x56.png",
                "caption": "Figure 21:3SAT accuracy across four difficulty levels—easy underconstrained, easy overconstrained, hard (single solution), and hard (multiple solutions). Each figure plots accuracy against the number of variables. Notably, even test-time scaling models experience a significant performance drop once the number of variables exceeds 10 in the hard-solution setting.",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x57.png",
                "caption": "",
                "position": 1716
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x58.png",
                "caption": "",
                "position": 1718
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x59.png",
                "caption": "",
                "position": 1719
            }
        ]
    },
    {
        "header": "Appendix ETSP - Traveling Salesman Problem",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x60.png",
                "caption": "Figure 22:TSP overall performance and token usage. The left figure shows overall model performance across nine models. The right figure shows pareto tradeoff between accuracy and token usage for all benchmarks.",
                "position": 1758
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x61.png",
                "caption": "",
                "position": 1761
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x62.png",
                "caption": "Figure 23:Results on TSP with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy. Note that there is a large gap (almost 35%) between the best reasoning model and a hypothetical model that can potentially be trained to verify and select the best outcome from the model with the lowest best-of-5 (i.e. GPT-4o).",
                "position": 1783
            }
        ]
    },
    {
        "header": "Appendix FBA-Calendar - Planning",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x63.png",
                "caption": "Figure 24:BA-Calendar Metrics.",
                "position": 1822
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x63.png",
                "caption": "",
                "position": 1825
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x64.png",
                "caption": "",
                "position": 1829
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 1834
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x65.png",
                "caption": "Figure 25:Results on BA-Calendar with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1849
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x66.png",
                "caption": "Figure 26:BA-Calendar tokens v/s performance.",
                "position": 1857
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x66.png",
                "caption": "",
                "position": 1860
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x67.png",
                "caption": "",
                "position": 1864
            },
            {
                "img": "https://arxiv.org/html/2504.00294/extracted/6325488/figures/model_legend.png",
                "caption": "",
                "position": 1869
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x68.png",
                "caption": "Figure 27:BA-Calendar Constraint Level accuracy.",
                "position": 1882
            }
        ]
    },
    {
        "header": "Appendix GMaze - Navigation",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x69.png",
                "caption": "Figure 28:Maze overall performance and token usage.",
                "position": 1912
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x70.png",
                "caption": "",
                "position": 1915
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x71.png",
                "caption": "Figure 29:Results on Maze with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 1921
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x72.png",
                "caption": "Figure 30:Illustration of the Maze benchmark. Originally, the benchmark includes three different modalities: Text-only, Vision-only, and Vision-text. In this work, we only focus in the text-only reasoning skills.",
                "position": 1961
            }
        ]
    },
    {
        "header": "Appendix HSpatialMap - Spatial Reasoning",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.00294/x73.png",
                "caption": "Figure 31:SpatialMap overall performance and token usage.",
                "position": 1991
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x74.png",
                "caption": "",
                "position": 1994
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x75.png",
                "caption": "Figure 32:Results on SpatialMap with different aggregations by parallel scaling over 5 runs. Theredline indicates the lowest best-of-5 accuracy observed across all models, while theblueline represents the highest average pass@1 accuracy.",
                "position": 2000
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x76.png",
                "caption": "Figure 33:Illustration of the Spatial-Map (spatial understanding) benchmark. Originally, the benchmark includes three different modalities: Text-only, Vision-only, and Vision-text. In this work, we only focus in the text-only reasoning skills.",
                "position": 2036
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x23.png",
                "caption": "Figure 34:Distributions of the standard deviations of token usage within the same instance (5 repeats), shown for instances where the models are always correct, always incorrect, or mixed.",
                "position": 2067
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x23.png",
                "caption": "",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x77.png",
                "caption": "",
                "position": 2074
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x78.png",
                "caption": "",
                "position": 2078
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x79.png",
                "caption": "",
                "position": 2082
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x25.png",
                "caption": "",
                "position": 2087
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x80.png",
                "caption": "",
                "position": 2091
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x81.png",
                "caption": "",
                "position": 2095
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x82.png",
                "caption": "",
                "position": 2099
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x83.png",
                "caption": "",
                "position": 2104
            },
            {
                "img": "https://arxiv.org/html/2504.00294/",
                "caption": "",
                "position": 2108
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x85.png",
                "caption": "",
                "position": 2112
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x86.png",
                "caption": "",
                "position": 2116
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x27.png",
                "caption": "Figure 35:Distributions of average token usage, shown for instances where the models are always correct, always incorrect, or mixed. O1 has a higher concentration of “all correct” instances towards the shorter lengths, while for other models the “all correct” instances are more spread out indicating more unpredictability of token usage across instances even when the model is always correct.",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x27.png",
                "caption": "",
                "position": 2126
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x87.png",
                "caption": "",
                "position": 2130
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x88.png",
                "caption": "",
                "position": 2134
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x89.png",
                "caption": "",
                "position": 2138
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x90.png",
                "caption": "",
                "position": 2143
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x91.png",
                "caption": "",
                "position": 2147
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x92.png",
                "caption": "",
                "position": 2151
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x93.png",
                "caption": "",
                "position": 2155
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x94.png",
                "caption": "",
                "position": 2160
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x95.png",
                "caption": "",
                "position": 2164
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x96.png",
                "caption": "",
                "position": 2168
            },
            {
                "img": "https://arxiv.org/html/2504.00294/x97.png",
                "caption": "",
                "position": 2172
            }
        ]
    },
    {
        "header": "Appendix IPerformance vs. token usage tradeoffs - Extended",
        "images": []
    }
]