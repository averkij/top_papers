[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23277/x1.png",
                "caption": "Figure 1:We proposeSlowFast-VGen, a dual-speed action-driven video generation system that mimics the complementary learning system in human brains. The slow learning phase (a) learns an approximate world model that simulates general dynamics across a diverse set of scenarios.\nThe fast learning phase (b) stores episodic memory for consistent long video generation,e.g.,generating the same scene for “Loc1” after traveling across different locations. Slow-fast learning also facilitates long-horizon planning tasks (c) that require the efficient storage of long-term episodic memories.",
                "position": 113
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3SlowFast-VGen",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23277/x2.png",
                "caption": "Figure 2:SlowFast-VGenArchitecture. The left side illustrates theslow learningprocess, pretraining on all data with a masked conditional video diffusion model. The right side depicts thefast learningprocess, whereTemp-LoRAstores episodic memory during inference. Stream-in actions guide thegenerationof video chunks, withTemp-LoRAparameters updated after each chunk. In our slow-fast learning loop algorithm, the inner loop performs fast learning, supplyingTemp-LoRAparameters from multiple episodes to the slow learning process, which updates slow learning parametersΦΦ\\Phiroman_Φbased on frozen fast learning parameters.",
                "position": 197
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23277/x3.png",
                "caption": "Figure 3:Qualitative Examples of Video Generation with Regard to Slow Learning. OurSlowFast-VGenis able to conduct action-conditioned video generation in diverse scenarios.",
                "position": 675
            },
            {
                "img": "https://arxiv.org/html/2410.23277/x4.png",
                "caption": "Figure 4:Qualitative Examples of Fast Learning for Video Generation. t means frame number. Red boxes denote objects inconsistent with before.Temp-LoRAboosts consistency in long videos.",
                "position": 678
            },
            {
                "img": "https://arxiv.org/html/2410.23277/x5.png",
                "caption": "Figure 5:Qualitative Example of Planning.SlowFast-VGencan retain long-term memory.",
                "position": 749
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AContribution Statement",
        "images": []
    },
    {
        "header": "Appendix BMore Details about the Method",
        "images": []
    },
    {
        "header": "Appendix CDataset Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23277/x6.png",
                "caption": "Figure 6:Statistics of our Training Dataset.",
                "position": 1638
            }
        ]
    },
    {
        "header": "Appendix DMore Experimental Details",
        "images": []
    },
    {
        "header": "Appendix EExperiments on Ablations and Variations ofSlowFast-VGen",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.23277/x7.png",
                "caption": "Figure 7:Qualitative Examples on Slow Learning. Part 1.",
                "position": 1791
            },
            {
                "img": "https://arxiv.org/html/2410.23277/x8.png",
                "caption": "Figure 8:Qualitative Examples on Slow Learning. Part 2.",
                "position": 1794
            },
            {
                "img": "https://arxiv.org/html/2410.23277/x9.png",
                "caption": "Figure 9:Qualitative Examples on Fast Learning. Part 1. We mark consistent objects / frames in green bounding boxes and inconsistent ones in red.",
                "position": 1804
            },
            {
                "img": "https://arxiv.org/html/2410.23277/x10.png",
                "caption": "Figure 10:Qualitative Examples on Fast Learning. Part 2. We mark consistent objects / frames in green bounding boxes and inconsistent ones in red.",
                "position": 1807
            }
        ]
    },
    {
        "header": "Appendix FMore Qualitative Examples",
        "images": []
    }
]