[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25455/figures/removed-background-piper.png",
                "caption": "",
                "position": 114
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25455/x1.png",
                "caption": "Figure 1:Overview of the proposed training pipeline.\n(a)SFT training: For theii-th sample (a repository), both teacher and studentLLMs receive the promptqiq_{i}, which includes the task description and repository context. They generate completionsoito_{i}^{t}andoiso_{i}^{s}, respectively, expected to contain a shell script. The student model’s weights are updated by minimizing the cross-entropy loss between its output distribution and the teacher’s completion.\n(b)RL training: For each sample,LLMπθ\\pi_{\\theta}generates a completionoio_{i}, expected to contain a shell script. The completion is evaluated by a rule-based reward functionRR, which outputs a scoreRiR_{i}. The REINFORCE++ algorithm then updates theLLMweights using the rewardsRiR_{i}and responsesoio_{i}.",
                "position": 187
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments Setup",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25455/x2.png",
                "caption": "Table 1:Results on Repo2Run and Terminal-Bench for base models and our tuned Qwen3-8B.\nFor Repo2Run, success is determined as a zero exit code and no test collection errors. For Terminal-Bench, success is determined by per-sample evaluation commands. OurPIPermodel achieves the best performance on Repo2Run. However, SFT-based models underperform on Terminal-Bench’s multi-turn setting.",
                "position": 319
            },
            {
                "img": "https://arxiv.org/html/2509.25455/x2.png",
                "caption": "Figure 2:RLVR training dynamics with the proxy rewards described inSection˜3.2. Raw datapoints are shown as semi-transparent dots, with Gaussian-smoothed curves overlaid to highlight trends.Blueshows average reward on the training set;orangeshows average reward on the validation set. The x-axis is training steps, and the y-axis is average reward. Evolution of the LLM-as-a-Judge rewardRLLMR_{\\text{LLM}}(a)over the base model,(b)over the SFT model.",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2509.25455/x3.png",
                "caption": "Figure 3:Performance analysis of environment setup models on EnvBench-Python.(a)Pass@NNperformance showing how model success rates improve with multiple attempts (N=1N=1to55). OurPIPermodel (shown with cross markers) achieves performance comparable to much larger models like GPT-4o and Qwen3-32B, while substantially outperforming the base Qwen3-8B model.(b)Cost-performance tradeoff analysis comparing averagepass@1performance (averaged over five runs) against price per 1M output tokens (USD).",
                "position": 528
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Limitations and Future Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Reproducibility Statement",
        "images": []
    },
    {
        "header": "10Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BEmpirical Study of Environment Setup Failure Patterns",
        "images": []
    },
    {
        "header": "Appendix CTrain/Validation Performance",
        "images": []
    }
]