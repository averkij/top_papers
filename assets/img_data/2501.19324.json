[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19324/x1.png",
                "caption": "Figure 1:Reward-Guided Speculative Decoding (RSD).This diagram illustrates how RSD improves upon standard speculative decoding (SD) by incorporating reward-guided selection. SD strictly enforces exact token matching between the draft and target model, leading to unnecessary computations when mismatched tokens are discarded. In contrast, RSD evaluates draft outputs based on reward signalsrùëüritalic_rand selectively refines them, reducing reliance on exact matching and improving efficiency. The process starts with a small and fast draft model generating preliminary results, followed by a larger and more reliable target model verifying and refining predictions. Darker background regions indicate higher computational costs, showing how SD wastes resources on rejected tokens, whereas RSD reduces unnecessary steps by accepting useful draft outputs even when they do not exactly match, balancing efficiency and accuracy.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Reward-Guided Speculative Decoding",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19324/x2.png",
                "caption": "Figure 3:Left: A comparison of the reward scores for all questions generated by the draft model and the target model within the RSD framework.Middle: A focused comparison of the reward scores for correctly answered questions generated by the draft model and the target model in the RSD framework.Right: The winning rate (in terms of reward) comparison between the draft model and the target model, highlighting the proportion of cases where each model outperforms the other. RSD is configured with Qwen2.5-Math-1.5B-Instruct as the draft model, Qwen2.5-Math-7B-Instruct as the target model, and Skywork-o1-Open-PRM-7B as the PRM.",
                "position": 442
            }
        ]
    },
    {
        "header": "3Empirical Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19324/x3.png",
                "caption": "Figure 4:Flops vs. accuracy on MATH500.",
                "position": 1144
            },
            {
                "img": "https://arxiv.org/html/2501.19324/x4.png",
                "caption": "Figure 5:The impact of thresholdŒ¥ùõø\\deltaitalic_Œ¥with RSD (1.5B/7B/7B).",
                "position": 1155
            },
            {
                "img": "https://arxiv.org/html/2501.19324/x5.png",
                "caption": "Figure 6:Accuracy of weighting functions from Table1with RSD (1.5B/7B/7B). All settings share a similar inference cost.",
                "position": 1171
            }
        ]
    },
    {
        "header": "4Discussion",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Code Availability",
        "images": []
    },
    {
        "header": "Appendix AProof",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.19324/x6.png",
                "caption": "Figure B.1:The behaviour of RSD (1.5B/7B/7B) for differentŒ¥ùõø\\deltaitalic_Œ¥s and questions in different complexity levels (the higher the level, the harder the question.).Œ¥=0ùõø0\\delta=0italic_Œ¥ = 0andŒ¥=1ùõø1\\delta=1italic_Œ¥ = 1denotes all questions are solved by the draft model alone and the target model only, respectively. Overall, the involvement of the target model improves the accuracy. The improvement is more obvious for harder question, +16 for level 4 and 5. In addition, with an increasing level, the questions solved by the draft model only decrease for the sameŒ¥ùõø\\deltaitalic_Œ¥, demonstrating harder questions need more involvement of the target model.",
                "position": 3221
            },
            {
                "img": "https://arxiv.org/html/2501.19324/x7.png",
                "caption": "Figure B.2:Left: A comparison of the reward scores for all questions generated by the draft model and the target model within the RSD framework.Middle: A focused comparison of the reward scores for correctly answered questions generated by the draft model and the target model in the RSD framework.Right: The winning rate comparison between the draft model and the target model, highlighting the proportion of cases where each model outperforms the other in the RSD framework. RSD is configured with Qwen2.5-Math-1.5B-Instruct as the draft model, Qwen2.5-Math-72B-Instruct as the target model, and Skywork-o1-Open-PRM-7B as the PRM.",
                "position": 3365
            }
        ]
    },
    {
        "header": "Appendix BAdditional Empirical Results",
        "images": []
    }
]