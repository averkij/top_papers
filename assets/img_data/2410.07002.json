[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x1.png",
                "caption": "Figure 1:Different forms of programming assistance. The common uses of current LLMs are shown on the left. Our framework is shown on the right.",
                "position": 158
            }
        ]
    },
    {
        "header": "2Assistant-Conversation: New Conversation Framework for Programming Assistants",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x2.png",
                "caption": "Figure 2:Examples of Assistant-Conversation from our training data.",
                "position": 241
            }
        ]
    },
    {
        "header": "3APEval: Benchmark for Assisted Programming",
        "images": []
    },
    {
        "header": "4Programming-Instruct: Collect any data during programming",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x3.png",
                "caption": "Figure 3:Samples from AIprogrammer, Git Commit and Online Submit.",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x4.png",
                "caption": "Figure 4:Data processing pipeline. The randomly selected time point is the third, and the randomly selected data type isHandC.",
                "position": 416
            }
        ]
    },
    {
        "header": "5CursorCore: Fine-tune LLMs to align anything",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x5.png",
                "caption": "Figure 5:The distribution of programming language in the training data.",
                "position": 522
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x5.png",
                "caption": "Figure 5:The distribution of programming language in the training data.",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x6.png",
                "caption": "Figure 6:The distribution of history snippets in the training data.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x7.png",
                "caption": "Figure 7:The distribution of input lengths in the training data.",
                "position": 536
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x7.png",
                "caption": "Figure 7:The distribution of input lengths in the training data.",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x8.png",
                "caption": "Figure 8:The distribution of output lengths in the training data.",
                "position": 544
            }
        ]
    },
    {
        "header": "6Evaluation and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x9.png",
                "caption": "Figure 9:Data Selection Ablation on APEval.",
                "position": 575
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BCode modification representation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x10.png",
                "caption": "Figure 10:Different formats for representing code modifications.",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x10.png",
                "caption": "Figure 10:Different formats for representing code modifications.",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x11.png",
                "caption": "Figure 11:Performance of models using different formats on APEval.",
                "position": 2342
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x12.png",
                "caption": "Figure 12:Context length for models using different formats on APEval.",
                "position": 2347
            }
        ]
    },
    {
        "header": "Appendix CAdditional details about Programming-Instruct",
        "images": []
    },
    {
        "header": "Appendix DTarget area representation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x13.png",
                "caption": "Figure 13:With and without the use of location information on APEval.",
                "position": 2377
            }
        ]
    },
    {
        "header": "Appendix EDiscussion about thought process",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x14.png",
                "caption": "Figure 14:Performance of models using thought process or not on APEval.",
                "position": 2390
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x15.png",
                "caption": "",
                "position": 2399
            }
        ]
    },
    {
        "header": "Appendix FConversation retrieval for Assistant-Conversation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x16.png",
                "caption": "Figure 15:Performance of models using different sliding window sizes on APEval.",
                "position": 2415
            }
        ]
    },
    {
        "header": "Appendix GEvaluation results of other benchmarks",
        "images": []
    },
    {
        "header": "Appendix HAdditional evaluation results on APEval",
        "images": []
    },
    {
        "header": "Appendix IChat template",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x17.png",
                "caption": "Figure 16:Example of chat template and its corresponding demonstration in the IDE scenario.",
                "position": 2902
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x18.png",
                "caption": "Figure 17:Example of chat templates in LC and SR modes.",
                "position": 2905
            }
        ]
    },
    {
        "header": "Appendix JPrompts for evaluation",
        "images": []
    },
    {
        "header": "Appendix KPrompts for data collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07002/x19.png",
                "caption": "Figure 18:Few-shot prompts designed to leverage LLMs for simulating the behavior of a novice programmer.",
                "position": 3705
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x20.png",
                "caption": "Figure 19:Few-shot prompts designed to leverage LLMs for simulating the behavior of an ordinary programmer.",
                "position": 3708
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x21.png",
                "caption": "Figure 20:Few-shot prompts designed to leverage LLMs for simulating the behavior of an expert programmer.",
                "position": 3711
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x22.png",
                "caption": "Figure 21:Few-shot prompts designed to evaluate whether the outputs align with user intent.",
                "position": 3714
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x23.png",
                "caption": "Figure 22:Few-shot prompts designed to generate user instructions",
                "position": 3717
            },
            {
                "img": "https://arxiv.org/html/2410.07002/x24.png",
                "caption": "Figure 23:Few-shot prompts designed to generate chat-style interactions between models and users.",
                "position": 3720
            }
        ]
    },
    {
        "header": "Appendix LLimitations and future work",
        "images": []
    }
]