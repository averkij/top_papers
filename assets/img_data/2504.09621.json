[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09621/x1.png",
                "caption": "Figure 1:Comparison between different methods for handling large images in haze removal tasks. (a) Downsampling approach, which reduces the image size but loses critical high-frequency details. (b) Image slicing technique, which processes larger inputs but compromises global contextual information and object coherence. (c) The proposed method, which aims to effectively balance global context and local feature extraction to enhance haze removal performance in high-resolution images.",
                "position": 66
            },
            {
                "img": "https://arxiv.org/html/2504.09621/x2.png",
                "caption": "Figure 2:Comparison of GPU memory usage across various models. DehazeXL demonstrates a reduction in memory usage by approximately 65%-80% when processing large images compared to other methods. Notably, when employing FP16 format for inference, DehazeXL can process 10,240×\\times×10,240 pixel images with only 21 GB of memory.",
                "position": 81
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09621/x3.png",
                "caption": "Figure 3:Overall architecture of the proposed model. It begins by partitioning the hazy image into uniform-sized patches, which are then encoded into tokens by the Encoder. The Bottleneck injects global information into each token, enhancing the contextual representation. Subsequently, the Decoder reconstructs the tokens back into image patches, forming the final output image. Notably, to minimize memory consumption, both the Encoder and Decoder employ an asynchronous processing strategy, handling the input in multiple mini-batches sequentially rather than simultaneously. This design optimizes memory efficiency while ensuring effective haze removal.",
                "position": 123
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09621/x4.png",
                "caption": "Figure 4:Illustration of the baseline image and the path function. The region enclosed by the red box indicates the attribution area.",
                "position": 194
            }
        ]
    },
    {
        "header": "4Experiments and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09621/x5.png",
                "caption": "Figure 5:Dehazed results on the8KDehazedataset. The patches for comparison are marked with red boxes in the original images. PSNR / SSIM is calculated based on the patches to better reflect the performance difference. The proposed DehazeXL can directly infer images with a resolution of 8192×\\times×8192 without the need for slicing inference. Compared to other methods, the proposed method effectively eliminates segmentation artifacts and achieves superior visual quality.",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2504.09621/x6.png",
                "caption": "Figure 6:Dehazed results on the4KID[58]dataset. The proposed DehazeXL can effectively utilize global information to guide image restoration in different regions, enhancing the global consistency of the output results.",
                "position": 275
            },
            {
                "img": "https://arxiv.org/html/2504.09621/x7.png",
                "caption": "Figure 7:Dehazed results on theO-HAZE[2]dataset. The proposed DehazeXL demonstrates higher color fidelity and restores more details compared with other state-of-the-art methods.",
                "position": 278
            },
            {
                "img": "https://arxiv.org/html/2504.09621/x8.png",
                "caption": "Figure 8:Comparison of the dehazed results and attribution maps of different methods. The red box on (1-a) and (2-a) indicate the regions of interest for attribution. The attribution maps highlight how each pixel influences the dehazing results in the specified region.",
                "position": 488
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]