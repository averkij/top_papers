[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x1.png",
                "caption": "Figure 1:Performance comparison of several advanced multimodal agents/models across MM-BrowseComp and other prominent benchmarks. The lower accuracy on MM-BrowseComp across all models highlights its challenging nature and its effectiveness in evaluating the deep multimodal browsing capabilities of advanced agents. The sources for our evaluation metrics are detailed in Appendix6.",
                "position": 181
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x2.png",
                "caption": "Figure 2:Two illustrative examples from the MM-BrowseComp, showcasing both a text-only instance and one with an accompanying image in its input. To preserve the value of this benchmark, we request that youdo not post or display the plain text of the dataset publicly online.This helps prevent both data contamination of future training corpora and answer leakage during evaluation.",
                "position": 193
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x3.png",
                "caption": "Figure 3:An overview of the task distribution and composition of the MM-BrowseComp.",
                "position": 333
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x4.png",
                "caption": "(a)Overall Accuracy",
                "position": 1072
            },
            {
                "img": "https://arxiv.org/html/2508.13186/x4.png",
                "caption": "(a)Overall Accuracy",
                "position": 1075
            },
            {
                "img": "https://arxiv.org/html/2508.13186/x5.png",
                "caption": "(b)Strict Accuracy",
                "position": 1080
            },
            {
                "img": "https://arxiv.org/html/2508.13186/x6.png",
                "caption": "Figure 5:Distribution of error types for four different open-source agents when using Gemini-2.5-Flash-Preview-05-20 as a backbone model.",
                "position": 1097
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Benchmark Sources",
        "images": []
    },
    {
        "header": "7Distribution of Checklist Items by Modality",
        "images": []
    },
    {
        "header": "8Experimental Setup Details",
        "images": []
    },
    {
        "header": "9Failure Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x7.png",
                "caption": "Figure 7:Distribution of error types for different Agents, powered by two different models.",
                "position": 2276
            }
        ]
    },
    {
        "header": "10Detailed Results by Subtask",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.13186/x8.png",
                "caption": "Figure 8:Performance of the tool-augmented o3 across all subtasks.",
                "position": 2289
            }
        ]
    },
    {
        "header": "11Impact of Search Breadth on Model Performance",
        "images": []
    },
    {
        "header": "12Case Study",
        "images": []
    }
]