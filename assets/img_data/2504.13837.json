[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13837/x1.png",
                "caption": "Figure 1:(Left)The effect of RLVR on LLM‚Äôs reasoning ability.\nSearch trees are generated by repeated sampling from the base and RLVR-trained models for a given problem.Greyindicates paths that are unlikely to be sampled by the model, whileblackindicates paths that are likely to be sampled.Greenindicates correct paths, which has positive rewards.\nOur key finding is that all reasoning paths in the RLVR model are already present in the base model.\nFor certain problems like Problem A, RLVR training biases the distribution toward rewarded paths, improving sampling efficiency.\nHowever, this comes at the cost of reduced scope of reasoning capacity: For other problems like Problem B,\nthe base model contains the correct path, whereas that of the RLVR model does not.(Right)As RLVR training progresses, the average performance (i.e., pass@1) improves, but the coverage of solvable problems (i.e., pass@256) decreases, indicating a reduction in the model‚Äôs reasoning upper bound.",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x1.png",
                "caption": "",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x2.png",
                "caption": "",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x3.png",
                "caption": "Figure 2:Pass@kùëòkitalic_kcurves of base models and their zero-RL-trained counterparts across multiple mathematical benchmarks.\nWhenkùëòkitalic_kis small, RL-trained models outperform their base versions.\nHowever, askùëòkitalic_kincreases to the tens or hundreds, base models consistently catch up with RL-trained models across all benchmarks and LLM families without exception.\nEventually, base models surpass RL-trained models.",
                "position": 196
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3RLVR‚Äôs Effect on Reasoning Capacity Boundary",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13837/x4.png",
                "caption": "Figure 3:Oat-Zero for AIME24.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x5.png",
                "caption": "Figure 4:RLVR for Coding.",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x6.png",
                "caption": "Figure 5:Pass@kùëòkitalic_kcurves of base models and zero-RL counterparts.(Left)Code Generation.(Right)Visual Reasoning.",
                "position": 538
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x6.png",
                "caption": "",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x7.png",
                "caption": "",
                "position": 546
            }
        ]
    },
    {
        "header": "4Deep Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13837/x8.png",
                "caption": "Figure 6:(Left)Perplexity distribution of responses from different sources, evaluated by the base and RL models. The conditioning problemxùë•xitalic_xis omitted in the figure.(Right)Coverage comparison of base, Instruct, RL, and distilled models.",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x8.png",
                "caption": "",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x9.png",
                "caption": "",
                "position": 628
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x10.png",
                "caption": "Figure 7:(Top)Different RL algorithms.(Bottom)Different RL training steps.\nWe use afolded y-axisrange to better highlight the details atk=1ùëò1k=1italic_k = 1and256256256256.\nUnfolded version can be found inFigure8.\nThe detailed values for each point at pass@1 and pass@256 are provided inTable2andTable3.",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x10.png",
                "caption": "",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x11.png",
                "caption": "",
                "position": 658
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13837/x12.png",
                "caption": "Figure 8:Unfolded y-axis version ofFigure7.",
                "position": 1462
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x12.png",
                "caption": "",
                "position": 1465
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x13.png",
                "caption": "",
                "position": 1470
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x14.png",
                "caption": "Figure 9:Pass@kùëòkitalic_kcurves of the base and RL models in the filtered AIME24.",
                "position": 1673
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x15.png",
                "caption": "Figure 10:We found that the base model‚Äôs performance drops when the temperature exceeds 1.0, as it tends to generate more random and less coherent tokens. In contrast, the RL model‚Äôs performance remains relatively stable across different temperature settings. Therefore, we useT=0.6ùëá0.6T=0.6italic_T = 0.6in the main experiments, as it allows both models to demonstrate their best reasoning performance.",
                "position": 1678
            }
        ]
    },
    {
        "header": "Appendix BPrompt Templates",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.13837/x16.png",
                "caption": "Figure 11:Prompt for SimpleRL Training and Evaluation.\nThe base model uses the same prompt as the RL model during evaluation.",
                "position": 1704
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x17.png",
                "caption": "Figure 12:Prompt for Oat-Zero training and evaluation.",
                "position": 1710
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x18.png",
                "caption": "Figure 13:Prompt for Code-R1 training.",
                "position": 1715
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x19.png",
                "caption": "Figure 14:Prompt for Code-R1 Evaluation on LiveCodeBench.",
                "position": 1720
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x20.png",
                "caption": "Figure 15:Prompt for Code-R1 Evaluation on HumanEval+ and MBPP+.",
                "position": 1725
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x21.png",
                "caption": "Figure 16:Prompt for EasyR1 training and evaluation.",
                "position": 1730
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x22.png",
                "caption": "Figure 17:(1)\nPrompt for VeRL training and evaluation.",
                "position": 1735
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x23.png",
                "caption": "Figure 18:Qwen-2.5-Base-7B Correct Response - Case 1.",
                "position": 1741
            },
            {
                "img": "https://arxiv.org/html/2504.13837/x24.png",
                "caption": "Figure 19:Qwen-2.5-Base-7B Correct Response - Case 2.",
                "position": 1744
            }
        ]
    },
    {
        "header": "Appendix CBroader Impacts",
        "images": []
    }
]