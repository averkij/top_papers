[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/x1.png",
                "caption": "",
                "position": 152
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/x2.png",
                "caption": "Figure 2:Method overview.(a)Reflection-in-action: multiple candidate actions are generated and scored by an internal reflection LLM prior to execution. (b)Reflection-on-action: iteratively invoked when working memory hits K or at key milestones. Executed actions are critiqued by an external reflection LLM and stored in a working memory buffer; at milestones, hindsight re-evaluation assigns long-horizon credit. The resulting verbal reflections form self-supervised training data to update both the internal reflection LLM (supervised loss) and the action LLM (policy gradient) via test-time training, enabling agents to learn from execution experience during deployment.",
                "position": 196
            }
        ]
    },
    {
        "header": "3Reflective Test-Time Planning",
        "images": []
    },
    {
        "header": "4Experiments on Long-Horizon Household Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/x3.png",
                "caption": "Figure 3:Cupboard Fitting results. Blue bars show correct-placement rate, pink bars show fit rate. RIA means Reflection-in-action; ROA means Reflection-on-action. “W/o external reflection” means that we don’t use external reflection as the input to the action generation LLM. We implement two test-time training variants for ROA: one is test-time training on all base weights; and the other is test-time training on LoRA parameters only. Reflective Test-Time Planning significantly improves both success metrics.",
                "position": 685
            }
        ]
    },
    {
        "header": "5Experiments on the Cupboard Fitting Task",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/x4.png",
                "caption": "Figure 4:Examples of the Cupboard Fitting Task.",
                "position": 722
            },
            {
                "img": "https://arxiv.org/html/2602.21198/x5.png",
                "caption": "Figure 5:Qualitative Examples.Steps and reflections are simplified for better presentations. Blue text shows internal reflection used for candidate selection, orange text shows external reflection after execution, and red text suggests retrospective reflection. (a) Long-Horizon Household example. We use retro & internal because the generated retro reflection is also used to train the internal model. (b) Real-robot Cupboard Fitting example. We put reflection scores inside brackets, omit detailed reflections and only present the scores for simplicity.",
                "position": 725
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AContribution Statement",
        "images": []
    },
    {
        "header": "Appendix BTest-Time Cost Analysis",
        "images": []
    },
    {
        "header": "Appendix CGeneralization to Habitat-Matterport 3D Scenes",
        "images": []
    },
    {
        "header": "Appendix DHyperparameter Analyses for Cupboard Fitting Task",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/figures/cupboard_parameters_v4.png",
                "caption": "Figure 6:Hyperparameter ablation studies on Cupboard Fitting.Top Left:Performance vs. number of candidate actions. Peak performance (60.0%) occurs at N=6 candidates, demonstrating that internal reflection effectively identifies superior actions from diverse pools. Beyond N=6, performance plateaus as excessive candidates add computational cost without improving the best candidate quality.Top Right:Performance vs. sampling temperature. Optimal temperature range (T=1.25-1.5) balances candidate diversity with quality—temperatures below 0.5 produce overly similar candidates that limit reflection value, while temperatures above 1.75 generate incoherent actions that even accurate reflection cannot salvage.Bottom Left:Performance vs. LoRA configuration (rank, alpha). The optimal configuration (r=8,α\\alpha=16) achieves 60.0% performance, balancing adaptation capacity with training stability. Smaller configurations like (4,4) underfit with insufficient capacity (52.5%), while larger configurations cause mode collapse during test-time training—(16,32) drops to 41.5% and (32,32) collapses to 34.8% as the model begins predicting identical outputs for all inputs, losing the ability to distinguish between different spatial configurations and task contexts.Bottom Right:Performance vs. action budget (maximum steps). Performance improves dramatically from 30 steps (51.5%) to 50 steps (60.0%), but slightly degrades to 59.4% at 100 steps, suggesting that excessive action budgets allow suboptimal exploration strategies that accumulate errors over longer horizons.",
                "position": 1445
            }
        ]
    },
    {
        "header": "Appendix ESingle-Step Action Generation vs. Receding Horizon Planning",
        "images": []
    },
    {
        "header": "Appendix FExperiments on\nLong-Horizon Household Tasks: More Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.21198/figures/task_distribution.png",
                "caption": "Figure 7:Distribution of task categories in the dataset.",
                "position": 1616
            },
            {
                "img": "https://arxiv.org/html/2602.21198/x6.png",
                "caption": "Figure 8:Steps and reflections are simplified for better presentations. Blue text shows internal reflection used for candidate selection, orange text shows external reflection after execution. We put reflection scores inside brackets. Red text shows retrospective reflection and model updates.",
                "position": 1840
            }
        ]
    },
    {
        "header": "Appendix GCupboard Fitting: More Details",
        "images": []
    },
    {
        "header": "Appendix HMore Qualitative Examples",
        "images": []
    },
    {
        "header": "Appendix IPhysical Experiment Setup",
        "images": []
    }
]