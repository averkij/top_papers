[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07222/illustration_v3.png",
                "caption": "Figure 1:Grad-CAM of attention maps of VLM under white-box untargeted attacks through perturbed images. The texts are given at the bottom of the figure, with function words highlighted.Left:The VLM correctly recognizes the female student on the clean image given the tokenher.Mid:The VLM is distracted by the adversarial perturbation and partially looks at the male coach.Right:The distraction is mitigated by simply applying masks to remove all function words: the VLM successfully ‚Äòlooks back at‚Äô the female student.",
                "position": 139
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07222/pipeline_v2.png",
                "caption": "Figure 2:Left:An illustration of our Function-word De-Attention (FDA) method. On the existing process of attention calculation, which uses‚Ñ±V\\mathcal{F}_{V}and‚Ñ±T\\mathcal{F}_{T}, we add a parallel pipeline to calculate the attentions between function words‚Ñ±Tf\\mathcal{F}_{T_{f}}and the images‚Ñ±V\\mathcal{F}_{V}. Afterwards, the function-attention passes a control gateùí¢\\mathcal{G}before entering the FDA module (triangle) differentially to subtract distractions as presented in Eq.6.Right:We speculate that attacks can easily cross the boundary for misalignments for less aligned models (top), and by removing function-word distractions, models can learn a robust embedding (bottom), preventing misalignments.",
                "position": 213
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07222/vla_vis.png",
                "caption": "Figure 3:Left: T-SNE of the vision-language embedding of vanilla VLM, FDA, FARE, and TeCoA.Our FDA is the most aligned model.Right: Comparison of text-image similarity for vanilla VLM versus VLM + FDA.Our FDA yields better alignment with larger similarities and smaller variances.",
                "position": 2024
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADetails for attacks and evaluation metrics",
        "images": []
    },
    {
        "header": "Appendix BFull results for targeted attacks",
        "images": []
    },
    {
        "header": "Appendix CFull results for untargeted attacks",
        "images": []
    },
    {
        "header": "Appendix DFull results for ablation studies",
        "images": []
    },
    {
        "header": "Appendix EDetails for function word dictionary",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.07222/attention_visualization.png",
                "caption": "Figure 4:A heatmap of attention probabilities given the same image and text inputs.Left: Original attention probabilities are relatively ‚Äònoisy‚Äô and have several visible stripes with very low probabilities, implying the existence of some less relevant visual tokens that are activated, with negligible contributions.Mid: Attention probabilities with one FDA subtraction show much less aforementioned ‚Äòstripes‚Äô, with much cleaner and more focused attentions. However, some distractions still exist and remain visible.Right: Attention probabilities with two subtractions show the cleanest attention maps and have the most negligible distractions, with only strong activations on the most relevant visual tokens, i.e., with higher probabilities.",
                "position": 5355
            }
        ]
    },
    {
        "header": "Appendix FVisualization of attention scores",
        "images": []
    }
]