[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09017/x1.png",
                "caption": "",
                "position": 144
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09017/x2.png",
                "caption": "Figure 2:The process of data labeling, training, and inference for Contact-Anchored Policies. (a) During training, we detect the contact point from the data and label the trajectory with hindsight relabeling. (b) During inference, we use a user click or VLM conditioned on user command to derive the contact condition. In both cases, the contact tokens and visual tokens get concatenated and passed to the model which uses them as input to predict the actions.",
                "position": 358
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Contact-Anchored Policies",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09017/x3.png",
                "caption": "Figure 3:Our data collection tool and matching robot deployment gripper.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x4.png",
                "caption": "Figure 4:EgoGym: a lightweight simulation-in-the-loop environment used for quick development and evaluation of Contact-Anchored Policies (CAPs). EgoGym enables fast checkpoint evaluation and failure mode discovery across Pick, Open, and Close tasks using procedurally generated scenes.",
                "position": 480
            }
        ]
    },
    {
        "header": "4Evaluating CAP",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09017/figures/fig_4_test.jpg",
                "caption": "Figure 5:Evaluation environments for CAP. Each scene and object combination has 10 trials, so Pick checkpoints are evaluated for 250 episodes and Open or Close checkpoints are evaluated for 100 episodes.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x5.png",
                "caption": "Figure 6:Comparison of contact instructions generated by human oracles and vision-language models for the CAPs. Downstream CAP performance is comparable on all tasks.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x6.png",
                "caption": "Figure 7:Cross-embodiment deployment of CAP on a Franka FR3, XArm 6, Universal Robotics UR3e, and an iPhone app. For the robots, the same CAP checkpoint generates EE-space motion that we translate to joint position control with IK. For the iPhone, the user is prompted to move the iPhone to where the robot should go next.",
                "position": 665
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x7.png",
                "caption": "Figure 8:Evaluation of CAP zero-shot on diverse embodiments: each bar is a different set of evaluations in a unique site. To evaluate system robustness, we share checkpoints, setup instructions, and evaluation methodology to external collaborators and get performance numbers from them.",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x8.png",
                "caption": "Figure 9:Performing long-horizon manipulations with Contact-Anchored Policies controlled by a high-level VLM controller via tool-calling. On the top, to retrieve coffee beans from cabinet, a controller combines Pick, Open, and Close CAPs, while on the bottom, a table cleanup is performed with Pick CAP.",
                "position": 718
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x9.png",
                "caption": "Figure 10:Left:Sim-to-real correlation for single-blind EgoGym-Pick evaluations.Right:Analysis of failure modes of four iterations of CAP Pick checkpoints in EgoGym. With feedback from each iteration, our pipeline changes allowed better policy quality in real and sim.",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x10.png",
                "caption": "Figure 11:Relative success rate as a function of visual distractors for CAP andπ0.5\\pi_{0.5}models on EgoGym-Pick. Success rates are normalized to each model’s performance with zero distractors.",
                "position": 879
            }
        ]
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09017/x11.png",
                "caption": "Figure 12:Pipeline for Extracting Gripper Label By Using SAM2",
                "position": 1914
            },
            {
                "img": "https://arxiv.org/html/2602.09017/figures/robot_starting_poses_images.jpg",
                "caption": "Figure 13:Real robot configurations corresponding to each starting pose",
                "position": 2016
            },
            {
                "img": "https://arxiv.org/html/2602.09017/figures/robot_starting_poses_scatter.png",
                "caption": "Figure 14:Robot starting poses in the base–height parameter space",
                "position": 2019
            },
            {
                "img": "https://arxiv.org/html/2602.09017/figures/egogym_picks.jpg",
                "caption": "Figure 15:EgoGym Pick environment visualizations",
                "position": 2037
            },
            {
                "img": "https://arxiv.org/html/2602.09017/figures/egogym_open_close.jpg",
                "caption": "Figure 16:EgoGym Open/Close environment visualizations",
                "position": 2040
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x12.png",
                "caption": "Figure 17:Loss and simulation success rate over time for the Pick task during a CAP training run.",
                "position": 2162
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x12.png",
                "caption": "Figure 17:Loss and simulation success rate over time for the Pick task during a CAP training run.",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2602.09017/x13.png",
                "caption": "Figure 18:Training loss and simulation success rate over time for the Open task during a CAP training run.",
                "position": 2170
            },
            {
                "img": "https://arxiv.org/html/2602.09017/figures/cap-pickup-objects.jpg",
                "caption": "Figure 19:Evaluation objects used for the Pick evaluations",
                "position": 2176
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]