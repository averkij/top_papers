[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introducion",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02831/x1.png",
                "caption": "Figure 1:GENIE capabilities.GENIE combines the editability of Gaussians with the neural rendering power of Neural Radiance Fields (NeRF). It enables fine-grained, on-the-fly editing through either manual interaction or mesh-driven deformation.",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2508.02831/x2.png",
                "caption": "Figure 2:Evolution of two physical simulations.From left to right: (1) A rubber duck falling onto a pillow and deforming it. (2) A pirate flag waving under the influence of wind. Both simulations are performed on our own assets.",
                "position": 89
            }
        ]
    },
    {
        "header": "Related Works",
        "images": []
    },
    {
        "header": "Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02831/x3.png",
                "caption": "Figure 3:Examples of physical simulations.From top to bottom: (1) Rigid body simulation of falling leaves from theNeRF SyntheticFicus plant. (2) Soft body simulation deforming theNeRF SyntheticLego dozer. (3) Cloth simulation of fabric falling onto a cup from our custom asset collection. The middle column shows the driving mesh deformations.",
                "position": 158
            },
            {
                "img": "https://arxiv.org/html/2508.02831/x4.png",
                "caption": "Figure 4:Model overview.Top: During training, a subset of Gaussians is selected using Ray-Traced Gaussian Proximity Search (RT-GPS), which also handles pruning based on Gaussian confidence. The selected Gaussians are passed to Splash Grid Encoding, which interpolates their features and drives the densification process by inserting new Gaussians as needed. The interpolated features are then processed by the neural network‚Ñ±G‚ÄãE‚ÄãN‚ÄãI‚ÄãE\\mathcal{F}_{GENIE}to predict colourùêú\\mathbf{c}and opacityœÉ\\sigma, which are used for volumetric rendering. Bottom: At inference, the learned Gaussians serve as input and can undergo manual or physics-driven edits. The modified Gaussians are passed through the same rendering pipeline to produce the final image.",
                "position": 190
            }
        ]
    },
    {
        "header": "Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02831/x5.png",
                "caption": "Figure 5:The RT-GPS working principle.A light ray passing through the scene is illustrated, along with its intersections with the icosahedrons. The figure highlights which Gaussians are considered neighbors and which are excluded.",
                "position": 287
            }
        ]
    },
    {
        "header": "Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02831/Real_Scenes.png",
                "caption": "Figure 6:Example edits on real-world scenes.From top to bottom: (1) Manual edit of thefoxscene from(M√ºller et¬†al.2022), where the head is rotated from left to right. (2) Physics-based simulation in theGardenscene fromMip-NeRF 360, showing an object falling onto a tilted table and bouncing off. (3) Bottom row: physics simulation in thekitchenscene fromMip-NeRF 360, where a force is applied to deform a plasticine dozer.",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2508.02831/x6.png",
                "caption": "Figure 7:Qualitative comparison.Results shown on theNeRF-Syntheticdataset. Modified objects are in the top row. Each row compares reconstruction quality across different methods. Our results are added to those reported by(Chen, Lyu, and Wang2023).",
                "position": 688
            }
        ]
    },
    {
        "header": "Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02831/x7.png",
                "caption": "Figure 8:Mesh discontinuity.Mesh discontinuity during the editing causes holes in the edited model especially visible on the left side of the water basin.",
                "position": 2081
            },
            {
                "img": "https://arxiv.org/html/2508.02831/",
                "caption": "Figure 9:Too few Gausses.Too few Gausses during initialization and no densification causes network to have problems with proper reconstruction.",
                "position": 2084
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]