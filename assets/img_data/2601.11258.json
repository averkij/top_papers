[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11258/x1.png",
                "caption": "Figure 1:Overview of Parametric Skill Transfer (PaST).The motivation (left) illustrates how standard SFT fails to handle environmental errors, leading to hallucinations, while PaST enables robust execution by incorporating reasoning skills.\nOur approach is based on the empirical finding (top right) that parameter updates for knowledge (Δ​WS​F​T\\Delta W_{SFT}) and skills (Δ​WR​L\\Delta W_{RL}) are nearly orthogonal and reside in disentangled subspaces.\nPaST first extracts a domain-agnostic skill vectorvs​k​i​l​l=θSr​l−θSs​f​tv_{skill}=\\theta_{S}^{rl}-\\theta_{S}^{sft}from a source domain and then linearly injects it into a target model viaθf​i​n​a​l=θTs​f​t+λ⋅vs​k​i​l​l\\theta_{final}=\\theta_{T}^{sft}+\\lambda\\cdot v_{skill}, enabling efficient and effective knowledge adaptation without requiring expensive reinforcement learning in the target domain.",
                "position": 265
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11258/x2.png",
                "caption": "Figure 2:We visualize the layer-wise cosine similarity between the weight changes induced by SFT (Δ​WSFT\\Delta W_{\\text{SFT}}) and RL (Δ​WRL\\Delta W_{\\text{RL}}) on the LooGLE task. The dominant near-zero values indicate that knowledge acquisition and skill learning modify the model parameters along nearly orthogonal subspaces.",
                "position": 380
            }
        ]
    },
    {
        "header": "4Parametric Skill Transfer",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11258/x3.png",
                "caption": "Figure 3:Zero-shot cross-domain generalization on StableToolBench.Success Rate across 20 RL-unseen target categories using a skill vector trained solely onMovies.\nPaST (dark blue) raises the average success rate by+10.3%over the Target SFT baseline (grey). All results are averaged over three independent runs.",
                "position": 581
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Case Studies",
        "images": []
    },
    {
        "header": "Appendix BAdditional Visualization: Orthogonality Control Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.11258/x4.png",
                "caption": "Figure 4:Control Experiment: Similarity between two SFT updates.We visualize the cosine similarity between parameter updates induced by two different rounds of SFT (Δ​WSFT21\\Delta W_{\\text{SFT21}}vs.Δ​WSFT2\\Delta W_{\\text{SFT2}}) on LooGLE. Unlike the SFT-RL comparison, these updates show a clear positive correlation (red regions), indicating that knowledge injection tasks operate within a shared parameter subspace.",
                "position": 1399
            }
        ]
    },
    {
        "header": "Appendix CTheoretical Proof of Functional Disentanglement",
        "images": []
    },
    {
        "header": "Appendix DSQuAD Experiments",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details for LooGLE Experiments",
        "images": []
    },
    {
        "header": "Appendix FToolBench Experiments",
        "images": []
    },
    {
        "header": "Appendix GDeclaration of AI Usage",
        "images": []
    }
]