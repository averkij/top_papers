[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Sparse Value Neurons in Large Language Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x1.png",
                "caption": "Figure 1:AUC curves for layers 2–4 of the Qwen-2.5-14B-SimpleRL-Zoo model on the GSM8K and MATH500 datasets.\nThe curves indicate that the value probe can accurately predict the value by relying on only a very small number of value neurons.",
                "position": 226
            }
        ]
    },
    {
        "header": "3Robustness and Transferability of the Value Neurons",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x2.png",
                "caption": "Figure 2:AUC curves for layers 2–4 of the Qwen-2.5-14B-SimpleRL-Zoo model on the Minerva Math, ARC, and the STEM subset of MMLU datasets.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x3.png",
                "caption": "Figure 3:AUC curves for layers 2–4 of the Qwen-2.5-1.5B/7B/14B-SimpleRL-Zoo model on the GSM8K dataset.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x4.png",
                "caption": "Figure 4:AUC curves for different layers of the Qwen-2.5-1.5B-SimpleRL-Zoo model on the GSM8K dataset.",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x5.png",
                "caption": "Figure 5:AUC curves for layers 2–4 of the Llama-3.1-8B-Instruct, Gemma-3-4B-it, and Phi-3.5-mini-instruct models on the MATH500 dataset.",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x6.png",
                "caption": "Figure 6:IoU as a function of the pruning ratio. The IoU values for value neurons across different datasets are significantly higher than the random baseline, indicating that for the same LLM, the positions of value neurons are closely correlated across tasks.",
                "position": 366
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x7.png",
                "caption": "Figure 7:IoU as a function of the pruning ratio. The IoU values for value neurons across different models are significantly higher than the random baseline, indicating that models derived from the same base model share a substantial number of value neuron positions.",
                "position": 381
            }
        ]
    },
    {
        "header": "4Applications of the Value Neurons",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x8.png",
                "caption": "Figure 8:Dopamine neurons encode information regarding the model’s prediction error for the current state.\n(a)Positive Surprise:The model initially lacks confidence in answering the problem but ultimately provides the correct solution. This neuron exhibits two significant peaks when the model identifies a critical logical step and subsequently derives the final key result.\n(b)Negative Surprise:Conversely, the model begins with high confidence but fails to solve the problem correctly. The neuron displays a distinct trough at the exact moment a logical flaw occurs.",
                "position": 397
            },
            {
                "img": "https://arxiv.org/html/2602.00986/figures/relation/sample22_neuron1517.png",
                "caption": "Figure 9:The activation curves of a dopamine neuron across states under different ablation conditions. The yellow line represents the original trajectory, the blue line shows the result of zeroing 20% random neurons, and the red line depicts the result of zeroing the top 20% value neurons. While random ablation has a minimal impact on the overall trend, value neuron ablation significantly alters the trajectory of the curve. This indicates a close correlation between value and dopamine neurons.",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2602.00986/figures/relation/sample11_neuron1517.png",
                "caption": "",
                "position": 442
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AThe Benefit of Using the TD Error Training Objective",
        "images": []
    },
    {
        "header": "Appendix BHyperparameters",
        "images": []
    },
    {
        "header": "Appendix CDerivation of the IoU Curve for the Random Baseline",
        "images": []
    },
    {
        "header": "Appendix DTransferability Across Different Datasets: More IoU Curves",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x9.png",
                "caption": "Figure 10:IoU as a function of the pruning ratio. The IoU values for value neurons across different datasets are significantly higher than the random baseline, indicating that for the same LLM, the positions of identified value neurons are closely correlated across tasks.",
                "position": 1134
            },
            {
                "img": "https://arxiv.org/html/2602.00986/x10.png",
                "caption": "Figure 11:IoU as a function of the pruning ratio. The IoU values for value neurons across different datasets are significantly higher than the random baseline, indicating that for the same LLM, the positions of identified value neurons are closely correlated across tasks.",
                "position": 1139
            }
        ]
    },
    {
        "header": "Appendix EDetailed Procedures for Identifying Dopamine Neurons",
        "images": []
    },
    {
        "header": "Appendix FFurther Evidence for the Characteristics of Dopamine Neurons",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x11.png",
                "caption": "Figure 12:Dopamine neurons encode information regarding the model’s prediction error for the current state.\n(a)Positive Surprise:The model initially lacks confidence in answering the problem but ultimately provides the correct solution. This neuron exhibits a significant peak when the model identifies a critical logical step and subsequently derives the final key result.\n(b)Negative Surprise:Conversely, the model begins with high confidence but fails to solve the problem correctly. The neuron displays a distinct trough at the exact moment a wrong step occurs.",
                "position": 1225
            }
        ]
    },
    {
        "header": "Appendix GUsing Value Neurons to Measure Model Confidence",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.00986/x12.png",
                "caption": "Figure 13:Spearman correlation between the predicted value and the model’s avg@32 accuracy on the MATH500 dataset. The high correlation coefficients demonstrate the accuracy of the method in predicting model confidence.",
                "position": 1253
            }
        ]
    },
    {
        "header": "Appendix HModel Confidence Baseline Setup",
        "images": []
    }
]