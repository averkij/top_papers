[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13284/x1.png",
                "caption": "Figure 1:Benchmark accuracy of AceReason-Nemotron-1.1-7B on AIME 2024/2025 (avg@64), HMMT 2025 (avg@64), LiveCodeBench v5 (2024/08/01-2025/02/01, avg@8), and v6 (2025/02/01-2025/05/01, avg@8) using32768327683276832768output length.",
                "position": 136
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13284/x2.png",
                "caption": "Figure 2:Training Pipeline of AceReason-Nemotron 1.1. We start by performing math and code SFT on a base pretrained model. Next, we conduct three stages of math-only RL training with progressively growing response length, i.e., Stage-1 (8K), Stage-2 (16K), and Stage-3 (24K), to develop a math-specialized RL model. We then apply code-only RL training to enhance model’s coding capability. Lastly, we carry out a final stage of math-only RL to produce AceReason-Nemotron 1.1.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x3.png",
                "caption": "Figure 3:Response token length distributions for the math SFT dataset (left) and the code SFT dataset (right).",
                "position": 316
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x4.png",
                "caption": "",
                "position": 325
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13284/x5.png",
                "caption": "Figure 4:Log-scaled data statistics for the number of math and code prompts and the average number of responses per prompt. Each SFT dataset consist of both math and code SFT samples.",
                "position": 999
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x6.png",
                "caption": "",
                "position": 1008
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x7.png",
                "caption": "Figure 5:Accuracies on AIME24, AIME25, and LiveCodeBench V5 and V6 for different SFT datasets. For each SFT blend, the model is trained until the accuracy plateaus.",
                "position": 1014
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x8.png",
                "caption": "",
                "position": 1023
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x9.png",
                "caption": "",
                "position": 1028
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x10.png",
                "caption": "",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x11.png",
                "caption": "Figure 6:Accuracies over different epochs of training for SFT dataset v6 and v7.",
                "position": 1073
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x12.png",
                "caption": "",
                "position": 1082
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x13.png",
                "caption": "Figure 7:Math-onlyRL training starting from different SFT (distillation) models. The AIME24 accuracy at step-0 reflects the performance of the initial SFT checkpoints. The subsequent numbers in the figure show the final accuracy achieved at the end of each training stage: Math-Only Stage-1 (8K), Stage-2 (16K), Stage-3 (24K), and Stage-4 (32K).",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x14.png",
                "caption": "Figure 8:Left: Trajectories of temperature-adjusted entropy during RL training with different policy LLM temperature settings. Right: Impact of varying temperatures for inference and RL training. We observe that using a temperature of 0.6 for inference consistently yields better average results, and thus adopt 0.6 as the default inference temperature unless otherwise specified.",
                "position": 1118
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x15.png",
                "caption": "Figure 9:Ablation Studies onMath-OnlyRL training to assess the impact of overlong filtering. In both settings, Stage-1 starts with the same SFT model, and each subsequent stage begins with the same RL model from the previous stage trained under the best-performing setting (i.e., “w/ overlong filtering”). Notably, in the final stage (Stage-4), RL training without overlong filtering leads to superior performance. Evaluations on AIME24 and AIME25 are performed with a maximum sequence length of 32K.",
                "position": 1244
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x16.png",
                "caption": "",
                "position": 1253
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x17.png",
                "caption": "",
                "position": 1258
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x18.png",
                "caption": "",
                "position": 1263
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x19.png",
                "caption": "",
                "position": 1269
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x20.png",
                "caption": "",
                "position": 1274
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x21.png",
                "caption": "",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x22.png",
                "caption": "",
                "position": 1284
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x23.png",
                "caption": "Figure 10:Left: Ablation study comparing models trained with and without Math-Only Stage-1. For “w/o Stage-1”, the step-0 accuracy reflects the performance of the our SFT model on AIME25. In contrast, for \"w/ Stage-1\", the step-0 accuracy represents the final performance of Stage-1 RL initialized from the same SFT model. Right: Average response token length during Math-Only Stage-1 (8K) RL training.",
                "position": 1377
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x24.png",
                "caption": "",
                "position": 1386
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x25.png",
                "caption": "Figure 11:LiveCodeBench V5 accuracy over differentMath-OnlyRL stages.",
                "position": 1506
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x26.png",
                "caption": "Figure 12:Comparison of pass@K scores between AceReason-Nemotron-1.1-7B and the SFT-7B v7 model it is trained from. To compute pass@K, we generate 256 outputs per sample for AIME24 and AIME25, and 128 outputs for LiveCodeBench V5 and V6. We then randomly select K outputs, and evaluate pass@K. This procedure is repeated 100 times, and the final pass@K score is computed by averaging the results across all repetitions.",
                "position": 1521
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x27.png",
                "caption": "",
                "position": 1531
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x28.png",
                "caption": "Figure 13:Comparison of problem-level solving rates between AceReason-Nemotron1.1-7B and the SFT-7B v7 model it is trained from. For each problem, accuracy is averaged over 256 outputs for AIME24 and AIME25, and over 128 outputs for LiveCodeBench V5 and V6.",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x29.png",
                "caption": "",
                "position": 1560
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x30.png",
                "caption": "",
                "position": 1566
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x31.png",
                "caption": "",
                "position": 1571
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInstruction for evaluation",
        "images": []
    },
    {
        "header": "Appendix BRL training from different SFT models on AIME25",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13284/x32.png",
                "caption": "Figure 14:Math-onlyRL training starting from different SFT (distillation) models. The AIME25 accuracy at step-0 reflects the performance of the initial SFT checkpoints. The subsequent numbers in the figure show the final accuracy achieved at the end of each training stage: Math-Only Stage-1 (8K), Stage-2 (16K), Stage-3 (24K), and Stage-4 (32K).",
                "position": 2250
            }
        ]
    },
    {
        "header": "Appendix CPass@k Accuracy on Math-Only RL Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.13284/x33.png",
                "caption": "Figure 15:Pass@k results on AIME24, AIME25, LiveCodeBench V5, and V6, showcasing two SFT models and their subsequentMath-OnlyRL-trained versions. To compute pass@k, we generate 256 outputs per sample for AIME24 and AIME25, and 128 outputs for LiveCodeBench V5 and V6. We then randomly select k outputs, and evaluate pass@k. This procedure is repeated 100 times, and the final pass@k score is computed by averaging the results across all repetitions.",
                "position": 2261
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x34.png",
                "caption": "",
                "position": 2271
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x35.png",
                "caption": "Figure 16:Comparison of problem-level solving rates between the SFT model (v7) and the model afterMath-OnlyRL training. For each problem, accuracy is averaged over 256 outputs for AIME24 and AIME25, and over 128 outputs for LiveCodeBench V5 and V6.",
                "position": 2288
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x36.png",
                "caption": "",
                "position": 2297
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x37.png",
                "caption": "",
                "position": 2303
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x38.png",
                "caption": "",
                "position": 2308
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x39.png",
                "caption": "Figure 17:Problem-level solving rates comparison between SFT model (v5) and afterMath-OnlyRL training. For each problem, accuracy is averaged over 256 outputs for AIME24 and AIME25, and over 128 outputs for LiveCodeBench V5 and V6.",
                "position": 2314
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x40.png",
                "caption": "",
                "position": 2323
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x41.png",
                "caption": "",
                "position": 2329
            },
            {
                "img": "https://arxiv.org/html/2506.13284/x42.png",
                "caption": "",
                "position": 2334
            }
        ]
    },
    {
        "header": "Appendix DProblem-Level Solving Rates on Math-Only RL Models",
        "images": []
    }
]