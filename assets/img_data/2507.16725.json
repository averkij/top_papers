[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16725/x1.png",
                "caption": "Figure 1.Overview of the three primary misalignments addressed by our work.\nFrom left to right:\n(1) The divergence between narrow benchmark queries and broad, real-world user needs.\n(2) The challenge of collecting reliable and traceable information “nuggets” for fine-grained evaluation.\n(3) The tendency of existing frameworks to perform end-to-end evaluation while overlooking the agent’s intermediate process.",
                "position": 153
            }
        ]
    },
    {
        "header": "2.Sandbox for Agentic LLMs with Search",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16725/x2.png",
                "caption": "Figure 2.The architecture of the agentic LLM with search. The core model (ℳℳ\\mathcal{M}caligraphic_M) iteratively interacts with a webCorpusby invoking two primary tools:search, which retrieves a list of web pages for a given query, andfetch, which retrieves the content for a given URL. This cyclical process continues until the agent has gathered sufficient information to produce the final answer.",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2507.16725/x3.png",
                "caption": "Figure 3.Overview of the evaluation framework of RAVine. Left (§3.1): Attributable nugget collection via batched extraction at segment-level and semantically merging for refined, query-specific nuggets. Top-Right (§3.2): Block-level evaluation measuring task completeness and faithfulness of the final report. Bottom-Right (§4): Process evaluation of tool performance and efficiency.",
                "position": 299
            }
        ]
    },
    {
        "header": "3.Nugget-Centered Report Quality Evaluation",
        "images": []
    },
    {
        "header": "4.Process-Oriented Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16725/x4.png",
                "caption": "Figure 4.Correlation analysis between Task Completeness and Search Precision. Blue and orange points represent runs based on internal knowledge and search, respectively, and are used to fit the blue and orange regression lines. The red line represents the regression fit over all data points. In the top-left legend, r denotes the Pearson correlation coefficient and p indicates statistical significance. Overall trend shows weak positive correlation, while search-based runs show stronger positive correlation.",
                "position": 801
            },
            {
                "img": "https://arxiv.org/html/2507.16725/x5.png",
                "caption": "Figure 5.Statistics of the proportion of task completeness attributed to internal knowledge (𝐂𝐨𝐦𝐩𝐢𝐧subscript𝐂𝐨𝐦𝐩𝐢𝐧\\mathbf{Comp_{in}}bold_Comp start_POSTSUBSCRIPT bold_in end_POSTSUBSCRIPT) across models. The experiment is conducted using the dense index. “Q” denotes Qwen, and “L” denotes LLaMA. The numbers indicate the version and parameter scale. “T” refers to the thinking mode, while “N” refers to the mode without thinking.",
                "position": 804
            }
        ]
    },
    {
        "header": "5.Experiments",
        "images": []
    },
    {
        "header": "6.Related Work",
        "images": []
    },
    {
        "header": "7.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementations",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16725/x6.png",
                "caption": "Figure 6.Fitted distribution curves of the number of relevant segments, collected nuggets, and vital nuggets per query. The X-axis represents the corresponding count, and the Y-axis indicates the density for each count. The three vertical lines mark the 95th percentiles (P95) of the distributions for the three types of elements, respectively.",
                "position": 1621
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16725/x7.png",
                "caption": "Figure 7.Comparison of search gain scores across models under the two indexes. Model naming follows the rules used in Figure5.",
                "position": 2184
            },
            {
                "img": "https://arxiv.org/html/2507.16725/x8.png",
                "caption": "Figure 8.Comparison of fetch gain scores across models under the two indexes. Model naming follows the rules used in Figure5.",
                "position": 2187
            }
        ]
    },
    {
        "header": "Appendix CCase Study",
        "images": []
    }
]