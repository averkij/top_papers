[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x1.png",
                "caption": "",
                "position": 103
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x2.png",
                "caption": "Figure 2:Compared with the existing zero-shot customized generation framework. Our framework does not require any additional modules to extract or inject subject features. It only needs simple concatenation of the reference image and generated video, and VDM’s inherent force is used to generate custom video.",
                "position": 131
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x3.png",
                "caption": "Figure 3:Overall pipeline of VideoMaker. We directly input the reference image into VDM and use VDM’s modules for fine-grained feature extraction. We modified the computation of spatial self-attention to enable feature injection. Additionally, to distinguish between reference features and generated content, we designed the Guidance Information Recognition Loss to optimize the training strategy.",
                "position": 224
            }
        ]
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x4.png",
                "caption": "Figure 4:Qualitative comparison for customized object video generation. Compared with the blurry videos generated by VideoBooth[32], our generated videos have more details.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2412.19645/x5.png",
                "caption": "Figure 5:Qualitative comparison for customized human video generation. We compare our method with IP-Adapter[71], ID-Animator[23]and PhotoMaker[38]. We observe that our method achieves high-quality generation, promising editability, and subject fidelity.",
                "position": 536
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x6.png",
                "caption": "Figure 1:The overview of the celebrity dataset we use to test customized human video generation.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2412.19645/x7.png",
                "caption": "Figure 2:The overview of the dataset we use to test customized object video generation.",
                "position": 1914
            }
        ]
    },
    {
        "header": "Appendix BQuantitative Comparison Results on Non-Celebrity Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x8.png",
                "caption": "Figure 3:The overview of the non-celebrity dataset we used for testing customized human video generation.",
                "position": 2024
            }
        ]
    },
    {
        "header": "Appendix CUser Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/extracted/6097614/figures/user_study_human.png",
                "caption": "Figure 4:User Study for Customized Human Video Generation.",
                "position": 2130
            },
            {
                "img": "https://arxiv.org/html/2412.19645/extracted/6097614/figures/user_study_object.png",
                "caption": "Figure 5:User Study for Customized Object Video Generation.",
                "position": 2133
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix EMore Qualitative Comparison Results.",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.19645/x9.png",
                "caption": "Figure 6:More Qualitative comparison for customized human video generation on celebrity dataset.",
                "position": 2400
            },
            {
                "img": "https://arxiv.org/html/2412.19645/x10.png",
                "caption": "Figure 7:More Qualitative comparison for customized human video generation on non-celebrity dataset.",
                "position": 2403
            },
            {
                "img": "https://arxiv.org/html/2412.19645/x11.png",
                "caption": "Figure 8:More Qualitative comparison for customized human video generation on non-celebrity dataset.",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2412.19645/x12.png",
                "caption": "Figure 9:More Qualitative comparison for customized object video generation.",
                "position": 2409
            }
        ]
    },
    {
        "header": "Appendix FPotential Societal Impacts",
        "images": []
    }
]