[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x2.png",
                "caption": "Figure 2:Method overview.Given the motion-conditioned video generation model, ReVision operates in three stages. Stage 1: A coarse video is generated based on the provided conditions (e.g., target pose, marked inblue, indicating the rough position of theyellowpart in the last frame). Stage 2: 3D features from the generated coarse video are extracted and optimized using the proposed PPPM.\nStage 3: The optimized 3D sequences are used to regenerate the video with enhanced motion consistency. Best viewed when zoomed in.",
                "position": 169
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x3.png",
                "caption": "Figure 3:Motion-conditioned video generation.We extend SVD for motion-conditioned video generation by introducing two additional conditioning channels to the original condition: (1) part segmentation mask derived from the 3D motion sequence, and (2) its corresponding confidence map.",
                "position": 245
            }
        ]
    },
    {
        "header": "5Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x4.png",
                "caption": "Figure 4:Qualitative results.ReVision enables the generation of high-quality videos with complex motions and interactions, such as running with dogs, picking up a ball, and hitting a tennis ball.\nIt allows precise motion control over small body parts, such as arms and hands.\nZoom in for better detail. Please check the videos on the project page.",
                "position": 322
            }
        ]
    },
    {
        "header": "6Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x5.png",
                "caption": "Figure 6:The parametric 3D mesh serves as an effective object-level prior,ensuring complete human body structures in the coarse video generated during the first stage. In the left two images, the human keypoint model fails to detect the missing right hand, which is accurately “recovered” by the parametric human mesh model. In the right two images, the human mesh model provides a more accurate prior for both blurred hands.",
                "position": 561
            },
            {
                "img": "https://arxiv.org/html/2504.21855/x6.png",
                "caption": "Figure 7:Video generated in stage 1 (S1) and stage 3 (S3).Although fine-tuned on a dataset containing large motions, SVD still struggles to generate complex motion sequences.\nHowever, by incorporating the optimized 3D dense motion sequence from Stage 2, we significantly enhance both motion and visual quality and generate realistic videos with large motions in stage 3.",
                "position": 622
            }
        ]
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "9Architectural details for PPPM",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.21855/x7.png",
                "caption": "Figure 8:Architecture of the Parameterized Physical Prior Model",
                "position": 1736
            }
        ]
    },
    {
        "header": "10Improvement of Multi-stage Generation",
        "images": []
    }
]