[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x1.png",
                "caption": "",
                "position": 110
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x2.png",
                "caption": "(a)",
                "position": 176
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x2.png",
                "caption": "(a)",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x3.png",
                "caption": "(b)",
                "position": 184
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x4.png",
                "caption": "(c)",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x5.png",
                "caption": "Figure 2:Left:ShadowKVenhances long-context LLM inference throughput by offloading the value cache to the CPU while maintaining a low-rank key cache, landmarks, and outliers on the GPU. During decoding, it employs landmarks for efficient sparse attention, reducing computation and data movement.Right:ShadowKVeffectively utilizes a limited KV budget to achieve high accuracy, theoretically reaching over 7 TB/s equivalent bandwidth on an A100, and empirically boosts generation throughput by 3.04×\\times×for Llama-3.1-8B with on a batch of 122K contexts.",
                "position": 206
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Observations",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x6.png",
                "caption": "(a)",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x6.png",
                "caption": "(a)",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x7.png",
                "caption": "(b)",
                "position": 252
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x8.png",
                "caption": "(c)",
                "position": 258
            }
        ]
    },
    {
        "header": "4ShadowKV",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x9.png",
                "caption": "Algorithm 1ShadowKVPre-filling",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x10.png",
                "caption": "Algorithm 2ShadowKVDecoding",
                "position": 416
            }
        ]
    },
    {
        "header": "5Empirical Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x11.png",
                "caption": "Figure 6:Needle In A Haystack.",
                "position": 1278
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x12.png",
                "caption": "Figure 7:Multi-turn NIAH.",
                "position": 1334
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x13.png",
                "caption": "Figure 8:Comparison results between the models with full cache, ourShadowKV, and Quest.",
                "position": 1509
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x14.png",
                "caption": "(a)",
                "position": 1512
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x14.png",
                "caption": "(a)",
                "position": 1515
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x15.png",
                "caption": "(b)",
                "position": 1520
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x16.png",
                "caption": "(c)",
                "position": 1526
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.21465/x17.png",
                "caption": "(a)GLM-4-9B-1M",
                "position": 2603
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x17.png",
                "caption": "(a)GLM-4-9B-1M",
                "position": 2606
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x18.png",
                "caption": "(b)GLM-4-9B-1M w/ShadowKV",
                "position": 2612
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x19.png",
                "caption": "(c)Llama-3.1-8B-Instruct",
                "position": 2618
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x20.png",
                "caption": "(d)Llama-3.1-8B-Instruct w/ShadowKV",
                "position": 2624
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x21.png",
                "caption": "(e)Yi-9B-200K",
                "position": 2630
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x22.png",
                "caption": "(f)Yi-9B-200K w/ShadowKV",
                "position": 2636
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x23.png",
                "caption": "(g)Phi-3-Mini-128K",
                "position": 2642
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x24.png",
                "caption": "(h)Phi-3-Mini-128K w/ShadowKV",
                "position": 2648
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x25.png",
                "caption": "(i)Qwen2-7B-128K",
                "position": 2654
            },
            {
                "img": "https://arxiv.org/html/2410.21465/x26.png",
                "caption": "(j)Qwen2-7B-128K w/ShadowKV",
                "position": 2660
            }
        ]
    },
    {
        "header": "Appendix AExperiment Details",
        "images": []
    }
]