[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17765/x1.png",
                "caption": "Figure 1:Qwen3-Omni is a unified end-to-end model capable of processing multiple modalities, such as text, audio, image and video, and generating real-time text or speech response. Based on these features, Qwen3-Omni supports a wide range of tasks, including but not limited to voice dialogue, video dialogue, and video reasoning.",
                "position": 107
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Architecture",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.17765/figures/overview.png",
                "caption": "Figure 2:The overview of Qwen3-Omni. Qwen3-Omni adopts the Thinker-Talker architecture. Thinker is tasked with text generation while Talker focuses on generating streaming speech tokens by receives high-level representations directly from Thinker. To achieve ultra–low-latency streaming, Talker autoregressively predicts a multi-codebook sequence. At each decoding step, an MTP module outputs the residual codebooks for the current frame, after which the Code2Wav renderer incrementally synthesizes the corresponding waveform, enabling frame-by-frame streaming generation.",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2509.17765/figures/aut.png",
                "caption": "Figure 3:The overview of AuT. AuT is an attention-encoder-decoder based auto-regressive model, which is trained from scratch on 20 million hours of supervised audio. Qwen3-Omni employs the AuT encoder as the audio encoder to obtain general purpose audio representations at a token rate of 12.5Hz.",
                "position": 187
            }
        ]
    },
    {
        "header": "3Pretraining",
        "images": []
    },
    {
        "header": "4Post-training",
        "images": []
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6Evaluating Non‑Degradation Across Modalities",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Authors",
        "images": []
    },
    {
        "header": "9Appendix",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]