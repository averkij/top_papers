[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21574/x1.png",
                "caption": "Figure 1:We present X-Streamer, a framework that constructs an infinitely streamable digital human from a single portrait, capable of generating intelligent, real-time, multi-turn responses across text, speech, and video. X-Streamer delivers phoneme-level lip synchronization while maintaining long-range conversational memory and visual consistency throughout extended audiovisual interactions.",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21574/x2.png",
                "caption": "Figure 2:Overview of¬†X-Streamer. Given a single portraitIsI_{s}, X-Streamer¬†enables real-time audiovisual interaction through a dual-track autoregressive framework. A frozen Thinker transformer, instantiated from a pretrained language‚Äìspeech model, interprets streaming user text and audio queries, while an Actor generates synchronized interleaving text, speech, and video streams from the Thinker‚Äôs hidden states. Video is produced with chunk-wise autoregressive diffusion stabilized by diffusion forcing, and multimodal alignment is enforced via cross-attention. Deployed on two A100 GPUs, X-Streamer¬†streams at 25 fps, enabling coherent, long-horizon multimodal interactions.",
                "position": 130
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21574/x3.png",
                "caption": "Figure 3:Autoregressive Video Diffusion.The video transformer generates video chunk by chunk, applying bidirectional spatial self-attention within each chunk and cross-attention to the Thinker‚Äôs text‚Äìaudio hidden states, while enforcing causal temporal attention across chunks. Global attention to the reference image is maintained throughout. To stabilize long-horizon generation, we adopt chunk-wise diffusion forcing by assigning independent noise levels across chunks.",
                "position": 263
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21574/x4.png",
                "caption": "Figure 4:Qualitative comparisons on audio-synced (top) and long-range (bottom) video generations.",
                "position": 290
            },
            {
                "img": "https://arxiv.org/html/2509.21574/x5.png",
                "caption": "Figure 5:Visual Ablation.Diffusion forcing and global identity referencing stabilize long-horizon video generation, while applying spatially bidirectional attention within each video chunk (as opposed to fully causal token-wise attention) reduces flickering and preserves structural integrity.",
                "position": 513
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21574/x6.png",
                "caption": "Figure 6:Schedulerùí¶chunk\\mathcal{K}^{\\text{chunk}}of chunk-wise pyramid denoising.",
                "position": 1918
            },
            {
                "img": "https://arxiv.org/html/2509.21574/x7.png",
                "caption": "Figure 7:X-Streamer with visual perception. When the user issues a query (e.g., ‚Äúwhat number is this?‚Äù), a VLM analyzes the current webcam frame and produces a concise textual description, which is passed to¬†X-Streamer¬†to guide subsequent multimodal response generation.",
                "position": 1933
            },
            {
                "img": "https://arxiv.org/html/2509.21574/x8.png",
                "caption": "Figure 8:More results of¬†X-Streamer.",
                "position": 1940
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]