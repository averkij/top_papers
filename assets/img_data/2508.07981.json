[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x1.png",
                "caption": "Figure 1:Capabilities for Diverse Customized Visual Effects.Omni-Effectssupports both (a) single-VFX and (b) multi-VFX generation through pure prompt-guided generation. Integrated with theSpatial-Aware Prompt,Omni-Effectsenables (c) precise spatial VFX control and (d) intricate object-based visual effects with targeted environmental transformations.",
                "position": 162
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x2.png",
                "caption": "Figure 2:Defects in standard video generation models.(a) VFX disappearance, (b) quality degradation, (c) confusion between VFX elements, and (d) spatial uncontrollability.",
                "position": 171
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x3.png",
                "caption": "Figure 3:Flowchart of proposedOmni-Effects.Given a reference image and composite conditions of arbitrary length,Omni-Effectsfirst encodes each input into corresponding tokens. These tokens are concatenated and processed sequentially through downstream DiT blocks. These blocks incorporate two key technologies: (a)LoRA-MoE, a MoE plugin replacing standard FFN linear layers to enable collaborative expert task-solving and (b)SAP, which fuses effect descriptors with spatial trigger information during the attention stage while mitigating cross-condition information leakage via an IIF mechanism. Note that, in the IIF, dashed lines represent blocked information flow, while solid lines indicate active information transmission.",
                "position": 228
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x4.png",
                "caption": "Figure 4:FVD scores for diverse VFX trained with a shared LoRA.VFX performance exhibits an initial improvement followed by progressive degradation with increasing numbers of co-trained effects. This indicates inherent effect clustering: synergistic groups (e.g., Melt-like effects) improve co-training performance, while incompatible combinations (e.g., Deflate + Squish) suffer from mode collapse and underperform relative to compatible sets. Note that,lower FVD values indicate superior performance, with optimal VFX results uniformly achieved when the number of co-trained VFX equals 4.",
                "position": 294
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x5.png",
                "caption": "Figure 5:Visualization of controllable VFX performance and attention maps.(a) Position description lacks spatial control; (b) ControlNet faces inter-condition interference, leading to VFX leakage and artifacts; (c) ProposedSAP+IIFachieves precise positional controllability while preventing mutual interference between multi-VFX.",
                "position": 326
            }
        ]
    },
    {
        "header": "4Data and Training",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x6.png",
                "caption": "Figure 6:Qualitative Comparison of Multi-VFX Generation.The desired outcome requires the left chair to melt while the right levitates simultaneously.",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x6.png",
                "caption": "Figure 6:Qualitative Comparison of Multi-VFX Generation.The desired outcome requires the left chair to melt while the right levitates simultaneously.",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x7.png",
                "caption": "Figure 7:Effect of Different Attention Masks in SAP.Attention Masks are progressively removed while information flow constraints are relaxed from top to bottom.",
                "position": 784
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x8.png",
                "caption": "Figure 8:Scalable VFX augmentation.Omni-Effectssupports inference-time extension to diverse VFX composition.",
                "position": 790
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMethod",
        "images": []
    },
    {
        "header": "Appendix BDataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x9.png",
                "caption": "Figure 9:Synthetic VFX Video Generation via Keyframe Editing and WAN 2.1 Interpolation.",
                "position": 1703
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x10.png",
                "caption": "Figure 10:Some examples of our dataset curation pipeline.",
                "position": 1706
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x11.png",
                "caption": "Figure 11:Some examples of ourOmni-VFXdataset.",
                "position": 1709
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x12.png",
                "caption": "Figure 12:Distribution of ourOmni-VFXdataset.",
                "position": 1716
            }
        ]
    },
    {
        "header": "Appendix CImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x13.png",
                "caption": "Figure 13:Visualization of Data augmentation.",
                "position": 1768
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x14.png",
                "caption": "Figure 14:Flowchart of the metric design for controllable visual effect.",
                "position": 1802
            }
        ]
    },
    {
        "header": "Appendix DMetrics",
        "images": []
    },
    {
        "header": "Appendix EExperiments Results Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.07981/x15.png",
                "caption": "Figure 15:Qualitative Comparison of Single-VFX Generation.The desired outcome requires the right cup to explode\nwhile the left stays static.",
                "position": 1856
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x16.png",
                "caption": "Figure 16:Qualitative Comparison of Different LoRA Settings.",
                "position": 1863
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x17.png",
                "caption": "Figure 17:User Study for Multi-VFX Generation.Omni-Effectsexceeds other baseline.",
                "position": 1891
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x17.png",
                "caption": "Figure 17:User Study for Multi-VFX Generation.Omni-Effectsexceeds other baseline.",
                "position": 1894
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x18.png",
                "caption": "",
                "position": 2010
            },
            {
                "img": "https://arxiv.org/html/2508.07981/x19.png",
                "caption": "",
                "position": 2018
            }
        ]
    },
    {
        "header": "Appendix FMore Ablation Study",
        "images": []
    }
]