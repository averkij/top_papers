[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x1.png",
                "caption": "Figure 1:Performance on ViF-Bench. Our method outperforms both binary and existing MLLM-based detectors.",
                "position": 103
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x2.png",
                "caption": "Figure 2:Skyraleverages human-perceivable artifacts in AI-generated videos as grounded evidence for detection and explanation. Compared to off-the-shelf MLLMs and previous MLLM-based detectors, Skyra demonstrates superior artifact perception and detection capabilities.",
                "position": 108
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x3.png",
                "caption": "Figure 3:Overview of the ViF-CoT-4K dataset.(a)The hierarchical taxonomy of AI-generated video artifacts.(b)Visual examples of artifacts under our taxonomy.(c)Construction pipeline of ViF-CoT-4K dataset, including authentic data collection and AI-generated video collection, manual annotation, and the step-by-step chain-of-thought explanation data construction process.",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x4.png",
                "caption": "Figure 4:Statistics of the ViF-CoT-4K and ViF-Bench.(a)Distribution of samples generated by different generators in ViF-CoT-4K (train) and ViF-Benchmark (test) set.(b)Distribution of artifacts types in ViF-CoT-4K. Detailed proportion is provided in the Appendix.(c)Word cloud of the CoT annotations in ViF-CoT-4K.",
                "position": 147
            }
        ]
    },
    {
        "header": "3ViF Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x5.png",
                "caption": "Figure 5:Overview of Skyra. We leverage a two-stage training pipeline to improve Skyra’s artifacts perception and detection capabilities:(a)cold-start initialization with balanced fake and real explanation response templates to endow the base model with basic AI-generated artifacts perception capability.(b)reinforcement learning with adapted rewards to encourage the model’s self-driven visual probe process.",
                "position": 187
            }
        ]
    },
    {
        "header": "4Skyra",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x6.png",
                "caption": "Figure 6:Case Study. More examples are provided in the appendix.",
                "position": 2310
            }
        ]
    },
    {
        "header": "6Conclusion and Discussions",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "AThe ViF Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/images/supplementary/annotation_platform.png",
                "caption": "Figure 7:Annotation platform UI.",
                "position": 2641
            }
        ]
    },
    {
        "header": "BAnalysis of Detection Capabilities",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/images/supplementary/tsne_embeddings.png",
                "caption": "Figure 8:The T-SNE result of Demamba.",
                "position": 2675
            },
            {
                "img": "https://arxiv.org/html/2512.15693/images/supplementary/CAM_demamba.png",
                "caption": "Figure 9:Visualization of Class Activation Maps (CAMs) produced by DeMamba on real video samples.",
                "position": 2680
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x7.png",
                "caption": "Figure 10:Response examples of off-the-shelf MLLMs.",
                "position": 2692
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x8.png",
                "caption": "Figure 11:Response examples of existing MLLM-based detector, BusterX++[wen2025busterx++].",
                "position": 2706
            }
        ]
    },
    {
        "header": "CAdditional Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x9.png",
                "caption": "Figure 12:System prompt and user prompt design.",
                "position": 2750
            }
        ]
    },
    {
        "header": "DBroader Impacts",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.15693/x10.png",
                "caption": "Figure 13:Chain-of-Thought Annotation Prompt.",
                "position": 2800
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x11.png",
                "caption": "Figure 14:ViF-Bench Video Sample Examples-I",
                "position": 3141
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x12.png",
                "caption": "Figure 15:ViF-Bench Video Sample Examples-II",
                "position": 3147
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x13.png",
                "caption": "Figure 16:Skyra’s Response Example on Real Videos, I",
                "position": 3153
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x14.png",
                "caption": "Figure 17:Skyra’s Response Example on Real Videos, II",
                "position": 3158
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x15.png",
                "caption": "Figure 18:Skyra’s Response Example on Fake Videos, Texture Anomaly-Structure Anomaly",
                "position": 3163
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x16.png",
                "caption": "Figure 19:Skyra’s Response Example on Fake Videos, Color & Lighting Anomaly-Color Over-Saturation",
                "position": 3168
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x17.png",
                "caption": "Figure 20:Skyra’s Response Example on Fake Videos, Move Forgery-Camera Motion Inconsistency",
                "position": 3173
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x18.png",
                "caption": "Figure 21:Skyra’s Response Example on Fake Videos, Object Inconsistency-Shape Distortion",
                "position": 3178
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x19.png",
                "caption": "Figure 22:Skyra’s Response Example on Fake Videos, Interaction Inconsistency-Abnormal Rigid-Body Crossing",
                "position": 3183
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x20.png",
                "caption": "Figure 23:Skyra’s Response Example on Fake Videos, Unnatural Movement-Unnatural Human Movement",
                "position": 3188
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x21.png",
                "caption": "Figure 24:Skyra’s Response Example on Fake Videos, Violation of Causality Law-Violation of Physical Law",
                "position": 3193
            },
            {
                "img": "https://arxiv.org/html/2512.15693/x22.png",
                "caption": "Figure 25:Skyra’s Response Example on Fake Videos, Violation of Commonsense-Text Distortion",
                "position": 3198
            }
        ]
    },
    {
        "header": "ELicense",
        "images": []
    }
]