[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07090/x1.png",
                "caption": "Figure 1:Illustration of embedding inversion attack and different defense strategies. (a) Sensitive information can be easily identified from non-protected text embeddings. (b) Adding spherical noise mitigates privacy leakage but harms textual semantics. (c) Our approach applies elliptical noise guided by a user-defined privacy concept, selectively adding stronger perturbations to privacy-sensitive dimensions while preserving non-sensitive semantics. A real-world case study is presented in AppendixJ.",
                "position": 137
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3SPARSE Framework",
        "images": []
    },
    {
        "header": "4Experimental Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07090/x2.png",
                "caption": "Figure 2:Visualization of the learned neuron mask by SPARSE for individual tokens, where larger values represent higher privacy sensitivity.",
                "position": 1096
            },
            {
                "img": "https://arxiv.org/html/2602.07090/x2.png",
                "caption": "Figure 2:Visualization of the learned neuron mask by SPARSE for individual tokens, where larger values represent higher privacy sensitivity.",
                "position": 1098
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEmpirical Validation of Privacy-Sensitive Dimensions",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07090/x3.png",
                "caption": "Figure 3:Sensitivity distribution comparison between the top and bottom 10% privacy neurons. The Wilcoxon Signed Rank Test indicates a highly significant difference (p-value=1.30×10−21=1.30\\times 10^{-21}).",
                "position": 1736
            }
        ]
    },
    {
        "header": "Appendix BMissing Proof in Section3.2",
        "images": []
    },
    {
        "header": "Appendix CAlgorithm for Mahalanobis Noise Sampling",
        "images": []
    },
    {
        "header": "Appendix DDataset Statistics and Evaluation Metrics",
        "images": []
    },
    {
        "header": "Appendix ESensitive Token Extraction",
        "images": []
    },
    {
        "header": "Appendix FAdditional Experimental Results",
        "images": []
    },
    {
        "header": "Appendix GComputational Overhead",
        "images": []
    },
    {
        "header": "Appendix HImplementation Details of SPARSE",
        "images": []
    },
    {
        "header": "Appendix IImplementation details of Attack Models",
        "images": []
    },
    {
        "header": "Appendix JCase Study on MIMIC-III dataset",
        "images": []
    },
    {
        "header": "Appendix KLimitations",
        "images": []
    },
    {
        "header": "Appendix LUse of Large Language Models (LLMs)",
        "images": []
    }
]