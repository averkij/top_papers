[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Approach",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07818/x1.png",
                "caption": "Figure 1:We visualize the reward curves of Stable Diffusion, FLUX.1-dev, and HunyuanVideo-T2I on HPS score from left to right. After applying CLIP score, the HPS score decreases, but the generated images become more natural (Figure9in Appendix), and the CLIP score improves (Tables2and3).",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x2.png",
                "caption": "Figure 2:We visualize the training curves of motion quality and visual aesthetics quality on HunyuanVideo, motion quality on SkyReels-I2V.",
                "position": 714
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x3.png",
                "caption": "Figure 3:(a) We visualize the training curves of binary rewards. (b) We show the human evaluation results using FLUX (T2I), HunyuanVideo (T2V), and SkyReel (I2V), respectively.",
                "position": 735
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x4.png",
                "caption": "Figure 4:This figure shows the rewards on Best-of-N inference scaling, the ablation on timestep selection, and the ablation on noise level, respectively. While Best-of-N inference scaling consistently improves performance with more samples, it reduces sampling efficiency. Therefore, we leave Best-of-N as an optional extension.",
                "position": 759
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Experimental Settings",
        "images": []
    },
    {
        "header": "7More Analysis",
        "images": []
    },
    {
        "header": "8Classifier-Free Guidance (CFG) Training",
        "images": []
    },
    {
        "header": "9Advantages over DDPO and DPOK",
        "images": []
    },
    {
        "header": "10Inserting DDPO into Rectified Flow SDEs",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.07818/x5.png",
                "caption": "Figure 5:We visualize the results of DDPO and Ours. DDPO always diverges when applied to rectified flow SDEs.",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x6.png",
                "caption": "Figure 6:We visualize the results by selecting FLUX optimized with the HPS score at iterations 0, 60, 120, 180, 240, and 300. The optimized outputs tend to exhibit brighter tones and richer details. However, incorporating CLIP score regularization is crucial, as demonstrated in Figures11,12, and13.",
                "position": 1890
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x7.png",
                "caption": "Figure 7:Visualization of the diversity of the model before and after RLHF. Different seed tends to generate similar images after RLHF.",
                "position": 1893
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x8.png",
                "caption": "Figure 8:Visualization of the results of reward hacking (with different initialization noise) and without reward hacking (with the same initialization noise) on HunyuanVideo. Prompt: A splash of water in a clear glass, with sparkling, clear radiant reflections, sunlight, sparkle",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x9.png",
                "caption": "Figure 9:This figure demonstrates the impact of the CLIP score. The prompt is \"A photo of cup\". We find that the model trained solely with HPS-v2.1 rewards tends to produce unnatural (\"oily\") outputs, while incorporating CLIP scores helps maintain more natural image characteristics.",
                "position": 1899
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x10.png",
                "caption": "Figure 10:Overall visualization.We visualize the results before and after RLHF of FLUX and HunyuanVideo.",
                "position": 1902
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x11.png",
                "caption": "Figure 11:We present the original outputs of FLUX, alongside optimizations driven solely by the HPS score and those enhanced by both the HPS and CLIP scores.",
                "position": 1905
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x12.png",
                "caption": "Figure 12:We present the original outputs of FLUX, alongside optimizations driven solely by the HPS score and those enhanced by both the HPS and CLIP scores.",
                "position": 1908
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x13.png",
                "caption": "Figure 13:We present the original outputs of FLUX, alongside optimizations driven solely by the HPS score and those enhanced by both the HPS and CLIP scores.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x14.png",
                "caption": "Figure 14:We present the original outputs of HunyuanVideo-T2I, alongside optimizations driven solely by the HPS score and those enhanced by both the HPS and CLIP scores.",
                "position": 1914
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x15.png",
                "caption": "Figure 15:We present the original outputs of Stable Diffusion, alongside optimizations driven solely by the HPS score and those enhanced by both the HPS and CLIP scores.",
                "position": 1917
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x16.png",
                "caption": "Figure 16:Visualization results of HunyuanVideo.",
                "position": 1920
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x17.png",
                "caption": "Figure 17:Visualization results of HunyuanVideo.",
                "position": 1923
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x18.png",
                "caption": "Figure 18:Visualization results of HunyuanVideo.",
                "position": 1926
            },
            {
                "img": "https://arxiv.org/html/2505.07818/x19.png",
                "caption": "Figure 19:Visualization results of SkyReels-I2V.",
                "position": 1929
            }
        ]
    },
    {
        "header": "11More Visualization Results",
        "images": []
    }
]