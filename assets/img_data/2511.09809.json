[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09809/x1.png",
                "caption": "Figure 1:Overview of our proposed STS framework. Given text and image inputs, encoders‚Ñ∞t‚Äã(‚ãÖ)\\mathcal{E}_{t}(\\cdot)and‚Ñ∞v‚Äã(‚ãÖ)\\mathcal{E}_{v}(\\cdot)extract text embeddings/prototypes, and visual embeddings. A probability distribution‚ÑôC‚ÄãL‚ÄãI‚ÄãP‚Äã(y=yc|Xùöùùöéùöúùöù)\\mathbb{P}_{CLIP}(y=y_{c}|X_{\\mathtt{test}})is computed based on these embeddings. Then we perform a refinement step of test-time adaptation, where we tune the learnable low-dimensional coefficients to generate a small steering to the text prototypes to close the gap between the source and target distributions. Marginal entropy of the CLIP similarities of the shifted embeddings and the class prototypes is minimized.",
                "position": 259
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09809/rank.png",
                "caption": "Figure 2:Most spectral energy in CLIP text prototypes is captured by a small subset of singular values, highlighting strong low-rank structure across datasets.",
                "position": 416
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09809/x2.png",
                "caption": "Table 1:Comparison of top-1 accuracy (%) across ImageNet and its OOD variants. The best results in each section are highlighted inbold.Underlineindicates second-best.",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2511.09809/x2.png",
                "caption": "Table 2:Performance comparisons on fine-grained classification. The best results in each section are highlighted inbold.Underlineindicates second-best.",
                "position": 620
            }
        ]
    },
    {
        "header": "5Analysis and ablation",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09809/x2.png",
                "caption": "(a)CIFAR10-C comparison.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2511.09809/x2.png",
                "caption": "(a)CIFAR10-C comparison.",
                "position": 951
            },
            {
                "img": "https://arxiv.org/html/2511.09809/x3.png",
                "caption": "(b)Accuracy vs. viewsNN.",
                "position": 956
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABroader Impact",
        "images": []
    },
    {
        "header": "Appendix BTechnical Appendices",
        "images": []
    },
    {
        "header": "Appendix CSingular Vector Selection for Test-Time Latent Steering",
        "images": []
    },
    {
        "header": "Appendix DAdditional Implementation Details",
        "images": []
    },
    {
        "header": "Appendix ELicense Information",
        "images": []
    }
]