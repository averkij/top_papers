[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17855/x1.png",
                "caption": "Figure 1:Example of claim and evidence documents, alongside span interactions for uncertainty and generated natural language explanations.",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2505.17855/x2.png",
                "caption": "Figure 2:Explanations produced by earlier systems, e-FEVER(Stammbach and Ash,2020), Explain-MT(Atanasova et al.,2020), and JustiLM(Zeng and Gao,2024), compared with those from our CLUE framework. CLUE is the only approach that explicitly traces model uncertainty to the conflicts and agreements between the claim and multiple evidence passages.",
                "position": 206
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Automatic Evaluation",
        "images": []
    },
    {
        "header": "6Human Evaluation",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17855/extracted/6470555/figures/LOGO_ERC-FLAG_EU.jpg",
                "caption": "",
                "position": 1013
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABackbone model performance on public benchmarks",
        "images": []
    },
    {
        "header": "Appendix BMethod: Selecting attention heads to steer",
        "images": []
    },
    {
        "header": "Appendix CPrompt Example for Assigning Relation Labels to Captured Span Interactions",
        "images": []
    },
    {
        "header": "Appendix DPerturbation details for faithfulness measurement",
        "images": []
    },
    {
        "header": "Appendix EDifferences Between Entropy-CCT and CCT",
        "images": []
    },
    {
        "header": "Appendix FPrompt template forPromptBaseline,CLUE-SpanandCLUE-Span+Steeringon Healthver and Druid dataset",
        "images": []
    },
    {
        "header": "Appendix GExtended Statistical Analysis of Faithfulness Scores",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17855/extracted/6470555/figures/humaneval_setup.png",
                "caption": "Figure 6:Example of human evaluation set-up. Explanation A was generated using PromptBaseline, Explanation B by CLUE-Span, and Explanation C by CLUE-Span+Steering",
                "position": 2838
            }
        ]
    },
    {
        "header": "Appendix HHuman Evaluation Details",
        "images": []
    }
]