[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/abstract.png",
                "caption": "Figure 1:The core path of large multimodal reasoning models",
                "position": 209
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/intro.png",
                "caption": "Figure 2:The roadmap of large multimodal reasoning models. The models highlighted in the box are representative models transitioning from Stage 3 towards Stage 4, as indicated by the directional arrow.",
                "position": 297
            }
        ]
    },
    {
        "header": "2Evolving Paradigms of Multimodal Reasoning and Discussion",
        "images": []
    },
    {
        "header": "3Roadmap of Multimodal Reasoning Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.04921/x1.png",
                "caption": "Figure 4:Taxonomy and representative methods of structural reasoning in multimodal chain-of-thought.",
                "position": 1135
            },
            {
                "img": "https://arxiv.org/html/2505.04921/x2.png",
                "caption": "Figure 5:Timeline (top) and core components (bottom) of recent multimodal O1-like and R1-like models. The top part illustrates the chronological emergence of representative models. The bottom part summarizes key components including structured reasoning paradigms, reinforcement learning algorithms (e.g., DPO and GRPO), and the design of rule-based reward models.",
                "position": 2687
            }
        ]
    },
    {
        "header": "4Towards Native Multimodal Reasoning Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/stage4_case1.png",
                "caption": "Figure 6:Case study of OpenAI o3â€™s long multimodal chain-of-thought, reaching the correct answer after 8 minutes and 13 seconds of reasoning. The question is from Chinese Civil Service Examination.",
                "position": 4857
            },
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/stage4_o3_examples2.png",
                "caption": "Figure 7:Case study of OpenAI o3: Find locations, solve a puzzle and create multimedia contents.",
                "position": 4860
            },
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/stage4_o3_examples1.png",
                "caption": "Figure 8:Case study of OpenAI o3: Visual problem solving and file processing.",
                "position": 4863
            },
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/nlmrms.png",
                "caption": "Figure 9:Overview of next-generation native large multimodal reasoning model. The envisioned system aims to achieve comprehensive perception across diverse real-world data modalities, enabling precise omnimodal understanding and in-depth generative reasoning. This foundational model will lead to more advanced forms of intelligent behavior, learning from world experience and realizing lifelong learning and self-improvement.",
                "position": 5410
            }
        ]
    },
    {
        "header": "5Dataset and Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.04921/extracted/6403685/figures/dataset.png",
                "caption": "Figure 10:The outlines of datasets and benchmarks. We reorganize the multimodal datasets and benchmarks into four main categories: Understanding, Generation, Reasoning, and Planning.",
                "position": 5491
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]