[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01618/x1.png",
                "caption": "(a)Llama-3.2-1B-Instruct",
                "position": 150
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x1.png",
                "caption": "(a)Llama-3.2-1B-Instruct",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x2.png",
                "caption": "(b)Llama-3.1-8B-Instruct",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x3.png",
                "caption": "(c)Qwen2.5-Math-1.5B-Instruct",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x4.png",
                "caption": "(d)Qwen2.5-Math-7B-Instruct",
                "position": 171
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Method",
        "images": []
    },
    {
        "header": "5Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01618/x5.png",
                "caption": "Figure 4:Results of ablation on 100 question subset comparing the performance of PF across various PRMs. We find that the Qwen PRM scales the most effectively across generations.",
                "position": 852
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x6.png",
                "caption": "Figure 5:Effect of different aggregation strategies for the process reward model Qwen2.5-Math-PRM-7B, evaluated on a 100-question subset of the MATH500 dataset. The plot compares the commonly used aggregation strategies‚ÄîMin, Last, and Product‚Äîagainst our proposed Model Aggregation method.",
                "position": 865
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x7.png",
                "caption": "Figure 6:Results of using Llama 3.2 1B as our policy model across temperatures (0.4, 0.6, 0.8, 1.0, 1.2, and 1.4) and particle numbers (1, 2, 4, 8, 16, and 32).",
                "position": 879
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x8.png",
                "caption": "Figure 7:Comparison of PF and Particle Gibbs with different numbers of iterations, evaluated on a 100-question subset of the MATH-500 dataset using Llama-3.2-1B-Instruct as the policy model.",
                "position": 898
            },
            {
                "img": "https://arxiv.org/html/2502.01618/x9.png",
                "caption": "Figure 8:Comparison of PF and PT with different particle group sizes, evaluated on a 100-question subset of the MATH500 dataset using Llama-3.2-1B-Instruct as the policy model.",
                "position": 911
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01618/x10.png",
                "caption": "Figure 9:Particle filtering for inference scaling in details. We initializexùë•xitalic_xparticles with the ‚Äùfirst step‚Äù of an answer to a question. At every step, each particlepisubscriptùëùùëñp_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTis given a scoresitsuperscriptsubscriptùë†ùëñùë°s_{i}^{t}italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPTby the PRM, which is then used as a weightwitsuperscriptsubscriptùë§ùëñùë°w_{i}^{t}italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPTto determine how likely that particle is to be resampled (evolved via a solid line) at the next step. A particle is deemed ‚Äùactive‚Äù (green, in this diagram) until it generates an‚ü®EOS‚ü©token, after which it is still able to be resampled (evolved via a dashed line) but is not evolved further. This process continues until all particles have completed their answers and become inactive (filled yellow).",
                "position": 1445
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]