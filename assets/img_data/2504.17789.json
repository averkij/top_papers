[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x1.png",
                "caption": "Figure 1:High-resolution images generated by our 2.7B AR model with Token-Shuffle (shuffle window size = 2).",
                "position": 196
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x2.png",
                "caption": "Figure 2:Token-Shuffle Pipeline:a plug-and-play operation pair for reducing visual token number in MLLMs, comprising a token-shuffle operation to merge spatially local visual tokens for Transformer input and a token-unshuffle operation to disentangle inferred visual tokens.",
                "position": 217
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Token-Shuffle",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x3.png",
                "caption": "Figure 3:Illustration of visual vocabulary dimensional redundancy.Left:Two MLPs reduce visual token rank by a factor ofrùëüritalic_r.Right:Pre-training loss (log-scaled perplexity) for differentrùëüritalic_rvalues, showing substantial dimension reduction with minimal performance impact.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x4.png",
                "caption": "",
                "position": 289
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x5.png",
                "caption": "Figure 4:Token-Shuffle can enhance efficiency quadratically. For instance, with a shuffle window sizes=2ùë†2s=2italic_s = 2, we achieve approximately a4√ó4\\times4 √óreduction in both training FLOPs and token number. Considering the use of KV-cache during inference, inference time scales roughly linearly with the token number.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x6.png",
                "caption": "Figure 5:Comparison of different CFG schedulerswith a monotonic increase in CFG scale from 1 to 7.5.Right:CFG-scheduler improves both visual aesthetics and text alignment, compared to the baseline of a consistent CFG value of 7.5 across all visual tokens.",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x7.png",
                "caption": "Figure 6:Human evaluationcomparing Token-Shuffle with LlamaGenSun et¬†al. (2024a)(AR-based model without text), Lumina-mGPTLiu et¬†al. (2024)(AR-based model with text) and LDMRombach et¬†al. (2022)(diffusion-based model) on text alignment, visual flaws, and visual appearance.",
                "position": 829
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x8.png",
                "caption": "Figure 7:Visual comparisonwith other open-source diffusion-based and AR-based models (zoom in for details).",
                "position": 847
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x9.png",
                "caption": "Figure 8:Visual comparison of different Token-Shuffle window sizes. We tested each prompt with fixed random seeds and reported the VQAScoreLin et¬†al. (2024)in the bottom-right corner.",
                "position": 871
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x10.png",
                "caption": "(a)More MLP blocks",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x10.png",
                "caption": "(a)More MLP blocks",
                "position": 908
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x11.png",
                "caption": "(b)Drop tokens",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x12.png",
                "caption": "(c)Positional Embedding",
                "position": 918
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x13.png",
                "caption": "(d)Re-sampler & Simple impl.",
                "position": 923
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x14.png",
                "caption": "Figure 10:Training losses for different shuffle window sizes.",
                "position": 942
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Implemental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x15.png",
                "caption": "Figure 11:We plot theaverage loss (left)andgradient norm (right)when training with a resolution of2048√ó2048204820482048\\times 20482048 √ó 2048. Training shows instability after approximately 20K iterations.",
                "position": 1846
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x16.png",
                "caption": "",
                "position": 1849
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x17.png",
                "caption": "Figure 12:Without explicitly appending<|start_of_image|>token, our model naturally generates text based on input and seamlessly transitions to an image, consistently and automatically concluding in line with training data format.",
                "position": 1871
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x18.png",
                "caption": "Figure 13:CFG scalevs.VQAScore.",
                "position": 1874
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x18.png",
                "caption": "Figure 13:CFG scalevs.VQAScore.",
                "position": 1877
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x19.png",
                "caption": "Figure 14:Human evaluation of text alignment, comparing Token-Shuffle with various AR-based and diffusion-based models. Results may vary slightly from Fig.6due to the generated images are assessed by different vendors.",
                "position": 1882
            }
        ]
    },
    {
        "header": "7More Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.17789/x20.png",
                "caption": "Figure 15:Examples of generated images under different CFG scales.",
                "position": 1902
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x21.png",
                "caption": "Figure 16:Attention maps of three implementations: bi-directional, causal, and Token-Shuffle. Illustrated with a feature map size of4√ó4444\\times 44 √ó 4(16 tokens) and a shuffle window size of 2 for Token-Shuffle.",
                "position": 1919
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x22.png",
                "caption": "Figure 17:Visual examples comparing Token-Shuffle (compress ratio8√ó8\\times8 √ówith Token-Shuffle window size of 2) and high compress VQGAN (compress ratio16√ó16\\times16 √ó).",
                "position": 1932
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x22.png",
                "caption": "Figure 17:Visual examples comparing Token-Shuffle (compress ratio8√ó8\\times8 √ówith Token-Shuffle window size of 2) and high compress VQGAN (compress ratio16√ó16\\times16 √ó).",
                "position": 1935
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x23.png",
                "caption": "Figure 18:Human evaluation of Token-Shuffle (compress ratio8√ó8\\times8 √ówith Token-Shuffle window size of 2) and high compress VQGAN (compress ratio16√ó16\\times16 √ó).",
                "position": 1940
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x24.png",
                "caption": "Figure 19:ùüèùüéùüêùüí√óùüèùüéùüêùüí10241024\\mathbf{1024\\times 1024}bold_1024 √ó bold_1024resolution images generated by Token-Shuffle with a shuffle window size of 2. We show generated images focusing on position, color, counting, and combination. The prompts are from GenEvalGhosh et¬†al. (2024)prompts.",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x25.png",
                "caption": "Figure 20:ùüèùüéùüêùüí√óùüèùüéùüêùüí10241024\\mathbf{1024\\times 1024}bold_1024 √ó bold_1024resolution images generated by Token-Shuffle with a shuffle window size of 2. We show two images of same prompt with different random seeds, focusing on complex scenarios or hard prompts. The prompts are from our internal evaluation prompts.",
                "position": 2073
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x26.png",
                "caption": "Figure 21:ùüêùüéùüíùüñ√óùüêùüéùüíùüñ20482048\\mathbf{2048\\times 2048}bold_2048 √ó bold_2048resolution images generated by Token-Shuffle with a shuffle window size of 2. Images are resized for visualization. Please zoom in to see the details in top row and the overall soft holistic beauty in bottom row.",
                "position": 2076
            },
            {
                "img": "https://arxiv.org/html/2504.17789/x27.png",
                "caption": "Table 5:Examples of generated images with visual flaws and structural errors, marked with red circle (zoom in to see details).",
                "position": 2087
            }
        ]
    },
    {
        "header": "8Discussions",
        "images": []
    }
]