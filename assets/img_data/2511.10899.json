[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10899/x1.png",
                "caption": "Figure 1:Comparison of Base LLM and Tool-augmented LLM (TaLM) reasoning. The Base LLM (top) derives the solution through step-by-step mathematical reasoning, while the TaLM (bottom) relies onempirical checksand multiple tool calls to search for the minimum, a failure mode characteristic of Tool-Induced Myopia (TIM).",
                "position": 163
            }
        ]
    },
    {
        "header": "2Tool-induced Myopia",
        "images": []
    },
    {
        "header": "3EvaluatingTIMin Language Models",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.10899/x2.png",
                "caption": "Figure 2:Reasoning behavior vs. tool usage.Metrics are computed over bins defined by the number of tool calls in model solution: {0–3, 4–7, 8–11, 12+}.(a) Win Rate(higher is better) shows that the Base model more frequently outperformsTaLMas tool usage increases, indicating a widening gap at higher call counts.(b) Miss Rate(higher is worse) generally rises with additional tool calls, indicating more missing steps in tool-dependent trajectories.(c) PRM Accuracy(higher is better) typically declines as the number of calls grows.",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2511.10899/x3.png",
                "caption": "Figure 3:Correlation between code complexity metrics and Miss Rate across TaLMs.\n(a) Pearson correlation coefficients for Line of Code and Cyclomatic Complexity with Miss Rate.\n(b) Corresponding p-values with significance thresholds at p=0.05 (red) and p=0.10 (orange). Asterisks denote marginal significance (*p<0.10, **p<0.05). No statistically significant correlations are found, suggesting thatTIMis not driven by code complexity.",
                "position": 542
            },
            {
                "img": "https://arxiv.org/html/2511.10899/x4.png",
                "caption": "Figure 4:Change in reasoning error rates after tool use (Δ=TaLM−Base\\Delta=\\text{TaLM}-\\text{Base}). Positive values indicate that an error type becomes more frequent when the model has access to Code Interpreter tool.",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2511.10899/x5.png",
                "caption": "Figure 5:Code Interpreter invocation rates across TaLMs. Thinking models (GPT-5, o4-mini, Gemini-2.5-Flash) use the tool on an average of ~50% more problems than non-thinking models.",
                "position": 574
            }
        ]
    },
    {
        "header": "6MitigatingTIMHallucination",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]