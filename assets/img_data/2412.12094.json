[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12094/x1.png",
                "caption": "Figure 1:The loss comparison between vanilla Transformer and proposed SepLLM. SepLLM achieves lower loss at different computation costs and different training time consistently.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x2.png",
                "caption": "",
                "position": 156
            },
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/a1.png",
                "caption": "Figure 2:The visualization of attention scores among different layers given the input ‚ÄúNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. ‚Ä¶‚Äù. Note that the separator tokens like ‚Äú,‚Äù and ‚Äú.‚Äù contribute massive attentions.",
                "position": 173
            },
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/a2.png",
                "caption": "",
                "position": 176
            },
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/a3.png",
                "caption": "",
                "position": 177
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12094/x3.png",
                "caption": "Figure 3:The overall paradigm of¬†SepLLM. The left side illustrates the attention mask in the training or pre-filling stage given the input ‚ÄúABC,DE.FG\\n\\absentùëõ\\backslash n\\ italic_n‚Äù. The right side illustrates the KV cache management in the generation stage.",
                "position": 256
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x4.png",
                "caption": "Figure 4:Overall framework of the proposed SepLLM¬†tailored for streaming applications. The KV pairs are storaged in four cache blocks (displayed as four columns), and are updated in each iteration (shown in a single row). Once the runtime usageS‚Å¢i‚Å¢z‚Å¢er‚Å¢u‚Å¢nùëÜùëñùëßsubscriptùëíùëüùë¢ùëõSize_{run}italic_S italic_i italic_z italic_e start_POSTSUBSCRIPT italic_r italic_u italic_n end_POSTSUBSCRIPTreach the max capacityc, SepLLM move KV caches of separator tokens in Past Window Cache into Separator Cache and drop other KV caches.",
                "position": 259
            }
        ]
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12094/x5.png",
                "caption": "(a)Lossw.r.tsteps",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x5.png",
                "caption": "(a)Lossw.r.tsteps",
                "position": 635
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x6.png",
                "caption": "(b)Loss Ratiow.r.tFLOPs",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x7.png",
                "caption": "Figure 6:Training loss curves for the post-training.",
                "position": 721
            }
        ]
    },
    {
        "header": "5Concluding Remarks",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AVisualization of Attention Scores",
        "images": []
    },
    {
        "header": "Appendix BThe Evolution of KV Caches",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12094/x8.png",
                "caption": "Figure 7:The evolution of KV caches in the streaming setting.",
                "position": 1647
            }
        ]
    },
    {
        "header": "Appendix CTraining Acceleration",
        "images": []
    },
    {
        "header": "Appendix DThe Performance of Different Models",
        "images": []
    },
    {
        "header": "Appendix ENeedle In A Haystack",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/Pythia160M_full_2048_pythia160m_k0_w64_global_step135000_step64_s200_e1990_nosep_shortNeedle1.png",
                "caption": "Figure 8:Needle In A Haystacktest results for streamingLLM (n=64) based on Pythia-160M-deduped.",
                "position": 1978
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x9.png",
                "caption": "",
                "position": 1983
            },
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/llama1.png",
                "caption": "",
                "position": 1986
            },
            {
                "img": "https://arxiv.org/html/2412.12094/extracted/6065529/fig/llama3.png",
                "caption": "",
                "position": 1989
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x10.png",
                "caption": "Figure 12:An example of attention map in\nLlama-3-8B-Instruct (Layer 0 and Head 0).",
                "position": 1993
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x11.png",
                "caption": "Figure 13:An example of attention map in\nLlama-3-8B-Instruct (Layer 1 and Head 0).",
                "position": 1997
            },
            {
                "img": "https://arxiv.org/html/2412.12094/x12.png",
                "caption": "Figure 14:An example of attention map in\nLlama-3-8B-Instruct (Layer 2 and Head 0).",
                "position": 2001
            }
        ]
    },
    {
        "header": "Appendix FDiscussions on Separators",
        "images": []
    }
]