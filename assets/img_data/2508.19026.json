[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/x1.png",
                "caption": "",
                "position": 140
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/x2.png",
                "caption": "Figure 2:TheCritic Agent, acting as the master of ceremonies (MC), orchestrates interactions among specialized agents using video context and task instructions. It sequentially engages theSystem II VQA Expert,Skeptical Researcher,Detective, andMeta Reviewer, accumulating insights at each stage. Upon receiving final recommendations from theMeta Reviewer, the MC relays them to theSystem II VQA Expertfor VQA refinement. Subsequently, a subset of these refined VQAs undergoes evaluation by human experts for final validation.",
                "position": 199
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MovieCORE  Creation and Curation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/x3.png",
                "caption": "Figure 3:Comparison of single-pass and agentic annotation. The agentic method (bottom) elicits specific scene details, concrete examples, and detailed story elements, demonstrating the enhanced granularity achieved through multi-agent refinement. Text in blue indicates new, specific details absent in the single-pass version. The single-pass annotation (top), on the other hand, while also attempting to ask deeper questions, remains at a more abstract level.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x4.png",
                "caption": "Figure 4:Wordcloud illustrating key themes and concepts of MovieCORE with terms such as \"emotional\", \"character\" and \"influence\" very prominent.",
                "position": 336
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5ACE: Agentic Choice Enhancement",
        "images": []
    },
    {
        "header": "6Quantitative Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/images/qual_moviecore.png",
                "caption": "Figure 5:Qualitative Comparison of Model Responses. This figure contrasts responses from InternVL-2 (zero-shot), HERMES (fully-supervised), and HERMES+ACE on two questions about cheetah behaviors. Purple text highlights conceptual understanding while blue text indicates specific visual evidence and contextual details. Note how ACE enhances responses with more precise scene descriptions and behavioral insights.",
                "position": 778
            }
        ]
    },
    {
        "header": "7Qualitative Results",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/x5.png",
                "caption": "Figure S1:Extracting Detailed Context from Videos:We input each video to MiniCPM-v2.6, prompting it with a series of carefully crafted questions (left). The model’s responses (right) provide rich, multi-faceted details about the video, including narrative flow, character information, setting, mood, and target audience. This extracted information serves asData Infopriors to inform our annotation agents, ensuring a comprehensive understanding of the video content before the VQA generation process.",
                "position": 1258
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x6.png",
                "caption": "Figure S2:System Messages for the Annotation Agents",
                "position": 1261
            }
        ]
    },
    {
        "header": "Appendix IReproducibility Statement",
        "images": []
    },
    {
        "header": "Appendix IIMore Details on MovieCORE",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/images/lower_scores_human_review.drawio.png",
                "caption": "Figure S3:A parade scene from MovieCORE featuring various cultural and historical elements. This particular QA receives low answerability and relevance scores from one of our reviewers but was still kept following thorough review by a human meta-reviewer.",
                "position": 1451
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x7.png",
                "caption": "Figure S4:Video Question Answering Evaluation Form used in our human verification process.The form assesses four critical dimensions (relevance, clarity, depth, and answerability) on a 5-point scale. Each dimension is clearly defined with anchored endpoints to ensure consistent evaluation. The form includes sections for both question/answer assessment and caption verification to ensure comprehensive content quality. Evaluators use this standardized form to systematically review each QA pair while referring to the corresponding video content.",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x8.png",
                "caption": "Figure S5:Additional Comparison of single-pass and agentic annotation. The agentic method (bottom) delves into specific scene details, such as the hippopotamus’s evolution from a chaotic force to a symbol of innocence, and highlights changes in cinematography that reflect this transformation. The single-pass annotation (top) provides a general interpretation of themes like human-animal conflict without specific scene references.",
                "position": 1466
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x9.png",
                "caption": "Figure S6:Additional Comparison of single-pass and agentic annotation. The agentic method (bottom) specifies visual techniques like dramatic lighting, shadow play, and strategic camera angles that enhance emotional weight and suspense, offering concrete examples like close-up shots capturing raw emotion. The single-pass annotation (top) mentions general visual elements but lacks a detailed analysis of how these techniques impact the narrative.",
                "position": 1469
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x10.png",
                "caption": "Figure S7:Bloom’s Taxonomy Pyramid. The pyramid illustrates the hierarchical nature of cognitive skills, progressing from lower-order to higher-order thinking.",
                "position": 1533
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x10.png",
                "caption": "Figure S7:Bloom’s Taxonomy Pyramid. The pyramid illustrates the hierarchical nature of cognitive skills, progressing from lower-order to higher-order thinking.",
                "position": 1536
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x11.png",
                "caption": "Figure S8:Prompts we use to instruct GPT4-o-mini to compute the Bloom’s taxonomy level for the different datasets we show inTable˜1of the main paper.",
                "position": 1541
            }
        ]
    },
    {
        "header": "Appendix IIIDetails on the Bloom’s Taxonomy",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.19026/x12.png",
                "caption": "Figure S9:Prompt to evaluate the quality and relevance of the evidence provided in the answers.",
                "position": 1598
            },
            {
                "img": "https://arxiv.org/html/2508.19026/x13.png",
                "caption": "Figure S10:Evaluation Prompts:These figures illustrate the prompts we use for each of the evaluation methods we employ. The prompt forEvidenceis shown inFigure˜S9.",
                "position": 1601
            }
        ]
    },
    {
        "header": "Appendix IVEvaluation Methodology",
        "images": []
    },
    {
        "header": "Appendix VLicence",
        "images": []
    }
]