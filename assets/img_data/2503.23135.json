[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23135/x1.png",
                "caption": "Figure 1:The mechanism of self attention (a) and convolution (b). (c) shows that the human vision system can ‚ÄúSee Large‚Äù through the peripheral vision, and ‚ÄúFocus Small‚Äù through the central vision. (d) shows the distribution of rods and cones depending on the eccentricity from the fovea of the human eye. They contribute to the formation of extensive peripheral vision and focal central vision.",
                "position": 87
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23135/x2.png",
                "caption": "Figure 2:Comparison of self-attention, convolution, and LS conv.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2503.23135/x3.png",
                "caption": "Figure 3:(a) The illustration of our proposed LS convolution. (b) The illustration of our proposed LSNet. LSNet has four stages withH8√óW8ùêª8ùëä8\\frac{H}{8}\\times\\frac{W}{8}divide start_ARG italic_H end_ARG start_ARG 8 end_ARG √ó divide start_ARG italic_W end_ARG start_ARG 8 end_ARG,H16√óW16ùêª16ùëä16\\frac{H}{16}\\times\\frac{W}{16}divide start_ARG italic_H end_ARG start_ARG 16 end_ARG √ó divide start_ARG italic_W end_ARG start_ARG 16 end_ARG,H32√óW32ùêª32ùëä32\\frac{H}{32}\\times\\frac{W}{32}divide start_ARG italic_H end_ARG start_ARG 32 end_ARG √ó divide start_ARG italic_W end_ARG start_ARG 32 end_ARG, andH64√óW64ùêª64ùëä64\\frac{H}{64}\\times\\frac{W}{64}divide start_ARG italic_H end_ARG start_ARG 64 end_ARG √ó divide start_ARG italic_W end_ARG start_ARG 64 end_ARGresolutions respectively, whereHùêªHitalic_HandWùëäWitalic_Wdenote the width and height of the input image.Cùê∂Citalic_Crepresents the channel dimension. The norm layer and nonlinearity are omitted for simplicity.",
                "position": 245
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation and Architectural Details",
        "images": []
    },
    {
        "header": "Appendix BMore Comparisons",
        "images": []
    },
    {
        "header": "Appendix CQualitative Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.23135/x4.png",
                "caption": "Figure 4:Visualization of the effective receptive field. Best viewed when zoomed in. (a) and (b) show that RepMixer and CGA exhibit unnatural patterns in the effective receptive field. (c) illustrates that LS convolution enables broad peripheral perception and central view focusing simultaneously. (d) shows that without LKP, LS convolution presents a smaller receptive field compared with (c), indicating the effectiveness of LKP.",
                "position": 3267
            },
            {
                "img": "https://arxiv.org/html/2503.23135/x5.png",
                "caption": "Figure 5:Visualization of the aggregation weights in LS convolution. The second row shows that the aggregation weights are well correlated with semantic relevant areas. The third row indicates that integrating LKP enables LS convolution to capture more precise visual patterns with improved contextual information.",
                "position": 3270
            },
            {
                "img": "https://arxiv.org/html/2503.23135/x6.png",
                "caption": "Figure 6:Visualization of the feature maps of LKP and SKA. The second column in each part shows that LKP can encompass a broad view of the scene. The third column in each part indicates that based on LKP, SKA can further grasp more subtle features and detailed patterns.",
                "position": 3273
            },
            {
                "img": "https://arxiv.org/html/2503.23135/x7.png",
                "caption": "Figure 7:Qualitative results for object detection and instance segmentation on COCO-2017[49].",
                "position": 3276
            },
            {
                "img": "https://arxiv.org/html/2503.23135/x8.png",
                "caption": "Figure 8:Qualitative results for semantic segmentation on ADE20K[106]. The upper row shows the ground truth masks, and the lower row presents the predicted masks.",
                "position": 3279
            }
        ]
    },
    {
        "header": "Appendix DContribution, Limitation, and Impact",
        "images": []
    }
]