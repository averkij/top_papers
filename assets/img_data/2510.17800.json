[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17800/x1.png",
                "caption": "Figure 1:(Upper) Comparison of two paradigms for long-context tasks: conventional approaches directly feeding plain text into LLMs, and the proposed VLM-based paradigm, Glyph, which renders text as compact images to achieve substantial input-token compression. (Lower) Glyph attains competitive performance on LongBench and MRCR, while offering significant compression and inference speedup over its text backbone model on 128K-token inputs.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17800/x2.png",
                "caption": "Figure 2:Glyph consists of three main stages: continual pre-training on rendered long-text data, LLM-driven genetic search for optimal rendering configurations, and post-training with SFT, RL. Together, these stages enable efficient long-context modeling with visual-text compression.",
                "position": 223
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17800/x3.png",
                "caption": "Figure 3:Performance comparison of Glyph and the baseline across different context windows, demonstrating that Glyph achieves performance equivalent to longer contexts with substantially shorter context window.",
                "position": 724
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17800/fig/speedup_panels_times.png",
                "caption": "Figure 4:Speedup ratios of Glyph over the text backbone model for prefill, decoding, and training across different sequence lengths.",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2510.17800/fig/ruler_performance.png",
                "caption": "Figure 5:Model performance degradation across different sequence lengths on the Ruler benchmark.",
                "position": 979
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARendering Parameters",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.17800/x4.png",
                "caption": "Figure 6:The optimal parameter setting. The left column lists the values for page layout, font, and spacing, while the right column provides an example of the rendered text.",
                "position": 2181
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    }
]