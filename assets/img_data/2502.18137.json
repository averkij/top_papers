[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18137/x1.png",
                "caption": "Figure 1:SpargeAttncan achieve 1.83x speedup onMochion L40 GPU, with no video quality loss.",
                "position": 100
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x2.png",
                "caption": "Figure 2:Some sampled patterns of attention mapPùëÉPitalic_Pin video, image, and language generation models.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18137/x3.png",
                "caption": "Figure 3:Workflow ofSpargeAttn.",
                "position": 143
            }
        ]
    },
    {
        "header": "3SpargeAttn",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18137/x4.png",
                "caption": "Figure 4:Exemplary patterns of the query and key in the attention of various models.",
                "position": 154
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x5.png",
                "caption": "Figure 5:Illustration of different token permutation methods in1√ó6√ó61661\\times 6\\times 61 √ó 6 √ó 6space, with block size of 4.",
                "position": 519
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18137/x6.png",
                "caption": "Figure 6:Comparison examples onFluxandStable-Diffusion3.5. The sparsity ofSpargeAttn, MInference and FlexPrefill is 0.38, 0.3, and 0.4 onFluxand 0.31, 0.3, and 0.35 onStable-Diffusion3.5.",
                "position": 1099
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x7.png",
                "caption": "Figure 7:Comparison examples onMochi. The sparsity ofSpargeAttn, MInference and FlexPrefill is 0.47, 0.3, and 0.4.",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x8.png",
                "caption": "Figure 8:A NeedleInAHaystack comparison example onLlama3.1. The sparsity ofSpargeAttn, MInference, and FlexPrefill is 0.5, 0.5, and 0.54.",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x9.png",
                "caption": "Figure 9:Kernel speed comparison under varying sparsity on RTX4090. Input tensors have a sequence length of 22K and a head dimension of 128.SpargeAttn+FA2/Sage/Sage2means deploying our method on FlashAttention2, SageAttention or SageAttention2(Zhang et¬†al.,2024a).",
                "position": 1115
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.18137/x10.png",
                "caption": "Figure 10:A NeedleInAHaystack comparison example onLlama3.1. The sparsity ofSpargeAttn, MInference, and FlexPrefill is 0.36, 0.3, and 0.3.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2502.18137/x11.png",
                "caption": "Figure 11:Comparison examples onMochi. The sparsity ofSpargeAttn, MInference and FlexPrefill is 0.47, 0.3, and 0.4.",
                "position": 2155
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]