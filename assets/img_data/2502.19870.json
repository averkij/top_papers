[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19870/x1.png",
                "caption": "Figure 1:Comparison between the existing benchmark and MMKE-Bench with a detailed example. In this example, the texts in red represent the edited counterfactual content. T/I-Rel represents text and image reliability, T/I-Gen represents text and image generalization and Port represents portability. Previous benchmarks mainly focus on entity recognition editing using a triplet-based knowledge representation format, which does not align with actual scenarios. MMKE-Bench focuses on evaluating diverse semantic editing in realistic scenarios in a natural language format.",
                "position": 133
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Definition",
        "images": []
    },
    {
        "header": "4Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19870/x2.png",
                "caption": "Figure 2:The construction pipeline of MMKE-Bench.",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x3.png",
                "caption": "Figure 3:The types of samples in MMKE-Bench.",
                "position": 352
            }
        ]
    },
    {
        "header": "5Experiement",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19870/x4.png",
                "caption": "Figure 4:Evaluation comparison of IKE for MiniGPT-4 with existing benchmarks. Port for MMEdit and MIKE, is set 1, as they are not evaluated.",
                "position": 1332
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x5.png",
                "caption": "Figure 5:Case study of editing examples",
                "position": 1737
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x5.png",
                "caption": "Figure 5:Case study of editing examples",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x6.png",
                "caption": "Figure 6:Case study of question answer",
                "position": 1745
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ABenchmark construction",
        "images": []
    },
    {
        "header": "Appendix BExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19870/x7.png",
                "caption": "Figure 7:Evaluation comparison of IKE for BLIP2 with existing benchmarks. I-Gen and Port for MMEdit, along with Port for MIKE, is set 1, as they ignore the relevant criteria.",
                "position": 2781
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x8.png",
                "caption": "Figure 8:Prompt for editing knowledge.",
                "position": 3973
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x9.png",
                "caption": "Figure 9:Prompt for editing generating reliability question.",
                "position": 3976
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x10.png",
                "caption": "Figure 10:Prompt for generating portability question.",
                "position": 3979
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x11.png",
                "caption": "Figure 11:In Fig.11 (a), the single editing takes one edit at a time and evaluates immediately, while in Fig.11 (b) and (c) the sequential editing involves continuous edits and tests after several other edits.",
                "position": 3982
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x12.png",
                "caption": "Figure 12:There is a difference between Visual Entity Knowledge and Visual Semantic Knowledge. Visual Entity Knowledge focuses on entity objects, such as people, things, etc. Visual Semantic Knowledge focuses on the knowledge abstracted from images, such as gestures, traffic signs, facial expressions, etc. For example, for Visual Entity Knowledge, in Figure 12 (a), the training knowledge needs a reference to the entity, such as ”Donald John Trump”, focusing on the information of the entity object; However, in (b) of Figure 12, for Visual Semantic Knowledge, entity reference, such as ”The man”, is not needed, but the gesture of the person in the image is emphasized.",
                "position": 3985
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x13.png",
                "caption": "Figure 13:Loss iteration graph trained by SERAC method on Visual Semantic Knowledge data. Through the analysis of images, we can find that the SERAC method can normally achieve the convergence of loss on this data amount, and the loss value will approach 0 at last.",
                "position": 3988
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x14.png",
                "caption": "Figure 14:Loss iteration graph trained by MEND method on Visual Semantic Knowledge data. Through the analysis of images, we can find that the MEND method can normally achieve the convergence of loss on this data amount, and the loss value will approach 0 at last.",
                "position": 3993
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x15.png",
                "caption": "Figure 15:Data Example-1 of Visual Entity Editing in MMKE-Bench.",
                "position": 3999
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x15.png",
                "caption": "Figure 15:Data Example-1 of Visual Entity Editing in MMKE-Bench.",
                "position": 4002
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x16.png",
                "caption": "Figure 16:Data Example-2 of Visual Entity Editing in MMKE-Bench.",
                "position": 4007
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x17.png",
                "caption": "Figure 17:Data Example-1 of Visual Semantic Editing in MMKE-Bench.",
                "position": 4013
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x17.png",
                "caption": "Figure 17:Data Example-1 of Visual Semantic Editing in MMKE-Bench.",
                "position": 4016
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x18.png",
                "caption": "Figure 18:Data Example-2 of Visual Semantic Editing in MMKE-Bench.",
                "position": 4021
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x19.png",
                "caption": "Figure 19:Data Example-1 of User-Specific Editing in MMKE-Bench.",
                "position": 4027
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x19.png",
                "caption": "Figure 19:Data Example-1 of User-Specific Editing in MMKE-Bench.",
                "position": 4030
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x20.png",
                "caption": "Figure 20:Data Example-2 of User-Specific Editing in MMKE-Bench.",
                "position": 4035
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x21.png",
                "caption": "Figure 21:Case Study on Visual Entity Editing Example-1 in MMKE-Bench.",
                "position": 4041
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x21.png",
                "caption": "Figure 21:Case Study on Visual Entity Editing Example-1 in MMKE-Bench.",
                "position": 4044
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x22.png",
                "caption": "Figure 22:Case Study on Visual Entity Editing Example-2 in MMKE-Bench.",
                "position": 4049
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x23.png",
                "caption": "Figure 23:Case Study on Visual Semantic Editing Example-1 in MMKE-Bench.",
                "position": 4055
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x23.png",
                "caption": "Figure 23:Case Study on Visual Semantic Editing Example-1 in MMKE-Bench.",
                "position": 4058
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x24.png",
                "caption": "Figure 24:Case Study on Visual Semantic Editing Example-2 in MMKE-Bench.",
                "position": 4063
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x25.png",
                "caption": "Figure 25:Case Study on User-Specific Editing Example-1 in MMKE-Bench.",
                "position": 4069
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x25.png",
                "caption": "Figure 25:Case Study on User-Specific Editing Example-1 in MMKE-Bench.",
                "position": 4072
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x26.png",
                "caption": "Figure 26:Case Study on User-Specific Editing Example-2 in MMKE-Bench.",
                "position": 4077
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x27.png",
                "caption": "Figure 27:Case Study of Question Answer Example-1 of Visual Semantic Editing in MMKE-Bench. The texts in brown indicate the same content as the editing knowledge.",
                "position": 4083
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x27.png",
                "caption": "Figure 27:Case Study of Question Answer Example-1 of Visual Semantic Editing in MMKE-Bench. The texts in brown indicate the same content as the editing knowledge.",
                "position": 4086
            },
            {
                "img": "https://arxiv.org/html/2502.19870/x28.png",
                "caption": "Figure 28:Case Study of Question Answer Example-2 of Visual Semantic Editing in MMKE-Bench. The texts in brown indicate the same content as the editing knowledge.",
                "position": 4091
            }
        ]
    },
    {
        "header": "Appendix CMore results",
        "images": []
    }
]