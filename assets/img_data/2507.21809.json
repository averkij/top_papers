[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21809/x1.png",
                "caption": "",
                "position": 62
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x2.png",
                "caption": "Figure 1:An overview ofHunyuanWorld 1.0applications.",
                "position": 65
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Technical Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21809/x3.png",
                "caption": "Figure 2:An overview ofHunyuanWorld 1.0architecture for 3D world generation. Given a conditioned scene image or textual description,HunyuanWorld 1.0generates layer-wise 3D worlds in mesh through a staged generative framework. We first leverage a diffusion model (Panorama-DiT) to generate a panoramic image, which serves as an initial world proxy for providing full 360Â° scene information. We then obtain semantically layered scene representations via world layering and reconstruction. To ensure layer-wise alignment of the reconstructed 3D world, we enhance the panoramic depth estimation model with a cross-layer depth alignment strategy. Also, users can obtain full 3D objects via image-to-3D generation or represent the sky as HDRI maps for downstream applications.",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x4.png",
                "caption": "Figure 3:An overview of our panoramic data curation pipeline.",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x5.png",
                "caption": "Figure 4:Visual results of image-to-panorama generation byHunyuanWorld 1.0.",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x6.png",
                "caption": "Figure 5:Visual results of text-to-panorama generation byHunyuanWorld 1.0.",
                "position": 302
            }
        ]
    },
    {
        "header": "3Model Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21809/x7.png",
                "caption": "Figure 6:Qualitative comparisons for image-to-panorama generation (World Labs). Left: panoramic images generated from the same input image. Right: Four perspectively rendered views.",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x8.png",
                "caption": "Figure 7:Qualitative comparisons for image-to-panorama generation (Tanks and Temples). Left: panoramic images generated from the same input image. Right: Four perspectively rendered views.",
                "position": 424
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x9.png",
                "caption": "Figure 8:Qualitative comparisons for text-to-panorama generation (case 1).\nLeft: panoramic images generated from the text at the bottom. Right: Four perspectively rendered views.",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x10.png",
                "caption": "Figure 9:Qualitative comparisons for text-to-panorama generation (case 2).\nLeft: panoramic images generated from the text at the bottom. Right: Four perspectively rendered views.",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x11.png",
                "caption": "Figure 10:Visual results of text-to-world generation byHunyuanWorld 1.0.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x12.png",
                "caption": "Figure 11:Visual results of image-to-world generation byHunyuanWorld 1.0.",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x13.png",
                "caption": "Figure 12:Qualitative comparisons for image-to-world generation. For each case, we render three perspective views from the generated 3D scenes.",
                "position": 566
            },
            {
                "img": "https://arxiv.org/html/2507.21809/x14.png",
                "caption": "Figure 13:Qualitative comparisons for text-to-world generation. For each case, we render three perspective views from the generated 3D scenes.",
                "position": 571
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Contributors",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]