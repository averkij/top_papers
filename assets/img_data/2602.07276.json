[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x1.png",
                "caption": "",
                "position": 154
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x2.png",
                "caption": "Figure 1:Comparison of Task-Vector Steering, Semantic-Driven Vector Steering, andSteer2Adapt.(a) Task-Vector Steering derives task vectors through large-scale data training; while effective, this approach is computationally intensive and lacks semantic interpretability. (b) Concept-Vector Steering utilizes pre-defined semantic concept vectors, which often lack the necessary expressiveness for complex downstream tasks. (c)Steer2Adapt(ours) employs Bayesian Optimization with minimal examples to find an optimal linear combination of concept vectors, achieving high performance while remaining data-efficient and semantically transparent.",
                "position": 162
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x3.png",
                "caption": "Figure 2:Steer2AdaptOverview.(1) Semantic prior subspace construction: based on human’s insights, we define a set of concepts that will affect model performance in a domain and extract corresponding steering vectors to form a semantic prior subspace within LLMs activation space. (2) Composed vector search: using only a few task examples, we run Bayesian optimization over the subspace coefficients with a stability-aware objective that rewards fixing wrong predictions while penalizing flips from correct to incorrect, yielding a composed steering vector for inference-stage model steering.",
                "position": 240
            }
        ]
    },
    {
        "header": "4Experiment Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x4.png",
                "caption": "Figure 3:Steer2Adaptdelivers strong, consistent improvements across both reasoning and safety domains.Top row: reasoning results; bottom row: safety results.Left: Task generalization, measured by average percentage improvement over the baseline across models for each task.Middle: Model generalization, measured by average percentage improvement over the baseline across tasks for each backbone model.Right: Reliability and gain distribution, showing performance changes across all evaluation scenarios (reasoning:55tasks×\\times33models per method; safety:44tasks×\\times33models per method).\nAcross both domains,Steer2Adaptachieves strong average gains while exhibiting compact, positively centered distributions, indicating robust and consistent performance.",
                "position": 675
            }
        ]
    },
    {
        "header": "5Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x5.png",
                "caption": "Figure 4:Steer2Adaptdepends on basis direction relevance and is robust to moderate subspace noise.(a) Steering reasoning with a mismatched subspace (safety directions) causes large performance drops and higher variance.\n(b) Adding a small number of less relevant directions to the reasoning subspace leads to only minor performance changes.\n(c) Task vectors from relevant tasks can form an effective steering subspace with performance comparable to semantic subspaces.",
                "position": 736
            },
            {
                "img": "https://arxiv.org/html/2602.07276/x6.png",
                "caption": "Figure 5:Steer2Adaptachieves the best performance–efficiency trade-off.We report an efficiency score that measures the gain in task performance per unit of inference cost, computed asEfficiency=(Improvement−Minimum Performance)/Inference Overhead\\text{Efficiency}=(\\text{Improvement}-\\text{Minimum Performance})/\\text{Inference Overhead}.",
                "position": 776
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x7.png",
                "caption": "Figure 6:Transparent basis combinations inSteer2Adapt.\nLeft: Coding gains align with structured reasoning traits.\nRight: Safety objectives exhibit entangled, non-uniform trade-offs.",
                "position": 809
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07276/x8.png",
                "caption": "Figure 7:Radar visualizations of reasoning basis activations across tasks and backbone models.",
                "position": 2762
            },
            {
                "img": "https://arxiv.org/html/2602.07276/x9.png",
                "caption": "Figure 8:Radar visualizations of safety basis activations across tasks and backbone models.",
                "position": 2765
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]