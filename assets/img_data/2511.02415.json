[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02415/x1.png",
                "caption": "Figure 1:Left: ChartM3covers 9 major categories of chart types, totaling 62 subcategories. Right: Performance comparison of representative MLLMs across ChartM3task categories.",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2511.02415/x2.png",
                "caption": "",
                "position": 95
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3ChartM3",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02415/x3.png",
                "caption": "Figure 2:The ChartM3data generation pipeline follows a progressive automated workflow that begins by generating key questions and utilizing RAG to select appropriate templates from a diverse chart database. The process then advances through multiple code-driven stages: creating structured data, producing rendering code, and generating Q&A pairs with multi-step visual reasoning reasoning synthesizing analytical code. Finally the pipeline conducts model-based comprehensive assessments of data quality and difficulty levels.",
                "position": 390
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02415/x4.png",
                "caption": "Figure 3:Performance comparison between models trained by SFT with and without CoT Q&A across different evaluation metrics.",
                "position": 1108
            },
            {
                "img": "https://arxiv.org/html/2511.02415/x5.png",
                "caption": "Figure 4:Performance of models trained by GRPO with different numbers of samples across multiple datasets.",
                "position": 1119
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Consideration",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02415/x6.png",
                "caption": "Figure 5:The distribution of ChartM3Q&A categories.",
                "position": 1734
            },
            {
                "img": "https://arxiv.org/html/2511.02415/x7.png",
                "caption": "Figure 6:Examples of ChartM3Template Database.",
                "position": 2243
            },
            {
                "img": "https://arxiv.org/html/2511.02415/x8.png",
                "caption": "Figure 7:A Case Study of ChartM3Evaluation Results. While both GPT-4o and the base model provided incorrect answers, the model trained with CoT-SFT successfully analyze the medians across categories during its reasoning process and produce the correct ranking.",
                "position": 2246
            },
            {
                "img": "https://arxiv.org/html/2511.02415/x9.png",
                "caption": "Figure 8:A Case Study of ChartM3Evaluation Results for Multi-Chart Scenarios. Although individual chart elements are straightforward, GPT demonstrates limitations in cross-graph analysis. Specifically, when examining renewable energy growth from 2000 to 2020, GPT fails to properly reference the first graph. The base model incorrectly substitutes total energy consumption data for renewable energy consumption. In comparison, the model trained with CoT-SFT correctly identifies that renewable energy levels in 2020 are below 1500 units, producing a prediction that more closely aligns with the standard answer compared to Claude 3.5 Sonnet.",
                "position": 2249
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]