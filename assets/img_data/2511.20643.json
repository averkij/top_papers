[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x1.png",
                "caption": "Figure 1:Task-adaptive, steerable,Concept-AwareBatchSampling (CABS).The per-sample concept multiplicities(left)of MSCOCO retrieval and ImageNet classification train sets depict their divergent distributional properties. By only modifying a simple scoring function,CABScan flexibly adapt to different target tasks (details inSec.3). Both our classification-optimized (CABS-DM, seeSec.4) and retrieval-optimized (CABS-FM, seeSec.5) variants outperform IID sampling by large margins, across several experimental configurations.",
                "position": 169
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x2.png",
                "caption": "Figure 2:DataConcept.We start with images from DataComp(Gadre et al.,2023)and build a concept bankùí±\\mathcal{V}by merging, deduplicating, and filtering various concept sources.\nIn ‚ë†First-order tagging, we assign a preliminary list of concepts (fromùí±\\mathcal{V}) to each sample. ‚ë° We thengroundeach concept in the image, removing noise in the initial candidates. ‚ë¢ Lastly, we use a model to transform alt-texts intoconcept-aware captions.",
                "position": 224
            }
        ]
    },
    {
        "header": "2Concept-Aware Dataset Augmentation",
        "images": []
    },
    {
        "header": "3Concept-Aware Batch Sampling",
        "images": []
    },
    {
        "header": "4CABS withDiversity Maximization",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x3.png",
                "caption": "Figure 3:Sub-batch compositions.CABS-DM induces a near-uniform concept frequency distribution, de-biasing the distributional skew induced by IID-sampling.Uniqueindicates total unique concepts in the sub-batch: CABS-DM incorporates nearly double the concepts in the curated sub-batch, compared to IID.",
                "position": 443
            }
        ]
    },
    {
        "header": "5CABS withFrequency Maximization",
        "images": []
    },
    {
        "header": "6Data- & Compute-Constrained Experiments",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x4.png",
                "caption": "Figure 4:CABS with longer training (1.28B samples seen).Both CABS-DM and CABS-FM show significant boost over IID for ViT-B-32-CLIP in both compute-constrained and data-constrained regimes, the grey dashed line being the point where compute-constraint shift to data-constraint in an IID sampling regime.",
                "position": 1574
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x4.png",
                "caption": "",
                "position": 1577
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x5.png",
                "caption": "",
                "position": 1581
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataConceptCuration: Further Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x6.png",
                "caption": "Figure 5:Qualitative Results with different RAM++ thresholds. WhileUdandarao et al.(2024)found 0.7 to be the suitable RAM++ threshold, we show qualitative examples across three different thresholds: 0.7, 0.75, 0.8 on a much larger concept bank. We find the most suitable pool of concepts at the 0.75 confidence threshold.",
                "position": 2926
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x7.png",
                "caption": "Figure 6:Ensembling bounding boxes provides the best detection predictions forDataConcept.Using Weighted Box Fusion, we are able to detect single instances(no overlap of\nbounding boxes) of all relevant objects in an image.",
                "position": 2966
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x8.png",
                "caption": "Figure 7:What is the distribution of concepts in web-scale pretraining datasets?We demonstrate the distribution of concept counts inDataConceptafter annotations using GroundingDINO. Indeed,DataConceptis strongly long-tailed with 86 concepts having more than 1 million annotations, 685 concepts having more than 100,000 annotations, 2670 concepts having more than 10,000 annotations and 5326 concepts having more than 1,000 annotations.",
                "position": 3492
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x9.png",
                "caption": "Figure 8:What is the complexity ofDataConceptsamples based on visual concepts?We demonstrate the distribution of concept counts per sample after annotations using GroundingDINO. Note that GroundingDINO can predict a concept many times, hence these numbers reflect the total number of concepts detected in an image, not unique concepts, hence acting as a suitable measure of image complexity.",
                "position": 4124
            }
        ]
    },
    {
        "header": "Appendix BConcept-aware Recaptioning",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x10.png",
                "caption": "Figure 9:Comparing 3 state-of-the-art open-weight VLMs on concept-aware captioning for pimage-text pretraining datasets.We compare Moondream2, Molmo-7B and Qwen2-VL-7B across a random subset of DataComp-128M and select Qwen2-VL for a combination of its higher quality captions and appropriate processing speed.",
                "position": 4155
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x11.png",
                "caption": "Figure 10:Word Count Distribution.Comparison of DataComp alt-text captions and Qwen2-VL-7B recaptions. Alt-text remains short-form, while recaptions are substantially longer. Extremely long alt-text outliers are excluded from the plot for clarity.",
                "position": 4169
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x12.png",
                "caption": "Figure 11:Some examples of concept-aware synthetic captions. We observe good concept-adherence and multilingual understanding.",
                "position": 4212
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x13.png",
                "caption": "Figure 12:Some more examples of concept-aware synthetic captions. We observe good concept-adherence and multilingual understanding.",
                "position": 4215
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x14.png",
                "caption": "Figure 13:Some more examples of concept-aware synthetic captions. We observe good concept-adherence and multilingual understanding.",
                "position": 4218
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x15.png",
                "caption": "Figure 14:Some more examples of concept-aware synthetic captions. We observe good concept-adherence and multilingual understanding.",
                "position": 4221
            }
        ]
    },
    {
        "header": "Appendix CCABS: More Details",
        "images": []
    },
    {
        "header": "Appendix DExtended Benchmark Performance",
        "images": []
    },
    {
        "header": "Appendix EContinual Pretraining",
        "images": []
    },
    {
        "header": "Appendix FAblation on Filter Ratios",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20643/x16.png",
                "caption": "Figure 15:CABS-DM filtering ratio ablation. We choosef=0.8f=0.8based on ImageNet validation performance. For simplicity, we maintain this filter ratio forCABS-FM as well, and still see strong performance gains on image-text retrieval benchmarks.",
                "position": 6410
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x17.png",
                "caption": "Figure 16:Dataset-wise comparisons for all benchmarks for CLIP ViT-S/16 betweenCABS-DM and IID sampling for alt-text. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6428
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x18.png",
                "caption": "Figure 17:Dataset-wise comparisons for all benchmarks for CLIP ViT-S/16 betweenCABS-DM and IID sampling for synthetic recaptions. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6431
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x19.png",
                "caption": "Figure 18:Dataset-wise comparisons for all benchmarks for CLIP ViT-B/32 betweenCABS-DM and IID sampling for alt-text. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6434
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x20.png",
                "caption": "Figure 19:Dataset-wise comparisons for all benchmarks for CLIP ViT-B/32 betweenCABS-DM and IID sampling for synthetic recaptions. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6437
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x21.png",
                "caption": "Figure 20:Dataset-wise comparisons for all benchmarks for SigLIP ViT-B-16 betweenCABS-DM and IID sampling for alt-text. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6440
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x22.png",
                "caption": "Figure 21:Dataset-wise comparisons for all benchmarks for SigLIP ViT-B-16 betweenCABS-DM and IID sampling for synthetic recaptions. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6443
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x23.png",
                "caption": "Figure 22:Dataset-wise comparisons for all benchmarks for SigLIP ViT-SO400M-14 betweenCABS-DM and IID sampling for alt-text. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6446
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x24.png",
                "caption": "Figure 23:Dataset-wise comparisons for all benchmarks for SigLIP ViT-SO400M-14 betweenCABS-DM and IID sampling for synthetic recaptions. A positive performance difference indicates a benchmark whereCABS-DM outperforms IID sampling.",
                "position": 6449
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x25.png",
                "caption": "Figure 24:Dataset-wise comparisons for all benchmarks for CLIP ViT-B-32 betweenCABS-DM (f=0.5f=0.5) and MetaCLIP curation on alt-text.",
                "position": 6670
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x26.png",
                "caption": "Figure 25:Dataset-wise comparisons for all benchmarks for CLIP ViT-B-32 betweenCABS-DM (f=0.75f=0.75) and MetaCLIP curation on alt-text.",
                "position": 6673
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x27.png",
                "caption": "Figure 26:Dataset-wise comparisons for all benchmarks for CLIP ViT-B-32 betweenCABS-DM (f=0.8f=0.8) and MetaCLIP curation on alt-text.",
                "position": 6676
            },
            {
                "img": "https://arxiv.org/html/2511.20643/x28.png",
                "caption": "Figure 27:Dataset-wise comparisons for all benchmarks for SigLIP ViT-B-16 betweenCABS-DM (f=0.8f=0.8) and MetaCLIP curation on alt-text.",
                "position": 6679
            }
        ]
    },
    {
        "header": "Appendix GFine-grained Benchmark Performance",
        "images": []
    }
]