[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09696/x1.png",
                "caption": "Figure 1:State of the art performance on public visual benchmarks.Frontier LMMs score highly on many popular benchmarks, leaving little headroom. By comparison, ourZeroBenchproves impossible for current models, leaving maximum headroom.",
                "position": 164
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x2.png",
                "caption": "Figure 2:Rapid progress was made on visual benchmarks last year.Compiled from(OpenCompass Contributors,2023).",
                "position": 173
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/example_questions/oar.jpg",
                "caption": "Figure 3:ExampleZeroBenchquestions and answers††.Our benchmark contains 100 of these challenging questions.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/example_questions/neurips.jpg",
                "caption": "",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/example_questions/snowflakes_annotated.png",
                "caption": "",
                "position": 247
            }
        ]
    },
    {
        "header": "3ZeroBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09696/x3.png",
                "caption": "Table 1:ZeroBenchstatistics.",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x3.png",
                "caption": "Figure 4:Question length distribution.",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x4.png",
                "caption": "Figure 5:Image size distribution.",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/example_questions/music_notes.jpg",
                "caption": "Figure 6:ZeroBenchsubquestions. To differentiate model performance, we include subquestions for steps required to answer the main question.",
                "position": 385
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09696/x5.png",
                "caption": "Figure 7:Sample recurring visual interpretation errors onZeroBenchsubquestions.These examples demonstrate that despite attaining respectable scores on the subquestions – indicating a high level of competency – models such as Claude 3.5 Sonnet v2 and Gemini 2.0 Flash Thinking struggle on these relatively simple resolving and counting tasks. Full-resolution images were used for evaluation.o1 pro —Claude 3.5 Sonnet v2 —QVQ —Gemini 2.0 Flash Thinking.",
                "position": 990
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x6.png",
                "caption": "",
                "position": 1006
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/llm_icons/logan/claude-35.png",
                "caption": "",
                "position": 1007
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x7.png",
                "caption": "",
                "position": 1008
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x8.png",
                "caption": "",
                "position": 1009
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x9.jpeg",
                "caption": "",
                "position": 1036
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x10.png",
                "caption": "",
                "position": 1040
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x11.png",
                "caption": "",
                "position": 1043
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x12.jpg",
                "caption": "",
                "position": 1070
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x13.png",
                "caption": "",
                "position": 1074
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x14.png",
                "caption": "",
                "position": 1077
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x17.png",
                "caption": "",
                "position": 1095
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x18.png",
                "caption": "",
                "position": 1095
            }
        ]
    },
    {
        "header": "6Future Outlook",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix APrompts",
        "images": []
    },
    {
        "header": "Appendix BHyperparameters",
        "images": []
    },
    {
        "header": "Appendix CModel versions",
        "images": []
    },
    {
        "header": "Appendix DAPI access time",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09696/x19.png",
                "caption": "Figure 8:Examples illustrating that o1 pro fails primarily due to its inability to count.On the left, the model struggles with counting the number of bottles in a fairly simple and straightforward setting. On the right, the model faces a challenge in a more complex setup where counting the total number of breads requires carefully following each bread and keeping track of the breads counted so far.",
                "position": 2312
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/qualitatives/counting/barbari.png",
                "caption": "",
                "position": 2337
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x5.png",
                "caption": "Figure 9:Examples illustrating o1 pro failing with spatial reasoning.On the left, the model struggles to accurately resolve the number of circle pairs that are disjoint, while on the right, o1 pro incorrectly extracts the letters corresponding to each coloured arrow.",
                "position": 2347
            },
            {
                "img": "https://arxiv.org/html/2502.09696/",
                "caption": "",
                "position": 2372
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x21.png",
                "caption": "Figure 10:Examples illustrating two common failure modes.On the left, o1 pro struggles to read an analog clock. On the right, a simple counting problem is shown, related to the number of fingers on a hand.",
                "position": 2382
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/qualitatives/known-failure-modes/hand.png",
                "caption": "",
                "position": 2406
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x22.png",
                "caption": "Figure 11:Examples illustrating failures to follow and trace lines in images.On the left, there is a logic gate simulation that requires tracking inputs through different gates to predict the outcome. On the right, there is a simple graph-following problem where the model must navigate between nodes based on the input character.",
                "position": 2416
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/qualitatives/following-lines/graph.png",
                "caption": "",
                "position": 2440
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x23.png",
                "caption": "Figure 12:Examples illustrating o1 pro struggling with mirror reflections.On the left, the model miscounts the dumbbells; on the right, part of the watch screen is occluded, but its reflection remains visible—yet the model fails to read the time correctly from the mirror.",
                "position": 2465
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/qualitatives/known-failure-modes/clock.png",
                "caption": "",
                "position": 2489
            },
            {
                "img": "https://arxiv.org/html/2502.09696/x24.png",
                "caption": "Figure 13:Examples illustrating how o1 pro fails to accurately percieve understand a world model and simulate interactions within it.On the left, there is a sample from the game Pong, where the model needs to gather information and understand movement within the game. On the right, there is a navigation puzzle, in which the player must develop a strategy to effectively reach the exit.",
                "position": 2498
            },
            {
                "img": "https://arxiv.org/html/2502.09696/extracted/6201733/figures/qualitatives/simulating/Sokoban.jpg",
                "caption": "",
                "position": 2522
            }
        ]
    },
    {
        "header": "Appendix EFailure cases",
        "images": []
    }
]