[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/zero_class.png",
                "caption": "(a)General performance.",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/zero_class.png",
                "caption": "(a)General performance.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/com.png",
                "caption": "(b)Compositional performance",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x1.png",
                "caption": "(c)An illustration for the compositional understanding.",
                "position": 133
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related work",
        "images": []
    },
    {
        "header": "3.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/neg_data.png",
                "caption": "Figure 2.The overview of our proposed LLM-driven negative caption generation pipeline. We leverage the robust in-context learning capabilities of LLM to generate five types of hard negative captions.",
                "position": 213
            },
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/DeGLA.png",
                "caption": "Figure 3.The proposed training framework of DeGLA.",
                "position": 370
            }
        ]
    },
    {
        "header": "4.Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.16801/x2.png",
                "caption": "Figure 4.Zero-shot image-text retrieval performance comparison on MSCOCO and Flickr30k.",
                "position": 1167
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x2.png",
                "caption": "",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x3.png",
                "caption": "",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x4.png",
                "caption": "Figure 5.Performance trade off between compositional reasoning (average performance on VALSE, SugarCrepe, and ARO benchmarks) and zero-shot classification.",
                "position": 1187
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x5.png",
                "caption": "(a)Ablation ofλ1,λ2subscript𝜆1subscript𝜆2\\lambda_{1},\\lambda_{2}italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT",
                "position": 1190
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x5.png",
                "caption": "(a)Ablation ofλ1,λ2subscript𝜆1subscript𝜆2\\lambda_{1},\\lambda_{2}italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT",
                "position": 1193
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x6.png",
                "caption": "(b)Ablation ofλ3subscript𝜆3\\lambda_{3}italic_λ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT",
                "position": 1198
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x7.png",
                "caption": "(c)Ablation of hard negative types.",
                "position": 1203
            },
            {
                "img": "https://arxiv.org/html/2504.16801/extracted/6383958/images/case.png",
                "caption": "Figure 7.The case study between CLIP and DeGLA.Green ✔indicates true caption, whilered ✗indicates false caption. The bar chart represents the model’s prediction results.",
                "position": 1317
            }
        ]
    },
    {
        "header": "5.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.16801/x8.png",
                "caption": "Figure 8.Details of the prompt utilized for generating high-quality examples and negative captions",
                "position": 2477
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x9.png",
                "caption": "Figure 9.Rewritten examples generated by ChatGPT.",
                "position": 2622
            },
            {
                "img": "https://arxiv.org/html/2504.16801/x10.png",
                "caption": "Figure 10.Hard negative examples generated by LLaMA3.1-8B-instruct.",
                "position": 2634
            }
        ]
    },
    {
        "header": "Appendix ASupplementary Material",
        "images": []
    }
]