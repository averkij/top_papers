[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17612/x1.png",
                "caption": "Figure 1:Performance comparison of different sizes ofQwen2.5-Instructmodels[1]on the average accuracy of four factual reasoning tasks (HotpotQA[2], Bamboogle[3], MuSiQue[4], 2WikiMultiHopQA[5]) and four mathematical reasoning tasks (MATH[6], GSM-Hard[7], AIME[8], OlymMATH[9]). Distillation is done using the 32B model as the teacher and models ranging from 0.5B to 7B as students. Agent distillation consistently improves the performance of smaller models across both domains by enabling them to perform code execution and retrieve information for tasks adaptively. Full results are provided inTable 2.",
                "position": 126
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17612/x2.png",
                "caption": "Figure 2:Concept.Chain-of-Thought (CoT) distillation trains student models to mimic static reasoning traces from LLMs, but often fails when new knowledge or precise computation is needed at test time.\nOur proposed agent distillation instead teaches student models to think andact—e.g., retrieve facts or execute code—offering stronger generalization and better robustness to hallucination.",
                "position": 195
            }
        ]
    },
    {
        "header": "2Related works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Agent Distillation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17612/x3.png",
                "caption": "Figure 3:(a) First-thought Prefix:We prompt teacher with a CoT prompt to induce step-by-step reasoning. The first reasoning step is used as a prefix to generate an agentic trajectory, which is then distilled to a student agent to teach CoT-style reasoning initialization.(b) Self-consistent Action Generation:The agent generates multiple candidate actions and selects the one with consistent outcomes. Thoughts are omitted for brevity.",
                "position": 335
            }
        ]
    },
    {
        "header": "5Experimental setup",
        "images": []
    },
    {
        "header": "6Results",
        "images": []
    },
    {
        "header": "7Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17612/x4.png",
                "caption": "Figure 4:Performance comparison on the MATH subcategories and levelsbetween CoT and Agent distillation of 3B models. Left: Accuracy by problem category. Right: Accuracy by problem difficulty level. The results highlight thatftp¯¯¯¯ftp\\overline{\\underline{\\textsc{{ftp}}}}over¯ start_ARG under¯ start_ARG ftp end_ARG end_ARGimproves the performance of small agents in harder problems.",
                "position": 1168
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x5.png",
                "caption": "Figure 5:Comparison ofsag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARGin agents andself-consistency[65]in CoTfor 3B models: self-consistency in CoT is helpful in math tasks but not in factual tasks.",
                "position": 1200
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x5.png",
                "caption": "Figure 5:Comparison ofsag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARGin agents andself-consistency[65]in CoTfor 3B models: self-consistency in CoT is helpful in math tasks but not in factual tasks.",
                "position": 1203
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x6.png",
                "caption": "Figure 6:Generated token countscomparisons in 3B models. For factual reasoning tasks (HotpotQA, MuSiQue), agent generates more tokens than CoT. In contrast, for math reasoning tasks (MATH, AIME), CoT generates slightly more tokens than agent.",
                "position": 1208
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x7.png",
                "caption": "Figure 7:Impact of Self-consistent Action Generation(sag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARG) on code generation errors across models and 3\nmath datasets.sag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARGconsistently reduces code parse (dark) and code execution (light) errors, especially for smaller models (0.5B) and the AIME dataset.",
                "position": 1239
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x7.png",
                "caption": "Figure 7:Impact of Self-consistent Action Generation(sag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARG) on code generation errors across models and 3\nmath datasets.sag¯¯¯¯sag\\overline{\\underline{\\textsc{{sag}}}}over¯ start_ARG under¯ start_ARG sag end_ARG end_ARGconsistently reduces code parse (dark) and code execution (light) errors, especially for smaller models (0.5B) and the AIME dataset.",
                "position": 1242
            },
            {
                "img": "https://arxiv.org/html/2505.17612/x8.png",
                "caption": "Figure 8:Average retrieval tool callsacross three model sizes and datasets. Harder tasks and larger sizes make agents use more retrieval calls.",
                "position": 1248
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitations",
        "images": []
    },
    {
        "header": "Appendix BBroader impacts",
        "images": []
    },
    {
        "header": "Appendix CImplementation details",
        "images": []
    },
    {
        "header": "Appendix DAdditional analysis",
        "images": []
    }
]