[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18092/x1.png",
                "caption": "",
                "position": 76
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x2.png",
                "caption": "",
                "position": 80
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x3.png",
                "caption": "",
                "position": 84
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x4.png",
                "caption": "(a)The input compression rate and performance gain when different LLMs are cascaded withQwenLong-CPRS.",
                "position": 89
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x4.png",
                "caption": "(a)The input compression rate and performance gain when different LLMs are cascaded withQwenLong-CPRS.",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x5.png",
                "caption": "(b)Performance of Qwen2.5-32b-instruct with different context management methods.",
                "position": 97
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18092/x6.png",
                "caption": "Figure 2:The concept ofdynamic context optimization, which aims to enhance context processing efficiency by maximizing information density. Given a long-context input, this paradigm dynamically compresses it into query-specific content at varying granularities, facilitating concise and accurate information extraction for different user queries. For instance,keywordsforsearch queries,sentencesforquestion answering, andparagraphsforsummarization.",
                "position": 120
            }
        ]
    },
    {
        "header": "2QwenLong-CPRS",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18092/x7.png",
                "caption": "(a)The model architecture ofQwenLong-CPRS.",
                "position": 206
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x7.png",
                "caption": "(a)The model architecture ofQwenLong-CPRS.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x8.png",
                "caption": "(b)The workflow of generative LLMs cascadingQwenLong-CPRSin this paper.",
                "position": 214
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18092/x9.png",
                "caption": "Figure 4:Performance ofQwenLong-CPRSin NIAH test with input length is upto 1M.",
                "position": 1691
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x10.png",
                "caption": "Figure 5:Comparative performance analysis of LLMs with and withoutQwenLong-CPRSintegration. Numerical values in parentheses indicate each modelâ€™s maximum input capacity.",
                "position": 1697
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x11.png",
                "caption": "Figure 6:Performance comparison between RAG andQwenLong-CPRSacross varying retrieved token quantities",
                "position": 1710
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x12.png",
                "caption": "Figure 7:System latency of different context management methods with various input length.",
                "position": 1723
            }
        ]
    },
    {
        "header": "5Conclusion and Future Works",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18092/x13.png",
                "caption": "Figure 8:Example case #1: multi-value Needle-in-a-Haystack test.",
                "position": 2731
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x14.png",
                "caption": "Figure 9:Example case #2: English multi-hop QA.",
                "position": 2734
            },
            {
                "img": "https://arxiv.org/html/2505.18092/x15.png",
                "caption": "Figure 10:Example case #2: Contract element extraction.",
                "position": 2737
            }
        ]
    },
    {
        "header": "Appendix ACase Study",
        "images": []
    }
]