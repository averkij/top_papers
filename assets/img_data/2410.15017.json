[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.15017/extracted/5939010/figures/intro_diag_v2.png",
                "caption": "Figure 1:An overview of speech tokenization approaches using discrete acoustic, semantic, and contextual tokens. DM-Codec integrates these multimodal representations for robust speech tokenization, learning comprehensive speech representations.",
                "position": 82
            }
        ]
    },
    {
        "header": "2Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.15017/extracted/5939010/figures/tokenizer_v4.png",
                "caption": "Figure 2:DM-Codec framework consists of an encoder that extracts latent representations from the input speech signal. These latent vectors are subsequently quantized using a Residual Vector Quantizer (RVQ). We designed two distinct distillation approaches: (i) distillation from a language model, and (ii) a combined distillation from both a language model (LM) and a speech model (SM). These approaches integrate acoustic, semantic, and contextual representations into the quantized vectors to improve speech representation for downstream tasks.",
                "position": 135
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Experimental Results and Discussion",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Limitations and Broader Impact",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]