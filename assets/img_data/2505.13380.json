[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x1.png",
                "caption": "Figure 1:The evolution of zero-shot performance averaged over nine visual instruction tuning tasks throughout training of various SMoE algorithms using a 5.1B parameters backbone.",
                "position": 157
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2CompeteSMoE",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x2.png",
                "caption": "(a)The router learns the competition policy.",
                "position": 210
            },
            {
                "img": "https://arxiv.org/html/2505.13380/x2.png",
                "caption": "(a)The router learns the competition policy.",
                "position": 213
            },
            {
                "img": "https://arxiv.org/html/2505.13380/x3.png",
                "caption": "(b)Normal routing using the router.",
                "position": 218
            }
        ]
    },
    {
        "header": "3Statistical Guarantee of the Competition Mechanism",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x4.png",
                "caption": "Figure 3:Comparison of expert change rates at different training stages. Lower values are better.",
                "position": 939
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix ASummary of Main Notations",
        "images": []
    },
    {
        "header": "Appendix BBroader Impact",
        "images": []
    },
    {
        "header": "Appendix CAdaptive Layer-wise Competition Control",
        "images": []
    },
    {
        "header": "Appendix DEffectiveness of Activation Functions in the Competition Mechanism",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x5.png",
                "caption": "Figure 4:Performance comparison of different activation functions used within the Competition Mechanism over 9 benchmarks.",
                "position": 1410
            }
        ]
    },
    {
        "header": "Appendix EEvaluation of Mean and Norm Strategies for Competition Mechanism",
        "images": []
    },
    {
        "header": "Appendix FEvaluation of Distillation Loss Effectiveness",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x6.png",
                "caption": "Figure 5:Learning performance of‚Ñíùíüsubscript‚Ñíùíü\\mathcal{L}_{\\mathcal{D}}caligraphic_L start_POSTSUBSCRIPT caligraphic_D end_POSTSUBSCRIPTand‚Ñíùíüwo-regsubscript‚Ñísubscriptùíüwo-reg\\mathcal{L}_{{\\mathcal{D}}_{\\text{wo-reg}}}caligraphic_L start_POSTSUBSCRIPT caligraphic_D start_POSTSUBSCRIPT wo-reg end_POSTSUBSCRIPT end_POSTSUBSCRIPTmeasured by the Level Learning metric at every 20% of training steps on the MMBench-EN benchmark.",
                "position": 1464
            },
            {
                "img": "https://arxiv.org/html/2505.13380/x6.png",
                "caption": "Figure 5:Learning performance of‚Ñíùíüsubscript‚Ñíùíü\\mathcal{L}_{\\mathcal{D}}caligraphic_L start_POSTSUBSCRIPT caligraphic_D end_POSTSUBSCRIPTand‚Ñíùíüwo-regsubscript‚Ñísubscriptùíüwo-reg\\mathcal{L}_{{\\mathcal{D}}_{\\text{wo-reg}}}caligraphic_L start_POSTSUBSCRIPT caligraphic_D start_POSTSUBSCRIPT wo-reg end_POSTSUBSCRIPT end_POSTSUBSCRIPTmeasured by the Level Learning metric at every 20% of training steps on the MMBench-EN benchmark.",
                "position": 1467
            }
        ]
    },
    {
        "header": "Appendix GFurther Analysis of Router Behavior",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x7.png",
                "caption": "Figure 6:Entropy analysis of expert selection frequency across perception and reasoning tasks. Lower entropy indicates higher specialization in expert routing.",
                "position": 1530
            },
            {
                "img": "https://arxiv.org/html/2505.13380/x8.png",
                "caption": "Figure 7:Layer-wise entropy of expert weight distributions for CompeteSMoE and SMoE across three tasks: Real-World Perception, Real-World Reasoning, and Mathematical Reasoning.",
                "position": 1536
            }
        ]
    },
    {
        "header": "Appendix HAblation Study",
        "images": []
    },
    {
        "header": "Appendix IHyperparameter Setting",
        "images": []
    },
    {
        "header": "Appendix JTraining Curves on Vision-Language Benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13380/x9.png",
                "caption": "Figure 8:Training curves of CompeteSMoE compared to five advanced MoE algorithms on vision-language benchmarks.",
                "position": 1924
            }
        ]
    },
    {
        "header": "Appendix KAdditional Theoretical Results",
        "images": []
    },
    {
        "header": "Appendix LProof of Theoretical Results",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]