[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06703/x1.png",
                "caption": "Figure 1:Comparison between the performance of smaller LLMs compute-optimal TTS and that of larger LLMs CoT on MATH-500 and AIME24.(a) & (d)Llama-3.2-3B-Instruct surpasses Llama-3.1-405B-Instruct and GPT-4o on MATH-500 and AIME24;(b) & (e)DeepSeek-R1-Distill-1.5B outperforms o1-preview on MATH-500 and AIME24, and surpasses o1-mini on MATH-500;(c) & (f)DeepSeek-R1-Distill-7B beats o1 on MATH-500 and AIME24, and exceeds DeepSeek-R1 on AIME24.",
                "position": 168
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Setup & Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06703/x2.png",
                "caption": "Figure 2:Comparison of different external TTS methods.",
                "position": 243
            }
        ]
    },
    {
        "header": "3Rethinking Compute-Optimal Test-Time Scaling",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06703/x3.png",
                "caption": "Figure 3:Distribution of Pass@1 accuracy of Qwen2.5-72B-Instruct on MATH-500, divided into five bins.",
                "position": 322
            }
        ]
    },
    {
        "header": "4How to Scale Test-Time Compute Optimally?",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06703/x4.png",
                "caption": "Figure 4:Performance of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct on MATH-500 with different PRMs and TTS strategies.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x5.png",
                "caption": "Figure 5:Performance of Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct on AIME24 with different PRMs and TTS strategies.",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x6.png",
                "caption": "Figure 6:The relationship between TTS performance and process supervision abilities of different PRMs on MATH, where the size of each circle represents the number of parameters of the PRM and the curve represents the fitted function.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x7.png",
                "caption": "Figure 7:TTS performance of policy models with parameters from 0.5B to 72B on MATH-500 with different scaling methods.",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x8.png",
                "caption": "Figure 8:TTS performance of three Llama policy models on MATH-500 with three difficulty levels.",
                "position": 449
            }
        ]
    },
    {
        "header": "5Results for Compute-Optimal Test-Time Scaling",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion & Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Template for Test-Time Scaling",
        "images": []
    },
    {
        "header": "Appendix BFull Results of Test-Time Scaling with Different Policy Models, PRMs, and Scaling Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06703/x9.png",
                "caption": "Figure 9:TTS performance of three Llama policy models on MATH-500 with different difficulty levels.",
                "position": 2125
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x10.png",
                "caption": "Figure 10:TTS performance of different policy models on MATH-500 with different PRMs and scaling strategies.",
                "position": 2128
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x11.png",
                "caption": "Figure 11:TTS performance of different policy models on AIME24 with different PRMs and scaling strategies.",
                "position": 2131
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x12.png",
                "caption": "Figure 12:Toy case of beam search with RLHFlow-Mistral-PRM-8B and RLHFlow-Deepseek-PRM-8B.",
                "position": 2149
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x13.png",
                "caption": "Figure 13:TTS case of Over-Criticism.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x14.png",
                "caption": "Figure 14:TTS case of Error Neglect.",
                "position": 2155
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x15.png",
                "caption": "Figure 15:TTS case of Error Neglect.",
                "position": 2158
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x16.png",
                "caption": "Figure 16:TTS case of Error Localization Bias.",
                "position": 2161
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x17.png",
                "caption": "Figure 17:TTS case of Scoring Bias.",
                "position": 2164
            },
            {
                "img": "https://arxiv.org/html/2502.06703/x18.png",
                "caption": "Figure 18:TTS case of Scoring Bias.",
                "position": 2167
            }
        ]
    },
    {
        "header": "Appendix CCases",
        "images": []
    }
]