[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x1.png",
                "caption": "",
                "position": 94
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x2.png",
                "caption": "Figure 2:Overview of our MoDec-GS framework.To effectively train dynamic 3D Gaussians with complex motion, we introduce Global-to-Local Motion Decomposition (GLMD) (Sec4.1). We first train a Global Canonical Scaffold-GS (Global CS) with entire frames, and apply a Global Anchor Deformation (GAD) to Local Canonical Scaffold-GS (Local CS) dedicated to represent its corresponding temporal segment (Sec4.2). Next, to finely adjust the remaining local motion, we apply Local Gaussian Deformation (LGD) which explicitly deforms the reconstructed 3D Gaussians with a shared hexplane (Sec4.3). During the training, Temporal Interval Adjustment (TIA) is performed, optimizing the temporal interval into a non-uniform interval that adopts to the scene‚Äôs level of motion (Sec4.4).",
                "position": 169
            }
        ]
    },
    {
        "header": "4Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x3.png",
                "caption": "Figure 3:Concept and effect of 2-stage deformation.For representing a complex motion of 3D Gaussians, a global movement over time intervals can be more efficiently handled through deformation of anchor itself. In contrast, subtle motions of individual 3D Gaussians within a time interval can be effectively addressed by explicit deformation of each Gaussian.",
                "position": 294
            },
            {
                "img": "https://arxiv.org/html/2501.03714/x4.png",
                "caption": "Figure 4:Qualitative results comparison on three datasets[16,45,58].The yellow boxes highlight areas where the proposed method achieves notable visual quality improvements, and the storage for the corresponding sequence is displayed below each rendered patch.",
                "position": 586
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x5.png",
                "caption": "Figure 5:TIA effectiveness.",
                "position": 811
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BDemo Videos",
        "images": []
    },
    {
        "header": "Appendix CComparison with NeRF-extension frameworks",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x6.png",
                "caption": "Figure 6:Performance comparison visualization graph.Thexùë•xitalic_x-axis represents rendering speed (FPS)‚Üë‚Üë\\uparrow‚Üë, and theyùë¶yitalic_y-axis indicates PSNR‚Üë‚Üë\\uparrow‚Üë. Each framework is depicted as a bubble, with the size of the bubble representing the model storage size (MB)‚Üì‚Üì\\downarrow‚Üì.",
                "position": 1757
            }
        ]
    },
    {
        "header": "Appendix DDetailed Experimental Results",
        "images": []
    },
    {
        "header": "Appendix EAblation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.03714/x7.png",
                "caption": "Figure 7:Visualization of GLMD.Forcut-lemonscene in HyperNeRF[45]dataset, the rendered patch of Global CS, Local CS, and each time stamp are presented for a fixed camera viewpoint. We also illustrate the optical flow color map between those patches to observe the captured motion at each deformation stage. At GAD stage, deformation in mainly found near objects with dominant motion (e.g., the lemon and knife), and the overall color trends are similar, indicating a similar global motion direction. In contrast, at the LGD stage, motion is observed across the entire scene, with relatively more diverse range of motion directions.",
                "position": 2590
            },
            {
                "img": "https://arxiv.org/html/2501.03714/x8.png",
                "caption": "Figure 8:Failure case: HyperNeRF-broom.In the face of challenges in reconstructing dynamic scenes from monocular video, there are limitations in adequately representing thin and highly intricate textured objects.",
                "position": 2593
            }
        ]
    },
    {
        "header": "Appendix FLimitations and Future Works",
        "images": []
    }
]