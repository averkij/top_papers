[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x1.png",
                "caption": "Figure 1:The main pipeline ofLLaMA-Berry, whereSisubscriptùëÜùëñS_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTstand for problem-solving solutions andCisubscriptùê∂ùëñC_{i}italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTstands for critiques. The pipeline consists of four phases detailed in Section2.2, including selection, expansion, evaluation, and backpropagation.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x2.png",
                "caption": "Figure 2:Preference prediction process of PPRM and global quantile score based on Enhanced Borda Count method.",
                "position": 159
            }
        ]
    },
    {
        "header": "3Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x3.png",
                "caption": "Figure 3:Scaling of inference-time rollouts",
                "position": 807
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitation",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AHyper-paramerer settings",
        "images": []
    },
    {
        "header": "Appendix BDetails of Grading and Metrics",
        "images": []
    },
    {
        "header": "Appendix CDetails of PPRM Trainging",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x4.png",
                "caption": "Figure A1:Dataset Construction of PPRM.",
                "position": 1877
            },
            {
                "img": "https://arxiv.org/html/2410.02884/x5.png",
                "caption": "Figure A2:RLHF training of PPRM.",
                "position": 1906
            }
        ]
    },
    {
        "header": "Appendix DDetails of Berry-Tree Inference Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x6.png",
                "caption": "Figure A3:Architecture design ofBerry-Tree",
                "position": 1940
            }
        ]
    },
    {
        "header": "Appendix EScaling Study on Inference-time Token Overheads",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x7.png",
                "caption": "Figure A4:Average token consumption comparison across datasets, error bar stands for standard deviation.",
                "position": 1973
            },
            {
                "img": "https://arxiv.org/html/2410.02884/x8.png",
                "caption": "Figure A5:Average token consumption for LLaMA-3.1-8B-Instruct across olympiad-level datasets, error bar stands for standard deviation.",
                "position": 1976
            }
        ]
    },
    {
        "header": "Appendix FFuture Work",
        "images": []
    },
    {
        "header": "Appendix GCase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02884/x9.png",
                "caption": "Figure A6:Prompts for LLaMA-3.1-8B-Instruct",
                "position": 1996
            },
            {
                "img": "https://arxiv.org/html/2410.02884/x10.png",
                "caption": "Figure A7:Problem-solving example",
                "position": 1999
            }
        ]
    },
    {
        "header": "Appendix HConvergence Analysis of the Enhanced Borda Count (EBC) Method",
        "images": []
    },
    {
        "header": "Appendix IPseudo-code of main Algorithms",
        "images": []
    }
]