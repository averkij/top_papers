[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15776/x1.png",
                "caption": "Figure 1:Illustration of the CQR task. Given a query and its context, the rewriter aims to reformulate the query into a stand-alone form, which facilitates the off-the-shelf retriever in finding the most relevant passage.",
                "position": 134
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3ConvSearch-R1",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15776/x2.png",
                "caption": "Figure 2:Overview of ConvSearch-R1. In Stage 1, we self-distilled a set of high-quality data using few-shot learning and obtained the corresponding SFT model. In Stage 2, we further improved the rewriterâ€™s performance via RL by refining the reward function.",
                "position": 211
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15776/x3.png",
                "caption": "(a)Comparison on BM25",
                "position": 1163
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x3.png",
                "caption": "(a)Comparison on BM25",
                "position": 1166
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x4.png",
                "caption": "(b)Comparison on ANCE",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x5.png",
                "caption": "(a)Comparison on BM25",
                "position": 1178
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x5.png",
                "caption": "(a)Comparison on BM25",
                "position": 1181
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x6.png",
                "caption": "(b)Comparison on ANCE",
                "position": 1186
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x7.png",
                "caption": "(a)Comparison on TopiOCQA",
                "position": 1335
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x7.png",
                "caption": "(a)Comparison on TopiOCQA",
                "position": 1338
            },
            {
                "img": "https://arxiv.org/html/2505.15776/x8.png",
                "caption": "(b)Comparison on QReCC",
                "position": 1343
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AConvSearch-R1 VS Prior Works",
        "images": []
    },
    {
        "header": "Appendix BData Collection",
        "images": []
    },
    {
        "header": "Appendix CResults on Llama2-7B",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15776/x9.png",
                "caption": "Figure 8:Comparison of Reward Sparsity.",
                "position": 2154
            }
        ]
    },
    {
        "header": "Appendix DRank-Incentive Reward",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15776/x10.png",
                "caption": "Figure 9:Comparison of ConvSearch-R1 with previous works.",
                "position": 2362
            }
        ]
    },
    {
        "header": "Appendix EExperimental Details",
        "images": []
    }
]