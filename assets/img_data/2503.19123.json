[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19123/x1.png",
                "caption": "Figure 1:Limitation in Utilizing Better LLMs as Teacher Models due to Vocabulary Mismatch: Qwen2.5-Math(Yang et¬†al.,2024)outperforms Llemma(Azerbayev et¬†al.,2024)on math evaluation suite, but shares only 6.32% of its vocabulary with the student model, TinyLlama(Zhang et¬†al.,2024a).",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2503.19123/x2.png",
                "caption": "Figure 2:Overview of¬†Vocabulary-agnostic Teacher Guided Language Modeling.Left: Teacher models (such as Qwen, Mistral, DeepSeek) produce token sequences that differ from those of the student model (TinyLlama), leading to misalignment.Middle: To address this, Token-level Lexical Mapping establishes a one-to-many mapping from each student token to corresponding teacher tokens.Right: To overcome logit distribution divergence, the mapped teacher token loss is utilized to guide the training of the student model.",
                "position": 155
            }
        ]
    },
    {
        "header": "2Preliminary Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19123/x3.png",
                "caption": "Figure 3:Comparison of Sequence Overlap by Granularity.\nSequence overlap between the corresponding chunks of student (TinyLlama) and teacher models differs significantly across varying levels of granularity (Number of Chunks). IoU (Intersection over Union) refers to the overlap ratio between the two sequences, while IoS (Intersection over Student sequence) denotes the coverage of the student sequence by the teacher sequence.",
                "position": 213
            }
        ]
    },
    {
        "header": "3Vocabulary-agnostic Teacher Guided Language Modeling",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19123/x4.png",
                "caption": "Figure 4:Performance Comparison Across Various Teacher Models. VocAgnoLM¬†consistently outperforms logit distribution-based baselines.",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2503.19123/x5.png",
                "caption": "Figure 5:Comparison of Performance Improvements Across Different Teachers. VocAgnoLM¬†effectively mitigates vocabulary mismatch and leverages higher-performing teacher models to achieve significant performance gains, outperforming logit distribution-based baselines.",
                "position": 779
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19123/x6.png",
                "caption": "Figure 6:Correlation Between Performance and Sequence Alignment. Chunking alignment initially improves performance as the granularity increases, but performance sharply declines when the overlap (Char-level IoU and IoS) decreases significantly. Token-level Lexical Alignment¬†maintains high IoS and achieves superior performance with fine-grained alignment.",
                "position": 1023
            }
        ]
    },
    {
        "header": "7Related Works",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATeacher Model Details",
        "images": []
    },
    {
        "header": "Appendix BFurther Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19123/x7.png",
                "caption": "(a)Performance of student model guided by various teacher models based on different Top-K thresholds",
                "position": 2182
            },
            {
                "img": "https://arxiv.org/html/2503.19123/x7.png",
                "caption": "(a)Performance of student model guided by various teacher models based on different Top-K thresholds",
                "position": 2185
            },
            {
                "img": "https://arxiv.org/html/2503.19123/x8.png",
                "caption": "(b)Performance analysis ofŒªùúÜ\\lambdaitalic_Œªon ULD(Boizard et¬†al.,2025).",
                "position": 2190
            },
            {
                "img": "https://arxiv.org/html/2503.19123/x9.png",
                "caption": "Figure 8:Examples of teacher guidance demonstrating how teacher models influence the training of TinyLLaMA(Zhang et¬†al.,2024a). Orange solid arrows represent the guidance provided by the teacher model, while gray dashed arrows indicate tokens that were not included in the top-k threshold by teacher guidance.",
                "position": 2205
            }
        ]
    },
    {
        "header": "Appendix CTeacher Guidance Examples",
        "images": []
    }
]