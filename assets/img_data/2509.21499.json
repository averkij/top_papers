[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21499/x1.png",
                "caption": "Figure 1:We construct parallel code and natural language instruction datasets, apply targeted modifications (rule-based and generative-based perturbations, single programming language ablations), and fine-tune a separate LLM on each modified dataset. We then evaluate the resulting models across general natural language, code, and math reasoning tasks.",
                "position": 237
            }
        ]
    },
    {
        "header": "4Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21499/x2.png",
                "caption": "Figure 2:Performance (with stderr bars) of Qwen3-4B-Base across zero-shot, full code finetuning (code-ft), full natural language finetuning (nl-ft), and 50-50 code to NL data ratio finetuning (mixed ft). Incorporating code improves performance across tasks.",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x3.png",
                "caption": "Figure 3:Aggregated performance (with stderr bars) under structural perturbations (e.g. removing whitespace) vs. semantics perturbations (e.g. modifying the comments) of Qwen3-4B-Base. Semantic perturbations tend to be more harmful to performance than semantic ones.",
                "position": 653
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x4.png",
                "caption": "Figure 4:Aggregated performance (with stderr bars) under levels of explicitness of code structure (less explicit going from runnable code to NL procedure) of Qwen3-8B-Base. Certain algorithmic and graphical abstractions benefit reasoning.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x5.png",
                "caption": "Figure 5:Aggregated performance (with stderr bars) of Qwen3-0.6B-Base with various of token counts wrt to unperturbed code. Reductions can perform comparable or even better than the baseline.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x6.png",
                "caption": "Figure 6:Aggregated performance of Qwen3-8B-Base (with stderr bars), depending on how much the perturbed code data is readable to humans. Low-interpretability with misleading signals can match or perform better than other configurations.",
                "position": 662
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x7.png",
                "caption": "Figure 7:Performance (with stderr bars) of Qwen3-1.7B.Top:grouped by abstraction level (low-system, intermediate, high-scripting). Low-system and intermediate languages outperform on math.Bottom:individual programming languages. Python aligns best with NL, Rust leads on math.",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x7.png",
                "caption": "",
                "position": 712
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x8.png",
                "caption": "",
                "position": 717
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.21499/x9.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2150
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x9.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2153
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x10.png",
                "caption": "(b)Qwen3-0.6B",
                "position": 2159
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x11.png",
                "caption": "(c)Qwen3-1.7B-Base",
                "position": 2165
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x12.png",
                "caption": "(d)Qwen3-1.7B",
                "position": 2171
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x13.png",
                "caption": "(e)Qwen3-8B-Base",
                "position": 2177
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x14.png",
                "caption": "(a)Llama-3.2-1B",
                "position": 2190
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x14.png",
                "caption": "(a)Llama-3.2-1B",
                "position": 2193
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x15.png",
                "caption": "(b)Llama-3.2-3B",
                "position": 2199
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x16.png",
                "caption": "(a)gemma-3-1b",
                "position": 2212
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x16.png",
                "caption": "(a)gemma-3-1b",
                "position": 2215
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x17.png",
                "caption": "(b)gemma-3-4b",
                "position": 2221
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x18.png",
                "caption": "(a)OLMo-2-0425-1B",
                "position": 2234
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x18.png",
                "caption": "(a)OLMo-2-0425-1B",
                "position": 2237
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x19.png",
                "caption": "(b)OLMo-2-1124-7B",
                "position": 2243
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x20.png",
                "caption": "(a)SmolLM2-360M",
                "position": 2256
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x20.png",
                "caption": "(a)SmolLM2-360M",
                "position": 2259
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x21.png",
                "caption": "(b)SmolLM2-1.7B",
                "position": 2265
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x22.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2278
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x22.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2281
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x23.png",
                "caption": "(b)Qwen3-1.7B-Base",
                "position": 2287
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x24.png",
                "caption": "Figure 23:Task performance under perturbations aggregated by structure vs semantics across Qwen3-Base models (0.6B (top), 1.7B (mid), 8B (bottom)).",
                "position": 2304
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x25.png",
                "caption": "",
                "position": 2308
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x26.png",
                "caption": "",
                "position": 2310
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x27.png",
                "caption": "Figure 24:Task performance under perturbations aggregated by structure vs semantics across Llama-3.2 models (1B (top), 3B (bottom)).",
                "position": 2320
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x28.png",
                "caption": "",
                "position": 2324
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x29.png",
                "caption": "Figure 25:Task performance under perturbations aggregated by structure vs semantics across Gemma-3 models (1B (top), 4B (bottom)).",
                "position": 2334
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x30.png",
                "caption": "",
                "position": 2338
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x31.png",
                "caption": "Figure 26:Additional performance of OLMo-2-0425-1B aggregated by structure vs semantics across tasks.",
                "position": 2348
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x32.png",
                "caption": "Figure 27:Task performance under perturbations aggregated by structure vs semantics across SmolLM2 models (360M (top), 1.7B (bottom)).",
                "position": 2357
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x33.png",
                "caption": "",
                "position": 2361
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x34.png",
                "caption": "Figure 28:Task performance under perturbations aggregated by explicitness of code structure across Qwen3-Base models (0.6B (top), 1.7B (mid), 8B (bottom)).",
                "position": 2375
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x35.png",
                "caption": "",
                "position": 2379
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x36.png",
                "caption": "",
                "position": 2381
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x37.png",
                "caption": "Figure 29:Task performance under perturbations aggregated by explicitness of code structure across Llama-3.2 models (1B (top), 3B (bottom)).",
                "position": 2391
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x38.png",
                "caption": "",
                "position": 2395
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x39.png",
                "caption": "Figure 30:Task performance under perturbations aggregated by explicitness of code structure across Gemma-3 models (1B (top), 4B (bottom)).",
                "position": 2405
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x40.png",
                "caption": "",
                "position": 2409
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x41.png",
                "caption": "Figure 31:Additional performance of OLMo-2-0425-1B aggregated by explicitness of code structure across tasks.",
                "position": 2419
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x42.png",
                "caption": "Figure 32:Task performance under perturbations aggregated by explicitness of code structure across SmolLM2 models (360M (top), 1.7B (bottom)).",
                "position": 2428
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x43.png",
                "caption": "",
                "position": 2432
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x44.png",
                "caption": "Figure 33:Task performance under perturbations aggregated by relative information density across Qwen3-Base models (0.6B (top), 1.7B (mid), 8B (bottom)).",
                "position": 2446
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x45.png",
                "caption": "",
                "position": 2450
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x46.png",
                "caption": "",
                "position": 2452
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x47.png",
                "caption": "Figure 34:Task performance under perturbations aggregated by relative information density across Llama-3.2 models (1B (top), 3B (bottom)).",
                "position": 2462
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x48.png",
                "caption": "",
                "position": 2466
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x49.png",
                "caption": "Figure 35:Task performance under perturbations aggregated by relative information density across Gemma-3 models (1B (top), 4B (bottom)).",
                "position": 2476
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x50.png",
                "caption": "",
                "position": 2480
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x51.png",
                "caption": "Figure 36:Additional performance of OLMo-2-0425-1B aggregated by relative information density across tasks.",
                "position": 2490
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x52.png",
                "caption": "Figure 37:Task performance under perturbations aggregated by relative information density across SmolLM2 models (360M (top), 1.7B (bottom)).",
                "position": 2499
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x53.png",
                "caption": "",
                "position": 2503
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x54.png",
                "caption": "Figure 38:Task performance under perturbations aggregated by human interpretability across Qwen3-Base models (0.6B (top), 1.7B (mid), 8B (bottom)).",
                "position": 2517
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x55.png",
                "caption": "",
                "position": 2521
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x56.png",
                "caption": "",
                "position": 2523
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x57.png",
                "caption": "Figure 39:Task performance under perturbations aggregated by human interpretability across Llama-3.2 models (1B (top), 3B (bottom)).",
                "position": 2533
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x58.png",
                "caption": "",
                "position": 2537
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x59.png",
                "caption": "Figure 40:Task performance under perturbations aggregated by human interpretability across Gemma-3 models (1B (top), 4B (bottom)).",
                "position": 2547
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x60.png",
                "caption": "",
                "position": 2551
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x61.png",
                "caption": "Figure 41:Additional performance of OLMo-2-0425-1B aggregated by human interpretability across tasks.",
                "position": 2561
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x62.png",
                "caption": "Figure 42:Task performance under perturbations aggregated by human interpretability across SmolLM2 models (360M (top), 1.7B (bottom)).",
                "position": 2570
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x63.png",
                "caption": "",
                "position": 2574
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x64.png",
                "caption": "Figure 43:All perturbations across Qwen3-Base models (0.6B (top), 1.7B (mid), 8B (bottom)).",
                "position": 2588
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x65.png",
                "caption": "",
                "position": 2592
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x66.png",
                "caption": "",
                "position": 2594
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x67.png",
                "caption": "Figure 44:All perturbations across Llama-3.2 models (1B (top), 3B (bottom)).",
                "position": 2604
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x68.png",
                "caption": "",
                "position": 2608
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x69.png",
                "caption": "Figure 45:All perturbations across Gemma-3 models (1B (top), 4B (bottom)).",
                "position": 2618
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x70.png",
                "caption": "",
                "position": 2622
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x71.png",
                "caption": "Figure 46:OLMo-2-0425-1B with all perturbations.",
                "position": 2632
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x72.png",
                "caption": "Figure 47:All perturbations across SmolLM2 models (360M (top), 1.7B (bottom)).",
                "position": 2641
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x73.png",
                "caption": "",
                "position": 2645
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x74.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2659
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x74.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2662
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x75.png",
                "caption": "(b)Qwen3-0.6B",
                "position": 2668
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x76.png",
                "caption": "(c)Qwen3-1.7B",
                "position": 2674
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x77.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2681
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x77.png",
                "caption": "(a)Qwen3-0.6B-Base",
                "position": 2684
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x78.png",
                "caption": "(b)Qwen3-0.6B",
                "position": 2690
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x79.png",
                "caption": "(c)Qwen3-1.7B",
                "position": 2696
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x80.png",
                "caption": "(a)Grouped results (low-system, intermediate, high-scripting)",
                "position": 2709
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x80.png",
                "caption": "(a)Grouped results (low-system, intermediate, high-scripting)",
                "position": 2712
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x81.png",
                "caption": "(b)Per-language results",
                "position": 2718
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x82.png",
                "caption": "(a)Grouped results (low-system, intermediate, high-scripting)",
                "position": 2732
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x82.png",
                "caption": "(a)Grouped results (low-system, intermediate, high-scripting)",
                "position": 2735
            },
            {
                "img": "https://arxiv.org/html/2509.21499/x83.png",
                "caption": "(b)Per-language results",
                "position": 2741
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]