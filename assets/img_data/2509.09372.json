[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/Figures/facon1.png",
                "caption": "",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x1.png",
                "caption": "Figure 1:Characteristics of VLA-Adapter. ‚Äú‚Üì\\downarrow‚Äù is that smaller values are better, and vice versa. Our paradigm can effectively obtain the SOTA-level VLA model using a tiny-scale backbone.",
                "position": 170
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x2.png",
                "caption": "Figure 2:Existing representative bridge paradigms from VL to A.",
                "position": 241
            }
        ]
    },
    {
        "header": "3VLA-Adapter Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x3.png",
                "caption": "Figure 3:The proposed VLA framework. The key components are the effective condition exploration and Attention design. ‚ÄúAttention‚Äù specifically includes cross attention with conditions and self attention with itself. In the ‚ÄúUnified VLA-Adapter Framework‚Äù, ‚ÄúAttention‚Äù is the Bridge Attention as shown in Section3.3. Four conditions about ‚Äúlayer‚Äù and ‚Äútype‚Äù are given on the right.",
                "position": 256
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x4.png",
                "caption": "Figure 4:Comparison of four conditions in the VLA-Adapter framework on the LIBERO-Long. Blue and Green lines are single-layerùíût‚Ñõ\\mathcal{{\\cal C}}_{t}^{\\mathcal{R}}and single-layerùíûtùíú‚Äãùí¨\\mathcal{{\\cal C}}_{t}^{\\mathcal{AQ}}, as in Figure3a) and3b). Blue and Green columns are all-layerùíût‚Ñõ\\mathcal{{\\cal C}}_{t}^{\\mathcal{R}}and all-layerùíûtùíú‚Äãùí¨\\mathcal{{\\cal C}}_{t}^{\\mathcal{AQ}}, as in Figure3c) and3d). The detailed results are shown in AppendixC. Please note: the number of ActionQuery is 64 here. Its number is variable, similar to MetaQueries(Pan et¬†al.,2025)in MLLM research; we will explore it in Section4.5.",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x5.png",
                "caption": "Figure 5:The Policy with Bridge Attention. The Policy parameters are only 97M when the backbone is Qwen2.5-0.5B. Each-layerùíût‚Ñõ\\mathcal{{\\cal C}}_{t}^{\\mathcal{R}}andùíûtùíú‚Äãùí¨\\mathcal{{\\cal C}}_{t}^{\\mathcal{AQ}}are integrated in Bridge Attention with the corresponding-layer action latent. Bridge Attention maps VL to Action to the greatest extent. The degree ofùíût‚Ñõ\\mathcal{{\\cal C}}_{t}^{\\mathcal{R}}injection is learnable, ensuring the performance and stability of training.",
                "position": 395
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x6.png",
                "caption": "Figure 6:Real-world system Synria Alicia-D and the task examples.",
                "position": 1154
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x7.png",
                "caption": "Figure 7:Comparison on real-world tasks.",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x8.png",
                "caption": "Figure 8:Comparison of the different numbers of ActionQuery. The blue line shows the result of using only the last-layer ActionQuery. The red star shows the result of the full VLA-Adapter.",
                "position": 1186
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix of VLA-Adapter",
        "images": []
    },
    {
        "header": "Appendix ASetup Details of LIBERO Simulation Benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x9.png",
                "caption": "Figure A1:The examples and the task instructions on the LIBERO benchmark.",
                "position": 2460
            }
        ]
    },
    {
        "header": "Appendix BDiT-Based Policy Network",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x10.png",
                "caption": "Figure B1:The DiT-based policy network.",
                "position": 2476
            }
        ]
    },
    {
        "header": "Appendix CDetailed Comparison Results of Different Coditions",
        "images": []
    },
    {
        "header": "Appendix DPerformance on LIBERO Subtasks",
        "images": []
    },
    {
        "header": "Appendix ESetup Details of CALVIN Simulation Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x11.png",
                "caption": "Figure E1:The example and task completion conditions on the CALVIN ABC‚Üí\\toD.",
                "position": 2958
            }
        ]
    },
    {
        "header": "Appendix FSupplementary Details of Training and Hyperparameters",
        "images": []
    },
    {
        "header": "Appendix GExecution Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09372/x12.png",
                "caption": "Figure G1:Execution example on the real-world tasks.",
                "position": 3071
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x13.png",
                "caption": "Figure G2:Execution example on the LIBERO and CALVIN ABC‚Üí\\toD tasks.",
                "position": 3079
            },
            {
                "img": "https://arxiv.org/html/2509.09372/x14.png",
                "caption": "Figure H1:Execution example when the backbone is frozen.",
                "position": 3134
            }
        ]
    },
    {
        "header": "Appendix HEffectiveness Analysis of Frozen Backbone",
        "images": []
    }
]