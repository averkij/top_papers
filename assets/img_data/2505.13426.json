[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13426/x1.png",
                "caption": "Figure 1:Comparison of different models on games from VLM-Gym.",
                "position": 150
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2VLM-Gym: A Scalable Interactive Environment for VLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13426/x2.png",
                "caption": "Figure 2:Key features of VLM-Gym. We illustrate them using the Shisen-Sho game as an example.",
                "position": 172
            }
        ]
    },
    {
        "header": "3Reinforcement Learning with VLM-Gym",
        "images": []
    },
    {
        "header": "4Bootstrapping Perception and Reasoning Abilities via RL",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13426/extracted/6455193/images/game_curves.png",
                "caption": "Figure 3:Average game reward curves of different games for G0 models during RL process.",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x3.png",
                "caption": "Figure 4:The exploredperceptionandreasoningpatterns during G0 RL training in Shisen-Sho Game.",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2505.13426/extracted/6455193/images/localization_patterns.png",
                "caption": "Figure 5:Localization patterns count during G0 RL training for different games.",
                "position": 602
            },
            {
                "img": "https://arxiv.org/html/2505.13426/extracted/6455193/images/g1_scores.png",
                "caption": "Figure 6:Training curves of G1.",
                "position": 616
            },
            {
                "img": "https://arxiv.org/html/2505.13426/extracted/6455193/images/g0g1.png",
                "caption": "Figure 7:Comparisons of game reward between G0 and G1 across different games during RL.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2505.13426/extracted/6455193/images/perception_reward.png",
                "caption": "Figure 8:RL training curves exploring Perception Accuracy as process reward.",
                "position": 648
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APerception-Enhanced Cold Start Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13426/x4.png",
                "caption": "Figure 9:The process of constructing perception-enhanced cold start data via knowledge distillation and programmable environments.",
                "position": 1258
            }
        ]
    },
    {
        "header": "Appendix BG0 2048 Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13426/x5.png",
                "caption": "Figure 10:G0 2048 case studies. The case shows that before RL training, the model produced incorrect perception and reasoning outputs, yet still received positive rewards, which encouraged the policy to adopt these flawed behaviors.",
                "position": 1266
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x6.png",
                "caption": "(a)Correct Action",
                "position": 1274
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x6.png",
                "caption": "(a)Correct Action",
                "position": 1277
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x7.png",
                "caption": "(b)Wrong Action",
                "position": 1282
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x8.png",
                "caption": "(a)Correct Action",
                "position": 1336
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x8.png",
                "caption": "(a)Correct Action",
                "position": 1339
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x9.png",
                "caption": "(b)Wrong Action",
                "position": 1344
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x10.png",
                "caption": "(a)Correct Action",
                "position": 1351
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x10.png",
                "caption": "(a)Correct Action",
                "position": 1354
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x11.png",
                "caption": "(b)Wrong Action",
                "position": 1359
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x12.png",
                "caption": "(a)Correct Action",
                "position": 1453
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x12.png",
                "caption": "(a)Correct Action",
                "position": 1456
            },
            {
                "img": "https://arxiv.org/html/2505.13426/x13.png",
                "caption": "(b)Wrong Action",
                "position": 1461
            }
        ]
    },
    {
        "header": "Appendix CDetails of Games",
        "images": []
    }
]