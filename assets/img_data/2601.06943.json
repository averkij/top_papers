[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06943/Fig/paper-icon.png",
                "caption": "",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2601.06943/x1.png",
                "caption": "Figure 1:Overview of the VideoDR construction pipeline.",
                "position": 204
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06943/x2.png",
                "caption": "Figure 2:An example of the VideoDR task: identifying a museum via video visual cues, then using multi-hop search to find the closest \"donâ€™t miss\" exhibit to the entrance and outputting its accession number WB.67.",
                "position": 226
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Video Deep Research",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06943/x3.png",
                "caption": "Figure 3:Human solvability across benchmark difficulty levels.",
                "position": 355
            },
            {
                "img": "https://arxiv.org/html/2601.06943/x4.png",
                "caption": "Figure 4:Data statistics of VideoDR, including (a) video category, (b) question length, and (c)video duration.",
                "position": 371
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]