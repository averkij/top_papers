[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/teaser/teaser.png",
                "caption": "",
                "position": 64
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x1.png",
                "caption": "",
                "position": 67
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Feed-Forward 3D Reconstruction at Scale",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/method/vggt_workings.png",
                "caption": "(a)VGGT",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/method/vggt_workings.png",
                "caption": "(a)VGGT",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/method/ttt_optim.png",
                "caption": "(b)TTT-based global attention replacement with linear scaling.",
                "position": 177
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x2.png",
                "caption": "(a)Best number of optimizer step of test-time training objective for two sizes of image collections.",
                "position": 322
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x2.png",
                "caption": "(a)Best number of optimizer step of test-time training objective for two sizes of image collections.",
                "position": 325
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x3.png",
                "caption": "(b)Pointmap prediction error for different number of input images\n(lower is better).",
                "position": 331
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/experiments/qualitative_comparison.png",
                "caption": "",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x4.png",
                "caption": "Figure 3:Runtime (↓\\downarrow)vs.Chamfer distance (↓\\downarrow) for collections of size∈{100,500,1​k}\\in\\{100,500,1k\\}on 7scenes dataset.In terms of reconstruction quality (Chamfer distance), we observe a small gap betweenVGG-T3andO​(n2)O(n^{2})baselines, that narrows with increasing number of images. However, for1​k1kinput, VGGT takes ca.1111min whileVGG-T3only needs5858seconds (11.6×11.6\\timesspeedup).VGG-T3scales comparably to TTT3R and does not degrade w.r.t.increasing number of images.",
                "position": 782
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "AImplementation Details",
        "images": []
    },
    {
        "header": "BVGGT adjustments",
        "images": []
    },
    {
        "header": "CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/x5.png",
                "caption": "Figure 4:Pointmap error with increasing number of images when varying the optimizer steps on the TTT objective.",
                "position": 1229
            }
        ]
    },
    {
        "header": "DAdditional Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0726_00.png",
                "caption": "Figure 5:Qualitative comparison.From left to right: VGGT, TTT3R,VGG-T3(Ours)",
                "position": 1292
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0726_00.png",
                "caption": "",
                "position": 1295
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0734_00.png",
                "caption": "",
                "position": 1300
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0735_00.png",
                "caption": "",
                "position": 1305
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0738_00.png",
                "caption": "",
                "position": 1310
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/scannet_comparison/scene0757_00.png",
                "caption": "",
                "position": 1315
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/mapo.png",
                "caption": "Figure 6:Visual localization examples in Wayspots and 7scenes.Ground truth camera for query image (not used for reconstruction) shown on the left in green, predicted camera and geometry in red.",
                "position": 1326
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/mapo.png",
                "caption": "",
                "position": 1329
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/cubes.png",
                "caption": "",
                "position": 1334
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/squarebench.png",
                "caption": "",
                "position": 1339
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/pumpkin.png",
                "caption": "",
                "position": 1344
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/visloc/kitti.png",
                "caption": "Figure 7:In-the-wild visual localization.We reconstruct a sequence of the KITTI dataset, then localize a tourist picture that was recorded 7 years later. Note the changes in appearance and composition of the scene.",
                "position": 1351
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/waymo/1.png",
                "caption": "(a)Similar reconstruction as VGGT.",
                "position": 1358
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/waymo/1.png",
                "caption": "",
                "position": 1361
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/waymo/2.png",
                "caption": "(a)Similar reconstruction as VGGT.",
                "position": 1366
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/waymo/failure_0.png",
                "caption": "",
                "position": 1372
            },
            {
                "img": "https://arxiv.org/html/2602.23361/2602.23361v1/figures/sup/waymo/failure_1.png",
                "caption": "(b)Failure cases.",
                "position": 1377
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]