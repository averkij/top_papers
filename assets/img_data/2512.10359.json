[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10359/x1.png",
                "caption": "Figure 1:We categorize our toolkit into 3 types: spatial tools, temporal tools, and general tools. We also compare 3 toolchain strategies: the toolchain shortcut, which shows the lowest efficiency in tool utilization; the spatiotemporal-disentangled toolchain, which lacks mutual feedback between spatial and temporal reasoning; and the spatiotemporal-interleaved toolchain, which achieves the best accuracy and frame efficiency. We attribute this to its progressive localization of the 3D Region of Interest (3D RoI). See Section4.2for details.",
                "position": 189
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10359/x2.png",
                "caption": "Figure 2:Visualization of our video toolkit, tool cards, and visible frame dictionary. Demonstration of theSTARpipeline. In this case, the LLM planner sequentially invokes five tools—temporal grounding, image captioning, frame selection, OCR, and summarization—to solve the problem.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2512.10359/x3.png",
                "caption": "",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix ATool Detail",
        "images": []
    },
    {
        "header": "Appendix BDatasets",
        "images": []
    },
    {
        "header": "Appendix CBaselines",
        "images": []
    },
    {
        "header": "Appendix DAblation on each tool",
        "images": []
    },
    {
        "header": "Appendix EScalability with more frames",
        "images": []
    },
    {
        "header": "Appendix FGeneralizability with different base LLMs",
        "images": []
    },
    {
        "header": "Appendix GAnalysis on Tool Balance",
        "images": []
    },
    {
        "header": "Appendix HFailure Cases",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10359/x4.png",
                "caption": "Figure 4:A case of counting problem from VideoMME, mainly solved by object detector.",
                "position": 1882
            },
            {
                "img": "https://arxiv.org/html/2512.10359/x5.png",
                "caption": "Figure 5:A case of action recognition problem from VideoMME.",
                "position": 1885
            },
            {
                "img": "https://arxiv.org/html/2512.10359/x6.png",
                "caption": "Figure 6:A case of action reasoning problem from VideoMME.",
                "position": 1888
            }
        ]
    },
    {
        "header": "Appendix ICase Study",
        "images": []
    }
]