[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x1.png",
                "caption": "",
                "position": 138
            },
            {
                "img": "https://arxiv.org/html/2601.12910/x2.png",
                "caption": "",
                "position": 142
            },
            {
                "img": "https://arxiv.org/html/2601.12910/x3.png",
                "caption": "",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2601.12910/x4.png",
                "caption": "",
                "position": 175
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x5.png",
                "caption": "Figure 1:Example fromSciCoQA, showing specific model implementation in the paper, and its implementation in the code (simplified for readability). The paper’s description and the code’s implementation mismatch, creating apaper-code discrepancy.",
                "position": 190
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x6.png",
                "caption": "Figure 2:Overview of the data collection process ofSciCoQA. We source real-world data from Reproducibility papers and GitHub issues. For the former, paper-code discrepancies are extracted from the paper with GPT-5, for the latter, issues are pre-filtered using Qwen3. Next, all candidates are manually filtered to remove any that do not fit our discrepancy definition. Finally, all paper-code discrepancies are verified with GPT-5. For synthetic data, we generate discrepancies using GPT-5 for AI and other computational domains.",
                "position": 217
            }
        ]
    },
    {
        "header": "3SciCoQA",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x7.png",
                "caption": "Figure 3:Analysis of the real (blue), synthetic (orange), and combined (green) discrepancy data. The y-axis shows the proportion of the data. The arXiv subjects stand for Computer Science (CS), Electrical Engineering and Systems Science (EESS), Physics, Statistics (Stats), Quantitative Biology (Q-Bio), and Mathematics (Math). TheDiscrepancy Categorychart shows only the distribution over computer science papers.",
                "position": 264
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x8.png",
                "caption": "Figure 4:Results of the top 8 best performing models (sorted by average recall on the real and synthetic data) on the discrepancy dataset by different analyses. From left to right, we analyze the origin of the discrepancy, the type of discrepancy, the number of tokens in the input prompt, and the publication year of the paper.",
                "position": 326
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x9.png",
                "caption": "Figure 5:Performance of top 8 models when given paper and code, and only the code, split by data origin: Real (R), Synthetic (S), and combined (R+S).",
                "position": 368
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AGitHub Crawl Details",
        "images": []
    },
    {
        "header": "Appendix BPrompts",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x10.png",
                "caption": "Figure 6:Quantitative analysis of synthetic code modifications. We show the distribution of number of changed files, number of generated diff snippets, added (green) vs. removed (orange) lines in those snippets, and Jaccard similarity between the original and modified code.",
                "position": 1825
            }
        ]
    },
    {
        "header": "Appendix DSynthetic Code Analysis",
        "images": []
    },
    {
        "header": "Appendix EAnalysis by Programming Language",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x11.png",
                "caption": "Figure 7:Distribution of programming languages inSciCoQA. The columns of the plot show the distribution by number ofRepos,Files,Lines, andTokensfor each respective programming language. The rows show the distribution for the real, synthetic, and combined data.",
                "position": 2095
            }
        ]
    },
    {
        "header": "Appendix FExtended Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.12910/x12.png",
                "caption": "Figure 8:Correlation between model recall on the synthetic (x-axis) and real (x-axis) subsets ofSciCoQA. Each point represents one of the 21 evaluated models. The dashed line visualizes the Pearson correlation.",
                "position": 2456
            }
        ]
    },
    {
        "header": "Appendix GExample Discrepancies inSciCoQA",
        "images": []
    },
    {
        "header": "Appendix HExample Synthetic Discrepancies inSciCoQA",
        "images": []
    }
]