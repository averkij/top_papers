[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18731/x1.png",
                "caption": "Figure 1:Comparison of personalized reward modeling methods: (a) Personalized input incorporates user contexts; (b) Personalized parameter assigns user-specific parameters; (c) Meta Reward Modeling formulates personalization as a meta-learning problem by learning an adaptable initialization.",
                "position": 91
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18731/x2.png",
                "caption": "Figure 2:Overview of Meta Reward Modeling. The model employs base reward functions with shared weight initialization, adapts user-specific weights in the inner loop, and updates both initialization and base functions in the outer loop with the robust personalization objective.",
                "position": 368
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18731/x3.png",
                "caption": "Figure 3:Performance of average accuracy on the worst 10%, 20%, and 50% of users for (a) PRISM and (b) Reddit TLDR with 100 examples. MRM consistently outperforms baselines on all proportions of worst users, showing stronger robustness.",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2601.18731/x4.png",
                "caption": "Figure 4:Effect of threshold ratio on PRISM.\n(a) Overall accuracy with different threshold ratios (ρ=0.1,0.2,0.5\\rho=0.1,0.2,0.5).\n(b) Accuracy on the worstk%k\\%of users (k=10,20,50k=10,20,50).",
                "position": 933
            },
            {
                "img": "https://arxiv.org/html/2601.18731/x5.png",
                "caption": "Figure 5:Performance with respect to (a) meta batch size and (b) smoothing parameterγ\\gamma. In (b),γ=0∗\\gamma{=}0^{*}denotes hard filtering.",
                "position": 938
            },
            {
                "img": "https://arxiv.org/html/2601.18731/x6.png",
                "caption": "Figure 6:Performance of few-shot adaptation on unseen users. We vary the number of few-shot examples for each user (x-axis) and report accuracy on three settings. MRM consistently outperforms baselines and shows stronger gains with more examples.",
                "position": 941
            },
            {
                "img": "https://arxiv.org/html/2601.18731/x7.png",
                "caption": "Figure 7:Number of trainable parameters as the number of users increases for different methods.",
                "position": 1056
            }
        ]
    },
    {
        "header": "6Ethical and Privacy Considerations",
        "images": []
    },
    {
        "header": "7Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]