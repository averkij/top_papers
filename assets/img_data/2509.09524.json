[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Datasets, tasks, and evaluation metrics",
        "images": []
    },
    {
        "header": "3In-context learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.09524/x1.png",
                "caption": "Figure 1:Our two-step pipeline to solve both tasks, based on ICL. In the first step (Task B), we sample examples from an annotatorâ€™s past annotations and prompt the LLM to model annotator-specific behavior and predict labels for test inputs. In the second step, we aggregate these predictions into soft labels (Task A).",
                "position": 343
            }
        ]
    },
    {
        "header": "4Fine-tuning approaches",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExample of an ICL prompt",
        "images": []
    }
]