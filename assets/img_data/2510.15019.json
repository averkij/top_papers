[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15019/x1.png",
                "caption": "Figure 1:Highly-consistent 3D objects edited by Nano3D.Our framework supports a range of training-free and part-level tasks especially on shape, including removal, addition, and replacement, while only requiring users to provide source 3D objects and instructions, without any mask.",
                "position": 89
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15019/x2.png",
                "caption": "Figure 2:The Nano3D pipeline.The original 3D object is voxelized and encoded into sparse structure and structured latent respectively. Stage 1 modifies geometry via Flow Transformer with FlowEdit, guided by Nano Banana–edited images. Stage 2 generates structured latents with Sparse Flow Transformer, supporting TRELLIS-inherent appearance editing. Voxel/Slat-Merge further ensures consistency across both stages before decoding the final 3D object.",
                "position": 189
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x3.png",
                "caption": "Figure 3:Data Construction Pipeline.The figure shows our pipeline. We first sample images from the dataset and prompt Qwen2.5-VL to generate editing instructions by completing templates. Trellis then generates 3D meshes from the images. Finally, the image, instruction, and mesh are fed into Nano3D, and the resulting 3D assets are filtered for quality.",
                "position": 236
            }
        ]
    },
    {
        "header": "5Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15019/x4.png",
                "caption": "Figure 4:Qualitative results.We present three edit types—object removal, addition, and replacement. In each case, Nano3D confines changes to the target region (red dashed circles) and produces view-consistent edits, while leaving the rest of the scene unchanged. Geometry stays sharp and textures remain faithful in unedited areas, with no noticeable artifacts.",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x5.png",
                "caption": "Figure 5:Qualitative comparison.Our method achieves the best editing performance with faithful instruction semantic alignment and perfect original structure consistency across multi-view images.",
                "position": 302
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x6.png",
                "caption": "Figure 6:Ablation study onτ\\tau.The leftmost voxel represents the pre-editing state, with the editing instruction being to remove the wings. The three voxels on the right correspond to the masks generated during the voxel-merge stage forτ=100\\tau=100,τ=50\\tau=50, andτ=30\\tau=30(from left to right). As observed, whenτ=100\\tau=100, the detected mask most accurately aligns with the editing regions, while lower values include irrelevant non-editing areas.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x7.png",
                "caption": "Figure 7:Ablation study on Voxel/Slage-Merge.Our methods sequentially ensure geometry and appearance consistency, demonstrating their complementary roles.",
                "position": 471
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x8.png",
                "caption": "Figure 8:Comparison with Editing Methods Requiring Masked InputComparison between Nano3D and VoxHammer under identical mask-guided editing settings. Both methods receive the same bounding boxes, editing instructions, and target outputs. Nano3D preserves high consistency in non-edited regions, while VoxHammer exhibits inconsistencies compared to the input 3D assets in these areas, as evidenced by the red-bordered highlights.",
                "position": 477
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15019/x9.png",
                "caption": "Figure 9:A bad case sampled from the 3D-AlpacaYe et al. (2025b)dataset shows that its image consistency before and after editing is poorly maintained.",
                "position": 1619
            },
            {
                "img": "https://arxiv.org/html/2510.15019/x10.png",
                "caption": "Figure 10:We present additional editing results involving addition, removal, and replacement. Edited regions are highlighted with red dashed circles. As shown, Nano3D achieves high editing consistency, preserving geometry and texture outside the edited areas.",
                "position": 1989
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]