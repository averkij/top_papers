[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x1.png",
                "caption": "Figure 1:DexUMItransfer dexterous human manipulation skills to various robot hand by using wearable exoskeletons and a data processing framework. We demonstrate DexUMI’s capability and effectiveness on both underactuated (e.g., Inspire) and fully-actuated (e.g., XHand) robot hand for a wide variety of manipulation tasks. Please see project websitehttps://dex-umi.github.io/for details.",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x2.png",
                "caption": "Figure 2:Exoskeleton Design.The optimized exoskeleton design shares the same joint-to-fingertip position mapping as the target robot hand while maintaining the wearability. The exoskeletons utilizes the encoder to precisely capture the joint action and 150° DFoV camera to record the information-rich visual observation. An iPhone is rigidly mounted to track the wrist pose through the ARKit.",
                "position": 194
            }
        ]
    },
    {
        "header": "3Hardware Adaptation to Bridge the Embodiment Gap",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x3.png",
                "caption": "Figure 3:Mechanism Optimization.To avoid thumb collision between human hand and exoskeleton, the hardware optimization step allows us to move the exoskeleton thumb backward while still preserving the original fingertip and joint mapping in SE(3) space.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2505.21864/x4.png",
                "caption": "Figure 4:Bridging the Visual Gap.To convert the visual observation into policy training data, we first segment the exoskeleton using SAM2 (b) and inpaint the missing background (c). The corresponding joint action (a) is replayed on the dexterous hand to obtain the robot hand image (d). SAM2 is applied to obtain the robot mask (e). The intersection (f) of the exoskeleton mask (b) and robot mask (e) identifies the visible part of the hand during interaction. Finally, we replace pixels in the inpainted background (c) with the visible robot hand (g).",
                "position": 321
            }
        ]
    },
    {
        "header": "4Software Adaptation to Bridge the Visual Gap",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x5.png",
                "caption": "Figure 5:Policy Rollout:We evaluate DexUMI’s capabilities across challenging real-world tasks. TheCubetask tests basic picking precision. TheEgg Cartontask evaluates multi-finger coordination. TheTea Pickingtask assesses performance on contact-rich manipulation requiring millimeter-level fine-grained fingertip actions. Finally, theKitchentask tests capabilities on long-horizon high-precision actions to manipulate a knob, move a pan using both the side of thumb and index finger (beyond just fingertips), and utilize tactile sensing for visually challenging salt picking tasks.",
                "position": 349
            }
        ]
    },
    {
        "header": "5Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x6.png",
                "caption": "Figure 6:Comparisons.a) The policy outputs relative hand actions yield more precise action and demonstrate better multi-finger coordination. Note, we draw a sketch for the knob closing for better visualization. b) Even with noisy tactile sensor reading, the tactile significantly improve tasks which is visually challenging.",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2505.21864/x7.png",
                "caption": "Figure 7:Efficiency:Collection throughput (CT) within 15-minute. Though DexUMI still slower than bare hand, it achieves significant higher efficiency than teleportation.",
                "position": 572
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitation and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x8.png",
                "caption": "Figure 8:Inpainting Results.The visual observations in the original collected dataset contain exoskeletons and human hands. The software adaptation layer replaces these pixels with corresponding robot hand images while preserving the natural occlusion relationships during hand-object interactions. Please see project websitehttps://dex-umi.github.iofor details.",
                "position": 1816
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix CExoskeleton Design Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x9.png",
                "caption": "Figure 9:Inspire Mocap:We use motion capture system to record fingertips trajectories in the flange coordinate. We attached marker on fingers and flange to capture the fingertip pose in flange coordinate.",
                "position": 1881
            }
        ]
    },
    {
        "header": "Appendix DSensor Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.21864/x10.png",
                "caption": "Figure 10:Joint Encoder Circuit:The rotary sensor acts as a variable resistor with three output pins. As it rotates with the joint, the voltage on the ADC line changes approximately linearly.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2505.21864/x11.png",
                "caption": "Figure 11:Voltage Divider Circuit:This simple voltage divider circuit converts the resistance change of the FSR sensor into an analog voltage on the ADC line.",
                "position": 1940
            }
        ]
    },
    {
        "header": "Appendix EData Collection and Policy Training details",
        "images": []
    }
]