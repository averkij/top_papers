[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20631/x1.png",
                "caption": "Figure 1:Slow perception enjoys two stages: 1) Perception decomposition. A geometric shape is decomposed into basic visual units, such as circles and line segments, thereby unifying the fundamental representational form of diverse geometric figures. 2) Perception flow. Using the same modeling approach (predicting the endpoint based on the starting point) for line segments of different lengths is unreasonable. We employ a sectional copying method to express each line segment with a perceptual ruler.",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x2.png",
                "caption": "Figure 2:When humans trace a line, it is typically a slow perception process. Rather than sketching the line, especially a long line, in one stroke (long range “jump”), humans commonly draw a line with “multiple short strokes” for high precision. Our “slow perception” algorithm is designed based on this to mimic the gradual human process of discerning geometric figures.",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x3.png",
                "caption": "Figure 3:The framework of slow perception. Our approach is adaptable to the most popular LVLM frameworks. According to the next-token serialized prediction, predicted subsequent geometric points can reference the coordinates of preceding points to achieve closed shapes more easily. We establish a perceptual ruler as the upper limit for single-step distance prediction.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20631/x4.png",
                "caption": "Figure 4:The line distribution of rendered train data. The left figure shows the line length and the right is angle distributions to comprise the geometric shapes in the train data.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x5.png",
                "caption": "Figure 5:An example of the ground truth. This figure shows an rendered geometry sample and the corresponding text labels under the length of perceptual ruler being 4.",
                "position": 261
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20631/extracted/6101147/fig/line-style.png",
                "caption": "Figure 6:As the length of the perceptual ruler decreases, we can observe a steady improvement in almost all metrics. The shorter the perceptual ruler, the more “strokes” are needed to model a line, resulting in the model outputting more intermediate “gaze” points. This leads to increased computational complexity during inference, and correspondingly longer inference times, exhibiting to some extent an inference time scaling law.",
                "position": 645
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x6.png",
                "caption": "Figure 7:‘With jitter” represents the result of a trained model using gaze points that have been shaken. The “stroke order” of each line segment is mapped according to the color of the rainbow, e.g., red, orange, and yellow are used in “without jitter” result, and green, cyan, and blue are used in “with jitter” one.",
                "position": 795
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x7.png",
                "caption": "Figure 8:Slow perception visualization results. The first column represents the input image, and the second column shows the trace route of each “stroke” executed by the model in slow perception, with “stroke order” defined by rainbow colors. The third column is the final result of parsing slow perception.",
                "position": 802
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Appendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20631/x8.png",
                "caption": "Figure 9:Adding labels for points and lines in geometric shapes is easy for the auto-regression framework. Although this process does not affect the claim of slow perception, it is necessary to embed the geometry parsing results into downstream tasks, e.g., mathematic geometric VQA.",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x9.png",
                "caption": "Figure 10:The organizational of input when adding geometry parsing results as a reference for GPT-4o. We provide the parsing results as a “sketch” to GPT-4o, emphasizing that it can only represent the relationship between points and lines to a certain extent, and is only for reference. We require the model that the final answer still needs to be based on the input image.",
                "position": 872
            },
            {
                "img": "https://arxiv.org/html/2412.20631/x10.png",
                "caption": "Figure 11:Visualization of geometric parsing results of different models. For GPT-4o and Claude-3.5, we use this prompt to output the results:Write the Tikz code for this geometric figure, be careful not to write labels for points, only draw the geometric shape.",
                "position": 876
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]