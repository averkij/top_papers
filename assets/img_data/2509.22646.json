[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22646/logos/github.png",
                "caption": "",
                "position": 88
            },
            {
                "img": "https://arxiv.org/html/2509.22646/logos/huggingface.png",
                "caption": "",
                "position": 90
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22646/x1.png",
                "caption": "Figure 1:Human-perceived deepfake traces examples.The shown cases are selected fromPika 1.5,MiniMax-Video-01, andSoragenerated videos. For each deepfake trace, we annotate local bounding box regions, start and end timestamps, and provide natural language explanation. All fake trace categories are summarized inSection˜2.3and distribution can be found inFigure˜5.",
                "position": 130
            },
            {
                "img": "https://arxiv.org/html/2509.22646/x2.png",
                "caption": "Figure 2:DeeptraceRewarddata curation pipeline.Selected videos are uploaded to our annotation platform LabelBox(LabelBox,2024), where experts provide fine-grained deepfake trace annotations with bounding boxes, textual explanations, and start / end timestamps.",
                "position": 133
            }
        ]
    },
    {
        "header": "2DeeptraceRewardDataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22646/x3.png",
                "caption": "Figure 3:Labelbox annotation interface.Each video is annotated with localized bounding boxes that highlight specific regions across frames where fakeness is perceived. Each annotated deepfake trace is accompanied by a natural language explanation and predefined category labels.",
                "position": 255
            },
            {
                "img": "https://arxiv.org/html/2509.22646/x4.png",
                "caption": "Figure 4:DeeptraceRewarddeepfake trace category statistics. Category definitions can be found inSection˜3.3, and concrete examples for each category are listed inFigures˜1and6.",
                "position": 306
            },
            {
                "img": "https://arxiv.org/html/2509.22646/x4.png",
                "caption": "Figure 4:DeeptraceRewarddeepfake trace category statistics. Category definitions can be found inSection˜3.3, and concrete examples for each category are listed inFigures˜1and6.",
                "position": 309
            },
            {
                "img": "https://arxiv.org/html/2509.22646/x5.png",
                "caption": "Figure 5:Performance analysis between baseline models and our best reward model trained on the collectedDeeptraceRewarddataset. Our model is much better in all categories, especially in‘‘object spltting’’and‘‘object merging’’.",
                "position": 314
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22646/x6.png",
                "caption": "Figure 6:DeeptraceRewardexamples by category.Category definitions are inSection˜2.3and dataset statistics can be found inFigure˜5.",
                "position": 1187
            }
        ]
    },
    {
        "header": "Appendix BEthics Statement",
        "images": []
    },
    {
        "header": "Appendix CLimitations and future directions.",
        "images": []
    },
    {
        "header": "Appendix DExplanation Evaluation Prompt",
        "images": []
    },
    {
        "header": "Appendix EInference Setting and Prompt",
        "images": []
    },
    {
        "header": "Appendix FQualitative Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.22646/x7.png",
                "caption": "Figure 7:Qualitative analysis examples that compare ground-truth explanation, GPT generated explanation, and explanation generated by our best 7B reward model based on Video-LLaMa3.",
                "position": 1260
            }
        ]
    },
    {
        "header": "Appendix GFinetuning Setups",
        "images": []
    },
    {
        "header": "Appendix HVal Set Results",
        "images": []
    }
]