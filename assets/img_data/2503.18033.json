[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18033/x1.png",
                "caption": "Figure 1:Overview of OmnimatteZero-From left to right: The video and its corresponding object-masked version are encoded into the latent space. The spatio-temporal footprint of the target object is then identified and extracted from this encoding. Self-attention maps are leveraged to recognize effects associated with the object (such as a cat’s reflection), which are incorporated into both the object mask and the latent encoding. Using this mask, we apply two imperfect video inpainting methods: (a) Background-Preserving Inpainting, which retains background details but may leave behind traces of the object, and (b) Object-Removing Inpainting, which eliminates the object but might introduce background distortions. We refine the results through Attention-based Latent Blending, selectively combining the strengths of each inpainting method. Finally, few denoising steps of the video diffusion model enhances the blended output, producing a high-quality reconstruction with the object removed and the background well-preserved, as indicated by high PSNR values.",
                "position": 131
            }
        ]
    },
    {
        "header": "3Motivation: The failure of image inpainting approaches for videos",
        "images": []
    },
    {
        "header": "4Method: OmnimatteZero",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18033/extracted/6302754/figures/method_self_attn_maps.png",
                "caption": "Figure 2:Self-attention mapsfrom(a)LTX Video diffusion model and(b)Image based Stable Diffusion. The spatio-temporal video latent ”attends to object associated effects” (e.g., shadow, reflection) where, image models struggles to capture these associations.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2503.18033/extracted/6302754/figures/method_extr_comp.png",
                "caption": "Figure 3:(a) Foreground Extraction:The target object is extracted by latent code arithmetic, subtracting the background video encoding from the object+background latent (Latent Diff). This initially results in distortions, which are later corrected by replacing pixel values using the original video and a user-provided mask (Latent Diff + Refinement).(b) Layer Composition:The extracted object layer is added to a new background latent (Latent Addition). To improve blending, a few steps of SDEdit are applied, yielding a more natural integration of the object into the new scene (Latent Addition + SDEdit).",
                "position": 232
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.18033/x2.png",
                "caption": "Figure 4:Qualitative Results: Object removal and background reconstruction.The first row shows input video frames with object masks, while the second row presents the reconstructed backgrounds. Our approach effectively removes objects while preserving fine details, reflections, and textures, demonstrating robustness across diverse scenes. Notice the removal of the cat’s reflection in the mirror and water, the shadow of the dog and bicycle (with the rider), and the bending of the trampoline when removing the jumpers.",
                "position": 497
            },
            {
                "img": "https://arxiv.org/html/2503.18033/extracted/6302754/figures/qualitative_comp.png",
                "caption": "Figure 5:Qualitative Comparison: Object removal and background reconstruction.Our approach achieves cleaner background reconstructions with fewer artifacts while Generative Omnimatte[15]leaves some residuals, DiffuEraser[16]and ProPainter[36]struggle with noticeable traces (highlighted in red). The last two rows show that OmnimatteZero successfully removes effects where others fail.",
                "position": 501
            },
            {
                "img": "https://arxiv.org/html/2503.18033/extracted/6302754/figures/qualitative_foreground.png",
                "caption": "Figure 6:Qualitative Comparison: Foreground Extraction.Foreground extraction comparison between OmnimatteZero and OmnimatteRF[17]. Our method accurately captures both the object and its associated effects, such as shadows and reflections, in contrast to OmnimatteRF, often missing or distorting shadows (row 2) and reflections (row 3).",
                "position": 528
            },
            {
                "img": "https://arxiv.org/html/2503.18033/extracted/6302754/figures/qualitative_insertion.png",
                "caption": "Figure 7:Qualitative Comparison: Layer Composition.The extracted foreground objects, along with their shadows and reflections, are seamlessly integrated into diverse backgrounds, demonstrating the effectiveness of our approach in preserving visual coherence and realism across different scenes.",
                "position": 545
            }
        ]
    },
    {
        "header": "6Summary",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]