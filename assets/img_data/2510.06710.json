[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06710/figures/title-icon/logo_white.png",
                "caption": "",
                "position": 202
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/title-icon/huggingface_logo-noborder.png",
                "caption": "",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/title-icon/github-logo.png",
                "caption": "",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x1.png",
                "caption": "Figure 1:Overview of RLinf-VLA. Through a unified interface, RLinf-VLA seamlessly supports diverse VLA architectures, multiple RL algorithms, and various simulators. To flexibly accommodate the integration of rendering, training, and inference in RL+VLA training, RLinf-VLA provides three GPU allocation modes:colocated,disaggregated, and a novelhybridmode. A single unified model achieves 98.11% success on 130 LIBERO tasks and 97.66% on 25 ManiSkill tasks in simulation, while an RL-trained model demonstrates superior zero-shot generalization on a real-world Franka robot compared to the SFT model.",
                "position": 342
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary for Reinforcement Learning",
        "images": []
    },
    {
        "header": "3Framework Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06710/x2.png",
                "caption": "Figure 2:VLA+RL training loop",
                "position": 521
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/shared.png",
                "caption": "(a)Colocated GPU Allocation",
                "position": 527
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/shared.png",
                "caption": "(a)Colocated GPU Allocation",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/shared.png",
                "caption": "(a)Colocated GPU Allocation",
                "position": 533
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/separated.png",
                "caption": "(b)Disaggregated GPU Allocation",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/alloc-annotation.png",
                "caption": "(c)Hybrid GPU Allocation with Fine-Grained Pipelining",
                "position": 547
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/alloc-annotation.png",
                "caption": "",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/gpu-alloc/mixed.png",
                "caption": "(c)Hybrid GPU Allocation with Fine-Grained Pipelining",
                "position": 555
            }
        ]
    },
    {
        "header": "4Algorithm Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06710/x3.png",
                "caption": "Figure 4:Illustration of different logprob levels.",
                "position": 931
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/rollout-feature/rollout-legend.png",
                "caption": "(a)Fixed Episode Length",
                "position": 1052
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/rollout-feature/rollout-legend.png",
                "caption": "",
                "position": 1055
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/rollout-feature/fix-epi-len.png",
                "caption": "(a)Fixed Episode Length",
                "position": 1060
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/rollout-feature/partial-reset.png",
                "caption": "(b)Partial Reset",
                "position": 1065
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/rollout-feature/with-mask.png",
                "caption": "(c)Valid Action Mask",
                "position": 1070
            }
        ]
    },
    {
        "header": "5Experiment Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06710/x4.png",
                "caption": "(a)OpenVLA",
                "position": 1219
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x4.png",
                "caption": "(a)OpenVLA",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x5.png",
                "caption": "(b)OpenVLA-OFT",
                "position": 1227
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x6.png",
                "caption": "Figure 7:Training curve of OpenVLA-OFT with GRPO on LIBERO-130.",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x7.png",
                "caption": "(a)GPU-parallelized Simulator ManiSkill with OpenVLA",
                "position": 1565
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x7.png",
                "caption": "(a)GPU-parallelized Simulator ManiSkill with OpenVLA",
                "position": 1568
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x8.png",
                "caption": "(b)GPU-parallelized Simulator ManiSkill with OpenVLA-OFT",
                "position": 1573
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x9.png",
                "caption": "(c)CPU-parallelized Simulator LIBERO with OpenVLA-OFT",
                "position": 1578
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x10.png",
                "caption": "Figure 9:Latency breakdown for LIBERO with the OpenVLA-OFT setting.",
                "position": 1602
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x11.png",
                "caption": "(a)Success rate in ManiSkill.",
                "position": 1625
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x11.png",
                "caption": "(a)Success rate in ManiSkill.",
                "position": 1628
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x12.png",
                "caption": "(b)Value loss in ManiSkill.",
                "position": 1633
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x13.png",
                "caption": "(c)Success rate in LIBERO-Goal",
                "position": 1638
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x14.png",
                "caption": "(a)OpenVLA",
                "position": 1645
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x14.png",
                "caption": "(a)OpenVLA",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x15.png",
                "caption": "(b)OpenVLA-OFT",
                "position": 1653
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x16.png",
                "caption": "Figure 12:Ablation study on trajectory length normalization.",
                "position": 1678
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x17.png",
                "caption": "(a)LIBERO-Goal",
                "position": 1690
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x17.png",
                "caption": "(a)LIBERO-Goal",
                "position": 1693
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x18.png",
                "caption": "(b)ManiSkill",
                "position": 1698
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x19.png",
                "caption": "(a)OpenVLA, ManiSkill",
                "position": 1708
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x19.png",
                "caption": "(a)OpenVLA, ManiSkill",
                "position": 1711
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x20.png",
                "caption": "(b)OpenVLA-OFT, ManiSkill",
                "position": 1716
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x21.png",
                "caption": "(c)OpenVLA-OFT, LIBERO-Goal",
                "position": 1721
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x22.png",
                "caption": "(a)PPO, LIBERO-10",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x22.png",
                "caption": "(a)PPO, LIBERO-10",
                "position": 1748
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x23.png",
                "caption": "(b)GRPO, LIBERO-130",
                "position": 1753
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x24.png",
                "caption": "(a)PPO",
                "position": 1766
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x24.png",
                "caption": "(a)PPO",
                "position": 1769
            },
            {
                "img": "https://arxiv.org/html/2510.06710/x25.png",
                "caption": "(b)GRPO",
                "position": 1774
            },
            {
                "img": "https://arxiv.org/html/2510.06710/figures/real-world/real-horizon.png",
                "caption": "Figure 17:Example of real-world deployment with an RL-trained model performing the task of placing a banana into a bowl.",
                "position": 1867
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]