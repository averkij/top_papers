[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05160/x1.png",
                "caption": "Figure 1:We develop a universal multimodal embedding benchmark, MMEB, along withVlm2Vec, an embedding model adapted from vision-language models (VLMs).Vlm2Vecis capable of following instructions and performing various multimodal embedding tasks, accommodating any combination of image and text modalities.",
                "position": 100
            }
        ]
    },
    {
        "header": "2MMEB: A Benchmark for Multimodal Embeddings",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05160/x2.png",
                "caption": "Figure 2:An overview of the tasks and datasets in MMEB. MMEB includes four meta-tasks and 36 datasets: 20 in-distribution datasets (blue) used for training and 16 out-of-distribution (orange) datasets used exclusively for evaluation.",
                "position": 535
            }
        ]
    },
    {
        "header": "3Vlm2Vec: Transforming LVMs to Embedders",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05160/x3.png",
                "caption": "Figure 3:Vlm2Vecuses a VLM as the backbone to deeply integrate image and text features. It is trained with a contrastive loss between the query and target, following task-specific instructions. The training data consists of diverse combinations of modalities on both the query and target sides, which may include images, text, or image-text pairs.",
                "position": 596
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05160/x4.png",
                "caption": "Figure 4:The figures demonstrate the influence of the training setup onVlm2Vecâ€™s final performance. Here, we examine the effects of training batch size, the number of sub-image crops, and the number of training steps.",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2410.05160/x5.png",
                "caption": "Figure 5:The figures show the generalization ability of models trained on one meta-task to other unseen meta-tasks. Models trained on retrieval tasks demonstrate better generalization ability because retrieval tasks involve a more diverse combination of text and visual modalities from both the query and target sides.",
                "position": 957
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/imagenet_example.jpg",
                "caption": "Table 6:Examples of datasets in MMEB (Part 1 of 4).Instructionsare written in italic font style.",
                "position": 2877
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/imagenet_a_example.jpg",
                "caption": "",
                "position": 2959
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/imagenet_r_example.jpg",
                "caption": "",
                "position": 2985
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/n24news_example.jpg",
                "caption": "",
                "position": 3012
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/voc_2007_example.jpg",
                "caption": "",
                "position": 3039
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/sun397_example.jpg",
                "caption": "",
                "position": 3065
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/objectnet_example.jpg",
                "caption": "",
                "position": 3091
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/country211_example.jpg",
                "caption": "",
                "position": 3117
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/hatefulmemes_example.jpg",
                "caption": "",
                "position": 3143
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/place365_example.jpg",
                "caption": "",
                "position": 3169
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/ok_vqa_example.jpg",
                "caption": "Table 7:Examples of datasets in MMEB (Part 2 of 4).Instructionsare written in italic font style.",
                "position": 3188
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/a_okvqa_example.jpg",
                "caption": "",
                "position": 3272
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/docvqa_example.jpg",
                "caption": "",
                "position": 3299
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/infovqa_example.jpeg",
                "caption": "",
                "position": 3326
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/chartqa_example.png",
                "caption": "",
                "position": 3353
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/scienceqa_example.jpg",
                "caption": "",
                "position": 3380
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/v7w_telling_example.jpg",
                "caption": "",
                "position": 3407
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/vizwiz_example.jpg",
                "caption": "",
                "position": 3434
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/GQA_example.jpg",
                "caption": "",
                "position": 3461
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/textvqa_example.jpg",
                "caption": "",
                "position": 3488
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/visdial_example.jpg",
                "caption": "Table 8:Examples of datasets in MMEB (Part 3 of 4).Instructionsare written in italic font style.",
                "position": 3507
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/visualnews_t2i_example.jpg",
                "caption": "",
                "position": 3601
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/mscoco_t2i_example.jpg",
                "caption": "",
                "position": 3628
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/webqa_example.png",
                "caption": "",
                "position": 3656
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/edis_example.jpg",
                "caption": "",
                "position": 3684
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/wiki_ss_nq.jpg",
                "caption": "",
                "position": 3710
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/visualnews_i2t_example.jpg",
                "caption": "",
                "position": 3726
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/mscoco_i2t_example.jpg",
                "caption": "",
                "position": 3752
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/cirr_1.jpg",
                "caption": "Table 9:Examples of datasets in MMEB (Part 4 of 4).Instructionsare written in italic font style.",
                "position": 3771
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/cirr_2.jpg",
                "caption": "",
                "position": 3837
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/fashioniq_1.jpg",
                "caption": "",
                "position": 3854
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/fashioniq_2.jpg",
                "caption": "",
                "position": 3863
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/nights_1.jpg",
                "caption": "",
                "position": 3880
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/nights_2.jpg",
                "caption": "",
                "position": 3889
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/oven_1.jpg",
                "caption": "",
                "position": 3906
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/oven_2.jpg",
                "caption": "",
                "position": 3916
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/mscoco_1.jpg",
                "caption": "",
                "position": 3938
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/mscoco_2.jpg",
                "caption": "",
                "position": 3947
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/v7w_pointing_1.jpg",
                "caption": "",
                "position": 3964
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/v7w_pointing_2.png",
                "caption": "",
                "position": 3973
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/refcoco_1.jpg",
                "caption": "",
                "position": 3990
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/refcoco_2.jpg",
                "caption": "",
                "position": 3999
            },
            {
                "img": "https://arxiv.org/html/2410.05160/extracted/5920037/figures/dataset_examples_figures/refcoco_match_example.png",
                "caption": "",
                "position": 4016
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]