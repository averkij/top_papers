[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03666/x1.png",
                "caption": "Figure 1:Implicit vs. explicit alignment for omni-modal embeddings.(a) Implicit alignment leads to modality-dependent sharpness, negative hardness imbalance, and unstable ranking.\n(b)e5-omniperforms explicit alignment with three lightweight modules to calibrate cross-modality similarities.",
                "position": 119
            }
        ]
    },
    {
        "header": "2Method:e5-omni",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03666/x2.png",
                "caption": "Figure 2:Overview ofe5-omni.Given omni-modal inputs,e5-omniaugments a VLM backbone with three lightweight components:\n(1)Modality-aware temperature calibrationcomputes a modality-composition indicatorw‚Äã(x)w(x)and applies learnable modality-specific temperaturesùùâ\\boldsymbol{\\tau}to calibrate logits‚Ñì‚Äã(q,p)\\ell(q,p);\n(2)Controllable negative curriculumprogressively masks easy negatives and optimizes a masked debiased objective‚ÑíDCL\\mathcal{L}_{\\mathrm{DCL}};\n(3)Batch whitening and covariance alignmentwhitens batch embeddings and adds a CORAL-style covariance regularizer.",
                "position": 181
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03666/x3.png",
                "caption": "Figure 3:PCA overlap on VOC2007.\nLeft:e5-omniw/o. alignment. Right:e5-omni.\nWe project embeddings into a shared 2D PCA space and overlay2‚ÄãœÉ2\\sigmacovariance ellipses.\nWe reportcentroid(distance between the query/target mean embeddings) andcovgap(Frobenius gap between their covariance matrices).",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2601.03666/x4.png",
                "caption": "Figure 4:Covariance-difference heatmap on VOC2007.\nLeft:e5-omniw/o. alignment. Right:e5-omni.\nAfter a fixed 32D random projection, we visualizecovdiff: the entrywise magnitude of the query‚Äìtarget covariance difference matrix.",
                "position": 846
            },
            {
                "img": "https://arxiv.org/html/2601.03666/x5.png",
                "caption": "Figure 5:The performances ofe5-omni-7B under different training settings on MMEB-V2. We report the overall scores using same metric as in Table1.",
                "position": 876
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADetailed Results on MMEB-V2",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03666/x6.png",
                "caption": "Figure 6:Sensitivity to negative curriculum settings on MMEB-V2 (7B backbone).",
                "position": 2721
            }
        ]
    },
    {
        "header": "Appendix CAdditional Hyperparameter Studies",
        "images": []
    }
]