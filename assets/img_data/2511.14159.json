[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.14159/x1.png",
                "caption": "Figure 1:(a)Misleading Textual Input:\nmisleading questions are created by injecting inaccurate or irrelevant information into otherwise normal queries. (b)Misleading Visual Input: misleading visual cues arise from real-world scenes, causing models to misinterpret the image content (e.g., stools mistaken for mushrooms).",
                "position": 90
            },
            {
                "img": "https://arxiv.org/html/2511.14159/x2.png",
                "caption": "Figure 2:Examples from six misleading categories defined in MVI-Bench. Each pair contains anormal image(left) andmisleading image(right) with the same MCQ and corresponding ground-truth answer. For the misleading image, an additional distractor option is shown alongside the correct answer. Answer choices are omitted for brevity (see Fig.4for full format).",
                "position": 155
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3MVI-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.14159/x3.png",
                "caption": "Figure 3:Overview of MVI-Bench statistics.(a) Six balanced misleading visual categories.\n(b) Three diverse image sources: natural, synthetic, and edited.\n(c) Broad object coverage across multiple domains.\n(d) High pairwise similarity ensures semantic consistency between normal and misleading image pairs.",
                "position": 387
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.14159/x4.png",
                "caption": "Figure 4:Comparison between the “non-think” and “think” modes of SAIL-VL.In the non-think mode, the model answers directly based on visual evidence, while in the think mode, the model is guided byhistorical thoughtsand tend tooveremphasize fine details.",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2511.14159/x5.png",
                "caption": "Figure 5:Attention-guided masking for a counterintuitive instance.Qwen2.5-VL-7B spuriously associates a receipt with a book.\n(a) On the normal image with one book, it answers incorrectly.\n(b) On the misleading image, it coincidentally answers “2” by counting the receipt as an extra book.\n(c) Masking the receipt flips the prediction, confirming the spurious correlation.",
                "position": 1593
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix ALimitations and Future Work",
        "images": []
    },
    {
        "header": "Appendix BEthics Statement",
        "images": []
    },
    {
        "header": "Appendix CMore Details about MVI-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.14159/x6.png",
                "caption": "Figure 6:Benchmark Curation Pipeline.The pipeline starts with image collection, followed by VQA annotation, data filtering, and ultimately results in MVI-Bench. To ensure data quality, human verification is performed at each key stage to eliminate low-quality data, annotations, and ambiguous evaluation questions.",
                "position": 1648
            },
            {
                "img": "https://arxiv.org/html/2511.14159/x7.png",
                "caption": "Figure 7:Comparison between the “non-think” and “think” modes of SAIL-VL.In the non-think mode, the model answers directly based on visual evidence, while in the think mode, the model is guided byhistorical thoughtsand tend tooveremphasize fine details.",
                "position": 1651
            }
        ]
    },
    {
        "header": "Appendix DExperiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.14159/x8.png",
                "caption": "Figure 8:More Examples from six misleading categories defined in MVI-Bench.",
                "position": 2142
            }
        ]
    },
    {
        "header": "Appendix EMore Cases",
        "images": []
    }
]