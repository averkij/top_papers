[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/main_fig.png",
                "caption": "Figure 1:Our Main Contributions. We develop a novel probabilistic metric for model similarity, CAPA (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT), which adjusts for chance agreement due to accuracy. Using this, we find (1) LLM-as-a-judge scores are biased towards more similar models controlling for the model’s capability (2) Gain from training strong models on annotations of weak supervisors (weak-to-strong generalization) is higher when the two models are more different, (3) Concerningly, model errors are getting more correlated as capabilities increase.",
                "position": 174
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/OPENLLMLB_MCQ_data/judgement_scores_vs_similarity.png",
                "caption": "Figure 2:Judgment Score relation with Model Similarity.Each line is a regression model fit between judgment and similarity scores as computed between model and judge pairs. Each point represents a single pair, and⋄⋄\\diamond⋄indicates that both, the model and the judge, come from the same model family. We report for each fit the corresponding Pearson correlation values,r𝑟ritalic_r. We found significant positive correlation between judgment scores and similarity across all judges,∗⁣∗**∗ ∗indicatesp<0.01𝑝0.01p<0.01italic_p < 0.01.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x1.png",
                "caption": "Figure 3:Similarity vs Gain from Weak-to-Strong Training.Across 12 model pairs, the strong student gains more from weak-to-strong training on tasks where it is more different from the weak supervisor (p<0.01𝑝0.01p<0.01italic_p < 0.01).",
                "position": 504
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x2.png",
                "caption": "Figure 4:Role of Complementary Knowledge and Elicitation in Weak-to-Strong Generalization. We decompose the accuracy of the weak-to-strong trained model on four parts of the test data distribution, based on the correctness of the weak supervisor and an oracle strong elicited model which uses ground-truth annotations. Sub-rectangles represent weak, strong model pairs. Results are averaged across 15 tasks. Complementary knowledge transfer explains weak-to-strong model accuracy beyond elicitation.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/size_colored_by_family.png",
                "caption": "Figure 5:Average Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) vs Model Capability. We split 130 LMs into 5 buckets based on their accuracy percentile. For each LM we compute its mean similarity within the bucket (across models from different developers), and plot it against model accuracy. The size of the scatter points is proportional to model size. Asκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTmeasures overlap in mistakes, the positive correlation indicates LM mistakes are getting more correlated with increasing capabilities.",
                "position": 572
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/metrics/calibrated_versus_inc.png",
                "caption": "Figure 6:Metric comparison when models tend towards agreement. We compare different metric values for two models in a binary setting. For first model we set 90% accuracy and calibration to 0.99 (meaning the model is highly confident in its answers). For the second model, we increase it’s calibration from 0.01 to 0.99 to approach the same distribution as the first model. On y-axis we are plotting metric value on x-axis we are reportingp¯¯𝑝\\overline{p}over¯ start_ARG italic_p end_ARGfor the second model which as the model becomes more calibrated approaches accuracy of the first model.",
                "position": 2726
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/metrics/calibrated_versus_inc_disagree.png",
                "caption": "Figure 7:Metric comparison when models tend towards disagreement (Read plot from right to left). We compare different metric values for two models in a binary setting. For the first model, we set accuracy to 90% and calibration to 0.99 (the model is highly confident in its answers). For the second model, we incrementally increase its disagreement with model one by pushing its probability mass to the second option and increasing its calibration to 0.99.",
                "position": 2729
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/metrics/calibrated_versus_inc_disagree.png",
                "caption": "Figure 7:Metric comparison when models tend towards disagreement (Read plot from right to left). We compare different metric values for two models in a binary setting. For the first model, we set accuracy to 90% and calibration to 0.99 (the model is highly confident in its answers). For the second model, we incrementally increase its disagreement with model one by pushing its probability mass to the second option and increasing its calibration to 0.99.",
                "position": 2732
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/metrics/calibrated_versus_inc_disagree_adj.png",
                "caption": "Figure 8:Metric comparison when models tend towards disagreement with adjustedκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT. Replication of fig.8but with adjustedκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTas asκp^^subscript𝜅𝑝\\hat{\\kappa_{p}}over^ start_ARG italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT end_ARG, computation following eq.18.",
                "position": 2737
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/OPENLLMLB_MCQ_data/judgement_scores_vs_ours_error_cons.png",
                "caption": "Figure 9:Judgment Scores vs CAPA and vs Error Consistency.We compare the relationship of judge scores on the filtered MMLU-Pro to our improved error consistency and to the original version ofGeirhos et al. (2020).",
                "position": 2793
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/OPENLLMLB_MCQ_data/reference_judgement_scores_vs_mcq_accuracy.png",
                "caption": "Figure 10:Accuracy of free-form responses compared with multiple-choice accuracy on MMLU-Pro.The free-form responses were rated using an ensemble of five capable LM judges. Each judge was given access to the original MMLU-Pro reference answers and their decisions whether a given response is correct or not were aggregated using majority voting.",
                "position": 2813
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/OPENLLMLB_MCQ_data/judgement_scores_vs_reference_judgment_scores.png",
                "caption": "Figure 11:Judgment Scores compared with the ensemble judgment accuracy given access to reference answers.We compare the judgment scores of each judge using only their own knowledge and capabilities to the rating of a judge ensemble that has access to the ground-truth options. The latter is a good proxy of the real correctness of responses.",
                "position": 2832
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x3.png",
                "caption": "Figure 12:We decompose the accuracy of the weak to strong trained model on four parts of the train data distribution based on whether the weak supervisor and an oracle strong elicited model (using ground-truth annotations) are correct or wrong. All results are averaged over 15 datasets. Sub-rectangles represent weak, strong model pairs. On the train dataset, complementary knowledge transfer (mean accuracy0.590.590.590.59) plays an equal role as elicitation (mean accuracy0.560.560.560.56).",
                "position": 6700
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x4.png",
                "caption": "Figure 13:Various Similarity Metrics vs Weak-to-Strong gain. The highest correlation is seen for CAPAκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, though in the binary classification setup of weak-to-strong generalization the probabilistic information does not add much value compared to error consistency.1−J⁢S⁢D1𝐽𝑆𝐷1-JSD1 - italic_J italic_S italic_Dgives a more noisy scatter plot, with lower correlation (r𝑟ritalic_r).",
                "position": 6710
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x4.png",
                "caption": "",
                "position": 6713
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x5.png",
                "caption": "",
                "position": 6717
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x6.png",
                "caption": "",
                "position": 6721
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x7.png",
                "caption": "",
                "position": 6726
            },
            {
                "img": "https://arxiv.org/html/2502.04313/x8.png",
                "caption": "Figure 14:Test Accuracies for various models and ceiling estimates in Weak-to-Strong training. The accuracies are averaged over 12 model pairs. The initial strong student model has consistently lower accuracy than the weak supervisor consistent withBurns et al. (2024); Scherlis et al. (2024). The weak-to-strong trained student surpasses the weak-supervisor across datasets. However it has lower accuracy than the elicitation ceiling which trains the strong student on ground-truth annotations. Finally, our new estimated ceiling which incorporates the complementary knowledge of the weak supervisor has even higher accuracies, showing even more scope for improvements.",
                "position": 6762
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/instruct_base_both.png",
                "caption": "Figure 15:LM Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) vs Capabilities in Instruct-tuned and Base models on MMLU pro and BBH. After applying the same model binning stratergy and pairwise similarity, a steeper trend is observed in the instruct-tuned models compared to base models for both datasets.",
                "position": 7286
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/combined_plots.png",
                "caption": "Figure 16:Role of question difficulty in similarity-capability trend.We plot in parallel (a) Scatter plot with model pairs, illustrating the increasing trend of similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) with model capability. (b) Average similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) across all capability bins for different levels of question hardness. CAPA is mostly consistent across question hardness, with a slight increase on the hardest questions. This shows that question difficulty is not a significant confounder for increasing similarity in mistakes.",
                "position": 7302
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/side_by_side_scatter_other_metrics.png",
                "caption": "Figure 17:Error consistency and JSD for model similarity on BBH and MMLU Pro.The y-axis represents the similarity computed using JSD and Error consistency. JSD exhibits high variance and a flat trend, whereas Error Consistency shows an increasing trend with model capability, similar to the trend observed inκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT.",
                "position": 7366
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/fleiss_kappa_bar_side_by_side.png",
                "caption": "(a)LM Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTforM>2𝑀2M>2italic_M > 2) vs Average Accuracy of Model Pairs in each Capability bin",
                "position": 7375
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/fleiss_kappa_bar_side_by_side.png",
                "caption": "(a)LM Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPTforM>2𝑀2M>2italic_M > 2) vs Average Accuracy of Model Pairs in each Capability bin",
                "position": 7378
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/discrete_kappa_bar_side_by_side.png",
                "caption": "(b)LM Similarity (Discreteκpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) vs Average Accuracy of Model Pairs in each Capability bin",
                "position": 7383
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/subjectwise_MMLU.png",
                "caption": "Figure 19:LM Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) vs Capability on MMLU pro for each subject.The increasing trend holds for all 14 subjects in MMLU pro. The similarity trend is therefore not a consequence of a particular domain or subject in MMLU Pro.",
                "position": 7394
            },
            {
                "img": "https://arxiv.org/html/2502.04313/extracted/6181841/fig/MMLU_cleaned/subset_BBH.png",
                "caption": "Figure 20:LM Similarity (κpsubscript𝜅𝑝\\kappa_{p}italic_κ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT) vs Capability on each Big-Bench Hard task.The increasing trend holds for most BBH tasks. Each task has atmost 250 questions, resulting in minimal data to compute similarity for the individual tasks.",
                "position": 7397
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]