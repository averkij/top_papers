[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.01592/x1.png",
                "caption": "",
                "position": 160
            }
        ]
    },
    {
        "header": "Takeaway Messages",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Framework",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.01592/x2.png",
                "caption": "Figure 2:Computational cost of various attack methods against GPT-5.2, measured by input and output token usage (log10scale).",
                "position": 2226
            },
            {
                "img": "https://arxiv.org/html/2601.01592/x3.png",
                "caption": "Figure 3:Attack stealthiness against GPT-5.2 measured by perplexity (PPL) on Qwen3-32B (log10scale). Lower PPL indicates more stealthy prompts. Shaded bands mark high (<10<10), moderate (1010â€“3030), and low (>30>30) stealthiness.",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2601.01592/x4.png",
                "caption": "Figure 4:Diversity analysis of attack methods against GPT-5.2, quantified by the mean pairwise cosine distance between embeddings of successful adversarial prompts.",
                "position": 2248
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAppendix: Usage and Extensibility",
        "images": []
    }
]