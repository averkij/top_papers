[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04062/x1.png",
                "caption": "Figure 1:Up to 91% forward step reduction with ZipAR. Samples are generated by Emu3-Gen model with next-token prediction paradigm (the first column) and ZipAR (the right three columns).",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04062/x2.png",
                "caption": "Figure 2:(a) An overview of the training and decoding pipeline for auto-regressive (AR) visual generation models. For models trained with a next-token prediction objective, each forward pass generates a single visual token. (b) Medusa[2]and Jacobi[16]decoding predict multiple adjacent tokens in sequence order. (c) MAR[13]predicts multiple tokens in a random order. (d) The proposed ZipAR predicts multiple spatially adjacent tokens.",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2412.04062/x3.png",
                "caption": "Figure 3:The attention scores of visual tokens in the Lumina-mGPT-7B[14]and LlamaGen-XL[17]models.Slash lines indicate that significant attention scores are allocated to tokens at fixed intervals, corresponding to tokens in the same column of previous rows.The full attention scores are presented by storing the attention scores of each visual token during decoding and concatenating them.",
                "position": 97
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04062/x4.png",
                "caption": "Figure 4:A toy example of the ZipAR framework. The window size is set to2222in this toy example.",
                "position": 146
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04062/x5.png",
                "caption": "Figure 5:Samples generated by Emu3-Gen model with next-token prediction paradigm (the first column) and ZipAR under different configurations (the right three columns). The classifier-free guidance is set to 6.0.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2412.04062/x6.png",
                "caption": "Figure 6:Samples generated by LlamaGen-XL model with next-token prediction paradigm (the first column) and ZipAR under different configurations (the right three columns). The classifier-free guidance is set to 7.5.",
                "position": 306
            },
            {
                "img": "https://arxiv.org/html/2412.04062/x7.png",
                "caption": "Figure 7:Samples generated by Lumina-mGPT-7B-768 model with next-token prediction paradigm (the first column) and ZipAR under different configurations (the right three columns). The classifier-free guidance is set to 3.",
                "position": 311
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]