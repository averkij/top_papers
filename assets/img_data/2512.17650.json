[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17650/x1.png",
                "caption": "Figure 1:Our ReCo enables video editing based on sole textual instructions, achieving precise and high-fidelity video content modification. ReCo can adeptly handle diverse and challenging video editing tasks, including both local object editing and global style transfer.",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17650/x2.png",
                "caption": "Figure 2:An overview of our ReCo framework.\nWe reformulate the instructional video editing task as anin-context generationparadigm, guided by the source video and instruction prompt.\nThe source video is treated as an explicit condition via feeding it into an auxiliary video condition branch.\nTo emphasize editing modifications and alleviate the tokens interference between editing and non-editing areas, ReCo introduces two region-based constraints:\n(1) Latent-space regularization, which increases the latent discrepancy of the editing region between source and target videos while reducing that of non-editing areas.\n(2) Attention-space regularization, which suppresses the attention of the target edit region towards the corresponding region in the source video, thereby mitigating inherent token interference, while simultaneously strengthening the attention on its own generated content.",
                "position": 115
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Our Approach",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17650/x3.png",
                "caption": "Figure 3:Comparison between existing video editing datasets and our ReCo-Data. Ours features the most balanced data distribution and has a higher ratio of the high-quality samples.",
                "position": 705
            },
            {
                "img": "https://arxiv.org/html/2512.17650/x4.png",
                "caption": "Figure 4:Examples of video editing (i.e., add object, replace object and style transfer) results by different approaches.",
                "position": 746
            },
            {
                "img": "https://arxiv.org/html/2512.17650/x5.png",
                "caption": "Figure 5:Visual comparisons on the object removal task.",
                "position": 749
            },
            {
                "img": "https://arxiv.org/html/2512.17650/x6.png",
                "caption": "Figure 6:Editing results on replace task among variants of ReCo.",
                "position": 872
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "1Construction Pipeline of ReCo-Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17650/x7.png",
                "caption": "Figure 7:An overview of our data construction pipeline. The process consists of six main stages: raw data pre-processing, object segmentation, instruction generation, condition pair construction, video synthesis, and video filtering and re-captioning.",
                "position": 968
            }
        ]
    },
    {
        "header": "2VLLM-based Evaluation Benchmark",
        "images": []
    },
    {
        "header": "3Implementation of Baselines and ReCo",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.17650/x8.png",
                "caption": "Figure 8:The system prompts that are fed into Gemini-2.5-Flash-Thinking[team2023gemini]for video editing assessment. We require VLLM to evaluate the four video editing tasks from three major perspectives, i.e., edit accuracy, video naturalness and video quality.",
                "position": 1212
            },
            {
                "img": "https://arxiv.org/html/2512.17650/x9.png",
                "caption": "Figure 9:Four examples of instructional video editing by ReCo to verify the generalization ability. Our model demonstrates the strong generalization to the abstract and creative editing tasks.",
                "position": 1215
            }
        ]
    },
    {
        "header": "4Generalization Ability of ReCo",
        "images": []
    }
]