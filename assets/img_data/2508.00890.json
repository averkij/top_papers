[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary Knowledge and Problem Definition",
        "images": []
    },
    {
        "header": "4Insights of Test-time Scaling on Multi-stage Complex Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00890/x1.png",
                "caption": "Figure 1:Performance variance on 2WikiMultiHopQA with increasing sampling and inference FLOPs.\nTop: performance by sample count; bottom: performance by log-scaled inference FLOPs.\n(a) Retrieval accuracy measured by Retrieval F1 (Ret_F1). (b-d) QA performance under varying retrieval quality levels measured by Gen_EM, the exact match between the generated answer and ground truth",
                "position": 266
            }
        ]
    },
    {
        "header": "5AgentTTS: Agent for Test-time Scaling Budget Allocation",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00890/x2.png",
                "caption": "Figure 2:Overview of LLM Agent for Test-time Scaling Budget Allocation.",
                "position": 299
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00890/x3.png",
                "caption": "Figure 3:Performance trajectories across various search methods over 50 trials.\nX-axis: trial count; Y-axis: best performance up to each trial. The best score is obtained from the optimal trial in a prior grid search and serves as the benchmark for all methods. More results are in AppendixA.7.",
                "position": 410
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x4.png",
                "caption": "Figure 4:(a-c) Search trajectories under varying training sizes on 2WikiMultiHopQA. (d) Ablation study on 2WikiMultiHopQA with a total budget of 900.",
                "position": 876
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x5.png",
                "caption": "Figure 5:Interpreting AgentTTS Through Integrated Empirical Insights. 2Wiki means 2WikiMultiHopQA. A complete case is in AppendixA.8.",
                "position": 882
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x6.png",
                "caption": "Figure 6:Comparative search results under low, medium, and high compute budget settings.",
                "position": 890
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.00890/x7.png",
                "caption": "Figure 7:Test-time scaling and AgentTTS search trajectories under price budget. Left: scaling curves; Right: corresponding search trajectories.",
                "position": 3339
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x8.png",
                "caption": "(a)2Wiki-Ret",
                "position": 3402
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x8.png",
                "caption": "(a)2Wiki-Ret",
                "position": 3405
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x9.png",
                "caption": "(b)2Wiki-QA",
                "position": 3410
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x10.png",
                "caption": "(c)Hotpot-Ret",
                "position": 3415
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x11.png",
                "caption": "(d)Hotpot-QA",
                "position": 3421
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x12.png",
                "caption": "(e)CWQ-Ret",
                "position": 3426
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x13.png",
                "caption": "(f)CWQ-QA",
                "position": 3431
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x14.png",
                "caption": "(g)TaskBench-Decomp",
                "position": 3437
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x15.png",
                "caption": "(h)TaskBench-ToolSel",
                "position": 3442
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x16.png",
                "caption": "(i)TaskBench-ParamPred",
                "position": 3447
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x17.png",
                "caption": "Figure 9:Performance variance on 2WikiMultiHopQA with increasing sampling, inference FLOPs, and budget.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a) Retrieval accuracy measured by Retrieval F1 (Ret_F1). (b-d) QA performance under varying retrieval quality levels measured by Gen_EM, the exact match between the generated answer and the ground truth.",
                "position": 3461
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x18.png",
                "caption": "Figure 10:Performance variance on HotpotQA with increasing sampling, inference FLOPs, and budget.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a) Retrieval subtask performance; (b-d) Question answering performance under different retrieval quality levels.",
                "position": 3467
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x19.png",
                "caption": "Figure 11:Performance variance on CWQ with increasing sampling, inference FLOPs, and budget.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a) Retrieval performance; (b-d) Question answering performance under different retrieval quality levels.",
                "position": 3474
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x20.png",
                "caption": "Figure 12:Performance variance on WebQSP with increasing sampling, inference FLOPs, and budget.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a) Retrieval performance; (b-d) Question answering performance under different retrieval quality levels.",
                "position": 3479
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x21.png",
                "caption": "Figure 13:Performance variance on Taskbench-DailyAPIUsage with increasing sampling, inference FLOPs, and budget.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a) Task decomposition performance; (b) Tool selection performance; (c-d) Parameter prediction under different tool-selection quality levels.",
                "position": 3484
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x22.png",
                "caption": "Figure 14:Performance variance on ChatDev with increasing sampling and inference FLOPs.\nTop: performance by sample count; middle: performance by log-scaled inference FLOPs; bottom: performance by normalized budget.\n(a-c) The consistency score during coding, static test, and dynamic test, respectively.",
                "position": 3489
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x23.png",
                "caption": "Figure 15:Performance trajectories across various search methods over 50 trials.\nX-axis: trial count; Y-axis: best performance up to each trial. The best score is obtained from the optimal trial in a prior grid search and serves as the benchmark for all methods.",
                "position": 3501
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x24.png",
                "caption": "Figure 16:Detailed Cases of Interpreting AgentTTS Through Integrated Empirical Insights.",
                "position": 3516
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x25.png",
                "caption": "(a)AgentTTS on 2Wiki (budget = 850).",
                "position": 3525
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x25.png",
                "caption": "(a)AgentTTS on 2Wiki (budget = 850).",
                "position": 3528
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x26.png",
                "caption": "(b)AgentHPO on 2Wiki (budget = 850).",
                "position": 3534
            },
            {
                "img": "https://arxiv.org/html/2508.00890/x27.png",
                "caption": "Figure 18:Class Diagram of the AgentTTS Framework.",
                "position": 3733
            }
        ]
    },
    {
        "header": "Appendix ATechnical Appendices and Supplementary Material",
        "images": []
    }
]