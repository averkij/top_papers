[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18933/extracted/6028427/figures/intro.png",
                "caption": "Figure 1:Comparative analysis. (Left) Speed comparison between EfficientTAM and SAM 2 on a single NVIDIA A100 GPU. While SAM 2 is challenging for on-device deployment, our EfficientTAM can run 261 ms per frame on iPhone 15 Pro Max. (Right)\nFPS/Parameter/Performance comparison of EfficientTAM, SAM 2, and other efficient models for zero-shot video object segmentation on SA-V test. We benchmark FPS (frames per second) of all models with 1024 Ã— 1024 input resolution on a single NVIDIA A100.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18933/x1.png",
                "caption": "Figure 2:EfficientTAM architecture. Our proposed EfficientTAM takes a vanilla lightweight ViT image encoder for frame feature extraction. An efficient memory cross-attention is proposed to further improve the efficiency of EfficientTAM by leveraging the strong locality of memory spatial embeddings. EfficientTAM is fully trained on SA-1B (image) and SA-V (video) for unified image and video segmentation.",
                "position": 209
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Efficient Cross-Attention",
        "images": []
    },
    {
        "header": "8Ablation Studies",
        "images": []
    },
    {
        "header": "9Qualitative Evaluation",
        "images": []
    }
]