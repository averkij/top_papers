[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15499/x1.png",
                "caption": "Figure 1:Training/validation loss with downstream performance on HellaSwag and PIQA for 1B dense models trained with 2T tokens: SDD-1B (Post-Norm) achieves superior convergence (1.5√ó1.5\\times1.5 √ó) and generalization over OLMo2-1B (Pre-Norm).",
                "position": 91
            }
        ]
    },
    {
        "header": "2Scale-Distribution Decoupling",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15499/x2.png",
                "caption": "Figure 2:Comparison of vanilla and SDD-based Self-Attention /FFN Architectures. The top-left figure shows the standard self-attention module, while the top-right presents the self-attention module with SDD. Similarly, the middle figure depicts the standard feed-forward network (FFN), and the bottom shows the SDD-based FFN. In these figures, ‚ÄúFC‚Äù represents a fully-connected layer, and ‚ÄúSDD‚Äù denotes the SDD-based fully-connected layer, formulated as Eqn.1. Labels beneath ‚ÄúFC‚Äù and ‚ÄúSDD‚Äù indicate their learnable parameters. Notably, the additional parameterŒ±ùõº\\alphaitalic_Œ±in ‚ÄúSDD‚Äù is a one-dimensional vector, contributing negligible overhead.",
                "position": 137
            }
        ]
    },
    {
        "header": "3Theoretical Analysis",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15499/x3.png",
                "caption": "Figure 3:Training and validation loss on C4 for dense models trained with 200 billion tokens. A comparison of OLMo2-1B (Pre-Norm), DeepNorm-1B (Post-Norm), PostNorm-1B (Post-Norm), and SDD-1B (Post-Norm) highlights the superior convergence and stability of SDD-1B.",
                "position": 406
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x4.png",
                "caption": "Figure 4:Downstream performance on MMLU, HellaSwag, ARC-Challenge, and OpenbookQA for dense models trained on 200B tokens. SDD-1B consistently outperforms others, showcasing superior generalization.",
                "position": 417
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x5.png",
                "caption": "Figure 5:Training and Validation Loss on C4 for MoE Models with 250 Billion Tokens: Comparison of OLMoE-588M-3B (Pre-Norm) and SDD-588M-3B (Post-Norm).",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x6.png",
                "caption": "Figure 6:Downstream performance on MMLU, HellaSwag, ARC-Challenge, and Commonsense for MoE models with 250 billion training tokens.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x7.png",
                "caption": "Figure 7:Comparison of Gradient Norms Across Layers. We compare four methods: OLMo2-1B (Pre-Norm), PostNorm-1B, DeepNorm-1B, and SDD-1B (all Post-Norm). ‚Äúatt_proj‚Äù refers to the query/key/value projection, ‚Äúattn_out‚Äù to the attention output projection, ‚Äúff_proj‚Äù to the gating and first FC layer in the feed-forward network (FFN), and ‚Äúff_out‚Äù to the second FC layer in the FFN. SDD-1B demonstrates notably stable gradient norms, effectively addressing gradient explosion and vanishing.",
                "position": 526
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x8.png",
                "caption": "Figure 8:Training and downstream performance of SDD-588M-3B with Pre-Norm and Post-Norm compared to OLMoE-588M-3B (Pre-Norm). Models trained on 250 billion tokens show that SDD improves convergence speed and downstream accuracy in the Pre-Norm setting. Switching to Post-Norm with SDD yields even greater performance gains.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x9.png",
                "caption": "Figure 9:Layer-Wise Feature Similarity Across Normalization Methods. This figure compares feature similarity across layers in OLMo2-1B, PostNorm-1B, DeepNorm-1B, and SDD-1B. SDD-1B achieves the highest inter-layer similarity, indicating more stable feature propagation.",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x10.png",
                "caption": "",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x11.png",
                "caption": "",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x12.png",
                "caption": "",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x13.png",
                "caption": "Figure 10:Scaling with model depth: OLMo2-1B (Pre-Norm) vs. SDD-1B (Post-Norm). All models are trained on 200 billion tokens, with only the number of layers varied. SDD shows superior scaling behavior as model depth increases, highlighting its robustness in deeper networks.",
                "position": 699
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AOmitted Proof",
        "images": []
    },
    {
        "header": "Appendix BArchitectural Configuration",
        "images": []
    },
    {
        "header": "Appendix CAdditional Results on Dense models",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15499/x14.png",
                "caption": "Figure 11:Training and Downstream Performance of Dense Models. This figure compares validation loss and downstream task performance for SDD-1B and OLMo2-1B trained on 2T tokens, alongside PostNorm-1B and DeepNorm-1B trained on 200B tokens. SDD-1B exhibits lower loss and superior generalization, demonstrating its effectiveness in large-scale training.",
                "position": 1492
            },
            {
                "img": "https://arxiv.org/html/2502.15499/x15.png",
                "caption": "Figure 12:Training and Downstream Performance of MoE Models with 250B Tokens. This figure compares the validation loss and downstream task performance of SDD-588M-3B and OLMoE-588M-3B. SDD-588M-3B demonstrates lower loss and superior generalization across benchmarks, highlighting its effectiveness in MoE training.",
                "position": 1502
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results on MoE models",
        "images": []
    }
]