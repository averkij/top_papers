[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04378/x1.png",
                "caption": "Figure 1:Dedicated Feedback and Edit Models enables Llama-3.1-Nemotron-70B-Instruct to reach SoTA performance on Arena Hard at 92.7 as of 5 Mar 2025, compared to 90.4 achieved by OpenAI o1-preview-2024-09-12(LMSys,2024)and 92.3 by DeepSeek R1(DeepSeek-AI etÂ al.,2025)* means model specialized in Math, Coding and Logic problems, which are highly represented in Arena Hard.",
                "position": 203
            }
        ]
    },
    {
        "header": "2Dataset",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": []
    },
    {
        "header": "5Ablation Studies",
        "images": []
    },
    {
        "header": "6Scaling",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04378/x2.png",
                "caption": "Figure 2:Feedback and Edit Models enable effective Inference-Time scaling across various dimensions.",
                "position": 777
            }
        ]
    },
    {
        "header": "7Distillation",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt Preprocessing",
        "images": []
    },
    {
        "header": "Appendix BPrompt Templates",
        "images": []
    },
    {
        "header": "Appendix CBad Edit Details",
        "images": []
    },
    {
        "header": "Appendix DFurther Dataset Statistics",
        "images": []
    },
    {
        "header": "Appendix EIllustrative Example",
        "images": []
    },
    {
        "header": "Appendix FAligned Model Evaluation Details",
        "images": []
    },
    {
        "header": "Appendix GTraining Details",
        "images": []
    },
    {
        "header": "Appendix HCompute requirements",
        "images": []
    },
    {
        "header": "Appendix IExample Feedback by prompting Llama-3.1-Nemotron-70B-Instruct",
        "images": []
    },
    {
        "header": "Appendix JExample Feedback by Feedback Model",
        "images": []
    }
]