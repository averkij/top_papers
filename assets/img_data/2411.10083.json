[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work on Multilingual Large Language Models",
        "images": []
    },
    {
        "header": "3Pretraining",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.10083/x1.png",
                "caption": "Figure 1:Total multilingual data tokens during the pretraining phase sourced from MultiWiki and CulturaX.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2411.10083/x2.png",
                "caption": "Figure 2:Data distribution during pretraining between 44,000 and 190,000 steps.",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2411.10083/x2.png",
                "caption": "Figure 2:Data distribution during pretraining between 44,000 and 190,000 steps.",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2411.10083/x3.png",
                "caption": "Figure 3:Data distribution during the decay phase.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/f_line_loss.png",
                "caption": "Figure 4:The trend of training and validation loss during pretraining.",
                "position": 411
            }
        ]
    },
    {
        "header": "4Post-training",
        "images": []
    },
    {
        "header": "5Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/radar.png",
                "caption": "Figure 5:Comparison of performance in multilingual tasks between PolyLM 1.7B and Xmodel-1.5 1B",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2411.10083/x4.png",
                "caption": "Figure 6:The distribution of task types in our evaluation set. Task types with fewer than 5 occurrences were removed.",
                "position": 662
            }
        ]
    },
    {
        "header": "6Case Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/eval_results_ar_evolutions.png",
                "caption": "Figure 7:Evolution of performance in Arabic bench during pre-training",
                "position": 683
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/eval_results_th_evolutions.png",
                "caption": "Figure 8:Evolution of performance in Thai bench during pre-training",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/eval_results_fr_evolutions.png",
                "caption": "Figure 9:Evolution of performance in French bench during pre-training",
                "position": 689
            }
        ]
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "8Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/website.png",
                "caption": "Figure 10:Annotation interface for students at Chulalongkorn University",
                "position": 1375
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/efficient_and_concise_answers.png",
                "caption": "Figure 11:The model performs well in e-commerce Q&A, providing concise and clear answers.",
                "position": 1390
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/sexual_species_bad_case.png",
                "caption": "Figure 12:The model struggles with distinguishing gendered language in Thai, particularly with gendered particles.",
                "position": 1396
            },
            {
                "img": "https://arxiv.org/html/2411.10083/extracted/6001620/figures/time_bad_case.png",
                "caption": "Figure 13:The model faces challenges in handling time and numerical data in Thai, leading to translation errors.",
                "position": 1402
            }
        ]
    },
    {
        "header": "9Appendix",
        "images": []
    }
]