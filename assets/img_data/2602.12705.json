[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/figures/teaser.png",
                "caption": "Figure 1:Performance comparison of MedXIAOHE against SOTA models on comprehensive medical benchmarks.The left panel shows the overall average score across 30+ benchmarks, demonstrating the strong performance of MedXIAOHE. The right panels detail the comparative results across six key capabilities. In the upper-left bar chart, dark bars represent scores on public benchmarks, and light bars represent scores on in-house benchmarks. We did not evaluate in-house benchmarks on Gemini 3.0 Pro because of changes in its privacy protocols.",
                "position": 203
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/x1.png",
                "caption": "Figure 2:The architecture of MedXIAOHE.The model utilizes a Multimodal Native-Resolution Transformer to process diverse medical imaging modalities (e.g., X-ray, CT, Pathology) with varying resolutions and aspect ratios. Visual features encoded by Seed-ViT are projected via an MLP Adapter and interleaved with text tokens, integrating medical knowledge and patient records to support multi-turn dialogue and reasoning-based generation.",
                "position": 267
            }
        ]
    },
    {
        "header": "2Overview and Architecture",
        "images": []
    },
    {
        "header": "3Continual Pre-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/figures/pretrain_data_pipeline_v6.png",
                "caption": "Figure 3:Data-cleaning pipeline for the continual pretraining corpus.The pipeline comprises two main stages: a text-cleaning workflow and a multimodal data production workflow. To construct a high-quality pretraining corpus, we apply a combination of hash-based deduplication, rule-based filtering, and model-based quality control.",
                "position": 688
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/MedicalEntityTree.png",
                "caption": "Figure 4:Architecture overview of the Medical Entity Tree.This hierarchical taxonomy organizes medical concepts into aligned categories to facilitate balanced entity training, precise knowledge coverage quantification, and entity-driven data acquisition.",
                "position": 718
            }
        ]
    },
    {
        "header": "4Mid-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/x2.png",
                "caption": "Figure 5:Mid-training data construction overview.The framework illustrates the comprehensive pipeline designed to synthesize high-fidelity medical reasoning data from diverse sources.a,The data synthesis engine aggregates unsupervised and supervised corpora, utilizing knowledge graphs and multi-agent consensus to construct structured reasoning datasets.b,A multi-expert reject sampling mechanism with dual-quality gates is employed to distill diverse and causally valid reasoning trajectories.c,The process incorporates a structured Chain-of-Thought construction pipeline with automatic quality checks, strictly aligning visual perception with logical deduction to eliminate hallucinations.",
                "position": 1111
            },
            {
                "img": "https://arxiv.org/html/2602.12705/x3.png",
                "caption": "Figure 6:Agentic Data Synthesis and Training Pipeline.The system integrates a comprehensive toolset including General Search (Google, Scholar), Medical Search (Drug Labels, Clinical Records), and Image Editing (Zoom In, Rotate). The pipeline synthesizes challenging QA pairs through difficulty filtering, ensuring questions require multi-step tool use. Finally, an Agentic RL process trains the model to interact, observe, and summarize, producing structured traces that include specific tool definitions, thought processes, and execution results.",
                "position": 1158
            }
        ]
    },
    {
        "header": "5Post-training",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/x4.png",
                "caption": "Figure 7:Post-training Pipeline. During post-training, we adopt the same synthesis pipeline as in mid-training, augment it with expert annotations, and perform SFT followed by RL optimization. In parallel, we mine hard negatives via rejection sampling and feed them back into the training loop for iterative refinement.",
                "position": 1262
            },
            {
                "img": "https://arxiv.org/html/2602.12705/x5.png",
                "caption": "Figure 8:Architecture of the Multi-Layered Hybrid Reward System.Data Router directs inputs to two parallel reward modules: Rule-based Reward, and Rubric Reward. The Aggregation Layer combines these signals into a final scalar reward for RL optimization.",
                "position": 1334
            }
        ]
    },
    {
        "header": "6Unified Med-VLM Benchmark",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Contributions",
        "images": []
    },
    {
        "header": "9Qualitative examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.12705/x6.png",
                "caption": "Figure 9:An example of tool-assisted medical reasoning: the model retrieves and verifies evidence before producing the answer.",
                "position": 2504
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/think_with_image_original_pic.png",
                "caption": "Figure 10:An example of magnification-assisted reasoning. The process flows vertically: the model analyzes the original image, calls a zoom tool, observes the zoomed-in crop (inserted in the middle), and concludes the diagnosis.",
                "position": 2518
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/think_with_image_zoom_in.png",
                "caption": "",
                "position": 2547
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/think_with_image_zoom_in2.png",
                "caption": "",
                "position": 2547
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/grounding_case_raw.png",
                "caption": "Figure 11:Process of Medical Grounding Reasoning: The model takes the raw X-ray (top), analyzes it via logical reasoning (middle text), and outputs grounded bounding boxes for abnormalities (displayed in middle and bottom visualizations).",
                "position": 2566
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/grounding_case_main.png",
                "caption": "",
                "position": 2577
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/grounding_case_res.png",
                "caption": "",
                "position": 2584
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/complex_diagnostic_case.jpg",
                "caption": "Figure 12:An example of a complex diagnostic. The model links pancytopenia with splenomegaly to “hairy” lymphoid cells on the peripheral smear and concludes Hairy Cell Leukemia (TRAP+).",
                "position": 2611
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/rk_taoge_stage2_case_fig1.png",
                "caption": "Figure 13:Example of radiology report generation with structured CoT, showing three input chest X-ray views, the prompt, stepwise reasoning, and the final Findings/Impression output.",
                "position": 2681
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/rk_taoge_stage2_case_fig2.png",
                "caption": "",
                "position": 2685
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/rk_taoge_stage2_case_fig3.png",
                "caption": "",
                "position": 2685
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/heart_report.jpeg",
                "caption": "Figure 14:An example of precise information extraction from a deformed clinical report. The model identifies the specific row in the measurement table, uses the ZOOM tool to correct for resolution and deformation issues, and accurately extracts the numerical value requested by the user. The above content was originally in Chinese.",
                "position": 2724
            },
            {
                "img": "https://arxiv.org/html/2602.12705/figures/heart_tool_call.jpeg",
                "caption": "",
                "position": 2768
            }
        ]
    },
    {
        "header": "10Evaluation Details",
        "images": []
    },
    {
        "header": "11Prompts for Entity Extraction",
        "images": []
    }
]