[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08115/extracted/5917356/figs/title-2.png",
                "caption": "",
                "position": 64
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x1.png",
                "caption": "Figure 1:Performance and efficiency ofOptimavariants across optimization iterations.Left: Average performance gain over iterations.Optimavariants consistently outperform CoT, Multi-Agent Debate (MAD), and Self-Consistency.Right: Average inference token numbers over iterations. AllOptimavariants achieve better performance with substantially fewer tokens.",
                "position": 78
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x1.png",
                "caption": "",
                "position": 81
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x2.png",
                "caption": "",
                "position": 85
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Optima: Optimizing Multi-Agent LLMs via Iterative Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08115/x3.png",
                "caption": "Figure 2:Overview of theOptimaframework for training LLM-based MAS. The iterative process includes four stages:Generate, Rank, Select, andTrain. Note that the ranking process, while also involved in DPO data generation, is not shown in the Generate stage for simplicity.",
                "position": 119
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08115/x4.png",
                "caption": "(a)Inference scaling on debate tasks",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x4.png",
                "caption": "(a)Inference scaling on debate tasks",
                "position": 698
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x5.png",
                "caption": "(b)Performance vs. token usage on GSM8k",
                "position": 703
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x6.png",
                "caption": "Figure 4:Case study: Evolution of agent communication inOptima-iSFT across iterations on 2WMH QA.The different contexts given to the two agents are omitted for brevity. The progression demonstrates increasing efficiency and task-oriented communication.",
                "position": 820
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AInference Scaling Laws on Information Exchange Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08115/x7.png",
                "caption": "(a)iSFT on Debate tasks.",
                "position": 1927
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x7.png",
                "caption": "(a)iSFT on Debate tasks.",
                "position": 1930
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x8.png",
                "caption": "(b)iDPO on Debate tasks.",
                "position": 1935
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x9.png",
                "caption": "(c)iSFT-DPO on Debate tasks.",
                "position": 1940
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x10.png",
                "caption": "(d)iSFT on IE tasks.",
                "position": 1946
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x11.png",
                "caption": "(e)iDPO on IE tasks.",
                "position": 1951
            },
            {
                "img": "https://arxiv.org/html/2410.08115/x12.png",
                "caption": "(f)iSFT-DPO on IE tasks.",
                "position": 1956
            }
        ]
    },
    {
        "header": "Appendix BAdditional Pseudo-Codes forOptimaVariants",
        "images": []
    },
    {
        "header": "Appendix CCase Study on Reward Components Ablation",
        "images": []
    },
    {
        "header": "Appendix DCase Study on Debate Task",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.08115/x13.png",
                "caption": "Figure 6:Evolution of agent communication inOptimafor a debate task across iterations.",
                "position": 2401
            }
        ]
    },
    {
        "header": "Appendix EExperiment Details",
        "images": []
    },
    {
        "header": "Appendix FPrompts used in Experiments",
        "images": []
    }
]