[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06329/figs/signal4.png",
                "caption": "Figure 1:Acoustic discontinuity disturbs negative log-likelihood loss (NLL) responses locally.Top: SALMon samples consist of a shared prompt and a separate continuation, where positive samples maintain acoustic consistency, and negative samples contain abrupt acoustic transitions. Bottom: NLL response of Llama-Mimi-1.3B with standard error margins. Response on negative samples show localized spike within a short temporal window after the transition in contrast to the positive sample. Global token perplexity aggregates likelihood contributions outside this localized region (Sec.2.2), making it susceptible to long-range loss volatility, thereby motivating our localized and normalized evaluation methods (Sec.3.1,3.2)",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x1.png",
                "caption": "",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x2.png",
                "caption": "Figure 2:NLL response of various models on SALMon samples with standard error margins. High-scoring models on SALMon (e.g., Flow-SLM) exhibit localized NLL spikes for negative samples within a short temporal window after the transition. This behavior is less apparent in lower-performing models such as GSLM.",
                "position": 138
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x3.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x4.png",
                "caption": "",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x5.png",
                "caption": "",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x6.png",
                "caption": "",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x7.png",
                "caption": "",
                "position": 153
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Proposed Method",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06329/x8.png",
                "caption": "Figure 3:Overall performance of spoken language models on consistency tasks.The x-axis shows model accuracy (score) under different evaluators: (a1) alternative likelihood estimators, (b) MOS, and (c) embedding-as-a-judge, where model color codes are shown in (a1) and shared among all plots. In (a1), we correlate scores from proposed methods against those from global token perplexity (Global-PPL); the horizontal spread highlights the discrepancy across evaluation methods. The alternative methods rate strong models more favorably thanGlobal-PPL, substantially closing the gap to the human topline. In (a2), we correlate deviations from the proposed methods againstGlobal-PPLscores. Deviations generally become larger at higherGlobal-PPLperformance (blue), until it saturates due to the maximum performance ceiling (orange). Negative deviations exhibit a similar trend in absolute magnitude, though this is less surprising since they are soft-bounded by distance to random baseline (green).",
                "position": 414
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x9.png",
                "caption": "",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x10.png",
                "caption": "",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x11.png",
                "caption": "",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x12.png",
                "caption": "Figure 4:Correlation between proposed evaluation methods vs golden labels provided by either MOS scores (top), or embedding judge proxies (bottom). The figure shows effectiveness of perplexity normalization and localization. The validility of the embedding judges stem from high correlation with the MOS scores (top right).",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x13.png",
                "caption": "Figure 5:Composition of the average per-sample advantage, which is defined as the difference between the negative loss and the positive loss. Advantage differs across evaluation methods in both token-type composition and loss magnitude.",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x14.png",
                "caption": "",
                "position": 658
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.06329/x15.png",
                "caption": "Figure 6:Positive vs. Negative Sample Mean NLL-Loss Response forGSLMacross six consistency splits.",
                "position": 4688
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x16.png",
                "caption": "Figure 7:Positive vs. Negative Sample Mean NLL-Loss Response forpGSLMacross six consistency splits.",
                "position": 4691
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x17.png",
                "caption": "Figure 8:Positive vs. Negative Sample Mean NLL-Loss Response forTWIST-1.3Bacross six consistency splits.",
                "position": 4694
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x18.png",
                "caption": "Figure 9:Positive vs. Negative Sample Mean NLL-Loss Response forSpirit-LMacross six consistency splits.",
                "position": 4697
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x19.png",
                "caption": "Figure 10:Positive vs. Negative Sample Mean NLL-Loss Response forSpirit-LM-Expressiveacross six consistency splits.",
                "position": 4700
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x20.png",
                "caption": "Figure 11:Positive vs. Negative Sample Mean NLL-Loss Response forTASTEacross six consistency splits. We follow TASTEâ€™s audio-text alignment setting and report with textual tokens as the granularity of the x-axis.",
                "position": 4703
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x21.png",
                "caption": "Figure 12:Positive vs. Negative Sample Mean NLL-Loss Response forFlow-SLM-1B-Extendedacross six consistency splits. At the transition timeframe (t=0), each of the category has distinct postive/negative response (clear separation by 95% confidence interval).",
                "position": 4706
            },
            {
                "img": "https://arxiv.org/html/2601.06329/x22.png",
                "caption": "Figure 13:Positive vs. Negative Sample Mean NLL-Loss Response forLlama-mimi-1.3Bacross six consistency splits. At the transition timeframe (t=0), each of the category has distinct postive/negative response (clear separation by 95% confidence interval).",
                "position": 4709
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]