[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19261/x1.png",
                "caption": "Figure 1:Overview of the Drop-Upcycling method.The key difference from the na√Øve Upcycling is Diversity re-initialization, introduced in Section3.",
                "position": 158
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19261/x2.png",
                "caption": "Figure 2:Initialization of expert weights.Columns (rows) are selected according to a set of randomly selected indices of the intermediate layerùíÆùíÆ\\mathcal{S}caligraphic_S, then all elements of them are re-initialized with the normal distribution. Other columns (rows) are maintained.",
                "position": 324
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19261/x3.png",
                "caption": "Figure 3:Comparison of learning curves for different MoE construction methods.\nThe top and bottom rows illustrate the changes in training loss and downstream task scores during training, respectively. In both metrics, the proposed method, Drop-Upcycling withr=0.5ùëü0.5r=0.5italic_r = 0.5, achieves the best performance, gaining initial knowledge transfer while avoiding convergence slowdown.",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x4.png",
                "caption": "Figure 4:Impact of re-initialization ratiorùëüritalic_r.The training loss and downstream task score over the total number of tokens processed during training on 8√ó152M (left two figures) and 8√ó1.5B (right two figures) settings are illustrated.\nEven with differentrùëüritalic_rvalues, Drop-Upcycling robustly outperforms na√Øve Upcycling, and 0.5 appears to be the most effective ratio.",
                "position": 1211
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x5.png",
                "caption": "Figure 5:Comparison of expert routing patterns across different MoE construction methods.Drop-Upcycling exhibits more balanced expert utilization than na√Øve Upcycling.\nResults shown for layers 0 (first), 8, 16, and 23 (last); see AppendixC.2for results on all layers.",
                "position": 1222
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Setup Details",
        "images": []
    },
    {
        "header": "Appendix BDatasets and evaluation methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.19261/x6.png",
                "caption": "Figure 6:Expert routing patterns for early layers (0-7) of the 8√ó1.5B MoE models.",
                "position": 2581
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x7.png",
                "caption": "Figure 7:Expert routing patterns for middle layers (8-15) of the 8√ó1.5B MoE models.",
                "position": 2584
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x8.png",
                "caption": "Figure 8:Expert routing patterns for late layers (16-23) of the 8√ó1.5B MoE models.",
                "position": 2587
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x9.png",
                "caption": "Figure 9:Comparison between global and layer-wise load balancing across different initialization methods.Top: Training loss trajectories over 40B tokens. Bottom: Evaluation metrics measured at iterations corresponding to 10B, 20B, 30B, and 40B tokens. Results show comparable performance between global and layer-wise approaches across all methods.",
                "position": 2604
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x10.png",
                "caption": "Figure 10:Expert routing patterns for early layers (0-7) under layer-wise load balancing at 40B tokens",
                "position": 2607
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x11.png",
                "caption": "Figure 11:Expert routing patterns for middle layers (8-15) under layer-wise load balancing at 40B tokens",
                "position": 2610
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x12.png",
                "caption": "Figure 12:Expert routing patterns for late layers (16-23) under layer-wise load balancing at 40B tokens",
                "position": 2613
            },
            {
                "img": "https://arxiv.org/html/2502.19261/x13.png",
                "caption": "Figure 13:Convergence catch-up analysis.We compare the relative convergence speed of Drop-Upcycling and baseline methods by examining the number of training tokens required to reach the same loss value. The x-axis represents the number of training tokens processed by the baseline method, while the y-axis shows the difference in training tokens needed by Drop-Upcycling to achieve the same loss. Positive values indicate that Drop-Upcycling achieves the loss faster, while negative values suggest the baseline method is ahead.",
                "position": 2627
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experimental Results and Analysis",
        "images": []
    }
]