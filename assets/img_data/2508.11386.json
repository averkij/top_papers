[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3System setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11386/fig/model_performance_aime_2024_lines.png",
                "caption": "Figure 2:Performance on AIME24 ofQwen2.5-Instructmodels and their post-trained versions which are fine-tuned onDeepSeek-R1reasoning traces (reproducings1.1work, following[7]).",
                "position": 417
            }
        ]
    },
    {
        "header": "4Exemplary Application",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11386/fig/pipeline_overview.png",
                "caption": "Figure 4:Overview of our pipeline, covering the central aspects of the process: synthetic data creation, information retrieval, reasoning trace generation, and model fine-tuning.",
                "position": 596
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11386/fig/lean_models_comparison.png",
                "caption": "Figure 5:Performance on condition prediction ofQwen2.5-Instructmodels alone, with the use of RAG and with their post-trainedt0versions which combine RAG and reasoning.",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2508.11386/fig/interface.png",
                "caption": "Figure 6:Snapshot of the chat interface.",
                "position": 1181
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]