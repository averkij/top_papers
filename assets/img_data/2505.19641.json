[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19641/x1.png",
                "caption": "Figure 1:The framework of logic data synthesis. The process begins with the selection of suitable tasks and the identification of key parameters that control task difficulty. Next, logic instances are generated with appropriate difficulty control (e.g., setting the grid size of Sudoku to 7). These instances are subsequently formalized into natural language instructions. Each task is paired with a task-specific verifier to check the correctness of responses. This framework enables the systematic synthesis of high-quality logic data, covering a wide range of difficulty levels and 35 task types.",
                "position": 139
            }
        ]
    },
    {
        "header": "2SynLogic: Synthesizing Logical Reasoning Data at Scale",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19641/x2.png",
                "caption": "(a)7B models onSynLogic-Easy",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x2.png",
                "caption": "(a)7B models onSynLogic-Easy",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x3.png",
                "caption": "(b)32B models onSynLogic-Hard",
                "position": 322
            }
        ]
    },
    {
        "header": "3Reinforcement Learning onSynLogic",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19641/x4.png",
                "caption": "(a)Avg Length and Reflection of 7B Training.",
                "position": 489
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x4.png",
                "caption": "(a)Avg Length and Reflection of 7B Training.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x5.png",
                "caption": "(b)Avg Length and Reflection of 32B Training.",
                "position": 497
            }
        ]
    },
    {
        "header": "4Scaling RL Training with Diverse Verifiable Reasoning Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19641/x6.png",
                "caption": "(a)Acc on KOR-Bench.",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x6.png",
                "caption": "(a)Acc on KOR-Bench.",
                "position": 544
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x7.png",
                "caption": "(b)Avg Acc on Math.",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x8.png",
                "caption": "(c)Avg Math Acc vs. Consumed Math Data",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x9.png",
                "caption": "(a)Acc on KOR-Bench.",
                "position": 561
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x9.png",
                "caption": "(a)Acc on KOR-Bench.",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x10.png",
                "caption": "(b)Avg Acc on Code.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x11.png",
                "caption": "(c)Avg Code Acc vs. Consumed Coding Data.",
                "position": 574
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComprehensive Overview ofSynLogic",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.19641/x12.png",
                "caption": "(a)Training accuracy of 7B model",
                "position": 1440
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x12.png",
                "caption": "(a)Training accuracy of 7B model",
                "position": 1443
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x13.png",
                "caption": "(b)Training accuracy of 32B model",
                "position": 1448
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x14.png",
                "caption": "(a)Performance on MATH 500.",
                "position": 1460
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x14.png",
                "caption": "(a)Performance on MATH 500.",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x15.png",
                "caption": "(b)Performance on AIME 2024.",
                "position": 1468
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x16.png",
                "caption": "(c)Performance on AMC 2023.",
                "position": 1473
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x17.png",
                "caption": "(a)Performance on our coding data validation split.",
                "position": 1494
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x17.png",
                "caption": "(a)Performance on our coding data validation split.",
                "position": 1497
            },
            {
                "img": "https://arxiv.org/html/2505.19641/x18.png",
                "caption": "(b)Performance on LiveCodeBench.",
                "position": 1502
            }
        ]
    },
    {
        "header": "Appendix BTraining and Evaluation Details",
        "images": []
    }
]