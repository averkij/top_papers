[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01237/x1.png",
                "caption": "Figure 1:Impact of theŒ≤ùõΩ\\betaitalic_Œ≤Parameter on ASFT and ORPO Alignment Quality.The plot shows how tuningŒ≤ùõΩ\\betaitalic_Œ≤(Section3.1.2) affects both ASFT and ORPO performance. Results are reported for GPT-4 Win Rate in the Llama 3.2 3B TL;DR setup and for AlpacaEval 2 LC Win Rate in the Llama 3.1 8B UF scenario. All other hyperparameters (e.g., learning rates) are selected via grid search, using each method‚Äôs best configuration atŒ≤=1ùõΩ1\\beta=1italic_Œ≤ = 1as the baseline. See Section5.2for more details.",
                "position": 652
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01237/x2.png",
                "caption": "Figure 2:GPT-4 Evaluation of Llama 3.2 3B TL;DR setup.The comparison shows multiple alignment methods (rows) using their best hyperparameters, where each approach aims to generate concise and accurate summaries. Most methods exceed 90% Win Rate; ASFT achieves 87.2%, maintaining robust summarization performance. See Section5.2for more details.",
                "position": 709
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.01237/x3.png",
                "caption": "Figure 3:Pareto front for alignment quality and KL divergence.Results for Llama 3.1 8B UF on AlpacaEval 2 LC. Methods are grouped into pairwise and pointwise categories, with pairwise achieving higher LC values while remaining within overlapping confidence intervals. See Section5.3for more details.",
                "position": 1068
            },
            {
                "img": "https://arxiv.org/html/2502.01237/x4.png",
                "caption": "Figure 4:Pairwise vs. Pointwise Ranking Methods on Toy Example.Model capacity impacts ranking accuracy, with pairwise methods outperforming pointwise ones as capacity increases. This behavior is consistent with results observed in Llama experiments on the UF dataset. See Section5.3for more details.",
                "position": 1077
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BEquivalence of ASFT Loss and Binary Cross-Entropy Loss",
        "images": []
    },
    {
        "header": "Appendix CRelationship Between ORPO and ASFT Loss Functions",
        "images": []
    },
    {
        "header": "Appendix DProof of Theorem3.4",
        "images": []
    },
    {
        "header": "Appendix EProof of Theorem3.5",
        "images": []
    },
    {
        "header": "Appendix FProof of Theorem3.6",
        "images": []
    },
    {
        "header": "Appendix GPareto fronts for Llama 3.2 setups",
        "images": []
    },
    {
        "header": "Appendix HToy Example Details",
        "images": []
    },
    {
        "header": "Appendix IGPT-4 Side-By-Side Evaluation Prompt",
        "images": []
    }
]