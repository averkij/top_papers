[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02152/x1.png",
                "caption": "Figure 1:Tabby Multi-Head modifications (right side) compared to an original, Non-Tabby LLM on the left.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Tabby Architecture & Plain Train Method",
        "images": []
    },
    {
        "header": "3Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02152/x2.png",
                "caption": "Figure 2:Process for calculating our primary metric, Machine Learning Efficacy (MLE). We train a generative model, which produces a synthetic dataset. Two downstream classifiers are trained: one on the generative model’s training data and the other on the synthetic data. Each downstream model is evaluated on real test data. MLE is the difference in downstream models’ test-time performance. Higher scores indicate better-quality synthetic data.",
                "position": 429
            },
            {
                "img": "https://arxiv.org/html/2503.02152/x3.png",
                "caption": "Figure 3:Performance profile curves and AUP scores across computed using the MLE scores on our evaluation tasks.\nThe top performing method isTabby MH DGPT2with plain training.",
                "position": 602
            },
            {
                "img": "https://arxiv.org/html/2503.02152/x4.png",
                "caption": "Figure 4:The House dataset’s target Median House Value column as a function of its most-predictive feature, Median Income. Left to right: synthetic data from Tab-DDPM, the prior best LLM-based method and Plain Tabby MH, followed by the original data distribution.",
                "position": 610
            },
            {
                "img": "https://arxiv.org/html/2503.02152/x5.png",
                "caption": "Figure 5:Machine Learning Efficacy (MLE) as a function of parameter count for 7 base LLMs, using Non-Tabby or Tabby MH architectures. Non-Tabby points displayed in blue; MH points in purple. Red line represents Original, upper-bound performance.",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2503.02152/x6.png",
                "caption": "Figure 6:Per-column validation loss across10101010epochs of training Tabby MH Distilled-GPT2 on a subset of House, with average validation loss (black line). While the Occupancy column initially displays the highest loss, Median Income improves little throughout training and becomes the highest-loss column by step32000320003200032000.",
                "position": 800
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATerminology Glossary",
        "images": []
    },
    {
        "header": "Appendix BAdditional dataset information",
        "images": []
    },
    {
        "header": "Appendix CTabby for Nested Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02152/x7.png",
                "caption": "Figure 7:An overview of the Tabby MH modifications for the nested Glaucoma dataset.",
                "position": 1591
            }
        ]
    },
    {
        "header": "Appendix DDetails on Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02152/x8.png",
                "caption": "Figure 8:An overview of the Tabby MH modifications that can occur inside the LLM transformer blocks. Left to right: an original, non-Tabby LLM, a Tabby LLM with MoE MLP block, a Tabby LLM with MoE attention block, and a Tabby LLM with both MoE MLP and attention blocks. Tabby is very flexible, so as to accommodate a wide variety of tabular datasets.",
                "position": 2023
            }
        ]
    },
    {
        "header": "Appendix EFurther Experimental Results",
        "images": []
    }
]