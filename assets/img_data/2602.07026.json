[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2The Isotropic Fallacy",
        "images": []
    },
    {
        "header": "3Modality Gap",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x1.png",
                "caption": "Figure 2:Geometric Statistics of the Modality Gap.(a) Geometric Gradient Constraint. The reference leakage ratio (blue) closely tracks the geometric baselinesin⁡θ​(Ut,U)\\sin\\theta(U_{t},U)(red), confirming that gradients are confined within the evolving task subspaceUtU_{t}. (b) Passive Bias Evolution. The orthogonal bias componentγ​(t)\\gamma(t)exhibits high cosine stability (blue) with only slow cumulative drift (red), indicating a passive evolution driven by subspace rotation rather than direct optimization. (c) Semantic Signal Locking (U-side). In the semantic subspaceUU, the condition numberκ​(ΣU)\\kappa(\\Sigma_{U})(blue) remains extremely high (>103>10^{3}), showing strong anisotropy. The correlationρalign\\rho_{\\text{align}}(red) rapidly converges to≈1\\approx 1, confirming that residual variance is locked to the gradient covariance structure. (d) Orthogonal Noise Decoupling (V-side). In the orthogonal subspaceVV, the residual noise maintains a stretched shape (κ>101\\kappa>10^{1}, blue). Crucially, the bias vectorγ\\gammamaintains an angle of≈90∘\\approx 90^{\\circ}(red) relative to the principal noise direction, proving that the static bias and dynamic noise are geometrically decoupled and orthogonal.",
                "position": 431
            }
        ]
    },
    {
        "header": "4ReAlign:Training-Free Modality Alignment",
        "images": []
    },
    {
        "header": "5ReVision: A Scalable Training Paradigm",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x2.png",
                "caption": "Figure 4:We measure the modality gap between aligned centroids on Bunny and DenseFusion. While the baseline C3 stagnates at a geometric bottleneck (≈0.0023\\approx 0.0023) due to isotropic assumptions, ReAlign reduces the gap to the10−410^{-4}scale by effectively modeling anisotropic covariance.",
                "position": 783
            }
        ]
    },
    {
        "header": "7Appendix Organization.",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AModality Gap Phenomenon Essential Causes",
        "images": []
    },
    {
        "header": "Appendix BProof of Theoretical Claims",
        "images": []
    },
    {
        "header": "Appendix CU–V Weak Coupling Analysis",
        "images": []
    },
    {
        "header": "Appendix DBeyond the Isotropic Assumption: A Geometric Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x3.png",
                "caption": "Figure 5:Geometric Fidelity Analysis via Spectral and Angular Properties.(a) Semantic Hierarchy: The eigenspectrum analysis reveals that C3(red line) exhibits a flattened slope with an elevated tail (α≈1.06\\alpha\\approx 1.06), indicating that unstructured noise injection dilutes fine-grained semantic structure. In contrast, ReAlign (blue line) maintains a power-law decay (α≈1.33\\alpha\\approx 1.33) that matches the intrinsic geometry of the source text. (b) Angular Topology Matching: KDE plots of cosine similarities demonstrate that C3causes a severe distributional shift (JS Divergence = 0.1924), destroying angular relationships. ReAlign achieves a near-perfect overlap with the target prior (JS Divergence = 0.0066), validating its ability to restore centroid alignment while preserving the topological structure.",
                "position": 1585
            },
            {
                "img": "https://arxiv.org/html/2602.07026/x4.png",
                "caption": "Figure 6:Global Alignment Visualization via PCA.We visualize the manifold alignment across three settings: (a) Original Text forms a distinct cluster separated from the image modality with negligible mixing (0.32%). (b) C3expands the text distribution via noise but fails to effectively penetrate the visual manifold (1.31%). (c) ReAlign successfully shifts the text distribution into the visual support region, achieving a mixing rate of 4.35%. This represents a relative improvement of over3×3\\timescompared to the C3baseline, confirming significant manifold penetration.",
                "position": 1602
            }
        ]
    },
    {
        "header": "Appendix ERobustness Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x5.png",
                "caption": "Figure 7:Impact of unpaired sample size on the modality gap for statistical estimation.",
                "position": 1619
            },
            {
                "img": "https://arxiv.org/html/2602.07026/x6.png",
                "caption": "Figure 8:(a) Comparison of alignment residuals using Float32 vs. Float64 accumulators. (b) Trends of processing time (O​(N)O(N)) and peak memory usage (O​(1)O(1)) across dataset sizes.",
                "position": 1635
            },
            {
                "img": "https://arxiv.org/html/2602.07026/x7.png",
                "caption": "Figure 9:Comparison of modality gap performance under in-domain and cross-domain statistical alignment for General and Medical domains.",
                "position": 1655
            }
        ]
    },
    {
        "header": "Appendix FFailure Strategy Analysis: Blockwise Covariance Alignment",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x8.png",
                "caption": "Figure 10:Failure mechanism analysis of Blockwise Covariance Alignment.(a) Spectrum Decay: The high condition number (≈1.1×103\\approx 1.1\\times 10^{3}) of text embeddings induces numerical instability during covariance inversion, amplifying tail noise. In contrast, ReAlign maintains stability via isotropic scaling. (b) Semantic Preservation: KNN neighborhood overlap rates reveal that Blockwise’s aggressive whitening causes a collapse of the local semantic topology (retaining only 10% overlap), whereas ReAlign effectively preserves 87% of the semantic structure.",
                "position": 1786
            }
        ]
    },
    {
        "header": "Appendix GThe Long-Caption Paradox",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x9.png",
                "caption": "Figure 11:Geometric Analysis of the Long-Caption Paradox.(a) Effective Rank: Measurements reveal that Long captions exhibit a high effective rank (≈52.9\\approx 52.9) similar to the visual modality (≈57.5\\approx 57.5). This indicates a diffuse, high-entropy covariance structure that is difficult to align. In contrast, Short captions (≈41.0\\approx 41.0) function as a compact, low-rank approximation of the visual content, offering greater statistical stability. (c) Initial Modality Gap: The inclusion of non-visual linguistic noise in long captions acts as a disturbing force, significantly widening the initial modality gap (‖Δ​μ‖≈0.51\\|\\Delta\\mu\\|\\approx 0.51) by approximately 30% compared to concise captions (‖Δ​μ‖≈0.39\\|\\Delta\\mu\\|\\approx 0.39).",
                "position": 1941
            },
            {
                "img": "https://arxiv.org/html/2602.07026/x10.png",
                "caption": "Figure 12:Visualization of Linguistic Noise in Dense Captions. We highlight non-visual segments (marked in red) within long captions, such as abstract inferences, contextual associations, and subjective interpretations. These tokens lack direct visual grounding and geometrically act as noise vectors, pulling the semantic centroid away from the true visual anchor.",
                "position": 1957
            }
        ]
    },
    {
        "header": "Appendix HExperiments Setting",
        "images": []
    },
    {
        "header": "Appendix IQualitative Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.07026/x11.png",
                "caption": "Figure 13:Qualitative analysis examples of ReVision.This figure shows the model’s visual perception ability across various complex tasks.",
                "position": 2010
            }
        ]
    },
    {
        "header": "Appendix JRelated Work",
        "images": []
    },
    {
        "header": "Appendix KBroader Impact",
        "images": []
    }
]