[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25772/x1.png",
                "caption": "",
                "position": 101
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25772/x2.png",
                "caption": "Figure 2:Overview of VFXMaster.1) During training, we randomly sample two prompt-video pairs with the same visual effects as reference and target respectively. By sharing the same 3D VAE and text encoder, the reference part and the target part are landed into the same latent space. We concatenate them along the token dimension as a unified token sequence and feed into the DiT blocks. 2) We design an attention mask to manage information flow to focus on the visual effect of the reference and prevent information leakage. 3) For the tough Out-of-Domain (OOD) samples, we propose an efficient one-shot effect adaptation process to train the concept-enhance tokens for improving the generalization capability.",
                "position": 172
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25772/x3.png",
                "caption": "Figure 3:In-Domain Comparison.Qualitative comparison of ours with VFXCreator[24]and OminiEffects[27]on the OpenVFX dataset. CogVideoX* refers to CogVideoX after supervised fine-tuning on our VFX dataset. All human portraits used in the experiment are AI-generated, and this applies to all subsequent images.",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x4.png",
                "caption": "Figure 4:Out-of-Domain Comparison.",
                "position": 605
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AMethod Details",
        "images": []
    },
    {
        "header": "BDatasets and Metric",
        "images": []
    },
    {
        "header": "CExperiment Result Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.25772/x5.png",
                "caption": "Figure 5:Examples of the “Invisible” and “Soul Jump” visual effects using VFXMaster.",
                "position": 1368
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x6.png",
                "caption": "Figure 6:Examples of the “Freezing” and “Blazing” visual effects using VFXMaster.",
                "position": 1371
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x7.png",
                "caption": "Figure 7:Examples of the “Agent Reveal” and “Butterfly” visual effects using VFXMaster.",
                "position": 1374
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x8.png",
                "caption": "Figure 8:Examples of the “Disintegration” visual effect using VFXMaster.",
                "position": 1377
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x9.png",
                "caption": "Figure 9:Examples of the “Anime Couple” and “Artistic Clay” visual effect using VFXMaster.",
                "position": 1380
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x10.png",
                "caption": "Figure 10:Examples of the “The Flash”, “Tada” and “Angle Wings” visual effect using VFXMaster.",
                "position": 1383
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x11.png",
                "caption": "Figure 11:Examples of the “Fire Breathe” and “Floral Eyes” visual effect using VFXMaster.",
                "position": 1386
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x12.png",
                "caption": "Figure 12:Qualitative results of ablation study.",
                "position": 1389
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x13.png",
                "caption": "Figure 13:First Frame Captioning via Reference Video.",
                "position": 1392
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x14.png",
                "caption": "Figure 14:Video Caption Template.",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x15.png",
                "caption": "Figure 15:VFX-Comprehensive Assessment Score-Part 1.",
                "position": 1398
            },
            {
                "img": "https://arxiv.org/html/2510.25772/x16.png",
                "caption": "Figure 16:VFX-Comprehensive Assessment Score-Part 2.",
                "position": 1401
            }
        ]
    },
    {
        "header": "DMore Qualitative Results",
        "images": []
    }
]