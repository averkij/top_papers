[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20571/x1.png",
                "caption": "Figure 1:RLVR with 1 example (green) can perform as well as using datasets with thousands of examples (blue).Left/Right corresponds to MATH500/Average performance on 6 mathematical reasoning benchmarks.\nBase model is Qwen2.5-Math-1.5B.œÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTandœÄ13subscriptùúã13\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPTare examples defined by Eqn.2and detailed in Tab.2, and they are all from the 1.2k DeepScalerR subset (DSR-sub).\nSetup details are in Sec.3.1.\nWe find that RLVR with 1 example{œÄ13}subscriptùúã13\\{\\pi_{13}\\}{ italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT }(35.7%) performs close to that with 1.2k DSR-sub (35.9%), and RLVR with 2 examples {œÄ1,œÄ13subscriptùúã1subscriptùúã13\\pi_{1},\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT} (36.6%) even performs better than RLVR with DSR-sub and as well as using 7.5k MATH train dataset (36.7%).\nDetailed results are in Fig.2.\nAdditional results for non-mathematical reasoning tasks are in Tab.1.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x2.png",
                "caption": "",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x3.png",
                "caption": "Figure 2:Detailed performance of 1/2-shot RLVR for Qwen2.5-Math-1.5B.Results are reported for the checkpoint achieving the best average across 6 math benchmarks (Fig.1).Yellow,blue, andgreencorrespond to the performance of thebase model,RLVR with full dataset, and1/2-shot RLVR, respectively.\nAll RLVR setups significantly outperform the base model.\nFurther evaluation details are provided in Sec.3.1.\nModels‚Äô best individual benchmark results are listed in Tab.8in the Appendix.\nAdditional results for non-mathematical reasoning tasks are in Tab.1.",
                "position": 194
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20571/x4.png",
                "caption": "Figure 3:Post-saturation generalization in 1-shot RLVR.The training accuracy ofœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(Left) andœÄ13subscriptùúã13\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT(Middle) in 1-shot RLVR saturates before step 100, but their test performance continues improving. On the other hand, the training accuracy for RLVR with 1.2k DSR-sub dataset (Right) still has not saturated after 2000 steps, but there is no significant improvement on test tasks after step 1000.",
                "position": 503
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x5.png",
                "caption": "",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x6.png",
                "caption": "",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x7.png",
                "caption": "Figure 4:The model can still generalize on test data after overfitting training example for 1-shot RLVR‚Äôs post-saturation generalization. Here we show model‚Äôs response to training exampleœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTand a selected MATH500 problem.Green/Redare used for markingCorrect/Wronganswers.\nThe model converges onœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(before step 500) and later attempt to generate longer solutions forœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTin different styles (step 1300), and gradually performs better on evaluation task.\nBut it significantlyoverfitstraining dataœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTat step 1860 (when model achieves 74% MATH500 accuracy), as it mixes the correct process (cyan) with meaningless output.\nHowever, the test response is normal, even trying a different strategy (‚ÄúRational Root Theorem‚Äù) from step-1300 responses.",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x8.png",
                "caption": "Figure 5:(Left, Middle) Average response length on training data and entropy loss.After around 1300/1700 steps, the average response length of 1-shot RLVR withœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT/œÄ13subscriptùúã13\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPTsignificantly increases, corresponding to the fact that the model tries to solve the single problem with longer CoT reasoning in a more diverse way (Fig.4, step 1300), which is also confirmed by the increase of entropy loss. These may also indicate the gradual overfitting of training example (Fig.4, step 1860).\nDuring the training of RLVR with 1.2k DSR-sub, the response length keeps decreasing.(Right) Number of reflection words detected in evaluation tasks.The number of reflection words (‚Äúrethink‚Äù, ‚Äúrecheck‚Äù, and ‚Äúrecalculate‚Äù) appearing in evaluation tasks increases in the process of 1-shot RLVR withœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT/œÄ13subscriptùúã13\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT, especially after around 1250 steps, matching the increase of response length.\nOn the other hand, RLVR with 1.2k DSR-sub contains fewer reflection words as the training progresses.",
                "position": 922
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x9.png",
                "caption": "",
                "position": 925
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x10.png",
                "caption": "",
                "position": 926
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x11.png",
                "caption": "Figure 6:Model distilled by long-CoT reasoning data may need more data for RLVR.",
                "position": 1233
            }
        ]
    },
    {
        "header": "4Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20571/x12.png",
                "caption": "Figure 7:Encouraging exploration can improve post-saturation generalization.tùë°titalic_tis the temperature parameter for training rollouts.",
                "position": 1481
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion and Discussion",
        "images": []
    },
    {
        "header": "7Acknoledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperiment Setup",
        "images": []
    },
    {
        "header": "Appendix BEvaluation Result",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.20571/x13.png",
                "caption": "Figure 8:Different data have large difference on improving MATH500 accuracy, but they all improve various tasks rather than their own task.From left to right correspond to 1-shot RL onœÄ1subscriptùúã1\\pi_{1}italic_œÄ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,œÄ11subscriptùúã11\\pi_{11}italic_œÄ start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT,œÄ13subscriptùúã13\\pi_{13}italic_œÄ start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT, orœÄ16subscriptùúã16\\pi_{16}italic_œÄ start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT. Details are in Tab.3.",
                "position": 3340
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x14.png",
                "caption": "",
                "position": 3343
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x15.png",
                "caption": "",
                "position": 3345
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x16.png",
                "caption": "",
                "position": 3346
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x17.png",
                "caption": "Figure 9:Detailed evaluation results on each benchmark for RLVR on Qwen2.5-Math-1.5B.",
                "position": 3352
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x18.png",
                "caption": "",
                "position": 3355
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x19.png",
                "caption": "",
                "position": 3356
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x20.png",
                "caption": "",
                "position": 3358
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x21.png",
                "caption": "",
                "position": 3359
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x22.png",
                "caption": "",
                "position": 3360
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x23.png",
                "caption": "",
                "position": 3362
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x24.png",
                "caption": "Figure 10:Detailed evaluation results on each benchmark for RLVR on Qwen2.5-Math-7B.",
                "position": 3368
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x25.png",
                "caption": "",
                "position": 3371
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x26.png",
                "caption": "",
                "position": 3372
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x27.png",
                "caption": "",
                "position": 3374
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x28.png",
                "caption": "",
                "position": 3375
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x29.png",
                "caption": "",
                "position": 3376
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x30.png",
                "caption": "",
                "position": 3378
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x31.png",
                "caption": "Figure 11:Detailed evaluation results on each benchmark for RLVR on Llama-3.2-3B-Instruct.",
                "position": 3384
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x32.png",
                "caption": "",
                "position": 3387
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x33.png",
                "caption": "",
                "position": 3388
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x34.png",
                "caption": "",
                "position": 3390
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x35.png",
                "caption": "",
                "position": 3391
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x36.png",
                "caption": "",
                "position": 3392
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x37.png",
                "caption": "",
                "position": 3394
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x38.png",
                "caption": "Figure 12:Detailed evaluation results on each benchmark for RLVR on DeepSeek-R1-Distill-Qwen-1.5B.",
                "position": 3400
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x39.png",
                "caption": "",
                "position": 3403
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x40.png",
                "caption": "",
                "position": 3404
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x41.png",
                "caption": "",
                "position": 3406
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x42.png",
                "caption": "",
                "position": 3407
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x43.png",
                "caption": "",
                "position": 3408
            },
            {
                "img": "https://arxiv.org/html/2504.20571/x44.png",
                "caption": "",
                "position": 3410
            }
        ]
    },
    {
        "header": "Appendix CExample Details",
        "images": []
    }
]