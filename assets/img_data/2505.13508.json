[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x1.png",
                "caption": "Figure 1:Generated outputs from Time-R1 showcasing its capabilities.(Left) Future Event Time Prediction (Stage 2). (Right) Creative Scenario Generation (Stage 3), with output compared to a real-world headline.",
                "position": 167
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x2.png",
                "caption": "Figure 2:Overview of the Time-R1 framework.The process consists of three stages: (a) Stage 1 establishes foundational understanding by fine-tuning a base LLM on historical data across four temporal subtasks, driven by reinforcement learning (GRPO) and a dynamic reward system, resulting in modelŒ∏1subscriptùúÉ1\\theta_{1}italic_Œ∏ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. (b) Stage 2 trainsŒ∏1subscriptùúÉ1\\theta_{1}italic_Œ∏ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTfor future event time prediction using post-cutoff data and a rule-based reward, producingŒ∏2subscriptùúÉ2\\theta_{2}italic_Œ∏ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. (c) Stage 3 leveragesŒ∏2subscriptùúÉ2\\theta_{2}italic_Œ∏ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTfor inference-based creative future scenario generation, followed by evaluation, without further RL.",
                "position": 211
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x3.png",
                "caption": "Figure 3:Monthly Avg. Total ScoreR‚Å¢(x,y)ùëÖùë•ùë¶R(x,y)italic_R ( italic_x , italic_y )for Stage 2 Future Event Prediction (August 2024 - Feb 2025). Compares Time-R1 variants (Œ∏2subscriptùúÉ2\\theta_{2}italic_Œ∏ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTandŒ∏2‚Ä≤superscriptsubscriptùúÉ2‚Ä≤\\theta_{2}^{\\prime}italic_Œ∏ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT) against baselines. Evaluated withŒ±=0.1ùõº0.1\\alpha=0.1italic_Œ± = 0.1.",
                "position": 702
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x4.png",
                "caption": "Figure 4:Impact of the Dynamic Reward Curriculum.(a) Total ScoreR‚Å¢(x,y)ùëÖùë•ùë¶R(x,y)italic_R ( italic_x , italic_y )on the Stage 1 Time-Difference Estimation task, comparing training \"With Dynamic Reward\" (blue, solid line) versus \"Without Dynamic Reward\" (red, dashed line, fixedŒ±=0.1ùõº0.1\\alpha=0.1italic_Œ± = 0.1). (b) Corresponding Average Response Length across all Stage 1 tasks for the same two training strategies. The y-axis for response length is broken to accommodate different scales. The dynamic reward approach not only achieves higher task scores but also promotes significantly more concise model outputs.",
                "position": 895
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperimental Configuration Details",
        "images": []
    },
    {
        "header": "Appendix BDataset Construction and Details",
        "images": []
    },
    {
        "header": "Appendix CDetailed Stage 1 Learning Curves and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x5.png",
                "caption": "Figure 5:Learning curves for Stage 1 subtasks during (Left) Phase 2 and (Right) Phase 3 of the dynamic reward curriculum. The left plot also shows the Inconsistency Penalty Factor (PinconsubscriptùëÉinconP_{\\text{incon}}italic_P start_POSTSUBSCRIPT incon end_POSTSUBSCRIPT) for Time-Difference Estimation and Event Ordering tasks on the right y-axis during Phase 2.",
                "position": 1787
            }
        ]
    },
    {
        "header": "Appendix DFurther Discussion on Implementation Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x6.png",
                "caption": "Figure 6:Impact of different KL loss coefficients (Œ≤ùõΩ\\betaitalic_Œ≤) on the average response length during training. A lower coefficient (0.0001) leads to longer average responses compared to the default setting (0.001).",
                "position": 1813
            }
        ]
    },
    {
        "header": "Appendix EAdditional Generated Examples of Time-R1",
        "images": []
    },
    {
        "header": "Appendix FIllustration of Length and Repetition Penalty Efficacy",
        "images": []
    },
    {
        "header": "Appendix GLimitations",
        "images": []
    },
    {
        "header": "Appendix HEthical Statement",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.13508/x7.png",
                "caption": "Figure 7:Prompt for the Timestamp Inference task.",
                "position": 2390
            },
            {
                "img": "https://arxiv.org/html/2505.13508/x8.png",
                "caption": "Figure 8:Prompt for the Time-Difference Estimation task.",
                "position": 2400
            },
            {
                "img": "https://arxiv.org/html/2505.13508/x9.png",
                "caption": "Figure 9:Prompt for the Event Ordering task.",
                "position": 2410
            },
            {
                "img": "https://arxiv.org/html/2505.13508/x10.png",
                "caption": "Figure 10:Prompt for the Masked Time Entity Completion task.",
                "position": 2420
            },
            {
                "img": "https://arxiv.org/html/2505.13508/x11.png",
                "caption": "Figure 11:Prompt for the Future Event Time Prediction task.",
                "position": 2430
            },
            {
                "img": "https://arxiv.org/html/2505.13508/x12.png",
                "caption": "Figure 12:Prompt for the Creative Future Scenario Generation task.",
                "position": 2440
            }
        ]
    },
    {
        "header": "Appendix IPrompts",
        "images": []
    }
]