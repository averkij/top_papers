[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13061/extracted/6076804/imgs/radar.png",
                "caption": "Figure 1:Illustration of the quantitative comparison of discrete and continuous tokenization performance across our VidTok model and state-of-the-art methods, evaluated using four metrics: PSNR, SSIM, LPIPS, and FVD. All performance metrics are obtained through experiments conducted under a consistent evaluation protocol to ensure fairness and comparability. Larger chart areas correspond to better performance across all metrics.",
                "position": 120
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13061/x1.png",
                "caption": "Figure 2:An overview of video tokenizers.",
                "position": 132
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3VidTok",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13061/x2.png",
                "caption": "Figure 3:The improved model architecture. In the context of a causal setting, consider an input with dimensionsT√óH√óW=17√ó256√ó256ùëáùêªùëä17256256T\\times H\\times W=17\\times 256\\times 256italic_T √ó italic_H √ó italic_W = 17 √ó 256 √ó 256. Assuming a temporal compression factor of4444and a spatial compression factor of8888, the intermediate latent representation is reduced to dimensionsT√óH√óW=5√ó32√ó32ùëáùêªùëä53232T\\times H\\times W=5\\times 32\\times 32italic_T √ó italic_H √ó italic_W = 5 √ó 32 √ó 32.",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2412.13061/x3.png",
                "caption": "Figure 4:Left: Vector Quantization (VQ) employed in Vector Quantised-Variational AutoEncoder (VQ-VAE)(Van Den¬†Oord et¬†al.,2017). Right: Finite Scalar Quantization (FSQ)(Mentzer et¬†al.,2024)utilized in our model.",
                "position": 271
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.13061/extracted/6076804/imgs/results/full_comp.png",
                "caption": "Figure 5:Qualitative comparison with the state-of-the-art video tokenizers.",
                "position": 528
            },
            {
                "img": "https://arxiv.org/html/2412.13061/extracted/6076804/imgs/results/fps8_fps3.png",
                "caption": "Figure 6:The influence of different sample rates on model performance during training. The second row presents the test results obtained using training data with a sample rate of 8 FPS, while the third row shows the test results using training data with a sample rate of 3 FPS. The results demonstrate that employing training data with reduced frame rates enhances the model‚Äôs capacity to effectively capture motion dynamics.",
                "position": 811
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]