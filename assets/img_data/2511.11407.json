[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11407/x1.png",
                "caption": "Figure 1:Bloom’s levels across microscopy multimodal datasets. MicroVQA++ exhibits a substantially higher proportion in harder level and absolute count of higher-difficulty questions than MicroVQA, reflecting a stricter and more demanding evaluation setting.",
                "position": 169
            }
        ]
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11407/x2.png",
                "caption": "Figure 2:MicroVQA++ is built in three stages. We first sample figure–caption pairs from the Microscopy category of BIOMEDICA. An MLLM agent then extracts answer spans from the captions to construct initial QA pairs, leveraging peer-reviewed articles to ensure expert-validated supervision. Next, we pass the data through HiCQA-Graph, which evaluates cross-modal consistency to judge generation quality. Finally, conditioned on the validated items (human check pipeline available in appendix), an MLLM agent produces CoT rationales and MCQ variants for each question.redindicates grounding informations andgreenindicates important entities.",
                "position": 280
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.11407/x3.png",
                "caption": "Figure 3:a)andb)shows CLIP and NLI only filtering method.c)indicates HiCQA-Graph structure. Cross-modal consistency token is added to Image and QA nodes. Two heads are used to predict soft weak supervised labels.",
                "position": 362
            },
            {
                "img": "https://arxiv.org/html/2511.11407/x4.png",
                "caption": "Figure 4:Two-dimensional t-SNE of CLIP embeddings for images and questions. t-SNE uses perplexity of 30 and 1,000 iterations.",
                "position": 562
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]