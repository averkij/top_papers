[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/x1.png",
                "caption": "Figure 1:The Pass@1 performance of our WebAggregator models, tuned on the automatically constructed training resource, WebAggregatorQA, is comparable to or even exceeds that of GPT-4.1 on both GAIA-text and the more challenging WebAggregatorQA test set.",
                "position": 174
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/x2.png",
                "caption": "Table 1:Comparison between our WebAggregatorQA created byExplore to Evolveand previous data resources.IS: information-seeking,IA: information-aggregation. Our method could construct data that covers diverse aggregation needs (Table2) compared with samples of previous work (Figure5).",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2510.14438/x3.png",
                "caption": "Figure 2:TheExplore to Evolvedata construction pipeline of WebAggregatorQA.(1) Proactive Online Web Exploring gathers comprehensive information by interacting with the web environment through tools (more details in Figure8). (2) Task Construction via Automatic Aggregation Logic Synthesis constructs QA pairs grounded on the explored knowledge by instantiating and evolving the high-level aggregation guidance into concrete operations, e.g.,Statistic Analysis→\\rightarrowstandard deviation. (3) Quality Control ensures the data quality and diversity.",
                "position": 301
            }
        ]
    },
    {
        "header": "2Explore to Evolve",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/x4.png",
                "caption": "Figure 3:The distribution of domains in WebAggregatorQA, tasks categorized by the number of different tools involved during construction, and steps (an action-observation round) in data synthesis.",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2510.14438/x5.png",
                "caption": "Figure 4:Word cloud of aggregation operations extracted from the constructed tasks. In theAutomatic Aggregation Logic Synthesisstage, the agent converts high-level guidance into concrete low-level operations to combine knowledge snippets into new conclusions.\nThe illustrated task requires seeking knowledge bySearch,Visit,Click,FileRead, and aggregations to derive the final answer.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2510.14438/x6.png",
                "caption": "Figure 5:Samples from TaskCraft(Shi et al.,2025a), WebDancer(Wu et al.,2025a), and WebShaper(Tao et al.,2025)primarily evaluate basic information-seeking skills, such asElement -¿ RetrieveandSet -¿ Sets Compositionfor entity filtering. In contrast, the selected WebAggregatorQA samples demand significantly more complex information aggregation to derive final answers. Crucially, these diverse aggregation strategies areautomatically evolvedby agents, guided by high-level logics and accumulated knowledge during data construction, resulting in rich variability that reflects task-specific intricacies.",
                "position": 375
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/x7.png",
                "caption": "Figure 6:Distributions of tasks required different numbers of tools (a) and aggregation operations (d). Proportion of information source (b) and aggregation operations (c) that are needed across tasks.",
                "position": 1135
            }
        ]
    },
    {
        "header": "4Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/figs/tool-use.png",
                "caption": "Figure 7:Steps and tool use density of two models across test sets.",
                "position": 1198
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAgent Structure",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14438/x8.png",
                "caption": "Figure 8:A running example ofProactive Web Exploring: a greater variety of interactions fosters a richer diversity of knowledge and introduces more challenges throughout the process, e.g., questions built from file knowledge also test the file-processing abilities of responding agents.",
                "position": 1968
            },
            {
                "img": "https://arxiv.org/html/2510.14438/x9.png",
                "caption": "Figure 9:A multimodal sample from the test set of WebAggregatorQA. To solve this task, the agent must extract information from the image to obtain clues for the next step. Since the image is not provided with the question, the agent is required to locate the relevant picture independently.",
                "position": 2044
            }
        ]
    },
    {
        "header": "Appendix BMore Details for WebAggregatorQA",
        "images": []
    }
]