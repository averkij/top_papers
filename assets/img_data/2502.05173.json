[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x1.png",
                "caption": "Figure 1:VideoRoPE outperforms RoPE variants on benchmarks.",
                "position": 225
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x2.png",
                "caption": "Figure 2:Left:To demonstrate the importance of frequential allocation, based on VIAH (a) we present a more challenging V-NIAH-D task (b) that similar images are inserted as distractors.Right:Compared to M-RoPE, our VideoRoPE is more robust in retrieval and is less affected by distractors.",
                "position": 228
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x3.png",
                "caption": "Figure 3:Attention-based frequential allocation analysis.Middle: M-RoPE‚Äôs temporal dimension (tùë°titalic_t) is limited to local information, resulting in a diagonal layout.Bottom: VideoRoPE effectively retrieves the needle using the temporal dimension.\nThe x and y coordinates represent the video frame number, e.g., 50 for 50 frames.\nFor more details see AppendixE.",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x4.png",
                "caption": "(a)Temporal Frequency Allocation in M-RoPE",
                "position": 571
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x4.png",
                "caption": "(a)Temporal Frequency Allocation in M-RoPE",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x5.png",
                "caption": "(b)Temporal Frequency Allocation in VideoRoPE (ours)",
                "position": 580
            }
        ]
    },
    {
        "header": "4VideoRoPE",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x6.png",
                "caption": "Figure 5:The position embeddings of adjacent text tokens for Vanilla RoPE (toprow), the corresponding visual tokens in adjacent frames for M-RoPE (middlerow) and our VideoRoPE (bottomrow) with interleaved spatial and temporal last design.",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x7.png",
                "caption": "(a)3D visualization for Vanilla RoPE.",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x7.png",
                "caption": "(a)3D visualization for Vanilla RoPE.",
                "position": 777
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x8.png",
                "caption": "(b)3D visualization for M-RoPE.",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2502.05173/x9.png",
                "caption": "(c)3D visualization for VideoRoPE.",
                "position": 788
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x10.png",
                "caption": "Figure 7:Visualization of the retrieval results for V-NIAH and V-NIAH-D. The color gradient from green to red represents the progression of needle retrieval performance, from perfect to zero.",
                "position": 953
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMORE EXPERIMENTS",
        "images": []
    },
    {
        "header": "Appendix BAdditional Details on Evaluation Benchmarks",
        "images": []
    },
    {
        "header": "Appendix CMore Related Works",
        "images": []
    },
    {
        "header": "Appendix DV-NIAH-D Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x11.png",
                "caption": "Figure 8:Five visual question-answering problems along with their corresponding needle and distractor.",
                "position": 2687
            }
        ]
    },
    {
        "header": "Appendix ESupplementary Attention Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.05173/x12.png",
                "caption": "Figure 9:Additional visual analysis of attention.",
                "position": 2697
            }
        ]
    },
    {
        "header": "Appendix FSupplementary Explanation on Frequency Allocation",
        "images": []
    }
]