[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01928/x1.png",
                "caption": "Figure 1:Model overview.Overview of the IAUNet architecture, highlighting the Pixel and Transformer Decoder stages. Given an input imageIIitalic_I, the encoder extracts multi-scale features as skip connections for the Pixel decoder. At each decoder block, we add skip connectionsXsX_{s}italic_X start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPTto the main featuresXXitalic_Xand inject normalized coordinate features for CoordConv. Stacked depth-wise convolutions with an SE block refine spatial information, generating mask featuresXmX_{m}italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. The Transformer decoder then processes learnable queriesqqitalic_qthrough three Transformer blocks per layer, iteratively refining them withXmX_{m}italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. Deep supervision loss is applied after each Transformer block using updated queriesq^\\hat{q}over^ start_ARG italic_q end_ARGand high-resolution mask features.",
                "position": 124
            }
        ]
    },
    {
        "header": "3Model Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01928/x2.png",
                "caption": "Figure 2:LIVECell. Visualization of instance segmentation predictions on the LIVECell dataset across different state-of-the-art models (using R50 backbone). We also report per-image AP score. Last columns shows ground-truth annotations.",
                "position": 146
            },
            {
                "img": "https://arxiv.org/html/2508.01928/x3.png",
                "caption": "Figure 3:Revvity-25. Visualization of instance segmentation predictions on the Revvity-25 dataset across different state-of-the-art models (using R50 backbone). Last columns shows ground-truth annotations. IAUNet as well as MaskDINO show good generalization across tiny details and overlaping instances. We also report per-image AP score.",
                "position": 175
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]