[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Technical preliminaries",
        "images": []
    },
    {
        "header": "3The lightweight multi-modal app control framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17883/extracted/5948706/phone_diagram_v5.png",
                "caption": "Figure 1:Illustration of AcT. A separate encoding of each UI element into a vectoret,isubscriptùëíùë°ùëñe_{t,i}italic_e start_POSTSUBSCRIPT italic_t , italic_i end_POSTSUBSCRIPTby using pretrained embedding models. The embeddings are then fed into the sequence of a transformerxtsubscriptùë•ùë°x_{t}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTalong with the previous timesteps in that episode. The prediction of the transformer is decoded to produce the next action which consists ofattypesubscriptsuperscriptùëétypeùë°a^{\\text{type}}_{t}italic_a start_POSTSUPERSCRIPT type end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTandatspecsubscriptsuperscriptùëéspecùë°a^{\\text{spec}}_{t}italic_a start_POSTSUPERSCRIPT spec end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.",
                "position": 226
            },
            {
                "img": "https://arxiv.org/html/2410.17883/extracted/5948706/hier_arc3.png",
                "caption": "Figure 2:The architecture of LiMAC. The history of observations-actions{ot,at‚àí1,ot‚àí1..}\\{o_{t},a_{t-1},o_{t-1}..\\}{ italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT . . }and goalgùëîgitalic_gare processed to vectorxùë•xitalic_xand passed to AcT.\nThe image observationotimgsubscriptsuperscriptùëúimgùë°o^{\\text{img}}_{t}italic_o start_POSTSUPERSCRIPT img end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTwith the bounding boxes and the goalgùëîgitalic_gare passed as inputs to the VLM.\nThe VLM is only called if an action that requires text completion is selected, based on the action type output of AcT. The action is finally selected based on the protocol described inSection3.",
                "position": 239
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Work on App Control",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADataset Format",
        "images": []
    },
    {
        "header": "Appendix BPrompt Engineering Baselines",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17883/x1.png",
                "caption": "Figure 3:Confusion matrix for action type selection for LiMAC in AndroidControl.",
                "position": 1716
            },
            {
                "img": "https://arxiv.org/html/2410.17883/extracted/5948706/flight_case_study.png",
                "caption": "Figure 4:Relaxed target element in yellow (timestep 3) and failed action in red (final timestep). The target element of theclickin timestep 3 is considered correct under our relaxed accuracy because its bounding box is almost identical to the correct element, and clicking either would have the same effect (opening the text bar). In the final timestep, the agent inputs text ‚ÄòDetroit‚Äô rather than ‚ÄòLas Vegas‚Äô, a clear confusion between the origin and destination of the trip stated in the goal, leading to an incorrect prediction.",
                "position": 1727
            },
            {
                "img": "https://arxiv.org/html/2410.17883/extracted/5948706/sofa_case_study.png",
                "caption": "Figure 5:Relaxedinput-textin yellow (timestep 4) and overall successful episode. Timestep 4 is considered correct under our relaxedinput-texttextual component because it is simply the singular form of the correct text, leading to a Jaccard index greater than 0.5 and presumably the same search results. The episode terminates successfully, with all timesteps being considered correct under our evaluation metrics.",
                "position": 1730
            }
        ]
    },
    {
        "header": "Appendix ECase Studies",
        "images": []
    }
]