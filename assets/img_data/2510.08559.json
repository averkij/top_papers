[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08559/x1.png",
                "caption": "Figure 1:SciVideoBenchfeaturesresearch-levelexperimental videos accompanied by challenging questions that rigorously evaluate advanced video understanding. It emphasizes thesynergistic interactionamong accuratevisual perception,expert knowledge, and sophisticatedlogical reasoning.",
                "position": 140
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08559/x2.png",
                "caption": "Figure 2:Overview of our annotation pipeline. We manually annotate QA pairs for three example videos using both the video and the associated paper. A multi-agent LLM system generates and refines QA pairs: the QA Generator produces initial questions, the Evaluator answers them with reasoning, the Visual Comparer checks for visual grounding and timestamps cues, and the Refiner ensures questions rely on video content and improves option quality. Human experts verify and refine the final QA pairs. Audio transcripts are omitted for simplicity.",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x3.png",
                "caption": "Figure 3:Discipline and subject distribution inSciVideoBench.\nOur benchmark covers four major scientific disciplines—Biology, Chemistry, Medicine, and Physics—encompassing more than 25 specialized subjects.\nThis diverse coverage ensures a comprehensive evaluation across a wide range of scientific domains.",
                "position": 367
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x4.png",
                "caption": "(a)Video duration distribution.",
                "position": 381
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x4.png",
                "caption": "(a)Video duration distribution.",
                "position": 384
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x5.png",
                "caption": "(b)Question length distribution.",
                "position": 389
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x6.png",
                "caption": "(c)Option length distribution.",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x7.png",
                "caption": "Figure 5:Examples ofSciVideoBench, including videos from 4 disciplines (Physics, Biology, Chemistry, and Medicine), which involve 19 different subjects. The research-level QAs challenge LMMs in three different aspects (Conceptual, Hypothetical, and Quantitative) that are of vital importance in scientific experiment video understanding.",
                "position": 427
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08559/x8.png",
                "caption": "Figure 6:Chain-of-thought prompt used inSciVideoBench",
                "position": 1421
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x9.png",
                "caption": "Figure 7:Chain-of-Thought (CoT) performance gains acrossproprietary modelsandopen-source models.\nAn obvious difference betweenproprietary modelsacross all the reasoning aspects can be observed;\nwhile foropen-source models, quantitative reasoning has a notable performance boost,\nwhile the other two reasoning aspects have negative impacts.\nThis phenomenon again demonstrates that the quantitative settings inSciVideoBenchrequire sophisticated multi-step reasoning\nthat can benefit a lot from chain-of-thought prompts. Best viewed in color.",
                "position": 1429
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x10.png",
                "caption": "Figure 8:The impact of LMM backbones on the performance.",
                "position": 1602
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x11.png",
                "caption": "Figure 9:Failure case example of Gemini-2.0-Flash-Thinking.",
                "position": 1735
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix overview",
        "images": []
    },
    {
        "header": "Appendix BDisciplines and Subjects",
        "images": []
    },
    {
        "header": "Appendix CConfiguration of Evaluated Models",
        "images": []
    },
    {
        "header": "Appendix DMetadata Generation Using Gemini 2.5 Pro",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.08559/x12.png",
                "caption": "Figure 10:The prompt for Gemini 2.5 Pro to generate metadata to support initial annotation.",
                "position": 2841
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x13.png",
                "caption": "Figure 11:The prompt for Gemini 2.5 Pro to generate distractors.",
                "position": 2846
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x14.png",
                "caption": "Figure 12:The prompt for Gemini 2.5 Pro to update distractors.",
                "position": 2851
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x15.png",
                "caption": "Figure 13:Failure case example of InternVL-3-14B with chain-of-thought prompt compared with the correct reasoning of Gemini 1.5 Pro. InternVL-3-14B makes the wrong predictions because of the incorrect visual perception of the experiment results, while Gemini 1.5 Pro correctly captures the unchanged state of the peak at different wavelength.",
                "position": 2939
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x16.png",
                "caption": "Figure 14:Failure case example of Qwen2.5-VL-32B-Instruct. The model makes the wrong prediction because of lacking the domain knowledge about the incubation process.",
                "position": 2944
            },
            {
                "img": "https://arxiv.org/html/2510.08559/x17.png",
                "caption": "Figure 15:Failure case example of InternVL-3-9B. The model makes the wrong predictions because of the wrong calculating logic and wrong solvent identification.",
                "position": 2949
            }
        ]
    },
    {
        "header": "Appendix EMore Failure Case Studies",
        "images": []
    }
]