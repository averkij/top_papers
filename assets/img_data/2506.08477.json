[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08477/x1.png",
                "caption": "Figure 1:Illustration of previous methods and ourU-CoT+.\nPrevious methods follow either fully supervised or low-resource settings, fine-tuning LMMs/LLMs with labeled data or prompting advanced LMMs (e.g., GPT-4) with (or without) few-shot examples or retrieval-augmented mechanisms.\nThese methods do not necessarily guarantee predictions that include explicit reasoning.\nU-CoT+ employs aHigh-fidelity Meme2Textpipeline to convert the multimodal harmful meme detection task into a unimodal, text-only setting, and further enhances LLM performance throughUnimodal Guided CoT Prompting.\nAn output example given by Qwen2.5-14B under U-CoT+ is presented in “Step-by-step Reasoning”.",
                "position": 247
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08477/x2.png",
                "caption": "Figure 2:Comparison of classification confusion matrices under three different zero-shot CoT prompting schemes, with Llava1.6-7B and Qwen2VL-7B as the base LMMs for Meme2Text, and Qwen2.5-14B as the base LLM for unimodal, text-only inference.",
                "position": 1473
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADatasets",
        "images": []
    },
    {
        "header": "Appendix BBaselines",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.08477/x3.png",
                "caption": "Figure 3:Distribution of error types within the thirty randomly sampled error cases from each of FHM, PrideMM, and Harm-P.",
                "position": 3805
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x4.png",
                "caption": "Figure 4:Example LLM reasoning outputs for correctly detected harmful memes in FHM.",
                "position": 3808
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x5.png",
                "caption": "Figure 5:Example LLM reasoning outputs for correctly detected harmful memes in Harm-C.",
                "position": 3811
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x6.png",
                "caption": "Figure 6:Example LLM reasoning outputs for correctly detected harmful memes in Harm-P.",
                "position": 3814
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x7.png",
                "caption": "Figure 7:Example LLM reasoning outputs for correctly detected harmful memes in MultiOFF.",
                "position": 3817
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x8.png",
                "caption": "Figure 8:Example LLM reasoning outputs for correctly detected harmful memes in PrideMM.",
                "position": 3820
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x9.png",
                "caption": "Figure 9:Example LLM reasoning outputs for correctly detected harmful memes in MAMI.",
                "position": 3823
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x10.png",
                "caption": "Figure 10:Error Analysis on FHM.",
                "position": 3826
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x11.png",
                "caption": "Figure 11:Error Analysis on PrideMM.",
                "position": 3829
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x12.png",
                "caption": "Figure 12:Error Analysis on Harm-P.",
                "position": 3832
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x13.png",
                "caption": "Figure 13:Examples of potential annotation errors in FHM, PrideMM and Harm-P.",
                "position": 3835
            },
            {
                "img": "https://arxiv.org/html/2506.08477/x14.png",
                "caption": "Figure 14:Our proposed High-fidelity Meme2Text pipeline.",
                "position": 3838
            }
        ]
    },
    {
        "header": "Appendix DCase Study",
        "images": []
    }
]