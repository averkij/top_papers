[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x1.png",
                "caption": "Figure 1:Causal information flow dissection for modality following. (a) Multimodal cues are routed to instruction tokens, which function as structural anchors.\n(b) Shallow attention layers route cues to these anchors to form a “latent buffer” without enforcing selection.\n(c) Deep attention layers act as the “definitive arbiter”, resolving modality competition based on instruction semantic, while MLP layers exhibit semantic inertia, acting as an adversarial force driven by internal priors.",
                "position": 151
            }
        ]
    },
    {
        "header": "2Constructing Analysis Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x2.png",
                "caption": "Figure 2:Illustration of Vision Following. Given conflict visual and textual contexts—depicting two and three individuals respectively—the model is presented with a vision-centric query along with specific instructions and a bilingual answer entity dictionary. The ground truth is the vision-compliant answer.",
                "position": 214
            }
        ]
    },
    {
        "header": "3Instruction Functions as Structural Anchors",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x3.png",
                "caption": "Figure 3:ℐN​S​S​D\\mathcal{I}_{NSSD}results across the different knockout pathways in text-following (left) and vision-following (right) tasks. We useSource↛Target\\text{Source}\\nrightarrow\\text{Target}to represent blocking the attention mechanism from the source tokens to the target tokens. For convenience, ’Last’ denotes the generated token.",
                "position": 351
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x4.png",
                "caption": "(a)Qwen2.5-VL-7B",
                "position": 355
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x4.png",
                "caption": "(a)Qwen2.5-VL-7B",
                "position": 358
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x5.png",
                "caption": "(b)InternVL3-8B",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x6.png",
                "caption": "(a)Layer-wise LDAR results.",
                "position": 447
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x6.png",
                "caption": "(a)Layer-wise LDAR results.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x7.png",
                "caption": "(b)Causal path blocking.",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x8.png",
                "caption": "(a)Latent logit intensities.",
                "position": 469
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x8.png",
                "caption": "(a)Latent logit intensities.",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x9.png",
                "caption": "(b)Signal Intensity Contribution",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x10.png",
                "caption": "Figure 7:Modality arbitration margin contribution. Attention and MLP attribution to the arbitration margin, illustrating the roles of deep attention (arbitration) and MLPs (opposing influence).",
                "position": 487
            }
        ]
    },
    {
        "header": "4Mechanistic Dissection of Modality Arbitration",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x11.png",
                "caption": "Figure 8:Functional sparsity and specialization of attention heads. Layer-wise contribution of individual heads to the modality arbitration margin. Arbitration power is sparse and predominantly concentrated indeep layers. Despite task differences, a significant overlap in top-performing heads suggests the existence of modality-agnostic arbitration hubs.",
                "position": 667
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x11.png",
                "caption": "",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x12.png",
                "caption": "",
                "position": 674
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x13.png",
                "caption": "Figure 9:Causal verification via head intervention. Comparison of Modality Following Ratio (MFR) for target, random and shared heads for Text Following (TF) and Vision Following (VF).Left:Impact of the number of blocked heads on MFR.Right:Impact of the amplification coefficientα\\alphaon MFR.",
                "position": 709
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADiscussion",
        "images": []
    },
    {
        "header": "Appendix BDataset Construction",
        "images": []
    },
    {
        "header": "Appendix CMore Details for Attention Knockout Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x14.png",
                "caption": "(a)Blocking Window Sizew=1w=1",
                "position": 1393
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x14.png",
                "caption": "(a)Blocking Window Sizew=1w=1",
                "position": 1396
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x15.png",
                "caption": "(b)Blocking Window Sizew=5w=5.",
                "position": 1401
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x16.png",
                "caption": "(a)InternVL3-8B",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x16.png",
                "caption": "(a)InternVL3-8B",
                "position": 1420
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x17.png",
                "caption": "(b)LLaVA1.5-7B",
                "position": 1425
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x18.png",
                "caption": "(a)Layer-wise LDAR results.",
                "position": 1442
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x18.png",
                "caption": "(a)Layer-wise LDAR results.",
                "position": 1445
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x19.png",
                "caption": "(b)Causal path blocking.",
                "position": 1450
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x20.png",
                "caption": "(c)Modality arbitration margin contribution.",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x21.png",
                "caption": "(a)Latent logit intensities.",
                "position": 1462
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x21.png",
                "caption": "(a)Latent logit intensities.",
                "position": 1465
            },
            {
                "img": "https://arxiv.org/html/2602.03677/x22.png",
                "caption": "(b)Signal Intensity Contribution",
                "position": 1470
            }
        ]
    },
    {
        "header": "Appendix DMore Results for Mechanistic Dissection of Modality Arbitration",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.03677/x23.png",
                "caption": "Figure 14:Causal verification via head intervention.\nWe compare the Modality Following Ratio (MFR) for Text Following (TF) and Vision Following (VF) across three settings:\n(1) TopK Inst: utilizing Top-KKinstruction aggregation (K>1K>1); we report results forK=2K=2as a representative instance, given the similar performance trends observed acrossK>1K>1.\n(2) Avg Answer: employing an averaging strategy that aggregates logits across all semantically equivalent answer tokens;\n(3) Ours: the default max-pooling strategy used in the main text.Left:Impact of the number of blocked heads on MFR.Right:Impact of the amplification coefficientα\\alphaon MFR.",
                "position": 1494
            }
        ]
    },
    {
        "header": "Appendix EAblation Studies and Robustness Analysis",
        "images": []
    }
]