[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/x1.png",
                "caption": "Figure 1:Qualitative performance of VARIN given diverse prompts.",
                "position": 88
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/fig/HART.jpg",
                "caption": "Figure 2:Visualizations of each scale of the generation process of HART(tang2024hart,). The features of a cat (top) and the landscape (bottom) are only distinguishable above 6 scales.",
                "position": 148
            }
        ]
    },
    {
        "header": "4Inverse Autoregressive Transformation and Editable Inverse Noise",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/x2.png",
                "caption": "Figure 3:VARIN pipeline: the prefix tokencs​r​c+r<kc_{src}+r_{<k}is fed to transformer to get log probabilitypkp_{k}. We then use pseudo inverse-argmax to find the inverse noisenkn_{k}from ground truth labelrkr_{k}and logitpkp_{k}. These noise setn1,n2,…,nKn_{1},n_{2},\\dots,n_{K}is later used for editing control.",
                "position": 190
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/x3.png",
                "caption": "Figure 4:Qualitative result of editing results between VARIN and baseline Regeneration. We should better editing capability and background preservation.",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2509.01984/x4.png",
                "caption": "Figure 5:Fine-grained editing examples with VARIN using Switti(voronov2024switti,). VARIN successfully performs localized modifications such as changing facial expressions, object replacement, and hand gestures while preserving original image details.",
                "position": 661
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "Appendix BRegeneration Algorithm",
        "images": []
    },
    {
        "header": "Appendix CAblation",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/x5.png",
                "caption": "Figure 6:Ablation of Regeneration on beginning scale for editingss. We can see that asssincreases, the edited image are more like the source image. For smallss, the edited image is too different from the source image. Therefore, the bestssfor editing is around 6 to 8",
                "position": 1670
            },
            {
                "img": "https://arxiv.org/html/2509.01984/fig/tau.png",
                "caption": "Figure 7:Qualitative result for ablation ofτ\\taufor VARIN.",
                "position": 1754
            }
        ]
    },
    {
        "header": "Appendix DGumbel Truncation Sampling",
        "images": []
    },
    {
        "header": "Appendix EEditing using Only Target Prompt",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.01984/x6.png",
                "caption": "Figure 8:The first column is source image. The second column is target VARINAlgorithm˜6, and the third column is source-target VARINAlgorithm˜3. The green and red color texts are source and target prompt, correspondingly.",
                "position": 1902
            },
            {
                "img": "https://arxiv.org/html/2509.01984/x7.png",
                "caption": "Figure 9:Editing results on complex scene involves two objects.",
                "position": 1905
            },
            {
                "img": "https://arxiv.org/html/2509.01984/x8.png",
                "caption": "Figure 10:Extending VARIN to different architectures and base models.",
                "position": 1908
            },
            {
                "img": "https://arxiv.org/html/2509.01984/x9.png",
                "caption": "Figure 11:Comparing VARIN with different methods.",
                "position": 1911
            },
            {
                "img": "https://arxiv.org/html/2509.01984/x10.png",
                "caption": "Figure 12:Failure cases: large movement and complex interaction between object",
                "position": 1941
            }
        ]
    },
    {
        "header": "Appendix FMore Qualitative Comparison",
        "images": []
    },
    {
        "header": "Appendix GLimitation",
        "images": []
    }
]