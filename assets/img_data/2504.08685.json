[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08685/x1.png",
                "caption": "Figure 1:Short and detailed captions are generated by our video captioning model. The short captions provide action-centric summaries of the videos, while the detailed captions offer rich descriptions of the scenes, including attributes, objects, and environments.",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/video_data_pipeline.png",
                "caption": "Figure 2:Video Data Processing Pipeline Overview.",
                "position": 257
            }
        ]
    },
    {
        "header": "3Design and Discussions",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08685/x2.png",
                "caption": "Figure 3:Overview of VAE architecture.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original_cake.jpg",
                "caption": "(a)Original Video",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original_cake.jpg",
                "caption": "(a)Original Video",
                "position": 318
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v3_rec_cake.jpg",
                "caption": "(b)48×48\\times48 ×compression Seaweed VAE",
                "position": 323
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v4_rec_cake.jpg",
                "caption": "(c)64×64\\times64 ×compression Seaweed VAE",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original_skiing.jpg",
                "caption": "(a)Original Video",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original_skiing.jpg",
                "caption": "(a)Original Video",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v3_skiing.jpg",
                "caption": "(b)48×48\\times48 ×Seaweed VAE",
                "position": 343
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v4_skiing.jpg",
                "caption": "(c)64×64\\times64 ×Seaweed VAE",
                "position": 348
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x3.png",
                "caption": "48×48\\times48 ×VAE at30ksteps",
                "position": 355
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x3.png",
                "caption": "48×48\\times48 ×VAE at30ksteps",
                "position": 358
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x4.png",
                "caption": "64×64\\times64 ×VAE at30ksteps",
                "position": 363
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x5.png",
                "caption": "48×48\\times48 ×VAE,45ksteps",
                "position": 369
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x6.png",
                "caption": "64×64\\times64 ×VAE at45ksteps",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x7.png",
                "caption": "48×48\\times48 ×VAE at60ksteps",
                "position": 380
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x8.png",
                "caption": "64×64\\times64 ×VAE at60ksteps",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x9.png",
                "caption": "Figure 7:Validation metric curves on high-resolution image reconstruction (512×512512512512\\times 512512 × 512) show the effectiveness of mix-resolution VAE training.",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x10.png",
                "caption": "Figure 8:Loss comparison between the dual-stream and the hybrid-stream architectures. The table compares the two losses under the same training FLOPs.",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x11.png",
                "caption": "Figure 9:Illustration of the space-full and window attention architecture.",
                "position": 502
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/dit_attn/scaling_laws.png",
                "caption": "Figure 10:Loss comparison of full and space-full attention.",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/dit_attn/scaling_laws.png",
                "caption": "Figure 10:Loss comparison of full and space-full attention.",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/dit_attn/new_attn_loss2.png",
                "caption": "Figure 11:Loss comparison of full and window attention.",
                "position": 523
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x12.png",
                "caption": "Figure 12:Loss comparison between RoPE and MM-Rope.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/sft/turtle_keyframes.jpg",
                "caption": "Figure 13:Top: Before SFT.Bottom: After SFT.\nResults for prompt \"Turtle swimming in the ocean\".",
                "position": 610
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/sft/astronaut_00007.jpg",
                "caption": "Figure 14:Left: Before SFT.Middle: Good SFT.Right: Overfit SFT.\nResults for prompt: \"An astronaut running through an alley in Rio de Janeiro, 4k, high resolution\".",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x13.png",
                "caption": "Figure 15:Two image-to-video examples before (top row) and after (bottom row) DPO. DPO significantly improves the structure and motion quality.",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/training_infrastructure/mlao.png",
                "caption": "Figure 16:Multi-level activation checkpointing(MLAC). (a) Vanilla AC saves inputs on device could still encounter GPU OOM. (b) MLAC further supports offloading module inputs to achieve zero-activation AC, (c) and minimize recomputation overheads by saving compute-bound activations to multi-level storage space.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/training_infrastructure/runtime_balance.png",
                "caption": "Figure 17:Balance samples within one batch across GPUs by runtime metric.Top: seqlen-to-runtime lookup table.Bottom left: One batch samples across GPUs before balance.Bottom left: One batch samples across GPUs after balance.",
                "position": 655
            }
        ]
    },
    {
        "header": "4Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08685/x14.png",
                "caption": "Figure 18:Comparison of Seaweed-7B with the top ranking models: Kling 1.6, Sora, HunyuanVideo, and Wan-2.1. The task is image-to-video.",
                "position": 810
            },
            {
                "img": "https://arxiv.org/html/2504.08685/x15.png",
                "caption": "Figure 19:Comparison of the Seaweed-7B Model top ranking models: Veo 2.0 and Wan-2.1. The task is text-to-video.",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original.jpg",
                "caption": "(a)Original Video",
                "position": 1031
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/original.jpg",
                "caption": "(a)Original Video",
                "position": 1034
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v3_formal.jpg",
                "caption": "(b)48×48\\times48 ×Seaweed VAE",
                "position": 1039
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/v4_formal.jpg",
                "caption": "(c)64×64\\times64 ×Seaweed VAE",
                "position": 1045
            },
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/vae_visualization/hunyuan_4x8x8.jpg",
                "caption": "(d)48×\\times×Hunyuan VAE",
                "position": 1050
            }
        ]
    },
    {
        "header": "5Applications",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.08685/extracted/6349619/figures/application/audio-cavp.png",
                "caption": "Figure 21:Contrastive Audio-Visual Pretraining (CAVP).",
                "position": 1094
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Contributors and Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]