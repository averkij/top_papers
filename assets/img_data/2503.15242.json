[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15242/x1.png",
                "caption": "Figure 1:BigO(Bench)framework overview: Given a coding problem and human solutions, the framework evaluates language models on three key tasks: (1) predicting time-space complexities of existing solutions, (2) generating new code that meets specified complexity requirements, and (3) ranking solutions against human-written code with similar complexity profiles. The complexity framework automatically validates model outputs by computing runtime distributions and curve coefficients.",
                "position": 125
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Dynamic Complexity Inference Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15242/x2.png",
                "caption": "Figure 2:Outline of the dynamic complexity inference framework. The framework takes a code snippet and a single example of inputs to this code snippet. Then, it processes the code snippet and proceeds with extensive inputs generation, based on the provided example of inputs: inputs are independently or interdependently increased in size, using several expansion methods that can be the identity or random, among else. This forms a queue of synthetic inputs on which to execute the provided code snippet. These executions happen independently in sandboxes, where runtime and memory footprint measures are taken. Once all the measures are collected, the framework can model the code snippet time and space dependencies to the different inputs. Using curve fitting, the time and space complexity of the code is computed on each input separately and then altogether. The global time and space complexity over all inputs is what is being returned.",
                "position": 198
            }
        ]
    },
    {
        "header": "4Benchmark Data Release",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/dataset_composition.png",
                "caption": "Figure 3:Distribution of time-space complexity classes acrossBigO(Bench)dataset of 3,105 coding problems. Each problem is included when at least one solution exists with that specific time-space complexity pair.\nLinear time O(n) represents 38% of solutions, while constant space O(1) accounts for 25%.\nThe chart orders classes by computational efficiency, with less common classes grouped under ‚Äúother‚Äù.\nProblems for which the framework can not infer a time complexity and/or a space complexity are not counted.",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/global_error_analysis.jpg",
                "caption": "Figure 4:Failure rate analysis of the complexity inference framework. The top plot shows the overall distribution of framework failures across all problems. The bottom heatmap breaks down failure rates by input type and number of distinct inputs.\nApproximately 84% of problems have failure rates below 30%, demonstrating robust performance across most input configurations.",
                "position": 378
            }
        ]
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6Quantitative Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/benchmark_complexity.jpg",
                "caption": "Figure 5:LLM results aggregated by time complexity class and by algorithmic notions for all models part ofBigO(Bench).",
                "position": 1193
            },
            {
                "img": "https://arxiv.org/html/2503.15242/x3.png",
                "caption": "Figure 6:Model performance per coding benchmarks:HumanEval,MBPPandBigCodeBenchmain metrics are allP‚Å¢a‚Å¢s‚Å¢s‚Å¢@‚Å¢1ùëÉùëéùë†ùë†@1Pass@1italic_P italic_a italic_s italic_s @ 1; forBigO(Bench), we displayA‚Å¢l‚Å¢l‚Å¢@‚Å¢1ùê¥ùëôùëô@1All@1italic_A italic_l italic_l @ 1results.",
                "position": 1215
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Complexity Prediction Example",
        "images": []
    },
    {
        "header": "9Complexity Generation Example",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/complexity_per_algorithmic_notion_time.png",
                "caption": "Figure 7:Breakdown of time complexity classes across different algorithmic categories. The stacked bar charts reveal how complexity requirements vary by problem type. Problems involving graph handling and string manipulation tend to have higher computational complexity, while basic arithmetic and sequence operations typically achieve more efficient complexity classes.",
                "position": 2584
            },
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/complexity_per_algorithmic_notion_space.png",
                "caption": "Figure 8:Breakdown of space complexity classes across different algorithmic categories. The stacked bar charts reveal how complexity requirements vary by problem type. Problems involving graph handling and string manipulation tend to have higher computational complexity, while basic arithmetic and sequence operations typically achieve more efficient complexity classes.",
                "position": 2587
            },
            {
                "img": "https://arxiv.org/html/2503.15242/extracted/6297511/figures/complexity_per_difficulty.png",
                "caption": "Figure 9:Evolution of time and space complexity distributions across problem difficulty levels (A through D+). This visualization demonstrates how harder problems tend to require more computationally intensive solutions. The proportion of linear and constant-time solutions decreases with difficulty, while the share of higher-order polynomial and logarithmic complexities increases.",
                "position": 2590
            }
        ]
    },
    {
        "header": "10Repartition of Complexity Classes per Algorithmic Notions",
        "images": []
    }
]