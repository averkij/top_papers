[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x131.png",
                "caption": "",
                "position": 44
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x132.png",
                "caption": "",
                "position": 53
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x133.png",
                "caption": "",
                "position": 65
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x1.png",
                "caption": "Figure 1:An HoT, composed of a re-formatted question and answer, generated byGemini-1.5-Pro() in response to a GSM8K question.",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x3.png",
                "caption": "",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x4.png",
                "caption": "",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x5.png",
                "caption": "",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x6.png",
                "caption": "",
                "position": 251
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x7.png",
                "caption": "",
                "position": 267
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x2.png",
                "caption": "Figure 2:Gemini-1.5-Pro() first highlights key facts in the question, then generates an answer with highlights linked to those facts.\nSeeTabs.T26andT38for more examples.",
                "position": 313
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/arrow.png",
                "caption": "Figure 4:LLMs generate HoT responses by wrapping XML tags around the information that the model determines is the most important.\nRegex and CSS are then used to visualize the highlights for user readability.",
                "position": 401
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x9.png",
                "caption": "Table 1:Over all 5 LLMs, HoT consistently improves accuracy over CoT across arithmetic tasks. Notably, HoT achieves the largest performance gains in AQUA (+14.64for) and r-GSM (+12.73for).",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x10.png",
                "caption": "",
                "position": 544
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x11.png",
                "caption": "",
                "position": 596
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x12.png",
                "caption": "",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x13.png",
                "caption": "",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x16.png",
                "caption": "Table 2:Over all 5 LLMs, HoT consistently improves accuracy over CoT across QA tasks (StrategyQA, SpartQA, Date Understanding) and reading comprehension tasks (Break and Census). The largest gains are observed in StrategyQA (+15.07for) and SpartQA (+11.88for).",
                "position": 684
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x17.png",
                "caption": "",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x18.png",
                "caption": "",
                "position": 700
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x19.png",
                "caption": "",
                "position": 744
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x20.png",
                "caption": "",
                "position": 766
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x21.png",
                "caption": "",
                "position": 788
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x23.png",
                "caption": "Table 3:HoT outperforms CoT across logical reasoning BBH subsets, with notable gains in Judgment (+15.5for) and Five Object tasks (+6.00for).",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x24.png",
                "caption": "",
                "position": 839
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x25.png",
                "caption": "",
                "position": 884
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x26.png",
                "caption": "",
                "position": 906
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x27.png",
                "caption": "",
                "position": 928
            }
        ]
    },
    {
        "header": "4Datasets",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x28.png",
                "caption": "",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x29.png",
                "caption": "",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x30.png",
                "caption": "",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x31.png",
                "caption": "",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x32.png",
                "caption": "",
                "position": 1054
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x33.png",
                "caption": "",
                "position": 1054
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x34.png",
                "caption": "",
                "position": 1054
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x35.png",
                "caption": "Figure 6:Our ablation study shows that every component inHoTprompting (+++)—repeating the question (R-Q), adding tags to only question (T-Q), adding tags to only answer (T-A)—contributes to the accuracy of our HoT method.\nEvery HoT component alone outperforms the vanillaCoT(×\\times×).\ny-axis shows mean accuracy across 6 datasets.",
                "position": 1056
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x36.png",
                "caption": "",
                "position": 1061
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x37.png",
                "caption": "",
                "position": 1061
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x38.png",
                "caption": "",
                "position": 1061
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x39.png",
                "caption": "",
                "position": 1074
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x40.png",
                "caption": "",
                "position": 1074
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x41.png",
                "caption": "",
                "position": 1081
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x43.png",
                "caption": "Table 4:The mean number of tags generated by LLMs forHoTmatch that byfew-show demonstrations the most compared to other variations (T-QandT-A), showing the importance of instructing LLMs to insert tags to both questions and answers (i.e.,HoT).\nAll numbers are means computed across 6 datasets in the ablation study.",
                "position": 1084
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x44.png",
                "caption": "",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x45.png",
                "caption": "",
                "position": 1094
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x46.png",
                "caption": "",
                "position": 1095
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x47.png",
                "caption": "",
                "position": 1097
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x48.png",
                "caption": "Figure 7:(a)Moving tags in the answer of HoT to random phrases (i.e., Mismatched HoT) results in substantial accuracy drops across many datasets e.g., thisΔΔ\\Deltaroman_Δis-3.25for.(b)The average accuracy drop of MismatchedHoTw.r.t.HoTis-2.13pp.(c)On average across 4 LLMs, MismatchedHoTstill outperforms vanillaCoTby a mean gain of+1.21pp.",
                "position": 1215
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x48.png",
                "caption": "",
                "position": 1217
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x49.png",
                "caption": "",
                "position": 1226
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x50.png",
                "caption": "",
                "position": 1235
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x51.png",
                "caption": "",
                "position": 1236
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x52.png",
                "caption": "",
                "position": 1248
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x53.png",
                "caption": "",
                "position": 1257
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x54.png",
                "caption": "",
                "position": 1258
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x56.png",
                "caption": "",
                "position": 1272
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x57.png",
                "caption": "",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x58.png",
                "caption": "",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x59.png",
                "caption": "",
                "position": 1279
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x60.png",
                "caption": "",
                "position": 1295
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x61.png",
                "caption": "",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x62.png",
                "caption": "",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x63.png",
                "caption": "",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x64.png",
                "caption": "",
                "position": 1306
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x66.png",
                "caption": "Table 6:Users spend∼similar-to\\sim∼25% less time when verifying chains of thoughts with highlights (compared to without highlights).\nHighlights tend to cause users to accept LLM answers more, resulting in improved accuracy incorrectcases and worse accuracy inincorrectones.",
                "position": 1317
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x67.png",
                "caption": "",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x69.png",
                "caption": "Table 7:The estimatedhuman verification accuracy on all 17 benchmarks is higher with highlights (HoT) rather than without highlights (CoT).\nMore results inAppendixF.",
                "position": 1401
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x70.png",
                "caption": "",
                "position": 1453
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x71.png",
                "caption": "",
                "position": 1485
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x72.png",
                "caption": "",
                "position": 1501
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x73.png",
                "caption": "",
                "position": 1517
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x74.png",
                "caption": "",
                "position": 1549
            },
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/llm_icons/logan/llavavision.png",
                "caption": "",
                "position": 1549
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x75.png",
                "caption": "",
                "position": 1562
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x76.png",
                "caption": "",
                "position": 1562
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x77.png",
                "caption": "",
                "position": 1562
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x78.png",
                "caption": "",
                "position": 1562
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x79.png",
                "caption": "",
                "position": 1568
            }
        ]
    },
    {
        "header": "7Discussion and Future Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AHuman Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x80.png",
                "caption": "",
                "position": 2348
            },
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/Human/Screenshot1.png",
                "caption": "Figure F1:Screenshot of a CoT question from the DROP dataset in the online interface.",
                "position": 2404
            },
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/Human/Screenshot2.png",
                "caption": "Figure F2:Screenshot of a HoT question from the GSM-Symbolic dataset in the online interface.",
                "position": 2407
            }
        ]
    },
    {
        "header": "Appendix BLLM-as-a-Judge accuracy with HoT",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x82.png",
                "caption": "",
                "position": 2451
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x84.png",
                "caption": "Table T1:HoT and CoT have mixed effects on LLM-as-a-Judge accuracy across different models and modalities.",
                "position": 2466
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x85.png",
                "caption": "",
                "position": 2552
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x86.png",
                "caption": "Table T6:On the left, QwQ-32B-Preview fails to generate tags in the question, and its answer is excessively long, despite our few-shot examples providing short and concise answers with sufficient tags in both questions and answers. In contrast, models likeLlama-3.1-70Bsuccessfully generate tags in both the question and answer, producing responses that are short and concise.",
                "position": 2897
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x87.png",
                "caption": "",
                "position": 2908
            }
        ]
    },
    {
        "header": "Appendix CXML Tag Ablation Study",
        "images": []
    },
    {
        "header": "Appendix DModel Details",
        "images": []
    },
    {
        "header": "Appendix EHoT Visualization Detail Code",
        "images": []
    },
    {
        "header": "Appendix FEstimate verification accuracy of users",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x88.png",
                "caption": "Table T8:Estimated human verification accuracy for HoT on arithmetic tasks.",
                "position": 3243
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x89.png",
                "caption": "",
                "position": 3314
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x90.png",
                "caption": "",
                "position": 3340
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x91.png",
                "caption": "",
                "position": 3366
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x92.png",
                "caption": "Table T9:Estimated human verification accuracy for HoT on reading comprehension tasks.",
                "position": 3403
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x93.png",
                "caption": "",
                "position": 3463
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x94.png",
                "caption": "",
                "position": 3485
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x95.png",
                "caption": "",
                "position": 3507
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x96.png",
                "caption": "Table T10:Estimated human verification accuracy for HoT on the subset of logical tasks in BBH.",
                "position": 3536
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x97.png",
                "caption": "",
                "position": 3634
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x98.png",
                "caption": "",
                "position": 3656
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x99.png",
                "caption": "",
                "position": 3678
            }
        ]
    },
    {
        "header": "Appendix GHoT may hurtLlama-3.1-8B,Qwen-2.5-Coder-32Bperformance",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x102.png",
                "caption": "Table T13:Performance comparison of CoT and HoT acrossLlama-3.1-8B() andQwen-2.5-Coder-32B(), evaluated on QA (StrategyQA and Date Understanding) and logical reasoning datasets.",
                "position": 3832
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x103.png",
                "caption": "",
                "position": 3833
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x104.png",
                "caption": "",
                "position": 3838
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x105.png",
                "caption": "",
                "position": 3839
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x106.png",
                "caption": "",
                "position": 3840
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x107.png",
                "caption": "",
                "position": 3841
            }
        ]
    },
    {
        "header": "Appendix HDetail Analysis of the Impact of Tagging and Question Repetition on Chain-of-Thought Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x108.png",
                "caption": "Table T14:Performance comparison of various few-shot prompting strategies (CoT, Repeated Question, Tags in Question, Tags in Answer, and Tag in QA) across multiple models (Gemini-1.5-Flash,Gemini-1.5-Pro,Llama-3.1-70B, andLlama-3.1-405B) and datasets (tested each dataset on 400 random samples). The table shows promptTags in QAachieves the highest mean accuracy among multiple prompts.",
                "position": 4024
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x109.png",
                "caption": "",
                "position": 4194
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x110.png",
                "caption": "",
                "position": 4251
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x111.png",
                "caption": "Table T15:The average number of tags in Question using promptTag in Question.",
                "position": 4285
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x111.png",
                "caption": "Table T15:The average number of tags in Question using promptTag in Question.",
                "position": 4288
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x112.png",
                "caption": "",
                "position": 4296
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x113.png",
                "caption": "",
                "position": 4297
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x114.png",
                "caption": "Table T16:The average number of tags in Answer using promptTag in Question. Numbers over 0.00 are the result of the model not properly following instructions.",
                "position": 4354
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x115.png",
                "caption": "",
                "position": 4362
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x116.png",
                "caption": "",
                "position": 4363
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x117.png",
                "caption": "Table T17:The average number of tags in Question using promptTag in Answer.",
                "position": 4420
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x117.png",
                "caption": "Table T17:The average number of tags in Question using promptTag in Answer.",
                "position": 4423
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x118.png",
                "caption": "",
                "position": 4431
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x119.png",
                "caption": "",
                "position": 4432
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x120.png",
                "caption": "Table T18:The average number of tags in Answer using promptTag in Answer.",
                "position": 4489
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x121.png",
                "caption": "",
                "position": 4497
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x122.png",
                "caption": "",
                "position": 4498
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x123.png",
                "caption": "Table T19:The average number of tags in Reformatted Question using promptTag in both Question and Answer.",
                "position": 4555
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x123.png",
                "caption": "Table T19:The average number of tags in Reformatted Question using promptTag in both Question and Answer.",
                "position": 4558
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x124.png",
                "caption": "",
                "position": 4566
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x125.png",
                "caption": "",
                "position": 4567
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x126.png",
                "caption": "Table T20:The average number of tags in Answer usingTag in both Question and Answer.",
                "position": 4624
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x127.png",
                "caption": "",
                "position": 4632
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x128.png",
                "caption": "",
                "position": 4633
            }
        ]
    },
    {
        "header": "Appendix IHighlighted Fewshot Chain of Thought Annotation",
        "images": []
    },
    {
        "header": "Appendix JSome Highlight Failure Cases",
        "images": []
    },
    {
        "header": "Appendix KDatasets",
        "images": []
    },
    {
        "header": "Appendix LHighlighted Chain-of-Thought in o1-like models",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.02003/x129.png",
                "caption": "",
                "position": 6988
            },
            {
                "img": "https://arxiv.org/html/2503.02003/x130.png",
                "caption": "",
                "position": 6992
            },
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/llm_icons/logan/deepseekmain.png",
                "caption": "Table T56:Percentage of questions with<fact>tags inthinking tokens.",
                "position": 7085
            },
            {
                "img": "https://arxiv.org/html/2503.02003/extracted/6253278/figures/llm_icons/logan/deepseekmain.png",
                "caption": "Table T57:An example of HoT generated by DeepSeek-R1.",
                "position": 7107
            }
        ]
    },
    {
        "header": "Appendix MHighlight the computed results in the reasoning chain",
        "images": []
    }
]