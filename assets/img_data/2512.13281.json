[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13281/x1.png",
                "caption": "Figure 1:Illustration of Video Reality Test.An ASMR video with audio is sourced either from a real social-media creator or a video generation model (creator), and the reviewer (a video understanding model or human) must decide whether the video is real or AI-generated.",
                "position": 179
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13281/x2.png",
                "caption": "Figure 2:An overview of Peer-Review framework for ASMR video reality testing.Video generation models (“creators”) attempt to synthesize fake ASMR videos that can fool multimodal reviewers, while video-understanding models (“reviewers”) aim to detect fakes. Leaderboards on both sides highlight which creators deceive the most reviewers and which reviewers identify the most fake videos, revealing a competitive peer-review process between generation and detection.",
                "position": 409
            }
        ]
    },
    {
        "header": "3Video Reality Test",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13281/x3.png",
                "caption": "Figure 3:Illustration of Video Reality Test creation pipline, encompassing four phases:(i)Popular ASMR videos are manually collected,(ii)Preprocess the raw videos by splitting and removing backgrounds, then extract the first frame,(iii)Get the text description by Gemini-2.5-pro given the video,(iv)Clustering the videos by Qwen3-embedding-4B with maximum silhouette score, and then sampling the representative ones to alleviate class unbalance.",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x4.png",
                "caption": "Figure 4:Detailed analysis of Video Reality Test.(a)is the example of Video Reality Test across different dimensions,(b)is the statistic of the distribution of Video Reality Test on easy and hard level,(c)upper is the action statistics of Video Reality Test and the bottom is the video time distribution and comparison of easy-level and hard-level on Video Reality Test.",
                "position": 512
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13281/x5.png",
                "caption": "Table 2:Performance comparison on Video Reality Test for video understanding.Gold,silver, andbronzedenote the best, second, and third performers.\nGeneration type is ImgText2Vid consistently.",
                "position": 560
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x5.png",
                "caption": "Table 3:Performance comparison on Video Reality Test of video generation modelson different generate types. image means the start-frame image and text means the text description.",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x5.png",
                "caption": "Figure 5:Key Ablation and Analysis.(a) shows that SoTA VLMs’ performance drops after the sora watermark removal, showing that they rely on the watermark as a shortcut rather than true video quality. (b) shows that incorporating audio along with visual inputs generally improves reality detection accuracy. (c) highlights the bias of models toward classifying videos as real rather than fake, demonstrating the challenge posed by Video Reality Test in the reality test.",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x6.png",
                "caption": "Table 4:The accuracy distribution on easy-level for real/generated videos between(i) answer with thinking✔and(ii) directly answer✘; generate videos with (i) video content text(with text)and (ii) ”generate the video as real as possible”(without text).VLMs prone to predict real than fake.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x6.png",
                "caption": "Figure 6:Qualitative Results on Video Reality Test, where the top one shows that the 1st VLM Gemini-2.5-pro selected by Video Reality Test, uses the Sora2 watermark as a shortcut for reality detection, but classifies the video as real once the watermark is removed;\nthe middle one shows that incorporating audio enhances the model’s ability to detect fake videos. Gemini-2.5-Flash successfully identifies fakes when both visual and auditory cues are present but is misled when relying solely on visual information;\nand the bottom one shows that Veo3.1-fast generates high-quality videos that successfully deceive GPT-5.",
                "position": 1264
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Contents",
        "images": []
    },
    {
        "header": "6Different prompt for video reality test",
        "images": []
    },
    {
        "header": "7Prompt to get the text description of the ASMR video",
        "images": []
    },
    {
        "header": "8Visualization Examples.",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13281/x7.png",
                "caption": "Figure 7:Gemini-2.5-pro on veo3.1-fast generated videos, with and without audio. After adding the audio, the VLM detects the video to be fake.",
                "position": 1409
            },
            {
                "img": "https://arxiv.org/html/2512.13281/x8.png",
                "caption": "Figure 8:Gemini-2.5-flash on sora2 generated videos, with and without audio. After adding the audio, the VLM detects the video to be fake.",
                "position": 1412
            }
        ]
    },
    {
        "header": "9Detailed experiments",
        "images": []
    }
]