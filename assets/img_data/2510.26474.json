[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/figures/first.png",
                "caption": "Figure 1:Matthew effect in self-improvement of LVLMs over iterations and our re-balanced solution.Dark areasillustrate the imbalanced distribution in vanilla self-improvement, where dominant head and narrow tail become more severe over iterations.Light areasdepict re-balanced self-improvement–our methods for counteracting Matthew effect by reducing the head and augmenting the tail.",
                "position": 167
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3“Matthew Effect” in Self-improvement",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/x1.png",
                "caption": "((a))Performance bottlenecks.",
                "position": 321
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x1.png",
                "caption": "((a))Performance bottlenecks.",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x2.png",
                "caption": "((b))Distribution of difficulty level.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x3.png",
                "caption": "((c))Distribution of response length.",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x4.png",
                "caption": "((a))Data with different accuracy.",
                "position": 371
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x4.png",
                "caption": "((a))Data with different accuracy.",
                "position": 374
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x5.png",
                "caption": "((b))Length with differentKK.",
                "position": 379
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x6.png",
                "caption": "((c))Length with different level.",
                "position": 384
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/x7.png",
                "caption": "Figure 4:Data distribution of difficulty levels (1=easiest, 5=most difficult) in successful trajectories under different strategies with Qwen2-VL-7B-Instruct atK=16K=16.",
                "position": 842
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/x8.png",
                "caption": "Figure 5:Average performance comparison between vanilla and self-correction in visual self-improvement.",
                "position": 1016
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x9.png",
                "caption": "Figure 6:Comparison of tail data performancewithandwithoutimages on Qwen2-VL-7B-Instruct atK=8K=8.",
                "position": 1057
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/figures/prompt.png",
                "caption": "Figure 7:Prompt for training, sampling and testing.",
                "position": 1811
            }
        ]
    },
    {
        "header": "Appendix BError Type Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/figures/prompt_type.png",
                "caption": "Figure 8:Prompt for determining error type.",
                "position": 1859
            },
            {
                "img": "https://arxiv.org/html/2510.26474/figures/case_right.png",
                "caption": "Figure 9:A case misclassified as incorrect due to exact-match rules, where \\pi andπ\\piappear in different formats.",
                "position": 1982
            }
        ]
    },
    {
        "header": "Appendix CCase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/figures/case_rp.png",
                "caption": "Figure 10:An example of repeat-based padding with Qwen2-VL-7B-Instruct model on MMPR-mini test set.\nCompared to vanilla self-improvement, repeat-based padding successfully finds the relationship between∠\\angleAOC and∠\\angleABC, reaching the right answer.",
                "position": 1994
            },
            {
                "img": "https://arxiv.org/html/2510.26474/figures/case_gr.png",
                "caption": "Figure 11:An example of guided resampling with InternVL2.5-4B model on MathVerse test set. In this case, vanilla self-improvement demonstrates the confusion of heighthhwith radiusrr, while guided resampling addresses this problem successfully.",
                "position": 1999
            }
        ]
    },
    {
        "header": "Appendix DMatthew Effect Mitigation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/x10.png",
                "caption": "Figure 12:Data distribution of difficulty levels in successful trajectories under different strategies with Qwen2-VL-7B-Instruct atK=8K=8.",
                "position": 2013
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x11.png",
                "caption": "Figure 13:Data distribution of difficulty levels in successful trajectories under different strategies with InternVL2.4-4B atK=8K=8.",
                "position": 2016
            },
            {
                "img": "https://arxiv.org/html/2510.26474/x12.png",
                "caption": "Figure 14:Data distribution of difficulty levels in successful trajectories under different strategies with InternVL2.4-4B atK=16K=16.",
                "position": 2019
            }
        ]
    },
    {
        "header": "Appendix EBatch Sampling and Iterative Sampling",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26474/figures/case_sc.png",
                "caption": "Figure 15:An example of self-correction capabilities of Qwen2-VL-7B-Instruct model.",
                "position": 2078
            },
            {
                "img": "https://arxiv.org/html/2510.26474/figures/prompt_selfcorrection.png",
                "caption": "Figure 16:Prompt for self-correction.",
                "position": 2109
            },
            {
                "img": "https://arxiv.org/html/2510.26474/figures/case_sc_right.png",
                "caption": "Figure 17:An example of self-correction with InternVL2.5-4B model on MMPR-mini test set. In this case, the model of vanilla self-improvement made identification errors during tangent calculations, indicating deficient visual comprehension capabilities. In contrast, the self-correction method successfully addresses this problem and performs detailed computations to reach the correct answer.",
                "position": 2116
            }
        ]
    },
    {
        "header": "Appendix FApplying Self-correction to Self-improvement",
        "images": []
    }
]