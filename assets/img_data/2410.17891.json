[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary and Notation",
        "images": []
    },
    {
        "header": "3Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17891/x1.png",
                "caption": "Figure 1:The overview of our approach to adapt autoregressive (AR) models to diffusion models.Left: The shift operation in AR models enables the output layerhisubscript‚Ñéùëñh_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTto approximate the distribution of next tokensxi+1subscriptùë•ùëñ1x_{i+1}italic_x start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPTin hidden representations through the cross entropy (CE) loss.Middle: We remove the causal mask gradually during training eventually making our model bi-directional.Right: inside the diffusion models we shift the logits to compute the loss with the next token (i.e., the loss onhisubscript‚Ñéùëñh_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTwould be with respect toxi+1subscriptùë•ùëñ1x_{i+1}italic_x start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT), while perceptually, the diffusion models are still functioning as recovering the original signals (sincehisubscript‚Ñéùëñh_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTcorresponds toxi+1subscriptùë•ùëñ1x_{i+1}italic_x start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPTin AR loss).",
                "position": 237
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17891/x2.png",
                "caption": "Figure 2:Training loss over tokens for different scales of our adapted diffusion models.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2410.17891/x3.png",
                "caption": "Figure 3:Quality evaluation for unconditional generation, with perplexity measured by GPT2 large and distinct 2-gram diversity.",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2410.17891/x4.png",
                "caption": "Figure 4:Single batch decoding speed (seconds) for different models using flash-attention 2.",
                "position": 869
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AObjective Derivations",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.17891/x5.png",
                "caption": "Figure 5:The unconditional generation quality for different diffusion time stepsTùëáTitalic_Tand sampling algorithms. We annotate the temperature of top-kùëòkitalic_ksampling and top-p sampling.",
                "position": 2567
            },
            {
                "img": "https://arxiv.org/html/2410.17891/x6.png",
                "caption": "Figure 6:Finetune GSM8K data with discrete diffusion objectives, using a base model of either GPT2-S/M or DiffuGPT-S/M. DiffuGPT converges faster and attains a lower loss.",
                "position": 2580
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    }
]