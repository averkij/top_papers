[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": []
    },
    {
        "header": "3Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20282/x1.png",
                "caption": "Figure 1:Distribution plot of the flattened logits sampled from 20 sample data points for each of the four models: Base, EM, RL, and RL after EM.",
                "position": 529
            },
            {
                "img": "https://arxiv.org/html/2505.20282/x2.png",
                "caption": "Figure 2:The left y-axis represents the EM training loss, while the right y-axis shows the average score across four reasoning benchmarks. It can be observed that the training loss converges rapidly, whereas the average score peaks around step 10 and then begins to decline. The results in the figure are obtained by repeating the experiments with the same training hyper-parameters using 16 different seeds to reduce randomness.",
                "position": 545
            },
            {
                "img": "https://arxiv.org/html/2505.20282/x3.png",
                "caption": "Figure 3:The impact of generation temperature during EM training on the average performance of the trained model across four reasoning datasets. The results in the figure are obtained by repeating the experiments with the same training hyper-parameters using 16 different seeds to reduce randomness.",
                "position": 556
            },
            {
                "img": "https://arxiv.org/html/2505.20282/x4.png",
                "caption": "Figure 4:The impact of generation temperature during evalutating on the average performance of\nthe trained model across four reasoning datasets. The results in the figure are obtained by repeating the\nexperiments with the same training hyper-parameters using 16 different seeds to reduce randomness.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2505.20282/x5.png",
                "caption": "Figure 5:The blue curve on the left represents the average performance across four mathematical reasoning benchmarks of the model trained with RL during the EM phase as training steps progress, while the curve on the right shows the performance of the model trained with EM during the RL phase. The results in the figure are obtained by repeating the experiments with the same training hyper-parameters using 16 different seeds to reduce randomness.",
                "position": 605
            },
            {
                "img": "https://arxiv.org/html/2505.20282/x6.png",
                "caption": "Figure 6:The impact of learning rate during EM training on the average performance of the model at step 10 across four reasoning datasets. The results in the figure are obtained by repeating the experiments with the same training hyper-parameters using 16 different seeds to reduce randomness.",
                "position": 792
            }
        ]
    },
    {
        "header": "4Future Work",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]