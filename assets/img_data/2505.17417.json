[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17417/x1.png",
                "caption": "Figure 1:Overview of the training process using Speechless. In Stage 1, we train a quantizer using ASR data. In Stage 2, we train Speechless, which maps text and duration tokens to audio tokens. In Stage 3, we fine-tune an LLM using audio tokens generated by Speechless. At inference time the LLM is able to accept speech input through the Whisper Encoder, even though no speech data was used to fine-tune the LLM.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Results",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]