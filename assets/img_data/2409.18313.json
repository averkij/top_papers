[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18313/x1.png",
                "caption": "Figure 1:Overview: Our goal is for robots to navigate and communicate effectively in any environment where humans are present. We introduce Embodied-RAG, a framework for automatically building hierarchical spatial memory and providing both explanations and navigation across multiple levels of query abstraction. Embodied-RAG supports robotic operations regardless of the query‚Äôs abstraction level, the platform, or the environment.",
                "position": 83
            }
        ]
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IITask: Embodied-RAG Benchmark",
        "images": []
    },
    {
        "header": "IIIRelated Works",
        "images": []
    },
    {
        "header": "IVMethod: Embodied Retrieval and Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18313/extracted/5910947/images/Figure2_method-2.png",
                "caption": "Figure 2:Embodied-RAG method overview. (a) Memory is constructed by hierarchically organizing the nodes of the topological map into a semantic forest. (b) The memory in (a) can be retrieved for a query, with parallelized tree traversals. (c) Navigation actions with text outputs, or global explanations can be generated for the query, with using the retrieval results as LLM contexts.",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2409.18313/extracted/5910947/images/Figure4_retrieval.png",
                "caption": "Figure 3:We illustrate three retrieval methods: (a) Semantic Match, (b) Retrieval-Augmented Generation (RAG), and (c) our proposed method, Embodied-RAG. Semantic Match retrieves the node in the topological map with the highest cosine similarity with the query, while RAG outputs topkùëòkitalic_knodes. In contrast, Embodied-RAG retrieves the bestkùëòkitalic_kchainsof the semantic forest.",
                "position": 391
            }
        ]
    },
    {
        "header": "VExperiments",
        "images": []
    },
    {
        "header": "VIResults",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.18313/x2.png",
                "caption": "Figure 4:Example reasoning of Embodied-RAG and RAG for generation tasks are highlighted in blue and pink boxes, respectively.",
                "position": 514
            },
            {
                "img": "https://arxiv.org/html/2409.18313/extracted/5910947/images/ablation_k.png",
                "caption": "Figure 5:Effect of total number ofKùêæKitalic_Ksearches orKùêæKitalic_Kretrievals",
                "position": 537
            }
        ]
    },
    {
        "header": "VIILimitations and Future work",
        "images": []
    },
    {
        "header": "VIIIConclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]