[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10687/x1.png",
                "caption": "Figure 1:Left:Stable Part Diffusion 4D (SP4D)takes a monocular input video and generates novel-view RGB videos (bottom-left) as well as consistent part segmentation videos across all views.Right:SPD also supports single image input and synthesizes multi-view RGB images and corresponding part decompositions. These results can be lifted to 3D to produce riggable meshes with part-aware geometry and articulated structure.",
                "position": 92
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10687/x2.png",
                "caption": "Figure 2:Limitations of traditional 2D and 3D part decomposition methods.Left: Appearance-based 2D segmentation methods like SAM2 fail to produce kinematic parts.\nMiddle: SOTA 3D rigging methods(Song et al.,2025)lack the capability to infer kinematic part structures from appearance and generalize poorly to diverse shapes.\nRight: Existing 3D part segmentation models(Tang et al.,2024a;Yang et al.,2024)focus on semantic regions and are not suited for kinematic decomposition.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Related Work.",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10687/x3.png",
                "caption": "Figure 3:Stable Part Diffusion 4D model architecture.Our model builds upon SV4D 2.0 and extends it with a parallel part segmentation branch and a BiDiFuse module that enables bidirectional feature exchange between RGB and part branches. The network jointly generates multi-view videos for appearance and kinematics-aware part segmentation. Key components include: (1) spatial color encoding for part masks, enabling shared VAE encoder/decoder; (2) BiDiFuse for cross-branch consistency; and (3) a contrastive loss for spatial-temporal part alignment. We use a two-stage training strategy: first, training the RGB branch on ObjaverseDy, then fine-tuning the full model with BiDiFuse on KinematicParts20K with supervision on both branches.",
                "position": 217
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10687/x4.png",
                "caption": "Figure 4:Multi-view kinematic part video results on synthetic and real-world videos.We show qualitative results of our SP4D model on both the validation set of KinematicParts20K and real-world DAVIS videos. Each group presents two time frames across two novel views. The input video frame is noted withpurpleboxes. SP4D produces temporally and spatially consistent part decompositions across diverse object categories and motions.",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2509.10687/x5.png",
                "caption": "Figure 5:Visual comparison of part segmentation.We show results across three views for various articulated objects. The rows contain input RGB image (top), our SP4D-generated part segmentation (middle), and the SAM2 baseline (bottom). Compared to SAM2, SP4D produces more structured part decompositions that align with object articulation and are consistent across views.",
                "position": 489
            }
        ]
    },
    {
        "header": "5Broader Societal Impact",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BKinematicParts20K Dataset",
        "images": []
    },
    {
        "header": "Appendix CMore Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.10687/x6.png",
                "caption": "Figure 6:User study interface for evaluating multi-view kinematic part segmentation.Participants are presented with video results generated by different methods and asked to rank them based on part consistency, structural correctness, and motion coherence. The study compares SP4D with baseline methods to assess perceptual quality and kinematic alignment.",
                "position": 1629
            }
        ]
    },
    {
        "header": "Appendix DEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix EAdditional Discussion",
        "images": []
    }
]