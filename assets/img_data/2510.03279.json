[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1 Introduction",
        "images": []
    },
    {
        "header": "2 Related Work",
        "images": []
    },
    {
        "header": "3 Investigation of Memory Patterns",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.03279/x1.png",
                "caption": "Figure 1:Overall workflow of MemMamba. The framework is composed ofnnstacked MemMamba Block Layers, where each layer preserves critical context via the Note Block and enables long-range interaction through sparse cross-layer attention.",
                "position": 297
            },
            {
                "img": "https://arxiv.org/html/2510.03279/x2.png",
                "caption": "Figure 2:Workflow of a MemMamba Block Layer. Each block integrates three components: state space model (SSM) updates, cross-token attention, and periodically triggered cross-layer attention.",
                "position": 300
            }
        ]
    },
    {
        "header": "4 Method",
        "images": []
    },
    {
        "header": "5 Experimental Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.03279/x3.png",
                "caption": "Figure 3:Ablation results of the core mechanisms. The same hardware conditions and training configurations are used.",
                "position": 1008
            },
            {
                "img": "https://arxiv.org/html/2510.03279/x4.png",
                "caption": "Figure 4:Comparison of ETMF and ECLMF across different Mamba variants",
                "position": 1027
            }
        ]
    },
    {
        "header": "6 Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.03279/x5.png",
                "caption": "Figure 5:Comparison of perplexity (PPL) across models at different context lengths.",
                "position": 1736
            },
            {
                "img": "https://arxiv.org/html/2510.03279/x6.png",
                "caption": "Figure 6:Effect of different pooling functions on modeling quality.",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2510.03279/x7.png",
                "caption": "Figure 7:Impact of state-pool size and window size on PPL.",
                "position": 1883
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]