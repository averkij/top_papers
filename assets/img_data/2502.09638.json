[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09638/x1.png",
                "caption": "Figure 1:Left: An overview of our work: we propose to first jailbreak capable LLMs (i.e. Step 1) to help us jailbreak other LLMs for specific harmful behaviors (i.e. Step 2) ‚Äì namely this is a jailbreaking-to-jailbreak (J2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) process. Step 1 is done by human red teamers, and Step 2 is fully automated.Right: Our results showsJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTis more effective than leading automated attacks directly applied on GPT-4o (e.g. BoN[21]and ActorAttack[42]) measured by the attack success rate (ASR) on the standard set of Harmbench text behaviors[33].",
                "position": 201
            },
            {
                "img": "https://arxiv.org/html/2502.09638/x2.png",
                "caption": "Figure 2:An example attack log between the LLM red teamer (i.e.J2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT(Sonnet-3.5)) and the target LLM (i.e. GPT-4o). We provide the complete conversation in AppendixD.",
                "position": 220
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09638/x3.png",
                "caption": "Figure 3:An overview of our red teaming workflow. We first createJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTattackers. Second,J2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTjailbreaks the target LLM in multi-turn conversations with hard-coded prompts to do planning and debriefing. We iterate over different red teaming strategies until a successful jailbreak is founded or we exhaust our strategy set.",
                "position": 264
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09638/x4.png",
                "caption": "(a)ASRs of different backbone LLMs ofJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTwhen scaling the number cycles (N).",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2502.09638/x4.png",
                "caption": "(a)ASRs of different backbone LLMs ofJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTwhen scaling the number cycles (N).",
                "position": 440
            },
            {
                "img": "https://arxiv.org/html/2502.09638/x5.png",
                "caption": "(b)ASRs forJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT(Gemini) andJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT(Sonnet-3.5) when instructed to conduct a T-turn attack against GPT-4o.",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2502.09638/x6.png",
                "caption": "Figure 5:Comparing Human, LLM Red Teamer (J2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) and Algorithm-based automated methods on Harmbench for GPT-4o and RR.",
                "position": 628
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Details in Red Teaming Strategies",
        "images": []
    },
    {
        "header": "Appendix BMore Context on Our Red Teaming Workflow",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.09638/x7.png",
                "caption": "Figure 6:We measure the refusal rates of different LLMs for the request to conduct red teaming after applying different red teaming guidance (i.e.XhumansubscriptùëãhumanX_{\\text{human}}italic_X start_POSTSUBSCRIPT human end_POSTSUBSCRIPTto jailbreak their safeguard. We find the length of user inputs inXhumansubscriptùëãhumanX_{\\text{human}}italic_X start_POSTSUBSCRIPT human end_POSTSUBSCRIPTas the most correlated factor that influences this refusal rate. Results for each model are aggregated over 40 Harmbench behaviors with different levels of harmfulness.",
                "position": 1917
            },
            {
                "img": "https://arxiv.org/html/2502.09638/x8.png",
                "caption": "Figure 7:The number discovered successful jailbreaks when scaling the set of strategies. Results are aggregated from Haiku-3.5, Sonnet-3.5, Gemini-1.5-pro and GPT-4o asJ2subscriptùêΩ2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTagainst GPt-4o for the first 50 behaviors in the standard text set of Harmbench.",
                "position": 2000
            }
        ]
    },
    {
        "header": "Appendix CJudge Prompts",
        "images": []
    },
    {
        "header": "Appendix DJailbreak Examples",
        "images": []
    }
]