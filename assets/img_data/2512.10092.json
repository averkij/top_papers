[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x1.png",
                "caption": "Figure 1:Converting text documents into interpretable embeddings with sparse autoencoders.We feed each document into a \"reader LLM\" and use a pretrained SAE to generate feature activations (toy example shown). Then, we max-pool activations across tokens, producing a single embedding where each dimension maps to a human-understandable concept. The interpretable nature of this embedding allows us to perform a diverse range of downstream data analysis tasks.",
                "position": 160
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x2.png",
                "caption": "Figure 2:Average difference of judge-verified frequencies for generated hypotheses.SAEs find bigger differences than the LLM baseline.",
                "position": 440
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x2.png",
                "caption": "Figure 2:Average difference of judge-verified frequencies for generated hypotheses.SAEs find bigger differences than the LLM baseline.",
                "position": 443
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x3.png",
                "caption": "Figure 3:SAEs recover synthetic correlations while LLMs do so unreliably.[Left]For all SAE latent pairs, we plot their NPMI with semantic similarity between latent descriptions. Among pairs with high NPMI but low semantic similarity (proxy for “interesting” correlations), we successfully recover pairs relevant to the synthetic correlations, shown in color.[Right]We reshuffle our Pile dataset ten times but find that LLMs discover the synthetic correlations inconsistently.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x4.png",
                "caption": "Figure 4:SAEs discover more truly correlated pairs compared to baselines.[Left]Distribution of verified NPMIs of discovered latent pairs across all methods.[Right]Hypotheses from SAE pairs. Hypothesized concepts can be broader than latents, and most hypotheses are verified as true. Some are not discovered by the LLM.",
                "position": 510
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x5.png",
                "caption": "Figure 5:SAE embeddings discover novel clusters.On GSM8k answers, dense embeddings[left]and instruction-tuned embeddings[middle]tend to cluster by math problem content. Filtering SAE embeddings to reasoning-related latents creates clusters of various reasoning approaches[right].",
                "position": 550
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x6.png",
                "caption": "Figure 6:MAP averaged over queries, for each method and dataset. Query expansion uses 1–20 phrases; temperature varies from 0.01–1.5.",
                "position": 567
            }
        ]
    },
    {
        "header": "5Case Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x7.png",
                "caption": "Figure 7:Emerging characteristics over new generations of OpenAI models. All frequencies shown are judge-verified. Full labels inAppendix˜H.[Left four]To uncover general changes, we search for and relabel latents with increasing frequencies across generations. We find emerging trends ranging from behavioral to syntactic.[Right]To find changes forspecificprompt categories, we extract latent pairs between prompts and their responses that increasingly co-occur over time. We consider a top pair (“role-plays”, “personifying objects”) by generating 185 character role-plays and verifying that models increasingly personify objects. We provide a qualitative example on the right.",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x8.png",
                "caption": "Figure 8:Identification and investigation of spurious correlation in Tulu-3’s SFT dataset.Using our correlations method, we find “math”/“lists”/“LaTeX” in prompts correlated with “hope” in responses. Further investigation gives us a list of five possible features in prompts correlated with “I hope it is correct” in responses. Has the model learned to say this, and under what kinds of prompts?",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x9.png",
                "caption": "Figure 9:Triggering the response “I hope it is correct” in Tulu-3.Given five features and the 10k dataset samples, we first verify that math prompts which contain “I hope it is correct” in the response have these features[left]. Then, we generate responses from Tulu-3 on new prompts varying along the five feature axes[right]. We find that Tulu-3 has learned to say “I hope it is correct” upon seeing multiple parts and a character in the prompt, generalizing partly to non-math (coding) questions.",
                "position": 618
            }
        ]
    },
    {
        "header": "6Limitations & Conclusion",
        "images": []
    },
    {
        "header": "7Acknowledgements",
        "images": []
    },
    {
        "header": "Appendix AMethods",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x10.png",
                "caption": "Figure 10:Detailed methodology for each of the four tasks.",
                "position": 643
            }
        ]
    },
    {
        "header": "Appendix BAdditional Related Work",
        "images": []
    },
    {
        "header": "Appendix CLatent labeling prompts",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results—Dataset Diffing",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x11.png",
                "caption": "Figure 11:Verification rates of generated hypotheses for diffing. We find that SAEs generate valid hypotheses more often than our LLM baselines when comparing multiple models (left three) and similarly otherwise (right three).",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x12.png",
                "caption": "Figure 12:Coverage of generated hypotheses overall. We compute the % of responses that have at least one hypothesis with the \"target\" dataset uniquely verified. The generated hypotheses for SAEs have greater coverage of the unique qualities of target datasets over pure LLMs on multi-model setups (left three). SAEs have similar or slightly worse coverage for two-model cases (right three).",
                "position": 1746
            }
        ]
    },
    {
        "header": "Appendix EAdditional Results—Correlations",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x13.png",
                "caption": "Figure 13:Histogram of correlation metric (left: NPMI, right: CO) and semantic similarity of latent pairs. We choose NPMI as our metric.",
                "position": 3020
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x13.png",
                "caption": "",
                "position": 3023
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x14.png",
                "caption": "",
                "position": 3027
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/croatian-emoticons_50.png",
                "caption": "Figure 14:(a)-(d) We plot the discovered group of pairs (NPMI>0.8>0.8, semantic similarity<0.2<0.2) for each type of text injected, with 0.5% of texts being injected texts. Relevant pairs are colored. (e) We show the proportion of relevant pairs in the candidate group for different injection levels 0.1%-1%. (f) We inject all 3 texts at once.",
                "position": 3040
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/croatian-emoticons_50.png",
                "caption": "",
                "position": 3043
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/baseball-slang_50.png",
                "caption": "",
                "position": 3047
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/conservative-academic_style_50.png",
                "caption": "",
                "position": 3051
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/conservative-academic_slant_50.png",
                "caption": "",
                "position": 3055
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/all_injection_types_percentage.png",
                "caption": "",
                "position": 3059
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/corr/multi_injections_50_each.png",
                "caption": "",
                "position": 3063
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x15.png",
                "caption": "Figure 15:CDF of conditional occurrence for pairs discovered by every method, for CivilComments (left) and the Pile (right).",
                "position": 3482
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x15.png",
                "caption": "",
                "position": 3485
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x16.png",
                "caption": "",
                "position": 3489
            }
        ]
    },
    {
        "header": "Appendix FAdditional Results—Clustering",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x17.png",
                "caption": "Figure 16:Dense embedding (top row), instruction-tuned embedding (middle row) and SAE embedding (bottom row) clustering results: (1) topic (2) sentiment (3) temporal framing and (4) writing style. Mappings from clusters to true labels are chosen with the Hungarian algorithm[hungarian].",
                "position": 7189
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x18.png",
                "caption": "Figure 17:Normal clustering with dense embeddings[left]and the full SAE embedding[right]. The SAE embedding clusters along how the description is written, with generally good cluster accuracy.",
                "position": 7202
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x19.png",
                "caption": "Figure 18:Targeted clustering with instruction-tuned embeddings[left]and the reduced SAE embedding[right]. The SAE embedding finds clusters of character descriptions.",
                "position": 7205
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x20.png",
                "caption": "Figure 19:Per-cluster accuracies for differentnclustersn_{\\text{clusters}}for prompts, responses and the Pile. The solid lines are the median, dashed lines the interquartile range and dotted lines the range.",
                "position": 7218
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x20.png",
                "caption": "",
                "position": 7221
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x21.png",
                "caption": "",
                "position": 7225
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x22.png",
                "caption": "",
                "position": 7229
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x23.png",
                "caption": "Figure 20:Twitter sentiment[tweetsentiment]clustering results.",
                "position": 7460
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x24.png",
                "caption": "Figure 21:Twitter emotion[tweetemotion]clustering results.",
                "position": 7463
            }
        ]
    },
    {
        "header": "Appendix GAdditional Results—Retrieval",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x25.png",
                "caption": "Figure 22:MP@50 averaged over queries for each method and dataset. Query expansion uses 1–20 phrases; temperature varies from 0.01 to 1.5.",
                "position": 8027
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x26.png",
                "caption": "Figure 23:Performance of BM25+LLM with different number of phrases generated and aggregated.",
                "position": 8033
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x27.png",
                "caption": "Figure 24:Performance of OpenAI+LLM with different number of phrases generated and aggregated.",
                "position": 8036
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x28.png",
                "caption": "Figure 25:Performance of Gemini+LLM with different number of phrases generated and aggregated.",
                "position": 8039
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x29.png",
                "caption": "Figure 26:Performance of SAE method at differentTTused to aggregate features, for each dataset.",
                "position": 8042
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_prompts.png",
                "caption": "Figure 27:Ranking similarity among the relevant documents, using Rank-Biased Overlap (RBO)[rbo]with hyperparameterp=0.98p=0.98since we are concerned about the top 50 results.",
                "position": 9110
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_prompts.png",
                "caption": "",
                "position": 9113
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_responses.png",
                "caption": "",
                "position": 9117
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_mot.png",
                "caption": "",
                "position": 9121
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_pile10k.png",
                "caption": "",
                "position": 9126
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_arxiv.png",
                "caption": "",
                "position": 9130
            },
            {
                "img": "https://arxiv.org/html/2512.10092/figs/ret/rbo_story.png",
                "caption": "",
                "position": 9134
            }
        ]
    },
    {
        "header": "Appendix HExtended Findings from OpenAI Case Study",
        "images": []
    },
    {
        "header": "Appendix IAblations on Reader Model Size",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x30.png",
                "caption": "Figure 28:F1 scores after relabeling SAE latentsper dataset.",
                "position": 9245
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x30.png",
                "caption": "Figure 28:F1 scores after relabeling SAE latentsper dataset.",
                "position": 9248
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x31.png",
                "caption": "Figure 29:F1 scores using fixed SAE latent labels(based on LMSYS-1M).",
                "position": 9253
            }
        ]
    },
    {
        "header": "Appendix JProperties of SAE Latents",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.10092/x32.png",
                "caption": "Figure 30:Left: Empirical CDF of normalized average precision of the classifier for latents in each log-frequency range. Right: Automatic interpretability score summary.",
                "position": 9270
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x32.png",
                "caption": "",
                "position": 9273
            },
            {
                "img": "https://arxiv.org/html/2512.10092/x33.png",
                "caption": "",
                "position": 9277
            }
        ]
    },
    {
        "header": "Appendix KLLM Judge Details",
        "images": []
    },
    {
        "header": "Appendix LDataset Generation Details",
        "images": []
    },
    {
        "header": "Appendix MLLM usage policy",
        "images": []
    }
]