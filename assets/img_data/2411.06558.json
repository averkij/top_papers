[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06558/x1.png",
                "caption": "",
                "position": 100
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06558/x2.png",
                "caption": "Figure 2:The overall framework of RAG, which divides regional-aware generation into two stages: (1)Regional Hard Bindingensures the proper response of regional prompts by processing each region individually with its fundamental description, and bound at the firstrùëüritalic_rsteps to ensure accurate attribute representation and entity localization.\n(2)Regional Soft Refinementimproves the harmony of adjacent region via enabling the interaction of regional local conditions with global image latent within the cross-attention layers at the laterT‚àírùëáùëüT-ritalic_T - italic_rsteps. The lower left corner shows an example of spatial region set for regional hard binding and regional soft refinement.",
                "position": 144
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06558/x3.png",
                "caption": "Figure 3:Illustration of Re-painting. Different from regular image-to-image inpainting, repainting inherits from last generation with only the target area re-initialized (upper). Given the parameters in previous generation, users are allowed to specify a target area with a new prompt and repaint the image, without relying on addtional inpainting models (bottom).",
                "position": 391
            },
            {
                "img": "https://arxiv.org/html/2411.06558/x4.png",
                "caption": "Figure 4:Qualitative comparisons on compositional text-to-image generation. From top to bottom, we show 5 examples of different prompts and regions. Compared with previous methods, we demonstrate excellent regional control capabilities.",
                "position": 488
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.06558/x5.png",
                "caption": "Figure 5:Qualitative comparisons on image repaintingbetween our RAG and the state-of-the-art inpainting model BrushNet. Our results are more region-aware with harmonious effect with the surrounding, revealing diverse potential for applications.",
                "position": 513
            },
            {
                "img": "https://arxiv.org/html/2411.06558/x6.png",
                "caption": "Figure 6:Qualitative analysis of Hard Binding and Soft Refinement. The former ensures the proper responses of each region, while the latter enhances the coherence among regions.",
                "position": 581
            },
            {
                "img": "https://arxiv.org/html/2411.06558/x7.png",
                "caption": "Figure 7:Qualitative analysis of hard binding stepsrùëüritalic_rand base strengthŒ¥ùõø\\deltaitalic_Œ¥. A few steps of binding is sufficient for regional completeness, and the regional coherence improves gradually when increasing base strength.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2411.06558/x8.png",
                "caption": "Figure 8:Comparison of inference time and visual comparison between the original RAG and RAG with acceleration.",
                "position": 587
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]