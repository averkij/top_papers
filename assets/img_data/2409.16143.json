[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/coffe_face_crop.jpeg",
                "caption": "Figure 1:You print out an exciting new computer vision paper to review, but as you sit down at your desk to start reading you knock over your coffee cup. At first, you are annoyed, but then, you laugh! The sight of the stain induces “pareidolia” in your brain: rather than an unsightly blemish, you see a happy face. In this paper we explore the phenomenon of face pareidolia: Why don’t we see faces all the time? Why do we see them at all when they are clearly so different from human faces? Can a better understanding of face pareidolia help computer vision–based face detection?",
                "position": 121
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/dataset_summary.jpg",
                "caption": "Figure 2:Examples of face pareidolia from our “Faces in Things” dataset.Faces in Things consists of five thousand images annotated with bounding boxes (shown here), and facial attributes such as perceived emotion, gender, and intentionality.",
                "position": 183
            }
        ]
    },
    {
        "header": "3Faces in Things Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/x1.png",
                "caption": "Figure 3:Attributes of the Faces in Things Dataset.We find that 31% of faces are considered challenging to spot; faces are largely (31%) judged as happy; approximately half (47%) are judged as accidental rather than by design; animals and humans are seen in roughly equal numbers; and we observe a slight bias (16% vs 3%) towards male over female faces, similar to biases observed in prior studies[57,56].",
                "position": 206
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/all_image_panel_half.jpg",
                "caption": "Figure 4:The Appearance of an Average Pareidolic Face.Per-channel histogram-equalized average images for registered pareidolic faces (our Faces in Things dataset), human faces (samples from the WIDER FACE dataset[62]), and animal faces (AnimalWeb[24]). The average pareidolic face, while less distinct than human or animal, has surprisingly clear eye, nose, and mouth features, and vertical symmetry.",
                "position": 223
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/fine_tuned_preds.png",
                "caption": "Figure 5:Qualitative Analysis of Transfer Experiments.On a sample of held-out test images, we visualize the confident(p>10%)𝑝percent10(p>10\\%)( italic_p > 10 % )detections of ourground truth (red), our modelfine-tuned on human faces (blue), and our modelfine-tuned on animal faces (green). It is evident from these and Table1that fine-tuning on animal faces significantly boosts the model’s ability to detect pareidolic faces.",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/transfer_learning_double_fig_2.png",
                "caption": "Figure 6:Measuring the effect of several training interventions on pareidolic face detectionThe left plot shows that fine-tuning RetinaNet on animals improves pareidolic face detection more than any other intervention. Conversely, the right plot shows that pareidolic fine-tuning improves animal face detection performance.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/feature_tsne.png",
                "caption": "Figure 7:Visualizing RetinaNet Representations across Datasets.Animal+Pareidolia fine-tuned RetinaNet representations tend to group animal and pareidolic faces together. This lends evidence to the hypothesis that the perception of animal and pareidolic faces are linked. (To highlight the commonality of pareidolic animal detection we note the similarity of these points to a frog.)",
                "position": 315
            }
        ]
    },
    {
        "header": "5Modeling Pareidolia",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/GaussianModelPanel2.png",
                "caption": "Figure 8:Illustration of the proposed Gaussian model for pareidolia with three example generating distributions. To make pareidolia likely, the generating distribution needs a proper distribution of spatial frequencies. A process with too few spatial frequencies (left) is likely to only generate weak face-like details (“face-ness”: low). In contrast, with too many frequencies (right), faces can be modeled with exquisite detail (“face-ness”: high), but the likelihood of drawing any particular desired combination become vanishingly small. The most likely pareidolic images form when the generating distribution has the right spectrum (middle), enabling reasonable faces to emerge with reasonable likelihood. In other words, this model predicts that pareidolic faces will match the low frequencies of faces but differ in the higher frequency details.",
                "position": 388
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/gaussian_model_prob.jpg",
                "caption": "Figure 9:Probability of pareidolia (Eq.6) in the Gaussian model (σ=10𝜎10\\sigma=10italic_σ = 10) across images with different spatial frequency distributions (Sec.5.4). This assumes spatial frequencies are uncorrelated and thus underestimates the probability of pareidolia, however peak pareidolia is still present.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/gaussian_model_prob.jpg",
                "caption": "Figure 9:Probability of pareidolia (Eq.6) in the Gaussian model (σ=10𝜎10\\sigma=10italic_σ = 10) across images with different spatial frequency distributions (Sec.5.4). This assumes spatial frequencies are uncorrelated and thus underestimates the probability of pareidolia, however peak pareidolia is still present.",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/feature_detection.png",
                "caption": "Figure 10:Probability of pareidolia under the feature-based example of Eq. (8) as a function of the rate of feature detection,λi=λsubscript𝜆𝑖𝜆\\lambda_{i}=\\lambdaitalic_λ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_λfor alli𝑖iitalic_i, within the random images. Note the low probability of pareidolia for both feature-free (λ→0→𝜆0\\lambda\\rightarrow 0italic_λ → 0) and feature-rich (λ≫0much-greater-than𝜆0\\lambda\\gg 0italic_λ ≫ 0) random images.",
                "position": 422
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/paired_psychophysics.png",
                "caption": "Figure 11:Measuring Peak Pareidolia.Left: Subjects were asked how many faces they see in each noise image. We plot the average number of faces detected as a function of noise frequency (examples on x-axis), the mean over all subjects and its 95% confidence interval in red. Right: average number of faces detected by our fine-tuned models. This reveals the “peak pareidolia” effect predicted in Section5across humans and machines.",
                "position": 470
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/noise_levels.jpg",
                "caption": "Figure 12:Different frequency noise levels used in human experiments from Fig.11.",
                "position": 973
            },
            {
                "img": "https://arxiv.org/html/2409.16143/x2.png",
                "caption": "Figure 13:Left: Pareidolia reported for two subject groups with different random seed images shows no significant difference between groups. Right: Response time (RT) mirrors number of faces for small to medium filter widths, but does not fall off as sharply. Plots report±1plus-or-minus1\\pm 1± 1standard deviation.",
                "position": 1031
            },
            {
                "img": "https://arxiv.org/html/2409.16143/x3.png",
                "caption": "Figure 14:Left: Pareidolia by subject. Right: Female and Male subjects both demonstrate peak pareidolia, and do not show significant differences. Plot reports±1plus-or-minus1\\pm 1± 1standard deviation.",
                "position": 1034
            },
            {
                "img": "https://arxiv.org/html/2409.16143/x4.png",
                "caption": "Figure 15:Left: Human Contrast Sensitivity Function for 1024x1024 image shown at full screen height Field of View (full FOV, blue), and at half size (half FOV, orange). Right: Peak pareidola measured in humans for stimuli viewed at full and half FOV. Full Screen data for 14 subjects, Half screen data for two subjects. Plot reports±1plus-or-minus1\\pm 1± 1standard deviation.",
                "position": 1040
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/all_image_panel.jpg",
                "caption": "Figure 16:The Appearance of an Average Pareidolic Face.Shown here are the (a) raw average and (b) per-channel histogram-equalized average images for registered pareidolic faces (our Faces in Things dataset), human faces (samples from the WIDER FACE dataset[62]), and animal faces (AnimalWeb[24]). The average pareidolic face, while less distinct than human or animal, has surprisingly clear eye, nose, and mouth features, and vertical symmetry.",
                "position": 1133
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/faces_by_condition.jpg",
                "caption": "Figure 17:Average faces from the Faces in Things dataset that fit certain label criteria.",
                "position": 1144
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/fit_gaussian_model.png",
                "caption": "Figure 18:Fitting our Gaussian model (green) to human data. The Viola-Jones face detector also shows peak pareidolia (purple).",
                "position": 1159
            },
            {
                "img": "https://arxiv.org/html/2409.16143/extracted/5874652/figs/confusion_mat.png",
                "caption": "Figure 19:Simultaneous face detection and classification. Block structure shows similarity between animal and pareidolic faces.",
                "position": 1177
            }
        ]
    },
    {
        "header": "Appendix 0.AAppendix",
        "images": []
    }
]