[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07641/x1.png",
                "caption": "Figure 1:Paradigm comparison: Static Tool Paradigm (left) vs Test-Time Tool Evolution (right). Static approaches require pre-collected tool libraries, limiting coverage and domain adaptability. Our test-time evolution starts with an empty library and generates tools on-demand during problem-solving, enabling continuous evolution to new domains and problems.",
                "position": 284
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07641/x2.png",
                "caption": "Figure 2:The architecture of the Test-Time Tool Evolution (TTE) framework. The system operates through a closed-loop workflow comprising five integrated stages. (1) Structured Task Decomposition: The Problem Analyzer decomposes complex scientific queries into a sequence of executable sub-goals. (2) Dynamic Tool Retrieval: The system queries the Dynamic Tool Registry for existing atomic tools. If retrieval fails, it triggers (3) Generative Tool Synthesis: The Tool Synthesizer creates candidate tools on-the-fly, which undergo strict verification by the Tool Verifier. (4) Atomic Tool Refinement: Validated tools are decoupled into reusable atomic units by the Atomic Decomposer, filtered by the Redundancy Checker, and registered to update the library. (5) Runtime Execution Engine: Once the required tools are successfully retrieved or generated for all the steps, the Tool Executor executes the sequence to synthesize the final answer.",
                "position": 353
            }
        ]
    },
    {
        "header": "3Test-Time Tool Evolution",
        "images": []
    },
    {
        "header": "4The SciEvo Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07641/x3.png",
                "caption": "Figure 3:Tool distribution of the curated SciEvo benchmark. SciEvo covers 25 sub-disciplines across four major scientific fields: Physics (499 tools), Chemistry (192), Mathematics (171), and Materials (63), demonstrating comprehensive coverage of diverse scientific computational needs.",
                "position": 531
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07641/x4.png",
                "caption": "Figure 4:Accuracy comparison on SciEvo. We compare the “No Tool call” baseline against our TTE-Zero method using direct queries (“Q + Tools”) and Sub-goal Decomposition (“S + Tools”).",
                "position": 1124
            }
        ]
    },
    {
        "header": "6Results and Analysis",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Limitations",
        "images": []
    },
    {
        "header": "9Ethical Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComplete Algorithmic Workflow",
        "images": []
    },
    {
        "header": "Appendix BPrompts for Each Agent Module",
        "images": []
    },
    {
        "header": "Appendix CSubject-wise Results on SciEvo",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.07641/x5.png",
                "caption": "Figure 8:Histogram of tool usage frequency (Hit-count) across three benchmarks. The x-axis represents the reuse frequency of tools, and the y-axis denotes the number of tools.",
                "position": 1897
            },
            {
                "img": "https://arxiv.org/html/2601.07641/x6.png",
                "caption": "Figure 9:Kernel Density Estimation (KDE) of tool utilization rates. The distribution curves visualize the distributional shift in tool reusability.",
                "position": 1900
            }
        ]
    },
    {
        "header": "Appendix DAnalysis of Tool Reusability",
        "images": []
    },
    {
        "header": "Appendix EExplanation of Evaluation Metrics",
        "images": []
    },
    {
        "header": "Appendix FThe Tool Overload Phenomenon",
        "images": []
    },
    {
        "header": "Appendix GCase Studies",
        "images": []
    },
    {
        "header": "Appendix HDataset Comparison and Uniqueness",
        "images": []
    },
    {
        "header": "Appendix ITheoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix JFuture Directions and Broader Impact",
        "images": []
    }
]