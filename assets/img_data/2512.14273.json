[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14273/x1.png",
                "caption": "Figure 1:OurZoom-Zerofirst rolls out samples to localize relevant segments with preliminary answers in the coarse-grained pass, then zooms into spotlight segments with higher-resolution video tokens in the fine pass. For example, the coarse pass may miss the small visual cue “29%”, but the zoom-in captures the fine-grained details. This fine-grained visual verification (zoom-in accuracy reward) ensures that the temporally grounded segments truly provide key visual evidence.",
                "position": 91
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": []
    },
    {
        "header": "4Zoom-Zero",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14273/x2.png",
                "caption": "Figure 2:We presentZoom-Zero, a coarse-to-fine training pipeline that first rolls out samples to localize relevant segments with preliminary answers, followed by a fine-grained pass by zooming into spotlight segments and dynamically allocating high-resolution video tokens. The zoom reward enforces fine-grained visual verification of the predicted temporal span. In this example, only a faithful span prediction with the correct final answer yields the highest reward. Then we propose token-selective credit assignment (TokenAdv) for a finer-grained advantage estimation.",
                "position": 180
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ATraining Data",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CLimitation of GRPO in Uniform Credit Assignment",
        "images": []
    },
    {
        "header": "Appendix DExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.14273/x3.png",
                "caption": "Figure 3:Temporal grounding robustness analysis on NExT-GQA.Left: mIoU results across different ground-truth clue durations. Right: mIoU results across different clue proportions (ground-truth clue duration relative to the total video duration).",
                "position": 1146
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x4.png",
                "caption": "Figure 4:Training curve: IoU rewardRI​o​UR_{IoU}and answer rewardRAccR_{\\mathrm{Acc}}comparison with baseline GRPO and our improved GRPO with TokenAdv.",
                "position": 1249
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x5.png",
                "caption": "Figure 5:A qualitative example for long video understanding.",
                "position": 1252
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x6.png",
                "caption": "Figure 6:A qualitative example for long video understanding.",
                "position": 1255
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x7.png",
                "caption": "Figure 7:A qualitative example for long video understanding.",
                "position": 1258
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x8.png",
                "caption": "Figure 8:A qualitative example for long video understanding.",
                "position": 1261
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x9.png",
                "caption": "Figure 9:A qualitative example for grounded videoQA with temporal zoom-in.",
                "position": 1264
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x10.png",
                "caption": "Figure 10:A qualitative example for long video understanding with coarse-to-fine zoom-in.",
                "position": 1267
            },
            {
                "img": "https://arxiv.org/html/2512.14273/x11.png",
                "caption": "Figure 11:A qualitative example for long video understanding with coarse-to-fine zoom-in.",
                "position": 1270
            }
        ]
    },
    {
        "header": "Appendix ELimitation and Future Direction",
        "images": []
    }
]