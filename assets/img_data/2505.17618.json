[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17618/extracted/6468488/logo_new.png",
                "caption": "",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x1.png",
                "caption": "Figure 1:We proposeEvolutionarySearch(EvoSearch), a novel and generalist test-time scaling framework applicable to both image and video generation tasks. EvoSearch significantly enhances sample quality through strategic computation allocation during inference,enabling Stable Diffusion 2.1 to exceed GPT4o, and Wan 1.3B to outperform Wan 14B model and Hunyuan 13B model with10√ó10\\times10 √ófewer parameters.",
                "position": 149
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Related Work",
        "images": []
    },
    {
        "header": "4Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17618/x2.png",
                "caption": "Figure 2:Visualization of a test-time alignment experiment. We train a diffusion model with3333-layer MLP on Gaussian mixtures (pre-trained distribution), with the goal to capture multimodal unseen target distribution, where rewardr‚Å¢(X,Y)=‚àí|X2+Y2‚àí4|ùëüùëãùëåsuperscriptùëã2superscriptùëå24r(X,Y)=-|X^{2}+Y^{2}-4|italic_r ( italic_X , italic_Y ) = - | italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_Y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 |. EvoSearch achieves superior performance, capturing all the modes with the highest reward (-0.74).",
                "position": 276
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x3.png",
                "caption": "Figure 3:Overview of our method. EvoSearch progressively moves forward along the denoising trajectory to refine and explore new states.",
                "position": 300
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x4.png",
                "caption": "Figure 4:t-SNE Visualization of latentùíôtsubscriptùíôùë°\\bm{x}_{t}bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTfrom SD2.1 model at different steps, colored by their corresponding ImageReward scores. At denoising step 0,ùíôtsubscriptùíôùë°\\bm{x}_{t}bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTis Gaussian noises.Top row: Results from Stable Diffusion 2.1 model.Bottom row: Results from Flux.1-dev.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x5.png",
                "caption": "",
                "position": 356
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17618/x6.png",
                "caption": "Figure 6:VideoRewards on VBench & VBench2.0 (top) and VideoGen-Eval[90](bottom).",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x6.png",
                "caption": "Figure 6:VideoRewards on VBench & VBench2.0 (top) and VideoGen-Eval[90](bottom).",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x7.png",
                "caption": "",
                "position": 594
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x8.png",
                "caption": "Figure 7:EvoSearch can generalize to unseen metrics.Top¬†row: DrawBench results on SD2.1.Bottom¬†row: DrawBench results on Flux.1-dev.",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2505.17618/extracted/6468488/figs/demo_comp.png",
                "caption": "Figure 8:A qualitative example showing that EvoSearch generates videos with superior visual quality, enhanced background consistency, and improved semantic alignment with the input text prompts.",
                "position": 762
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x9.png",
                "caption": "Figure 9:Human evaluation results.",
                "position": 776
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x9.png",
                "caption": "Figure 9:Human evaluation results.",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x10.png",
                "caption": "",
                "position": 783
            },
            {
                "img": "https://arxiv.org/html/2505.17618/extracted/6468488/figs/diversity.png",
                "caption": "Figure 10:For the same prompt, EvoSearch generates more visually diverse images.",
                "position": 791
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExperimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17618/x11.png",
                "caption": "Figure 11:Ablation study on the population size scheduleùí¶ùí¶\\mathcal{K}caligraphic_K. We denote the population size scheduleùí¶={kstart,kT,‚ãØ,ktj,‚ãØ,ktn}ùí¶subscriptùëòstartsubscriptùëòùëá‚ãØsubscriptùëòsubscriptùë°ùëó‚ãØsubscriptùëòsubscriptùë°ùëõ\\mathcal{K}=\\{k_{\\rm start},k_{T},\\cdots,k_{t_{j}},\\cdots,k_{t_{n}}\\}caligraphic_K = { italic_k start_POSTSUBSCRIPT roman_start end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , ‚ãØ , italic_k start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT , ‚ãØ , italic_k start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT }, wherekstartsubscriptùëòstartk_{\\rm start}italic_k start_POSTSUBSCRIPT roman_start end_POSTSUBSCRIPTis the size of the initial sampled Gaussian noises. We use Stable Diffusion 2.1 to conduct EvoSearch on DrawBench, employing ImageReward as the guidance reward function during search, and the denoising step is50505050. From left to right of the x-axis, the population size scheduleùí¶ùí¶\\mathcal{K}caligraphic_Kis configured as: 0){60,40,50}604050\\{60,40,50\\}{ 60 , 40 , 50 }; 1){70,30,50}703050\\{70,30,50\\}{ 70 , 30 , 50 }; 2){80,20,50}802050\\{80,20,50\\}{ 80 , 20 , 50 }; 3){62,62,20}626220\\{62,62,20\\}{ 62 , 62 , 20 }; 4){58,58,30}585830\\{58,58,30\\}{ 58 , 58 , 30 }; 5){54,54,40}545440\\{54,54,40\\}{ 54 , 54 , 40 }; 6){46,46,60}464660\\{46,46,60\\}{ 46 , 46 , 60 };7){40,60,50}406050\\{40,60,50\\}{ 40 , 60 , 50 }; 8){30,70,50}307050\\{30,70,50\\}{ 30 , 70 , 50 }; 9){20,80,50}208050\\{20,80,50\\}{ 20 , 80 , 50 }, where we maintain the evolution schedule as{50,40}5040\\{50,40\\}{ 50 , 40 }.",
                "position": 2205
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x12.png",
                "caption": "Figure 12:Ablation study on the evolution scheduleùíØùíØ\\mathcal{T}caligraphic_T. We use Stable Diffusion 2.1 to conduct EvoSearch on the DrawBench, employing ImageReward as the guidance reward function during search. We denote the evolution scheduleùíØ={T,‚ãØ,tj,‚ãØ,tn}ùíØùëá‚ãØsubscriptùë°ùëó‚ãØsubscriptùë°ùëõ\\mathcal{T}=\\{T,\\cdots,t_{j},\\cdots,t_{n}\\}caligraphic_T = { italic_T , ‚ãØ , italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , ‚ãØ , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }. From left to right of the x-axis,\nthe evolution schedule is 0){50,30}5030\\{50,30\\}{ 50 , 30 }; 1){50,20}5020\\{50,20\\}{ 50 , 20 }; 2){50,10}5010\\{50,10\\}{ 50 , 10 }; 3){50,30}5030\\{50,30\\}{ 50 , 30 }; 4){50,20}5020\\{50,20\\}{ 50 , 20 }; 5){50,10}5010\\{50,10\\}{ 50 , 10 }. To keep the same test-time scaling computation budget across different evolution schedules, each population size schedule is adjusted as 0){60,50,50}605050\\{60,50,50\\}{ 60 , 50 , 50 }; 1){70,50,50}705050\\{70,50,50\\}{ 70 , 50 , 50 }; 2){80,50,50}805050\\{80,50,50\\}{ 80 , 50 , 50 }; 3){55,55,50}555550\\{55,55,50\\}{ 55 , 55 , 50 }; 4){60,60,50}606050\\{60,60,50\\}{ 60 , 60 , 50 }; 5){75,75,50}757550\\{75,75,50\\}{ 75 , 75 , 50 }.",
                "position": 2216
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x13.png",
                "caption": "Figure 13:EvoSearch can generalize to unseen metrics, where ImageReward is set as the guidance reward function during search.Top¬†row: DrawBench results on SD2.1.Bottom¬†row: DrawBench results on Flux.1-dev.",
                "position": 2222
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x14.png",
                "caption": "Figure 14:Comparative analysis of test-time scaling methods for Stable Diffusion 2.1.EvoSearchdemonstrates consistent improvements in image quality and text-prompt alignment as NFEs increase, achieving accurate interpretations of the challenging prompt with high computational efficiency. In contrast,Best-of-Nfails to produce semantically correct results even with increased NFEs, whileParticle Samplingintroduces semantic ambiguity at higher NFEs (e.g., confusing wine glasses and eyeglasses). Notably,EvoSearchfurther enables SD2.1 to outperformGPT4o.",
                "position": 2249
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x15.png",
                "caption": "Figure 15:Results of test-time scaling for Flux.1-dev.EvoSearchdemonstrates significant exploration ability, enabling the generation of images with diverse styles, while bothBest-of-NandParticle Samplinggenerate images with reduced diversity.",
                "position": 2254
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x16.png",
                "caption": "Figure 16:Results of test-time scaling for Flux.1-dev.EvoSearchcan even achieve accurate spatial relationship interpretation with only10√ó10\\times10 √óscaled computation budget, while consistently improving image quality through higher NFEs.",
                "position": 2260
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x17.png",
                "caption": "Figure 17:Results of test-time scaling for Hunyuan 13B. The denoising step is30303030, and we scale up the test-time computation by20√ó20\\times20 √ó. Only EvoSearch generates high-quality video aligned closely with the text prompt.",
                "position": 2265
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x18.png",
                "caption": "Figure 18:Results of test-time scaling for Hunyuan 13B. The denoising step is30303030, and we scale up the test-time computation by20√ó20\\times20 √ó. EvoSearch successfully follows the text prompt while the baselines fail.",
                "position": 2270
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x19.png",
                "caption": "Figure 19:Results of test-time scaling for Hunyuan 13B. The denoising step is30303030, and we scale up the test-time computation by20√ó20\\times20 √ó. EvoSearch demonstrates superior text alignment and higher-quality generation compared to baselines.",
                "position": 2275
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x20.png",
                "caption": "Figure 20:Results of test-time scaling for Hunyuan 13B. The denoising step is30303030, and we scale up the test-time computation by20√ó20\\times20 √ó. The video generated by EvoSearch demonstrates better temporal consistency and text alignment.",
                "position": 2280
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x21.png",
                "caption": "Figure 21:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch. Qualitative results demonstrate thatEvoSearchenables Wan1.3B to outperform Wan14B, its10√ó10\\times10 √ólarger counterpart.",
                "position": 2285
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x22.png",
                "caption": "Figure 22:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch.EvoSearchenables smaller models to achieve not only competitive but superior performance compared to their larger counterparts.",
                "position": 2290
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x23.png",
                "caption": "Figure 23:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch.EvoSearchdemonstrate superior text-alignment performance.",
                "position": 2295
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x24.png",
                "caption": "Figure 24:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch.EvoSearchenhances Wan1.3B‚Äôs capability in dynamic-attribute video generation.",
                "position": 2300
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x25.png",
                "caption": "Figure 25:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch.EvoSearchenhances Wan1.3B‚Äôs capability in handling challenging prompts, outperforming Wan14B given the same inference time.",
                "position": 2305
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x26.png",
                "caption": "Figure 26:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch. The video generated byEvoSearchfollows the text instruction more closely, exhibiting improved logical consistency.",
                "position": 2310
            },
            {
                "img": "https://arxiv.org/html/2505.17618/x27.png",
                "caption": "Figure 27:We scale up the test-time computation of Wan1.3B by5√ó5\\times5 √ó, ensuring equivalent inference times between Wan14B andWan1.3B+EvoSearch.EvoSearchsignificantly improves the generation quality with superior semantic alignment.",
                "position": 2315
            }
        ]
    },
    {
        "header": "Appendix BAdditional Experimental Results",
        "images": []
    }
]