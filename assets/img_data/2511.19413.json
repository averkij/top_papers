[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x1.png",
                "caption": "(a)Performance vs. consistency.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x1.png",
                "caption": "(a)Performance vs. consistency.",
                "position": 171
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x2.png",
                "caption": "(b)Manifold coverage.",
                "position": 176
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x3.png",
                "caption": "(a)Supervised fine-tuning",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x3.png",
                "caption": "(a)Supervised fine-tuning",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x4.png",
                "caption": "(b)Reconstruction-base approaches",
                "position": 252
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x5.png",
                "caption": "(c)Reward-based approaches",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x6.png",
                "caption": "(d)Ours: Minmax optimization",
                "position": 264
            }
        ]
    },
    {
        "header": "3UniGame",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x7.png",
                "caption": "Figure 3:Overview of UniGame.This adversarial self-play improves understanding robustness and understanding-generation consistency. The perturberCCis a lightweight (3-layer MLP) module and the hard bufferâ„¬\\mathcal{B}is a filtering mechanism.",
                "position": 337
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x8.png",
                "caption": "(a)OOD and adv. robustness.",
                "position": 950
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x8.png",
                "caption": "(b)Training Loss Comparison",
                "position": 958
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x9.png",
                "caption": "(a)Case study for close-ended and open-ended understanding tasks.",
                "position": 1021
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x9.png",
                "caption": "(a)Case study for close-ended and open-ended understanding tasks.",
                "position": 1024
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x10.png",
                "caption": "(b)Case study for generation tasks.",
                "position": 1030
            }
        ]
    },
    {
        "header": "5Conclusion and Limitation",
        "images": []
    },
    {
        "header": "Appendix AAlgorithm Details",
        "images": []
    },
    {
        "header": "Appendix BTraining Details",
        "images": []
    },
    {
        "header": "Appendix CDetailed Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x11.png",
                "caption": "(a)Cases drawn from the hard-sample buffer that successfully challenged the model.",
                "position": 1534
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x11.png",
                "caption": "(a)Cases drawn from the hard-sample buffer that successfully challenged the model.",
                "position": 1537
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x12.png",
                "caption": "(b)VQA accuracy across different adversarial ratios, with the best reaching 83.4%.",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2511.19413/figs/sweetsopt.jpg",
                "caption": "Figure 7:Perturbation Sweetspot",
                "position": 1551
            },
            {
                "img": "https://arxiv.org/html/2511.19413/x13.png",
                "caption": "Figure 8:heatmap Ablation study on CLIP constraint configurations. We report VQAv2\naccuracy for different combinations of CLIP\nweight and CLIP similarity threshold",
                "position": 1554
            }
        ]
    },
    {
        "header": "Appendix DRobustness Results",
        "images": []
    },
    {
        "header": "Appendix EDetails on Case Study",
        "images": []
    },
    {
        "header": "Appendix FConvergence and Hyperparameter Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.19413/x14.png",
                "caption": "Figure 9:The best result of all of our runs, optimization path are projected to a two dimension axis.",
                "position": 1702
            },
            {
                "img": "https://arxiv.org/html/2511.19413/figs/selfplay_dynamic.png",
                "caption": "Figure 10:Self-play dynamics between the generation and the understanding . The two branches alternately dominate the training objective, exhibiting a stable tug-of-war behavior.",
                "position": 1705
            },
            {
                "img": "https://arxiv.org/html/2511.19413/figs/eps_curve.png",
                "caption": "Figure 11:Perturebation Budget",
                "position": 1723
            },
            {
                "img": "https://arxiv.org/html/2511.19413/figs/dominate_timeline.png",
                "caption": "Figure 12:Dominance timeline. The trajectory alternates between understanding and generation phases, illustrating a stable tug-of-war rather than collapse to either side during training.",
                "position": 1726
            }
        ]
    },
    {
        "header": "Appendix GTheoretical Insights",
        "images": []
    }
]