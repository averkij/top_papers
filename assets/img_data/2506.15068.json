[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15068/x1.png",
                "caption": "Figure 1:Our proposed reward model Prefbertbetter reflects human judgments by distinguishing the good responses from the bad ones than other traditional metrics, generalized reward model.",
                "position": 183
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Conceptual Backgrounds",
        "images": []
    },
    {
        "header": "4Experiment Setup",
        "images": []
    },
    {
        "header": "5Automatic Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15068/x2.png",
                "caption": "Figure 2:Reward curves duringgrpotraining show key differences across reward functions. Traditional metrics show minimal reward change—only 0.05 forrouge-L and 0.25 forbertscore—indicating limited model improvement across all global training steps. In contrast, 3B-grm-llama-3B’s reward is strongly correlated with response length; by step 60, it already generates the maximum allowed tokens (1,024), causing reward values to plateau around 0.6. Prefbertshows a more meaningful reward progression, not strictly tied to length, suggesting it favors responses of an optimal length rather than simply longer outputs.",
                "position": 836
            }
        ]
    },
    {
        "header": "6Human Evaluation",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Ethics",
        "images": []
    },
    {
        "header": "9Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATechnical Details",
        "images": []
    },
    {
        "header": "Appendix BDataset Details",
        "images": []
    },
    {
        "header": "Appendix CPrompt Template",
        "images": []
    },
    {
        "header": "Appendix DMarkdown Expression Check",
        "images": []
    },
    {
        "header": "Appendix EAnnotation Tool",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.15068/extracted/6550552/figures/annotation_app.jpg",
                "caption": "Figure 3:Our annotation tool for response quality annotation. Annotators will be displayed with the question prompt, the answers for the seven models, where they need to slide due to limited screen width. Annotators can then put their Likert scores (1-5) and comments or notes for each response, and then finally rank the responses based on their preferences and ratings.",
                "position": 2391
            }
        ]
    },
    {
        "header": "Appendix FShowcases for Qualitative Analysis",
        "images": []
    }
]