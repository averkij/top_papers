[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": []
    },
    {
        "header": "3TransferEngine",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27656/x1.png",
                "caption": "Figure 1:TransferEnginemanaging GPUs across NUMA nodes, each with multiple NICs. Commands are forwarded to workers, which respond back to the callback handler orImmCounter.",
                "position": 356
            }
        ]
    },
    {
        "header": "4KvCache Transfer",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27656/x2.png",
                "caption": "Figure 3:KV transfer between prefillers and decoders",
                "position": 570
            }
        ]
    },
    {
        "header": "5RL Rollout Weight Transfer",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27656/x3.png",
                "caption": "Figure 4:Weight transfer data path for different approaches.",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x4.png",
                "caption": "Figure 5:Pipelined weight transfer execution.",
                "position": 602
            }
        ]
    },
    {
        "header": "6MoE Dispatch/Combine",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27656/x5.png",
                "caption": "Figure 6:Dispatch and Combine GPU-CPU-NIC coordination",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x6.png",
                "caption": "Figure 7:Dispatch into private and contiguous buffers",
                "position": 700
            }
        ]
    },
    {
        "header": "7Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.27656/x7.png",
                "caption": "Figure 8:Point-to-Point communication performance",
                "position": 791
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x8.png",
                "caption": "Figure 9:Impact of private buffer size on p50 decode latency",
                "position": 919
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x9.png",
                "caption": "Figure 10:Separate Send and Receive Latency for EP=64",
                "position": 940
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x10.png",
                "caption": "Figure 11:MoE Decode Latency. Bar height is mean. Error bars show p01, p25, p50, p75, p95, p99. Error bars forpplxindicate stddev.",
                "position": 950
            },
            {
                "img": "https://arxiv.org/html/2510.27656/x11.png",
                "caption": "Figure 12:MoE Prefill Latency. Bar height is mean. Error bars show p01, p25, p50, p75, p95, p99.",
                "position": 953
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]