[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06494/x1.png",
                "caption": "",
                "position": 117
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06494/x2.png",
                "caption": "Figure 2:LightSwitch Material-Relighting Diffusion Framework.LightSwitch relights multi-view posed input images to a given target illumination. It infers and encodes multi-view consistent material image maps (ùêàd,ùêàorm\\mathbf{I}_{\\text{d}},\\mathbf{I}_{\\text{orm}}) using a material diffusion model (StableMaterialMV[23]) and concatenates them to the Pl√ºcker ray maps (ùêè\\mathbf{P}), encoded input images (ùê±src\\mathbf{x}_{\\text{src}}), and noisy latents (ùê≥t\\mathbf{z}_{t}) in the channel dimension. The multi-view relighting UNet denoises the noisy latents and cross-attends to the lighting latents concatenated with the latent lighting directions (ùêÑdir\\mathbf{E}_{\\text{dir}}). The lighting latents are encoded from the processed target environment map images(ùêÑtgtH,ùêÑtgtL)(\\mathbf{E}^{H}_{\\text{tgt}},\\mathbf{E}^{L}_{\\text{tgt}}). The Stable Diffusion encoders and decoder are kept frozen.",
                "position": 155
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06494/x3.png",
                "caption": "Figure 3:Denoising Relighting for Any Number of Views.Given the quadratic complexity of all-pair multi-view attention, we divide the input latentsùê≥t\\mathbf{z}_{t}into mini-batchesùê≥t(1),‚Ä¶,ùê≥t(b)\\mathbf{z}_{t}^{\\text{(1)}},\\dots,\\mathbf{z}_{t}^{\\text{(b)}}and make latents attend to each other only within a subset per denoising iteration. When the batches are shuffled after the denoising step, they can attend to another subset in the next iteration. By continuously shuffling the subsets across DDPM iterations we approximate the full relighting diffusion. To relight a novel view, we optimize a 3D gaussian splat on the training images and render the novel view using the rasterizer. The novel view is then inserted into the set source views, enabling consistent novel view relighting.",
                "position": 172
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x4.png",
                "caption": "Figure 4:Direct Relighting Comparison on Synthetic Objects.Given 8 images of an object, LightSwitch predicts a multi-view consistent relighting under a target illumination. With its usage of inferred material information, our model accurately relights objects with complex appearance effects such as specularities. On the other hand, the baselines bake in details from the source view into the target relighting and relight inconsistently across views.",
                "position": 252
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06494/x5.png",
                "caption": "Figure 5:3D Relighting Comparison on Objects With Lighting.Our method successfully relights a novel view to a target illumination while the baselines exhibit errors in the relit appearance. LightSwitch‚Äôs efficiency means it can relight a given novel view in 5 minutes at a high accuracy while operating on images at the original resolution (1728√ó\\times1120).",
                "position": 358
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x6.png",
                "caption": "Figure 6:2D Relighting Ablation Comparison.",
                "position": 494
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x7.png",
                "caption": "Figure 7:3D Relighting Comparison on NeRF-Synthetic.While other methods exhibit issues in the relit appearance such as baked-in albedo, reconstruction artifacts, and incorrect geometry, our method successfully relights with high fidelity.",
                "position": 501
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Additional Visualizations",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06494/x8.png",
                "caption": "Figure 8:Additional Visualizations of LightSwitch Relighting on Synthetic Objects.",
                "position": 1548
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x9.png",
                "caption": "Figure 9:Additional Visualizations of LightSwitch Relighting on Synthetic Objects.",
                "position": 1552
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x10.png",
                "caption": "Figure 10:Additional Visualizations of LightSwitch Relighting on Synthetic Objects.",
                "position": 1556
            },
            {
                "img": "https://arxiv.org/html/2508.06494/x11.png",
                "caption": "Figure 11:Additional Visualizations of LightSwitch 3D Relightings on NeRF-Synthetic.",
                "position": 1560
            }
        ]
    },
    {
        "header": "8Additional Details",
        "images": []
    }
]