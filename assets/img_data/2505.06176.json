[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06176/x1.png",
                "caption": "Figure 1.We present MonetGPT, an image operation-aware multimodal large language modelÂ (MLLM), that provides automatic suggestions for image retouching. Given a photographÂ (left), MonetGPT analyzes it to identify a set of issues and possible adjustments to fix them. The solution steps are then translated to a set of procedural operations, along with respective parameter settings, drawing from a given library of operations, which occurs in three stages. (Visual puzzles, on which we train the MLLM, are not shown here.)",
                "position": 114
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06176/extracted/6423088/figures/png_figs/motivation.png",
                "caption": "Figure 2.Generative tools, for example instructPix2Pix(Brooks etÂ al.,2023)or MGIE(Fu etÂ al.,2024), produce impressive image enhancements but can result in identity loss (e.g., faces, hands, objects) and are harder to override by users.\nProcedural approaches are more controllable as they restrict operations to a given set of user-prescribed operation library, and can be overridden or applied in parts.\nCurrent MLLMs (bottom-left: e.g., GPT o1 applied using a library of operations, presented as doc-strings), do not have a good internal model of image operations, and perform worse than our operation-aware variantÂ (bottom-right). SeeSection5for evaluation.",
                "position": 134
            }
        ]
    },
    {
        "header": "2.Related Work",
        "images": []
    },
    {
        "header": "3.Design Considerations",
        "images": []
    },
    {
        "header": "4.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06176/extracted/6423088/figures/png_figs/puzzle_one.png",
                "caption": "Figure 3.Puzzle A. This puzzle intends to teach what any single operationğ’ªğ’ª\\mathcal{O}caligraphic_Oâˆˆ\\inâˆˆâ„’â„’\\mathcal{L}caligraphic_L, along with its valueVğ‘‰Vitalic_V, does to a source imageISsubscriptğ¼ğ‘†I_{S}italic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPTto produce an edited imageIEsubscriptğ¼ğ¸I_{E}italic_I start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT. The visual puzzle being, given an ordered pair(IS,IE)subscriptğ¼ğ‘†subscriptğ¼ğ¸(I_{S},I_{E})( italic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ), one has to predict(ğ’ª,V)ğ’ªğ‘‰(\\mathcal{O},V)( caligraphic_O , italic_V ). Using(IS,IE)subscriptğ¼ğ‘†subscriptğ¼ğ¸(I_{S},I_{E})( italic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ), we also generate corresponding reasoningRğ‘…Ritalic_R.",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2505.06176/extracted/6423088/figures/png_figs/puzzle_two.png",
                "caption": "Figure 4.Puzzle B. This puzzle intends to teach about image aesthetics under any single operationğ’ªğ’ª\\mathcal{O}caligraphic_Oâˆˆ\\inâˆˆâ„’â„’\\mathcal{L}caligraphic_L. The visual puzzle being, given a set of randomly ordered images(IE,IV1,IV2,IV3,IV4)subscriptğ¼ğ¸subscriptğ¼subscriptğ‘‰1subscriptğ¼subscriptğ‘‰2subscriptğ¼subscriptğ‘‰3subscriptğ¼subscriptğ‘‰4(I_{E},I_{V_{1}},I_{V_{2}},I_{V_{3}},I_{V_{4}})( italic_I start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ), generated from an expert-edited final imageIXsubscriptğ¼ğ‘‹I_{X}italic_I start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPTby applying operationğ’ªğ’ª\\mathcal{O}caligraphic_Owith perturbed values{Vi}subscriptğ‘‰ğ‘–\\{V_{i}\\}{ italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }, one has to\norder the set of images, based on low to high valuesVisubscriptğ‘‰ğ‘–V_{i}italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, as well as identify the optimal imageIXsubscriptğ¼ğ‘‹I_{X}italic_I start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPTalong with the perturbations values to go back toIXsubscriptğ¼ğ‘‹I_{X}italic_I start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPTfrom each image. Note that we implicitly assume that any perturbation of an expert-edited image results in a worse image. Using the image set and the operation, we also generate corresponding reasoningRğ‘…Ritalic_R.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2505.06176/extracted/6423088/figures/png_figs/puzzle_three.png",
                "caption": "Figure 5.Puzzle C. This puzzle intends to teach how to generate a retouching plan. The visual puzzle being,\ngiven an ordered pair(IS,IE)subscriptğ¼ğ‘†subscriptğ¼ğ¸(I_{S},I_{E})( italic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ), one has to come up with a retouching plan{(ğ’ªi,Vi)}subscriptğ’ªğ‘–subscriptğ‘‰ğ‘–\\{(\\mathcal{O}_{i},V_{i})\\}{ ( caligraphic_O start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) }listing the operations, fromâ„’â„’\\mathcal{L}caligraphic_L, along with the associated parameter values. Using the image retouching sequence and the operations, we also generate corresponding reasoningRğ‘…Ritalic_R, in the form of Â¡Adjustment,Issue,SolutionÂ¿ for each operation.",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2505.06176/extracted/6423088/figures/png_figs/results_gallery.png",
                "caption": "Figure 6.Each row depicts an input image and a retouched version produced by each of the baselines. While generative baselines (MGIE) struggle to preserve the identity (last row), Exposure or Gemini sometimes generate too bright or dark results (third row). Direct regression with an MLLM fails to make sufficient enhancements. Our method is capable of providing balanced and aesthetic enhancements.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2505.06176/x2.png",
                "caption": "Figure 7.(Left)Â MonetGPT responds to subtle changes in the input image, producing different edit plans. In contrast, our regression baseline largely misses the subtle variations in the input and proposes almost identical retouching plans.\n(Right)Â MonetGPT can produce different edit plans based on style tags, here we showretro,balanced, andvibrantproducing different edit plans, resulting different retouched results.",
                "position": 364
            }
        ]
    },
    {
        "header": "5.Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06176/x3.png",
                "caption": "Figure 8.User preference study comparing our method against baselines Exposure(Hu etÂ al.,2018)(white-box system) and MGIE(Fu etÂ al.,2024)(instruction-guided MLLM enhancer). We presented participants with a source image alongside a pair of edited images, where our result was randomly paired with one of the baselines. Responses were collected from users experienced in photo retouching (expertusers) and those with varying familiarity (noviceusers). Participants could also selectneitherif both edits failed to improve upon the original image. Both expert and novice groups demonstrated a preference for our results, as shown.",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2505.06176/x4.png",
                "caption": "Figure 9.Autoregressive editing. The autoregressive nature of MLLMs, combined with our staged editing pipeline, allows the user to edit the plan (ğ’«ğ’«\\mathcal{P}caligraphic_P) at any stage. The refined plan is used to determine subsequent parameter values. Moreover, the edited planğ’«â€²superscriptğ’«â€²\\mathcal{P^{{}^{\\prime}}}caligraphic_P start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT â€² end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPTenables the MLLM to generate plans for subsequent stages that are consistent with the edits. The bottom image (ğ’«âˆ—â€²â€²\\mathcal{P^{{}^{\\prime\\prime}*}}caligraphic_P start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT â€² â€² end_FLOATSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT) shows a result following further modifications to the second and third stages, after the first stage was modified to generateğ’«â€²â€²superscriptğ’«â€²â€²\\mathcal{P^{{}^{\\prime\\prime}}}caligraphic_P start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT â€² â€² end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT.",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2505.06176/x5.png",
                "caption": "Figure 10.For each operation in our library, we show a violin plot of the adjustment values proposed by MonetGPT and the baseline which directly regresses the values on 100 images from the PPR10k dataset. While the baseline overfits and predicts the same values, MonetGPT utilizes the full range of values.",
                "position": 491
            }
        ]
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]