[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.05003/x1.png",
                "caption": "",
                "position": 64
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.05003/x2.png",
                "caption": "Figure 2:ReCaptureconsists, at setup time, of (a) Anchor video generation (b) Masked video fine-tuning using spatial and temporal LoRAs. To generate the clean output video with the new camera trajectory we simply perform inference of the video model.",
                "position": 96
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.05003/x3.png",
                "caption": "Figure 3:Anchor video generationusing image-level multiview-diffusion models to generate new views frame-by-frame.",
                "position": 151
            },
            {
                "img": "https://arxiv.org/html/2411.05003/x4.png",
                "caption": "Figure 4:Anchor video generationusing depth estimation to turn each frame into a point cloud and then generating new views by controlling the camera pose.",
                "position": 154
            },
            {
                "img": "https://arxiv.org/html/2411.05003/x5.png",
                "caption": "Figure 5:Comparisons with generative camera dolly[82]using anorbitcamera trajectory.",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2411.05003/x6.png",
                "caption": "Figure 6:Galleryof generated videos with novel and unseen user-provided camera trajectories usingReCapture.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2411.05003/x7.png",
                "caption": "Figure 7:Visualization of the effectiveness of masked video fine-tuning (Stage 2) for generating spatially and temporally coherent outputs from noisy anchor videos.",
                "position": 738
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.05003/x8.png",
                "caption": "Figure 8:Detailed ablation of all components of our method.",
                "position": 786
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]