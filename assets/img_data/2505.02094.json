[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/x1.png",
                "caption": "Figure 1.Our framework enables physically simulated robots to learn robust and generalizable interaction skills from sparse demonstrations: (top left) Learning sustained and robust dribbling from a single, brief demonstration; (top right) acquiring robust skill transitions from fragment skill demonstrations; (bottom left) generalizing book grasping to varied poses from one demonstration; and (bottom right) learning to reorientate a cube from a single grasp pose.",
                "position": 199
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/x2.png",
                "caption": "Figure 2.Given a degraded reference trajectory containing physically unreachable state transitions, perfect trajectory reconstruction becomes impossible. The goal is to learn a set of ideal trajectories that are both physically feasible and satisfy reconstruction thresholds. These ideal trajectories must exist within anŒµùúÄ\\boldsymbol{\\varepsilon}bold_italic_Œµ-neighborhood of the reference trajectory.",
                "position": 243
            }
        ]
    },
    {
        "header": "3.Preliminaries on RLID",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/x3.png",
                "caption": "Figure 3.Given sparse demonstrations (e.g., two short trajectories of Shot and Dribble), there exist infinite valid but uncaptured trajectories that can either bridge between them or emerge from their neighboring states (illustrated by question marks). Our method uncovers these potential trajectories via three key steps: (1) construct a Stitched Trajectory Graph (STG) to identify possible transitions, (2) expand STG into a State Transition Field (STF) that establishes connections for arbitrary states within the demonstration neighborhood, and (3) learn a skill policy via Adaptive Trajectory Sampling (ATS) and Reinforcement Learning from Interaction Demonstrations (RLID). This enables robust skill transition and generalization far beyond the original sparse demonstrations.",
                "position": 263
            }
        ]
    },
    {
        "header": "4.Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/fig4-1_SM_layup.png",
                "caption": "(a)SM on Layup, 0.0% SR",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/fig4-1_SM_layup.png",
                "caption": "(a)SM on Layup, 0.0% SR",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/fig4-2_ours_layup.png",
                "caption": "(b)Ours on Layup, 96.6% SR",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/fig4-3_SM_lrun2run.png",
                "caption": "(c)SM on DL-DR, 1.4% SR",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/fig4-4_ours_lrun2run.png",
                "caption": "(d)Ours on DL-DR, 100% SR",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2505.02094/x4.png",
                "caption": "(a)SM on Pour-Kettle-Cup",
                "position": 473
            },
            {
                "img": "https://arxiv.org/html/2505.02094/x4.png",
                "caption": "(a)SM on Pour-Kettle-Cup",
                "position": 476
            },
            {
                "img": "https://arxiv.org/html/2505.02094/x5.png",
                "caption": "(b)SM on Stand-Chair",
                "position": 482
            },
            {
                "img": "https://arxiv.org/html/2505.02094/x6.png",
                "caption": "(c)Ours on Pour-Kettle-Cup",
                "position": 488
            },
            {
                "img": "https://arxiv.org/html/2505.02094/x7.png",
                "caption": "(d)Ours on Stand-Chair",
                "position": 494
            }
        ]
    },
    {
        "header": "5.Experiment",
        "images": []
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/Comparison_fig6-1.png",
                "caption": "(a)Comparison of Skill Success Rates at Different Training Epochs",
                "position": 2027
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/Comparison_fig6-1.png",
                "caption": "(a)Comparison of Skill Success Rates at Different Training Epochs",
                "position": 2030
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/Comparison_fig6-2.png",
                "caption": "(b)Comparison ofùú∫ùú∫\\boldsymbol{\\varepsilon}bold_italic_Œµ-Neighborhood Success Rate at Different Training Epochs",
                "position": 2036
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/Comparison_fig6-3.png",
                "caption": "(c)Comparison of Skill Transition Success Rate at Different Training Epochs",
                "position": 2042
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/Comparison_fig6-4.png",
                "caption": "(d)Comparison of Normalized Reward at Different Training Epochs",
                "position": 2048
            },
            {
                "img": "https://arxiv.org/html/2505.02094/extracted/6408435/images/skill_transition_final.png",
                "caption": "Figure 7.Comparison of skill transition success rate (%) between five basketball skills. Our method demonstrates robust performance in achieving high success rates for transitions between arbitrary skills.",
                "position": 2057
            }
        ]
    },
    {
        "header": "Appendix AAdditional Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02094/x8.png",
                "caption": "Figure 8.Increasing and annealing the exploration rate in vanilla PPO",
                "position": 2338
            }
        ]
    },
    {
        "header": "Appendix BTechnical Details",
        "images": []
    },
    {
        "header": "Appendix CHyperparameters",
        "images": []
    }
]