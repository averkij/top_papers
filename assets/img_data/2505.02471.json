[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02471/x1.png",
                "caption": "Figure 1:The output results and multimodal interactive demos ofMing-Lite-Uni. Our model supports basic multimodal chatting, text-to-image generation, image editing, and image style transfer based on textual instructions.",
                "position": 97
            }
        ]
    },
    {
        "header": "2Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02471/x2.png",
                "caption": "Figure 2:The framework ofMing-Lite-Uni.Our model fixes the MLLM and fine-tunes the diffusion model through the newly designed multi-scale learnable tokens, multi-scale representation alignment, and connector.",
                "position": 135
            },
            {
                "img": "https://arxiv.org/html/2505.02471/x3.png",
                "caption": "Figure 3:The AR part ofMing-Lite-Uni.Our model reuses the M2-omni MLLM as a frozen token prediction module, retaining only its text and image branches. The pretraining procedure and dataset of the AR model are consistent with our previous work, please refer to[ref]for details.",
                "position": 207
            }
        ]
    },
    {
        "header": "3Training Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02471/extracted/6403604/figures/mjdata.jpg",
                "caption": "Figure 4:Basic image-text training pairs ofMing-Lite-Uni.",
                "position": 237
            },
            {
                "img": "https://arxiv.org/html/2505.02471/extracted/6403604/figures/editdata.png",
                "caption": "Figure 5:Ming-Lite-Uniimage editing data examples in the training set.",
                "position": 292
            },
            {
                "img": "https://arxiv.org/html/2505.02471/extracted/6403604/figures/styledata.png",
                "caption": "Figure 6:Ming-Lite-Uniimage style transfer data examples in the training set.",
                "position": 295
            }
        ]
    },
    {
        "header": "4Benchmark Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.02471/x4.png",
                "caption": "Figure 7:Instruction based image editing results outputted byMing-Lite-Uni.",
                "position": 870
            }
        ]
    },
    {
        "header": "5Contributors",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]