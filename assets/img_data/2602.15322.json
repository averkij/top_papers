[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15322/figs/magma_fig1.png",
                "caption": "Figure 1:Pre-training performance on C4 across model scales.Despite discarding half of updates, SkipUpdate yields substantial improvements over state-of-the-art dense optimizers.",
                "position": 161
            }
        ]
    },
    {
        "header": "2Update Masking as a Regularization",
        "images": []
    },
    {
        "header": "3Momentum-Aligned Update Masking",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15322/figs/nanomoe_new.png",
                "caption": "Figure 2:Optimization trajectories of pre-training the Nano MoE model on OpenWebText.",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2602.15322/figs/loss_layer3_N20_normal-lt.png",
                "caption": "Figure 3:Magma on light-tailed and heavy-tailed data distributions.Top:Optimization trajectories for Adam and Magma.Bottom:Robust condition number defined as the ratio between the maximum and median eigenvalues of the loss Hessian.",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2602.15322/figs/loss_layer3_N20_gamma-ht.png",
                "caption": "",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2602.15322/figs/condition_number_layer3_N20_normal-lt.png",
                "caption": "",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2602.15322/figs/condition_number_layer3_N20_gamma-ht.png",
                "caption": "",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2602.15322/figs/h.png",
                "caption": "Figure 4:Magma on homogeneous and heterogeneous quadratics.Top:Optimization trajectories for AdamW and Magma on quadratic objectives with identical eigenspectra but different block structures.Bottom:Average gradient–momentum alignment per block.",
                "position": 486
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Literature Review",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProofs of Claims",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.15322/x1.png",
                "caption": "Figure A1:Comparison of eval perplexity for different values of sampling ratioppand damping temperatureτ\\tau.",
                "position": 2144
            },
            {
                "img": "https://arxiv.org/html/2602.15322/x1.png",
                "caption": "Figure A1:Comparison of eval perplexity for different values of sampling ratioppand damping temperatureτ\\tau.",
                "position": 2147
            },
            {
                "img": "https://arxiv.org/html/2602.15322/x2.png",
                "caption": "Figure A2:Comparison of training perplexity on the C4 dataset over 20,000 iterations for Dense and Sparse momentum updates, with and without damping.",
                "position": 2152
            },
            {
                "img": "https://arxiv.org/html/2602.15322/x3.png",
                "caption": "Figure A3:Sensitivity analysis of learning rate on evaluation perplexity. Unlike Adam and C-Adam, which exhibit narrow optimal windows, Adam+Magma maintains consistent performance, demonstrating stability across a significantly wider hyperparameter range.",
                "position": 2166
            }
        ]
    },
    {
        "header": "Appendix CAblation Studies",
        "images": []
    }
]