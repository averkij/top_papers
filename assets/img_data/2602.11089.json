[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11089/x1.png",
                "caption": "",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11089/x2.png",
                "caption": "Figure 2:Illustration of DataChef training framework. Given a task, a policy LLM generates a data recipe, which is executed to produce a training dataset. The Data Verifier then evaluates a sampled subset to provide a scalar reward, guiding the policy update via GRPO to optimize for data quality and executability.",
                "position": 211
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11089/x3.png",
                "caption": "Figure 3:Correlation analysis of data evaluation metrics. (left) We summarize the Pearson correlation coefficients across all six evaluated tasks. (right) We detail the relationship between metric scores (X-axis) and downstream performance (Y-axis) on Language and Code tasks. The Data Verifier maintains a strong, consistent positive correlation across disparate domains. Please refer to Fig.8in Appx.Dfor complete results.",
                "position": 605
            },
            {
                "img": "https://arxiv.org/html/2602.11089/x4.png",
                "caption": "Figure 4:Analysis of RL Effectiveness. (a) RL training dynamics indicate that the policy consistently converges toward high-quality data recipe generation. (b) Evaluation results show that RL yields substantial improvements on out-of-domain tasks.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2602.11089/images/code_analysis_v4.png",
                "caption": "Figure 5:Analysis of operation frequency in generated recipes. We compare the average number of function calls per recipe across different models.",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2602.11089/images/finance-v8.png",
                "caption": "Figure 6:Visualization of data distribution in generated recipes. We project the source datasets and the data recipes generated by different models into a 2D embedding space.",
                "position": 814
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details of DataChef",
        "images": []
    },
    {
        "header": "Appendix BDetails of Experiments Setup",
        "images": []
    },
    {
        "header": "Appendix CCase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.11089/x5.png",
                "caption": "Figure 8:Complete results for correlation analysis.",
                "position": 2368
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results on Correlation Analysis",
        "images": []
    }
]