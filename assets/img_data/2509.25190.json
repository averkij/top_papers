[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25190/x1.png",
                "caption": "Figure 1:We proposeVisual Jigsaw, a self-supervised post-training task that enhances visual perception and understanding in MLLMs. Training on visual jigsaw tasks substantially strengthens fine-grained perception, monocular spatial perception, and compositional visual understanding in images; temporal understanding in videos; and geometry-aware understanding in 3D, demonstrating its generality and effectiveness across modalities. For clearer visualization, the value ranges differ across benchmarks in each radar chart.",
                "position": 98
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25190/x2.png",
                "caption": "Figure 2:Illustration of the Visual Jigsaw tasks.In the Image Jigsaw (top left), an image is partitioned into non-overlapping patches, shuffled into a sequence, and the model is tasked with predicting the correct raster order. In the Video Jigsaw (bottom), a video is segmented into temporal clips, shuffled, and the model predicts their original chronological order. In the 3D Jigsaw (top right), points with distinct depth values are sampled from an RGB-D image, shuffled and annotated in the RGB view, and the model is required to recover the correct depth order from nearest to farthest. Across all tasks, the policy model outputs an ordering that is compared against the ground truth, and a partial accuracy reward is assigned when only some elements are correctly ordered.",
                "position": 164
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25190/x3.png",
                "caption": "Figure 3:Performance with different jigsaw difficulties on image and video tasks.",
                "position": 965
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25190/x4.png",
                "caption": "Figure 4:Examples of the image jigsaw task. Each row shows a shuffled set of patches from an image, where the model is required to reconstruct the correct raster scan order. The ground-truth answers are displayed on the right.",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2509.25190/x5.png",
                "caption": "Figure 5:Example of the video jigsaw task. Each row shows a clip from the original video image, and the 6 clips are shuffled. The model is required to reconstruct the correct chronological order. The ground-truth answers are displayed on the right.",
                "position": 2338
            },
            {
                "img": "https://arxiv.org/html/2509.25190/x6.png",
                "caption": "Figure 6:Examples of the 3D jigsaw task. The model is required to order the points in each image from closest to farthest relative to the camera. The ground-truth answers are displayed on the right.",
                "position": 2341
            },
            {
                "img": "https://arxiv.org/html/2509.25190/x7.png",
                "caption": "Figure 7:Qualitative examples on image tasks.",
                "position": 2351
            },
            {
                "img": "https://arxiv.org/html/2509.25190/x8.png",
                "caption": "Figure 8:Qualitative examples on video tasks.",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2509.25190/x9.png",
                "caption": "Figure 9:Qualitative examples on 3D tasks.",
                "position": 2357
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]