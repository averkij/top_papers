[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x1.png",
                "caption": "Figure 1:Samples of videos generated by Kling or Gen-3 inPhyGenBenchwith4444different aspects. The results show that current T2V models struggle to generate videos that align with physical commonsense (e.g., the lack of a plane‚Äôs reflection in water in the first video of the second row).",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3PhyGenBench",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x2.png",
                "caption": "Figure 2:(a) is the overview of the proposedPhyGenBench. (b) is thePhyGenBenchdata pipeline, which covers four physics categories. We select key physical laws and manually craft initial prompts that reflect the corresponding physical phenomena. GPT-4o adds details and enhances diversity by varying objects. After manual review, we obtain 160 T2V prompts.",
                "position": 211
            }
        ]
    },
    {
        "header": "4PhyGenEval",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x3.png",
                "caption": "Figure 3:An overview of the proposedPhyGenEval.PhyGenEvalis divided into three parts: Key Physical Phenomena Detection, Physics Order Verification, and Overall Naturalness Evaluation. Each part uses an appropriate VLM in combination with physical-based customized questions generated by GPT-4o. The final score is the combined result of the three parts. For the example in the figure, the three-stage scores are00,1111(onlyq1subscriptùëû1q_{1}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTis correct), and00. The final score is calculated as 0 according to4.2.",
                "position": 259
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x4.png",
                "caption": "Figure 4:Different video generation evaluation metric inPhyGenBench. Except for the proposedPhyGenEval, the current methods cannot reasonably assess the correctness of physical commonsense in videos fromPhyGenBench.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2410.05363/x5.png",
                "caption": "Figure 5:Qualitative comparisons of four categories. Current models perform relatively well in generating optical phenomenons but are weaker in mechanics, thermal, and material properties.",
                "position": 605
            }
        ]
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APhyGenBench Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x6.png",
                "caption": "Figure 6:Samples of videos generated by Kling, Vchitect, and Cogvideo5b in Videophy.All T2V models struggle to achieve proper text alignment and produce high-quality videos, making it meaningless to evaluate physical correctness in Videophy.",
                "position": 1228
            }
        ]
    },
    {
        "header": "Appendix BPhyGenEval Details",
        "images": []
    },
    {
        "header": "Appendix CExperiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.05363/x7.png",
                "caption": "Figure 7:The qualitative comparison of CogVideoX 2B and CogVideoX 5B. The result shows that simply scaling up can solve some issues, but dynamic physical phenomenons involving the design of motion patterns remain challenging.",
                "position": 2012
            },
            {
                "img": "https://arxiv.org/html/2410.05363/x8.png",
                "caption": "Figure 8:The qualitative comparison of effects before and after using rewritten prompts. The results indicate that rewriting prompts addresses only a few basic issues (such as flame color reactions), while the majority of problems remain unsolved.",
                "position": 2026
            },
            {
                "img": "https://arxiv.org/html/2410.05363/x9.png",
                "caption": "Figure 9:Detailed diagram of the human evaluation process. We ask the annotators to score the semantic alignment and physical commonsense alignment of the video according to the scoring criteria in the figure.",
                "position": 2146
            }
        ]
    },
    {
        "header": "Appendix DDiscussion",
        "images": []
    }
]