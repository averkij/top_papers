[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Measuring Agents Collaborative Capabilities",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02687/x1.png",
                "caption": "Figure 2.1:Core System Diagram.In sequence, we (i) first generate a random mazem∼ℳ​(θ)m\\sim\\mathcal{M}(\\theta)and split it into two copies,m1,m2m^{1},m^{2}, with roughly half the cells obfuscated using “?” symbols, (ii) each agent is then given a maze copy along with the rules,rr, after which they engage in a dialogue until either the maximum number of turns is reached or the task is completed, finally (iii) the raw transcript,τ\\tau, is passed to a “grader” agent that extracts the agreed upon route,zz, which is checked against the ground-truth maze to decide outcomeyy.",
                "position": 197
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02687/x2.png",
                "caption": "Figure 4.1:The Collaboration Gap.Mean weighted outcomes of 6×\\times6 maze-solving experiments in solo and homogeneous collaboration mode with 95% CI.\nWe first set a “maze solving” capability baseline by presenting a model with the full maze (gray marks), showing weighted outcomes surpass 0.5 for most models.\nNext, we present models the same mazes but “distribute” the information over two map copies (yellow marks).\nWe note a performance degradation for many, only reporting values that pass a 95% CI between the solo settings.\nFinally, we evaluate models’ collaborative capabilities by pairing them with an independent copy of themselves, providing each a distributed half of the maze (red marks).\nMost models display a significant performance “gap” when moving from solving mazes solo to collaboratively.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x3.png",
                "caption": "(a)OpenAI",
                "position": 472
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x3.png",
                "caption": "(a)OpenAI",
                "position": 475
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x4.png",
                "caption": "(b)OpenAI and Google",
                "position": 480
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x5.png",
                "caption": "(c)Anthropic, Google, OpenAI, xAI",
                "position": 486
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x6.png",
                "caption": "(a)Strong Primer",
                "position": 613
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x6.png",
                "caption": "(a)Strong Primer",
                "position": 616
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x7.png",
                "caption": "(b)Strong Recovery",
                "position": 621
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendices",
        "images": []
    },
    {
        "header": "Appendix APrompts and Models Used",
        "images": []
    },
    {
        "header": "Appendix BMaze Hyperparameter Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02687/x8.png",
                "caption": "(a)Solo: Full and Distributed.For each model, we report solo mean performance with 95 % CI onNNxNNmazes whereN∈{4,6,8,10,12,18}N\\in\\{4,6,8,10,12,18\\}.\nWe note that for most models performance drastically drops in the distributed setting forN>6N>6. Both gpt-5 and o3 perform remarkably well up toN=12N=12.",
                "position": 2033
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x8.png",
                "caption": "",
                "position": 2036
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x9.png",
                "caption": "(a)Solo: Full and Distributed.For each model, we report solo mean performance with 95 % CI onNNxNNmazes whereN∈{4,6,8,10,12,18}N\\in\\{4,6,8,10,12,18\\}.\nWe note that for most models performance drastically drops in the distributed setting forN>6N>6. Both gpt-5 and o3 perform remarkably well up toN=12N=12.",
                "position": 2041
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x10.png",
                "caption": "(b)Homogeneous Collaboration.We ablate collaborative performance for selected strong performers on mazes ofN∈{6,8,10}N\\in\\{6,8,10\\}. Note that performance drops considerably for all models except gpt-5.",
                "position": 2050
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x11.png",
                "caption": "Figure B.2:Solo Weighted Outcomes for Wall Density Ablations.We report mean values with 95% CI on 6x6 mazes for∼\\sim30 rollouts, varying the wall densityp∈{0,0.15,0.30,0.45,0.60,0.75}p\\in\\{0,0.15,0.30,0.45,0.60,0.75\\}.\nNote that for the solo full setting (top), gpt-4.1 and gpt-4.1-mini display the most variance in the rangep∈[0.30,0.45]p\\in[0.30,0.45], whereas the gpt-4.1-nano performance monotonically degrades as wall density increases.\nFor the distributed setting, all three models drop performance as the wall density increases.",
                "position": 2067
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x11.png",
                "caption": "",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x12.png",
                "caption": "",
                "position": 2075
            }
        ]
    },
    {
        "header": "Appendix CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.02687/x13.png",
                "caption": "(a)Homogeneous vs. Heterogeneous Token Efficiency.We display median token efficiency of homogeneous and heterogeneous collaborations (when available).",
                "position": 3071
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x13.png",
                "caption": "(a)Homogeneous vs. Heterogeneous Token Efficiency.We display median token efficiency of homogeneous and heterogeneous collaborations (when available).",
                "position": 3074
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x14.png",
                "caption": "(b)Token Efficiency Stratified by Other Agent.We compare the change in median token efficiency when an agent is paired with either a “More\" or “Less\" efficient agent.\n“More/Less” here refers to agents that use fewer/more tokens in their homogeneous collaboration.\nNote that on average, agents tend to adapt their efficiency to their partner.",
                "position": 3080
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x15.png",
                "caption": "(a)Homogeneous Collaboration.",
                "position": 3098
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x15.png",
                "caption": "(a)Homogeneous Collaboration.",
                "position": 3101
            },
            {
                "img": "https://arxiv.org/html/2511.02687/x16.png",
                "caption": "(b)Heterogeneous Collaboration.",
                "position": 3108
            }
        ]
    },
    {
        "header": "Appendix DGrading Ablation",
        "images": []
    },
    {
        "header": "Appendix EDialogue Example Snippets",
        "images": []
    },
    {
        "header": "Appendix FError Analysis",
        "images": []
    }
]