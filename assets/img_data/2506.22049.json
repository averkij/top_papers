[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22049/x1.png",
                "caption": "(a)Pre-LN",
                "position": 222
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x1.png",
                "caption": "(a)Pre-LN",
                "position": 225
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x2.png",
                "caption": "(b)Pre‚Äâ+‚ÄâGPAS",
                "position": 230
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x3.png",
                "caption": "(c)GPAS block",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x4.png",
                "caption": "(d)GPAS backprop",
                "position": 240
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Gradient-Preserving Activation Scaling",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22049/x5.png",
                "caption": "(a)Pretrain loss",
                "position": 658
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x5.png",
                "caption": "(a)Pretrain loss",
                "position": 661
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x6.png",
                "caption": "(b)Evaluation loss",
                "position": 666
            }
        ]
    },
    {
        "header": "5Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22049/x7.png",
                "caption": "(a)Learned gate valuesŒ±lsubscriptùõºùëô\\alpha_{l}italic_Œ± start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTfor different models",
                "position": 846
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x7.png",
                "caption": "(a)Learned gate valuesŒ±lsubscriptùõºùëô\\alpha_{l}italic_Œ± start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPTfor different models",
                "position": 849
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x8.png",
                "caption": "(b)Activated gate valuesSiLU‚Å¢(Œ±l)SiLUsubscriptùõºùëô\\mathrm{SiLU}(\\alpha_{l})roman_SiLU ( italic_Œ± start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT )across training steps of Pre‚Äâ+‚ÄâGPAS",
                "position": 854
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x9.png",
                "caption": "(a)Pre-LN",
                "position": 868
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x9.png",
                "caption": "(a)Pre-LN",
                "position": 871
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x10.png",
                "caption": "(b)Pre‚Äâ+‚ÄâGPAS",
                "position": 876
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x11.png",
                "caption": "(a)Pre-LN",
                "position": 893
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x11.png",
                "caption": "(a)Pre-LN",
                "position": 896
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x12.png",
                "caption": "(b)Pre‚Äâ+‚ÄâGPAS",
                "position": 901
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x13.png",
                "caption": "(a)Attention weight norm ratio",
                "position": 915
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x13.png",
                "caption": "(a)Attention weight norm ratio",
                "position": 918
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x14.png",
                "caption": "(b)FFN weight norm ratio",
                "position": 923
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x15.png",
                "caption": "(a)Pre-LN vs. Pre‚Äâ+‚ÄâGPAS",
                "position": 943
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x15.png",
                "caption": "(a)Pre-LN vs. Pre‚Äâ+‚ÄâGPAS",
                "position": 946
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x16.png",
                "caption": "(b)LNS vs. LNS‚Äâ+‚ÄâGPAS",
                "position": 951
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APretrain Results on 7B-Parameter Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.22049/x17.png",
                "caption": "(a)Pretrain loss",
                "position": 1766
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x17.png",
                "caption": "(a)Pretrain loss",
                "position": 1769
            },
            {
                "img": "https://arxiv.org/html/2506.22049/x18.png",
                "caption": "(b)Evaluation loss",
                "position": 1774
            }
        ]
    },
    {
        "header": "Appendix BGradient Preservation with GPAS",
        "images": []
    },
    {
        "header": "Appendix CProof of Theorem1of GPAS",
        "images": []
    },
    {
        "header": "Appendix DLicense",
        "images": []
    }
]