[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/x1.png",
                "caption": "Figure 1:Overview of HUGSIM. We propose HUGSIM, a photorealistic closed-loop simulator for AD, supporting a variety of scenes from different datasets and scenarios with varying levels of difficulty. HUGSIM also provides a closed-loop benchmark and presents challenges for existing AD algorithms.",
                "position": 140
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/x2.png",
                "caption": "Figure 2:The Pipeline of HUGSIM.We reconstruct urban scenes by disentangling them as ground, non-ground static background, and dynamic objects, while also enabling multi-modal rendering. Subsequently, we implement a closed-loop simulator based on the reconstructed results, providing a benchmark for evaluating autonomous driving algorithms.",
                "position": 351
            }
        ]
    },
    {
        "header": "3Urban Scene Reconstruction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/lane_distortion/35.png",
                "caption": "Figure 3:Lane DistortionIn the left image of the extrapolated view, the lane appears highly distorted due to incorrect geometry of ground gaussians. In contrast, the right image, which applies the multi-plane ground model, shows significantly fewer artifacts in the same view.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/lane_distortion/35_gd.png",
                "caption": "",
                "position": 437
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/ground_model/ground_model6.png",
                "caption": "Figure 4:The Multi-Plane Ground Model.Our ground model is initialized by multiple planes, each containing a set of flat 3D Gaussians. During training, we sample small patches of these Gaussians and constrain the height variance.",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/single/imgs/0422_capture.png",
                "caption": "Figure 5:Non-Native Vehicle ReconstructionWe reconstruct more than 100 vehicles from 3DRealCar[20]to enable 360-degree high-fidelity actor observation. Additionally, we place shadow Gaussians with gradually changing opacity inside a rounded rectangle to enhance the visual realism of the inserted actor.",
                "position": 507
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/single/imgs/0422_render.png",
                "caption": "",
                "position": 516
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/single/imgs/0702_capture.png",
                "caption": "",
                "position": 522
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/single/imgs/0702_render.png",
                "caption": "",
                "position": 526
            },
            {
                "img": "https://arxiv.org/html/2412.01718/x3.png",
                "caption": "Figure 6:3D Semantic Reconstruction.Comparison between applying softmax to accumulated 2D semantic logits (left) and to 3D semantic logits (right). Normalizing semantic logits in 3D space clearly reduces floaters and yields better 3D semantic reconstruction than the 2D normalization counterpart. This improvement is also crucial for our simulator collision detection.",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2412.01718/x4.png",
                "caption": "",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/attack/aggressive_planner_v4.png",
                "caption": "Figure 7:The Aggressive Driving Behavior Model.From (a) to (e), we illustrate the behavior of an aggressive actor (orange) attempting to collide the ego-vehicle (green) over a time period.\nIn (a), the attacker selects the trajectory with the highest probability of collision by estimating the future trajectory of the ego vehicle based on its current state. In (c), the attacker re-estimates and updates the trajectory, successfully colliding with the ego vehicle in (e).",
                "position": 735
            }
        ]
    },
    {
        "header": "4Simulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/method/HD_Score/hdscore2.png",
                "caption": "Figure 8:Illustration of sub-scores combined in HUGSIM.We present cases that result in the failure or reduction of the corresponding sub-scores.",
                "position": 913
            }
        ]
    },
    {
        "header": "5Rendering Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/mars3_crop1.png",
                "caption": "Figure 9:Details Qualitative Comparisonwith MARS on KITTI-360 Leaderboard.",
                "position": 969
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/ours3_crop1.png",
                "caption": "",
                "position": 978
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/mars3_crop2.png",
                "caption": "",
                "position": 982
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/ours3_crop2.png",
                "caption": "",
                "position": 986
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/mars4_crop1.png",
                "caption": "",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/ours4_crop1.png",
                "caption": "",
                "position": 996
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/mars5_crop1.png",
                "caption": "",
                "position": 1000
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/details_mars/ours5_crop1.png",
                "caption": "",
                "position": 1004
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/pnf_comp3.png",
                "caption": "Figure 10:Qualitative Comparisonwith PNF on KITTI-360 Leaderboard.",
                "position": 1034
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/ours_comp3.png",
                "caption": "",
                "position": 1043
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/pnf_comp6.png",
                "caption": "",
                "position": 1049
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/ours_comp6.png",
                "caption": "",
                "position": 1053
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/pnf_comp9.png",
                "caption": "",
                "position": 1059
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti360_leaderboard/compare_pnf/ours_comp9.png",
                "caption": "",
                "position": 1063
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti02_pseudo/gt_paste.png",
                "caption": "Figure 11:Qualitative Comparisonon KITTI and vKITTI. We use monocular-based 3D bounding box predictions for KITTI, and manually jittered 3D bounding boxes for vKITTI. We zoom in on a patch of a dynamic object for each KITTI scene.",
                "position": 1378
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti02_pseudo/mars_paste.png",
                "caption": "",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti02_pseudo/ours_paste.png",
                "caption": "",
                "position": 1399
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti06_pseudo/nsg_paste.png",
                "caption": "",
                "position": 1410
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti06_pseudo/mars_paste.png",
                "caption": "",
                "position": 1414
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti06_pseudo/ours_paste.png",
                "caption": "",
                "position": 1418
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/kitti06_pseudo/gt_paste.png",
                "caption": "",
                "position": 1422
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti02_noise/nsg_result.jpg",
                "caption": "",
                "position": 1436
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti02_noise/mars_result.jpg",
                "caption": "",
                "position": 1440
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti02_noise/ours.png",
                "caption": "",
                "position": 1444
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti02_noise/gt.jpg",
                "caption": "",
                "position": 1448
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti06_noise/nsg_result.jpg",
                "caption": "",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti06_noise/mars_result.jpg",
                "caption": "",
                "position": 1459
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti06_noise/ours.png",
                "caption": "",
                "position": 1463
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/kitti_comparison/vkitti06_noise/gt.jpg",
                "caption": "",
                "position": 1467
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/streetgs/sg_waymo1.png",
                "caption": "Figure 12:Extrapolated Views Qualitative Comparisonwith StreetGaussian and NeuRAD[70]on Waymo.",
                "position": 1632
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/streetgs/sg_waymo2.png",
                "caption": "",
                "position": 1646
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/neurad/neurad_waymo1.png",
                "caption": "",
                "position": 1657
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/neurad/neurad_waymo2.png",
                "caption": "",
                "position": 1661
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours/ours_waymo1.png",
                "caption": "",
                "position": 1672
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours/ours_waymo2.png",
                "caption": "",
                "position": 1676
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/neurad/neurad_nusc1.png",
                "caption": "Figure 13:Extrapolated Views Qualitative Comparisonwith NeuRAD[70]on nuScenes.",
                "position": 1701
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/neurad/neurad_nusc2.png",
                "caption": "",
                "position": 1715
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours/ours_nusc1.png",
                "caption": "",
                "position": 1726
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours/ours_nusc2.png",
                "caption": "",
                "position": 1730
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/rogs/rogs_interp2.png",
                "caption": "Figure 14:Qualitative Comparisonwith RoGS. Compared to our results, RoGS exhibits grid-style aliasing and limited rendering areas. Both methods show no obvious distortion in extrapolated views.",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/rogs/rogs_interp2_zoom.png",
                "caption": "",
                "position": 1797
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/rogs/rogs_extrap1.png",
                "caption": "",
                "position": 1801
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/rogs/rogs_extrap1_zoom.png",
                "caption": "",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours_ground/ours_interp2.png",
                "caption": "",
                "position": 1816
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours_ground/ours_interp2_zoom.png",
                "caption": "",
                "position": 1820
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours_ground/ours_extrap1.png",
                "caption": "",
                "position": 1824
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ext_comparison/ours_ground/ours_extrap1_zoom.png",
                "caption": "",
                "position": 1828
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/raw_013_crop.png",
                "caption": "Figure 15:Detail Qualitative Comparisonon KITTI with Noisy Bounding Boxes.",
                "position": 2096
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/opt_013_crop.png",
                "caption": "",
                "position": 2105
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/ours_013_crop.png",
                "caption": "",
                "position": 2109
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/raw_039_crop.png",
                "caption": "",
                "position": 2115
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/opt_039_crop.png",
                "caption": "",
                "position": 2119
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/unicycle/imgs/ours_039_crop.png",
                "caption": "",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_dist_int.png",
                "caption": "Figure 16:Qualitatively Ablation of Ground Model",
                "position": 2160
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_dist_ext.png",
                "caption": "",
                "position": 2174
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_scale_int.png",
                "caption": "",
                "position": 2185
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_scale_ext.png",
                "caption": "",
                "position": 2189
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_mu_int.png",
                "caption": "",
                "position": 2200
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/wo_mu_ext.png",
                "caption": "",
                "position": 2204
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/ours_int.png",
                "caption": "",
                "position": 2215
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/ground/ours_ext.png",
                "caption": "",
                "position": 2219
            }
        ]
    },
    {
        "header": "6Closed-Loop Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/insert/indig1.png",
                "caption": "Figure 17:Qualitative Comparisonwith native and non-native vehicles insertion.",
                "position": 2264
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/insert/non_indig1.png",
                "caption": "",
                "position": 2273
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/insert/indig2.png",
                "caption": "",
                "position": 2279
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/eval/ablation/insert/non_indig2.png",
                "caption": "",
                "position": 2283
            },
            {
                "img": "https://arxiv.org/html/2412.01718/x5.png",
                "caption": "Figure 18:Evaluation Results on HUGSIM Benchmark. The histograms indicate performance of models on each type of dataset, while the lines represent the averaged sub-scores across datasets.",
                "position": 2316
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/benchmark/case_study/hallucination_roi.jpg",
                "caption": "Figure 19:Case Study. The left part shows the RGB observations, perception results, and planning trajectories, the right part displays the predicted BEV information of UniAD.",
                "position": 2328
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/benchmark/case_study/overwhelme.jpg",
                "caption": "",
                "position": 2349
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/benchmark/case_study/opportunism2.jpg",
                "caption": "",
                "position": 2360
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/benchmark/case_study/instability.jpg",
                "caption": "",
                "position": 2371
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/zhy.jpg",
                "caption": "",
                "position": 3015
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/llz.pic.jpg",
                "caption": "",
                "position": 3028
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/wjb.jpg",
                "caption": "",
                "position": 3041
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/lyc.jpg",
                "caption": "",
                "position": 3053
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/bdf.jpg",
                "caption": "",
                "position": 3066
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/lbb2.png",
                "caption": "",
                "position": 3079
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/wy.png",
                "caption": "",
                "position": 3092
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/andreas.jpg",
                "caption": "",
                "position": 3105
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/figures/people/yiyi.jpg",
                "caption": "",
                "position": 3118
            }
        ]
    },
    {
        "header": "Appendix AImplementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/medium000.jpg",
                "caption": "Figure 20:Scenarios Design. Green, blue, gray, and orange represent the ego vehicle, static actors, normal actors, and aggressive actors, respectively.",
                "position": 3243
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/medium001.jpg",
                "caption": "",
                "position": 3257
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/medium002.jpg",
                "caption": "",
                "position": 3261
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/hard000.jpg",
                "caption": "",
                "position": 3290
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/hard001.jpg",
                "caption": "",
                "position": 3294
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/hard002.jpg",
                "caption": "",
                "position": 3298
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/extreme000.jpg",
                "caption": "",
                "position": 3327
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/extreme001.jpg",
                "caption": "",
                "position": 3331
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/scenarios/extreme002.jpg",
                "caption": "",
                "position": 3335
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/2d_01.png",
                "caption": "Figure 21:Qualitative Comparisonof 3D and 2D softmax results. Note that normalizing semantic logits in 3D space (Ours w/ùêí3D_normsubscriptùêí3D_norm\\mathbf{S}_{\\text{3D\\_norm}}bold_S start_POSTSUBSCRIPT 3D_norm end_POSTSUBSCRIPT) clearly reduces floaters and yields better 3D semantic reconstruction than the 2D normalization counterpart (Ours w/ùêí2D_normsubscriptùêí2D_norm\\mathbf{S}_{\\text{2D\\_norm}}bold_S start_POSTSUBSCRIPT 2D_norm end_POSTSUBSCRIPT).",
                "position": 3535
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/3d_01.png",
                "caption": "",
                "position": 3544
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/2d_02.png",
                "caption": "",
                "position": 3550
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/3d_02.png",
                "caption": "",
                "position": 3554
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/2d_03.png",
                "caption": "",
                "position": 3560
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/softmax_ablation/3d_03.png",
                "caption": "",
                "position": 3564
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/nerfacto_002.jpg",
                "caption": "Figure 22:Qualitative Comparisonwith Nerfacto on 2D space. The Pseudo GT column represents the semantic maps that are predicted by[4]on GT RGB images.",
                "position": 3584
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/ours_002.png",
                "caption": "",
                "position": 3593
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/gt_002.jpg",
                "caption": "",
                "position": 3597
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/nerfacto_031.jpg",
                "caption": "",
                "position": 3603
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/ours_031.png",
                "caption": "",
                "position": 3607
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/gt_031.jpg",
                "caption": "",
                "position": 3611
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/nerfacto_000.jpg",
                "caption": "",
                "position": 3617
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/ours_000.png",
                "caption": "",
                "position": 3621
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/gt_000.jpg",
                "caption": "",
                "position": 3625
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/nerfacto_026.jpg",
                "caption": "",
                "position": 3631
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/ours_026.png",
                "caption": "",
                "position": 3635
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/gt_026.jpg",
                "caption": "",
                "position": 3639
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/nerfacto_pcd_v2.png",
                "caption": "Figure 23:Qualitative Comparisonwith Nerfacto on 3D space.\nThe semantic point cloud extracted from Semantic Nerfacto struggles to faithfully represent the geometry.",
                "position": 3664
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_02/ours_pcd_v2.png",
                "caption": "",
                "position": 3673
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/nerfacto_pcd_v2.png",
                "caption": "",
                "position": 3679
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/nerfacto/seq_03/ours_pcd_v2.png",
                "caption": "",
                "position": 3683
            }
        ]
    },
    {
        "header": "Appendix BData",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/optimize/0_crop.png",
                "caption": "Figure 24:Visualization of Optimization Progress. Our method jointly optimizes the static background and the trajectory of the dynamic foreground objects. By integrating physical constraints using the unicycle model, our method allows for recovering a smooth trajectory from noisy 3D bounding boxes. To prevent visual clutter, we exclude point clouds of the dynamic object and only visualize the bounding boxes.",
                "position": 3725
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/optimize/2000_crop.png",
                "caption": "",
                "position": 3734
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/optimize/4900_crop.png",
                "caption": "",
                "position": 3738
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/trajectory/traj_comp6.png",
                "caption": "Figure 25:Pose comparisonwith QD-3DT.",
                "position": 3800
            }
        ]
    },
    {
        "header": "Appendix CHUGSIM Benchmark",
        "images": []
    },
    {
        "header": "Appendix DBaselines",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq01/3587_raw.png",
                "caption": "Figure 26:Qualitative Comparisonon depth. In the presence of the semantic loss‚Ñíùêísubscript‚Ñíùêí\\mathcal{L}_{\\mathbf{S}}caligraphic_L start_POSTSUBSCRIPT bold_S end_POSTSUBSCRIPT, We set the sky region‚Äôs depth infinite based on its semantic label.",
                "position": 4457
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq01/3587_smt.png",
                "caption": "",
                "position": 4466
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq01/3603_raw.png",
                "caption": "",
                "position": 4472
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq01/3603_smt.png",
                "caption": "",
                "position": 4476
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq02/3893_raw.png",
                "caption": "",
                "position": 4482
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq02/3893_smt.png",
                "caption": "",
                "position": 4486
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq02/3913_raw.png",
                "caption": "",
                "position": 4492
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq02/3913_smt.png",
                "caption": "",
                "position": 4496
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq03/6221_raw.png",
                "caption": "",
                "position": 4502
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq03/6221_smt.png",
                "caption": "",
                "position": 4506
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq03/6255_raw.png",
                "caption": "",
                "position": 4512
            },
            {
                "img": "https://arxiv.org/html/2412.01718/extracted/6037199/supplement/figures/depth/seq03/6255_smt.png",
                "caption": "",
                "position": 4516
            }
        ]
    },
    {
        "header": "Appendix EAdditional Experiment Results",
        "images": []
    }
]