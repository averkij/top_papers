[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18454/x1.png",
                "caption": "Figure 1:Comparison between discrete reasoning (left) and latent reasoning (right). Unlike the autoregressive sampling process in discrete reasoning, latent reasoning incorporates hidden representations from previous steps to enhance reasoning performance (between<think>and</think>).",
                "position": 74
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18454/x2.png",
                "caption": "Figure 2:Hybrid reasoning with gating (left) and hybrid reasoning policy optimization (right). During rollouts, the reasoning trajectory is generated hybridly with both discrete tokens and latent features, and for policy update, we compute the HRPO loss using the hybrid rollout buffer to update the model.",
                "position": 131
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18454/extracted/6470291/pics/hidden_comparison.png",
                "caption": "Figure 3:Reward on MATH for Qwen-2.5-1.5B using different latent reasoning strategies.",
                "position": 630
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x3.png",
                "caption": "Figure 4:Hidden ratio with varyingrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTinexp‚Å¢(‚àíc‚ãÖsoftplus‚Å¢(Œõ))exp‚ãÖùëêsoftplusŒõ\\texttt{exp}(-c\\cdot\\texttt{softplus}(\\Lambda))exp ( - italic_c ‚ãÖ softplus ( roman_Œõ ) )and learning rate. We visualize the hidden ratio and completion length for training runs withrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTfrom[0.95,0.98,0.99]0.950.980.99[0.95,0.98,0.99][ 0.95 , 0.98 , 0.99 ].",
                "position": 636
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x4.png",
                "caption": "Figure 5:Sensitivity analysis for temperatureœÑùúè\\tauitalic_œÑinEquation3. We visualize the reward and completion length for training runs with different temperature selected from[0.3,0.5,0.7,0.9]0.30.50.70.9[0.3,0.5,0.7,0.9][ 0.3 , 0.5 , 0.7 , 0.9 ].",
                "position": 732
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x5.png",
                "caption": "Figure 6:Example cross-lingual reasoning (English-Chinese) and its translation for HRPO.",
                "position": 739
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation",
        "images": []
    },
    {
        "header": "Appendix BAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.18454/x6.png",
                "caption": "Figure 10:Reward and completion length for training runs with different temperature values on GSM8k using the Qwen 1.5B backbone.",
                "position": 1884
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x7.png",
                "caption": "Figure 11:Reward and completion length for training runs with different temperature values on MATH using the Qwen 1.5B backbone.",
                "position": 1887
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x8.png",
                "caption": "Figure 12:Reward and completion length for training runs with different temperature values on knowledge tasks using the Qwen 1.5B backbone.",
                "position": 1890
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x9.png",
                "caption": "Figure 13:Reward and completion length for training runs with varying initialrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTon knowledge tasks using the Qwen 3B backbone.",
                "position": 1893
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x10.png",
                "caption": "Figure 14:Reward and completion length for training runs with varying initialrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTon GSM8k using the Qwen 3B backbone.",
                "position": 1896
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x11.png",
                "caption": "Figure 15:Reward and completion length for training runs with varying initialrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTon MATH using the Qwen 3B backbone.",
                "position": 1899
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x12.png",
                "caption": "Figure 16:Reward and completion length for training runs with varying initialrminsubscriptùëüminr_{\\mathrm{min}}italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPTon MMLU-ST / ARC-C using the Qwen 3B backbone.",
                "position": 1902
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x13.png",
                "caption": "Figure 17:Correct reasoning example 1 in HRPO.",
                "position": 1916
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x14.png",
                "caption": "Figure 18:Correct reasoning example 2 in HRPO.",
                "position": 1919
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x15.png",
                "caption": "Figure 19:Correct reasoning example 3 in HRPO.",
                "position": 1922
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x16.png",
                "caption": "Figure 20:Correct reasoning example 4 in HRPO.",
                "position": 1925
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x17.png",
                "caption": "Figure 21:Correct reasoning example 5 in HRPO.",
                "position": 1928
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x18.png",
                "caption": "Figure 22:Mistaken reasoning example 1 in HRPO.",
                "position": 1947
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x19.png",
                "caption": "Figure 23:Mistaken reasoning example 2 in HRPO.",
                "position": 1950
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x20.png",
                "caption": "Figure 24:Mistaken reasoning example 3 in HRPO.",
                "position": 1953
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x21.png",
                "caption": "Figure 25:Mistaken reasoning example 4 in HRPO.",
                "position": 1956
            },
            {
                "img": "https://arxiv.org/html/2505.18454/x22.png",
                "caption": "Figure 26:Mistaken reasoning example 5 in HRPO.",
                "position": 1959
            }
        ]
    },
    {
        "header": "Appendix CQualitative Analysis",
        "images": []
    }
]