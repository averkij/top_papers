[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02038/x1.png",
                "caption": "Figure 1:The overall architecture of our Marco-Voice system, incorporating speaker-emotion disentanglement, in-batch contrastive learning.",
                "position": 225
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.02038/x2.png",
                "caption": "Figure 2:Overall performance progression across model versions on Chinese and English datasets. The graph shows average accuracy scores across all emotions (excluding Playfulness) for emotion recognition tasks.",
                "position": 810
            },
            {
                "img": "https://arxiv.org/html/2508.02038/x3.png",
                "caption": "Figure 3:Emotion recognition performance comparison between Chinese and English datasets with style prompts. Results show accuracy scores for six emotion categories across seven model variants using the emotion2vec_base_finetuned classifier.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2508.02038/x4.png",
                "caption": "Figure 4:Cross-language performance comparison showing average emotion recognition accuracy between Chinese and English datasets across all model versions.",
                "position": 827
            },
            {
                "img": "https://arxiv.org/html/2508.02038/x5.png",
                "caption": "Figure 5:Effect of audio duration on emotion recognition accuracy. Performance is evaluated across three duration categories: short (<1s), medium (1s-3s), and long (>3s) audio segments for four primary emotions.",
                "position": 836
            },
            {
                "img": "https://arxiv.org/html/2508.02038/x6.png",
                "caption": "Figure 6:Gender-based performance analysis showing emotion recognition accuracy differences between male and female speakers on the Chinese dataset.",
                "position": 839
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]