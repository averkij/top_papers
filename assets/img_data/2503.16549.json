[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/extracted/6293211/logo.png",
                "caption": "",
                "position": 72
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/x1.png",
                "caption": "Figure 1:The Typical Process of Humans Solving Visual Mathematical\nProblems.We can summarize two key capabilities observed in the typical human\nproblem-solving process: perception and inference. The perception capability\ninvolves extracting relevant information from both visual and textual inputs,\nensuring accurate reasoning, which inspired the development of FlowVerse and\nMathFlow.",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x2.png",
                "caption": "Figure 2:Six Versions of Problems in FlowVerse.FlowVerse begins\nby categorizing the original problem information into four distinct\ncomponents: Descriptive Information (DI), Essential Information (EI), Only Question\n(OQ), and Reasoned Property (RP). The first three components are derived directly\nfrom the original problem statement, while RP is extracted from the solution\nand represents the inferences needed to solve the problem. In the Vision Centric\nversion, we convert the EI into diagrams, while in the Vision Primary version,\nwe convert both the EI and RP into diagrams.",
                "position": 107
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x3.png",
                "caption": "Figure 3:The Overview of MathFlow Pipeline.To effectively train MLLMs\nfor problem-solving, we decouple MLLMs into two sub-modules: the perception model\nand the inference model. The perception model is responsible for extracting\nand interpreting visual information, converting it into a form that can be effectively\nprocessed. The inference model uses this extracted information, along with the\noriginal question, to reason and derive solutions.",
                "position": 213
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/x4.png",
                "caption": "Figure 4:The FlowVerse-CoT-E Strategy.",
                "position": 962
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/extracted/6293211/fig4.png",
                "caption": "Figure 5:Comparison of Two Different CoT Evaluation Performances on\nFlowVerse†.",
                "position": 2304
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x5.png",
                "caption": "Figure 6:Problem-solving Comparison of MathFlow⋆GPT-4VGPT-4V{}_{\\mathrm{\\textbf{GPT-4V}}}start_FLOATSUBSCRIPT GPT-4V end_FLOATSUBSCRIPTand GPT-4V.",
                "position": 2312
            },
            {
                "img": "https://arxiv.org/html/2503.16549/extracted/6293211/model_error.png",
                "caption": "Figure 7:Comparison of Error Distributions Across Models on\nFlowVerse†.",
                "position": 2368
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/x6.png",
                "caption": "Figure 8:Manual Modification for EI in FlowVerse.For the original problems\nshown, we transfer some of the EI from diagrams to question texts (highlighted\nin green) to mark the Vision Centric version.",
                "position": 3472
            }
        ]
    },
    {
        "header": "Appendix AAdditional Details of FlowVerse",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/extracted/6293211/ratio.png",
                "caption": "Figure 9:Subject Distribution of FlowVerse.",
                "position": 3763
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x7.png",
                "caption": "Figure 10:Distribution of Question Length for Four Problem Versions.We\npresent the distribution of question length for the four problem versions,\nwith the horizontal axis representing question length in characters and the\nvertical axis depicting the corresponding probability distribution.",
                "position": 3920
            },
            {
                "img": "https://arxiv.org/html/2503.16549/extracted/6293211/bubble.png",
                "caption": "Figure 11:Visualization of Different Error Type across Different\nVersions using GPT-4 on FlowVerse.The horizontal axis represents different problem\nversions, while the vertical axis indicates the error types. The radius of each\nbubble corresponds to the number of visual perception errors, with smaller\nradii indicating fewer visual perception errors.",
                "position": 3963
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x8.png",
                "caption": "Figure 12:Comparison of Six Problem Versions in FlowVerse.",
                "position": 4151
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x9.png",
                "caption": "Figure 13:Comparison of Six Problem Versions in FlowVerse.",
                "position": 4154
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x10.png",
                "caption": "Figure 14:Comparison of Six Problem Versions in FlowVerse.",
                "position": 4157
            }
        ]
    },
    {
        "header": "Appendix BAdditional Details of MathFlow",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.16549/x11.png",
                "caption": "Figure 15:Data Annotation of the MathFlow-RPWe first employ Qwen2.5-72B\nto extract the corresponding steps from the solving-problem solution, then select\nstepNas the target for prediction. Subsequently, the precedingN-1steps are provided as input within the prompt, enabling the MLLM\nto predict the next step based on this sequential context.",
                "position": 4204
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x12.png",
                "caption": "Figure 16:Data Annotation of the MathFlow-SFT.We manually extract the\ncorresponding EI and RP from the solving-problem solution and associated\ndiagram. In this representation, the red-highlighted portions indicate EI, while\nthe blue-highlighted sections represent RP.",
                "position": 4264
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x13.png",
                "caption": "Figure 17:Response Comparison of GPT-4V and MathFlow⋆GPT-4V",
                "position": 5645
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x14.png",
                "caption": "Figure 18:Response Comparison of GPT-4V and MathFlow⋆GPT-4V",
                "position": 5648
            },
            {
                "img": "https://arxiv.org/html/2503.16549/x15.png",
                "caption": "Figure 19:Response Comparison of GPT-4V and MathFlow⋆GPT-4V",
                "position": 5651
            }
        ]
    },
    {
        "header": "Appendix CLimitation and Future Work",
        "images": []
    }
]