[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05283/x1.png",
                "caption": "Figure 1:A visual overview of the proposed approach.is illustrated. From left to right: We begin with two distinct input collections‚Äîone consisting of 3D shapes and the other of textual prompts. In the blue box, independent, frozen uni-modal encoders map each modality into separate, high-dimensional latent spaces, shown in the red box. A dimensionality reduction procedure is applied to project these learned spaces into low-dimensional subspaces, represented in the green box. Finally, an alignment method registers the two low-dimensional subspaces, enabling cross-modal applications such as shape retrieval, with examples depicted in the yellow box.",
                "position": 71
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05283/x2.png",
                "caption": "Figure 2:Linear CKA scores between text and 3D encoders without alignment.SpConv corresponds to MinkowskiNet. Higher scores reflect stronger alignment between encoder pairs, with the strongest alignment observed between multi-modal 3D encoders and CLIP text encoder due to their shared training on aligned representations. Uni-modal 3D encoders show significantly lower alignment with text encoders, though slightly higher with the CLIP text encoder.",
                "position": 492
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x3.png",
                "caption": "Figure 3:Linear CKA scores between text and 3D encoders after affine translation.SpConv refers to MinkowskiNet. Affine translation results in a similar increase in similarity for both 3D-to-text and text-to-3D directions.",
                "position": 495
            }
        ]
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05283/x4.png",
                "caption": "Figure 4:Impact of subspace dimensionality on retrieval performance.Comparison of three approaches: our proposed CCA + affine translation method (blue), affine translation without subspace projection (red), and baseline feature space alignment without transformation (orange). Results are shown for the uni-modal PointBERT and CLIP text encoder, with generalizations to other encoders provided in the supplementary.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x4.png",
                "caption": "",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x5.png",
                "caption": "",
                "position": 545
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x6.png",
                "caption": "Figure 5:Effect of anchor set size on retrieval performance.Validation set results with a fixed subspace dimensiond=50ùëë50d=50italic_d = 50show that retrieval performance improves as the anchor subset size increases but eventually reach a plateau. Results are shown for the uni-modal PointBERT and CLIP text encoder, with generalizations to other encoders provided in the supplementary.",
                "position": 551
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x6.png",
                "caption": "",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x7.png",
                "caption": "",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x8.png",
                "caption": "Figure 6:Pearson correlation between shape query chamfer distances and pairwise distances in the projected text latent subspace.We observe a higher Pearson correlation in the projected text latent subspace with optimal subspace dimension. Results are shown for the uni-modal PointBERT and CLIP text encoders.",
                "position": 565
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x9.png",
                "caption": "Figure 7:Shape retrieval comparison between original and reduced latent spaces.For a given query shape, we retrieve the closest match based on cosine similarity. Results demonstrate a higher semantic understanding in the reduced 3D latent subspace compared to the original latent space. Shown for uni-modal PointBERT and CLIP.",
                "position": 568
            }
        ]
    },
    {
        "header": "6Conclusion, Limitations and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADownstream results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.05283/x10.png",
                "caption": "(a)CLIP and PointBert",
                "position": 1701
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x10.png",
                "caption": "(a)CLIP and PointBert",
                "position": 1704
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x11.png",
                "caption": "(b)CLIP and MinkowskiNet",
                "position": 1709
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x12.png",
                "caption": "(c)CLIP and PointNet",
                "position": 1714
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x13.png",
                "caption": "(d)RoBERTa and PointBert",
                "position": 1720
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x14.png",
                "caption": "(e)RoBERTa and MinkowskiNet",
                "position": 1725
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x15.png",
                "caption": "(f)RoBERTa and PointNet",
                "position": 1730
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x16.png",
                "caption": "(g)BERT and PointBert",
                "position": 1736
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x17.png",
                "caption": "(h)BERT and MinkowskiNet",
                "position": 1741
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x18.png",
                "caption": "(i)BERT and PointNet",
                "position": 1746
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x19.png",
                "caption": "(a)CLIP and PointBert",
                "position": 1763
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x19.png",
                "caption": "(a)CLIP and PointBert",
                "position": 1766
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x20.png",
                "caption": "(b)CLIP and MinkowskiNet",
                "position": 1771
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x21.png",
                "caption": "(c)CLIP and PointNet",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x22.png",
                "caption": "(d)RoBERTa and PointBert",
                "position": 1782
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x23.png",
                "caption": "(e)RoBERTa and MinkowskiNet",
                "position": 1787
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x24.png",
                "caption": "(f)RoBERTa and PointNet",
                "position": 1792
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x25.png",
                "caption": "(g)BERT and PointBert",
                "position": 1798
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x26.png",
                "caption": "(h)BERT and MinkowskiNet",
                "position": 1803
            },
            {
                "img": "https://arxiv.org/html/2503.05283/x27.png",
                "caption": "(i)BERT and PointNet",
                "position": 1808
            }
        ]
    },
    {
        "header": "Appendix BAdditional ablations",
        "images": []
    }
]