[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10930/x1.png",
                "caption": "Figure 1:Evaluating AI systems’ evaluations.a,A holistic understanding of model reasoning demands not just assessing how AI systems solve problems (play games), but how they evaluate whether problems, systems, or games are worth pursuing at all;b,Not all evaluations of problems are interesting for evaluating models. Good evaluation queries pose a challenge by being difficult to compute, difficult to quantify, or both.",
                "position": 146
            }
        ]
    },
    {
        "header": "2From evaluating solutions to evaluating evaluation",
        "images": []
    },
    {
        "header": "3Methods",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10930/x2.png",
                "caption": "Figure 2:Evaluating payoff (fairness) evaluations.a,R2R^{2}between human- and model-predicted payoff evaluations, over all121121games. Each cell reports theR2R^{2}in payoff evaluations between two reasoners.b,Payoff predictions across a subset of the OpenAI model family, compared to people’s predicted payoffs (blue) and the estimated game-theoretic optimal (grey). Error bars depict bootstrappedR2R^{2}95% CIs.c-d,Example human- and a subset of model-predicted game evaluations. The distribution over human participants’ judgments or each models’2020rollouts are shown; the vertical axis shows the normalized density over binned distributions. Non-reasoning models (GPT-4 and DeepSeek-v3) are prompted with CoT.c,depicts a game where reasoning models are more aligned to people’s evaluations; in other games as ind,judgments are highly varied across models—with no model faithfully capturing the rich structure in the distribution of human judgments. More example games are included in AppendixA4.",
                "position": 202
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x3.png",
                "caption": "Figure 3:Evaluating funness evaluations.a,R2R^{2}between human- and model-predicted funness evaluations, over all121121games. Each cell reports theR2R^{2}in funness evaluations between those two reasoners.b,Funness evaluations across a subset of the OpenAI model family reveals non-monotonicty in fits when moving from non-reasoning to reasoning models. BootstrappedR2R^{2}are computed relative to people’s predicted funness, with error bars depicting the bootstrapped 95% CIs.c-dExample human- and model-predicted distributions over funness. The vertical axis shows the normalized density over the histogram of people and models’ binned judgments.c,depicts an example where people and most models (though not all, e.g., o1) recognize that the game is unlikely to be fun;d,however, people’s funness judgments are also variable, e.g., showing bimodality. This bimodality is not captured by most models, with a few exceptions (e.g., GPT-5) for this game. More example game evaluations are in AppendixA4.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x4.png",
                "caption": "Figure 4:Reasoning tokens used across games and evaluation queries.a,R2R^{2}between models’ median number of reasoning tokens used per game, for the payoff and funness evaluation queries.b,Median reasoning tokens used for games based on how many “traits” they differ from Tic-Tac-Toe (e.g., a game that is not played on a3×33\\times 3board, requires44pieces in a row to win, and constrains the win conditions to “only diagonals count,” has33traits different from Tic-Tac-Toe). Tic-Tac-Toe itself is zero. The heights of bars show averaged number of median tokens for that game, with error bars depicting standard deviation over games.c,Token usage based on higher-level game category.",
                "position": 457
            }
        ]
    },
    {
        "header": "5Related work",
        "images": []
    },
    {
        "header": "6Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Ethics statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix A1Additional related work",
        "images": []
    },
    {
        "header": "Appendix A2Example games",
        "images": []
    },
    {
        "header": "Appendix A3Additional model details",
        "images": []
    },
    {
        "header": "Appendix A4Additional analysis details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10930/x5.png",
                "caption": "Figure 5:Distribution over models’ and people’s predicted payoff judgments for example games.Example hand-selected representative game evaluations. The distribution over human participants’ judgments or each models’2020rollouts are shown. Panelsaanddshow the complete set of models for the examples shown in Figure2.",
                "position": 2041
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x6.png",
                "caption": "Figure 6:Distribution over models’ and people’s predicted funness for example games.Example hand-selected representative game evaluations. The distribution over human participants’ judgments or each models’2020rollouts are shown. Panelsbandcshow the complete set of models for the examples shown in Figure3.",
                "position": 2044
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x7.png",
                "caption": "Figure 7:Comparing distributional alignment of people and models.Games were judged by approximately2020people and language and reasoning models were sampled with2020rollouts per game. The distribution of judgments per game is compared using the Wasserstein Distance (lower means closer) over histograms of judgments per game. Histograms are over the range−1-1to11for payoff (a) and0to100100for funness (b).",
                "position": 2047
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x8.png",
                "caption": "Figure 8:Model- versus human-predicted payoff.Each point is a game. Averaged model- and human-predicted payoff per game. Error bars depict bootstrapped 95% CIs around the mean average payoff per game, bootstrapped over participants and model rollouts per game. The top row are language-only based models; the second row are reasoning models.",
                "position": 2063
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/K_in_a_Row_Square_payoff.png",
                "caption": "Figure 9:Distance between model and human payoff predictions, by game category.Averaged absolute difference between model and human payoff predictions, grouped by game category. Averaged over games within each category. Error bars depict standard deviation over absolute distance between model and human payoff predictions for games within the category.KKin a row indicates the number of pieces in a row needed to end the game, where horizontal, vertical, and diagonal all count (as in, e.g., a standard Tic-Tac-Toe game). We separate square and rectangular boards are separated for this setting; other categories mix board shape. Payoff values range from−1.0-1.0to1.01.0.",
                "position": 2066
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/K_in_a_Row_Rectangle_payoff.png",
                "caption": "",
                "position": 2069
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/Infinite_Board_payoff.png",
                "caption": "",
                "position": 2071
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/K_in_a_Row_Loses_payoff.png",
                "caption": "",
                "position": 2072
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/No_Diagonal_Win_Allowed_payoff.png",
                "caption": "Figure 10:Distance between model and human payoff predictions, by game category (continued).",
                "position": 2076
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/Only_Diagonal_Win_Allowed_payoff.png",
                "caption": "",
                "position": 2079
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/First_Player_Moves_2_Pieces_payoff.png",
                "caption": "",
                "position": 2081
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/Second_Player_Moves_2_Pieces_payoff.png",
                "caption": "",
                "position": 2082
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/First_Player_Handicap_P1_no_diag_payoff.png",
                "caption": "Figure 11:Distance between model and human payoff predictions, by game category (continued).",
                "position": 2086
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/First_Player_Handicap_P1_only_diag_payoff.png",
                "caption": "",
                "position": 2089
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories/Second_Player_K-1_to_Win_payoff.png",
                "caption": "",
                "position": 2091
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x9.png",
                "caption": "Figure 12:Model- versus human-predicted funness.Each point is a game. Averaged model- and human-predicted funness per game. Error bars depict bootstrapped 95% CIs around the mean average funness per game, bootstrapped over participants and model rollouts per game. The top row are language-only based models; the second row are reasoning models.",
                "position": 2105
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/K_in_a_Row_Square_fun.png",
                "caption": "Figure 13:Distance between model and human funness predictions, by game category.Averaged absolute difference between model and human funness evaluations, grouped by game category. Averaged over games within each category. Error bars depict standard deviation over absolute distance between model and human funness evaluations for games within the category. Funness values range from0to100.0100.0.",
                "position": 2108
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/K_in_a_Row_Rectangle_fun.png",
                "caption": "",
                "position": 2111
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/Infinite_Board_fun.png",
                "caption": "",
                "position": 2113
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/K_in_a_Row_Loses_fun.png",
                "caption": "",
                "position": 2114
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/No_Diagonal_Win_Allowed_fun.png",
                "caption": "Figure 14:Distance between model and human funness predictions, by game category (continued).",
                "position": 2118
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/Only_Diagonal_Win_Allowed_fun.png",
                "caption": "",
                "position": 2121
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/First_Player_Moves_2_Pieces_fun.png",
                "caption": "",
                "position": 2123
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/Second_Player_Moves_2_Pieces_fun.png",
                "caption": "",
                "position": 2124
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/First_Player_Handicap_P1_no_diag_fun.png",
                "caption": "Figure 15:Distance between model and human funness predictions, by game category (continued).",
                "position": 2128
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/First_Player_Handicap_P1_only_diag_fun.png",
                "caption": "",
                "position": 2131
            },
            {
                "img": "https://arxiv.org/html/2510.10930/figures/categories_fun/Second_Player_K-1_to_Win_fun.png",
                "caption": "",
                "position": 2133
            }
        ]
    },
    {
        "header": "Appendix A5Analyzing reasoning token usage",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10930/x10.png",
                "caption": "Figure 16:Reasoning token usage compared to human- and model-estimated payoff.a,Median usage relative to deviation between model and human;b,human and game-theoretic optimal, andc,that model and the game-theoretic optimal.",
                "position": 2142
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x11.png",
                "caption": "Figure 17:Explicit game simulation in reasoning models.a,Correlation (R2R^{2}) across models in rates of explicit game simulation, across all121121games;b,Simulation rates per game, depending on whether the game was evaluated on fairness (horizontal axis) or funness (vertical axis);c,Simulation rates broken down by game category. Error bars depict standard deviation over the simulation rates for the games in those categories.",
                "position": 2184
            },
            {
                "img": "https://arxiv.org/html/2510.10930/x12.png",
                "caption": "Figure 18:Assessing evaluations under varied“reasoning amount”.Select reasoning model (o3 and GPT-5) evaluations of games under varied reasoning “amounts”.a,BootstrappedR2R^{2}relative to people’s predicted payoffs (blue) and the estimated game-theoretic optimal (grey).b,BootstrappedR2R^{2}relative to people’s predicted game funness (green). Error bars depict the bootstrapped 95% CIs over games.",
                "position": 2193
            }
        ]
    },
    {
        "header": "Appendix A6Additional details on reasoning trace coding",
        "images": []
    }
]