[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IINTRODUCTION",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01778/images/overall.jpg",
                "caption": "Figure 1:Semantic Raster Image Fusion",
                "position": 136
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01778/images/DiffSemanticFusion.jpg",
                "caption": "Figure 2:DiffSemanticFusion Overview:Sparse PerceptionutilizesSparse4D[25]to extract bounding boxes of dynamic objects and map elements.Dense PerceptionutilizesLSS[26]andBEVDet[1]to extract BEV features.Vectorized GraphutilizesSemanticFormer[27]to extract graph information.Fusionfuses heterogeneous representations to unified space andDiffusion Plannerserves as trajectories decoder.",
                "position": 173
            }
        ]
    },
    {
        "header": "IIIMethod",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01778/images/map_diffusion.jpg",
                "caption": "Figure 3:Mapless QCNet Encoder with Online HD Map Diffusion",
                "position": 245
            }
        ]
    },
    {
        "header": "IVExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.01778/images/nusc_vis.jpg",
                "caption": "Figure 4:nuscenes qualitative results",
                "position": 2457
            },
            {
                "img": "https://arxiv.org/html/2508.01778/images/navsim_vis.jpg",
                "caption": "Figure 5:navsim qualitative results",
                "position": 2470
            }
        ]
    },
    {
        "header": "VConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]