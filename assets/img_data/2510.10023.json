[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10023/x1.png",
                "caption": "Figure 1:STAT is a three-stage skill-based data selection/generation method for supervised fine-tuning (SFT).Stage 1:Identify difficult questions for each model using reward filtering on model responses.Stage 2:Use frontier LLMs to analyze the model responses and build a model-specificMissing-Skill-Profile.Stage 3:Use a pre-constructedSkill-Mapto map the missing skill distribution to a training question distribution, which constitutes the STAT-Sel data. STAT-Syn synthesizes new questions using frontier LLMs targeted to the missing skills.",
                "position": 278
            }
        ]
    },
    {
        "header": "2STAT: Adapting training to model’s missing skills",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10023/x2.png",
                "caption": "Table 3:Improvements on various math benchmarks from applying STAT.\nResults under “+SFT” show the performance of SFT models trained with each method, while “+GRPO” shows the performance after applying GRPO on top of the corresponding SFT models. Our methods, STAT-Sel and STAT-Syn, achieve an average gain of up to6.7%6.7\\%over the base model, with strong OOD performances (AMC23 results reported on average@64, AIME on pass@64). Applying GRPO on top of fine-tuning with STAT further enhances these improvements by4%4\\%. Full results are provided for Llama-3.2-1B-Instruct inSectionD.1,AppendixD.",
                "position": 657
            },
            {
                "img": "https://arxiv.org/html/2510.10023/x2.png",
                "caption": "Figure 2:Comparison among the Top 10 frequent skills present in STAT-Sel, Embed-Sel, and MATH-Train questions selected on Llama-3.2-1B-Instruct. The skills emphasized in both baselines, MATH-Train and Embed-Sel, align poorly with the actual Top 10 missing skills of the model (i.e., skills in STAT-Sel). Furthermore, the missing skills are not necessarily those most common in the original data distribution, as shown by the skill distribution of MATH-Train.",
                "position": 1154
            },
            {
                "img": "https://arxiv.org/html/2510.10023/x3.png",
                "caption": "Figure 3:Continual learning results on MATH-perturb-hard. Further fine-tuning STAT models based on their missing skills on unseen data yields a 3–4%\\%gain (STAT-ConSel/ConSyn).",
                "position": 1192
            }
        ]
    },
    {
        "header": "4Why Skill-Targeted Training Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10023/x4.png",
                "caption": "Figure 4:Trained model performances(Left)and performance gain over base model(Right)on Top 10 frequent missing skills, across training strategies on Llama-3.2-1B-Instruct. Accuracies on the left plot are normalized per skill axis for better visualization. Our approaches STAT-Syn and STAT-Sel are most effective in enhancing model performance across nearly all the skills.",
                "position": 1216
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Works",
        "images": []
    },
    {
        "header": "Appendix BDetails of STAT data creation",
        "images": []
    },
    {
        "header": "Appendix CExperimental details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10023/x5.png",
                "caption": "Table 7:Improvements on various math benchmarks from applying STAT.\nResults under ‘+SFT’ show the performance of SFT models trained with each method, while ‘+GRPO’ shows the performance after applying GRPO on top of the corresponding SFT models. Our methods, STAT-Sel and STAT-Syn, achieve an average gain of up to 3.4% over the base model, with strong OOD performances (AMC23 results reported on average@64, AIME on pass@64). Applying GRPO on top of fine-tuning with STAT further enhances these improvements. SeeSection3.1for results on Llama-3.2-3B-Instruct and Qwen2.5-3B.",
                "position": 2795
            },
            {
                "img": "https://arxiv.org/html/2510.10023/x5.png",
                "caption": "Figure 6:Top 10 missing skills of Llama-3.2-3B-Instruct, Llama-3.2-1B-Instruct, and Qwen2.5-3B. The models struggle most with fundamental mathematical skills such as solving equations and basic arithmetic operations.",
                "position": 3058
            },
            {
                "img": "https://arxiv.org/html/2510.10023/x6.png",
                "caption": "Figure 7:Fine-tuned model performances on MATH subjects, across different training methods. For better visualization, accuracies are normalized per skill axis, with the base model drawn as a uniform circle and the highest-performing method on each skill placed at the outer edge. STAT-Syn and STAT-Sel are most effective in enhancing model performance across nearly all the subjects.",
                "position": 3161
            }
        ]
    },
    {
        "header": "Appendix EAblation & Analysis",
        "images": []
    }
]