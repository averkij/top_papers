[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methodology",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20150/x1.png",
                "caption": "Figure 1:Training dynamics on loss, validation metrics, validation in-catalg recommendation ratio with different backbone models during theSFTstage on theReddit-v2dataset.",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x2.png",
                "caption": "Figure 2:Left + Middle: Training dynamics of the reward acquired by ConvRec-R1 with Rank-GRPO on different rank during theRLstage.Right: Comparison of validation NDCG between GRPO and Rank-GRPO (both on-policy) on theReddit-v2dataset.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x3.png",
                "caption": "Figure 3:Training dynamic of reward and validation NDCG between GRPO, GSPO and Rank-GRPO (off-policy) onReddit-v2. See Appendix Fig.5for results with Llama3.2-1B-Instruct.",
                "position": 406
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ADetails for the Remap-Reflect-Adjust Pipeline",
        "images": []
    },
    {
        "header": "Appendix BGradient Analysis for GRPO, GSPO and Rank-GRPO",
        "images": []
    },
    {
        "header": "Appendix CImplementation Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Experimental Details and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.20150/x4.png",
                "caption": "Figure 4:Training dynamics of ConvRec-R1 withLlama3.2-1B-Instructbackbone (on-policy).",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x5.png",
                "caption": "Figure 5:Comparison of training dynamics of reward and validation NDCG between GRPO, GSPO and Rank-GRPO (off-policy) withLlama3.2-1B-Instructbackbone on theReddit-v2dataset.",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x6.png",
                "caption": "Figure 6:Dynamics of percentage of in-catalog recommendations on theReddit-v2validation set.",
                "position": 2153
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x7.png",
                "caption": "Figure 7:Training dynamics on loss, validation metrics, validation in-catalog recommendation ratio with different backbone models during theSFTstage on theRedialdataset.",
                "position": 2169
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x8.png",
                "caption": "Figure 8:Left + Middle: Training dynamics of the reward acquired by ConvRec-R1 with Rank-GRPO on different rank during theRLstage.Right: Comparison of validation NDCG between GRPO and Rank-GRPO (both on-policy) on theRedialdataset.",
                "position": 2172
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x9.png",
                "caption": "Figure 9:Left + Middle: Training dynamics of the reward acquired by ConvRec-R1 with Rank-GRPO on different rank during theRLstage.Right: Comparison of validation NDCG between GRPO and Rank-GRPO (off-policy) on theRedialdataset.",
                "position": 2468
            },
            {
                "img": "https://arxiv.org/html/2510.20150/x10.png",
                "caption": "Figure 10:Sensitivity of Recall@kkfor Rank-GRPO (exp∞\\exp_{\\infty}) toϵo\\epsilon_{o}with Qwen2.5-0.5B-Instruct.",
                "position": 2711
            }
        ]
    },
    {
        "header": "Appendix EDiscussion on Generalization of ConvRec-R1",
        "images": []
    },
    {
        "header": "Appendix FQualitative Examples",
        "images": []
    }
]