[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2OpenAI o1",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06807/x1.png",
                "caption": "Figure 1:Comparing reasoning LLMs OpenAI o1-preview and o1 to gpt-4o onCodeForces.",
                "position": 183
            }
        ]
    },
    {
        "header": "3OpenAI o1-ioi",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06807/extracted/6176040/figures/compute.png",
                "caption": "Figure 2:Additional RL training and additional test-time compute improves competitive mathematics performance.",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2502.06807/x2.png",
                "caption": "Figure 3:Further training OpenAI o1 on coding tasks and incorporating test-time strategies improves performance.",
                "position": 299
            },
            {
                "img": "https://arxiv.org/html/2502.06807/x3.png",
                "caption": "Figure 4:Performance of o1-ioi competing at IOI 2024.",
                "position": 309
            }
        ]
    },
    {
        "header": "4OpenAI o3",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06807/x4.png",
                "caption": "Figure 5:Performance of OpenAI o3 on theCodeForcesbenchmark.",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2502.06807/extracted/6176040/figures/brute_force.png",
                "caption": "Figure 6:o3 testing its own solution. This reflects a sophisticated reasoning strategy that partially implements the hand-designed test-time strategy used for o1-ioi in IOI 2024.",
                "position": 344
            },
            {
                "img": "https://arxiv.org/html/2502.06807/x5.png",
                "caption": "Figure 7:IOI 2024 scores under different submission strategies.Even without human-engineered heuristics or relaxed submission limits, o3 outperforms o1-ioi and surpasses the gold threshold with just 50 submissions.",
                "position": 369
            }
        ]
    },
    {
        "header": "5Software Engineering Evaluations",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06807/x6.png",
                "caption": "Figure 8:HackerRank Astra evaluation.",
                "position": 418
            },
            {
                "img": "https://arxiv.org/html/2502.06807/x7.png",
                "caption": "Figure 9:SWE-bench evaluation.",
                "position": 434
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAuthorship, credit attribution, and acknowledgments",
        "images": []
    },
    {
        "header": "Appendix BAdditionalCodeForcesDetails",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.06807/x8.png",
                "caption": "Figure 10:o3 would place among the best human competitive programmers in the world. Here we show the average solve rate and current rating for participants that entered at least 8 of our 12 unseen test contests. Horizontal lines show performance thresholds from the globalCodeForcesleaderboard of active competitors. The very best humans still solve more problems than AI, for now.",
                "position": 580
            }
        ]
    },
    {
        "header": "Appendix CIOI Submissions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]