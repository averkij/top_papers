[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x1.png",
                "caption": "",
                "position": 75
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x2.png",
                "caption": "Figure 2:PlenopticDreamer Framework.Its core is an autoregressive multi-camera video generator that retrieveskkvideo‚Äìcamera pairs{(ùêèn,ùêïn)}n=1k\\{(\\mathbf{P}^{n},\\mathbf{V}^{n})\\}_{n=1}^{k}from the memory bank using a 3D FOV‚Äìbased retrieval strategy. Conditioned on these retrieved pairs and the target cameraùêèk+1\\mathbf{P}^{k+1}, the model performs noisy scheduling and learnable reconstruction to generate the target videoùêïk+1\\mathbf{V}^{k+1}. To enable long video generation, a portion of the preceding frames inùêïk+1\\mathbf{V}^{k+1}is preserved as clean inputs at a certain ratio during training. Within each DiT block, temporal concatenation is applied to form video tokensùê±\\mathbf{x}as in-context condition.",
                "position": 136
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x3.png",
                "caption": "Figure 3:FOV-based Retrieval Comparison.Unlike prior frame-level retrieval methods[65,60], ours computes robust video-level similarity by averaging frame-wise similarities.",
                "position": 265
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x4.png",
                "caption": "Figure 4:Qualitative Comparison on the Basic Benchmark.PlenopticDreamer generates high-fidelity visuals with consistent hallucinations from different camera trajectories. In contrast, ReCamMaster and TrajectoryCrafter fail to preserve spatio-temporal consistency while maintaining visual quality, especially under large-angle viewpoint changes, such as leftward azimuth shifts.",
                "position": 551
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x5.png",
                "caption": "Figure 5:Qualitative Results on the Agibot Benchmark.Given a head-view manipulation video in Agibot, PlenopticDreamer-agibot (Ours) can generate temporally consistent videos from the left and right gripper viewpoints.",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x6.png",
                "caption": "Figure 6:Ablation Study.Qualitative visualization of effects from different training strategies and context retrieval method.",
                "position": 705
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x7.png",
                "caption": "Figure 7:Long Video Generation.Given a leftward rotation camera trajectory, ours (w/ LVG Cond.) preserves spatial consistency across adjacent video chunks, yielding seamless transitions at their boundaries (highlighted by red dotted lines).",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x8.png",
                "caption": "Figure 8:Focal Length Effect.Our method simulates varying depth-of-field effects corresponding to different focal lengths (18mm‚Üí\\rightarrow100mm) under a ‚Äúzoom-in‚Äù camera trajectory.",
                "position": 829
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AMore Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x9.png",
                "caption": "Figure S1:Image Matching Result.The red points indicate the matched pixel correspondences across the input images..",
                "position": 1005
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x10.png",
                "caption": "Figure S2:Full Camera Trajectories on the Basic Benchmark.The sequence proceeds as: (1) Rotation Left‚Üí\\rightarrow(2) Arc Right (w/ Rot.)‚Üí\\rightarrow(3) Azimuth Right‚Üí\\rightarrow(4) Rotation Right‚Üí\\rightarrow(5) Arc Left (w/ Rot.)‚Üí\\rightarrow(6) Azimuth Left‚Üí\\rightarrow(7) Tilt Up‚Üí\\rightarrow(8) Translate Down (w/ Rot.)‚Üí\\rightarrow(9) Tilt Down‚Üí\\rightarrow(10) Translate Up (w/ Rot.)‚Üí\\rightarrow(11) Elevation Up‚Üí\\rightarrow(12) Zoom Out.",
                "position": 1099
            }
        ]
    },
    {
        "header": "Appendix BMore Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05239/x11.png",
                "caption": "Figure S3:More Visual Results on the Basic Benchmark.Our method generates consistent hallucinated context in unseen region.",
                "position": 1110
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x12.png",
                "caption": "Figure S4:More Qualitative Comparison on the Basic Benchmark.The figures above and below correspond to frames 54 and 88, respectively. Please check full videos on the website provided in the website.",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x13.png",
                "caption": "Figure S5:More Visual Results on the Agibot Benchmark.The sequence proceeds as: (1) Left-gripper View‚Üí\\rightarrow(2) Right-gripper View.",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x14.png",
                "caption": "Figure S6:More Qualitative Comparison on the Agibot Benchmark.The figures above and below correspond to frames 24 and 93, respectively. Compared to our method, ReCamMaster* exhibits noticeably stronger object distortion and inconsistency.",
                "position": 1119
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x15.png",
                "caption": "Figure S7:More Long Video Generation Results under Dynamic and Static Novel-Camera Settings.",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2601.05239/x16.png",
                "caption": "Figure S8:More Focal Length Effect Results.Our method synthesizes depth-of-field variations across focal lengths (18mm‚Üí\\rightarrow100mm). Shorter focal lengths produce more greater changes in the resulting field-of-view (FOV).",
                "position": 1125
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]