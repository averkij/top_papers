[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x1.png",
                "caption": "",
                "position": 134
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x2.png",
                "caption": "Figure 2:Motivation.Previous finetuning approaches[15,30]often fail to generate continuous scenes near the pole due to the limited ERP dataset.\nThe tuning-free approach[18]also fails to generate a seamless frame due to the ERP latent representation.",
                "position": 168
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x3.png",
                "caption": "Figure 3:Overall Pipeline.We initialize uniform spherical latents and extract perspective latents for multiple views at each denoising step using dynamic latent sampling. These latents are then denoised and fused using the MultiDiffusion[2]with distortion-aware weighted averaging. This process enables seamless and distortion-free 360-degree panoramic image and video generation in a tuning-free manner.",
                "position": 201
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x4.png",
                "caption": "Figure 4:Comparison of ERP and Spherical Latent Representations.When changing perspective, the ERP latent representation shows significant density variations in latent density depending on position, especially near the poles, while our spherical representation maintains a nearly uniform density across all perspectives.",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x5.png",
                "caption": "Figure 5:Comparison of Nearest and Dynamic Sampling.Nearest sampling oftenresamples the selected latentsoromits central ones, while dynamic sampling selects latents from the center outward, discarding only the outermost ones.",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x6.png",
                "caption": "Figure 6:Qualitative results of our method.Visualization results for the entire scene using the ERP representation and 3 perspectives views across various elevation multiple perspective images or frames. Additional results are available in the supplementary materials.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x7.png",
                "caption": "",
                "position": 538
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x8.png",
                "caption": "Figure 7:Qualitative comparison of all image and video baselines.Each sample presents perspective images from the top view to the bottom view, highlighting end-to-end continuity and distortion. Other methods exhibit noticeable artifacts, such as split seams, severe distortions near the poles, blurriness, or spots due to inadequate handling of these issues. In contrast, our method generates seamless, high-quality panoramic content without such artifacts.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x9.png",
                "caption": "Figure 8:Ablation on latent sampling and weighted averaging.Nearest sampling lacks information exchange between views, leading to inconsistencies and visible overlap artifacts caused byundersampling problem. In contrast, dynamic sampling facilitates information sharing, resulting in more integrated outputs. With weighted averaging, both sampling methods improve seamlessness. However, nearest sampling still fails to maintain connectivity between adjacent regions, leading to discontinuities.",
                "position": 892
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AAppendix",
        "images": []
    },
    {
        "header": "BSpherical Latent Sampling",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x10.png",
                "caption": "Figure 9:Similarities between positional embeddings calculated with discrete and continuous positions.The small squares represent the similarity distribution when the central pixel is used as a query. As shown in the figure, when discretization is applied, within the same row or column, resulting in high similarity. However, when positions vary slightly (as in the continuous case), the similarity drops significantly.",
                "position": 1427
            }
        ]
    },
    {
        "header": "CExperimental Details",
        "images": []
    },
    {
        "header": "DAdditonal Qualitative/Quantitative Comparison",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.14396/x11.png",
                "caption": "Figure 10:Comparison with spherical and ERP.The red box highlights blurry artifacts that appear near the polar regions. As the number of view directions decreases, more latents remain unsampled and unprocessed during denoising, making the issue more severe.",
                "position": 1553
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x12.png",
                "caption": "Figure 11:Additional Qualitative Results (Images)",
                "position": 1556
            },
            {
                "img": "https://arxiv.org/html/2504.14396/x13.png",
                "caption": "Figure 12:Additional Qualitative Results (Videos). The animated results are available on our project page.",
                "position": 1559
            }
        ]
    },
    {
        "header": "EImplementation Details",
        "images": []
    }
]