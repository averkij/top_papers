[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10792/x1.png",
                "caption": "Figure 1:Rectified flows for image inversion and editing.Our approach efficiently inverts reference style images in (a) and (b) without requiring text descriptions of the images and applies desired edits based on new prompts (e.g. â€œa girlâ€ or â€œa dwarfâ€).\nFor a reference content image (e.g. a cat in (c) or a face in (d)), it performs semantic image editing (e.g. â€œsleeping catâ€) and stylization (e.g. â€œa photo of a cat in origmai styleâ€) based on prompts, without leaking unwanted content from the reference image. Input images have orange borders.",
                "position": 91
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10792/x2.png",
                "caption": "Figure 2:Graphical model illustrating (a) DDIM inversion and (b) RF inversion.\nDue to nonlinearities in DM trajectory, the DDIM inverted latentğ±1subscriptğ±1{\\mathbf{x}}_{1}bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTsignificantly deviates from the original imageğ²0subscriptğ²0{\\mathbf{y}}_{0}bold_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT.\nRF inversion without controller reduces this deviation, resulting inğ±1subscriptğ±1{\\mathbf{x}}_{1}bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nWith controller, RF inversion further eliminates the reconstruction error, makingğ±1subscriptğ±1{\\mathbf{x}}_{1}bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTnearly identical toğ²0subscriptğ²0{\\mathbf{y}}_{0}bold_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, which enhances the faithfulness.",
                "position": 159
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Algorithm: Inversion and Editing via Controlled ODEs",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10792/x3.png",
                "caption": "Figure 3:Inverting flows by controlled ODEsÂ (8) and (15).",
                "position": 654
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x4.png",
                "caption": "Figure 4:Effect of controller guidanceÎ·ğœ‚\\etaitalic_Î·given the original image and the prompt: â€œA young manâ€.\nIncreasingÎ·ğœ‚\\etaitalic_Î·improves the faithfulness to the original image, which is reconstructed atÎ·=1ğœ‚1\\eta\\!=\\!1italic_Î· = 1.",
                "position": 673
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x5.png",
                "caption": "Figure 5:Stroke2Image generation.Our method generates photo-realistic images of bedroom or church given stroke paints, showing robustness to initial corruptions.",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x6.png",
                "caption": "Figure 6:Image editing for adding face accessories.Prompt: â€œface of a man/woman wearing glassesâ€.\nThe proposed method better preserves the identity while applying the desired edits.",
                "position": 685
            }
        ]
    },
    {
        "header": "5Experimental Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10792/x7.png",
                "caption": "Figure 7:Editing (a) stylized expression, (b) age, (c) gender, and (d) object insert.\nGiven an original image and a text prompt, our algorithm performs semantic image editing in the wild.",
                "position": 735
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x8.png",
                "caption": "Figure 8:Comparison using Flux backbone.",
                "position": 842
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Broader Impact Statement",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Theoretical Results",
        "images": []
    },
    {
        "header": "Appendix BTechnical Proofs",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.10792/x9.png",
                "caption": "Figure 9:Effect of starting time.Prompt: â€œA young manâ€.\nThe number below each figure denotes the starting time scaled by 28 (the total number of denoising steps) for better interpretation.\nIn the absence of controller guidance (Î·t=0subscriptğœ‚ğ‘¡0\\eta_{t}=0italic_Î· start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0), increasing the starting time (sğ‘ sitalic_s) in our controlled ODEÂ (15) improves faithfulness to the original image.",
                "position": 2754
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x10.png",
                "caption": "Figure 10:Effect of controller guidance.Prompt: â€œA young manâ€.\nFor a fixed starting times=0ğ‘ 0s=0italic_s = 0, consider a time-varying controller guidance scheduleÎ·t=Î·â¢âˆ€tâ‰¤Ï„subscriptğœ‚ğ‘¡ğœ‚for-allğ‘¡ğœ\\eta_{t}=\\eta~{}\\forall t\\leq\\tauitalic_Î· start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_Î· âˆ€ italic_t â‰¤ italic_Ï„and00otherwise.\nThe number below each figure denotes the stopping timeÏ„ğœ\\tauitalic_Ï„scaled by 28 (the total number of denoising steps) for better interpretation.\nIncreasingÏ„ğœ\\tauitalic_Ï„increases the controller guidance (Î·tsubscriptğœ‚ğ‘¡\\eta_{t}italic_Î· start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) that improves faithfulness to the original image.",
                "position": 2768
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x11.png",
                "caption": "Figure 11:Effect of controller guidancefor another time-varying schedule.\nPrompt: â€œA young manâ€.\nThe number below each figure denotes the starting time scaled by 28 (the total number of denoising steps) for better interpretation.\nFor a fixed starting times=0ğ‘ 0s=0italic_s = 0and stopping timeÏ„=8ğœ8\\tau=8italic_Ï„ = 8, consider a time-varying controller guidance scheduleÎ·t=Î·â¢âˆ€tâ‰¤Ï„subscriptğœ‚ğ‘¡ğœ‚for-allğ‘¡ğœ\\eta_{t}=\\eta~{}\\forall t\\leq\\tauitalic_Î· start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_Î· âˆ€ italic_t â‰¤ italic_Ï„and00otherwise.\nIncreasingÎ·ğœ‚\\etaitalic_Î·increases the controller guidance (Î·tsubscriptğœ‚ğ‘¡\\eta_{t}italic_Î· start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT) that improves faithfulness to the original image.",
                "position": 2782
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x12.png",
                "caption": "(a)DDPM (13) Fwd.",
                "position": 2878
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x12.png",
                "caption": "(a)DDPM (13) Fwd.",
                "position": 2881
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x13.png",
                "caption": "(b)DDIM (14) Fwd.",
                "position": 2886
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x14.png",
                "caption": "(c)SDEÂ (12) Fwd.",
                "position": 2891
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x15.png",
                "caption": "(d)RF (6) Fwd.",
                "position": 2896
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x16.png",
                "caption": "(e)DDPM (13) Rev.",
                "position": 2902
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x17.png",
                "caption": "(f)DDIM (14) Rev.",
                "position": 2907
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x18.png",
                "caption": "(g)SDE (12) Rev.",
                "position": 2912
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x19.png",
                "caption": "(h)RF (6) Rev.",
                "position": 2917
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x20.png",
                "caption": "(a)ODE (8) Fwd.",
                "position": 2929
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x20.png",
                "caption": "(a)ODE (8) Fwd.",
                "position": 2932
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x21.png",
                "caption": "(b)ODE (15) Rev.",
                "position": 2937
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x22.png",
                "caption": "(c)SDE (10) Fwd.",
                "position": 2942
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x23.png",
                "caption": "(d)SDE (17) Rev.",
                "position": 2947
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x24.png",
                "caption": "Figure 14:Stroke2Image generation.Additional qualitative results on LSUN-Bedroom dataset comparing our method with SoTA training-free and training-based editing approaches.",
                "position": 2967
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x25.png",
                "caption": "Figure 15:Stroke2Image generation.Additional qualitative results on LSUN-Church dataset comparing our method with SoTA training-free and training-based editing approaches.",
                "position": 2973
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x26.png",
                "caption": "Figure 16:Robustness.For inversion, all methods perform well at recovering the stroke input when given a null prompt. However, when a new prompt like â€œa photo-realistic picture of a bedroomâ€ is provided, only our method successfully generates realistic images. The other methods continue to suffer from the initial corruption, failing to make the output more realistic.",
                "position": 2984
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x27.png",
                "caption": "Figure 17:Gender editing.Our method smoothly interpolates between â€œA manâ€â†”â†”\\leftrightarrowâ†”â€œA womanâ€.",
                "position": 2997
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x28.png",
                "caption": "Figure 18:Age editing.Our method regulates the extent of age editing.",
                "position": 3007
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x29.png",
                "caption": "Figure 19:Object insert.Text-guided insertion of multiple objects sequentially.",
                "position": 3018
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x30.png",
                "caption": "Figure 20:Stylization using reference text.Stylization of a reference image given prompt-based facial expressions in â€œdisney 3d cartoon styleâ€.",
                "position": 3030
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x31.png",
                "caption": "Figure 21:Stylization using a single reference image and various text prompts.Given a reference style image (e.g. â€œmelting golden 3d renderingâ€ at the top) and various text prompts (e.g. â€œa dwarf in melting golden 3d rendering styleâ€), our method generates images that are consistent with the reference style image and aligned with the given text prompt.",
                "position": 3040
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x32.png",
                "caption": "Figure 22:Stylization using a single prompt and various reference style images:â€œmelting goldenâ€, â€œline drawingâ€, â€œ3d renderingâ€, and â€œwooden sculptureâ€.\nGiven a style image (e.g. â€œ3d renderingâ€) and a text prompt (e.g. â€œface of a boy in 3d rendering styleâ€), our method generates images that are consistent with the reference style image and the text prompt.\nThe standard output from Flux is obtained by disabling our controller, which clearly highlights the importance of the controller.",
                "position": 3049
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x33.png",
                "caption": "Figure 23:Interface for human evaluation.Each participant is asked to select their preferred image based on two criteria:realismandfaithfulness.",
                "position": 3056
            },
            {
                "img": "https://arxiv.org/html/2410.10792/x34.png",
                "caption": "Figure 24:T2I generationusing rectified SDEÂ (22) for different number of discretization steps marked along the X-axis. The stochastic equivalent sampler FluxSDE generates samples visually comparable to FluxODE at different levels of discretization.",
                "position": 3099
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experiments",
        "images": []
    }
]