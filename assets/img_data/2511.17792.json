[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.17792/figs/icon.png",
                "caption": "",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/teaser.png",
                "caption": "",
                "position": 176
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.17792/figs/robot_setup.png",
                "caption": "(a)Quadruped robot hardware setup and communication network.",
                "position": 259
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/robot_setup.png",
                "caption": "(a)Quadruped robot hardware setup and communication network.",
                "position": 262
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/slam.png",
                "caption": "(b)SLAM pipeline for state estimation.",
                "position": 267
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/all_trajectories_plot.png",
                "caption": "(a)All trajectories.",
                "position": 274
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/all_trajectories_plot.png",
                "caption": "(a)All trajectories.",
                "position": 277
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/wordcloud.png",
                "caption": "(b)Word cloud of captions.",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/category.png",
                "caption": "(c)Semantic target categories.",
                "position": 287
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/radar_diagram.png",
                "caption": "(d)Target-Bench Evaluation Results.",
                "position": 292
            }
        ]
    },
    {
        "header": "3Target-Bench",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.17792/figs/data_samples.png",
                "caption": "Figure 4:Data sample visualization.",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/benchmark.png",
                "caption": "Figure 5:Target Benchmark Architecture.",
                "position": 345
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.17792/figs/model_compare_vggt.png",
                "caption": "Figure 6:World model performance comparison with VGGT as world decoderâ€™s spatio-temporal reconstruction tool.",
                "position": 693
            },
            {
                "img": "https://arxiv.org/html/2511.17792/figs/overall_score_comparison.png",
                "caption": "Figure 7:Overall score comparison between different spatio-temporal reconstruction tools. Detailed evaluation results with SpaTracker or ViPE can be found in theappendix.",
                "position": 1173
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    }
]