[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19087/figures/Gemini_multi_spectral_Teaser_figure.png",
                "caption": "Figure 1:We demonstrate here how a generalist Gemini2.5 multimodal model, trained on RGB-only inputs, can be adapted, when queried Zero-Shot and without any training, to understand new and unfamiliar multi-spectral inputs. This improves Gemini’s already strong performance on these tasks and extends its applicability to more Remote Sensing tasks which often rely on extra visual inputs.",
                "position": 69
            }
        ]
    },
    {
        "header": "2Previous work",
        "images": []
    },
    {
        "header": "3Multi-Sensor Zero-Shot Inference",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19087/x1.png",
                "caption": "Figure 2:Examples of the six inputs from BigEarthNet, which is a multi-spectral dataset. The inputs used here are RGB images (Column 1), and five different multi-spectral inputs, represented here as pseudo-color images, so that the model can understand them. Column 2 is constructed from the 8th multi-spectral band, which contains a broader range of the visible and near-infrared spectrum and the 4th and 3rd bands. Column 3 contains an a pseudo image, similar to NDVI, which is sensitive to vegetation. Column 4 shows a set of multi-spectral inputs which are more sensitive to water and Columns 5 and 6 might be also helpful for vegetation.\nWith that simple adaptation and a specialized prompt explaining the process of input generation we easily turn a generic foundational model into a model understanding and performing well on multi-sensor Remote Sensing data.",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x2.png",
                "caption": "",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x3.png",
                "caption": "",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x4.png",
                "caption": "",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x5.png",
                "caption": "",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x6.png",
                "caption": "",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x7.png",
                "caption": "",
                "position": 248
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x8.png",
                "caption": "Figure 3:Examples of the six inputs which are obtained from the multi-spectral EuroSat dataset and represented here as pseudo-color images. See Figure2for description of the images.",
                "position": 254
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x9.png",
                "caption": "",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x10.png",
                "caption": "",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x11.png",
                "caption": "",
                "position": 262
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x12.png",
                "caption": "",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x13.png",
                "caption": "",
                "position": 266
            },
            {
                "img": "https://arxiv.org/html/2509.19087/x14.png",
                "caption": "",
                "position": 268
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2.png",
                "caption": "Figure 4:Example results on the EuroSat data.\nThe multi-spectral inputs are helping for improved performance.Top:The answer provided by the proposed model with multi-spectral inputs is ‘River’ (9), which is the correct answer. Whereas the answer for the RGB-only input is ‘Forest’ (2).\nAs seen by the multi-spectral bands, while the input RGB image has blue/green visible features, the multi-spectral bands are able to detect water (bottom, left-most image which is an NDWI i.e. Normalized Difference Water Index image which is specifically targeting water bodies).Bottom:An example of ‘Forest’ (2) which the multi-spectral model identifies correctly.\nThe baseline model is mistaken focusing on the green/blue and classifies it as a ’Sea lake’ (10) which is incorrect.",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2_1.jpeg",
                "caption": "",
                "position": 576
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2_2.jpeg",
                "caption": "",
                "position": 577
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2_3.jpeg",
                "caption": "",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2_4.jpeg",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri2_5.jpeg",
                "caption": "",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo.png",
                "caption": "",
                "position": 582
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo_1.jpeg",
                "caption": "",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo_2.jpeg",
                "caption": "",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo_3.jpeg",
                "caption": "",
                "position": 585
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo_4.jpeg",
                "caption": "",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_fo_5.jpeg",
                "caption": "",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri.png",
                "caption": "Figure 5:Example results on the EuroSat data where both models are in agreement.Top:Another example of ‘River’ (9) which both models identify correctly.Bottom:Both models are mistaken, the proposed model identifies this as ’Annual crop’ (1), whereas the baseline model classifies it as a ’Sea lake’ . The ground truth is ‘Pasture’ (6).\nAs compared to Figure4, it is quite challenging to correctly identify the only from RGB image.",
                "position": 596
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri_1.jpeg",
                "caption": "",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri_2.jpeg",
                "caption": "",
                "position": 600
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri_3.jpeg",
                "caption": "",
                "position": 601
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri_4.jpeg",
                "caption": "",
                "position": 602
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_ri_5.jpeg",
                "caption": "",
                "position": 603
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa.png",
                "caption": "",
                "position": 605
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa_1.jpeg",
                "caption": "",
                "position": 606
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa_2.jpeg",
                "caption": "",
                "position": 607
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa_3.jpeg",
                "caption": "",
                "position": 608
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa_4.jpeg",
                "caption": "",
                "position": 609
            },
            {
                "img": "https://arxiv.org/html/2509.19087/figures/eurosat/download_pa_5.jpeg",
                "caption": "",
                "position": 610
            }
        ]
    },
    {
        "header": "5Conclusions and future work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional information on example Zero-Shot prompts",
        "images": []
    },
    {
        "header": "Appendix BDataset details",
        "images": []
    }
]