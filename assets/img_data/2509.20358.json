[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20358/x1.png",
                "caption": "Figure 1:We propose PhysCtrl, a novel framework for physics-grounded image-to-video generation with physical material and force control. PhysCtrl supports generating physics-plausible motion trajectories across multiple materials as control signals (second row), and allows controls over physics parameters (e.g.,Youngâ€™s ModulusEEof elastic material (third row)) andforce(last row). Note that in the bottom three rows, overlaid trajectories and frames use lighter hues for earlier time steps and darker hues for later ones.",
                "position": 71
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20358/x2.png",
                "caption": "Figure 2:An overview of PhysCtrl. Given a single image, we first lift the object in that image into 3D points. We then generate physics-grounded motion trajectories conditioned on physics parameters and external force with a diffusion model, which are then used as strong physics-grounded guidance for image-to-video generation.",
                "position": 208
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20358/x3.png",
                "caption": "Figure 3:Our trajectory generation architecture which consists of spatial attention and temporal attention in each block.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2509.20358/x4.png",
                "caption": "Figure 4:Qualitative comparison between our method and existing video generation methods.",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2509.20358/x5.png",
                "caption": "Figure 5:PhysCtrl generates videos of the same object under different physics parameters and forces.",
                "position": 345
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20358/x6.png",
                "caption": "Figure 6:Qualitative results: Compared to baselines, our method enables high-quality and coherent generation of motion sequences from physics conditions and closely matches the reference.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2509.20358/x7.png",
                "caption": "Figure 7:Comparison of using physics loss on trajectory generation. With physics loss, the results are more closely aligned with the reference.",
                "position": 513
            }
        ]
    },
    {
        "header": "6Conclusion and Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BUser Study",
        "images": []
    },
    {
        "header": "Appendix CPhysics Parameter Estimation",
        "images": []
    },
    {
        "header": "Appendix DMore Results",
        "images": []
    },
    {
        "header": "Appendix ESocietal Impacts",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.20358/x8.png",
                "caption": "Figure 8:More qualitative comparison between our method and baselines.",
                "position": 1430
            }
        ]
    },
    {
        "header": "Appendix FData and Model Safeguards",
        "images": []
    }
]