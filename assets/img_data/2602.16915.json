[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16915/x1.png",
                "caption": "Figure 1:Conceptual comparison. The Gated Recurrent Unit (GRU) relies on multiple non-linear gates and candidate statesh~t\\tilde{h}_{t}to update the hidden stateht{h}_{t}. Its complex gating mechanism introduces non-linear recursion that is difficult to analyze for long sequences. The Selective SSM streamlines this into a linear recurrence. By dynamically generating parameters from the inputxtx_{t}, the Selective SSM maintains ”input-dependent selectivity” to adaptively modulate information flow. We leveraged the characteristics of selective SSM to design ConvSS2D, enabling the adaptation iterative process.",
                "position": 109
            }
        ]
    },
    {
        "header": "IIRelated Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16915/x2.png",
                "caption": "Figure 2:Detailed architecture of the StereoAdapter-2: Our model iteratively refines disparity by integrating a Mamba Adapter. The refinement step is powered by the ConvSS2D operator, which enables adaptive and long-range spatial information propagation through multi-directional selective scanning.",
                "position": 175
            }
        ]
    },
    {
        "header": "IIIPreliminaries",
        "images": []
    },
    {
        "header": "IVThe Proposed Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16915/figures/pipeline.png",
                "caption": "Figure 3:Data synthesis pipeline. Semantic-aware style transfer and geometry-consistent novel view synthesis rendering pipeline for UW-StereoDepth-80K dataset.",
                "position": 340
            }
        ]
    },
    {
        "header": "VExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16915/x3.png",
                "caption": "Figure 4:Qualitative results of zero-shot stereo depth estimation",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2602.16915/x4.png",
                "caption": "Figure 5:Qualitative results of zero-shot underwater stereo depth estimation were obtained by deploying the model on a robotic platform.",
                "position": 590
            },
            {
                "img": "https://arxiv.org/html/2602.16915/x5.png",
                "caption": "Figure 6:Hardware platform for real world experiments.",
                "position": 861
            }
        ]
    },
    {
        "header": "VITest-Time Efficiency",
        "images": []
    },
    {
        "header": "VIILimitations and Future Work",
        "images": []
    },
    {
        "header": "VIIIConclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.16915/x6.png",
                "caption": "Figure 7:Qualitative results of zero-shot stereo depth estimation for different models on the SQUID dataset.",
                "position": 2322
            },
            {
                "img": "https://arxiv.org/html/2602.16915/x7.png",
                "caption": "",
                "position": 2335
            },
            {
                "img": "https://arxiv.org/html/2602.16915/x8.png",
                "caption": "Figure 9:Qualitative results of zero-shot stereo depth estimation for different models on the Tartanair Ocean dataset",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2602.16915/x9.png",
                "caption": "Figure 10:Visualization of UW-StereoDepth-80K",
                "position": 2357
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]