[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x1.png",
                "caption": "",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2602.04634/x2.png",
                "caption": "",
                "position": 161
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x3.png",
                "caption": "Figure 1:Comparison of depth and width scaling. While depth scaling enhances performance through sequential multi-turn interactions, width scaling orchestrates multi-agent systems for parallel execution.WideSeek-R1pushes the frontier of width scaling via MARL for synergized orchestration and execution.",
                "position": 166
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x4.png",
                "caption": "Figure 2:Overview ofWideSeek-R1Rollout and Training Pipeline. (1)Rollout: The lead agent coordinates task decomposition while subagents execute parallel subtasks using external tools. (2)Training: We adopt group-level advantage normalization and assign the same advantage to all agents within each multi-agent system, followed by a dual-level advantage reweighting mechanism at both token level and agent level applied to the GRPO objective for effective multi-agent, multi-turn RL training.",
                "position": 249
            }
        ]
    },
    {
        "header": "3WideSeek-R1",
        "images": []
    },
    {
        "header": "4Training Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x5.png",
                "caption": "Figure 3:Overview of our Automated Data Construction Pipeline. The pipeline comprises three stages:\n(1)Query Generation, where we extract user intents from HybridQA(Chenet al.,2020)and refine them into complex, schema-constrained queries that mandate specific table structures and broad coverage;\n(2)Answer Generation, where we prompt the model to generate two responses independently along with the unique column(s), enabling self-consistency verification; and\n(3)QA Pair Filtering, where we rigorously screen the data by discarding instances with low consistency or insufficient difficulty, ensuring that only robust and challenging samples remain in the final dataset.marks the steps powered by thegemini-3-pro-previewAPI.",
                "position": 385
            },
            {
                "img": "https://arxiv.org/html/2602.04634/figs/gemini-icon.png",
                "caption": "",
                "position": 390
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x6.png",
                "caption": "Figure 4:Comparison of depth and width scaling in performance with respect to (w.r.t.) test-time compute. The blue curve shows depth scaling in performance w.r.t. the number of turns (bottom axis), while the two red curves show width scaling in performance w.r.t. the number of subagents (top axis).",
                "position": 599
            },
            {
                "img": "https://arxiv.org/html/2602.04634/x7.png",
                "caption": "Figure 5:Ablation study on lead agent and subagents by assigningWideSeek-R1-4B to different roles.",
                "position": 625
            },
            {
                "img": "https://arxiv.org/html/2602.04634/x8.png",
                "caption": "Figure 6:Ablation study on training data by comparing models trained on hybrid, wide-only, and deep-only datasets.",
                "position": 628
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ALimitation",
        "images": []
    },
    {
        "header": "Appendix BRollout Detail",
        "images": []
    },
    {
        "header": "Appendix CDataset Detail",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.04634/x9.png",
                "caption": "(a)Row Count Distribution",
                "position": 1442
            },
            {
                "img": "https://arxiv.org/html/2602.04634/x9.png",
                "caption": "(a)Row Count Distribution",
                "position": 1445
            },
            {
                "img": "https://arxiv.org/html/2602.04634/x10.png",
                "caption": "(b)Column Count Distribution",
                "position": 1450
            }
        ]
    },
    {
        "header": "Appendix DTraining Detail",
        "images": []
    },
    {
        "header": "Appendix EEvaluation Detail",
        "images": []
    },
    {
        "header": "Appendix FPattern Analysis",
        "images": []
    },
    {
        "header": "Appendix GPrompt Detail",
        "images": []
    }
]