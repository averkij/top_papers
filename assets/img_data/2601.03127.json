[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03127/x1.png",
                "caption": "Figure 1:Challenges in reasoning-aware image generation. Existing models, exemplified by Qwen-Image-Edit, exhibit two failure modes: (1) inaccurate reasoning (without Thinker), leading to logically incorrect edits; and (2) imprecise rendering (with Thinker), where correct reasoning does not translate into faithful visual outputs. Our Unified Thinker aims to address both issues.",
                "position": 131
            },
            {
                "img": "https://arxiv.org/html/2601.03127/x2.png",
                "caption": "Figure 2:Visual demonstrations of Unified Thinker on unified image generative tasks, including image editing and text-to-image generation, along with reasoning.",
                "position": 134
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03127/x3.png",
                "caption": "Figure 3:Data construction pipeline for HieraReason-40K. We combine seed knowledge and user requests to generate structured reasoning traces and executable enhanced prompts.",
                "position": 209
            }
        ]
    },
    {
        "header": "4Framework and Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03127/x4.png",
                "caption": "Figure 4:Our proposed two-stage framework for reasoning-aware image generation. Stage 1 initializes the Thinker Model and Generator Model. Given an Image & Prompt (x), the Thinker generates a Reasoning Thought (y), which then guides the Generator to produce a Refined Image (z). Stage 2 further refines the Thinker and Generator Models to enhance their capability in integrating complex reasoning (y) into high-fidelity visual outputs (z), applicable to both novel image generation and existing image editing tasks.",
                "position": 242
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitations",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03127/critic_score_mean_step_le_400.png",
                "caption": "Figure 5:Mean reward score over training.",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2601.03127/time_step_generate_step_le_400.png",
                "caption": "Figure 6:Per-step rollout generation time over training.",
                "position": 1125
            }
        ]
    },
    {
        "header": "Appendix BSystem Prompt",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03127/x5.png",
                "caption": "Figure 7:Visual demonstrations of UnifiedThinker on unified image generative tasks.",
                "position": 1353
            },
            {
                "img": "https://arxiv.org/html/2601.03127/x6.png",
                "caption": "Figure 8:Visual demonstrations of UnifiedThinker on unified image generative tasks.",
                "position": 1357
            },
            {
                "img": "https://arxiv.org/html/2601.03127/x7.png",
                "caption": "Figure 9:Visual demonstrations of UnifiedThinker on unified image generative tasks.",
                "position": 1361
            }
        ]
    },
    {
        "header": "Appendix CDetails of HieraReason-40K",
        "images": []
    }
]