[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02056/x1.png",
                "caption": "Figure 1:Performance comparison of Synthio with other augmentation methods on down-sampled ESC-50 (100 samples). Traditional augmentation, such as SpecAug, degrades performance on small-scale datasets. Naive synthetic augmentation outperforms traditional methods significantly but plateaus with higher sample counts. Synthio further enhances performance by generating consistent and diverse synthetic data.",
                "position": 105
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02056/x2.png",
                "caption": "Figure 2:We propose to align the T2A modelùíØŒ∏superscriptùíØùúÉ\\mathcal{T}^{\\theta}caligraphic_T start_POSTSUPERSCRIPT italic_Œ∏ end_POSTSUPERSCRIPTwith the small-scale datasetùíüsmallsubscriptùíüsmall\\mathcal{D}_{\\text{small}}caligraphic_D start_POSTSUBSCRIPT small end_POSTSUBSCRIPTusing DPO. This helps us generate audios with acoustic characteristics aligned to that ofùíüsmallsubscriptùíüsmall\\mathcal{D}_{\\text{small}}caligraphic_D start_POSTSUBSCRIPT small end_POSTSUBSCRIPT.",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2410.02056/x3.png",
                "caption": "Figure 3:Overview of our proposedLanguage-Guided Audio Imaginationfor generating diverse synthetic augmentations. Starting with the small-scale dataset, we first generate audio captions and use an LLM to extract acoustic components (Prompt 1). Using these components and audio labels, we prompt the LLM to generate new and diverse captions (Prompt 2), which are then used to prompt the aligned T2A model for audio generation. The generated audios are filtered for label consistency using CLAP, with accepted audios added to the final synthetic dataset. Rejected audios undergo caption revision (Prompt 3) through a self-reflection process, and the revised captions are used to regenerate audios, iterating this processiùëñiitalic_itimes. Example captions are in Table6.",
                "position": 327
            }
        ]
    },
    {
        "header": "5Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02056/x4.png",
                "caption": "Figure 4:Comparison of spectral and pitch features between generated audios inùíüsynsubscriptùíüsyn\\mathcal{D}_{\\text{syn}}caligraphic_D start_POSTSUBSCRIPT syn end_POSTSUBSCRIPTand real audios inùíüsmallsubscriptùíüsmall\\mathcal{D}_{\\text{small}}caligraphic_D start_POSTSUBSCRIPT small end_POSTSUBSCRIPT(fornùëõnitalic_n= 100). Synthio-generated audios closely replicate the features of real data, demonstrating its ability to produce augmentations that maintain consistency with the original dataset (also see FAD scores in Sec.A.4.3).",
                "position": 3400
            }
        ]
    },
    {
        "header": "6Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02056/x5.png",
                "caption": "Figure 5:Category-wise improvement in performance with Synthio augmentations for long-tailed categories.",
                "position": 3804
            }
        ]
    },
    {
        "header": "7Conclusion, Limitations, and Future Work",
        "images": []
    },
    {
        "header": "8Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.02056/x6.png",
                "caption": "Figure 6:LLM prompt (Prompt 1) for extracting components from audio captions.",
                "position": 4838
            },
            {
                "img": "https://arxiv.org/html/2410.02056/x7.png",
                "caption": "Figure 7:LLM prompt (Prompt 2) for generating new audio captions given elements from existing captions.",
                "position": 4841
            },
            {
                "img": "https://arxiv.org/html/2410.02056/x8.png",
                "caption": "Figure 8:LLM prompt for generating random captions for Random Captions baselines in Table1.",
                "position": 4844
            },
            {
                "img": "https://arxiv.org/html/2410.02056/x9.png",
                "caption": "Figure 9:LLM prompt (Prompt 3) for rewriting captions of rejected audios.",
                "position": 4847
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]