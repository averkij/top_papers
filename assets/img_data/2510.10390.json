[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x1.png",
                "caption": "Figure 1:The RefusalBench pipeline transforms base QA datasets into diagnostic benchmarks through systematic linguistic perturbations using language models. The generator-verifier architecture ensures quality at scale.",
                "position": 301
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3The RefusalBench Methodology",
        "images": []
    },
    {
        "header": "4Experiments and Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x2.png",
                "caption": "Figure 2:Stratified coverage heatmaps for both benchmarks.Left:RefusalBench-NQ demonstrates balanced distribution of 1,600 samples across all 18 perturbation types and intensities.Right:RefusalBench-GaRAGe exhibits naturally imbalanced distribution of 1,506 samples across perturbation types.",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x3.png",
                "caption": "Figure 3:Generator-verifier pass rate matrices reveal significant self-evaluation bias. Models consistently rate their own outputs more favorably than peers.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x4.png",
                "caption": "Figure 4:Generator pass rates reveal universal model capabilities: all models excel at creating explicit logical flaws (EpistemicMismatch, Contradiction, FalsePremise) but struggle with implicit reasoning tasks (Ambiguity and MissingInfo).",
                "position": 541
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x5.png",
                "caption": "Figure 5:Answer vs. Refusal Accuracy of frontier models on both benchmarks. No model achieves excellence (>80%) on both dimensions simultaneously.Left:RefusalBench-NQ.Right:RefusalBench-GaRAGe.",
                "position": 545
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x6.png",
                "caption": "Figure 6:RefusalBench-NQ: Refusal detection F1 vs. category accuracy reveals two distinct sub-skills.",
                "position": 565
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x7.png",
                "caption": "Figure 7:Expected Calibration Error (ECE) decomposition on RefusalBench-NQ. Lower values indicate better calibration. Models show better calibration on refusals than answers.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x8.png",
                "caption": "Figure 8:Average confusion matrices across all models. When models should refuse, they frequently misclassify the refusal type asmissing information.",
                "position": 597
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x9.png",
                "caption": "Figure 9:Scale effects on RefusalBench-NQ. Answer and refusal accuracy show independent model-specific trajectories.",
                "position": 613
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x10.png",
                "caption": "Figure 10:RefusalBench-NQ: Impact of alignment methods on OLMo. DPO improves refusal accuracy over SFT.",
                "position": 624
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x11.png",
                "caption": "Figure 11:Domain-specific performance rankings on RefusalBench-GaRAGe. Models exhibit specialization patterns across professional domains.",
                "position": 633
            }
        ]
    },
    {
        "header": "5Conclusion and Future Work",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Related Work",
        "images": []
    },
    {
        "header": "Appendix BProof of Theorem3.1and Extended Analysis",
        "images": []
    },
    {
        "header": "Appendix CBenchmark Construction and Validation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x12.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2705
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x12.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2708
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x13.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 2713
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x14.png",
                "caption": "Figure 13:Data distribution across the five domains in the final RefusalBench-GaRAGe dataset, showing balanced coverage.",
                "position": 2726
            }
        ]
    },
    {
        "header": "Appendix DDetailed Evaluation Metrics",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x15.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2807
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x15.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2810
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x16.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 2815
            }
        ]
    },
    {
        "header": "Appendix EExtended Generator-Verifier Analysis (Supporting RQ1)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x17.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2906
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x17.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2909
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x18.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 2914
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x19.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2921
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x19.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2924
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x20.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 2929
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x21.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2966
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x21.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 2969
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x22.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 2974
            }
        ]
    },
    {
        "header": "Appendix FExtended Frontier Model Analysis (Supporting RQ2)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x23.png",
                "caption": "Figure 18:Refusal detection F1 vs. category accuracy on RefusalBench-GaRAGe. Bubble size indicates refusal volume. The detection-categorization gap widens compared to RefusalBench-NQ.",
                "position": 3004
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x24.png",
                "caption": "Figure 19:Reliability diagram for RefusalBench-NQ. The diagonal line represents perfect calibration. All models fall below this line, indicating systematic miscalibration.",
                "position": 3053
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x25.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3073
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x25.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3076
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x26.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 3081
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x27.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3100
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x27.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3103
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x28.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 3108
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x29.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3115
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x29.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3118
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x30.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 3123
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x31.png",
                "caption": "Figure 23:Models ranked by refusal accuracy (colored bars) and hierarchical refusal score (blue overlay bars) on RefusalBench-GaRAGe. The hierarchical score combines detection F1 and category accuracy.",
                "position": 3150
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x32.png",
                "caption": "Figure 24:Comprehensive performance metrics for RefusalBench-NQ. Table shows answer accuracy, refusal accuracy, calibrated refusal score (CRS), false refusal rate, missed refusal rate, and correct refusal rate.",
                "position": 3166
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x33.png",
                "caption": "Figure 25:Comprehensive performance metrics for RefusalBench-GaRAGe. Metrics include answer quality score, refusal accuracy, calibrated score, false refusal rate, missed refusal rate, and correct refusal rate.",
                "position": 3169
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x34.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3172
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x34.png",
                "caption": "(a)RefusalBench-NQ",
                "position": 3175
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x35.png",
                "caption": "(b)RefusalBench-GaRAGe",
                "position": 3180
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x36.png",
                "caption": "Figure 27:Answer quality metrics for RefusalBench-GaRAGe on answerable questions only. Shows eligibility score (understanding user intent), unadjusted factuality (support from all passages), and RAF score (support from relevant passages only).",
                "position": 3209
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x37.png",
                "caption": "Figure 28:Confusion matrices for nine frontier models on RefusalBench-NQ at MEDIUM intensity. Darker cells indicate higher frequency. Diagonal cells represent correct classifications.",
                "position": 3229
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x38.png",
                "caption": "Figure 29:Confusion matrices for frontier models on RefusalBench-GaRAGe. Lower diagonal values compared to RefusalBench-NQ indicate increased difficulty in multi-document contexts.",
                "position": 3232
            }
        ]
    },
    {
        "header": "Appendix GStatistical Analysis Details",
        "images": []
    },
    {
        "header": "Appendix HExtended Analysis of Influential Factors (Supporting RQ3)",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.10390/x39.png",
                "caption": "Figure 30:Domain champion analysis on RefusalBench-GaRAGe. Top performers for answer quality score (top) and refusal accuracy (bottom) are shown per domain. No model excels at both tasks within any domain.",
                "position": 3253
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x40.png",
                "caption": "Figure 31:Domain difficulty ranking for RefusalBench-GaRAGe based on average model performance. Higher scores indicate greater difficulty. Answer and refusal difficulties shown separately with overall difficulty as their average.",
                "position": 3256
            },
            {
                "img": "https://arxiv.org/html/2510.10390/x41.png",
                "caption": "Figure 32:Effect of thinking token count on Claude-4-Sonnet performance. Neither answer nor refusal accuracy improves meaningfully with extended reasoning traces, with slight degradation at maximum length.",
                "position": 3277
            }
        ]
    },
    {
        "header": "Appendix IRefusalBench Prompts",
        "images": []
    },
    {
        "header": "Appendix JSoftware, Models, and Packages Used",
        "images": []
    },
    {
        "header": "Appendix KRepresentative Perturbation Lever Catalogue",
        "images": []
    }
]