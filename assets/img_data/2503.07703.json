[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/seedream_2.0_pdf/overall_cn_en.png",
                "caption": "Figure 1:Seedream2.0 demonstrates outstanding performance across all evaluation aspects in bothEnglishandChinese.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/teaser_final.png",
                "caption": "Figure 2:Seedream 2.0 Visualization.",
                "position": 156
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Data Pre-Processing",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/x1.png",
                "caption": "Figure 3:Pre-training data system.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x2.png",
                "caption": "Figure 4:Overview of our knowledge injection process.",
                "position": 353
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x3.png",
                "caption": "Figure 5:Overview of our data cleaning process.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x4.png",
                "caption": "Figure 6:Flow diagram of Active Learning Lifecycle.",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x5.png",
                "caption": "Figure 7:Caption examples in our training data.",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x6.png",
                "caption": "Figure 8:Text Rendering: Data Pre-processing Pipeline.",
                "position": 490
            }
        ]
    },
    {
        "header": "3Model Pre-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/pipeline.png",
                "caption": "Figure 9:Overview of Seedream 2.0 Training and Inference Pipeline.",
                "position": 538
            },
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/arch.png",
                "caption": "Figure 10:Overview of Model Architecture.",
                "position": 547
            }
        ]
    },
    {
        "header": "4Model Post-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/x7.png",
                "caption": "Figure 11:Visualization during different post-training stages.",
                "position": 601
            },
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/Reward.png",
                "caption": "Figure 12:The reward curves show that the values across diverse reward models all exhibit a stable and consistent upward trend throughout the alignment process. Some visualization examples reveal that the human feedback alignment stage is crucial.",
                "position": 670
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x8.png",
                "caption": "Figure 13:PE Visualization. We provide 4 PE prompts for each original prompt.",
                "position": 745
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x9.png",
                "caption": "Figure 14:Refiner Visualization. Recommend to zoom in for the best visualization.",
                "position": 769
            }
        ]
    },
    {
        "header": "5Align to Instruction-Based Image Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/x10.png",
                "caption": "Figure 15:Quantitative ablation of SeedEdit. Left: GPT score v.s. CLIP image similarity. Right: GPT score v.s. AdaFace similarity.",
                "position": 803
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x11.png",
                "caption": "Figure 16:Qualitative comparison of SeedEdit revision. We show here that current approach significantly enhances ID retention.",
                "position": 817
            }
        ]
    },
    {
        "header": "6Model Acceleration",
        "images": []
    },
    {
        "header": "7Model Performance",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/x12.png",
                "caption": "Figure 17:Human Evaluation Results.",
                "position": 905
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x13.png",
                "caption": "Figure 18:EvalMuse Evaluation Results across fine-grained dimensions.",
                "position": 922
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x14.png",
                "caption": "Figure 19:Text Rendering Evaluation.",
                "position": 1403
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x15.png",
                "caption": "Figure 20:Chinese Characteristics Evaluation.",
                "position": 1420
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x16.png",
                "caption": "Figure 21:Response Rate of Chinese Characteristics across Dimensions.",
                "position": 1431
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07703/x17.png",
                "caption": "Figure 22:Chinese Characteristics Comparisons. Our model demonstrates a more accurate understanding and expression of Chinese elements.",
                "position": 1449
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x18.png",
                "caption": "Figure 23:Alignment Comparisons. Seedream and Ideogram 2.0 excel in these two prompts, while other models either struggle with imaginative scenarios or misinterpret quantity and position in the prompts below.",
                "position": 1452
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x19.png",
                "caption": "Figure 24:Structure comparisons. External models encounter issues with the distortion of fingers and limbs under complex movements.",
                "position": 1455
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x20.png",
                "caption": "Figure 25:Aesthetics comparisons. Seedream demonstrates outstanding performance in cinematic scenes and artistic design, while other models show weaker performance in artistic style and texture details.",
                "position": 1458
            },
            {
                "img": "https://arxiv.org/html/2503.07703/x21.png",
                "caption": "Figure 26:Text-Rendering Comparisons. Seedream performs exceptionally well in harmonizing text with content and demonstrates strong typesetting capabilities. Notably, it offers a distinct understanding of scenarios with Chinese characteristics.",
                "position": 1461
            },
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/text_example.jpeg",
                "caption": "Figure 27:Text Rendering by Seedream. Our model presents infinite potential in poster design and artistic creation.",
                "position": 1464
            },
            {
                "img": "https://arxiv.org/html/2503.07703/extracted/6263451/figures/seedream_2.0_pdf/compress_char_show_case.jpeg",
                "caption": "Figure 28:Chinese Characteristics by Seedream. Our model presents impressive representation of Chinese aesthetics.",
                "position": 1467
            }
        ]
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "9Contributions and Acknowledgments",
        "images": []
    }
]