[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/2500th_largest_subgraph.png",
                "caption": "Figure 1:Family trees from the ecosystem dataset. Edges represent different forms of derivative models that are documented as having finetuned, quantized, adapter or merged existing models. Diffusion patterns reveal large broadcasts and numerous generations of derivatives. Graphs without merges are trees, meaning no model has more than one parent (upper left, upper right, and lower left). All graphs are directed and acyclic.",
                "position": 91
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/2500th_largest_subgraph.png",
                "caption": "",
                "position": 94
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/250th_largest_subgraph.png",
                "caption": "",
                "position": 98
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/50th_largest_subgraph.png",
                "caption": "",
                "position": 103
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/25th_largest_subgraph.png",
                "caption": "",
                "position": 107
            }
        ]
    },
    {
        "header": "2A dataset of 1.86 million models on Hugging Face",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/megafigure_aug7.png",
                "caption": "Figure 2:Top ten most frequent licenses, tasks, languages, and libraries (top row). Top ten models ranked by number of children, datasets, arXiv categories of linked papers, and downloaded models (bottom row).",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/802th_largest_subgraph_forpaper2.png",
                "caption": "",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/802th_largest_subgraph_forpaper2.png",
                "caption": "",
                "position": 227
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/growth_rate_plot_withquantizationetc.png",
                "caption": "",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/diff_shorter.png",
                "caption": "Figure 4:Thediffbetween two sequences of model metadata. We measure the overall mutation rate and genetic similarity by tracking rates of overlap and departure between these sequences. The metadata sequence depicted on top is that ofQwen/Qwen1.5-72B, the base model depicted in Figure3; the bottom sequence is one of its finetunes. Additions are shown in green, deletions in red, and substitutions in yellow. This figure depicts character-level mutations corresponding most closely to the Levenshtein distance. We additionally measure and report similarity on term-level representations (using bag-of-words and TF-IDF), which we believe better captures categorical shifts in metadata.",
                "position": 239
            }
        ]
    },
    {
        "header": "3Measuring genetic similarity",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/metadata_finetune_tfidf_aug4.png",
                "caption": "Figure 5:Cosine similarity between TF-IDF embedding vectors, trained on terms appearing in the model metadata for all models in our dataset. Here, we sample finetunes meeting specific family structures. We enumerate all possible sub-trees of size 2 (B), 3 (C), and 4 (D), and enumerate all possible pairs of nodes within these sub-trees. When we compare these genetic similarities to the baseline of the similarity between any two nodes in the graph (A), we find that all observed family ties strongly predict attribute similarity. Similarities between pairs of models suggest that models are more related when they reside at similar depths and when they are topologically close in distance.",
                "position": 267
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/metadata_finetune_tfidf_aug4.png",
                "caption": "Figure 5:Cosine similarity between TF-IDF embedding vectors, trained on terms appearing in the model metadata for all models in our dataset. Here, we sample finetunes meeting specific family structures. We enumerate all possible sub-trees of size 2 (B), 3 (C), and 4 (D), and enumerate all possible pairs of nodes within these sub-trees. When we compare these genetic similarities to the baseline of the similarity between any two nodes in the graph (A), we find that all observed family ties strongly predict attribute similarity. Similarities between pairs of models suggest that models are more related when they reside at similar depths and when they are topologically close in distance.",
                "position": 270
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/drift-drawing-4.jpg",
                "caption": "Figure 6:We observe that siblings exhibit greater similarity in traits than parent-child pairs. This implies not only that there is a high rate of mutation, but that mutations are sufficiently directed.",
                "position": 276
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/rando-icon.png",
                "caption": "Figure 7:The graph contains many instances of some family subtrees. Pairwise similarities within subtrees are estimated via sampling.",
                "position": 282
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/duo-icon.png",
                "caption": "",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/trio-1-icon.png",
                "caption": "",
                "position": 300
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/trio-2-icon.png",
                "caption": "",
                "position": 304
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/quad-0-icon.png",
                "caption": "",
                "position": 308
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/quad-1-icon.png",
                "caption": "",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/quad-2-icon.png",
                "caption": "",
                "position": 316
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/quad-3-icon.png",
                "caption": "",
                "position": 320
            }
        ]
    },
    {
        "header": "4Evolution of traits",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_license_graph_customlayout_n20.png",
                "caption": "Figure 8:An oriented directed network of license mutation drifts (left) and corresponding summary statistics (right). Each node represents a license in our dataset, with directed edges indicating mutations in which a parent and child have different licenses. Drifts seem to be directed from commercial and restrictive licenses to permissive and copyleft licenses.",
                "position": 392
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_license_graph_customlayout_n20.png",
                "caption": "",
                "position": 395
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/model_card_length_and_auto_generated.png",
                "caption": "Figure 9:Even though model cards diminish in length over generations (left), the absolute frequency with which they use the terms ‘automatically generated’ or ‘generated automatically’ increases precipitously (right). These markers of auto-generated cards are uniquely observed in finetunes and adapters, suggesting these are byproducts of existing packages and libraries that enable developers to create finetunes and adaptations, and not those that enable merges and quantizations.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_language_graph_customlayout_n20_save.png",
                "caption": "Figure 10:Network of language mutation drifts (left) and corresponding summary statistics (center). Each node represents compatibility with a language in our dataset, with directed edges indicating mutations in which a parent and child have different language compatibilities. Drifts are directed towards English. We also see considerable diminishing language support over generations (right).",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_language_graph_customlayout_n20_save.png",
                "caption": "",
                "position": 458
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/number_of_compatible_languages.png",
                "caption": "",
                "position": 477
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_task_graph_customlayout_n20.png",
                "caption": "Figure 11:An oriented directed network of task mutation drifts (left) and corresponding summary statistics (right). Each node represents a task in our dataset, with directed edges indicating mutations in which a parent and child have different tasks. There is a high rate of mutation, and the direction of drifts seems to recapitulate the machine learning pipeline.",
                "position": 490
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/top_task_graph_customlayout_n20.png",
                "caption": "",
                "position": 493
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Details on the measures of genetic similarity",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/metadata_finetune_bow_aug4.png",
                "caption": "Figure 12:Bag of Words Cosine Similarity, Metadata.",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/metadata_finetune_levenshtein_aug4.png",
                "caption": "Figure 13:Levenshtein distance based similarity measure on the model metadata.",
                "position": 1359
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/modelcards_finetune_tfidf_aug4.png",
                "caption": "Figure 14:TF-IDF Cosine Similarity, Model Cards.",
                "position": 1362
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/modelcards_finetune_bow_aug4.png",
                "caption": "Figure 15:Bag of Words Cosine Similarity, Model Cards.",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2508.06811/figures/modelcards_finetune_levenshtein_aug8.png",
                "caption": "Figure 16:Levenshtein distance based similarity measure using the model cards. We have reason to believe this is the least reliable measure, as model cards are free text and Levenshtein distance relies heavily on text ordering, making it more suitable for structured strings. Even still, the directional patterns resemble the findings using other metrics.",
                "position": 1368
            }
        ]
    },
    {
        "header": "7Measuring the Mutation Rate",
        "images": []
    },
    {
        "header": "8Structural virality",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/hf_graph_virality_analysis_modelatlas_july142025_2.png",
                "caption": "Figure 17:Scatter plots depicting the maximum depth of every node in the tree (left), the average depth of every node in the tree (center) and the structural virality (right), for trees of various sizes (measured in number of nodes). Structural virality is defined as in[17]for diffusion trees. We use only the first-listed parent for merged models to model our dataset’s connected components as trees.",
                "position": 1397
            }
        ]
    },
    {
        "header": "9Further information on the dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.06811/figures/rando-icon.png",
                "caption": "Table 1:Subgraph patterns, their total occurrences, sampling conditions, and associated multiplicities conditioned on each pattern.nsucc​(u)n_{\\text{succ}}(u)refers to the number of successors (or, equivalently, the out-degree) of nodeuu.",
                "position": 1432
            }
        ]
    },
    {
        "header": "10Further information on sampling subtree topologies",
        "images": []
    }
]