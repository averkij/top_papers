[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10571/x1.png",
                "caption": "Figure 1:Overview of our trust-aware Agentic AI framework for visual classification, illustrating modular agents, orchestration stages, trust calibration, and retrieval-augmented re-evaluation for accurate, interpretable decisions.This workflow is designed for plant leaf disease classification but is generalizable to any RGB image classification task involving multimodal agents and trust-aware decision pipelines.",
                "position": 112
            }
        ]
    },
    {
        "header": "2Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10571/x2.png",
                "caption": "Figure 2:Experiment I – Zero-Shot Performance.(a) Violin plot of model confidence distributions across all classes for Qwen-2.5-VL, GPT-4o, and the orchestrator in the zero-shot configuration (Experiment I). (b) Top-1 classification accuracy comparison of Qwen, GPT, and the orchestrator in Experiment I. (c) Weighted precision scores of all agents in the zero-shot setting. (d) Histogram of raw confidence scores reported by Qwen, GPT, and the orchestrator. (e) Mean confidence scores per agent, aggregated across the entire test set. (f) Weighted recall for each agent in zero-shot inference. (g) Weighted F1-scores for Qwen, GPT, and the orchestrator, highlighting performance balance. (h) Confusion matrix for Qwen-2.5-VL predictions on the evaluation set. (i) Confusion matrix for GPT-4o predictions, revealing inter-class confusion patterns. (j) Confusion matrix for the final orchestrator decision outcomes based on trust-aware arbitration.",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x3.png",
                "caption": "Figure 3:Experiment II – Fine-Tuned Agents.(a) Violin plot of confidence distributions across all classes for Qwen-2.5-VL, GPT-4o, and the orchestrator following supervised fine-tuning.\n(b) Top-1 classification accuracy comparison after agent fine-tuning.\n(c) Weighted precision scores across the three agents, showing enhanced discriminative performance.\n(d) Histogram of raw confidence scores across all predictions, reflecting sharper calibration post fine-tuning.\n(e) Mean confidence scores per agent, showing convergence in self-reported certainty.\n(f) Weighted recall scores for Qwen, GPT, and the orchestrator on the test set.\n(g) Weighted F1-scores highlighting overall performance balance improvements.\n(h) Confusion matrix for Qwen-2.5-VL showing improved inter-class discrimination.\n(i) Confusion matrix for GPT-4o illustrating reduced misclassification frequency.\n(j) Confusion matrix for the orchestrator’s final decisions, demonstrating stability in arbitration after fine-tuning.",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x4.png",
                "caption": "Figure 4:Experiment III – Trust-Aware Orchestration with RAG and Re-Evaluation Loops.(a) Violin plot depicting confidence distributions across all classes for Qwen-2.5-VL, GPT-4o, and the orchestrator in the trust-aware setup with retrieval augmentation and re-evaluation. (b) Accuracy comparison across the three agents under trust-calibrated arbitration. (c) Weighted precision scores for all models following trust-aware reasoning. (d) Histogram of raw confidence outputs from each agent after trust score filtering. (e) Mean confidence values per agent post re-evaluation, showing enhanced calibration and reduced overconfidence. (f) Weighted recall metrics across all models in the final pipeline. (g) Weighted F1-scores reflecting the balance of precision and recall under trust-informed decision-making. (h) Confusion matrix for Qwen-2.5-VL predictions after Image-RAG integration and re-evaluation. (i) Confusion matrix for GPT-4o responses within the trust-aware system. (j) Final decision confusion matrix of the orchestrator, highlighting improvements in accuracy and reduced inter-class confusion due to trust filtering and context-grounded retrieval.",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x5.png",
                "caption": "Figure 5:Time Performance Analysis across Experimental Configurations.a) Boxplot showing inference time distribution per image in Experiment I (zero-shot setting).\nb) Boxplot showing inference time distribution in Experiment II (fine-tuned setting).\nc) Boxplot showing inference time distribution in Experiment III (trust-aware orchestration with RAG).\nd) Histogram of inference time frequencies for Experiment I.\ne) Histogram of inference time frequencies for Experiment II.\nf) Histogram of inference time frequencies for Experiment III.\nThese visualizations highlight how orchestration strategies and model configurations affect latency, offering insight into the computational trade-offs of agentic AI systems.",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x6.png",
                "caption": "Figure 6:Confidence vs. Accuracy Calibration Analysis across Experiments.a) Confidence vs. accuracy plot for Qwen-2.5-VL in Experiment I (zero-shot setting);\nb) Confidence vs. accuracy plot for GPT-4o in Experiment I;\nc) Confidence vs. accuracy plot for the orchestrator in Experiment I;\nd) Confidence vs. accuracy plot for Qwen-2.5-VL in Experiment II (fine-tuned setting);\ne) Confidence vs. accuracy plot for GPT-4o in Experiment II;\nf) Confidence vs. accuracy plot for the orchestrator in Experiment II;\ng) Confidence vs. accuracy plot for Qwen-2.5-VL in Experiment III (trust-aware orchestration with RAG);\nh) Confidence vs. accuracy plot for GPT-4o in Experiment III;\ni) Confidence vs. accuracy plot for the orchestrator in Experiment III.\nThese calibration curves illustrate the alignment between predicted confidence and true accuracy across agents and experimental conditions, highlighting changes in overconfidence and calibration quality.",
                "position": 730
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x7.png",
                "caption": "Figure 7:Agent overconfidence vs. final macro-F1.(a) Experiment I: zero-shot predictions – overconfidence vs. macro-F1 score;\n(b) Experiment II: few-shot predictions – overconfidence vs. macro-F1 score;\n(c) Experiment III: trust-aware orchestration with RAG – overconfidence vs. macro-F1 score, both before and after re-evaluation loop.",
                "position": 743
            }
        ]
    },
    {
        "header": "3Discussion",
        "images": []
    },
    {
        "header": "4Methods",
        "images": []
    },
    {
        "header": "Declarations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix: Supplementary Figures",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.10571/x8.png",
                "caption": "Figure A1:AI agent prompt and response for disease classification.The prompt instructs a vision-language model to classify apple leaf diseases. The response includes the predicted category, natural language justification, self-reported confidence score, processing latency, and estimated computational cost, returned in a structured JSON format.",
                "position": 2057
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x9.png",
                "caption": "Figure A2:Orchestrator prompt and agentic response for decision arbitration.In the agentic AI system, the orchestrator receives classification outputs from multiple vision-language agents and synthesizes them into a single, trusted decision. The JSON-formatted response includes the selected class, rationale for agreement or disagreement, confidence score, processing time, and token-based inference cost.",
                "position": 2060
            },
            {
                "img": "https://arxiv.org/html/2507.10571/x10.png",
                "caption": "Figure A3:Experiment III Trust-aware orchestration with RAG and iterative re-evaluation.This flow diagram illustrates the dynamic reasoning pipeline in which the orchestrator triggers CLIP-based retrieval (Image-RAG) and a re-evaluation loop. Updated agent responses are scored by trust metrics to produce a final decision, enabling improved accuracy and interpretability for plant disease classification.",
                "position": 2064
            }
        ]
    },
    {
        "header": "Appendix: Supplementary Tables",
        "images": []
    }
]