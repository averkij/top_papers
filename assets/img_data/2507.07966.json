[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x1.png",
                "caption": "Figure 1:Training efficiency comparison with MR-SP (SP degree=4) on Qwen2.5-VL-7B and LongVILA-R1-7B and a single node 8×\\times×A100 GPUs. It achieves 2.1×\\times×speed-up and avoids GPU OOM issue on long frames.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x2.png",
                "caption": "Figure 2:Examples of LongVILA-R1. The illustration demonstrates sample tasks and their reasoning. From left to right, the examples include predicting the results of a football match, decision-making reasoning in Texas Hold’em Poker, and trajectory for spatial dynamics of objects. Notably, the spatial tracking video involves a relatively complex dynamic moving, for which the model fails to achieve accurate reasoning until the number of input video frames increases to 128.",
                "position": 123
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x3.png",
                "caption": "Figure 3:Data Distribution of LongVideo-Reason and total data in the LongVILA-R1 training framework. LongVideo-Reason comprises a total of 18,077 videos, from which 52K QAs with reasoning annotations. Additionally, we also include additional 110K QAs from existing works[12,13,14,15,16]for RL training.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x4.png",
                "caption": "Figure 4:Data generation process for the LongVideo-Reason dataset. This process begins with segmenting videos into 10-second clips and generating captions for each clip using NVILA-8B. Then based on the captions of all clips in a video, we generate question-answer pairs that involve reasoning across the content of the whole video, along with the reasoning annotations using a leading open-source reasoning LLM. Reasoning questions are categorized into Temporal, Goal and Purpose, Spatial, and Plot and Narrative. Finally, the reasoning annotations are reformatted for conciseness and alignment with video details. We present a more detailed figure of data generation process in Figure9in the appendix.",
                "position": 164
            }
        ]
    },
    {
        "header": "3LongVideo-Reason Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x5.png",
                "caption": "Figure 5:The LongVILA-R1 training pipeline. LongVILA-R1 builds upon the base training pipeline for LongVILA. MM-SP is further employed for SFT on long video understanding tasks with long CoT. Then, reinforcement scaling learning is conducted through Multi-modal Reinforcement Sequential Parallelism (MR-SP).",
                "position": 186
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x6.png",
                "caption": "Figure 6:LongVILA-R1 RL training framework. The framework integrates multi-modal reinforcement sequence parallelism (MR-SP) for scalable video frame encoding and LLM prefilling. RL utilizes a vLLM-based engine with cached video embeddings, tailored for LongVILA rollout. Rewards for accuracy and format guide policy optimization.",
                "position": 190
            }
        ]
    },
    {
        "header": "4LongVILA Training Pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x7.png",
                "caption": "Figure 7:The workflow of multi-modal reinforcement sequential parallel (MR-SP). To accommodate multi-modal input in reinforcement learning, we develop a custom sharding strategy to ensure balanced workload distribution and compatibility with SP communication. Efficient video embedding reuse and vLLM rollout acceleration strategies are implemented, while meeting the demands of policy model prefilling for dense video frames.",
                "position": 215
            }
        ]
    },
    {
        "header": "5Multi-modal Reinforcement SP",
        "images": []
    },
    {
        "header": "6Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x8.png",
                "caption": "Figure 8:Scaling video frames improves long video reasoning performance against non-reasoning baselines.",
                "position": 749
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Appendix ALimitations",
        "images": []
    },
    {
        "header": "Appendix BBorder Impacts",
        "images": []
    },
    {
        "header": "Appendix CMore Demos in Different Reasoning Subsets",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.07966/x9.png",
                "caption": "Figure 9:Detailed data generation process for the LongVideo-Reason dataset, supplementing Figure4.",
                "position": 852
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x10.png",
                "caption": "Figure 10:Detailed comparisons in the football game example. The video is available atLink.",
                "position": 857
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x11.png",
                "caption": "Figure 11:Detailed comparisons in the moving cup example. The video is available atLink.",
                "position": 861
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x12.png",
                "caption": "Figure 12:LongVILA-R1 reasoning example in the \"Goal and Purpose\" category. The video is available atLink.",
                "position": 865
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x13.png",
                "caption": "Figure 13:LongVILA-R1 reasoning example in the \"Plot and Narrative\" category. The video is available atLink.",
                "position": 869
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x14.png",
                "caption": "Figure 14:LongVILA-R1 reasoning example in the \"Spatial\" category. The video is available atLink.",
                "position": 873
            },
            {
                "img": "https://arxiv.org/html/2507.07966/x15.png",
                "caption": "Figure 15:LongVILA-R1 reasoning example in the \"Temporal\" category. The video is available atLink.",
                "position": 877
            },
            {
                "img": "https://arxiv.org/html/2507.07966/",
                "caption": "Figure 16:LongVILA-R1 reasoning example in the taboo game. The video is available atLink.",
                "position": 881
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]