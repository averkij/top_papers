[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.00955/x1.png",
                "caption": "Figure 1:SemViQA: A Three-Stage Method for semantic-based evidence retrieval and two-step verdict classification, whereP2subscriptùëÉ2P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTandP3subscriptùëÉ3P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTrepresent the probabilities of the two-class and three-class classifications, respectively, andy^2subscript^ùë¶2\\hat{y}_{\\text{2}}over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTandy^3subscript^ùë¶3\\hat{y}_{\\text{3}}over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTdenote their corresponding predictions.",
                "position": 208
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3SemViQA - Semantic Vietnamese Question Answering",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.00955/x2.png",
                "caption": "Figure 2:Graph representing the lengths of contexts.",
                "position": 240
            },
            {
                "img": "https://arxiv.org/html/2503.00955/x3.png",
                "caption": "Figure 3:Long context processing solution.",
                "position": 255
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.00955/x4.png",
                "caption": "Figure 4:Comparison of method performance, balancing accuracy and inference time. Each retrieval method is evaluated based on its highest achieved score, while the total inference time across both datasets is reported to highlight efficiency. Further details can be found in Table2.",
                "position": 1120
            },
            {
                "img": "https://arxiv.org/html/2503.00955/x5.png",
                "caption": "Figure 5:Impact of confidence threshold on evidence retrieval accuracy in SemViQA.",
                "position": 1131
            }
        ]
    },
    {
        "header": "5Conclusion and Future Works",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AStrict Accuracy in Fact-Checking",
        "images": []
    },
    {
        "header": "Appendix BHyperparameter and LLM Training Configuration",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.00955/x6.png",
                "caption": "Figure 6:Training progress of the ViMRClargelarge{}_{\\text{large}}start_FLOATSUBSCRIPT large end_FLOATSUBSCRIPTand InfoXLMlargelarge{}_{\\text{large}}start_FLOATSUBSCRIPT large end_FLOATSUBSCRIPTmodels.",
                "position": 1898
            },
            {
                "img": "https://arxiv.org/html/2503.00955/x7.png",
                "caption": "Figure 7:Training progress of the Qwen 1.5B and Qwen 3B models.",
                "position": 1901
            }
        ]
    },
    {
        "header": "Appendix CComparison of TF-IDF and QATC in Fact-Checking: Examples of Incorrect vs. Correct Evidence Selection",
        "images": []
    }
]