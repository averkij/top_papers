[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18071/extracted/5943765/figs/icon.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18071/x1.png",
                "caption": "(a)Example of prompt sensitivity in multi-modal benchmark.",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x1.png",
                "caption": "(a)Example of prompt sensitivity in multi-modal benchmark.",
                "position": 95
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x2.png",
                "caption": "(b)Framework of TP-Eval.",
                "position": 100
            }
        ]
    },
    {
        "header": "2Multimodal Large Language Model Evaluation",
        "images": []
    },
    {
        "header": "3Related works",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18071/x3.png",
                "caption": "Figure 2:The overview of our automatic prompt customization structure.",
                "position": 249
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18071/x4.png",
                "caption": "Figure 3:Results of different models on MMT-S (L2-category). Accuracy improvement is calculated by accuracy using the optimized prompt divided by accuracy using the original prompt. Three models showed varying improvement across different task types, while performance gains differ between models, highlighting the underestimation and bias introduced by original prompts and the effectiveness of our method.",
                "position": 370
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x5.png",
                "caption": "Figure 4:Overall performance with different prompt methods on MMMU with LLaVA. In most cases, the results after optimization surpass those achieved with the initial prompts, and they generally outperform the original questions as well.",
                "position": 387
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x5.png",
                "caption": "Figure 4:Overall performance with different prompt methods on MMMU with LLaVA. In most cases, the results after optimization surpass those achieved with the initial prompts, and they generally outperform the original questions as well.",
                "position": 390
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x6.png",
                "caption": "Figure 5:Result of applying optimized prompts to other models. Applying customized prompts from one model to another yields performance changes that differ from each model‚Äôs inherent characteristics.",
                "position": 395
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x7.png",
                "caption": "Figure 6:Performance on whether to use introspection or not.",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x7.png",
                "caption": "Figure 6:Performance on whether to use introspection or not.",
                "position": 423
            },
            {
                "img": "https://arxiv.org/html/2410.18071/x8.png",
                "caption": "Figure 7:Influence of re-ranking. Both excessively high and lowŒ±ùõº\\alphaitalic_Œ±can lead to a reduction in performance, and each model achieves optimal performance withŒ±‚àà[0.5,0.6]ùõº0.50.6\\alpha\\in[0.5,0.6]italic_Œ± ‚àà [ 0.5 , 0.6 ].",
                "position": 428
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]