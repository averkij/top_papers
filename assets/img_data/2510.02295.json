[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2VideoNSA",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x1.png",
                "caption": "Figure 1:Overview of VideoNSA. Video frames are encoded into frame-level KV blocks. VideoNSA utilizes three sparse attention branches during prefilling stage:compression branchreduces redundancy via token averaging,selection branchidentifies top-k important tokens, andsliding window branchenforces local temporal coverage. The outputs are combined through dynamic gating before integration with text tokens for LLM decoding.",
                "position": 246
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x2.png",
                "caption": "((a))",
                "position": 611
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x2.png",
                "caption": "((a))",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x3.png",
                "caption": "((b))",
                "position": 635
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x4.png",
                "caption": "((c))",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x5.png",
                "caption": "((d))",
                "position": 647
            }
        ]
    },
    {
        "header": "4Scaling Analysis and Findings",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x6.png",
                "caption": "((a))",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x6.png",
                "caption": "((a))",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x7.png",
                "caption": "((b))",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x8.png",
                "caption": "((c))",
                "position": 780
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x9.png",
                "caption": "((d))",
                "position": 786
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x10.png",
                "caption": "Figure 4:Gate weights across layers in VideoNSA. Compression remains dominant, while selection and sliding-window weaken in later layers.",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x10.png",
                "caption": "Figure 4:Gate weights across layers in VideoNSA. Compression remains dominant, while selection and sliding-window weaken in later layers.",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x11.png",
                "caption": "Figure 5:Inter-head similarities of gates in VideoNSA. Selection and sliding-window gates show high similarity in middle layers.",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x12.png",
                "caption": "Figure 6:Inference latency of each branch in VideoNSA.",
                "position": 850
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x13.png",
                "caption": "Figure 7:Attention sinks distribution of different branches.  VideoNSA maintains a low overall sink ratio, with pink points indicating identified sinks.",
                "position": 867
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x14.png",
                "caption": "Figure 8:Layer-wise attention sink ratio distribution in different branches and Flash Attention.",
                "position": 870
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x14.png",
                "caption": "Figure 8:Layer-wise attention sink ratio distribution in different branches and Flash Attention.",
                "position": 873
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x15.png",
                "caption": "Figure 9:Relative positions of attention sinks in different branches and Flash Attention.",
                "position": 878
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "6Acknowledgement",
        "images": []
    },
    {
        "header": "7Ethics Statement",
        "images": []
    },
    {
        "header": "8Reproducibility Statement",
        "images": []
    },
    {
        "header": "9The Use of Large Language Models",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BDetailed Training Settings",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Benchmarks and Settings",
        "images": []
    },
    {
        "header": "Appendix DMore Results on Long-form Video Benchmarks",
        "images": []
    },
    {
        "header": "Appendix EMore Results on Temporal Reasoning Benchmarks",
        "images": []
    },
    {
        "header": "Appendix FMore Results on Spatial Understanding Benchmarks",
        "images": []
    },
    {
        "header": "Appendix GVisualization of Attention Pattern in Each Branch",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/fig/nsa/layer_28_compression.png",
                "caption": "Figure 10:Attention pattern of the compression branch in the final layer of VideoNSA.",
                "position": 3482
            },
            {
                "img": "https://arxiv.org/html/2510.02295/fig/nsa/layer_28_selection.png",
                "caption": "Figure 11:Attention pattern of the selection branch in the final layer of VideoNSA.",
                "position": 3485
            },
            {
                "img": "https://arxiv.org/html/2510.02295/fig/nsa/layer_28_slidingwindow.png",
                "caption": "Figure 12:Attention pattern of the sliding window branch in the final layer of VideoNSA.",
                "position": 3488
            },
            {
                "img": "https://arxiv.org/html/2510.02295/fig/nsa/layer_28_final.png",
                "caption": "Figure 13:Attention pattern of the final vision attention output in the final layer of VideoNSA.",
                "position": 3491
            }
        ]
    },
    {
        "header": "Appendix HMore Results on Branch Combination",
        "images": []
    },
    {
        "header": "Appendix IMore results on information scaling study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x16.png",
                "caption": "((a))",
                "position": 4509
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x16.png",
                "caption": "((a))",
                "position": 4523
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x17.png",
                "caption": "((b))",
                "position": 4529
            }
        ]
    },
    {
        "header": "Appendix JMore results on attention scaling study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x18.png",
                "caption": "((a))",
                "position": 5810
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x18.png",
                "caption": "((a))",
                "position": 5824
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x19.png",
                "caption": "((b))",
                "position": 5830
            }
        ]
    },
    {
        "header": "Appendix KFull Gate Values Distribution",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x20.png",
                "caption": "Figure 16:Gate weight distribution of each layer.",
                "position": 6782
            }
        ]
    },
    {
        "header": "Appendix LMore Inter-head Gate Similarites Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x21.png",
                "caption": "L0",
                "position": 6789
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x21.png",
                "caption": "L0",
                "position": 6792
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x22.png",
                "caption": "L1",
                "position": 6797
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x23.png",
                "caption": "L4",
                "position": 6803
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x23.png",
                "caption": "L4",
                "position": 6806
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x24.png",
                "caption": "L5",
                "position": 6811
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x25.png",
                "caption": "L8",
                "position": 6817
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x25.png",
                "caption": "L8",
                "position": 6820
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x26.png",
                "caption": "L9",
                "position": 6825
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x27.png",
                "caption": "L12",
                "position": 6831
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x27.png",
                "caption": "L12",
                "position": 6834
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x28.png",
                "caption": "L13",
                "position": 6839
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x29.png",
                "caption": "L16",
                "position": 6845
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x29.png",
                "caption": "L16",
                "position": 6848
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x30.png",
                "caption": "L17",
                "position": 6853
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x31.png",
                "caption": "L20",
                "position": 6859
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x31.png",
                "caption": "L20",
                "position": 6862
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x32.png",
                "caption": "L21",
                "position": 6867
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x33.png",
                "caption": "L24",
                "position": 6873
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x33.png",
                "caption": "L24",
                "position": 6876
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x34.png",
                "caption": "L25",
                "position": 6881
            }
        ]
    },
    {
        "header": "Appendix MMore Analysis about Attention Sinks on Various Sparse Attention Settings",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.02295/x35.png",
                "caption": "((a))",
                "position": 6891
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x35.png",
                "caption": "((a))",
                "position": 6894
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x36.png",
                "caption": "((b))",
                "position": 6900
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x37.png",
                "caption": "((c))",
                "position": 6906
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x38.png",
                "caption": "",
                "position": 6923
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x39.png",
                "caption": "",
                "position": 6926
            },
            {
                "img": "https://arxiv.org/html/2510.02295/x40.png",
                "caption": "",
                "position": 6929
            }
        ]
    },
    {
        "header": "Appendix NDense Attention Sink Visualization",
        "images": []
    }
]