[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00880/x1.png",
                "caption": "Figure 1:HalluGuard Concept.Given a documentxxand a claimcc, the model first thinks before classifying their relationship asgroundedorhallucinated, and then produces a justification citing relevant parts ofxx.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00880/x2.png",
                "caption": "Figure 2:Examples of Relations.A grounded claim, an intrinsic hallucination, and an extrinsic hallucination.",
                "position": 209
            }
        ]
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00880/x3.png",
                "caption": "Figure 3:HalluGuard Training Pipeline.A domain-agnostic corpus is filtered, reformed, and used to generate three types of synthetic claims (grounded, intrinsic hallucinated, and extrinsic hallucinated). Preference data are built via cross-model generation (Qwen3-32B and Qwen3-0.6B), model-agreement verification and LLM-based consensus filtering are used to enhance quality and confidence. The Qwen3-4B backbone is then fine-tuned using LoRA and ORPO to mitigate hallucinations and produce evidence-grounded justifications in RAG applications.",
                "position": 254
            }
        ]
    },
    {
        "header": "5Experimental Setup",
        "images": []
    },
    {
        "header": "6Results",
        "images": []
    },
    {
        "header": "7Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00880/ablation_think_vs_no_think.png",
                "caption": "Figure 5:Effect of Model Reasoning.Radar plot comparing HalluGuard inthinkmode (lighter blue) vs. in/no_thinkmode (darker blue).",
                "position": 933
            }
        ]
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "9Future Work",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATechnical Reproducibility",
        "images": []
    },
    {
        "header": "Appendix BPrompt Template: Style Reformation",
        "images": []
    },
    {
        "header": "Appendix CPrompt Template: Claim Generation",
        "images": []
    },
    {
        "header": "Appendix DPrompt Template: Synthetic Pairs",
        "images": []
    },
    {
        "header": "Appendix EPrompt Template: Consensus Filter",
        "images": []
    },
    {
        "header": "Appendix FBenchmark Datasets",
        "images": []
    },
    {
        "header": "Appendix GReward Gap Across Training Epochs",
        "images": []
    },
    {
        "header": "Appendix HInference Parameters",
        "images": []
    },
    {
        "header": "Appendix IFine-Tuning Configuration",
        "images": []
    },
    {
        "header": "Appendix JORPO Preference Tuple: Full Example",
        "images": []
    }
]