[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20618/x1.png",
                "caption": "Fig. 1:LLMs outputs on the same image: sarcastic explanations diverge across models and prompts, whereas factual descriptions remain stable, highlighting their potential as reliable semantic anchors.",
                "position": 64
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.20618/x2.png",
                "caption": "Fig. 2:The Architecture of GDCNet. The Gated Multimodal Fusion & Classification module integrates discrepancy (FDF_{D}), text (FTF_{T}), and image (FIF_{I}) features to produce the fused representation (FfusedF_{\\text{fused}}).",
                "position": 107
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": []
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]