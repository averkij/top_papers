[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14913/x1.png",
                "caption": "Figure 1:Hybrid discriminative verification techniques (e.g., weighted self-consistency (WSC)(Welleck et al.,2024)and pessimistic verification (PV)(Shi & Jin,2025)) outperform generative pessimistic verification (GPV) under equalized compute budgets of less than 22.5 minutes (shaded region). For example, at latency budgets of 13.8 minutes and 15.7 minutes, hybrid discriminative verification can outperform generative verification by 15.3% and 2.8%, respectively.NNis doubled at each point along the x-axis. For GPV, each solution is verified twice (M=2M=2).",
                "position": 85
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x2.png",
                "caption": "",
                "position": 89
            }
        ]
    },
    {
        "header": "2Effective Discriminative Verification",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14913/x3.png",
                "caption": "Figure 2:Blue:The loss decreases over one epoch of training.Red:The score margin, i.e., the difference in score assigned to correct solutions and incorrect solutions on average across a global batch, increases during training. Together, these indicate that the discriminative verifier learns to discriminate between correct and incorrect solutions.",
                "position": 187
            }
        ]
    },
    {
        "header": "3Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14913/x4.png",
                "caption": "(a)M=1M=1",
                "position": 316
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x5.png",
                "caption": "(a)M=1M=1",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x6.png",
                "caption": "(b)M=2M=2",
                "position": 326
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x7.png",
                "caption": "(c)M=4M=4",
                "position": 331
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x8.png",
                "caption": "(d)M=8M=8",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x9.png",
                "caption": "(e)M=16M=16",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x10.png",
                "caption": "(f)M=32M=32",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x11.png",
                "caption": "(a)N=8N=8",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x12.png",
                "caption": "(a)N=8N=8",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x13.png",
                "caption": "(b)N=16N=16",
                "position": 455
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x14.png",
                "caption": "(c)N=32N=32",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x15.png",
                "caption": "(d)N=64N=64",
                "position": 465
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x16.png",
                "caption": "Figure 5:Left:Unlike BoN, hybrid techniques show consistent but diminishing improvements on AIME2024 from increasing the number of candidate resultsNNsampled from DeepSeek-R1-Distill-Qwen-32B.Right:The performance of DeepSeek-R1-Distill-Qwen-32B on AIME2024 scales logarithmically with the reasoning budget regardless of verification method. Here,N=32N=32.",
                "position": 479
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x17.png",
                "caption": "",
                "position": 484
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x18.png",
                "caption": "",
                "position": 488
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithms",
        "images": []
    },
    {
        "header": "Appendix BAdditional Technical Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.14913/x19.png",
                "caption": "Figure 6:Left:Validation accuracy of PV as a function of the pessimism weightα\\alphafor various numbers of independent candidate solutions(N)(N).Right:Validation accuracy of PV as a function of the pessimism weightα\\alphafor various-sized solver models.",
                "position": 1618
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x19.png",
                "caption": "",
                "position": 1621
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x20.png",
                "caption": "",
                "position": 1625
            },
            {
                "img": "https://arxiv.org/html/2510.14913/x21.png",
                "caption": "Figure 7:Validation accuracy on the held-out set when including vs. excluding reasoning content in verifier inputs for both training and inference.",
                "position": 1638
            }
        ]
    },
    {
        "header": "Appendix CAdditional Ablation Experiments",
        "images": []
    }
]