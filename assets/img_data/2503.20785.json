[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20785/x1.png",
                "caption": "",
                "position": 74
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Free4D",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20785/x2.png",
                "caption": "Figure 2:Overview of Free4D.Given an input image or text prompt, we first generate a dynamic videoğ’±={Iâ¢(t,1)}t=1Tğ’±superscriptsubscriptğ¼ğ‘¡1ğ‘¡1ğ‘‡\\mathcal{V}=\\{I(t,1)\\}_{t=1}^{T}caligraphic_V = { italic_I ( italic_t , 1 ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPTusing an off-the-shelf video generation model[59]. Then, we employ MonST3R[77]with a progressive static point cloud aggregation strategy for dynamic reconstruction, obtaining a 4D geometric structure. Next, guided by this structure, we render a coarse multi-view videoğ’®â€²={{Iâ€²â¢(t,k)}t=1T}k=1Ksuperscriptğ’®â€²superscriptsubscriptsuperscriptsubscriptsuperscriptğ¼â€²ğ‘¡ğ‘˜ğ‘¡1ğ‘‡ğ‘˜1ğ¾\\mathcal{S}^{\\prime}=\\{\\{I^{\\prime}(t,k)\\}_{t=1}^{T}\\}_{k=1}^{K}caligraphic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = { { italic_I start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ( italic_t , italic_k ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPTalong a predefined camera trajectory and refine it intoğ’®={{Iâ¢(t,k)}t=1T}k=1Kğ’®superscriptsubscriptsuperscriptsubscriptğ¼ğ‘¡ğ‘˜ğ‘¡1ğ‘‡ğ‘˜1ğ¾\\mathcal{S}=\\{\\{I(t,k)\\}_{t=1}^{T}\\}_{k=1}^{K}caligraphic_S = { { italic_I ( italic_t , italic_k ) } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPTusing ViewCrafter[76]. To ensure spatial-temporal consistency, we introduce Adaptive Classifer-Free Guidance (CFG) and Point Cloud Guided Denoising for spatial coherence, along with Reference Latent Replacement for temporal coherence. Finally, we propose an efficient training strategy with a Modulation-Based Refinement to lift the generated multi-view videoğ’®ğ’®\\mathcal{S}caligraphic_Sinto a consistent 4D representationâ„›â„›\\mathcal{R}caligraphic_R.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2503.20785/x3.png",
                "caption": "Figure 3:Qualitative comparisons of image-to-4D.We present the results using the same single-image prompts.",
                "position": 397
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20785/x4.png",
                "caption": "Figure 4:Qualitative comparisons of text-to-4D.We show the results based on the same text prompts.",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2503.20785/x5.png",
                "caption": "Figure 5:Qualitative Comparison of Ablation Studies.",
                "position": 420
            },
            {
                "img": "https://arxiv.org/html/2503.20785/x6.png",
                "caption": "Figure 6:Comparison of different methods based on the user study.",
                "position": 548
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BDetails of User Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20785/x7.png",
                "caption": "Figure A:The web interface of our user studies.The input prompt can be either a single image or a short text.",
                "position": 1786
            }
        ]
    },
    {
        "header": "Appendix CDetails of VBench Metrics",
        "images": []
    },
    {
        "header": "Appendix DRuntime Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.20785/x8.png",
                "caption": "Figure B:Failure Case.ViewCrafter[76]struggles with blurred or defocused regions, leading to distortions that propagate into the 4DGS-rendered results.",
                "position": 1868
            }
        ]
    },
    {
        "header": "Appendix ELimitations and Future Work",
        "images": []
    }
]