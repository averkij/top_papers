[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x1.png",
                "caption": "Figure 1:Illustration of the disparity betweenartificial scenariosand areal-world scenarioin VLM safety benchmarking.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x2.png",
                "caption": "Figure 2:An overview ofMemeSafetyBench.1) Dataset Construction(section3):\nUsing an LLM, build a dataset of 50,430 samples defined as realistic harmful and harmless tasks.2) Response Generation(section4.1):\nGenerate a response that aims to evaluate VLM safety across various interaction environments using three settings.3) Safety Evaluation(section4.2):\nEvaluate the responses of the VLM using a safety moderator from three complementary perspectives.",
                "position": 204
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Dataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x3.png",
                "caption": "Figure 3:A safety taxonomy ofMemeSafetyBench. The first level defines general categories of safety risks and the second level enumerates specific task types within each category. All categories, except those designated asHarmless, belong toHarmful.",
                "position": 377
            }
        ]
    },
    {
        "header": "4Evaluation Setup",
        "images": []
    },
    {
        "header": "5Results & Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x4.png",
                "caption": "Figure 4:Model-wise Attack Success Rate (ASR) in percentage across eleven safety categories.",
                "position": 1244
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x5.png",
                "caption": "Figure 5:Trends of safety metrics across different model sizes and response generation settings.\nWe employ InternVL-2.5 family with parameter sizes of 1B, 2B, 4B, 8B, 26B, and 38B.",
                "position": 1262
            }
        ]
    },
    {
        "header": "6Discussion & Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethical Considerations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x6.png",
                "caption": "Figure 6:Example responses from the InternVL2.5 family models (2B, 4B, 26B, 38B) to a harmful prompt, along with the corresponding safety moderator judgments.",
                "position": 2154
            },
            {
                "img": "https://arxiv.org/html/2505.15389/extracted/6462605/figure/img/case_study.jpg",
                "caption": "Figure 7:Example responses generated by LLaVA-1.6-13B (Vicuna) under different interaction scenarios with a harmful instruction: Single-turn without Meme, Single-turn with Meme, and Multi-turn with Meme.",
                "position": 2162
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x7.png",
                "caption": "",
                "position": 2166
            }
        ]
    },
    {
        "header": "Appendix BDataset Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x8.png",
                "caption": "Figure 8:Examples of classified memes and generated instructions by category.",
                "position": 3115
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x9.png",
                "caption": "Figure 9:The t-SNE visualization of instruction embeddings by category.",
                "position": 3129
            }
        ]
    },
    {
        "header": "Appendix CHuman Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x10.png",
                "caption": "Figure 10:A task completion annotation guideline for human annotator.",
                "position": 3176
            },
            {
                "img": "https://arxiv.org/html/2505.15389/extracted/6462605/figure/img/annotation_tool_UI_ex1.png",
                "caption": "Figure 11:(a) User interface of used annotation tool (part 1 of 2). Continued onnext page.",
                "position": 3179
            },
            {
                "img": "https://arxiv.org/html/2505.15389/extracted/6462605/figure/img/annotation_tool_UI_ex2.png",
                "caption": "Figure 12:(b) User interface of used annotation tool (part 2 of 2). Continued fromprevious page.",
                "position": 3182
            }
        ]
    },
    {
        "header": "Appendix DPrompt Details",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details",
        "images": []
    },
    {
        "header": "Appendix FMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15389/x11.png",
                "caption": "Figure 23:Model-wiseRefusal Rate (RR)in percentage across eleven safety categories.",
                "position": 3666
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x12.png",
                "caption": "",
                "position": 3671
            },
            {
                "img": "https://arxiv.org/html/2505.15389/x13.png",
                "caption": "",
                "position": 3674
            }
        ]
    },
    {
        "header": "Appendix GUse of AI assistants",
        "images": []
    }
]