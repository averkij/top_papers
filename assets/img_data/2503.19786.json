[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19786/extracted/6308720/assets/zurich-receipt.jpg",
                "caption": "Figure 1:Example of visual interaction with Gemma 3 27B IT model.",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2503.19786/extracted/6308720/assets/zurich_answer.png",
                "caption": "",
                "position": 130
            }
        ]
    },
    {
        "header": "2Model Architecture",
        "images": []
    },
    {
        "header": "3Instruction-Tuning",
        "images": []
    },
    {
        "header": "4Evaluation of final models",
        "images": []
    },
    {
        "header": "5Ablations",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19786/x1.png",
                "caption": "Figure 2:Summary of the performance of different pre-trained models from Gemma 2 and 3 across general abilities. These plots are meant to give a simplified summary and details are in the appendix.",
                "position": 1045
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x2.png",
                "caption": "",
                "position": 1049
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x3.png",
                "caption": "",
                "position": 1050
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x4.png",
                "caption": "Figure 3:Impact of Local:Global ratioon the perplexity on a validation set.\nThe impact is minimal, even with 7-to-1 local to global.\nThis ablation is run with text-only models.",
                "position": 1062
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x5.png",
                "caption": "Figure 4:Impact of Sliding Windowsize on perplexity measured on a validation set.\nWe consider 2 2B models, with 1:1 and 1:3 local to global layer ratios.\nThis ablation is run with text-only models.",
                "position": 1084
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x6.png",
                "caption": "Figure 5:Model versus KV cache memoryduring inference with a pre-fill KV cache of size 32k.\nWe consider a 2B model with different local to global ratios and sliding window sizes (sw).\nWe compare to global only, which is the standard used in Gemma 1 and Llama.\nThis ablation is run with a text-only model.",
                "position": 1097
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x7.png",
                "caption": "Figure 6:KV cache memory versus context length.We show the memory usage of the KV cache for our architecture (L:G=5:1, sw=1024) and a transformer with global attention only – as used in LLaMa or Gemma 1.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2503.19786/extracted/6308720/assets/lc_all_sizes3.png",
                "caption": "Figure 7:Long contextperformance of pre-trained models before and after RoPE rescaling.",
                "position": 1114
            },
            {
                "img": "https://arxiv.org/html/2503.19786/x8.png",
                "caption": "Figure 8:Small versus large teacher.Relative difference of perplexity when using a small and large teacher as a function of the token size of training. Smaller numbers means distilling from a larger teacher is better.",
                "position": 1121
            }
        ]
    },
    {
        "header": "6Memorization and Privacy",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.19786/x9.png",
                "caption": "Figure 9:Total memorization rates for both exact and approximate memorization. Gemma 3 models memorize significantly less than all prior models. *No results for approximate memorization on these models.",
                "position": 1240
            }
        ]
    },
    {
        "header": "7Responsibility, Safety, Security",
        "images": []
    },
    {
        "header": "8Discussion and Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    }
]