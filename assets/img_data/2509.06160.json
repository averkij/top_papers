[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06160/x1.png",
                "caption": "Figure 1:(Left)Existing methods attempt to build deep reasoning \"forwards\" for a user request through trial-and-error (RL) or costly distillation, which falter in open-ended domains that lack clear, verifiable reward signals.(Right)We propose a third path for teaching deep reasoning, REverse-Engineered Reasoning (REER). REER works “backwards”, recovering plausible human-like thought process from known-good outputs in open-source Question-Answer (QA) pairs.",
                "position": 161
            }
        ]
    },
    {
        "header": "2Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06160/x2.png",
                "caption": "Figure 3:Method Overview: Iterative Local Search for deep reasoning Synthesis.",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2509.06160/x3.png",
                "caption": "Figure 4:Analysis of Token Length & Perplexity Before and After the Search. The leftmost two plots show that our iterative search process consistentlyreduces perplexity (PPL). The rightmost two plots show that the process also tends toincrease the token lengthof the thinking trajectory, reflecting the addition of more detailed reasoning steps.",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2509.06160/x4.png",
                "caption": "Figure 5:Distribution of the final 20K training dataset by categories taking more than 0.5% account. The primary chart shows a diverse range of topics, with a large emphasis onArtisticwriting. The detailed view of \"Artistic\" reveals a focus on Creative Writing and other styles, ensuring comprehensive coverage for open-ended generation.",
                "position": 375
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06160/x5.png",
                "caption": "Figure 6:Qualitative comparison of generation quality. Scores are normalized across five dimensions related to deep thinking. DeepWriter-8B shows a reasoning profile far superior to the open-source baseline and is competitive with top proprietary models.",
                "position": 722
            },
            {
                "img": "https://arxiv.org/html/2509.06160/x6.png",
                "caption": "Figure 7:Comparison of the top 50 thinking pattern frequencies for models trained with and without the injection of human-like thinking patterns during data synthesis. The model with injection (left) shows a more diverse and balanced distribution of patterns, while the model without (right) relies heavily on a few formulaic phrases.",
                "position": 775
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6List of Prompts",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06160/x7.png",
                "caption": "Figure 8:Token Length distribution of Thinking and Answer part of DeepWriter-8B.",
                "position": 2029
            },
            {
                "img": "https://arxiv.org/html/2509.06160/x8.png",
                "caption": "Figure 9:Response String Length Distribution across different models.",
                "position": 2035
            }
        ]
    },
    {
        "header": "7Behavioral Analysis",
        "images": []
    }
]