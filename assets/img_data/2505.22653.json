[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x1.png",
                "caption": "Figure 1:All of (1) standard RL, (2) RL with 40% of the rewards manually flipped to the opposite, and (3) RL with only Reasoning Pattern Rewards (RPR) (i.e., rewards are given whenever key reasoning phrases appear, without verifying the final answer)‚Äîcan improve Qwen-2.5-7B‚Äôs accuracy on MATH-500 from an initial 5% to over 70%.\nThe performance gap between these three setups is minimal compared to the overall improvements.",
                "position": 94
            }
        ]
    },
    {
        "header": "2Noisy verification rewards in math tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x2.png",
                "caption": "Figure 2:The prompt used in math training, where the ‚Äúquestion‚Äù placeholder will be replaced with a specific question.",
                "position": 153
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x3.png",
                "caption": "Figure 3:Accuracy on three test sets during training.\nDue to critic warmup, the actor model is not updated during the first 20 steps; thus, the x-axis begins at step 20.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x4.png",
                "caption": "Figure 4:An illustration of how the reasoning pattern reward works through two example outputs.\nSuppose the red text represents high-frequency phrases that we have pre-identified as indicating key reasoning processes.\nIn the first output, five key phrases are present, so the reward is 5rùëüritalic_r.\nSimilarly, the second output contains four key phrases, so the reward is 4rùëüritalic_r.\nWe do not verify the correctness of the answer.",
                "position": 231
            }
        ]
    },
    {
        "header": "3Noisy reward models in open NLP tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x5.png",
                "caption": "Figure 5:Reward model‚Äôs accuracy across the training.\nCheckpoints at specific steps are used for RL experiments.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x6.png",
                "caption": "Figure 6:The prompt used in the HelpSteer3 task, where the ‚Äúquestion‚Äù and ‚Äúchat history‚Äù placeholders are filled accordingly.",
                "position": 326
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x7.png",
                "caption": "Figure 7:Qwen-2.5-7B trained with an 85%-accurate RM performs similarly to using a 75%-accurate RM, but significantly better than using a 65%-accurate RM.\nThe ‚ÄúNet Win‚Äù refers to the performance advantage of the former RM over the latter.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x8.png",
                "caption": "Figure 8:Reward noise calibration effectively enhances downstream performance.",
                "position": 416
            }
        ]
    },
    {
        "header": "4Related works",
        "images": []
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x9.png",
                "caption": "Figure 10:An example of output in the later stage of RL math training, where only the reasoning pattern reward is used without correctness verification.\nThe model has arrived at the correct answer ‚ÄúA,‚Äù but due to the ongoing reasoning process, the<think>tag remains open, causing the output length to reach the limit and preventing the correct answer from being generated in answer tags.",
                "position": 1122
            }
        ]
    },
    {
        "header": "Appendix AExperiments on Qwen-2.5-3B and Llama-3.1-8B",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x10.png",
                "caption": "Figure 11:Qwen-2.5-3B results for Experiments 1 and 2: Accuracy on three test sets during training.",
                "position": 1139
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x11.png",
                "caption": "Figure 12:(a) Average response length of Qwen-2.5-3B during training with original vs calibrated RMs.\nThe calibrated RMs successfully enable this small-scale model to perform reasoning, whereas the original RMs fail.\n(b) Experiment 3 using Qwen-2.5-3B models trained with calibrated RMs.",
                "position": 1158
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x12.png",
                "caption": "Figure 13:Our calibrated RMs successfully elicit Qwen-2.5-3B‚Äôs reasoning ability, whereas the original RM fails to do so.\nThis figure presents 1 of 2 output cases.\nThe Chinese question translates to:\n‚ÄúPlease design a teaching PowerPoint for teaching elementary school students about [statistical charts]. The overall structure of the PPT should include three parts: introductory activity, developmental activity, and summary activity.\nEach of these activities must include:\nA question that triggers student inquiry, along with an image illustrating the context of the problem.\nA concept explanation (detailed).\nA math hands-on activity using multiple representations, with a clearly listed step-by-step process.\nAt the end of the PPT, include a formative assessment checklist. Each checklist item should start with the symbol \"‚ñ°‚ñ°\\Box‚ñ°\" aligned to the left and should address three aspects: knowledge, skills, and attitudes.\nPlease present the entire PPT in Markdown format with a three-level heading structure.\nFor fractions, use the a/b format as it is easier for me to understand.\nAs for the images, first translate the QUERY into English, and then use the following website with an English query to retrieve the images:https://source.unsplash.com/960x640/?QUERY\nUse Markdown syntax to display the images.‚Äù",
                "position": 1163
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x13.png",
                "caption": "Figure 14:This figure presents the second of two output cases from Qwen-2.5-3B, trained with the calibrated 85%-accurate RM.\nThe model demonstrates reasoning to solve a physics problem.",
                "position": 1178
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x14.png",
                "caption": "Figure 15:Llama-3.1-8B results for Experiments 1 and 2: Accuracy on three test sets during training (Llama-3.1-8B).",
                "position": 1188
            }
        ]
    },
    {
        "header": "Appendix BHuman evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x15.png",
                "caption": "Figure 16:The evaluation prompt for GPT, designed according to the core guidelines for human annotators.\nThe placeholders will be replaced with user-assistant chat history and two models‚Äô responses.",
                "position": 1195
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x16.png",
                "caption": "Figure 17:Human evaluation results and agreements.",
                "position": 1285
            }
        ]
    },
    {
        "header": "Appendix CCase studies",
        "images": []
    },
    {
        "header": "Appendix DLimitations, broader impacts and safety issues",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22653/x17.png",
                "caption": "Figure 18:Œ±=0.1ùõº0.1\\alpha=0.1italic_Œ± = 0.1enables Qwen‚Äôs effective reasoning in HelpSteer3 task.\nThese experiments use the 85%-accurate RM.",
                "position": 1319
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x18.png",
                "caption": "Figure 19:How to create a chatbot using an LLM: the answer from Qwen-2.5-7B trained with the calibrated 85%-accurate RM.",
                "position": 1334
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x19.png",
                "caption": "Figure 20:How to create a chatbot using an LLM: the answer from Qwen-2.5-7B trained with the original 85%-accurate RM.",
                "position": 1337
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x20.png",
                "caption": "Figure 21:How to create a chatbot using an LLM: the answer from Qwen-2.5-7B trained with the calibrated 65%-accurate RM.",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2505.22653/x21.png",
                "caption": "Figure 22:How to create a chatbot using an LLM: the answer from Qwen-2.5-7B trained with the original 65%-accurate RM.",
                "position": 1343
            }
        ]
    },
    {
        "header": "Appendix ERPR weight in calibration",
        "images": []
    }
]