[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13001/x1.png",
                "caption": "Figure 1:Left: Example renders from the BiomedSegFM challenge dataset (original images and segmentation masks) covering five imaging modalities: CT, MRI, microscopy, PET, and ultrasound. Top-right: Sample text prompts. Bottom-right: Key challenges include (1) multi-modal heterogeneity, (2) multi-class segmentation, and (3) target-patch ratio imbalance, causing spatio-textual misalignment, sequential inference inefficiency, and FP/FN errors. Our solutions: channel-wise prompt alignment (2.3),\nparallel spatial prompts (2.3), and dynamic resampling (2.5).",
                "position": 111
            }
        ]
    },
    {
        "header": "2Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13001/x2.png",
                "caption": "Figure 2:Medal S framework pipeline. Multi-scale visual features from the image encoder and text embeddings from the text encoder are fused by a query decoder into adapted embeddings. Parallel spatial prompts (simulated, predicted, or annotated) are processed at native resolution and aligned via channel-wise matching, maintaining full fidelity. This achieves a greater than10×10\\timesspeedup for 24-class segmentation versus sequential processing (see Fig.4) and supports iterative self-refinement for precise segmentation.",
                "position": 163
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results and discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.13001/x3.png",
                "caption": "Figure 3:Comparison of Medal S and ground truth results on the validation set for five different modalities. For each modality, we present both good segmentation results and bad segmentation results.",
                "position": 1157
            },
            {
                "img": "https://arxiv.org/html/2511.13001/x4.png",
                "caption": "Figure 4:Efficiency comparison of spatial prompting strategies. (a) Inference runtime and (b) peak GPU memory consumption versus the number of classes. Parallel prompting achieves minimal time complexity with respect to the number of classes, resulting in a greater than10×10\\timesspeedup for 24-class segmentation over the sequential approach, whose runtime grows substantially. While parallel prompting requires moderately more memory, it remains within practical limits and offers a favorable trade-off for drastic time savings in multi-class scenarios.",
                "position": 1177
            },
            {
                "img": "https://arxiv.org/html/2511.13001/x5.png",
                "caption": "Figure 5:Qualitative comparison of Medal S with different spatial prompt configurations. From left to right: (a) Input Image, (b) Ground Truth, (c) Medal S without spatial prompts, (d) Medal S with Stage-1 prediction as spatial prompts, and (e) Medal S with GT masks as spatial prompts. Each configuration is visualized in axial, coronal, sagittal views and 3D rendering, demonstrating the progressive improvement in segmentation quality with better spatial prompts - particularly in noise reduction, confusion resolution, and continuity enhancement.",
                "position": 1180
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    }
]