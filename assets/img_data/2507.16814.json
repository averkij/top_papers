[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16814/x1.png",
                "caption": "Figure 1:The average pass@1 accuracy of SOPHIA and some representative models across eight benchmarks, as well as their pass@1 accuracy on OlympiadBench, MathVision test, and MMMU Pro. InternVL3.0-38B + SOPHIA significantly improves over its base model, InternVL3.0-38B (Instruct), achieving state-of-the-art performance on most of the benchmarks.",
                "position": 95
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16814/x2.png",
                "caption": "Figure 2:An overview of SOPHIA. SOPHIA samples reasoning trajectoriesğ’šisubscriptğ’šğ‘–\\bm{y}_{i}bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTand calculates rewards for both reasoningRâ¢(ğ’ši)ğ‘…subscriptğ’šğ‘–R(\\bm{y}_{i})italic_R ( bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )and visual understandingRâ¢(ğ’„i)ğ‘…subscriptğ’„ğ‘–R(\\bm{c}_{i})italic_R ( bold_italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Finally, it updates the LVLM policy via an off-policy method to cultivate visual slow-thinking reasoning abilities.",
                "position": 101
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Semi-off-Policy Reinforcement Learning",
        "images": []
    },
    {
        "header": "5Implementation",
        "images": []
    },
    {
        "header": "6Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16814/x3.png",
                "caption": "Figure 3:The performance of InternVL3.0-38B and InternVL3.0-38B+SOPHIA on MMMU Pro and MathVision over 480 training steps, where the green and blue solid lines represent their respective pass@1 accuracy, while the dashed lines indicate the base model performance.",
                "position": 789
            }
        ]
    },
    {
        "header": "7Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATheoretical Analysis",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix DAdditional Experiment on SOPHIA",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.16814/x4.png",
                "caption": "Figure A1:Examples of different response styles. (a) is the QwQ Preview response style and (b) is the DeepSeek-R1 response style.",
                "position": 2593
            }
        ]
    },
    {
        "header": "Appendix EPrompt",
        "images": []
    },
    {
        "header": "Appendix FLimitations",
        "images": []
    },
    {
        "header": "Appendix GBroader Impacts",
        "images": []
    }
]