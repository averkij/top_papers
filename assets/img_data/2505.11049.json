[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11049/x1.png",
                "caption": "(a)Prompt Harmfulness Detection Task.",
                "position": 110
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x1.png",
                "caption": "(a)Prompt Harmfulness Detection Task.",
                "position": 113
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x2.png",
                "caption": "(b)Response Harmfulness Detection Task.",
                "position": 118
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2GuardReasoner-VL",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/1_over_view_2.png",
                "caption": "Figure 2:Overview Training Pipeline of GuardReasoner-VL.It mainly contains three processes, including data curation, model cold-start, and online RL. Concretely, we first build a reasoning corpus, which contains 123K samples with 631K reasoning steps, spanning text, image, and text-image modalities. We cold-start the model via reasoning SFT. Then, we perform data augmentation to improve the difficulty and diversity of the data via safety-aware data concatenation. In addition, we conduct online RL with a dynamic clipping parameter and the designed length-aware safety reward.",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/9_image_2.png",
                "caption": "Figure 3:Input Modalities and Distribution of Our Training Data GuardReasoner-VLTrain.It contains 123K samples with 631K reasoning steps, spanning 3 input modalities, including text, image, and text-image. The prompt and response can be classified as harmful or unharmful.",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/6_aug_2.png",
                "caption": "Figure 4:Safety-Aware Data Concatenation for Data Augmentation.Given two samples with labels{ùí≥1,ùí¥1}subscriptùí≥1subscriptùí¥1\\{\\mathcal{X}_{1},\\mathcal{Y}_{1}\\}{ caligraphic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT }and{ùí≥2,ùí¥2}subscriptùí≥2subscriptùí¥2\\{\\mathcal{X}_{2},\\mathcal{Y}_{2}\\}{ caligraphic_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , caligraphic_Y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT }, we generate a new sampleùí≥newsubscriptùí≥new\\mathcal{X_{\\text{new}}}caligraphic_X start_POSTSUBSCRIPT new end_POSTSUBSCRIPTby concatenating text and merge image. We assign the new labelùí¥newsubscriptùí¥new\\mathcal{Y}_{\\text{new}}caligraphic_Y start_POSTSUBSCRIPT new end_POSTSUBSCRIPTas harmful if any of the original labelsùí¥1,ùí¥2subscriptùí¥1subscriptùí¥2\\mathcal{Y}_{1},\\mathcal{Y}_{2}caligraphic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_Y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTis harmful. It enables the guard model to identity harmful content hidden among predominantly harmless content.",
                "position": 293
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11049/x3.png",
                "caption": "Figure 5:Ablation Studies of 3B (left) and 7B Models (right) on Prompt Harmfulness Detection.Y-axis denotes F1 score (%), and X-axis denotes model variants in reasoning SFT and online RL.",
                "position": 1137
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x4.png",
                "caption": "",
                "position": 1144
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/9_7b_len.png",
                "caption": "Figure 6:Response Length and Reward During Training of Our Models.",
                "position": 1222
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/9_7b_reward.png",
                "caption": "",
                "position": 1231
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/7_text.png",
                "caption": "(a)Text.",
                "position": 1392
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/7_text.png",
                "caption": "(a)Text.",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/8_image.png",
                "caption": "(b)Image.",
                "position": 1400
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/7_text_image.png",
                "caption": "(c)Text-Image.",
                "position": 1406
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x5.png",
                "caption": "(a)Prompt Harmfulness Detection.",
                "position": 1423
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x5.png",
                "caption": "(a)Prompt Harmfulness Detection.",
                "position": 1426
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x6.png",
                "caption": "(b)Response Harmfulness Detection.",
                "position": 1431
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x7.png",
                "caption": "Figure 9:Ablation Studies of 3B (left) and 7B Models (right) on Response Harmfulness Detection.X-axis denotes model variants in reasoning SFT and online RL.",
                "position": 1438
            },
            {
                "img": "https://arxiv.org/html/2505.11049/x8.png",
                "caption": "",
                "position": 1445
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/5_reason_data.png",
                "caption": "Figure 10:Prompt for Reasoning Data Synthesis.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/4_rsft_data.png",
                "caption": "Figure 11:Instruction, Input, and Output for Reasoning SFT.",
                "position": 1772
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/5_case_text.png",
                "caption": "Figure 12:Case Study on Text Input Data. This case is sampled from WildGuardTest[25].",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/5_case_image.png",
                "caption": "Figure 13:Case Study on Image Input Data. This case is sampled from HatefulMemes[34].",
                "position": 1780
            },
            {
                "img": "https://arxiv.org/html/2505.11049/extracted/6445234/5_case_text_image.png",
                "caption": "Figure 14:Case Study on Text-Image Input Data. This case is sampled from SPA-VL-Eval[91].",
                "position": 1785
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]