[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/teaser.png",
                "caption": "Figure 1:Overview of VisTA. (Left) Our method trains an agent to autonomously discover effective combinations of visual tools without human supervision. (Right) By decoupling the agent from the reasoner, the learned policy can be seamlessly integrated with a wide range of reasoning models.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/tapo_train.png",
                "caption": "Figure 2:Policy Optimization.Given a user query, the agent selects tools from a pre-defined set of external tools. The tools are applied to the image, and their outputs and the query are fed to a frozen reasoner model. Both theDirect Path(query+image) and theTool-Augmented Path(query+tools+image) are evaluated to compute a reward signal, which is used to update the agent’s tool-selection policy.",
                "position": 157
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/each_tool_and_learn_policy_2_replace.png",
                "caption": "Figure 3:Comparison of ChartQA accuracy across individual tools (T0–T8), the no-tool baseline (No), our RL-based selection policy (Ours), and a pseudo-upper bound (Upper).",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/tool_correlation_2_replace.png",
                "caption": "Figure 4:Pearson correlation between tool usage frequency and individual tool performance.",
                "position": 666
            },
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/tool_dis_3_replace.png",
                "caption": "Figure 5:Tool selection frequency across our RL-trained agent, QwenVL-7B, and GPT-4o. Our method strongly favors effective tools (Tools 1 and 2) and avoids less useful ones, while QwenVL-7B shows a uniform distribution and GPT-4o selects broadly without clear alignment to tool performance.",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/geom_viz.png",
                "caption": "Figure 6:Tool Selection for a Geometry Question. Our agent selects the formal diagram parser, Inter-GPS, which accurately extracts essential details from the diagram and represents them in a formal structure. Leveraging this representation, the reasoner is able to determine the correct answer.",
                "position": 891
            },
            {
                "img": "https://arxiv.org/html/2505.20289/extracted/6478171/chart_viz.png",
                "caption": "Figure 7:Tool Selection for a Chart Question. An example demonstrating a case where the agent calls a set of complementary tools. This question requires understanding both numeric values (extracted from the table) and color information (extracted from the SVG). The reasoner combines this information to arrive at the correct answer.",
                "position": 897
            }
        ]
    },
    {
        "header": "5Discussion and Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]