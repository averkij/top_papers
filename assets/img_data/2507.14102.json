[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14102/x1.png",
                "caption": "(a)Standard CNN: Single-pass analysis with uniform processing.",
                "position": 129
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x1.png",
                "caption": "(a)Standard CNN: Single-pass analysis with uniform processing.",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x2.png",
                "caption": "(b)Bayesian CNN: Produces uncertainty maps but without focused refinement.",
                "position": 137
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x3.png",
                "caption": "(c)Uncertainty-Guided Progressive Learning (UGPL): Focuses computational resources on uncertain regions for enhanced classification.",
                "position": 143
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x4.png",
                "caption": "Figure 2:The UGPL architecture pipeline. Our framework processes an input CT image through a global uncertainty estimator to produce classification probabilities and an uncertainty map (left). The progressive patch extractor selects high-uncertainty regions for detailed analysis (center). These patches are processed by a local refinement network and combined with global predictions through an adaptive fusion module (right). Multiple loss functions (CE, UCC, CL, PDL, REG) are jointly optimized to ensure effective training of all components.",
                "position": 150
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14102/x5.png",
                "caption": "Figure 3:Architecture of the Local Refinement Network. The network processes extracted patches(p1,p2,‚Ä¶,pn)subscriptùëù1subscriptùëù2‚Ä¶subscriptùëùùëõ(p_{1},p_{2},...,p_{n})( italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ‚Ä¶ , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )through a patch encoder comprising four convolutional blocks with increasing feature dimensions (64‚Üí128‚Üí256‚Üí256) and adaptive average pooling. The encoded features are then fed into two parallel heads: a classification head that produces patch-specific logits, and a confidence estimation head that generates confidence scores used for weighted fusion of patch predictions.",
                "position": 216
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14102/x6.png",
                "caption": "Figure 4:Performance trends of model components across datasets. Accuracy (x-axis) and F1 score (y-axis) define trajectories from LM to GM to FM, with contour lines indicating performance density.",
                "position": 696
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x7.png",
                "caption": "Figure 5:ROC curves comparing global and fused model performance across datasets. The FM consistently maintains or improves the already high AUC values of the GM across all classes and datasets.",
                "position": 702
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "A1Extended Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14102/x8.png",
                "caption": "(a)",
                "position": 2503
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x8.png",
                "caption": "(a)",
                "position": 2506
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x9.png",
                "caption": "(b)",
                "position": 2511
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x10.png",
                "caption": "Figure 7:Uncertainty distribution by class for lung cancer detection. Malignant cases (green) exhibit significantly higher average uncertainty and broader distribution compared to benign cases (pink), which show a tighter, lower-uncertainty distribution. Normal cases (blue) display a distinctive bimodal distribution with peaks at both low and moderate uncertainty levels.",
                "position": 2688
            }
        ]
    },
    {
        "header": "A2Implementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14102/x11.png",
                "caption": "Figure 8:Memory usage scaling with input dimensions across UGPL variants. Lines represent different model configurations and ablations. Config 2 (brown line) consistently demonstrates the highest memory requirements due to its ResNet-50[29]backbone variant. Some configurations show counterintuitive scaling behavior, particularly at larger input sizes, highlighting complex interactions between model architecture and GPU memory management.",
                "position": 2698
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x12.png",
                "caption": "Figure 9:Evolution of model performance across different configurations. Top: Flow field visualization showing performance trajectories from simplified to complete model configurations for each dataset. Bottom: F1 score progression across configurations for COVID (left), Lung (middle), and Kidney (right) datasets, highlighting the dramatic improvement when all components are integrated in the full model.",
                "position": 2704
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x13.png",
                "caption": "",
                "position": 2712
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x14.png",
                "caption": "",
                "position": 2713
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x15.png",
                "caption": "",
                "position": 2714
            },
            {
                "img": "https://arxiv.org/html/2507.14102/x16.png",
                "caption": "Figure 10:Computational complexity (GFLOPs) versus inference time (ms) for UGPL variants. Points are colored by dataset, with marker style indicating ablation type and size representing input dimensions.",
                "position": 2768
            }
        ]
    },
    {
        "header": "A3Additional Experiments and Results",
        "images": []
    }
]