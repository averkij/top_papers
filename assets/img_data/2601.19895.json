[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.19895/x1.png",
                "caption": "(a)Training Stability",
                "position": 106
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x1.png",
                "caption": "(a)Training Stability",
                "position": 109
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x2.png",
                "caption": "(b)Expressiveness",
                "position": 114
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x3.png",
                "caption": "(c)Depth Scaling",
                "position": 119
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3KEEL",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.19895/x4.png",
                "caption": "Figure 2:Illustration of ourKeelarchitecture.",
                "position": 341
            }
        ]
    },
    {
        "header": "4Discussions",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.19895/x5.png",
                "caption": "(a)Loss stagnation",
                "position": 717
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x5.png",
                "caption": "(a)Loss stagnation",
                "position": 720
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x6.png",
                "caption": "(b)Irrecoverable instability",
                "position": 725
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x7.png",
                "caption": "(c)Optimization degradation",
                "position": 730
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x8.png",
                "caption": "(a)256 layers, batch size 8M",
                "position": 811
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x8.png",
                "caption": "(a)256 layers, batch size 8M",
                "position": 814
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x9.png",
                "caption": "(b)512 layers, batch size 4M",
                "position": 819
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x10.png",
                "caption": "(a)10B tokens, 512 layers",
                "position": 1277
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x10.png",
                "caption": "(a)10B tokens, 512 layers",
                "position": 1280
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x11.png",
                "caption": "(b)40B tokens, 512 layers",
                "position": 1285
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Limitation and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "8Layer Redundancy in Deep LLMs",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.19895/x12.png",
                "caption": "Figure 6:Performance degradation caused by the removal of each individual layer in Pre-LN andKeel.",
                "position": 1874
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x13.png",
                "caption": "(a)Qwen2.5-72B-Instruct",
                "position": 1877
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x13.png",
                "caption": "(a)Qwen2.5-72B-Instruct",
                "position": 1880
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x14.png",
                "caption": "(b)LLaMA-3.3-70B-Instruct",
                "position": 1886
            }
        ]
    },
    {
        "header": "9Discrepancy Between Training Loss and Downstream Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.19895/x15.png",
                "caption": "(a)Training loss of shallow and deep Pre-LN.",
                "position": 1903
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x15.png",
                "caption": "(a)Training loss of shallow and deep Pre-LN.",
                "position": 1906
            },
            {
                "img": "https://arxiv.org/html/2601.19895/x16.png",
                "caption": "(b)Training loss of Pre-LN and Keel.",
                "position": 1911
            }
        ]
    },
    {
        "header": "10Model Configuration",
        "images": []
    }
]