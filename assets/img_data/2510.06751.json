[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06751/x1.png",
                "caption": "Figure 1:Qualitative comparison of unstructured pruning methods on the SD3-Medium model(Esser et al.,2024). We evaluate Magnitude, DSnoT(Zhang et al.,2024c), Wanda(Sun et al.,2024), and our method (OBS-Diff) at various sparsity levels (20%, 30%, 40%, and 50%) using the same prompt and negative prompt. All images are generated at a resolution of512×512512\\times 512.",
                "position": 112
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06751/x2.png",
                "caption": "Figure 2:Illustration of the proposedOBS-Diffframework applied to the MMDiT architecture. Target modules are first partitioned into a predefined number of “Module Packages” and processed sequentially. For each package, hooks capture layer activations during a forward pass with a calibration dataset. This data, combined with weights from a dedicated timestep weighting scheme, is used to construct Hessian matrices. These matrices guide the Optimal Brain Surgeon (OBS) algorithm to simultaneously prune all layers within the current package before proceeding to the next.",
                "position": 231
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06751/x3.png",
                "caption": "Figure 3:Effect of the number of prompts in calibration dataset on the ImageReward.",
                "position": 965
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADeclaration Of LLM Usage",
        "images": []
    },
    {
        "header": "Appendix BImplementation Details",
        "images": []
    },
    {
        "header": "Appendix CMore Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06751/x4.png",
                "caption": "Figure 4:Pruning time of different unstructured pruning methods on SD3-Medium (2B) at 50% sparsity.",
                "position": 1660
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x4.png",
                "caption": "Figure 5:ImageReward vs. sparsity for various unstructured pruning methods on SD3-Medium.",
                "position": 1692
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x5.png",
                "caption": "Figure 6:More qualitative comparison of unstructured pruning methods on the SD3-Medium model. We evaluate Magnitude, DSnoT, Wanda, and our method (OBS-Diff) at various sparsity levels (20%, 30%, 40%, and 50%) using the same prompt and negative prompt. All images are generated at a resolution of512×512512\\times 512.",
                "position": 1863
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x6.png",
                "caption": "Figure 7:More qualitative comparison of unstructured pruning methods on the SD3-Medium model. We evaluate Magnitude, DSnoT, Wanda, and our method (OBS-Diff) at various sparsity levels (20%, 30%, 40%, and 50%) using the same prompt and negative prompt. All images are generated at a resolution of512×512512\\times 512.",
                "position": 1866
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x7.png",
                "caption": "Figure 8:More qualitative comparison of unstructured pruning methods on the SD3-Medium model. We evaluate Magnitude, DSnoT, Wanda, and our method (OBS-Diff) at various sparsity levels (20%, 30%, 40%, and 50%) using the same prompt and negative prompt. All images are generated at a resolution of512×512512\\times 512.",
                "position": 1869
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x8.png",
                "caption": "Figure 9:Qualitative comparison of unstructured pruning methods on Flux 1.dev at 70% sparsity. Results from Magnitude, DSnoT, Wanda, and our proposed OBS-Diff are shown.",
                "position": 1872
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x9.png",
                "caption": "Figure 10:Qualitative comparison of structured pruning methods on the SD3.5-Large model at various sparsity levels (15%, 20%, 25%, and 30%). Results from the L1-norm baseline and our proposed OBS-Diff are shown.",
                "position": 1875
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x10.png",
                "caption": "Figure 11:Qualitative comparison of structured pruning methods on the SD3.5-Large model at various sparsity levels (15%, 20%, 25%, and 30%). Results from the L1-norm baseline and our proposed OBS-Diff are shown.",
                "position": 1878
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x11.png",
                "caption": "Figure 12:Qualitative comparison of structured pruning methods on the SD3.5-Large model at various sparsity levels (15%, 20%, 25%, and 30%). Results from the L1-norm baseline and our proposed OBS-Diff are shown.",
                "position": 1881
            },
            {
                "img": "https://arxiv.org/html/2510.06751/x12.png",
                "caption": "Figure 13:Qualitative comparison of structured pruning methods on the SD3.5-Large model at various sparsity levels (15%, 20%, 25%, and 30%). Results from the L1-norm baseline and our proposed OBS-Diff are shown.",
                "position": 1884
            }
        ]
    },
    {
        "header": "Appendix DAdditional Qualitative Results",
        "images": []
    }
]