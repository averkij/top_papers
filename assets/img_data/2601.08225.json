[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/motivation_figure_2.png",
                "caption": "Figure 1:Plug-and-Play Tool Preparation Module. A modular pipeline for dynamic tool synthesis and preprocessing, designed to initiate multi-turn data generation from any arbitrary state.",
                "position": 151
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/task-oriented-2.png",
                "caption": "Figure 2:Task-Oriented Multi-Turn Conversation Generation Pipeline. An automated framework that generates tool-use trajectories focused on efficient task completion through direct simulator-based responses.",
                "position": 201
            }
        ]
    },
    {
        "header": "3Task-Oriented Multi-turn Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/user-oriented-3.png",
                "caption": "Figure 3:User-Oriented Multi-Turn Conversation Generation Pipeline. A framework that decouples tasks from interaction by employing a dedicated user simulator to mimic incremental human feedback and request-making.",
                "position": 242
            }
        ]
    },
    {
        "header": "4User-Oriented Multi-turn Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/user-oriented-execution-2.png",
                "caption": "Figure 4:User-oriented Tool-Execution Multi-turn Conversation Generation Pipeline. This pipeline integrates a SQL-tool generation module grounded in real-world database schemas with a dedicated user simulator to produce verifiable, high-fidelity multi-turn dialogues.",
                "position": 385
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/consistency.png",
                "caption": "Figure 5:Consistency analysis across varyingkkvalues. The charts illustrate the Passˆ^k performance for different models (GPT-OSS-120b, Qwen3-4b, and Qwen3-30b) across the Retail, Airline, and Telecom domains, showing how performance scales preserve in overall domains while increasedkkvalues.",
                "position": 776
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": []
    },
    {
        "header": "7Conclusion and Discussion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix APrompt of User-oriented Multi-turn Conversation",
        "images": []
    },
    {
        "header": "Appendix BStep, Turn, and Task definition of Generated dataset",
        "images": []
    },
    {
        "header": "Appendix CDomain Visualization of SQL-based Tool-execution Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/domain.png",
                "caption": "Figure 6:Domain Visualization of SQL-based User-Oriented Tool Execution Data. A word cloud visualizing the diverse, real-world domains synthesized through our SQL-backed executable pipeline.",
                "position": 1348
            }
        ]
    },
    {
        "header": "Appendix DQualitative Examples of Generated SQL Tool-use Data",
        "images": []
    },
    {
        "header": "Appendix ETraining & Inference Details",
        "images": []
    },
    {
        "header": "Appendix FEvaluation Details",
        "images": []
    },
    {
        "header": "Appendix GPreliminary Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.08225/figures/bfcl_category.png",
                "caption": "Figure 7:Category Distribution. (Top): Distribution of tool categories in the Berkeley Function Calling Leaderboard (BFCL). (Bottom): Category counts for the Nemotron Post-training dataset, highlighting the scale and category-specific density.",
                "position": 1405
            },
            {
                "img": "https://arxiv.org/html/2601.08225/figures/nemotron_category.png",
                "caption": "",
                "position": 1409
            },
            {
                "img": "https://arxiv.org/html/2601.08225/figures/bfcl_tsne.png",
                "caption": "Figure 8:Semantic Domain Visualization via Embedding Projections. (Top): Domain spread of the BFCL dataset. (Middle): Global domain visualization of the Nemotron Post-training dataset including the ’Others’ category. (Bottom): Visualization of Nemotron domains excluding the ’Others’ category, revealing the underlying distribution of specialized tasks.",
                "position": 1415
            },
            {
                "img": "https://arxiv.org/html/2601.08225/figures/nemotron_tsne.png",
                "caption": "",
                "position": 1419
            },
            {
                "img": "https://arxiv.org/html/2601.08225/figures/nemotron_woothers_tsne.png",
                "caption": "",
                "position": 1421
            }
        ]
    },
    {
        "header": "Appendix HScientific Artifacts Usage",
        "images": []
    },
    {
        "header": "Core Objective",
        "images": []
    },
    {
        "header": "Domain Analysis Framework",
        "images": []
    },
    {
        "header": "Question Generation Guidelines",
        "images": []
    },
    {
        "header": "Output Format",
        "images": []
    },
    {
        "header": "Quality Standards",
        "images": []
    },
    {
        "header": "Instructions",
        "images": []
    },
    {
        "header": "Input",
        "images": []
    },
    {
        "header": "Output Format",
        "images": []
    },
    {
        "header": "Field Definitions",
        "images": []
    },
    {
        "header": "Generation Guidelines",
        "images": []
    },
    {
        "header": "Example Analysis",
        "images": []
    },
    {
        "header": "Output Requirements",
        "images": []
    },
    {
        "header": "Remember",
        "images": []
    },
    {
        "header": "Task Overview",
        "images": []
    },
    {
        "header": "Analysis Framework",
        "images": []
    },
    {
        "header": "Tool Design Principles",
        "images": []
    },
    {
        "header": "Usefulness & Non-Triviality",
        "images": []
    },
    {
        "header": "Output Format",
        "images": []
    },
    {
        "header": "Naming & Parameter Conventions",
        "images": []
    },
    {
        "header": "Task Overview",
        "images": []
    },
    {
        "header": "Input Format",
        "images": []
    },
    {
        "header": "Output Generation Guidelines",
        "images": []
    },
    {
        "header": "Behavior Rules",
        "images": []
    },
    {
        "header": "Output Format",
        "images": []
    },
    {
        "header": "Policy",
        "images": []
    },
    {
        "header": "Rubric Verification (pre-step)",
        "images": []
    },
    {
        "header": "Critical checks (must pass)",
        "images": []
    },
    {
        "header": "NonCritical (do not block validity)",
        "images": []
    },
    {
        "header": "Error-aware handling",
        "images": []
    },
    {
        "header": "Decision rule",
        "images": []
    }
]