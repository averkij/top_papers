[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23807/x1.png",
                "caption": "Figure 1:Illustration of Uniform Layerwise Pruning and Dynamic Layerwise Pruning (DLP): Blue squares represent unpruned weights, while white squares denote pruned weights. In uniform layerwise pruning, the same sparsity ratio is applied to every layer. In contrast, DLP calculates the unimportance of each Transformer block to compare the relative importance of layers, assigning different sparsity ratios based on the principle that layers with higher importance should have lower sparsity.",
                "position": 169
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23807/x2.png",
                "caption": "Figure 2:WikiText validation perplexity of LLaMA1-7B, LLaMA1-13B and Vicuna-7B pruned by variousMat 70% sparsity using OWL.",
                "position": 298
            },
            {
                "img": "https://arxiv.org/html/2505.23807/x3.png",
                "caption": "Figure 3:Comparison of layerwise sparsity distributions between Ours (red) and OWL (orange). The bar chart in the background represents the Relative Importance Distribution (RID). In each subplot, the horizontal axis represents the layer index, the left vertical axis corresponds to the RID, and the right vertical axis corresponds to the layerwise sparsity ratio.",
                "position": 546
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComparison among Various Layerwise Sparsity Methods",
        "images": []
    },
    {
        "header": "Appendix BPerformance under Varying Levels of Sparsity",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23807/x4.png",
                "caption": "Figure 4:Comparison of different methods at high sparsity, Using SparseGPT and Wanda.",
                "position": 2299
            }
        ]
    },
    {
        "header": "Appendix CPer-Block vs. Per-Layer",
        "images": []
    },
    {
        "header": "Appendix DPer-Output vs. Per-Layer",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23807/x5.png",
                "caption": "Figure 5:Comparison of per-output and per-layer perplexity at different sparsity rates. Due to the significant difference in values between high and low sparsity rates, we use the logarithmic results for comparison.",
                "position": 2646
            }
        ]
    },
    {
        "header": "Appendix EIntegration with Other Compression Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.23807/x6.png",
                "caption": "Figure 6:Perplexity of LLaMA1-7B on different validation datasets under varying quantization bits.",
                "position": 2933
            }
        ]
    },
    {
        "header": "Appendix FIntegration with PEFT",
        "images": []
    },
    {
        "header": "Appendix GHyperparameter Setting",
        "images": []
    },
    {
        "header": "Appendix HRobustness across Various Validation Datasets",
        "images": []
    },
    {
        "header": "Appendix IZero-shot Tasks Performance",
        "images": []
    }
]