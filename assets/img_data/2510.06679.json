[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06679/x1.png",
                "caption": "",
                "position": 53
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x2.png",
                "caption": "",
                "position": 62
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06679/x3.png",
                "caption": "Figure 2:The Overview of DreamOmni2’s training data construction.(1)In stage 1, we use a feature mixing scheme to leverage the base model’s T2I capabilities, creating high-quality data pairs with concrete objects and abstract attributes.(2)In stage 2, we generate multimodal instruction-based editing data. Using stage 1 data, we train an extraction model to simulate objects or attributes in the target image and generate a reference image based on instructions. Additionally, we use an instruction-based editing model to modify the extracted objects or attributes in the target image to be different, creating the source image. This generates training pairs from reference and source images to the target image.(3)In stage 3, we extract objects from stage 2’s source images to create new reference images, forming training data for generating target images from reference images.",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x4.png",
                "caption": "Figure 3:Data distribution and samples for multimodal instruction-based editing and generation training data. Our dataset is comprehensive and diverse, including the generation and editing of concrete objects as well as abstract attributions, such as local and global attributions.",
                "position": 163
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x5.png",
                "caption": "Figure 4:Visual comparison of multimodal instruction-based editing. Compared to other competitive methods and even closed-source commercial models (GPT-4o and Nano Banana), DreamOmni2 shows more accurate editing results and better consistency.",
                "position": 241
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06679/x6.png",
                "caption": "Figure 5:Visual comparison of multimodal instruction-based generation. Our DreamOmni2 significantly outperforms current open-source models and achieves generation results comparable to closed-source commercial models (GPT-4 and Nano Banana).",
                "position": 381
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.06679/x7.png",
                "caption": "Figure 6:Examples of multimodal instruction-based generation in DreamOmni2 benchmark.",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x8.png",
                "caption": "Figure 7:Examples of multimodal instruction-based editing in DreamOmni2 benchmark.",
                "position": 1096
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x9.png",
                "caption": "Figure 8:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1114
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x10.png",
                "caption": "Figure 9:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1118
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x11.png",
                "caption": "Figure 10:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x12.png",
                "caption": "Figure 11:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1126
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x13.png",
                "caption": "Figure 12:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1130
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x14.png",
                "caption": "Figure 13:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1134
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x15.png",
                "caption": "Figure 14:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1138
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x16.png",
                "caption": "Figure 15:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1142
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x17.png",
                "caption": "Figure 16:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1146
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x18.png",
                "caption": "Figure 17:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1150
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x19.png",
                "caption": "Figure 18:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1154
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x20.png",
                "caption": "Figure 19:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1158
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x21.png",
                "caption": "Figure 20:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1162
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x22.png",
                "caption": "Figure 21:Multimodal instruction-based editing cases of DreamOmni2.",
                "position": 1166
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x23.png",
                "caption": "Figure 22:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x24.png",
                "caption": "Figure 23:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x25.png",
                "caption": "Figure 24:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1178
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x26.png",
                "caption": "Figure 25:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1182
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x27.png",
                "caption": "Figure 26:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1186
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x28.png",
                "caption": "Figure 27:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1190
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x29.png",
                "caption": "Figure 28:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1194
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x30.png",
                "caption": "Figure 29:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1198
            },
            {
                "img": "https://arxiv.org/html/2510.06679/x31.png",
                "caption": "Figure 30:Multimodal instruction-based generation cases of DreamOmni2.",
                "position": 1202
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]