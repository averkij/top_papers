[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "IIntroduction",
        "images": []
    },
    {
        "header": "IIMethodolody",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/Architecture.png",
                "caption": "Figure 1:Schematic diagram of the stages inREFINE-AFpipeline.",
                "position": 158
            }
        ]
    },
    {
        "header": "IIIExperiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/rl_training.png",
                "caption": "Figure 2:Moving average of the model rewards over the training steps for LLaMa 13B, LLaMa 13B and Mistral 7B.",
                "position": 351
            }
        ]
    },
    {
        "header": "IVData Quality of Generated Instruction Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/stats.png",
                "caption": "Figure 3:Length distributions of the instructions, inputs, and outputs generated byREFINE-AF.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/rouge_l.png",
                "caption": "Figure 4:Distribution of Rouge-L scores between generated instructions and their most similar seed instruction. This highlights the difference in generated instructions from seed tasks.",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/gpt3_similarity.png",
                "caption": "Figure 5:Similarity of instructions generated usingREFINE-AFwrt the GPT 3.5 instructions for different base models. This similarity has been calculated using Rouge-L scores.",
                "position": 590
            }
        ]
    },
    {
        "header": "VExperimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/human_eval.png",
                "caption": "Figure 6:Human Evaluation results using LLaMA 7B, LLaMA 2-13B, and Mistral 7B models trained on 15k instructions utilizing Self Instruct and our pipeline.",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/trend.png",
                "caption": "Figure 7:Effect of data size on the performance of the model. Shown using the scores onSuper-NIbenchmark",
                "position": 665
            }
        ]
    },
    {
        "header": "VIRelated Work",
        "images": []
    },
    {
        "header": "VIIConclusions and Future Work",
        "images": []
    },
    {
        "header": "VIIILimitations",
        "images": []
    },
    {
        "header": "IXAppendix",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/nounverb_7b.png",
                "caption": "(a)Llama 2 7B",
                "position": 823
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/nounverb_7b.png",
                "caption": "(a)Llama 2 7B",
                "position": 826
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/nounverb_13b.jpg",
                "caption": "(b)Llama 2 13B",
                "position": 831
            },
            {
                "img": "https://arxiv.org/html/2505.06548/extracted/6427169/Images/nounverb_mistral.jpg",
                "caption": "(c)Mistral 7B",
                "position": 837
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]