[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.00381/extracted/6496242/methods_figure_1column.png",
                "caption": "Figure 1:Neuro2Semantic architecture and training methodology. Training is split into 2 phases. In Phase 1, an adapter module is trained to output a neural embedding that is aligned with a fixed sentence embedding. In Phase 2, a corrector module is trained to read out the neural embedding as continuous language.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2506.00381/x1.png",
                "caption": "Figure 2:Performance comparison between Neuro2Semantic, baseline, and random control. The BLEU and BERTScore gains correspond to a tangible boost in semantic accuracy\n(A) Boxplots of BERTScore (left) and BLEU Score (right) comparing the performance of Neuro2Semantic, the baseline model[6], and a random control. Significance is indicated with a star based on a pairedt-test (p<<<0.05).\n(B) Out-of-domain performance for each method is shown.\n(C) Example sentence reconstructions from Neuro2Semantic (left), original text (middle), and baseline model (right). Samples represent moderately above-average performance rather than extreme cases. (D) The performance of the method is plotted across different percentages of training data. (E) The performance of the method is plotted across different percentages of electrode coverage. All error bars show one standard deviation.",
                "position": 126
            }
        ]
    },
    {
        "header": "3Experiments and Results",
        "images": []
    },
    {
        "header": "4Discussion",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]