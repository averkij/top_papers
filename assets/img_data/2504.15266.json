[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x1.png",
                "caption": "(a)Sibling Discovery",
                "position": 238
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x1.png",
                "caption": "(a)Sibling Discovery",
                "position": 241
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x2.png",
                "caption": "(b)Triangle Discovery",
                "position": 246
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x3.png",
                "caption": "(a)Circle Construction",
                "position": 255
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x3.png",
                "caption": "(a)Circle Construction",
                "position": 258
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x4.png",
                "caption": "(b)Line Construction",
                "position": 263
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x5.png",
                "caption": "Figure 3:Multi-token teacherless finetuning improves algorithmic creativity (top; Eq1) and reduces memorization (bottom; fraction of generations seen during training) on our four open-ended algorithmic tasks for aGemma v1 (2B)model.",
                "position": 271
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x6.png",
                "caption": "",
                "position": 281
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x7.png",
                "caption": "",
                "position": 287
            }
        ]
    },
    {
        "header": "2Open-ended algorithmic tasks & two types of creativity",
        "images": []
    },
    {
        "header": "3Training and Inference",
        "images": []
    },
    {
        "header": "4Experimental results",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x8.png",
                "caption": "Figure 4:Multi-token diffusion training improves algorithmic creativity (top; Eq1) on our four open-ended algorithmic tasks, and it reduces memorization on discovery tasks but not construction tasks (bottom).",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x9.png",
                "caption": "",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x10.png",
                "caption": "",
                "position": 564
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x11.png",
                "caption": "Figure 5:Hash-conditioning significantly improves algorithmic creativity of both next- and multi-token prediction onGemma v1 (2B)model. The labels in the X-axis denote the prefix (used during training and inference) and the temperature (used during inference).",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x12.png",
                "caption": "",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x13.png",
                "caption": "",
                "position": 573
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x14.png",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x15.png",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x16.png",
                "caption": "Figure 6:Hash-conditioning improves algorithmic creativity of theGPT-2 (86M)model (but not the diffusion model):\nThe X-axis labels denote the training and decoding procedure, while the legend indicates the type of prefix used during both.",
                "position": 586
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x17.png",
                "caption": "Figure 7:Multi-token training improves diversity scores forXSUMsummarization for largeGPT-2models: Here, we plot diversity and quality as measured over multiple checkpoints during finetuning, and observe differences in diversity for a fixed quality.",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x18.png",
                "caption": "",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x19.png",
                "caption": "",
                "position": 623
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusions",
        "images": []
    },
    {
        "header": "9Impact Statement",
        "images": []
    },
    {
        "header": "10Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATransformer Training Objectives",
        "images": []
    },
    {
        "header": "Appendix BFurther discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x20.png",
                "caption": "Figure 8:Even if multi-token prediction reduces memorization (on unseen hash strings), it has enough capacity to memorize training data on the seen hash-strings (denoted by hash-memorization). Note that the best algorithmic creativity forNTPandMTPare achieved at step 10k and 40k, respectively, which are the checkpoints we used to report metrics in Fig4.",
                "position": 2953
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x21.png",
                "caption": "",
                "position": 2955
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x22.png",
                "caption": "(a)Sibling Discovery",
                "position": 2963
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x22.png",
                "caption": "(a)Sibling Discovery",
                "position": 2966
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x23.png",
                "caption": "(b)Triangle Discovery",
                "position": 2972
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x24.png",
                "caption": "(a)Circle Construction",
                "position": 2981
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x24.png",
                "caption": "(a)Circle Construction",
                "position": 2984
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x25.png",
                "caption": "(b)Line Construction",
                "position": 2990
            }
        ]
    },
    {
        "header": "Appendix CDescription of datasets",
        "images": []
    },
    {
        "header": "Appendix DFurther experimental details",
        "images": []
    },
    {
        "header": "Appendix ESensitivity analyses forGemma v1 (2B)",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x26.png",
                "caption": "Figure 11:Training size and algorithmic creativity forGemma v1 (2B): Algorithmic creativity increases under multi-token prediction across various training set sizes. Note though that, in our examples, we except the gap to diminish eventually with sufficiently many training datapoints (this is unlike the failure of next-token prediction inB&N’24).",
                "position": 3182
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x27.png",
                "caption": "",
                "position": 3192
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x28.png",
                "caption": "",
                "position": 3197
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x29.png",
                "caption": "",
                "position": 3202
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x30.png",
                "caption": "",
                "position": 3207
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x31.png",
                "caption": "Figure 12:Task complexity and algorithmic creativity forGemma v1 (2B): Algorithmic creativity increases under multi-token prediction across (reasonable) variations in the dataset parameters (as described in §C).",
                "position": 3213
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x32.png",
                "caption": "",
                "position": 3222
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x33.png",
                "caption": "",
                "position": 3227
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x34.png",
                "caption": "",
                "position": 3232
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x35.png",
                "caption": "Figure 13:Weight given to multi-token objective and algorithmic creativity forGemma v1 (2B): Algorithmic creativity increases under multi-token prediction across various weights given to the multi-token component of the objective, barring some deviations forLine Construction.",
                "position": 3238
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x36.png",
                "caption": "",
                "position": 3247
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x37.png",
                "caption": "",
                "position": 3252
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x38.png",
                "caption": "",
                "position": 3258
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x39.png",
                "caption": "Figure 14:Weight given to multi-token objective and memorization score forGemma v1 (2B): Memorization reduces under multi-token prediction across various weights given to the multi-token component of the objective.",
                "position": 3264
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x40.png",
                "caption": "",
                "position": 3273
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x41.png",
                "caption": "",
                "position": 3278
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x42.png",
                "caption": "",
                "position": 3284
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x43.png",
                "caption": "Figure 15:Learning rate and algorithmic creativity forGemma v1 (2B): Algorithmic creativity increases under multi-token prediction across various learning rates.",
                "position": 3290
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x44.png",
                "caption": "",
                "position": 3300
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x45.png",
                "caption": "",
                "position": 3306
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x46.png",
                "caption": "",
                "position": 3312
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x47.png",
                "caption": "Figure 16:Training steps and algorithmic creativity forGemma v1 (2B): Algorithmic creativity under multi-token prediction across lengths of training.",
                "position": 3318
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x48.png",
                "caption": "",
                "position": 3327
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x49.png",
                "caption": "",
                "position": 3332
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x50.png",
                "caption": "",
                "position": 3337
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x51.png",
                "caption": "Figure 17:Batch size and algorithmic creativity forGemma v1 (2B): Algorithmic creativity increases under multi-token prediction across various batch sizes. Note that here batch size is effectively proportional to the model sequence length, since we pack multiple finetuning examples into the sequence.",
                "position": 3343
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x52.png",
                "caption": "",
                "position": 3352
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x53.png",
                "caption": "",
                "position": 3357
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x54.png",
                "caption": "",
                "position": 3362
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x55.png",
                "caption": "Figure 18:Algorithmic creativity under various sampling conditions forGemma v1 (2B): Across all conditions, and in almost all datasets (with a few exceptions inLine Construction), multi-token prediction improves creativity. Furthermore, hash-conditioning achieves best algorithmic creativity, with a longer hash helping more.",
                "position": 3374
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x56.png",
                "caption": "",
                "position": 3384
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x57.png",
                "caption": "",
                "position": 3390
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x58.png",
                "caption": "",
                "position": 3396
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x59.png",
                "caption": "Figure 19:Memorization under various sampling conditions forGemma v1 (2B): Barring a few conditions, the most prominent trend is that memorization reduces under multi-token prediction for various sampling conditions. Observe that the null and pause-conditioned modelsdoproduce some memorized output while their creativity was non-existent.",
                "position": 3402
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x60.png",
                "caption": "",
                "position": 3412
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x61.png",
                "caption": "",
                "position": 3418
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x62.png",
                "caption": "",
                "position": 3424
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x63.png",
                "caption": "Figure 20:Coherence under various sampling conditions forGemma v1 (2B): Surprisingly, coherence of all models is high or at least noticeable, across various sampling conditions. This suggests that the low algorithmic creativity of the null-conditioned models in the previous plots arises from model collapsing to single original point.",
                "position": 3430
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x64.png",
                "caption": "",
                "position": 3440
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x65.png",
                "caption": "",
                "position": 3446
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x66.png",
                "caption": "",
                "position": 3452
            }
        ]
    },
    {
        "header": "Appendix FAdditional experiments inSEDD (90M)vs.GPT-2 (86M)",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x67.png",
                "caption": "Figure 21:Learning rates and algorithmic creativity for theSEDD (90M)model vs.GPT-2 (86M):MTPachieves higher algorithmic creativity thanNTPwhen both are trained at their optimal learning rates.",
                "position": 3471
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x68.png",
                "caption": "",
                "position": 3473
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x69.png",
                "caption": "",
                "position": 3473
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x70.png",
                "caption": "",
                "position": 3473
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x71.png",
                "caption": "",
                "position": 3473
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x72.png",
                "caption": "Figure 22:Task complexity and algorithmic creativity ofSEDD (90M)model vs.GPT-2 (86M):MTPconsistently outperformsNTPunder varying task configurations, with some exceptions in theLine ConstructionandCircle Constructiondatasets.",
                "position": 3478
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x73.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x74.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x75.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x76.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x77.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x78.png",
                "caption": "",
                "position": 3480
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x79.png",
                "caption": "Figure 23:GPT-2 (86M)Transformer achieves higher algorithmic creativity with longer hash strings.\nWe report algorithmic creativity with hash strings of length 4 and 10, with bothNTPand teacherlessMTP.",
                "position": 3493
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x80.png",
                "caption": "",
                "position": 3496
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x81.png",
                "caption": "Figure 24:Sensitivity to formatting of the sequence inTriangle Discovery: We find that all our small models perform equally poorly with a node-wise representation of the input sequence, whereas there was a stark difference in performance with the edge-wise representation.",
                "position": 3515
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x82.png",
                "caption": "",
                "position": 3517
            }
        ]
    },
    {
        "header": "Appendix GAdditional experiments with medium-sized Transformer and SEDD",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x83.png",
                "caption": "Figure 25:On a medium-sized (∼similar-to\\sim∼400M) model, multi-token diffusion training improves algorithmic creativity from Eq1(top) on our four open-ended algorithmic tasks.",
                "position": 3530
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x84.png",
                "caption": "",
                "position": 3532
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x85.png",
                "caption": "",
                "position": 3532
            }
        ]
    },
    {
        "header": "Appendix HDecomposing creativity",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x86.png",
                "caption": "Figure 26:Algorithmic creativity and diversity are not necessarily correlated, exhibiting distinct dynamics: We find thatNTPhas a high diversity score through training, even higher thanMTP. However, its algorithmic creativity reaches only a mediocre peak before descending, whenMTPstarts surpassing it.",
                "position": 3563
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x87.png",
                "caption": "Figure 27:Decomposition of algorithmic creativity forGPT-2 (86M)inSibling Discovery: We report algorithmic creativity, diversity and memorization at the checkpoint of best algorithmic creativity. We see that hash-conditioning contributes to higher diversity but does not help bring down memorization; teacherless training helps both diversity and in bringing down memorization.",
                "position": 3579
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x88.png",
                "caption": "",
                "position": 3581
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x89.png",
                "caption": "Figure 28:Data scaling curve for algorithmic creativity and diversity: As we increase the training data (for a fixed underlying graph), the theoretically expected maximum algorithmic creativity decreases as expected, while the theoretically expected maximum diversity stays the same.NTPtails to achieve the theoretically expected algorithmic creativity, whileMTPalmost achieves the theoretically expected performance at scale.",
                "position": 3586
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x90.png",
                "caption": "",
                "position": 3588
            }
        ]
    },
    {
        "header": "Appendix IExperiments on summarization",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15266/x91.png",
                "caption": "Figure 29:Multi-Token Objective has no effect on diversity for smallerGPTmodels onXSUM.",
                "position": 3655
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x92.png",
                "caption": "",
                "position": 3661
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x93.png",
                "caption": "",
                "position": 3661
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x94.png",
                "caption": "Figure 30:Multi-Token Objective increases diversity forGPT-LandGPT-Mbut not forGPT-XLorGPT-SonCNN/DailyMail",
                "position": 3667
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x95.png",
                "caption": "",
                "position": 3673
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x96.png",
                "caption": "",
                "position": 3673
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x97.png",
                "caption": "",
                "position": 3673
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x98.png",
                "caption": "",
                "position": 3673
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x99.png",
                "caption": "Figure 31:Hash-conditioning has no effect on diversity forGPTmodels onXSUMsummarization with next-token prediction.",
                "position": 3686
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x100.png",
                "caption": "",
                "position": 3692
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x101.png",
                "caption": "",
                "position": 3692
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x102.png",
                "caption": "",
                "position": 3692
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x103.png",
                "caption": "",
                "position": 3692
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x104.png",
                "caption": "Figure 32:Hash-conditioning has no effect on diversity forGPTmodels onXSUMsummarization with multi-token prediction.",
                "position": 3698
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x105.png",
                "caption": "",
                "position": 3704
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x106.png",
                "caption": "",
                "position": 3704
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x107.png",
                "caption": "",
                "position": 3704
            },
            {
                "img": "https://arxiv.org/html/2504.15266/x108.png",
                "caption": "",
                "position": 3704
            }
        ]
    },
    {
        "header": "Appendix JMore related works",
        "images": []
    }
]