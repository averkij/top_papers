[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x1.png",
                "caption": "",
                "position": 84
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x2.png",
                "caption": "Figure 2:Customization adapters (custom diffusion[16]and dreambooth[26]) and concept control adapters (concept sliders[8]) trained on SDXL-base model can be transferred to all the distilled modeled without any additional finetuning. This demonstrates that concept representations are preserved through the diffusion distillation process",
                "position": 123
            }
        ]
    },
    {
        "header": "3Control Distillation",
        "images": []
    },
    {
        "header": "4DT: Diffusion Target Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x3.png",
                "caption": "Figure 3:DT-Visualization reveals generation inconsistencies. When prompted with ‚ÄúImage of dog and cat sitting on sofa,‚Äù the SDXL model produces an image with only a dog. However, DT-Visualization atT=10ùëá10T=10italic_T = 10shows the model initially conceptualizing a cat face (red box) before abandoning this element in the final generation. This demonstrates how diffusion models can discard semantic elements during the denoising process.",
                "position": 284
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x4.png",
                "caption": "Figure 4:Comparison of standard diffusion visualization vs. our Diffusion Target (DT) visualization. Left: Standard visualization of intermediate latents shows subtle differences between base and distilled models. Right: Our DT visualization technique reveals dramatic differences in how models predict the final output. Distilled models commit to final image structure in the first timestep, while base models gradually refine structure across multiple steps, explaining the observed mode collapse in distilled models.",
                "position": 294
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x5.png",
                "caption": "Figure 5:Measuring the dreamsim distance between intermediate DT-visualization and final image reveals that distilled models establish structural image composition within the initial diffusion step, whereas base models require approximately 30% of steps to achieve comparable structural definition.",
                "position": 300
            }
        ]
    },
    {
        "header": "5Diversity Distillation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x6.png",
                "caption": "Figure 6:Visual comparison of generation diversity.Each row shows three different generations (different random seeds) for the same prompt using: (left) base model, (middle) distilled model, and (right) our diversity distillation approach. Note how the distilled model produces visually similar outputs across seeds, while our approach restores diversity comparable to the base model while maintaining similar inference speed as distilled model.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x7.png",
                "caption": "Figure 7:(a) Impact of guidance scale from the base model on diversity shows optimal performance around 0 guidance. (b) Effect of the number of distilled model steps (kùëòkitalic_k) being replaced by base model inference. Running distilled model from first timestep (k=1ùëò1k=1italic_k = 1) provides diversity gains with minimal computational overhead. (c) Comparing the total timesteps of base model when replacing the first timestep of distilled model shows that replacing 1-1 timesteps of distilled with base is most ideal.",
                "position": 501
            }
        ]
    },
    {
        "header": "6Limitations",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "Code",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AControl Distillation: Reverse Transfer",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x8.png",
                "caption": "Figure A.1:Reverse Control Transfer: Control mechanisms (Custom Diffusion[16]and Concept Sliders[8]) trained on distilled models can be effectively transferred to base models without retraining. This bidirectional transferability confirms that concept representations are preserved during diffusion distillation. Note: LCM LoRA transfers were excluded due to training difficulties with the LCM architecture.",
                "position": 1070
            }
        ]
    },
    {
        "header": "Appendix BMode Collapse and Diversity",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x9.png",
                "caption": "Figure B.1:Comparison of generation diversity across different models for the prompt ‚Äùimage of a toy.‚Äù Each image shows different seeds for the same model. Note the structural similarity in distilled model outputs compared to the greater variation in base model and our hybrid approach.",
                "position": 1083
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x10.png",
                "caption": "Figure B.2:Comparison of generation diversity for ‚Äùimage of a flower‚Äù Distilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.",
                "position": 1086
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x11.png",
                "caption": "Figure B.3:Additional diversity comparison for ‚Äùcity street‚ÄùDistilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.",
                "position": 1092
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x12.png",
                "caption": "Figure B.4:Diversity comparison for abstract prompt: ‚Äùpicture of a monster‚Äù Distilled models (middle column) produce structurally similar outputs across different seeds, while our approach (right column) restores diversity comparable to the base model (left column) while maintaining the speed advantage of distilled models.",
                "position": 1095
            }
        ]
    },
    {
        "header": "Appendix CExtended DT-Visualization Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10637/x13.png",
                "caption": "Figure C.1:Extended DT-Visualization comparison between SDXL-Base and SDXL-DMD for the prompt. The visualization reveals that DMD commits to final structural composition within the first timestep, while Base gradually develops structure across multiple steps. This pattern is consistent across different content types and prompts.",
                "position": 1105
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x14.png",
                "caption": "Figure C.2:Extended DT-Visualization comparison between SDXL-Base and SDXL-DMD for the prompt. The visualization reveals that DMD commits to final structural composition within the first timestep, while Base gradually develops structure across multiple steps. This pattern is consistent across different content types and prompts",
                "position": 1108
            },
            {
                "img": "https://arxiv.org/html/2503.10637/x15.png",
                "caption": "Figure D.1:Qualitative comparison between (left) our hybrid approach, (right) skip-first-step approach. The skip-first-step approach improves diversity over the standard distilled model but exhibits reduced quality compared to our hybrid method, particularly in fine details and coherence.",
                "position": 1121
            }
        ]
    },
    {
        "header": "Appendix DSkip Step Approach",
        "images": []
    }
]