[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x1.png",
                "caption": "",
                "position": 77
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x2.png",
                "caption": "Figure 2:Motivation for outpainting incomplete off-frame light sources.(a) With complete off-frame light sources, state-of-the-art SIFR methods effectively remove lens flare artifacts. (b) In scenarios lacking complete views of off-frame sources, these methods degrade significantly, leaving noticeable artifacts. This highlights the importance of complete light source context, motivating our proposed outpainting solution.",
                "position": 126
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x3.png",
                "caption": "Figure 3:Overview of our proposed three-stage pipeline.(a)Light source prediction and conditioning: We introduce a multitask regression module to accurately predict off-frame or incomplete light source parameters (positions, radii, and confidences). These predicted parameters guide a rendering function to generate the corresponding light source mask. (b)Light source outpainting: Leveraging a LoRA fine-tuned diffusion-based inpainting model with light source conditioning, our approach accurately outpaints both missing off-frame light sources and associated flare artifacts, producing visually coherent and realistic results. (c)SIFR boosting: Our generated outpainted images serve as enhanced inputs to existing SIFR methods, significantly improving their performance on previously challenging scenarios with incomplete light source information. The proposed pipeline thus effectively operates as a plug-and-play module to boost existing flare removal models.",
                "position": 158
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x4.png",
                "caption": "Figure 4:Overview of the multitask regression module.Our model performs multitask regression to simultaneously predict two essential components: the physical parametersùêè\\mathbf{P}and the corresponding confidence probabilitiesùêú\\mathbf{c}for potential light sources.\nDuring training, these are supervised by a designed multitask loss. At inference, predicted parameters are integrated to generate light source masksMLM_{\\text{L}}.",
                "position": 367
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x5.png",
                "caption": "Figure 5:Qualitative comparison of lens flare removal results.We compare state-of-the-art SIFR methods (Zhou et al.[87], Flare7K++[13], and MFDNet[28]) alone and combined with our proposed method in two challenging scenarios:(top) no visible light sources and (bottom) incomplete light sources. Integrating our outpainting method (‚ÄúOurs+‚Äù) significantly improves flare removal quality, producing results closer to ground truth.",
                "position": 969
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x6.png",
                "caption": "Figure 6:Qualitative comparison of our outpainting results.We qualitatively compare our method with SD-Inpainting[53], SDXL-Inpainting[49], and PowerPaint[90]. Our method produces more realistic outpainting results, accurately capturing flare artifacts and aligning closely with real-world scenes.",
                "position": 982
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x7.png",
                "caption": "Figure 7:Ablation studies.We ablate three components on the light source outpainting results:(a) Incorporating noise reinjection significantly enhances the diffusion model‚Äôs capability to produce realistic, seamless, and visually coherent outpainted regions; (b) Latent space blending tends to produce inconsistent illumination and noticeable artifacts, while blending in RGB space yields results with smoother transitions and improved alignment with real-world intensity distributions. (c) Integrating the proposed conditioning module significantly improves the accuracy and realism of the generated off-frame light sources and flare patterns.",
                "position": 992
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.15868/x8.png",
                "caption": "Figure 8:Comparison of the downstream tasks.The visual results indicate that LightsOut enhances performance on object detection tasks as well. Our approach not only boosts detection confidence scores but also enables the identification of objects previously undetectable due to flare artifacts.",
                "position": 2489
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x9.png",
                "caption": "Figure 9:Failure Cases.",
                "position": 2626
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x10.png",
                "caption": "Figure 10:Flare removal results for in-the-wild scens.The red boxes indicate flare regions in the images. Our method effectively addresses off-frame light source scenes, which existing SIFR models fail to handle.",
                "position": 2653
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x11.png",
                "caption": "Figure 11:Outpainting results for in-the-wild scens.",
                "position": 2656
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x12.png",
                "caption": "Figure 12:Qualitative comparisons of light source mask prediction..",
                "position": 2673
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x13.png",
                "caption": "Figure 13:Additional Qualitative Comparisons..",
                "position": 2683
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x14.png",
                "caption": "Figure 14:Additional Qualitative Comparisons..",
                "position": 2686
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x15.png",
                "caption": "Figure 15:Additional Qualitative Comparisons..",
                "position": 2689
            },
            {
                "img": "https://arxiv.org/html/2510.15868/x16.png",
                "caption": "Figure 16:Additional Qualitative Comparisons..",
                "position": 2692
            }
        ]
    },
    {
        "header": "Appendix AAppendix Section",
        "images": []
    }
]