[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Automated Tool-Augmented Dialogue Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x1.png",
                "caption": "Figure 1:The overall closed-loop automatic pipeline ofLoopTool, which couples (a) GRPO optimization, (b) Greedy Capacity Probing, (c) Judgement-Guided Label Verification, and (d) Error-Driven Data Expansion for iterative tool-use enhancement.",
                "position": 165
            }
        ]
    },
    {
        "header": "4Iterative Model Training and Data Augment",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x2.png",
                "caption": "Figure 2:The Iterative Performance across four iterations evaluated in BFCL-v3. The left y-axis represents Category Acc (bar chart), while the right y-axis denotes Overall Acc (line chart).‚ÄúOverall w/o Iterations‚Äù refers to the result obtained under the same number of iteration steps, where we train solely on the initial seed datasetùíüseed\\mathcal{D}_{\\text{seed}}.",
                "position": 799
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x3.png",
                "caption": "Figure 3:The Prediction Accuracy of Error Seed across iterations.",
                "position": 939
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x3.png",
                "caption": "Figure 3:The Prediction Accuracy of Error Seed across iterations.",
                "position": 942
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x4.png",
                "caption": "Figure 4:Scaling performance with different model sizes.",
                "position": 947
            }
        ]
    },
    {
        "header": "6Conclusion and Limitation",
        "images": []
    },
    {
        "header": "Appendix AThe use of Large Language Models (LLMs)",
        "images": []
    },
    {
        "header": "Appendix BExperimental Details",
        "images": []
    },
    {
        "header": "Appendix CThe Algorithm of LoopTool",
        "images": []
    },
    {
        "header": "Appendix DThe example of Hierarchical Dual SubTrees",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x5.png",
                "caption": "Figure 5:The example subtree of Context Tree.",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x5.png",
                "caption": "Figure 5:The example subtree of Context Tree.",
                "position": 1343
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x6.png",
                "caption": "Figure 6:The example subtree of Constraint Tree.",
                "position": 1348
            }
        ]
    },
    {
        "header": "Appendix EThe Training Sample for GRPO",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x7.png",
                "caption": "Figure 7:The general instruction prompt employed in all GRPO samples. The variablesc‚Äãu‚Äãr‚Äãr‚Äãe‚Äãn‚Äãt‚Äã_‚Äãt‚Äãi‚Äãm‚Äãecurrent\\_timeandt‚Äão‚Äão‚Äãl‚Äã_‚Äãs‚Äãe‚Äãt‚Äãstool\\_setsare placeholders.",
                "position": 1361
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x8.png",
                "caption": "Figure 8:The example of Single-Turn GRPO samples.",
                "position": 1364
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x9.png",
                "caption": "Figure 9:The example of Multi-Turn GRPO samples.",
                "position": 1367
            }
        ]
    },
    {
        "header": "Appendix FThe Label Verification Prompt",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x10.png",
                "caption": "Figure 10:The Prompt used in Judge-Guide Label Verification for Judgement Model. The red text corresponds to variables that are placeholders.",
                "position": 1377
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x11.png",
                "caption": "Figure 11:The example withyj‚Äãu‚Äãd‚Äãg‚Äãe=PRED_WRONGy_{judge}=\\texttt{PRED\\_WRONG}identified by JGLV.",
                "position": 1380
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x12.png",
                "caption": "Figure 12:The example withyj‚Äãu‚Äãd‚Äãg‚Äãe=REF_WRONGy_{judge}=\\texttt{REF\\_WRONG}identified by JGLV.",
                "position": 1383
            }
        ]
    },
    {
        "header": "Appendix GThe Error Generation Prompt and New Error Samples",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.09148/x13.png",
                "caption": "Figure 13:The system prompt for Error-Driven Data Expansion (EDDE).",
                "position": 1393
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x14.png",
                "caption": "Figure 14:The user prompt for Error-Driven Data Expansion (EDDE).",
                "position": 1396
            },
            {
                "img": "https://arxiv.org/html/2511.09148/x15.png",
                "caption": "Figure 15:The new sample generated by EDDE according to the error in the model response.",
                "position": 1399
            }
        ]
    },
    {
        "header": "Appendix HThe Learning Curves in Iterative Learning",
        "images": []
    }
]