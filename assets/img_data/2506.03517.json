[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03517/x1.png",
                "caption": "Figure 1:Text-to-video results with our DenseDPO aligned model.Our method improves both visual quality and temporal consistency of the model, enabling generation of challenging motion.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03517/x2.png",
                "caption": "Figure 2:Comparison between VanillaDPO (top) and DenseDPO (bottom).VanillaDPO compares two videos generated from independent random noises and only assigns a single binary preference, biasing the annotators toward slow-motion videos.\nIn contrast, DenseDPO generates structurally similar videos from partially noised real videos, and label segment-level dense preferences.",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x3.png",
                "caption": "Figure 3:Guided video generation with differentŒ∑ùúÇ\\etaitalic_Œ∑.LowerŒ∑ùúÇ\\etaitalic_Œ∑means more guidance.\nWe sample one frame per video for visualization.Œ∑=0.75ùúÇ0.75\\eta=0.75italic_Œ∑ = 0.75is enough to maintain the motion trajectory and high-level semantics of the ground-truth video.\nFor slow-motion videos (top), a highŒ∑ùúÇ\\etaitalic_Œ∑suffices to generate artifact-free videos, while videos with challenging motion (bottom) require more guidance.",
                "position": 294
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03517/x4.png",
                "caption": "Figure 4:Qualitative results.Pre-trained model generates deformed limbs.\nVanillaDPO fixes it but generates almost static motion.\nStructuralDPO retains dynamics but produces oversaturated frames.\nDenseDPO is the only method that generates correct limbs, large dynamics, and high quality visuals.",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x5.png",
                "caption": "Figure 5:Human evaluationof DenseDPOvs.StructuralDPO (left) and VanillaDPO (right).\nTA, VQ, TC, DD stand for text alignment, visual quality, temporal consistency, and dynamic degree.",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x5.png",
                "caption": "",
                "position": 750
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x6.png",
                "caption": "",
                "position": 754
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetailed Experimental Setup",
        "images": []
    },
    {
        "header": "Appendix BCaveat of Guided Sampling",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03517/x7.png",
                "caption": "Figure 6:Visualization of losing sample loss dominance inuncorrupted regions.Top: example images with progressively increasing blur in the central region (note, that the visualization corresponds to an equally-corrupted RGB image, rather than the decoded corrupted latent tensor).\nBottom: the per-pixel loss differenceŒ¥‚Ñísubscriptùõø‚Ñí\\delta_{\\mathcal{L}}italic_Œ¥ start_POSTSUBSCRIPT caligraphic_L end_POSTSUBSCRIPTbetween losing and winning samples averaged across latent channels.\nPositive values indicate the dominance of losing sample losses, driving the model to unintentionally degrade predictions in artifact-free areas.\nFor clarity, we clamp maximum values in the visualization to the maximum loss difference observed in uncorrupted regions, preventing extreme outliers from dominating the heatmap.",
                "position": 2864
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x8.png",
                "caption": "Figure 7:Average loss differencemean‚Å¢(Œ¥‚Ñí)meansubscriptùõø‚Ñí\\texttt{mean}(\\delta_{\\mathcal{L}})mean ( italic_Œ¥ start_POSTSUBSCRIPT caligraphic_L end_POSTSUBSCRIPT )inuncorrupted regionsas a function of artifact severity.\nIncreasing blur severity amplifies the losing sample‚Äôs negative learning signal in good (uncorrupted) regions, illustrating the risk of inadvertently unlearning correct predictions.",
                "position": 2873
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.03517/x9.png",
                "caption": "(a)StructuralDPOvs.VanillaDPO",
                "position": 2930
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x9.png",
                "caption": "(a)StructuralDPOvs.VanillaDPO",
                "position": 2933
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x10.png",
                "caption": "(b)DenseDPOvs.pre-trained model",
                "position": 2938
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x11.png",
                "caption": "Figure 9:Text-to-video results with our DenseDPO aligned model.Here, we show generation of challenging human activities, novel animal actions, and physical phenomena.Please check out ourproject pagefor video results of baselines and our methods.",
                "position": 2948
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x12.png",
                "caption": "Figure 10:Qualitative comparison with baselines.Pre-trained model often generates deformed human body or unnatural object composition.\nVanillaDPO fixes these artifacts, but with significantly reduced dynamics.\nStructuralDPO retains the dynamics, but generates oversaturated frames or some artifacts.\nDenseDPO strikes the best balance over these dimensions.Please check out ourproject pagefor video results of baselines and our methods.",
                "position": 2955
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x12.png",
                "caption": "",
                "position": 2958
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x13.png",
                "caption": "",
                "position": 2963
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x14.png",
                "caption": "",
                "position": 2968
            },
            {
                "img": "https://arxiv.org/html/2506.03517/x15.png",
                "caption": "Figure 11:Uncurated samples of GPT o3 predicted dense preference labels.Each sample consists of a pair of structurally similar videos generated via guided sampling.\nVideos are sampled at 2 FPS.\nA topredbar means GPT prefers the first example, and a bottomgreenbar means GPT prefers the second example, otherwise it is a tie.\nWe highlight some obvious artifacts withbluerectangles.",
                "position": 3071
            }
        ]
    },
    {
        "header": "Appendix DLimitations and Future Works",
        "images": []
    },
    {
        "header": "Appendix EPytorch-style Pseudo Code for StructuralDPO and DenseDPO",
        "images": []
    }
]