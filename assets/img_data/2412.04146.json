[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04146/x1.png",
                "caption": "",
                "position": 101
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04146/x2.png",
                "caption": "Figure 2:Overview of AnyDressing.GivenNùëÅNitalic_Ntarget garments, AnyDressing customizes a character dressed in multiple target garments. The GarmentsNet leverages the Garment-Specific Feature Extractor (GFE) module to extract detailed features from multiple garments. The DressingNet integrates these features for virtual dressing using a Dressing-Attention (DA) module and an Instance-Level Garment Localization Learning mechanism. Moreover, the Garment-Enhanced Texture Learning (GTL) strategy further enhances texture details.",
                "position": 207
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04146/x3.png",
                "caption": "Figure 3:Qualitative comparisonswith state-of-the-art methods. Please zoom in for more details.",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x4.png",
                "caption": "Figure 4:Examples of plug-inresults of AnyDressing.",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x5.png",
                "caption": "Figure 5:Ablation resultson GFE and IGL modules.",
                "position": 797
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x6.png",
                "caption": "Figure 6:Ablation resultson GTL module.",
                "position": 800
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7Implementation Details",
        "images": []
    },
    {
        "header": "8Scalability of AnyDressing",
        "images": []
    },
    {
        "header": "9More Ablation Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.04146/x7.png",
                "caption": "Figure 7:Examples of thetraining dataset I.",
                "position": 1727
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x8.png",
                "caption": "Figure 8:Screenshot ofuser study.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x9.png",
                "caption": "Figure 9:Examples of thetraining dataset II.",
                "position": 1737
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x10.png",
                "caption": "Figure 10:Qualitative results ofmore combinations of clothing items.",
                "position": 1742
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x11.png",
                "caption": "Figure 11:Moreablation results on GFE and IGL modules.",
                "position": 1747
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x12.png",
                "caption": "Figure 12:Morequalitative comparisons I.",
                "position": 1752
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x13.png",
                "caption": "Figure 13:Morequalitative comparisons II.",
                "position": 1757
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x14.png",
                "caption": "Figure 14:Morequalitative results I.",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x15.png",
                "caption": "Figure 15:Morequalitative results II.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x16.png",
                "caption": "Figure 16:Morequalitative results III.",
                "position": 1772
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x17.png",
                "caption": "Figure 17:More results ofcombining ControlNet[55]and FaceID[54].",
                "position": 1777
            },
            {
                "img": "https://arxiv.org/html/2412.04146/x18.png",
                "caption": "Figure 18:More results ofcombining LoRAs[15].",
                "position": 1782
            }
        ]
    },
    {
        "header": "10More Results",
        "images": []
    }
]