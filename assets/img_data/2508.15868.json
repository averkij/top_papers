[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15868/x1.png",
                "caption": "Figure 1:Comparison between SFT, ReFT, and CARFT on the exploration of CoT.",
                "position": 178
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15868/x2.png",
                "caption": "Figure 2:The framework CARFT is composed of two sequential stages: (i) supervised fine-tuning (SFT), followed by (ii) contrastive feedback.",
                "position": 229
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15868/x3.png",
                "caption": "Figure 3:Accuracy curves of various methods on SVAMP dataset and Qwen2.5-7B-Instruct backbone.",
                "position": 612
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x4.png",
                "caption": "Figure 4:Accuracy curves of various methods on SVAMP dataset and CodeLlama-7B backbone.",
                "position": 618
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x5.png",
                "caption": "Figure 5:Accuracy of CARFT with positive signal and negative signal, based on the SVAMP dataset and with the CodeLlama-7B as the backbone model.",
                "position": 660
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x6.png",
                "caption": "Figure 6:Accuracy Curve of CARFT with positive signal and negative signal, based on the SVAMP dataset and with the CodeLlama-7B as the backbone model.",
                "position": 663
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x7.png",
                "caption": "Figure 7:Accuracy of CARFT with differentcc, based on the SVAMP dataset and with the CodeLlama-7B as the backbone model.",
                "position": 671
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x8.png",
                "caption": "Figure 8:Accuracy Curve of CARFT Partial Rewards, based on the SVAMP dataset and with the CodeLlama-7B as the backbone model.",
                "position": 683
            }
        ]
    },
    {
        "header": "5Conclusions",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.15868/x9.png",
                "caption": "Figure 9:Accuracy curves of various methods on GSM8K dataset and Qwen2.5-7B-Instruct backbone.",
                "position": 1335
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x10.png",
                "caption": "Figure 10:Accuracy curves of various methods on GSM8k dataset and CodeLlama-7B backbone.",
                "position": 1341
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x11.png",
                "caption": "Figure 11:Accuracy Curve of CARFT with differentcc, based on the SVAMP dataset and with the CodeLlama-7B as the backbone model.",
                "position": 1347
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x12.png",
                "caption": "Figure 12:RL loss curve for CARFT with the GSM8K dataset and CodeLlama-7B serving as the backbone model.",
                "position": 1353
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x13.png",
                "caption": "Figure 13:Constrastive loss curve for CARFT with the GSM8K dataset and CodeLlama-7B serving as the backbone model.",
                "position": 1356
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x14.png",
                "caption": "Figure 14:RL loss curve for ReFT with the GSM8K dataset and CodeLlama-7B serving as the backbone model.",
                "position": 1359
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x15.png",
                "caption": "Figure 15:RL loss curve for CARFT with the GSM8K dataset and Qwen2.5-7B-Instruct serving as the backbone model.",
                "position": 1372
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x16.png",
                "caption": "Figure 16:Contrastive loss curve for CARFT with the GSM8K dataset and Qwen2.5-7B-Instruct serving as the backbone model.",
                "position": 1375
            },
            {
                "img": "https://arxiv.org/html/2508.15868/x17.png",
                "caption": "Figure 17:RL loss curve for ReFT with the GSM8K dataset and Qwen2.5-7B-Instruct serving as the backbone model.",
                "position": 1378
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]