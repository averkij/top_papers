[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/main_plot.png",
                "caption": "Figure 1:Scatter plot of performance where the x-axis shows the HealthBench-hard score and the y-axis shows the Arena-Hard-v2 Creative Writing score. Marker size is proportional to the model parameter count.",
                "position": 195
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/main.png",
                "caption": "Figure 2:Method overview.(Top) HealthRubrics:we draft rubrics withGPT-5.1for real-world medical queries and multi-model responses, then have physicians refine them into validated preference supervision.(Bottom) HealthPrinciples:we distill recurring rubric patterns into reusable, scenario-specific principles, used to (i) scale rubric-grounded supervision to new questions and (ii) provide rubric references for inference-time self-revision.",
                "position": 223
            }
        ]
    },
    {
        "header": "3Pilot Study: Generalization Failure of Naive SFT",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/pilot.png",
                "caption": "Figure 3:HealthBench scores vs. training epoch on a random 70/30 split with 3K training questions and 2K held-out questions, evaluated using the official HealthBench script.",
                "position": 251
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/doctor.png",
                "caption": "Figure 6:Distribution of physician involved.",
                "position": 468
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/healthbench_hard_tool_calls.png",
                "caption": "Figure 8:Tool-call Scaling on HealthBench-hard.",
                "position": 1304
            }
        ]
    },
    {
        "header": "6Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.09653/image/healthbench_hard_questions.png",
                "caption": "Figure 9:Question scaling on HealthBench-hard under a fixed training-FLOPs budget with Qwen3-4B-Instruct.",
                "position": 1340
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASFT Data Generation Prompt",
        "images": []
    },
    {
        "header": "Appendix BMedical Query Classification for HealthRubrics",
        "images": []
    },
    {
        "header": "Appendix CSubcategory Definitions and Task Type Induction",
        "images": []
    },
    {
        "header": "Appendix DPrinciple Extraction from Rubrics",
        "images": []
    },
    {
        "header": "Appendix EQuestion Classification Prompts",
        "images": []
    },
    {
        "header": "Appendix FInference-time Rubric Guidance Tool",
        "images": []
    }
]