[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x1.png",
                "caption": "Figure 1:Illustration of the high-level concept of an LLM-powered GUI agent. The agent receives a user’s natural language request and orchestrates actions seamlessly across multiple applications. It extracts information from Word documents, observes content in Photos, summarizes web pages in the browser, reads PDFs in Adobe Acrobat, and creates slides in PowerPoint before sending them through Teams.",
                "position": 262
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Evolution and Progression of LLM-Brained GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x2.png",
                "caption": "Figure 3:An overview of GUI agents evolution over years.",
                "position": 1204
            }
        ]
    },
    {
        "header": "5LLM-Brained GUI Agents: Foundations and Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x3.png",
                "caption": "Figure 4:An overview of the architecture and workflow of a basic LLM-powered GUI agent.",
                "position": 1347
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x4.png",
                "caption": "Figure 5:Examples of GUIs from web, mobile and computer platforms.",
                "position": 1394
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x5.png",
                "caption": "Figure 6:Examples of different variants of VS Code GUI screenshots.",
                "position": 1400
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x6.png",
                "caption": "Figure 7:An example of a GUI and its widget tree.",
                "position": 2507
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x7.png",
                "caption": "Figure 8:Examples of UI element properties in the PowerPoint application for GUI Agent interaction.",
                "position": 2510
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x8.png",
                "caption": "Figure 9:An example illustrating the use of a CV approach to parse a PowerPoint GUI and detect non-standard widgets, inferring their types and labels.",
                "position": 2543
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x9.png",
                "caption": "Figure 10:Examples of various types of feedback obtained from a PowerPoint application environment.",
                "position": 2550
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x10.png",
                "caption": "Figure 11:A basic example of prompt construction in a LLM-brained GUI agent.",
                "position": 2583
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x11.png",
                "caption": "Figure 12:An example of the LLM’s inference output in a GUI agent.",
                "position": 2641
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x12.png",
                "caption": "Figure 13:Illustration of short-term memory and long-term memory in an LLM-brained GUI agent.",
                "position": 3189
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x13.png",
                "caption": "Figure 14:An example of multi-agent system collaboration in creating a desk.",
                "position": 3308
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x14.png",
                "caption": "Figure 15:An example of self-reflection in task completion of an LLM-powered GUI agent.",
                "position": 3333
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x15.png",
                "caption": "Figure 16:An example self-evolution in a LLM-powered GUI agent with task completion.",
                "position": 3367
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x16.png",
                "caption": "Figure 17:An example of MDP modeling for task completion in a GUI agent.",
                "position": 3410
            }
        ]
    },
    {
        "header": "6LLM-Brained GUI Agent Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x17.png",
                "caption": "Figure 19:An illustration of the local optimization stage in WebPilot[223]using MCTS. Figure adapted from the original paper.",
                "position": 5860
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x18.png",
                "caption": "Figure 20:An example illustrating how WebDreamer[232]uses an LLM to simulate the outcome of each action. Figure adapted from the original paper.",
                "position": 5863
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x19.png",
                "caption": "Figure 21:The multi-agent architecture employed in UFO[17]. Figure adapted from the original paper.",
                "position": 5952
            }
        ]
    },
    {
        "header": "7Data for Optimizing LLM-Brained GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x20.png",
                "caption": "Figure 22:A complete pipeline for data collection for training a GUI agent model.",
                "position": 6100
            }
        ]
    },
    {
        "header": "8Models for Optimizing LLM-Brained GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x21.png",
                "caption": "Figure 23:The evolution from foundation LLMs to GUI agent-optimized LAM with fine-tuning.",
                "position": 8123
            }
        ]
    },
    {
        "header": "9Evaluation for LLM-Brained GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x22.png",
                "caption": "Figure 24:An illustrative example of evaluation of task completion by a GUI agent.",
                "position": 9744
            }
        ]
    },
    {
        "header": "10Applications of LLM-Brained GUI Agents",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x23.png",
                "caption": "Figure 25:An example of testing font size adjustment using an LLM-powered GUI agent.",
                "position": 13073
            },
            {
                "img": "https://arxiv.org/html/2411.18279/x24.png",
                "caption": "Figure 26:A conceptual example of a GUI agent-powered virtual assistant on a smartphone.",
                "position": 13808
            }
        ]
    },
    {
        "header": "11Limitations, Challenges and Future Roadmap",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.18279/x25.png",
                "caption": "Figure 27:An illustrative example of human-agent interaction for completing an email sending request.",
                "position": 13982
            }
        ]
    },
    {
        "header": "12Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]