[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04808/x1.png",
                "caption": "Figure 1:Evaluation accuracy as a function of the number of allowed attempts during evaluation, averaged across five benchmarks: AIME 2024, MATH 500, AMC 2023, Minerva Math, and OlympiadBench. Both LLMs are based on Qwen 2.5 Math 1.5B and fine-tuned via RL on a small math dataset in either multi-attempt tasks or single-turn tasks (baseline).",
                "position": 57
            },
            {
                "img": "https://arxiv.org/html/2503.04808/extracted/6250029/fig/illust.png",
                "caption": "Figure 2:Illustration of the multi-attempt question-answer task. We extend the single-turn question-answer task from DeepSeek R1 to a multi-attempt setting, enabling iterative refinement.",
                "position": 75
            }
        ]
    },
    {
        "header": "2Approach",
        "images": []
    },
    {
        "header": "3Related Work",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04808/x2.png",
                "caption": "(a)Training Reward",
                "position": 231
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x2.png",
                "caption": "(a)Training Reward",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x3.png",
                "caption": "(b)Average Evaluation Accuracy",
                "position": 239
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x4.png",
                "caption": "(a)AIME 2024",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x4.png",
                "caption": "(a)AIME 2024",
                "position": 296
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x5.png",
                "caption": "(b)MATH500",
                "position": 301
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x6.png",
                "caption": "(c)AMC 2023",
                "position": 307
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x7.png",
                "caption": "(d)Minerva Math",
                "position": 312
            },
            {
                "img": "https://arxiv.org/html/2503.04808/x8.png",
                "caption": "(e)OlympiadBench",
                "position": 318
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]