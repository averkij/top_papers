[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x1.png",
                "caption": "",
                "position": 85
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x2.png",
                "caption": "Figure 2:(a) General Video DiT models like Mochi[69]often struggle to generate unconventional or counter-intuitive interactions, even with detailed descriptions.\n(b) Our method can customize a specific relation to generate videos on new subjects.",
                "position": 113
            },
            {
                "img": "https://arxiv.org/html/2503.07602/x3.png",
                "caption": "Figure 3:Averaged value feature across all layers and frames in Mochi. We identify that the relations encompass intricate spatial arrangements, layout variations, and nuanced temporal dynamics, presenting challenges in relational video customization.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x4.png",
                "caption": "Figure 4:Overall framework of DreamRelation.\nOur method decomposes relational video customization into two concurrent processes.\n(1) In Relational Decoupling Learning, Relation LoRAs in relation LoRA triplet capture relational information, while Subject LoRAs focus on subject appearances. This decoupling process is guided by hybrid mask training strategy based on their corresponding masks.\n(2) In Relational Dynamics Enhancement, the proposed space-time relational contrastive loss pulls relational dynamics features (anchor and positive features) from pairwise differences closer, while pushing them away from appearance features (negative features) of single-frame outputs.\nDuring inference, subject LoRAs are excluded to prevent introducing undesired appearances and enhance generalization.",
                "position": 212
            }
        ]
    },
    {
        "header": "3DreamRelation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x5.png",
                "caption": "Figure 5:Features and subspace similarity analysis of MM-DiT. (a) Value features across different videos encapsulate rich appearance information, and relational information often intertwines with these appearance cues. Meanwhile, query and key features exhibit similar patterns that differ from those of value features.\n(b) We perform singular value decomposition on the query, key, and value matrices of each MM-DiT block and compute the similarity of the subspaces spanned by their top-k left singular vectors, indicating query and key matrices share more common information while remaining independent of the value matrix.",
                "position": 267
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x6.png",
                "caption": "Figure 6:Qualitative comparison results. Our method outperforms all baselines in precisely capturing the intended relation and mitigating appearance and background leakage.",
                "position": 403
            },
            {
                "img": "https://arxiv.org/html/2503.07602/x7.png",
                "caption": "Figure 7:(a) Our method focuses on the desired relational region. (b) Our method is most preferred by users across all aspects.",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2503.07602/x8.png",
                "caption": "Figure 8:Qualitative ablation study on each component.",
                "position": 571
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.07602/x9.png",
                "caption": "Figure 9:More qualitative results of DreamRelation (1/2). Please zoom in for a better view.",
                "position": 2511
            },
            {
                "img": "https://arxiv.org/html/2503.07602/x10.png",
                "caption": "Figure 10:More qualitative results of DreamRelation (2/2). Please zoom in for a better view.",
                "position": 2514
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]