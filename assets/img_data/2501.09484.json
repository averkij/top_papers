[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09484/x1.png",
                "caption": "Figure 1.Using the same patient records and doctor model, our patient simulator (shown on the right in the figure) is compared to the baseline patient simulator (prompt engineering on GPT-4o, shown on the left in the figure). Online consultation dialogues are divided into inquiry and diagnosis stages, with D representing the doctor and P representing the patient in the figure. Based on the predefined set of dialogue strategies outlined in this paper, the dialogue strategies output by our model are highlighted inpurple. The output from our patient simulator may contain emotions or proactive questions, marked ingreen. In contrast, the baseline tends to provide more comprehensive symptoms in the first round, with additional symptoms and resulting significant differences highlighted inred. These dimensions illustrate that our model better approximates a real patient.",
                "position": 142
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.Patient Simulator",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09484/x2.png",
                "caption": "Figure 2.Prompts for synthesizing patient simulator training dialogues.",
                "position": 203
            },
            {
                "img": "https://arxiv.org/html/2501.09484/x3.png",
                "caption": "Figure 3.The system prompt of our patient simulator.",
                "position": 242
            },
            {
                "img": "https://arxiv.org/html/2501.09484/x4.png",
                "caption": "Figure 4.Workflow for assessing diagnostic accuracy in conversations using LLMs.",
                "position": 341
            }
        ]
    },
    {
        "header": "3.Relationship Between Inquiry and Diagnosis: Impact on Diagnostic Accuracy",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09484/x5.png",
                "caption": "Figure 5.Patients consistently use our patient simulator, and doctors initially employ different models to interact with the simulator for fixed n rounds (x-axis, n values are 1, 2, 3, 4, 5) to generate inquiry records. These records are then diagnosed using different doctor models, and the diagnostic accuracy (y-axis) is calculated.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2501.09484/x6.png",
                "caption": "Figure 6.Examples of four types of inquiry with D representing the doctor and P representing the patient in the figure.",
                "position": 477
            }
        ]
    },
    {
        "header": "4.Inquiry Differences Among Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09484/x7.png",
                "caption": "Figure 7.The comparison focuses on the distribution of four inquiry types across GPT-4o, GPT-4o-mini, and Claude-3-5-sonnet as inquiry models, segmented by inquiry rounds. The x-axis represents the inquiry models, while the y-axis indicates the proportion of the four inquiry types.",
                "position": 500
            }
        ]
    },
    {
        "header": "5.Related Works",
        "images": []
    },
    {
        "header": "6.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ACandidate Set of Dialogue Strategy Tags",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.09484/x8.png",
                "caption": "Figure 8.Inquiry Type Annotation Prompt",
                "position": 1408
            }
        ]
    },
    {
        "header": "Appendix BInquiry Type Annotation Prompt",
        "images": []
    }
]