[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Permuted Block-Sparse Attention",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21270/x1.png",
                "caption": "Figure 1:Illustration of causal attention without (Left) and with (Right) segmented permutation withB=1,S=4B=1,S=4. Segmented permutation enhances block-level sparsity via intra-segment permutation while preserving inter-segment causality. By restricting computation of blocks within on-diagonal segments (green blocks), we can safely skip inter-segment blocks (yellow blocks) for block-sparse attention.",
                "position": 260
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x2.png",
                "caption": "(a)",
                "position": 332
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x2.png",
                "caption": "(a)",
                "position": 335
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x3.png",
                "caption": "(b)",
                "position": 340
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21270/x4.png",
                "caption": "Table 1:Performance comparison of various sparse attention methods on LongBench.Boldandunderlinedscores indicate the best and second-best performing methods in each category, respectively, with the exception of the full attention baseline.",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x4.png",
                "caption": "Figure 3:Speedup of various methods relative to FlashAttention, measured by time to first token (TTFT) on LongBenchv2 across various sequence lengths. To accommodate longer sequences under memory constraints, we employ tensor parallelism with tp_size of 2 and 8 for the 256K and 512K contexts, respectively.",
                "position": 821
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x5.png",
                "caption": "Figure 4:Block-level density on various context lengths with and without permutation. A relative sparsity improvementÎ”\\Deltais calculated.",
                "position": 846
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x6.png",
                "caption": "(a)Permutation Target",
                "position": 858
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x6.png",
                "caption": "(a)Permutation Target",
                "position": 861
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x7.png",
                "caption": "(b)Segment Size",
                "position": 866
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Ethics Statement",
        "images": []
    },
    {
        "header": "8Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProofs of Permutation Properties",
        "images": []
    },
    {
        "header": "Appendix BBlock Selection",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21270/x8.png",
                "caption": "Figure 6:Longbench score vs. average block-level density at a context length of 32k of XAttention selection with and without permutation.",
                "position": 1713
            }
        ]
    },
    {
        "header": "Appendix CAnalysis on the Permutation Overhead",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21270/x9.png",
                "caption": "(a)Query-aware Key Permutation.",
                "position": 1728
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x9.png",
                "caption": "(a)Query-aware Key Permutation.",
                "position": 1731
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x10.png",
                "caption": "(b)Key-aware Query Permutation.",
                "position": 1737
            }
        ]
    },
    {
        "header": "Appendix DVisualization of Permutation",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.21270/x11.png",
                "caption": "(a)Layer 1, Head 13",
                "position": 1751
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x11.png",
                "caption": "(a)Layer 1, Head 13",
                "position": 1754
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x12.png",
                "caption": "",
                "position": 1757
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x13.png",
                "caption": "(b)Layer 10, Head 26",
                "position": 1763
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x14.png",
                "caption": "",
                "position": 1766
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x15.png",
                "caption": "(c)Layer 16, Head 9",
                "position": 1773
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x16.png",
                "caption": "",
                "position": 1776
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x17.png",
                "caption": "(d)Layer 28, Head 28",
                "position": 1782
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x18.png",
                "caption": "",
                "position": 1785
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x19.png",
                "caption": "(a)Layer 0, Head 0",
                "position": 1793
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x19.png",
                "caption": "(a)Layer 0, Head 0",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x20.png",
                "caption": "",
                "position": 1799
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x21.png",
                "caption": "(b)Layer 7, Head 22",
                "position": 1805
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x22.png",
                "caption": "",
                "position": 1808
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x23.png",
                "caption": "(c)Layer 22, Head 5",
                "position": 1815
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x24.png",
                "caption": "",
                "position": 1818
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x25.png",
                "caption": "(d)Layer 26, Head 20",
                "position": 1824
            },
            {
                "img": "https://arxiv.org/html/2510.21270/x26.png",
                "caption": "",
                "position": 1827
            }
        ]
    },
    {
        "header": "Appendix EUse of Large Language Models",
        "images": []
    }
]