[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15920/x1.png",
                "caption": "Figure 1:Overview of the AgenticLU pipeline: The model iteratively refines its understanding of long-context inputs through an agentic workflow. At each step, it raises self-clarifications, retrieves relevant context via the pointback mechanism, and updates its reasoning trace. The framework integrates CoC Path Construction to generate diverse reasoning paths, followed by two-stage fine-tuning (SFT and DPO) to enhance long-context understanding.",
                "position": 159
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3The Context Size Gap",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15920/x2.png",
                "caption": "Figure 2:Effective context size is smaller than nominal context size.Performance of Llama3.1-8B-Instruct (advertised 128K-token context) on the HotPotQA dataset\ndrops sharply as input length increases (8K, 16K, 32K, 64K, 128K), illustrating the\ngap between nominal and effective context capacities.",
                "position": 224
            }
        ]
    },
    {
        "header": "4Chain-of-Clarifications Workflow",
        "images": []
    },
    {
        "header": "5Data Generation & Model Training",
        "images": []
    },
    {
        "header": "6Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15920/x3.png",
                "caption": "Figure 3:Main results on 7 long-context tasks across context lengths from 8K to 128K.Our AgenticLU-8B (dotted orange) achieves significant improvements onalltasks over our base model Llama3.1-8B (solid orange). We also compare with the prompting methods (Step-by-Step, Plan-and-Solve, Fact-and-Reflect, LongRAG) and the state-of-the-art ProLong-8B model. AgenticLU-8B consistently maintains strong performance across most tasks and context lengths.",
                "position": 441
            }
        ]
    },
    {
        "header": "7Analyses & Ablation Studies",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Configurations",
        "images": []
    },
    {
        "header": "Appendix BShort Context Performance",
        "images": []
    },
    {
        "header": "Appendix CDetailed Results on Seven Benchmark Tasks",
        "images": []
    },
    {
        "header": "Appendix DChain-of-Clarifications Workflow",
        "images": []
    },
    {
        "header": "Appendix EEvaluation Template",
        "images": []
    }
]