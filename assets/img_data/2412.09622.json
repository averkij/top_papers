[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09622/x1.png",
                "caption": "",
                "position": 84
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09622/x2.png",
                "caption": "Figure 2:Framework Overview.The framework comprises two main stages: (a) generating concept-specific representations with individual pre-trained LoRA models and (b) merging these representations into a unified model using a novel contrastive objective. In (a), each LoRA model produces input-output pairs(Xi,Yi)subscriptùëãùëñsubscriptùëåùëñ(X_{i},Y_{i})( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )for distinct concepts(V1,V2,‚Ä¶,Vn)subscriptùëâ1subscriptùëâ2‚Ä¶subscriptùëâùëõ(V_{1},V_{2},\\dots,V_{n})( italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ‚Ä¶ , italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ), establishing positive pairs (aligned concepts) and negative pairs (unrelated concepts). In (b), these representations are combined into a single model,Œî‚Å¢WŒîùëä\\Delta Wroman_Œî italic_W, to enable multi-concept synthesis.LoRACLRaligns attracting positive pairs to ensure identity retention and repelling negative pairs to prevent cross-concept interference.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09622/x3.png",
                "caption": "Figure 3:Qualitative Results.LoRACLReffectively combines different numbers of unique concepts across a wide range of scenes, producing high-fidelity compositions that capture the complexity and nuance of multi-concept prompts in diverse environments.LoRACLRpreserves the identity of each concept, ensuring accurate representation in composite scenes while also maintaining fidelity in single-concept generation, as demonstrated in the last row. Real images from the original concepts are shown on the left for reference.",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x4.png",
                "caption": "Figure 4:Multi-Concept Comparison.Composite images generated by our method (LoRACLR) and competing methods (Orthogonal Adaptation[24], Mix-of-Show[9], Prompt+[39]) for multi-concept prompts. Each row depicts a different scene defined by the text prompts. Our method consistently preserves individual identities, while others struggle with identity preservation and concept interference.",
                "position": 236
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09622/x5.png",
                "caption": "Figure 5:Quantitative Results on Number of Concepts.Text alignment, image alignment, and identity preservation scores as the number of merged concepts increases. Our method achieves high scores across all metrics, maintaining identity and prompt adherence. Dots represent the baseline metrics for each LoRA model before merging, serving as a reference for performance comparisons.",
                "position": 446
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x6.png",
                "caption": "Figure 6:Style LoRA Integration.Our method combines styles like comic art and oil painting into multi-subject scenes, ensuring stylistic fidelity and content coherence, showcasing its flexibility.",
                "position": 482
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x7.png",
                "caption": "Figure 7:Non-human subject generation.Our method effectively combines diverse concepts such as animals, objects (e.g., tables, chairs, vases), and monuments (e.g., pyramids, rocks) into cohesive and visually appealing scenes.",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x8.png",
                "caption": "Figure 8:Ablation Study on Margin,ŒªdeltasubscriptùúÜdelta\\lambda_{\\text{delta}}italic_Œª start_POSTSUBSCRIPT delta end_POSTSUBSCRIPT, and Concept Count.Effect of varying margin,ŒªdeltasubscriptùúÜdelta\\lambda_{\\text{delta}}italic_Œª start_POSTSUBSCRIPT delta end_POSTSUBSCRIPT, and number of concepts (2, 5, 8, 12) on identity preservation and visual coherence.",
                "position": 551
            }
        ]
    },
    {
        "header": "5Limitation and Societal Impact",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "7User Study Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.09622/x9.png",
                "caption": "Figure 9:User Study Interface.Participants rated identity similarity between reference images and generated scenes, focusing on accuracy and realism.",
                "position": 1132
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x10.png",
                "caption": "Figure 10:Comparison between our method and OMG for generating multi-concept scenes.OMG struggles with intermediate layout dependence and compositional errors, particularly with same-gender concepts, while our method achieves seamless and accurate results.",
                "position": 1167
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x11.png",
                "caption": "Figure 11:Qualitative comparison of multi-concept scenes.Our method effectively captures dynamic interactions and complex stylistic elements, as seen in examples such as bustling kitchens and futuristic spaceships. It surpasses Orthogonal Adaptation, Mix-of-Show andùí´+limit-fromùí´\\mathcal{P}+caligraphic_P +in coherence and realism.",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x12.png",
                "caption": "Figure 12:Additional multi-concept image generation examples.Our method demonstrates superior integration of concepts and themes in diverse scenarios, such as operating rooms and detective noir settings, while maintaining stylistic fidelity.",
                "position": 1173
            },
            {
                "img": "https://arxiv.org/html/2412.09622/x13.png",
                "caption": "Figure 13:Extended qualitative results for multi-concept image generation.It showcases our method‚Äôs ability to generate intricate compositions, such as ancient libraries and sci-fi interiors. These results emphasize the robustness of our approach in maintaining style, subject integrity, and contextual relevance.",
                "position": 1176
            }
        ]
    },
    {
        "header": "8More Comparison",
        "images": []
    }
]