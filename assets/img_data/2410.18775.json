[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.18775/x1.png",
                "caption": "Figure 1:(a) Flowchart of the W-Bench evaluation process.\n(b) Watermarking performance. Each method is illustrated with a diamond and four bars. The area of the diamond represents the method’s encoding capacity. The y-coordinate of the diamond’s center indicates normalized image quality, calculated by averaging the normalized PSNR, SSIM, LPIPS, and FID between watermarked and input images. The x-coordinate represents robustness, measured by the True Positive Rate at a 0.1% False Positive Rate (TPR@0.1%FPR) averaged across four types of image editing methods, encompassing a total of seven distinct models and algorithms. The four bars are oriented to signify different editing tasks: image regeneration (left), global editing (top), local editing (right), and image-to-video generation (bottom). The length of each bar reflects the method’s normalized TPR@0.1%FPR after each type of image editing—the longer the bar, the better the performance.",
                "position": 117
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x2.png",
                "caption": "Figure 2:Process for analyzing the impact of image editing on an image’s frequency spectrum. In this example, the editing model Instruct-Pix2Pix, denoted asϵ⁢(⋅)italic-ϵ⋅\\epsilon(\\cdot)italic_ϵ ( ⋅ ), is employed. The functionℱ⁢(⋅)ℱ⋅\\mathcal{F}(\\cdot)caligraphic_F ( ⋅ )represents the Fourier transform, and we visualize its magnitude on a logarithmic scale.",
                "position": 170
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x3.png",
                "caption": "Figure 3:Impact of various image editing techniques and distortions on the frequency spectra of images. Results are averaged over 1,000 images. Image editing methods tend to remove frequency patterns in the mid- and high-frequency bands, while low-frequency patterns remain largely unaffected. This trend is also observed with blurring distortions such as pixelation and defocus blur. In contrast, commonly used distortions like JPEG compression and saturation do not exhibit similar behavior in the frequency domain. The analysis of SVD is not included, as it removes all patterns, rendering them invisible to the human eye. A discussion on SVD can be found in Section4.3.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x4.png",
                "caption": "Figure 4:The overall framework of our method,VINE. We utilize the pretrained one-step text-to-image model SDXL-Turbo as the watermark encoder. A condition adaptor is incorporated to fuse the watermark with the image before passing the information to the VAE encoder. Zero-convolution layers(Zhang et al.,2023)and skip connections are added for better perceptual similarity. For decoding the watermark, we employ ConvNeXt-B(Liu et al.,2022b)as the decoder, with an additional fully connected layer to output a 100-bit watermark. Throughout the entire training process, the SDXL-Turbo text prompt is set to null prompt. Figure9shows the condition adaptor architecture.",
                "position": 198
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x5.png",
                "caption": "Figure 5:The performance of watermarking methods under (a) Stochastic regeneration, (b) Global editing, and (c) Local editing. Additional results are available in Figure16.",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x6.png",
                "caption": "Figure 6:Frequency pattern visualizations for each watermarking method. The DWTDCT method is excluded because it closely resembles DWTDCTSVD and their pattern intensity is too weak to be discerned on the uniform scale. Please zoom in for a closer look.",
                "position": 2250
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x7.png",
                "caption": "Figure 7:Performance of watermarking methods at a resolution of 512×\\times×512 pixels under (a) Gaussian blurring, (b) brightness adjustments, (c) contrast modifications, (d) Gaussian noise, and (e) JPEG compression.",
                "position": 2439
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x8.png",
                "caption": "Figure 8:Assessment of watermarking methods at their respective training resolutions under the following conditions: (a) Gaussian blurring, (b) brightness adjustments, (c) contrast modifications, (d) Gaussian noise, and (e) JPEG compression. Training resolutions: MBRS, CIN, PIMoG, and SepMark were trained at 128×\\times×128 pixels; TrustMark, VINE-B, and VINE-R at 256×\\times×256 pixels; and StegaStamp at 400×\\times×400 pixels.",
                "position": 2442
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x9.png",
                "caption": "Figure 9:Architecture of the condition adaptor in Figure4. Each fully connected and convolutional layer is followed by an activation layer.",
                "position": 2453
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x10.png",
                "caption": "Figure 10:The reconstruction quality of (a) stochastic regeneration and (b) deterministic regeneration. The PSNR is calculated by comparing the regenerated image to the original image.",
                "position": 2484
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x11.png",
                "caption": "Figure 11:The reconstruction quality of stochastic regeneration and deterministic regeneration. Please zoom in for a closer look.",
                "position": 2487
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x12.png",
                "caption": "Figure 12:Different watermarks have minimal impact on the image global editing outcomes, resulting in only slight changes.",
                "position": 2860
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x13.png",
                "caption": "Figure 13:Different watermarks have minimal impact on the image local editing outcomes, resulting in only slight changes.",
                "position": 2863
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x14.png",
                "caption": "Figure 14:Different watermarks have little effect on image-to-video generation, leading to only minor changes.",
                "position": 2873
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x15.png",
                "caption": "Figure 15:Qualitative comparison of the evaluated watermarking methods. Please zoom in for a closer look.",
                "position": 2974
            },
            {
                "img": "https://arxiv.org/html/2410.18775/x16.png",
                "caption": "Figure 16:The performance of watermarking methods under (a) Deterministic regeneration with DPM-Solver, (b) Global editing with UltraEdit, (c) Global editing with Instruct-Pix2Pix, (d) Local editing with ControlNet-Inpainting, and (e) Image-to-video generation with Stable Video Diffusion.",
                "position": 2984
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]