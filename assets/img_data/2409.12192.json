[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.12192/x1.png",
                "caption": "Figure 1:(a) We present DynaMo, a new self-supervised method for learning visual representations for visuomotor control. DynaMo exploits the causal structure in demonstrations by jointly learning the encoder with inverse and forward dynamics models. DynaMo requires no augmentations, contrastive sampling, or access to ground truth actions. This enables downstream policy learning using limited in-domain data across simulated and real-world robotics tasks. For each environment, we pretrain the visual representation in-domain with DynaMo and learn a policy on the pretrained embeddings. (b) We provide real-world rollouts of policies learned with DynaMo representation on our multi-task xArm Kitchen and Allegro Manipulation environments.",
                "position": 118
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3DynaMo",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.12192/x2.png",
                "caption": "Figure 2:Embedding nearest neighbor matches for DynaMo, BYOL, MoCo, and TCN on the Block Pushing environment.(Top)The nearest neighbor matches visualized in pixel space.(Bottom)Matches visualized in a top-down view. We see that the DynaMo representation captures task-relevant features (end effector, block, and target locations in this case), whereas prior work fixates on the large robot arm.",
                "position": 182
            },
            {
                "img": "https://arxiv.org/html/2409.12192/x3.png",
                "caption": "Figure 3:Architecture of DynaMo. DynaMo jointly learns an image encoder, an inverse dynamics model, and a forward dynamics model with a forward dynamics prediction loss.",
                "position": 200
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.12192/x4.png",
                "caption": "Figure 4:We evaluate DynaMo on four simulated benchmarks - Franka Kitchen, Block Pushing, Push-T, and LIBERO Goal, and two real-world environments - Allegro Manipulation, and xArm Kitchen.",
                "position": 391
            }
        ]
    },
    {
        "header": "5Related works",
        "images": []
    },
    {
        "header": "6Discussion and Limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AEnvironment and dataset details",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.12192/x5.png",
                "caption": "Figure 5:xArm Kitchen environment tasks",
                "position": 2402
            }
        ]
    },
    {
        "header": "Appendix BHyperparameters and implementation details",
        "images": [
            {
                "img": "https://arxiv.org/html/2409.12192/extracted/5966724/figs/allegro_manip.png",
                "caption": "Figure 6:Rollouts on Allegro Manipulation with our DynaMo-pretrained encoder.",
                "position": 2998
            },
            {
                "img": "https://arxiv.org/html/2409.12192/extracted/5966724/figs/xarm_kitchen.png",
                "caption": "Figure 7:Rollouts on xArm Kitchen with our DynaMo-pretrained encoder.",
                "position": 3002
            }
        ]
    },
    {
        "header": "Appendix CReal robot environment rollouts",
        "images": []
    }
]