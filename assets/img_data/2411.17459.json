[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x1.png",
                "caption": "Figure 1:Performance comparison of video VAEs.Bubble area indicates the memory usage during inference. All measurements are conducted on 33 frames with 256√ó256 resolution videos. ‚ÄúChn‚Äù represents the number of latent channels. Higher PSNR and throughput indicate better performance.",
                "position": 79
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x2.png",
                "caption": "Figure 2:Overview of WF-VAE.Our architecture consists of a backbone and a main energy flow pathway. The pathway functions as a ‚Äúhighway‚Äù for main flow of video energy, channeling this energy into the backbone through concatenations, allowing more critical video information to be preserved in the latent representation.",
                "position": 115
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x3.png",
                "caption": "(a)Illustration ofCasual Cache.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x3.png",
                "caption": "(a)Illustration ofCasual Cache.",
                "position": 199
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x4.png",
                "caption": "(b)Qualitative comparison of tiling inference andCausal Cache",
                "position": 205
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x5.png",
                "caption": "Figure 4:Computational performance of encoding and decoding. We evaluate the encoding and decoding time and memory consumption across 33 frames with 256√ó256, 512√ó512, and 768√ó768 resolutions (benchmark models without causal convolution are tested with 32 frames). WF-VAE surpasses other VAE models by a large margin on both inference speed and memory efficiency.",
                "position": 460
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x6.png",
                "caption": "Figure 5:Qualitative comparison of reconstruction performance.We select two scenarios to comprehensively evaluate the visual quality of videos reconstructed by existing VAEs. Top: scenario containsrich details. Bottom: scenario containsfast motion.",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x7.png",
                "caption": "Table 2:Quantitative evaluation of different VAE models for video generation.We assess video generation quality using FVD16on both SkyTimelapse and UCF-101 datasets, and IS on UCF-101 following prior work[22].",
                "position": 483
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x7.png",
                "caption": "Figure 6:Generated videos using WF-VAE with Latte-L.Top:results trained with the SkyTimelapse dataset.Bottom:results trained with the UCF-101 dataset.",
                "position": 562
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x8.png",
                "caption": "(a)Number of latent channels.",
                "position": 568
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x8.png",
                "caption": "",
                "position": 571
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x9.png",
                "caption": "",
                "position": 575
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x10.png",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x11.png",
                "caption": "(a)Number of latent channels.",
                "position": 584
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x12.png",
                "caption": "(b)WL Loss weightsŒªW‚Å¢LsubscriptùúÜùëäùêø\\lambda_{W\\!L}italic_Œª start_POSTSUBSCRIPT italic_W italic_L end_POSTSUBSCRIPT.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x13.png",
                "caption": "(c)Number of energy flow path channelsCf‚Å¢l‚Å¢o‚Å¢wsubscriptùê∂ùëìùëôùëúùë§C_{flow}italic_C start_POSTSUBSCRIPT italic_f italic_l italic_o italic_w end_POSTSUBSCRIPT.",
                "position": 594
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Notations",
        "images": []
    },
    {
        "header": "7Wavelet Subband Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x14.png",
                "caption": "(a)Visualization of the eight subbands obtained after wavelet transform of the video.",
                "position": 1564
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x14.png",
                "caption": "(a)Visualization of the eight subbands obtained after wavelet transform of the video.",
                "position": 1567
            },
            {
                "img": "https://arxiv.org/html/2411.17459/x15.png",
                "caption": "(b)Energy and entropy of each subband.",
                "position": 1573
            }
        ]
    },
    {
        "header": "8Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.17459/x16.png",
                "caption": "Figure 9:Illustration ofCausal Cachewith parameterskùëòkitalic_k=3,sùë†sitalic_s=2, and chunk sizeTc‚Å¢h‚Å¢u‚Å¢n‚Å¢ksubscriptùëáùëê‚Ñéùë¢ùëõùëòT_{chunk}italic_T start_POSTSUBSCRIPT italic_c italic_h italic_u italic_n italic_k end_POSTSUBSCRIPT=4.",
                "position": 1701
            }
        ]
    },
    {
        "header": "9Derivation of Causal Cache",
        "images": []
    }
]