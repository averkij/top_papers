[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10821/x1.png",
                "caption": "Figure 1:In our experiment, VideoDeepResearch powered by DeepSeek-R1-0528 (reasoning module) and Seed1.5VL-pro/Qwen2.5VL-7B (visual module) outperforms state-of-the-art MLLMs, including GPT-4o, Gemini-1.5-Pro and Qwen2.5-VL-72B, across popular LVU benchmarks.",
                "position": 71
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10821/x2.png",
                "caption": "Figure 2:Framework of Video-DeepResearch.",
                "position": 80
            }
        ]
    },
    {
        "header": "2Methodology",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.10821/x3.png",
                "caption": "Figure 3:Task performance analysis on MLVU test set.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2506.10821/x4.png",
                "caption": "Figure 4:(a) Performance robustnessw.r.tvideo duration and (b) Visual token efficiency analysis on LongVideoBench.",
                "position": 460
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]