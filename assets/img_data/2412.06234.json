[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure1_main.jpg",
                "caption": "",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure2_overview.jpg",
                "caption": "Figure 2:Generative Densification overview.\nWe selectively densifies the topKùêæKitalic_KGaussians with large view-space positional gradients.",
                "position": 134
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure3_gd_layer.jpg",
                "caption": "Figure 3:Key components in Generative Densification Module.",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure4_pipeline.jpg",
                "caption": "Figure 4:Overview of the Generative Densification pipelines for object-level (top) and scene-level (bottom) reconstruction tasks.",
                "position": 345
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure5_experiment_object.jpg",
                "caption": "Figure 5:Qualitative comparisons of our object-level model trained for 50 epochs against the original LaRa.\nThe zoomed-in parts within the red boxes are shown on the right side of the second and third columns, focusing on the comparison of fine detail reconstruction.\nThe two images in the rightmost column present the Gaussians input to and output from our generative densification module, respectively.",
                "position": 630
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure6_exp_scene.jpg",
                "caption": "Figure 6:Qualitative comparisons of our scene-level model against the original MVSplat on the RE10K[46]dataset.",
                "position": 676
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure7_crsgen.jpg",
                "caption": "Figure 7:Qualitative comparisons of our scene-level model against the original MVSplat on the ACID[17]and DTU[12]datasets.",
                "position": 679
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure8_histogram.jpg",
                "caption": "Figure 8:2D histograms of Gaussian attributes.\nEach pixel represents a histogram bin, with brighter colors for higher counts.",
                "position": 966
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AAdditional Results on the DL3DV Dataset",
        "images": []
    },
    {
        "header": "Appendix BGenerating Residuals of Fine Gaussians",
        "images": []
    },
    {
        "header": "Appendix CModel Details",
        "images": []
    },
    {
        "header": "Appendix DTraining and Evaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure9_main_suppl.jpg",
                "caption": "Figure 9:Additional qualitative results of our object-level and scene-level model trained for 50 epochs and 450,000 iterations, respectively. The zoomed-in parts show our method selects and reconstructs the fine details through alternating densification layers, while preserving the smooth areas unchanged. Note that the 7-th column of the scene-level reconstruction results shows the union of fine Gaussians generated across all three densification layers, and the output Gaussians from the third layer are omitted due to space constraints.",
                "position": 2004
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure10_object_suppl.jpg",
                "caption": "Figure 10:Qualitative comparisons of our object-level model against the original LaRa[5], evaluated on the GSO[10]and Gobjaverse[33]dataset. The coarse and fine Gaussians are the input and output of generative densification module, respectively.",
                "position": 2009
            },
            {
                "img": "https://arxiv.org/html/2412.06234/extracted/6054475/fig/figure11_scene_suppl.jpg",
                "caption": "Figure 11:Qualitative comparisons of our scene-level model against the original MVSplat[7], evaluated on the RE10K[46]dataset. The red boxes show that our model better reconstructs the scene, removing visual artifacts and generating missing parts.",
                "position": 2014
            }
        ]
    },
    {
        "header": "Appendix EAdditional Qualitative Results",
        "images": []
    }
]