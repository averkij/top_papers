[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02474/x1.png",
                "caption": "Figure 1:Comparison between (a) prior turn-level, handcrafted operations and (b) MemSkill’s span-level, skill-conditioned generation.Prior methods interleave handcrafted operations with LLM calls to incrementally extract and revise memory turn by turn, while MemSkill selects a small set of skills from a shared skill bank and applies them in one pass to produce skill-guided memories.",
                "position": 164
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02474/x2.png",
                "caption": "Figure 2:MemSkill architecture overview.Given an interaction trace, MemSkill processes it span by span: the controller selects a Top-KKsubset of skills from a sharedskill bankconditioned on the current text span and retrieved memories, and an LLM executor applies the selected skills in one pass to update the trace-specificmemory bank. The constructed memory is then evaluated on memory-dependent training queries to provide task reward for optimizing the controller, while query-centric failures are logged into a sliding hard-case buffer. Periodically, the designer mines representative hard cases to refine existing skills and propose new ones, yielding alternating phases of skill usage and skill evolution. More skill case study can be found in Section4.5and AppendixB.",
                "position": 239
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.02474/x3.png",
                "caption": "Figure 3:Skill generalization under distribution shift on HotpotQA.We transfer the LoCoMo-trained skill bank to HotpotQA and evaluate three context-length settings (50/100/200 concatenated documents) following(Yuet al.,2025). Bars show LLM-judge (L-J) under LLaMA with different Top-KKskill counts, compared to MemoryOS and A-MEM.",
                "position": 732
            },
            {
                "img": "https://arxiv.org/html/2602.02474/x4.png",
                "caption": "Figure 4:Case study.We show representative evolved skills learned on LoCoMo and ALFWorld. (“Description” is omitted for brevity.)",
                "position": 754
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AMore Implementation Details",
        "images": []
    },
    {
        "header": "Appendix BCase Study",
        "images": []
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    }
]