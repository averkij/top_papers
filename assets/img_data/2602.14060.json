[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x24.png",
                "caption": "",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x1.png",
                "caption": "",
                "position": 108
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x2.png",
                "caption": "",
                "position": 116
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x3.png",
                "caption": "",
                "position": 117
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x5.png",
                "caption": "",
                "position": 126
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x6.png",
                "caption": "",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x7.png",
                "caption": "",
                "position": 141
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x8.png",
                "caption": "Figure 1:Four examples of theterm,context(input), anddefinition(output) for definition modeling task.",
                "position": 148
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x9.png",
                "caption": "Figure 2:Diagram ofLM-Lexicon(i.e.,Specialize-then-Synthesize) framework.",
                "position": 157
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x4.png",
                "caption": "Algorithm 1Compose MHA and MLP modules for each decoder layerℓ\\ellinLM-Lexicon.",
                "position": 277
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x10.png",
                "caption": "Figure 3:Four-cluster UMAP plot of 10K random definitions of terms in 3D-EX (§4). Each cluster is assigned manually with a[label]by their major constituents.",
                "position": 519
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x11.png",
                "caption": "Table 2:Main results on five benchmarks777We develop ad-hoc heuristic parser for proprietary models &LM-Lexiconto extract our focused part of the generation.. We highlight thehighest scoresamongLM-Lexiconand compared methods; * denotes the significance test, wherep<0.005p<0.005between our method and Rerank-T5 (prior SoTA).♣\\clubsuitdenotes that we reproduce the in-distribution results with supervised training, and†\\daggerindicates that the lines of results are not directly comparable with other settings. All*-ICLsettings employ the best setting with a 32-shot in practice.",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x12.png",
                "caption": "",
                "position": 858
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x13.png",
                "caption": "Figure 4:Best-of-Nrepeated sampling results (Bleu) on five benchmarks evaluated byoracle verifier.",
                "position": 934
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x14.png",
                "caption": "Figure 5:Scaling performance gains and human evaluation results. The left figure: Scaling test performance on 3D-EX, with varying number of experts. The right figure: Human evaluation results across five criteria.",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x15.png",
                "caption": "",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x4.png",
                "caption": "Table 3:Ablation on data partition method.",
                "position": 969
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x4.png",
                "caption": "Table 4:Ablation on different routing policies.",
                "position": 1012
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Ethics Statement",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Experiment Details",
        "images": []
    },
    {
        "header": "Appendix BCarbon Footprint",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x16.png",
                "caption": "Table 6:Details about the training required resources.",
                "position": 2126
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x17.png",
                "caption": "",
                "position": 2147
            }
        ]
    },
    {
        "header": "Appendix CAdditional Evaluation Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x18.png",
                "caption": "Figure 7:Scaling the in-context learning results of frontier causal LMs on WordNet withkk-shot demonstrations, wherekkscales logarithmically from0to128128. Prior SoTA denotes the Rerank-T5 proposed byHuang et al. (2021).",
                "position": 2269
            }
        ]
    },
    {
        "header": "Appendix DHuman Evaluation Agreement",
        "images": []
    },
    {
        "header": "Appendix EComparison of Different Definitions",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.14060/x4.png",
                "caption": "Table 10:Comparison of generated definition by models.",
                "position": 2450
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x19.png",
                "caption": "",
                "position": 2530
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x4.png",
                "caption": "Table 11:A comprehensive comparison of the most relative sparse mixture-of-experts frameworks in recent years, including MoE (Vanilla), BTM (Merge), BTX (Linear Router), andLM-Lexicon. Our method demonstrates advancements in semantic-centric specialized expert and adaptability across domains.",
                "position": 3049
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x22.png",
                "caption": "Table 12:Hyper-parameters ofLM-Lexicon-DenseandLM-Lexicon-MoEtraining.DS ZeRO-3(left-hand table) denotes stage-3 ZeRO parallelism implemented by DeepSpeedRajbhandari et al. (2020).Naive PP(right-hand table) denotes naive pipeline parallelism implemented byHugging Face TransformersWolf et al. (2020).",
                "position": 3172
            },
            {
                "img": "https://arxiv.org/html/2602.14060/x23.png",
                "caption": "Figure 12:Human evaluation guideline.",
                "position": 3318
            }
        ]
    },
    {
        "header": "Appendix FCode forLM-Lexicon",
        "images": []
    }
]