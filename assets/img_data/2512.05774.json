[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05774/x1.png",
                "caption": "Figure 1:Motivation of Active Video Perception. Prior methods follow apassiveperception paradigm which leverage query-agonistic captioner to perceive the video information, leading to low efficiency and imprecise visual grounding. Instead, weactivelyperceive query-relevant content by treating the long video as an interactive environment to be explored in a goal-directed manner.",
                "position": 143
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05774/x2.png",
                "caption": "Figure 2:Framework of Active Video Perception(AVP).AVPoperates by an iterative plan-observe-reflect process with MLLM agents. At each round, the planner decide what/where/how to interact with the video, the observer extract structured query-related evidence by executing the plan and the reflector evaluates the extracted evidence to decide whether an additional round is need.",
                "position": 242
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05774/x3.png",
                "caption": "Figure 3:Qualitative example ofAVP.\nGiven a multiple-choice query about the Tombstone monument’s first on-screen\nappearance, Round 1 performs a coarse scan of the entire video\n(0.5 FPS, low resolution) and localizes a candidate interval\n[1:00, 1:10], but theReflectorjudges the evidence insufficient.\nRound 2 re-plans a targeted pass over this window (2 FPS, medium resolution),\nenabling theObserverto localize the monument in the upper-left background\nand theReflectorto confidently select the correct answer (option D) and halt.",
                "position": 892
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ALimitations",
        "images": []
    },
    {
        "header": "Appendix BAdditional Quantitative Results and Analysis",
        "images": []
    },
    {
        "header": "Appendix CAdditional Qualitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05774/x4.png",
                "caption": "Figure 4:Qualitative example of multi-round active perception inAVP(MINERVA sample).Given the query, “After adding up all the millimeter totals on the sheet of paper illustrated at 09:58, and then adding the average length of Louisiana Pine Snake hatchlings according to the video, how many total millimeters are there?”,AVPfirst plans to focus on the local timestamped frame at 09:58 and extracts the seven millimeter totals from the handwritten measurement sheet (Round 1).\nThe reflector correctly judges that this evidence is insufficient because the average hatchling length is still unknown, and triggers a second round.\nIn Round 2, the planner re-directs the observer to uniformly scan the full video at low FPS, locating a narrated segment that states hatchlings “usually range from 4 to 5 feet in length.”\nBy fusing the previous numeric evidence with this newly discovered range, the reflector computes the total millimeter interval and selects the correct option.",
                "position": 2411
            },
            {
                "img": "https://arxiv.org/html/2512.05774/x5.png",
                "caption": "Figure 5:Failure Case ofAVP(MINERVA sample). Given a long broadcast basketball video,AVPmust answer:\n“How many three-pointers are made before the second clip of Hawaii versus UCSB?”\nThe planner chooses to scan the entire video at 0.5 FPS with low spatial resolution, the observer summarizes the retrieved segments into a structured evidence list, and the reflector produces a confident answer of two.\nHowever, the ground-truth reasoning (yellow box) shows that a three-pointer at 00:20 is missed, so the correct count is three.\nAlthough the internal reasoning over the collected evidence is coherent, the initial coarse observation policy fails to capture a short, local event, leading to an overconfident but incorrect prediction.",
                "position": 2438
            }
        ]
    },
    {
        "header": "Appendix DAdditional Implementation Detail",
        "images": []
    }
]