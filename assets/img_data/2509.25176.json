[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25176/pictures/logo.png",
                "caption": "",
                "position": 63
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x1.png",
                "caption": "Figure 1:Performance-efficiency comparison between different training methods applied to DeepSeek-R1-Distill-Qwen-1.5B. SIRI continually pushes the model to the Pareto frontier.",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminaries",
        "images": []
    },
    {
        "header": "4SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25176/pictures/deepscaler.png",
                "caption": "(a)DeepScaleR’s training dynamics(Luo et al.,2025b).",
                "position": 187
            },
            {
                "img": "https://arxiv.org/html/2509.25176/pictures/deepscaler.png",
                "caption": "(a)DeepScaleR’s training dynamics(Luo et al.,2025b).",
                "position": 190
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x2.png",
                "caption": "(b)Hypothesized iteration dynamics of SIRI.",
                "position": 195
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x3.png",
                "caption": "(a)Stair scheduler",
                "position": 236
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x3.png",
                "caption": "(a)Stair scheduler",
                "position": 239
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x4.png",
                "caption": "(b)Cosine scheduler",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x5.png",
                "caption": "(c)Stair-cosine scheduler",
                "position": 249
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25176/x6.png",
                "caption": "Figure 4:The 1.5B model’s Pass@1 accuracy and average response length of SIRI with 640-cycle length cosine scheduler over three iterations on the AIME24 benchmark.",
                "position": 614
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x7.png",
                "caption": "(a)Dynamics on AIME24",
                "position": 617
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x7.png",
                "caption": "(a)Dynamics on AIME24",
                "position": 620
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x8.png",
                "caption": "(b)Dynamics on AIME25",
                "position": 625
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x9.png",
                "caption": "Figure 6:Representative token frequency before and after compression.",
                "position": 632
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x10.png",
                "caption": "(a)Dynamics of cosine scheduler with different cycle lengths.",
                "position": 646
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x10.png",
                "caption": "(a)Dynamics of cosine scheduler with different cycle lengths.",
                "position": 649
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x11.png",
                "caption": "(b)Dynamics of different-shaped schedulers with a cycle length of 480.",
                "position": 654
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.25176/x12.png",
                "caption": "(a)Dynamics on AIME24",
                "position": 1143
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x12.png",
                "caption": "(a)Dynamics on AIME24",
                "position": 1146
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x13.png",
                "caption": "(b)Dynamics on AIME25",
                "position": 1151
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x14.png",
                "caption": "(a)320 cycle",
                "position": 1162
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x14.png",
                "caption": "(a)320 cycle",
                "position": 1165
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x15.png",
                "caption": "(b)480 cycle",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x16.png",
                "caption": "(c)640 cycle",
                "position": 1175
            },
            {
                "img": "https://arxiv.org/html/2509.25176/x17.png",
                "caption": "Figure 10:The entropy of DAPO-DeepScaleR-16K during 16K context training.",
                "position": 1191
            }
        ]
    },
    {
        "header": "Appendix AAdditional Experiment Results",
        "images": []
    }
]