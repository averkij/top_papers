[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/x1.png",
                "caption": "Figure 1:From Execution to Inference.Traditional ML agents improve through costly execution and external feedback, incurring substantial latency.\nOur work investigates whether superior data-grounded solutions can be identified before execution by leveraging “Implicit Execution Priors”.",
                "position": 209
            },
            {
                "img": "https://arxiv.org/html/2601.05930/x2.png",
                "caption": "Figure 2:Overview of the Framework.(a) Task Definition:TheData-centric Solution Preferencetask predicts solution superiority and confidence via latent reasoning.(b-c) Data Curation:We collect and filter real-world agent trajectories to construct thePreference Corpus.(d) Augmentation:Inputs are augmented withVerified Data Reportsvia a “Profile-Verify-Verbalize” pipeline.(e)ForeAgentApplication:The model serves as a filter within thePredict-then-Verifyloop, predicting preferencebeforephysical execution to prune candidates.",
                "position": 252
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Preference Corpus Curation",
        "images": []
    },
    {
        "header": "4Main Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/figures/deepseek_logo.png",
                "caption": "Table 2:Main Results: Predictive Capability and Boundary Analysis.This table presents the Pairwise Preference Accuracy (%) of the evaluated LLMs averaged over three runs, stratified by Task Dimensions and Solution Attributes. Results are reported as Mean±Stdev{}_{\\pm\\text{Stdev}}.DeepSeek-V3.2 (Thinking Mode)andGPT-5.1achieve global averages of61.5%and58.8%respectively, significantly outperforming the random baseline of50%and the complexity-based heuristic baseline of50.8%.",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2601.05930/figures/openai_logo.png",
                "caption": "",
                "position": 581
            }
        ]
    },
    {
        "header": "5Analysis & Insights",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/x3.png",
                "caption": "Figure 3:Comprehensive Analysis of World Model Mechanisms and Capabilities.(a) Impact of Data Representation:Predictive success stems from semantic data understanding rather than complexity heuristics.(b) Domain Sensitivity:The superiority of verbal reports remains consistent across domains.(c) Scaling Laws:Accuracy decouples from pure parameter scaling.(d) Inference Dynamics:Active reasoning outperforms direct answering with robust stability across temperatures.(e) Calibration Analysis:Self-reported confidence strictly correlates with accuracy.(f) Complexity Discrimination:Accuracy scales with the complexity gap.",
                "position": 734
            }
        ]
    },
    {
        "header": "6Agent Integration:ForeAgent",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/x4.png",
                "caption": "Figure 4:Agent Performance Analysis.(a)Task-wise Beat Ratio:ForeAgentachieves an average +6% improvement over the AIDE baseline.\n(b)Temporal Efficiency:The agent converges to peak performance using only 1/6 of the execution time, achieving an average6×6\\timesspeedup.\n(c)Search Breadth:By offloading evaluation to the “Implicit World Model”,ForeAgentexplores3.2×3.2\\timesmore nodes on average compared to the baseline, significantly expanding the search space within the same time budget.",
                "position": 986
            }
        ]
    },
    {
        "header": "7Related Work",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended Related Work",
        "images": []
    },
    {
        "header": "Appendix BCorpus Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/x5.png",
                "caption": "Figure 5:Hierarchical distribution of the unique solution architectures in our Prediction Corpus. The chart illustrates the balance achieved across major machine learning paradigms: Gradient Boosting&Trees, General/Sequential NNs, CNNs, and Transformers. The outer ring details specific model instances, demonstrating the high heterogeneity of the solution space.",
                "position": 3508
            }
        ]
    },
    {
        "header": "Appendix CDetailed Experiment Result",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.05930/x6.png",
                "caption": "Figure 6:Temporal Evolution of Performance.The curves display the Average Beat Ratio as a function of Execution Time (0–12 hours) for both the AIDE baseline andForeAgent. The results are broken down by the five individual AI4Science tasks and the overall Micro Average.",
                "position": 4244
            },
            {
                "img": "https://arxiv.org/html/2601.05930/x7.png",
                "caption": "Figure 7:Progression of Search Node Exploration.This figure illustrates the cumulative number of nodes explored (Avg. Node Num.) over the 12-hour duration. It compares the search trajectories ofForeAgentagainst AIDE across each specific task and the aggregated Micro Average.",
                "position": 4247
            },
            {
                "img": "https://arxiv.org/html/2601.05930/x8.png",
                "caption": "Figure 8:Domain and Task Sensitivity Analysis.The stacked bar chart presents the data representation study for each individual task. It visualizes the incremental performance impact of adding Raw Data, Numerical Statistics, and Verbal Reports to the Code-only baseline. The tasks are grouped by their respective domains (CV, NLP, and Data Science) to highlight domain-specific sensitivity.",
                "position": 4250
            }
        ]
    },
    {
        "header": "Appendix DDetailed Qualitative Analysis",
        "images": []
    },
    {
        "header": "Appendix EPrompt Templates",
        "images": []
    }
]