[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22202/x1.png",
                "caption": "Figure 1:Sentence-level reasoning framework.Training: the latent model reads the question tokens and previous embeddings, predictsh^tsubscript^‚Ñéùë°\\hat{h}_{t}over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and a frozen decoder reconstructsstsubscriptùë†ùë°s_{t}italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT;Inference: embedding can be rolled forward by(a) Discretized: decode‚Üí‚Üí\\rightarrow‚Üítext‚Üí‚Üí\\rightarrow‚Üíencode or(b) Continuous: pass-through.",
                "position": 144
            },
            {
                "img": "https://arxiv.org/html/2505.22202/x2.png",
                "caption": "Figure 2:Illustration of the different types of sentence embeddings used in our framework.",
                "position": 163
            }
        ]
    },
    {
        "header": "2Sentence embeddings for autoregressive modeling",
        "images": []
    },
    {
        "header": "3Sentence-Level Reasoning Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22202/extracted/6481194/figs/scale_chart.png",
                "caption": "(a)CoT vs. CTX-B on CommonsenseQA across GPT-2 variants.",
                "position": 595
            },
            {
                "img": "https://arxiv.org/html/2505.22202/extracted/6481194/figs/scale_chart.png",
                "caption": "(a)CoT vs. CTX-B on CommonsenseQA across GPT-2 variants.",
                "position": 598
            },
            {
                "img": "https://arxiv.org/html/2505.22202/extracted/6481194/figs/qual_analysis.png",
                "caption": "(b)GPT-4o Qualitative evaluation of the reasoning steps evaluated using a similar metric employed in[25], where SFT is trained using CoT and ours is usingCTX-B.",
                "position": 603
            }
        ]
    },
    {
        "header": "4Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22202/extracted/6481194/figs/robustness.png",
                "caption": "Figure 4:Performance Change when injecting a Gaussian random noise to different modes of inferencing, for Ctx-C model in GSM8K and CSQA datasets.",
                "position": 892
            }
        ]
    },
    {
        "header": "5Related Works",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Broader Impacts",
        "images": []
    },
    {
        "header": "Acknowledgment",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ASentenceLens Examples",
        "images": []
    },
    {
        "header": "Appendix BDataset Description",
        "images": []
    },
    {
        "header": "Appendix CComputation Complexity Analysis",
        "images": []
    },
    {
        "header": "Appendix DTermination Classifier",
        "images": []
    },
    {
        "header": "Appendix EExperiment Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.22202/extracted/6481194/figs/evaluation_prompt.png",
                "caption": "Figure 5:Evaluation Prompt used to GPT-4o for judging intermediate reasoning step‚Äôs quality.",
                "position": 2988
            },
            {
                "img": "https://arxiv.org/html/2505.22202/x3.png",
                "caption": "Figure 6:Example instances from each dataset.",
                "position": 2991
            }
        ]
    },
    {
        "header": "Appendix FEvaluation Prompt",
        "images": []
    }
]