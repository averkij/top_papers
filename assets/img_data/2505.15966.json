[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/x1.png",
                "caption": "Figure 1:Illustration of Pixel Reasoner.When asked a visually-rich question,Pixel-Reasonerfirst inspects the visual inputs. Then it iteratively refines its understanding and evolve its reasoning by leveraging visual operations, such aszoom-infor images andselect-framesfor videos, ultimately arriving at a conclusion.",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x1.png",
                "caption": "Figure 1:Illustration of Pixel Reasoner.When asked a visually-rich question,Pixel-Reasonerfirst inspects the visual inputs. Then it iteratively refines its understanding and evolve its reasoning by leveraging visual operations, such aszoom-infor images andselect-framesfor videos, ultimately arriving at a conclusion.",
                "position": 102
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x2.png",
                "caption": "Figure 2:The Learning Trap. Our approach combines a warm-start instruction tuning phase and curiosity-driven RL phase to overcome the learning trap.",
                "position": 107
            }
        ]
    },
    {
        "header": "2Problem Formulation",
        "images": []
    },
    {
        "header": "3Warm-Start Instruction Tuning",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/x3.png",
                "caption": "Figure 3:Direct Distillation from GPT4o may generate \"bypassing trajectories\" where the model ignores the visual operations and performs textual reasoning. We thus adopt a template-based synthesis strategy.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x3.png",
                "caption": "Figure 3:Direct Distillation from GPT4o may generate \"bypassing trajectories\" where the model ignores the visual operations and performs textual reasoning. We thus adopt a template-based synthesis strategy.",
                "position": 194
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x4.png",
                "caption": "Figure 4:We synthesize self-correction trajectories by inserting erroneous reasoning segments.",
                "position": 199
            }
        ]
    },
    {
        "header": "4Curiosity-Driven Reinforcement Learning",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/x5.png",
                "caption": "Figure 5:RL Requires Incentives to Explore Pixel-space Reasoning. Without proper incentives, the policy learns to bypass the nascent pixel-space reasoning, resulting declining RaPR.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x5.png",
                "caption": "Figure 5:RL Requires Incentives to Explore Pixel-space Reasoning. Without proper incentives, the policy learns to bypass the nascent pixel-space reasoning, resulting declining RaPR.",
                "position": 235
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x6.png",
                "caption": "Figure 6:The Training Trend of our Curiosity-Driven Reward Scheme. We leverage curiosity bonus to encourages exploration and efficiency penalty to punish excessive visual operations.",
                "position": 240
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/x7.png",
                "caption": "Figure 7:Trainig Dynamics of Ablation Baselines. During RL training, different baselines show different trends in triggering pixel-space reasoning (Left), and the error rate of utilizing visual operations (Middle). Our curiosity-driven reward scheme effectively cultivates pixel-space reasoning by actively practicing and enhancing this nascent ability, as evidenced by the narrowed gap in return between the two reasoning paradigms (Right).",
                "position": 537
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADerivations of Curiosity-Driven Reward",
        "images": []
    },
    {
        "header": "Appendix BData and Training Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/extracted/6464385/figures/datapipeline.png",
                "caption": "Figure 8:A detailed illustration of our data generation pipeline.",
                "position": 1346
            },
            {
                "img": "https://arxiv.org/html/2505.15966/x8.png",
                "caption": "Figure 9:Trainig Dynamics of RL without SSR. The ratio of reward uniformity steadily saturates to 90%.",
                "position": 1401
            }
        ]
    },
    {
        "header": "Appendix CAdditional Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15966/extracted/6464385/figures/example_mvbench.png",
                "caption": "Figure 10:Pixel-Reasonereffectively captures key frames that are most informative for solving the query.",
                "position": 1421
            },
            {
                "img": "https://arxiv.org/html/2505.15966/extracted/6464385/figures/infobest1.png",
                "caption": "Figure 11:Pixel-Reasonereffectively identifies the relevant region within the infographic and performs targeted analysis, either by refining the crop or directly answering the query.",
                "position": 1424
            }
        ]
    },
    {
        "header": "Appendix DPrompts",
        "images": []
    }
]