[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11496/figure/andesvl_radar_with_minmax.png",
                "caption": "Figure 1:Overall performance comparisons over 6 domains (text-rich, reasoning and math, general VQA, multi-image, multilingual and hallucination) of different SOTA MLLMs with 4B parameters.",
                "position": 200
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3AndesVL",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Overall_arch.png",
                "caption": "Figure 2:The overall architecture of AndesVL mainly includes a visual encoder, an MLP projector, and an LLM.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2510.11496/CoT_data_pipeline.png",
                "caption": "Figure 4:CoT data construction pipeline",
                "position": 795
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/sft_data_filtering_pipeline.png",
                "caption": "Figure 5:SFT Data Filtering Pipeline",
                "position": 1085
            },
            {
                "img": "https://arxiv.org/html/2510.11496/MPO_data_pipeline.png",
                "caption": "Figure 6:MPO data construction pipeline",
                "position": 1100
            }
        ]
    },
    {
        "header": "4Mobile-side Application of AndesVL",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Multi-scenario_training.png",
                "caption": "Figure 7:Multi-scenario LoRA training based on AndesVL.",
                "position": 1141
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/QALFT_framework_0926.png",
                "caption": "Figure 8:QALFT framework.",
                "position": 1255
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "6On-Device Performance",
        "images": []
    },
    {
        "header": "7Future Directions",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AContributor",
        "images": []
    },
    {
        "header": "Appendix BAndesUI Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Image_20250626212020.png",
                "caption": "Figure 9:Examples of widget labels in the AndesUI dataset.",
                "position": 8099
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Image_20250626212020.png",
                "caption": "",
                "position": 8102
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Image_20250626212041.png",
                "caption": "",
                "position": 8106
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/Image_20250626212056.png",
                "caption": "",
                "position": 8110
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/general_case_1.png",
                "caption": "Table 22:A dense captioning example of AndesVL.",
                "position": 8171
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/test_case_2.png",
                "caption": "Table 23:A knowledge question answering example of AndesVL.",
                "position": 8203
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/multi_demo1.png",
                "caption": "Table 24:An Example of Multi-Image Understanding of AndesVL.",
                "position": 8238
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/multi_demo2.png",
                "caption": "Table 25:An Example of Multi-Image Understanding of AndesVL.",
                "position": 8302
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/test_case_5.png",
                "caption": "Table 26:A visual reasoning example of AndesVL.",
                "position": 8355
            },
            {
                "img": "https://arxiv.org/html/2510.11496/OCR_case_1.jpeg",
                "caption": "Table 27:Demonstration of AndesVL’s ability of accurately extracting and comprehensing texts and visual elements from an image, understanding the user’s query, and retrieving the answer from the document.",
                "position": 8387
            },
            {
                "img": "https://arxiv.org/html/2510.11496/OCR_case_2.jpeg",
                "caption": "Table 28:An example of extracting multilingual texts from a long receipt.",
                "position": 8522
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/math_1_large.png",
                "caption": "Table 29:An example of solving a geometry problem.",
                "position": 8594
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/math_2_large.png",
                "caption": "Table 30:An example of solving an algebra problem.",
                "position": 8693
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/math_3_large.png",
                "caption": "Table 31:An example of solving an analytic geometry problem.",
                "position": 8815
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/ui_demo1.png",
                "caption": "Table 32:An example of Mobile UI understanding and reasoning.",
                "position": 8916
            },
            {
                "img": "https://arxiv.org/html/2510.11496/figure/ui_demo2.png",
                "caption": "Table 33:An example of Mobile UI understanding and reasoning.",
                "position": 8969
            }
        ]
    },
    {
        "header": "Appendix CQualitative Examples",
        "images": []
    }
]