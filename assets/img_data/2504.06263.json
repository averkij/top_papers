[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x1.png",
                "caption": "",
                "position": 105
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x2.png",
                "caption": "Figure 2:Overview of OmniSVG. OmniSVGÂ is built on a pre-trained vision-language model Qwen2.5-VL and incorporates an SVG tokenizer. The model tokenizes both text and image inputs as prefix tokens, while the SVG tokenizer encodes vector graphics commands into a unified representation space.",
                "position": 184
            }
        ]
    },
    {
        "header": "3MMSVG-2M",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x3.png",
                "caption": "Table 2:SVG draw-commands. Draw commands used in this work along with their arguments and a visualization are listed. The start-position(x1(x_{1}( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,y1)y_{1})italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT )is implicitly defined as the end-position of the preceding command.",
                "position": 257
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x4.png",
                "caption": "",
                "position": 356
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x5.png",
                "caption": "",
                "position": 408
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x6.png",
                "caption": "",
                "position": 464
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x7.png",
                "caption": "",
                "position": 490
            }
        ]
    },
    {
        "header": "4OmniSVG",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x8.png",
                "caption": "(a)Training PPL for our models.",
                "position": 638
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x8.png",
                "caption": "(a)Training PPL for our models.",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x9.png",
                "caption": "(b)Validation PPL for our models.",
                "position": 647
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x10.png",
                "caption": "Figure 4:Qualitative comparison with SOTA methods on Text-to-SVG task. We compare the propose method with SOTA Text-to-SVG methods on our evaluation benchmarks, namely Icon, Illustration and Character. The proposed method outperforms existing state-of-the-art approaches in both instruction-following and the aesthetic quality of the generated SVGs.",
                "position": 1119
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x11.png",
                "caption": "Figure 5:Qualitative comparison with SOTA methods on Image-to-SVG task. We compare the propose method with SOTA Image-to-SVG methods on our evaluation benchmarks. Despite generating plausible results on simple icon samples, optimization based methods like DiffVG[25]and LIVE[30]tend to output artifacts on complex images. GPT-4o[18]is only able to generate icon-level SVG even given the complex input image. StarVector[37]is able to generate SVG for the input icon image. However, when inputed the illustration or more complex character image, StarVector fails to generate SVGs. Please zoom-in for more details.",
                "position": 1123
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x12.png",
                "caption": "Figure 6:Generated SVG with Character-Reference (CRef) by OmniSVG.By training on MMSVG-Character with natural character image and SVG pair data, OmniSVG is capable of generating character SVGs through image references.",
                "position": 1142
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x13.png",
                "caption": "Figure 7:Qualitative study on parametrization.Ablation studies on color parametrization (abbreviated as param.) and coordinate (abbreviated ad coord.) paramterization are conducted.",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x14.png",
                "caption": "Figure 8:Illustration of the SVG generation capabilities of OmniSVG.",
                "position": 1177
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x15.png",
                "caption": "Figure 9:Limitation of OmniSVG on Image-to-SVG Task. OmniSVG can successfully generate vector style images, while fail to fit natural images.",
                "position": 1595
            }
        ]
    },
    {
        "header": "Appendix AAdditional Details of MMSVG-2M dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.06263/x16.png",
                "caption": "Figure 10:Samples from MMSVG-2M dataset. The proposed MMSVG-2M dataset can be separated into three subset, namely Icon, Illustration and Character. Samples from Icon, Illustration and part of Character subsets are downloaded from Internet. Another part of Character subset is generated by our data creation pipeline, which can provide image and SVG pairs for image prompting task.",
                "position": 1627
            },
            {
                "img": "https://arxiv.org/html/2504.06263/x17.png",
                "caption": "Figure 11:Image prompting dataset creation of MMSVG-2M Character. By utilizing FLUX-Redux and SVG vectorization tools, image prompting data pairs can be generated. We adpot FLUX-Redux downsampling scale with2,3232,32 , 3in practice by trading-off the character similarity and complexity of generated SVG.",
                "position": 1639
            },
            {
                "img": "https://arxiv.org/html/2504.06263/extracted/6346030/files/wordcloud.png",
                "caption": "Figure 12:Word cloud visualization of label distribution in the MMSVG-2M dataset.The size of each label corresponds to its frequency of occurrence. The larger the label, the more frequently it appears in the dataset.",
                "position": 1645
            }
        ]
    },
    {
        "header": "Appendix BMore details of the baselines",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]