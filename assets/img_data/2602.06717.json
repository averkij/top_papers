[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06717/x1.png",
                "caption": "Figure 1:(a) Probability that a training update isactive(mixed rewards in batch) yetmissesrare-correct solutions, as a function of group sizeNN. This probability peaks at intermediateNN: small groups rarely produce learning signal, large groups cover rare modes, but moderate groups combine active updates with poor coverage.\n(b,c) Empirical consequences on AIME 2025 (math) and IFEval (OOD): GRPO atN=8N{=}8improves pass@1 overN=2N{=}2but degrades pass@256, consistent with the sharpening regime. F-GRPO atN=8N{=}8recovers pass@256 while maintaining pass@1, using4×4{\\times}less compute thanN=32N{=}32.",
                "position": 127
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Theoretical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06717/x2.png",
                "caption": "Figure 2:Tail-miss probabilityPr⁡(ℬτ)\\Pr(\\mathcal{B}_{\\tau})from Lemma3.1versus group sizeNN. Each panel fixesμpos∈{0.8,0.5,0.2}\\mu_{\\mathrm{pos}}\\in\\{0.8,0.5,0.2\\}; curves varyρ=τ/μpos\\rho=\\tau/\\mu_{\\mathrm{pos}}, the fraction of correct mass in the rare-correct region. Stars mark peaks. For all parameter combinations,Pr⁡(ℬτ)\\Pr(\\mathcal{B}_{\\tau})peaks at intermediateNN: smallNNyields low activity, largeNNyields good coverage, but moderateNNcombines active groups with poor coverage of rare modes. Smallerρ\\rhoshifts the peak rightward and upward.",
                "position": 343
            }
        ]
    },
    {
        "header": "4F-GRPO: Focal weighting for Group-Relative Policy Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06717/x3.png",
                "caption": "Figure 3:Scaled advantage magnitudeg​(x)⋅|A^GRPO|g(x)\\cdot|\\widehat{A}^{\\mathrm{GRPO}}|versus success probabilityμpos​(x)\\mu_{\\mathrm{pos}}(x)for binary rewards. Solid lines: correct rollouts; dashed lines: incorrect rollouts. Higherγ\\gammasuppresses updates on high-success prompts, shifting gradient contribution toward prompts where the policy succeeds less frequently.",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2602.06717/x4.png",
                "caption": "Figure 4:Categorical policy simulation followingHuet al.(2025)setup.(a)Total correct massQposQ_{\\mathrm{pos}}vs. training step.(b)Retained positive massℳret\\mathcal{M}_{\\mathrm{ret}}vs. step.(c)Final metrics vs. group sizeNN, with three regimes:IslowQposQ_{\\mathrm{pos}}growth, diversity preserved;IIconcentration zone (shaded),QposQ_{\\mathrm{pos}}grows butℳret\\mathcal{M}_{\\mathrm{ret}}collapses;IIIboth metrics high. Solid:γ=0\\gamma{=}0; dashed:γ=1\\gamma{=}1.N=131​kN{=}131\\text{k}maintainsℳret≈1\\mathcal{M}_{\\mathrm{ret}}{\\approx}1throughout, consistent withPr⁡(ℬτ)<10−3\\Pr(\\mathcal{B}_{\\tau})<10^{-3}(AppendixJ).",
                "position": 520
            }
        ]
    },
    {
        "header": "5Experiments & Results",
        "images": []
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof of Lemma3.1",
        "images": []
    },
    {
        "header": "Appendix BMonotonicity of Sampled Distinct Mass Conditioned onXX",
        "images": []
    },
    {
        "header": "Appendix CFirst-order Softmax Expansion and Subset-mass Identity",
        "images": []
    },
    {
        "header": "Appendix DProof of Proposition3.2",
        "images": []
    },
    {
        "header": "Appendix EDetailed Term Analysis for Proposition3.2",
        "images": []
    },
    {
        "header": "Appendix FGroup Size Comparison: Full Results",
        "images": []
    },
    {
        "header": "Appendix GEntropy and KL Regularization: Full Results",
        "images": []
    },
    {
        "header": "Appendix HExperimental Details",
        "images": []
    },
    {
        "header": "Appendix IStatistical Significance",
        "images": []
    },
    {
        "header": "Appendix JCategorical Simulation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06717/x5.png",
                "caption": "Figure 5:Tail-miss probabilityPr⁡(ℬτ)\\Pr(\\mathcal{B}_{\\tau})versus group sizeNNforμpos=0.64\\mu_{\\mathrm{pos}}=0.64andτ=6.3×10−5\\tau=6.3\\times 10^{-5}(corresponding to a non-anchor correct action in the simulation). The non-monotonic shape explains the concentration zone: intermediateNNmaximizes the probability that a correct action is unsampled while the batch contains mixed rewards.",
                "position": 2934
            }
        ]
    },
    {
        "header": "Appendix KNotation",
        "images": []
    }
]