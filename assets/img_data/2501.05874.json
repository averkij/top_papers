[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.05874/x1.png",
                "caption": "Figure 1:A conceptual illustration of existing and the proposed RAG scenarios. (A) Textual RAG retrieves documents (relevant to queries) from a text corpus and incorporates them when generating answers. (B) Conventional multimodal RAG extends retrieval to include static images. (C)VideoRAG(ours) further extends the external knowledge source to videos.",
                "position": 165
            }
        ]
    },
    {
        "header": "2Method",
        "images": []
    },
    {
        "header": "3Experimental Setups",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.05874/x2.png",
                "caption": "Table 1:Overall RAG results across four metrics. The best results are highlighted inbold, and the second-best results are highlighted withunderline. Note that theOraclesetting (that uses ideal retrieval results) is not comparable to others.",
                "position": 250
            }
        ]
    },
    {
        "header": "4Experimental Results and Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.05874/x2.png",
                "caption": "Table 3:Retrieval results, where we use visual features alone, textual features alone, or an ensemble of their features.",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2501.05874/x2.png",
                "caption": "Figure 2:Impact of varying the interpolation ratio between textual and visual features on retrieval performance.",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2501.05874/x3.png",
                "caption": "Figure 3:Visualization of latent space of features across modalities with Principal Component Analysis (PCA).",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2501.05874/x4.png",
                "caption": "Figure 4:Breakdown performance of different models across 10 different categories.",
                "position": 506
            },
            {
                "img": "https://arxiv.org/html/2501.05874/x5.png",
                "caption": "Table 4:Case study comparingNa√ØveandVideoRAG-Vapproaches.",
                "position": 527
            },
            {
                "img": "https://arxiv.org/html/2501.05874/x6.png",
                "caption": "Table 6:Case study comparingTextRAG (BM25)andVideoRAG-Vapproaches.",
                "position": 641
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]