[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04812/x1.png",
                "caption": "",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2503.04812/x2.png",
                "caption": "",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2503.04812/x3.png",
                "caption": "",
                "position": 131
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04812/extracted/6207769/figures/distribution.png",
                "caption": "Figure 1:Similarity distributions of learned embeddings on the SUN397Xiao et¬†al. (2010)and RefCOCOKazemzadeh et¬†al. (2014)dataset. We present the query-target cosine similarity histograms of positive, hard negative, and easy negative pairs for the model trained with the standard InfoNCE loss and LLaVE.",
                "position": 157
            }
        ]
    },
    {
        "header": "2Preliminary Study",
        "images": []
    },
    {
        "header": "3Our Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04812/extracted/6207769/figures/model.png",
                "caption": "Figure 2:Overview of hardness-weighted contrastive learning. Please note that the policy and reward models are identical in our work. The dashed line indicates directly copying the parameters of the policy model to the reward model.",
                "position": 329
            },
            {
                "img": "https://arxiv.org/html/2503.04812/extracted/6207769/figures/cross-device.png",
                "caption": "Figure 3:An example of cross-device negative sample gathering (NùëÅNitalic_N=4444andKùêæKitalic_K=3333). The plus signs represent positive pairs, and the minus signs represent negative pairs. Each device calculates the similarity between its own queries and the targets on all other devices, which is then used for loss computation.",
                "position": 408
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.04812/extracted/6207769/figures/alpha.png",
                "caption": "Figure 4:Influence of theŒ±ùõº\\alphaitalic_Œ±on model performance, measured on IND and OOD datasets, respectively.",
                "position": 1465
            },
            {
                "img": "https://arxiv.org/html/2503.04812/extracted/6207769/figures/case.png",
                "caption": "Figure 5:Qualitative evaluation comparing LLaVE and VLM2Vec. Retrievals consistent with the ground truth are highlighted with red borders. From left to right, the images represent the top-1 to top-3 retrieval results.",
                "position": 2204
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]