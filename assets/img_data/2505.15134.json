[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": []
    },
    {
        "header": "3Entropy Minimization for Post-training",
        "images": []
    },
    {
        "header": "4EM-INF: Inference-time Logit Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15134/",
                "caption": "Figure 2:Computational efficiency of EM-INF compared to self-consistency withN=4,8,16ùëÅ4816N\\!=\\!4,8,16italic_N = 4 , 8 , 16on AMC.",
                "position": 963
            }
        ]
    },
    {
        "header": "5Limitations: Dependence on Base Model Capability and Confidence",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProof for proposition1",
        "images": []
    },
    {
        "header": "Appendix BAdaptive Temperature Scaling",
        "images": []
    },
    {
        "header": "Appendix CAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.15134/extracted/6461330/em_inf_self_consist_amc.png",
                "caption": "(a)Accuracy vs. FLOPs for combiningEM-INFand self-consistency at inference time on AMC.",
                "position": 2641
            },
            {
                "img": "https://arxiv.org/html/2505.15134/extracted/6461330/em_inf_self_consist_amc.png",
                "caption": "(a)Accuracy vs. FLOPs for combiningEM-INFand self-consistency at inference time on AMC.",
                "position": 2644
            },
            {
                "img": "https://arxiv.org/html/2505.15134/extracted/6461330/em_inf_iter_refine_leetcode.png",
                "caption": "(b)Accuracy vs. FLOPs for combiningEM-INFand iterative refinement at inference time on LeetCode.",
                "position": 2649
            },
            {
                "img": "https://arxiv.org/html/2505.15134/extracted/6461330/scicode_qualitative_analysis.png",
                "caption": "Figure 4:Qualitative analysis ofEM-INFon SciCode. Qwen2.5-7B-Instruct‚Äôs generated code (Left) fails to add random noise to all elements in the matrix, whereas the code generated withEM-INF(Right) performs the correct operation. We observe thatEM-INF(1) reduces the diversity of generated tokens and is more deterministic as expected; (2) generates correct code; (3) produces more concise outputs; and (4) is more helpful in scientific coding tasks like SciCode where LLMs are highly uncertain.",
                "position": 2669
            }
        ]
    },
    {
        "header": "Appendix DExperimental Setup",
        "images": []
    }
]