[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Group Think",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/gt_main_new.png",
                "caption": "Figure 1:Illustration of Group Think.Distinct threads of reasoning thoughts (indicated with superscripts(1),(2)12{(1)},{(2)}( 1 ) , ( 2 )) are parallelized with an inter-agent attention mechanism acting at the token level. Each tokenxk(‚ãÖ)superscriptsubscriptùë•ùëò‚ãÖx_{k}^{(\\cdot)}italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( ‚ãÖ ) end_POSTSUPERSCRIPTin a thread is able to attend to all previous tokens from all other threads at every generation time step, thereby inducing fine-grained collaborative behaviour. Tokens in green are generated in parallel. Normal intra-agent self-attention are depicted by solid orange arrows, while inter-agent cross attention by dashed lines.",
                "position": 191
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/gt_procedure_2_new.png",
                "caption": "Figure 2:Implementation of Group Think for local inference scenario.Artificial batches can be created in the low batch regime by rearranging sequences for the agents into distinct ‚Äúdata points‚Äù. At each time step, sequences for different thinkers are augmented with previous predictions from other thinkers, allowing self-attention mechanisms to include cross-agent dependencies at the token level. Green tokens are generated using a standard causal mask‚Äîwith some sparsity in the positional encodings corresponding to the locations of padding tokens.",
                "position": 285
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/gt_interleaved_1.png",
                "caption": "Figure 3:Implementation of Group Think for single thread data center inference scenario.Each agent is allocated a slot of token indexes: agent 1 (orange tokens) is allocated positions 110 to 169, while agent 2 (blue tokens) has 170 to 219. Token prediction for all agents is performed by adapting the sequence layout to interleave tokens from different agents, hence leading to non-sequential positional indices. At each time steptùë°titalic_t,NùëÅNitalic_Nnew tokens (green) are generated with a common causal mask, allowing both intra-agent and inter-agent attention. Tokens from previous timesteps (represented by semi-transparent blocks) are inserted in the KV cache. This design allows Group Think instances to be processed together with other requests in a batch within a data center environment.",
                "position": 296
            }
        ]
    },
    {
        "header": "4Can Pretrained LLMs Elicit Group Think? An Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_k_enumeration_cmpCOT_fix0515.png",
                "caption": "(a)Enumeration",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_k_enumeration_cmpCOT_fix0515.png",
                "caption": "(a)Enumeration",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_k_divide_and_conquer_cmpCOT_fix0515.png",
                "caption": "(b)Divide and Conquer",
                "position": 332
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_k_coding_cmpCOT_fix0515.png",
                "caption": "(c)Programming",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_n_enumeration_cmpCOT_fix0515.png",
                "caption": "(a)Enumeration",
                "position": 391
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_n_enumeration_cmpCOT_fix0515.png",
                "caption": "(a)Enumeration",
                "position": 394
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_n_divide_and_conquer_cmpCOT_fix0515.png",
                "caption": "(b)Divide and Conquer",
                "position": 399
            },
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/perf_vs_n_coding_cmpCOT_fix0515.png",
                "caption": "(c)Programming",
                "position": 404
            }
        ]
    },
    {
        "header": "5Discussion & Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Details for Data Center Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.11107/extracted/6445446/figures/gt-text-infill.png",
                "caption": "Figure 6:Interpretation of Group Think as a text infilling task.Each agent is allocated a slot of token position indexes which are gradually filled in. In this example, agent 1 (orange tokens) starts from index 110, and agent 2 (blue tokens) from index 170. As new tokens (in green) are generated, the KV cache (shown on the right) is filled. Each new tokenxt(n)subscriptsuperscriptùë•ùëõùë°x^{(n)}_{t}italic_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTfor thinkernùëõnitalic_n(shown in green) is generated using a standard causal mask, implicitly enabling each agent to attend to the sequences of all other agents, as they are contained in the KV cache.",
                "position": 1104
            }
        ]
    },
    {
        "header": "Appendix BGeneral Experiment Settings",
        "images": []
    },
    {
        "header": "Appendix CDetails of enumeration benchmark",
        "images": []
    },
    {
        "header": "Appendix DDetails of divide and conquer benchmark",
        "images": []
    },
    {
        "header": "Appendix EDetails of coding benchmark",
        "images": []
    },
    {
        "header": "Appendix FReasoning trajectory samples for the Enumeration benchmark",
        "images": []
    },
    {
        "header": "Appendix GReasoning trajectory samples for the Programming task",
        "images": []
    }
]