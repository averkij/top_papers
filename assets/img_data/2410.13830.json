[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13830/x1.png",
                "caption": "Figure 1:Customized video generation results of DreamVideo-2. Our method precisely generates customized subjects at specified positionswithout fine-tuning at inference time.",
                "position": 86
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13830/x2.png",
                "caption": "Figure 2:Overall framework of DreamVideo-2. During training, a random video frame is segmented to obtain the subject image with a blank background.\nThe bounding boxes extracted from the training video are converted into binary box masks.\nThen, the subject image is treated as a single-frame video and processed in parallel with the video by masked reference attention that incorporates blended masks to learn the subject appearance.\nMeanwhile, box masks are fed into a motion module that includes a spatiotemporal encoder and a ControlNet for motion control.\nBoth the masked reference attention and motion module are trained using a reweighted diffusion loss.",
                "position": 221
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13830/x3.png",
                "caption": "Figure 3:Illustration of motion control domination in DreamVideo-2. As seen in (b) and (c), motion control tends to dominate over subject learning during training, causing the degradation of subject identity.\nIn (d), our method ensures a balance between subject and motion control.",
                "position": 307
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13830/x4.png",
                "caption": "Figure 4:Qualitative comparison of joint subject customization and motion control. DreamVideo-2 generates videos with customized subjects and precise motion trajectory control, while other methods suffer from control conflicts, especially when trained on a single image.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x5.png",
                "caption": "Figure 5:Qualitative comparison of subject customization. DreamVideo-2 generates videos with accurate subject appearance and enhanced motion dynamics, aligning with provided prompts.",
                "position": 622
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x6.png",
                "caption": "Figure 6:Qualitative comparison of motion control.\nOur DreamVideo-2 achieves precise motion trajectory control and effectively maintains subjects within the specified bounding boxes.",
                "position": 685
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x7.png",
                "caption": "Figure 7:Human evaluationon joint subject customization and motion control.",
                "position": 763
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x8.png",
                "caption": "Figure 8:Qualitative ablation studieson each component and blended mask weight.",
                "position": 777
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "7Ethics Statement",
        "images": []
    },
    {
        "header": "8Reproducibility Statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.13830/x9.png",
                "caption": "Figure 9:Pipeline of dataset construction.",
                "position": 2480
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x10.png",
                "caption": "Figure 10:Failure cases.(a) Our method is limited by the base modelâ€™s inherent capabilities.\n(b) Our method struggles to decouple the camera and object motion control.",
                "position": 2635
            },
            {
                "img": "https://arxiv.org/html/2410.13830/x11.png",
                "caption": "Figure 11:More qualitative results of DreamVideo-2. Zoom in for a better view.",
                "position": 2652
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]