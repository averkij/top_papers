[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x1.png",
                "caption": "Figure 1:The comparison of static and dynamic testing processes. Our WorldGUI takes the first step to facilitate comprehensive GUI evaluation with various initial states. The red node represents an incorrect state.",
                "position": 102
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x2.png",
                "caption": "Figure 2:WorldGUI: An illustration of our proposed real-world GUI benchmark. The left shows that for each task, WorldGUI provides a user query, instructional video, and pre-actions. The pre-actions lead to different initial states. The key characteristic of our WorldGUI is the various initial states of the same task to stimulate the real-world testing process. The right shows the software included in our benchmark and the interactions about testing the agents in our GUI environment.",
                "position": 127
            }
        ]
    },
    {
        "header": "3WorldGUI Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x3.png",
                "caption": "Figure 3:GUI-Thinker. An overview of GUI-Thinker, includes five proposed components: Planner, Planner-Critic, Step-Check, Actor, and Actor-Critic. The Planner module receives the user query and an instructional video as input and generates an initial plan for the Planner-Critic process. This plan is then refined and executed step by step. Before each step is passed to the Actor module, it undergoes a Step-Check. After the Actor produces an action, the Actor-Critic module iteratively verifies the completion of the action and makes corrections if needed.",
                "position": 185
            }
        ]
    },
    {
        "header": "4GUI-Thinker: Thinking before Doing",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x4.png",
                "caption": "Figure 4:State-Aware Planner and Planner-Critic. The Planner generates an initial plan. Then, the Planner-Critic will assess the correctness of the plan and provide necessary corrections.",
                "position": 262
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x5.png",
                "caption": "Figure 5:Step-Check. This module first checks the step completion status via an MLLM, and then based on the output navigates current task processing.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x6.png",
                "caption": "Figure 6:Actor-Critic. This module includes two parts: task verification and task correction. The design follows theverify-then-correctmechanism. We set an internal loop in this module to iteratively correct the actions.",
                "position": 290
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": []
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "Impact Statement",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AComparison with other benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/extracted/6196878/figures/sdinterface.png",
                "caption": "Figure 7:An example of using Stable Diffusion for media creation in WorldGUI. The left shows the interface of using stable diffusion to create the photo. The right shows the user query and GT plan. If no instructional video, it is hard to include all the settings",
                "position": 1211
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x7.png",
                "caption": "",
                "position": 1214
            }
        ]
    },
    {
        "header": "Appendix BDetails of Actor Space",
        "images": []
    },
    {
        "header": "Appendix CData",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x8.png",
                "caption": "Figure 8:An example of augmenting one GUI task with manually aug the initial state and then using the execution scripts and corresponding agents to obtain the pre-action for each augmented case.",
                "position": 1329
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x9.png",
                "caption": "Figure 9:We present the examples of conducting the augmentations from the meta task.",
                "position": 1333
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x10.png",
                "caption": "Figure 10:Distribution of collect tasks, selected queries, and task amount of WorldGUI. We have gathered tasks across 10 desktop applications, focusing on the use of productivity software as well as fundamental computer operations and settings.",
                "position": 1417
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x11.png",
                "caption": "",
                "position": 1420
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x12.png",
                "caption": "",
                "position": 1421
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x13.png",
                "caption": "Figure 11:Pipeline of Data Construction. Human: Represents the annotators. Code: Refers to the scripts (e.g., Python Code) utilized to achieve the goal. Agent: We design an agent built upon the MLLMs to achieve the goal.",
                "position": 1425
            }
        ]
    },
    {
        "header": "Appendix DGUI-Thinker Reasoning Loop Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.08047/x14.png",
                "caption": "Figure 12:We show one successful prediction of our GUI-Thinker.",
                "position": 1516
            },
            {
                "img": "https://arxiv.org/html/2502.08047/extracted/6196878/figures/excel_parser.png",
                "caption": "Figure 13:We show two examples of using GUI Parser to obtain the element position information.",
                "position": 1519
            },
            {
                "img": "https://arxiv.org/html/2502.08047/extracted/6196878/figures/yt_parser.png",
                "caption": "",
                "position": 1522
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x15.png",
                "caption": "Figure 14:An example of using Planner-Critic to correct the plan.",
                "position": 1529
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x16.png",
                "caption": "Figure 15:Two examples of using Step-Check to check the subtask status.",
                "position": 1532
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x17.png",
                "caption": "Figure 16:An example of using Actor-Critic to correct the actions.",
                "position": 1535
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x18.png",
                "caption": "Figure 17:We display some common errors.",
                "position": 1542
            },
            {
                "img": "https://arxiv.org/html/2502.08047/x19.png",
                "caption": "Figure 18:We display some common errors",
                "position": 1545
            }
        ]
    },
    {
        "header": "Appendix EQualitative Results",
        "images": []
    }
]