[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04195/x1.png",
                "caption": "Figure 1:The gap between conventional speech processing systems and paralinguistic-aware modeling.(a)Common speech datasets omit paralinguistic vocalizations, while NVSpeech provides word-level annotations.(b)Conventional ASR ignores such cues; our paralinguistic-aware ASR jointly transcribes lexical and non-lexical content.(c)Standard TTS generates only text-based speech, while our TTS supports explicit insertion of paralinguistic vocalizations for human-like synthesis.",
                "position": 123
            }
        ]
    },
    {
        "header": "Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04195/x2.png",
                "caption": "Figure 2:Overview of our paralinguistic-aware speech recognition and generation pipeline.(1) A word-level human annotated dataset of verbal and non-verbal vocalizations is first constructed. (2) A paralinguistic-aware ASR model is trained to jointly transcribe verbal and non-verbal content. (3) This model is used to automatically annotate large-scale unlabeled speech. (4) The expanded dataset enables training a controllable and expressive TTS system that explicitly renders paralinguistic cues.",
                "position": 402
            }
        ]
    },
    {
        "header": "Paralinguistic Speech Recognition Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04195/x3.png",
                "caption": "Figure 3:Performance of paralingustic-aware ASR.",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2508.04195/x3.png",
                "caption": "Figure 4:F1 scores across paralinguistic categories.",
                "position": 615
            }
        ]
    },
    {
        "header": "The NVSpeech Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04195/x4.png",
                "caption": "(a)NVSpeechhuman",
                "position": 732
            },
            {
                "img": "https://arxiv.org/html/2508.04195/x4.png",
                "caption": "(a)NVSpeechhuman",
                "position": 735
            },
            {
                "img": "https://arxiv.org/html/2508.04195/x5.png",
                "caption": "(b)NVSpeech",
                "position": 740
            }
        ]
    },
    {
        "header": "Paralinguistic-enhanced TTS Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04195/x6.png",
                "caption": "Figure 6:Para-enhanced vs. Original (Human Preference).",
                "position": 935
            }
        ]
    },
    {
        "header": "Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]