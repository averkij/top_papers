[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19363/x1.png",
                "caption": "Figure 1:Model trajectories on long-context multi-hop QA with and without KeyChain RL data.(a)With KeyChain data, model exhibits an emergent plan–retrieve–reason–recheck thinking pattern, improving reasoning reliability and can generalize to longer contexts.(b)Without KeyChain data, reasoning and retrieval are entangled, the model often lacks an explicit planning step and does not deeply reason over retrieved information, frequently leading to errors. Reasoning steps are marked in blue and retrieval steps in orange.",
                "position": 92
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19363/x2.png",
                "caption": "Figure 2:Overview of our KeyChain data construction.",
                "position": 119
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19363/x3.png",
                "caption": "Figure 3:Needle in a Haystack retrieval across document depths. The base Qwen2.5-7B-Instruct does not fully pass the benchmark, whereas LoongRL-7B achieves perfect 100% retrieval accuracy.",
                "position": 709
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x3.png",
                "caption": "",
                "position": 712
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x4.png",
                "caption": "",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x5.png",
                "caption": "",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x6.png",
                "caption": "",
                "position": 725
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x7.png",
                "caption": "Figure 4:Long-context reasoning accuracy and training response lengths throughout RL training.",
                "position": 738
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility statement",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.19363/x8.png",
                "caption": "Figure 6:A skeleton of KeyChain-augmented training data used in LoongRL.",
                "position": 1597
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x9.png",
                "caption": "Figure 7:Training metrics for the three-stage schedule. Vertical dashed lines mark the transitionsWarmup→\\rightarrowStage II (distractor-augmented)andStage II→\\rightarrowStage III (hard-mined); stage lengths correspond to our setup (about 42, 168, and 117 steps).",
                "position": 1720
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x10.png",
                "caption": "Figure 8:Training metrics for the LoongRL-14B’s two-stage schedule. Vertical dashed lines mark the transitionsStage I (distractor-augmented)and→\\rightarrowStage III (hard-mined); stage lengths correspond to our setup (about 168, and 150 steps).",
                "position": 1723
            },
            {
                "img": "https://arxiv.org/html/2510.19363/x11.png",
                "caption": "Figure 9:Needle-in-a-Haystack performance of LoongRL-14B.",
                "position": 2145
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]