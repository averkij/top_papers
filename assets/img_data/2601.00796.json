[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.00796/x1.png",
                "caption": "",
                "position": 147
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.00796/x2.png",
                "caption": "Figure 2:Hierarchical frequency adaptation.Our primitives adaptively transition from Gaussian (topleft) to Gabor (bottom), enabling coarse-to-fine reconstruction. Each primitive learns its optimal frequency response via learnable weightsωi\\omega_{i}, achieving both geometric stability and texture detail in a unified framework.",
                "position": 226
            }
        ]
    },
    {
        "header": "3Preliminary: 3D Gaussian Splatting",
        "images": []
    },
    {
        "header": "4Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.00796/x3.png",
                "caption": "Figure 3:Method overview.Our approach represents dynamic videos as Adaptive Gabor primitives with temporally smooth motion. (Input) Multi-modal supervision from RGB, depth, tracking, and masks. (Optimization) Two core components: (1)Adaptive Motion: Cubic Hermite splines model primitive trajectories with control pointsμ​(t)\\mu(t),q​(t)q(t)in orthographic camera space, ensuring C1continuity. (2)Adaptive Gabor Representation: Learnable frequency weightsωk\\omega_{k}enable primitives to adaptively span from Gaussian (low-freq) to Gabor (high-freq), achieving hierarchical detail reconstruction. (Loss) Joint optimization via RGB, depth, flow supervision, and curvature regularizationLc​u​r​vL_{curv}. (Application) Supports frame interpolation, depth consistency, and video editing.",
                "position": 272
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x4.png",
                "caption": "Figure 4:Adaptive Gabor formulation.(a) Smooth transition between Gaussian and Gabor kernels.Our method (rightmost column,Sours​(x)S_{\\text{ours}}(x)) uses a compensation termbbto maintain energy stability while transitioning from pure Gaussian (ω=0\\omega=0, top) to frequency-modulated Gabor (ω=1\\omega=1, bottom). Naive combination1+S​(x)1+S(x)(third column) suffers from intensity artifacts.(b) Frequency weight combinations.Different (ω0\\omega_{0},ω1\\omega_{1}) pairs generate diverse spatial patterns, from smooth (lowω\\omega) to high-frequency textures (highω\\omega), enabling adaptive detail capture in different scene regions.",
                "position": 345
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x5.png",
                "caption": "",
                "position": 355
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.00796/x6.png",
                "caption": "Figure 5:Visual comparison on DAVIS dataset.Our method preserves finer details (fur, vehicle edges, wheel structures) and sharper motion boundaries compared to CoDeF[62]and Splatter A Video[76].Redboxes highlight key regions demonstrating our superior texture reconstruction and temporal consistency. Best viewed zoomed in.",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x7.png",
                "caption": "Figure 6:Depth consistency across time.(Left)Our 3D primitive representation maintains consistent depth for static elements across frames.(Right)While per-frame estimation (Marigold[37]) shows temporal flickering (redboxes). Explicit 3D geometry with smooth motion modeling ensures temporal coherence essential for depth-based video applications.",
                "position": 698
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x8.png",
                "caption": "Figure 7:Frame interpolation results.Our method generates temporally smooth intermediate frames between input keyframesttandt+1t+1by querying Cubic Hermite splines at fractional timestamps. The interpolated sequence (1st\\text{1}^{\\text{st}}through4th\\text{4}^{\\text{th}}frames) maintains consistent fur texture details and natural motion without ghosting artifacts. Red boxes show the preservation of high-frequency details throughout the interpolation. This demonstrates our method’s ability to produce continuous motion withC1C^{1}smoothness via curvature-regularized spline trajectories. Please refer to the supplementary video for full temporal coherence.",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x9.png",
                "caption": "Figure 8:Temporally consistent video editing.(Top) Per-frame editing causes temporal flickering with inconsistent styles between frames. (Bottom) Our canonical space editing maintains temporal consistency by applying style transfer to shared Adaptive Gabor primitives, ensuring identical treatment of scene elements across time while preserving motion dynamics.Redboxes highlight key differences. Please see the supplementary video.",
                "position": 724
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x10.png",
                "caption": "Figure 9:Stereo view synthesis.Our 3D representation enables novel view synthesis for stereo visualization from monocular video. This demonstrates that Adaptive Gabor primitives in orthographic camera coordinate space capture accurate 3D geometry, enabling immersive applications.",
                "position": 736
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x11.png",
                "caption": "Figure 10:Curvature regularization ablation.(Left)Withoutℒcurv\\mathcal{L}_{\\text{curv}}, interpolated frames show motion artifacts from trajectory oscillations.(Right)Our method produces smooth, artifact-free interpolation by constraining second-order derivatives, validating the necessity of explicit curvature control for temporal consistency.",
                "position": 850
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x12.png",
                "caption": "Figure 11:Adaptive initialization ablation.(Left) Without motion-aware initialization, primitives are poorly distributed, causing blurred details.(Right)Our adaptive initialization based on depth, tracking, and masks (Eqs.17,18and19) provides better initial geometry, yielding 6.78 dB improvement and sharp reconstruction.",
                "position": 861
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AActivation for Gabor Coefficients",
        "images": []
    },
    {
        "header": "Appendix BProof of Adaptive Degradation to Gaussian",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.00796/x13.png",
                "caption": "Figure 12:Visual comparison on DAVIS dataset.",
                "position": 2461
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x14.png",
                "caption": "Figure 13:Visual comparison on DAVIS dataset.",
                "position": 2475
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x15.png",
                "caption": "",
                "position": 2479
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x16.png",
                "caption": "Figure 14:Visual comparison on DAVIS dataset.",
                "position": 2483
            },
            {
                "img": "https://arxiv.org/html/2601.00796/x17.png",
                "caption": "",
                "position": 2487
            }
        ]
    },
    {
        "header": "Appendix CAdditional Visual Comparisons and Results",
        "images": []
    }
]