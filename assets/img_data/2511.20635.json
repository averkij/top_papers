[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20635/x1.png",
                "caption": "",
                "position": 100
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20635/x2.png",
                "caption": "Figure 2:Overview of iMontage.The model accepts a flexible set of reference images and producesNoutputs conditioned on a text prompt. Images are encoded by a 3D VAE separately, text by a language model, and both token streams are processed by an MMDiT. We concatenate clean reference-image tokens with noisy target tokens before denoising.Right:training uses fixed-length text tokens and variable-length image/noise tokens, transitions from dual stream to single stream blocks. For image branch, we applyMarginal RoPE, a head–tail temporal indexing that separates input and output pseudo-frames, preserves spatial RoPE, and supports many-to-many generation. In figure, notation H and W with subscription denote the height/width indices of the 2D RoPE computed at the image’s native resolution, while notation T represents assigned time index for temporal dimension.",
                "position": 152
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20635/x3.png",
                "caption": "Figure 3:Overview of our dataset:Our dataset is constructed from four sources and is organized into two stages, comprising high-quality foundational data and multiple task-oriented subsets.",
                "position": 182
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20635/x4.png",
                "caption": "Figure 4:Comparison with three baselines on storyboard generation setting. Single character and many characters samples are presented.",
                "position": 1228
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x5.png",
                "caption": "Figure 5:Ablation on different RoPE strategy.We evaluate on a subset of the editing data with low resolution, training each strategy for the same number of steps. In the figure, corner numbers indicate provenance:1original input,2edited ground truth,3output fromMarginal RoPE, and4output fromEven RoPE.",
                "position": 1732
            }
        ]
    },
    {
        "header": "5Conclusion and Limitations",
        "images": []
    },
    {
        "header": "6Implementation Details",
        "images": []
    },
    {
        "header": "7More Qualitative Results",
        "images": []
    },
    {
        "header": "8Detailed Experimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.20635/x6.png",
                "caption": "Figure 6:Visualization results for image editing. Zoom in to see more details.",
                "position": 2321
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x7.png",
                "caption": "Figure 7:Visualization results for image editing. Zoom in to see more details.",
                "position": 2324
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x8.png",
                "caption": "Figure 8:Visualization results for multi CRef. Zoom in to see more details.",
                "position": 2327
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x9.png",
                "caption": "Figure 9:Visualization results for conditioned CRef and SRef. Zoom in to see more details.",
                "position": 2330
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x10.png",
                "caption": "Figure 10:Visualization results for multi view generation, which can be divided to object-centric and scene-centric. Zoom in to see more details.",
                "position": 2333
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x11.png",
                "caption": "Figure 11:Representative failure case for certain task. Zoom in to see more details.",
                "position": 2336
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x12.png",
                "caption": "Figure 12:User study template.",
                "position": 2339
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x13.png",
                "caption": "Figure 13:User study comparison visualization results. Zoom in to see more details.",
                "position": 2343
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x14.png",
                "caption": "Figure 14:User study comparison visualization results. Zoom in to see more details.",
                "position": 2346
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x15.png",
                "caption": "Figure 15:User study comparison visualization results. Zoom in to see more details.",
                "position": 2349
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x16.png",
                "caption": "Figure 16:User study comparison visualization results. Zoom in to see more details.",
                "position": 2352
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x17.png",
                "caption": "Figure 17:User study comparison visualization results. Zoom in to see more details.",
                "position": 2355
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x18.png",
                "caption": "Figure 18:User study comparison visualization results. Zoom in to see more details.",
                "position": 2358
            },
            {
                "img": "https://arxiv.org/html/2511.20635/x19.png",
                "caption": "Figure 19:User study comparison visualization results. Zoom in to see more details.",
                "position": 2361
            }
        ]
    },
    {
        "header": "9More Discussion",
        "images": []
    }
]