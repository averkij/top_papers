[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/main_3.png",
                "caption": "Figure 1:The gradient update for the one-step student infùëìfitalic_f-distill. The gradient is a product of the difference between the teacher score and fake score, and a weighting function determined by the chosenfùëìfitalic_f-divergence and density ratio. The density ratio is readily available from the discriminator in the auxiliary GAN objective.",
                "position": 127
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x1.png",
                "caption": "Figure 2:Score difference and the weighting function on a 2D example.h‚Ñéhitalic_his the weighting function in forward-KL. Observe that the teacher and fake scores often diverge in lower-density regions (darker colors in the bottom left figure indicate larger score differences), where larger estimation errors occur. The weighting function downweights these regions¬†(lighter colors in the bottom right figure) during gradient updates forfùëìfitalic_f-distill.",
                "position": 133
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Method: generalfùëìfitalic_f-divergence minimization",
        "images": []
    },
    {
        "header": "4Comparing properties offùëìfitalic_f-divergence",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/x2.png",
                "caption": "(a)",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x2.png",
                "caption": "(a)",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x3.png",
                "caption": "(b)",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x4.png",
                "caption": "(a)",
                "position": 648
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x4.png",
                "caption": "(a)",
                "position": 651
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x5.png",
                "caption": "(b)",
                "position": 657
            }
        ]
    },
    {
        "header": "5Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/x6.png",
                "caption": "(a)",
                "position": 918
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x6.png",
                "caption": "(a)",
                "position": 921
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x7.png",
                "caption": "(b)",
                "position": 926
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x8.png",
                "caption": "(c)",
                "position": 931
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/vis_2.png",
                "caption": "Figure 6:(a)Uncurated generated samples by the multi-step teacher diffusion models (top), and one-step student infùëìfitalic_f-distill (bottom), using the same random seed. The teacher diffusion models use 35 and 50 steps on ImageNet-64 and Stable Diffusion v1.5, respectively.(b)Generated samples by reverse-KL and JS, using a prompt in COYO: ‚Äúa blue and white passenger train coming to a stop‚Äù.",
                "position": 1190
            }
        ]
    },
    {
        "header": "6Related work",
        "images": []
    },
    {
        "header": "7Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AProofs",
        "images": []
    },
    {
        "header": "Appendix BTraining details",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/x9.png",
                "caption": "(a)",
                "position": 2705
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x9.png",
                "caption": "(a)",
                "position": 2708
            },
            {
                "img": "https://arxiv.org/html/2502.15681/x10.png",
                "caption": "(b)",
                "position": 2713
            }
        ]
    },
    {
        "header": "Appendix CProperties offùëìfitalic_f-divergence",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/teaser_4.png",
                "caption": "Figure 8:Illustration of how the weighting functionh‚Ñéhitalic_h(red dotted line) in less mode-seeking divergence¬†(forward-KL,h=p/q‚Ñéùëùùëûh=p/qitalic_h = italic_p / italic_q) helps to learn the true data distributionpùëùpitalic_p, compared to more mode-seeking divergence¬†(reverse-KL,h‚â°1‚Ñé1h\\equiv 1italic_h ‚â° 1). We illustrate how using a less mode-seeking divergence can better capture different modes, from a skewed initial generative distributionqùëûqitalic_q, with the help of the weighting function.",
                "position": 2852
            }
        ]
    },
    {
        "header": "Appendix DAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15681/x11.png",
                "caption": "Figure 9:Training dynamics of JS and forward-KL on COYO-700M.",
                "position": 3313
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp1.png",
                "caption": "Figure 10:Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M.",
                "position": 3383
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp1.png",
                "caption": "",
                "position": 3386
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp2.png",
                "caption": "",
                "position": 3391
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp3.png",
                "caption": "Figure 11:Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M.",
                "position": 3397
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp3.png",
                "caption": "",
                "position": 3400
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp4.png",
                "caption": "",
                "position": 3405
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp5.png",
                "caption": "Figure 12:Generated samples from multi-step teachers and single-step students, using the same prompts and random seeds. The real data used for GAN objective are from COYO-700M.",
                "position": 3411
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp5.png",
                "caption": "",
                "position": 3414
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cp6.png",
                "caption": "",
                "position": 3419
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cifar10_edm.png",
                "caption": "Figure 13:35-step generated CIFAR-10 samples, by EDM[17](teacher). FID score: 1.79",
                "position": 3638
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/cifar10_kl.png",
                "caption": "Figure 14:One-step generated CIFAR-10 samples, by KL infùëìfitalic_f-distill. FID score: 1.92",
                "position": 3641
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/imagenet_64_edm.png",
                "caption": "Figure 15:79-step generated ImageNet-64 samples, by EDM[17](teacher). FID score: 2.35",
                "position": 3644
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/imagenet_64_js.png",
                "caption": "Figure 16:One-step generated ImageNet-64 samples, by JS infùëìfitalic_f-distill. FID score: 1.16",
                "position": 3647
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/sd_teacher.png",
                "caption": "Figure 17:50-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by SD v1.5 model[43](teacher). CFG=3. FID score: 8.59",
                "position": 3650
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/sd_js.png",
                "caption": "Figure 18:One-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by JS infùëìfitalic_f-distill, with CFG=1.75. FID score: 7.42",
                "position": 3653
            },
            {
                "img": "https://arxiv.org/html/2502.15681/extracted/6217836/img/step_36000.png",
                "caption": "Figure 19:One-step generated SD v1.5 samples, using randomly sampled COYO-700M prompts, by JS infùëìfitalic_f-distill, with CFG=5.",
                "position": 3656
            }
        ]
    },
    {
        "header": "Appendix EExtended Samples",
        "images": []
    }
]