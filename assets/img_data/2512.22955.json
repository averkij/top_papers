[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Method",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.22955/x1.png",
                "caption": "Figure 1:Changes of PPL and entropy during pre-training across 1B and 4B dense models, developed based on different configurations.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x1.png",
                "caption": "",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x2.png",
                "caption": "",
                "position": 435
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x3.png",
                "caption": "",
                "position": 439
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x4.png",
                "caption": "",
                "position": 444
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x5.png",
                "caption": "",
                "position": 448
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x6.png",
                "caption": "",
                "position": 452
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x7.png",
                "caption": "",
                "position": 457
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x8.png",
                "caption": "",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x9.png",
                "caption": "Figure 2:Changes of PPL and entropy during pre-training across 5B-A0.3B and 10B-A0.5B MoE models, developed based on different configurations.",
                "position": 467
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x9.png",
                "caption": "",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x10.png",
                "caption": "",
                "position": 474
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x11.png",
                "caption": "",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x12.png",
                "caption": "",
                "position": 483
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x13.png",
                "caption": "",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x14.png",
                "caption": "",
                "position": 491
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x15.png",
                "caption": "",
                "position": 496
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x16.png",
                "caption": "",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x17.png",
                "caption": "Figure 3:Changes of performance during pre-training across models with various model parameters, developed based on dense and MoE architectures under different configurations.",
                "position": 528
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x17.png",
                "caption": "",
                "position": 531
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x18.png",
                "caption": "",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x19.png",
                "caption": "",
                "position": 539
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x20.png",
                "caption": "",
                "position": 544
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x21.png",
                "caption": "",
                "position": 548
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x22.png",
                "caption": "",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x23.png",
                "caption": "",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x24.png",
                "caption": "",
                "position": 561
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x25.png",
                "caption": "Figure 4:Changes of performance during mid-training across 4B dense and 10B-A0.5B MoE models, developed based on different configurations.",
                "position": 567
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x25.png",
                "caption": "",
                "position": 570
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x26.png",
                "caption": "",
                "position": 574
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x27.png",
                "caption": "",
                "position": 578
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x28.png",
                "caption": "",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x29.png",
                "caption": "",
                "position": 587
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x30.png",
                "caption": "",
                "position": 591
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x31.png",
                "caption": "",
                "position": 596
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x32.png",
                "caption": "",
                "position": 600
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x33.png",
                "caption": "Figure 5:Changes of performance during RL training across various actor models, developed based on a 4B dense architecture under different configurations.",
                "position": 643
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x33.png",
                "caption": "",
                "position": 646
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x34.png",
                "caption": "",
                "position": 650
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x35.png",
                "caption": "",
                "position": 655
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x36.png",
                "caption": "",
                "position": 659
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x37.png",
                "caption": "",
                "position": 664
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x38.png",
                "caption": "",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x39.png",
                "caption": "Figure 6:Changes of performance during RL training across various actor models, developed based on a 10B-A0.5B MoE architecture under different configurations.",
                "position": 674
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x39.png",
                "caption": "",
                "position": 677
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x40.png",
                "caption": "",
                "position": 681
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x41.png",
                "caption": "",
                "position": 686
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x42.png",
                "caption": "",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x43.png",
                "caption": "",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x44.png",
                "caption": "",
                "position": 699
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x45.png",
                "caption": "Figure 7:Changes of entropy and response length during RL training across various actor models, developed based on 4B dense and 10B-A0.5B MoE architectures under different configurations.",
                "position": 705
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x45.png",
                "caption": "",
                "position": 708
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x46.png",
                "caption": "",
                "position": 712
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x47.png",
                "caption": "",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x48.png",
                "caption": "",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x49.png",
                "caption": "",
                "position": 725
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x50.png",
                "caption": "",
                "position": 729
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x51.png",
                "caption": "",
                "position": 734
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x52.png",
                "caption": "",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x53.png",
                "caption": "Figure 8:Pass@â€‹k\\text{Pass@}kcurve of base models on mathematics reasoning and code generation tasks, developed based on 4B dense and 10B-A0.5B MoE models under different configurations.",
                "position": 758
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x53.png",
                "caption": "",
                "position": 761
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x54.png",
                "caption": "",
                "position": 765
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x55.png",
                "caption": "",
                "position": 769
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x56.png",
                "caption": "",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x57.png",
                "caption": "",
                "position": 778
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x58.png",
                "caption": "",
                "position": 782
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x59.png",
                "caption": "",
                "position": 787
            },
            {
                "img": "https://arxiv.org/html/2512.22955/x60.png",
                "caption": "",
                "position": 791
            }
        ]
    },
    {
        "header": "4Related Works",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Appendix AExperiment Details for Pre-Training and Mid-Training",
        "images": []
    },
    {
        "header": "Appendix BExperiment Details for RL",
        "images": []
    }
]