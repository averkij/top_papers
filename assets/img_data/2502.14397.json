[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14397/x1.png",
                "caption": "",
                "position": 78
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14397/x2.png",
                "caption": "Figure 2:The overall architecture and training prodigim of photodoodle. The ominiEditor and EditLora all follow the lora training prodigm. We use a high rank lora for pre-training the OmniEditor on a large-scale dataset for general-purpose editing and text-following capabilities, and a low rank lora for fine-tuning EditLoRA on a small set of paired stylized images to capture individual artistsâ€™ specific styles and strategies for efficient customization. We encode the original image into a condition token and concatenate it with a noised latent token, controlling the generation outcome through MMAttention.",
                "position": 137
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14397/x3.png",
                "caption": "Figure 3:The generated results of PhotoDoodle. PhotoDoodle can mimic the manner and style of artists creating photo doodles, enabling instruction-driven high-quality image editing.",
                "position": 286
            },
            {
                "img": "https://arxiv.org/html/2502.14397/x4.png",
                "caption": "Figure 4:Compared to baseline methods, PhotoDoodle demonstrates superior instruction following, image consistency, and editing effectiveness.",
                "position": 289
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.14397/x5.png",
                "caption": "Figure 5:Ablation study results. Without OmniEditor pre-training, training EditLoRA directly reduces the harmony between sketches and photos and weakens text-following capabilities; removing Position Encoding Cloning decreases output consistency and introduces unwanted background changes; using only pre-trained OmniEditor without EditLoRA significantly reduces the degree of stylization.",
                "position": 567
            },
            {
                "img": "https://arxiv.org/html/2502.14397/x6.png",
                "caption": "Figure 6:User study results. The scores demonstrate the percentage of users who prefer ours over others under three evaluation metrics. PhotoDoodle outweighs all other baselines in user study.",
                "position": 592
            }
        ]
    },
    {
        "header": "5Limitation and Future Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]