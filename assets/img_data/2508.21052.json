[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21052/figures/final_teaser.png",
                "caption": "Figure 1:FakePartsBench is the first dataset specifically designed to include FakeParts deepfakes and outputs from state-of-the-art AI generative models.",
                "position": 107
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3What is missing from existing Deepfake datasets?",
        "images": []
    },
    {
        "header": "4FakePartsBench: A Benchmark for Video Deepfakes and FakeParts",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_caption_lenghts_by_word_count.png",
                "caption": "(a)Word-count distribution of FakePartsBench",
                "position": 660
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_caption_lenghts_by_word_count.png",
                "caption": "(a)Word-count distribution of FakePartsBench",
                "position": 663
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_topics_dataset.png",
                "caption": "(b)Topic distribution of FakePartsBench",
                "position": 668
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/pipeline.jpg",
                "caption": "Figure 3:Pipelineof FakePartsBench includes both full and FakeParts Deepfake videos. The partial manipulations, FakeParts, are categorized into three types: temporal, spatial, and style.",
                "position": 693
            }
        ]
    },
    {
        "header": "5Experimental Protocol",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation3.png",
                "caption": "Figure 4:GUI for user study: Participants classify a video as real or fake, and provide an explanation.",
                "position": 1037
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation3.png",
                "caption": "",
                "position": 1040
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation1.png",
                "caption": "",
                "position": 1044
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Faceswap_1.png",
                "caption": "Figure 5:Examples of deepfake from FakeParts. The deepfake grouped by manipulation family. Each column corresponds to a different technique family, showing three samples per group.",
                "position": 1058
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Inpainting_1.png",
                "caption": "",
                "position": 1071
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Interpolation_1.png",
                "caption": "",
                "position": 1072
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/IT2V_1.png",
                "caption": "",
                "position": 1073
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Faceswap_2.png",
                "caption": "",
                "position": 1076
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Inpainting_2.png",
                "caption": "",
                "position": 1077
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Interpolation_2.png",
                "caption": "",
                "position": 1078
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/IT2V_2.png",
                "caption": "",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Faceswap_3.png",
                "caption": "",
                "position": 1082
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Inpainting_3.png",
                "caption": "",
                "position": 1083
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Interpolation_3.png",
                "caption": "",
                "position": 1084
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/IT2V_3.png",
                "caption": "",
                "position": 1085
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Outpainting_1.png",
                "caption": "",
                "position": 1094
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Stylechange_1.png",
                "caption": "",
                "position": 1095
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/T2V_1.png",
                "caption": "",
                "position": 1096
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Real_1.png",
                "caption": "",
                "position": 1097
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Outpainting_2.png",
                "caption": "",
                "position": 1100
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Stylechange_2.png",
                "caption": "",
                "position": 1101
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/T2V_2.png",
                "caption": "",
                "position": 1102
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Real_2.png",
                "caption": "",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Outpainting_3.png",
                "caption": "",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Stylechange_3.png",
                "caption": "",
                "position": 1107
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/T2V_3.png",
                "caption": "",
                "position": 1108
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/generation/Real_3.png",
                "caption": "",
                "position": 1109
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix: FakeParts: a New Family of AI-Generated DeepFakes",
        "images": []
    },
    {
        "header": "Appendix AExtra information on the Human Perception Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation0.png",
                "caption": "(a)First page the annotators see for Video1.",
                "position": 2587
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation0.png",
                "caption": "(a)First page the annotators see for Video1.",
                "position": 2590
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation2.png",
                "caption": "(b)First page the annotators see for Video2.",
                "position": 2595
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation1.png",
                "caption": "(c)Second page the annotators see for Video1.",
                "position": 2601
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/annotations/deepfake_annotation3.png",
                "caption": "(d)Second page the annotators see for Video2.",
                "position": 2606
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_caption_lenghts_by_word_count.png",
                "caption": "(a)Word-count distribution of FakePartsBench",
                "position": 2617
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_caption_lenghts_by_word_count.png",
                "caption": "(a)Word-count distribution of FakePartsBench",
                "position": 2620
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/dataset/distribution_of_topics_dataset.png",
                "caption": "(b)Topic distribution of FakePartsBench",
                "position": 2625
            },
            {
                "img": "https://arxiv.org/html/2508.21052/wordcloud.png",
                "caption": "Figure 8:Word cloud showing the most frequent terms from human explanations of synthetic content detection.",
                "position": 2632
            }
        ]
    },
    {
        "header": "Appendix BExtra Quantitative Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.21052/figures/supmat/reals.jpg",
                "caption": "Figure 9:Examples of real videos collected from YouTube-VOS 2019vos2019.",
                "position": 2852
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/supmat/it2v.jpg",
                "caption": "Figure 10:Examples ofFull Fakes, including T2V (first two rows from SoRAopenai2024soraand second two rows are from Veo2google2025veo2) and IT2V from SoRAopenai2024sora. Green strokes indicate the condition image used in IT2V.",
                "position": 2863
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/supmat/spatial.jpg",
                "caption": "Figure 11:Examples ofSpatial FakeParts, including FaceSwap, inpainting, and outpainting methods. In inpainting, the green mask indicates the region to be removed.",
                "position": 2885
            },
            {
                "img": "https://arxiv.org/html/2508.21052/figures/supmat/tempo-style.jpg",
                "caption": "Figure 12:Examples ofTemporal and Style FakeParts, including Frame interpolation and Style Transfer.",
                "position": 2906
            }
        ]
    },
    {
        "header": "Appendix CImplementation details with Extra Qualitative Results",
        "images": []
    }
]