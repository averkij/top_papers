[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05113/Figures/teaser.jpg",
                "caption": "",
                "position": 82
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05113/x1.png",
                "caption": "Figure 2:Existing Gaussian splatting frameworks cannot produce plausible results from casually captured Mannequin-Challenge videos.(Top)A short clip of the hand-held input sequence exhibits unintentional subject motion.(Right)State-of-the-art methods containing SC-GS[huang2024sc], 4DGaussians[wu20244d], and D-3DGS[yang2024deformable]. They all leave noticeable blur and double contours around the woman’s face (blueframes).(Left)Our Splannequin reconstruction (redframe) is crisp and temporally consistent, revealing fine hair strands and facial detail with no ghosting.",
                "position": 131
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Background",
        "images": []
    },
    {
        "header": "4Problem Definition",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05113/x2.png",
                "caption": "Figure 3:Time-Camera Conceptualization.Assuming forward camera motion, the diagonal dashed line represents standard dynamic rendering, while the horizontal line shows freeze-time rendering at a fixed timestampt⋆t^{\\star}. Along this freeze-time line, unsupervised Gaussians are eitherhidden(red points, as the camera has passed them) ordefective(blue points, not yet well-observed). Our approach regularizes these problematic Gaussians by anchoring them to their supervised counterparts from other timestamps: hidden (red) Gaussians use past states, and defective (blue) Gaussians use future states. The right panel shows a bird’s-eye view of a hallway, illustrating how the camera’s path creates defective and hidden regions.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2512.05113/Figures/Hidden-Visible.jpg",
                "caption": "Figure 4:Illustration of hidden Gaussians.Given a timestamp, hidden Gaussians (Left) lie outside the camera frustum, receiving no supervision, whilevisibleGaussians (Right) are rasterized to form the image. Our method targets ill-supervised hidden Gaussians to prevent visual artifacts.",
                "position": 224
            }
        ]
    },
    {
        "header": "5Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05113/x3.png",
                "caption": "Figure 5:Splannequin Pipeline Overview. The pipeline: (1) extracts point clouds from input video, (2) use dynamic Gaussian splatting with dual-detection losses that anchor hidden Gaussians to earlier frames (t’<<t) and defective Gaussians to later frames (t<<t’), and (3) renders freeze-time videos at any timestampt⋆t^{\\star}. Temporal distance-based confidence weighting ensures appropriate regularization strength, with closer reference frames providing stronger anchoring than distant ones for robust temporal consistency and artifact elimination.",
                "position": 232
            }
        ]
    },
    {
        "header": "6Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.05113/x4.png",
                "caption": "Figure 6:Qualitative Comparison across Our Real-World Benchmark.Each column shows freeze-time renderings from all methods at a viewpoint. Rows correspond to direct comparisons of identical viewpoints with baselines: 4DGaussians (top), D-3DGS (middle), and SC-GS (bottom). Adding Splannequin consistently produces sharper, more temporally coherent results, exhibiting reduced ghosting and artifact suppression compared to baseline methods.",
                "position": 314
            },
            {
                "img": "https://arxiv.org/html/2512.05113/x5.png",
                "caption": "Figure 7:User-Selectable Freeze-Time Instants.Splannequin empowers users to select the precise moment to freeze, allowing for artistic control over the final scene. Both rows show high-fidelity freeze-time videos generated from the same input sequence but frozen at two different, user-selected timestamps.Top:At Timestamp 0, the subject in the inset is looking down.Bottom:At Timestamp 80, captured seconds later, the subject has turned their head. Our method successfully reconstructs both moments with sharp detail and stability, preserving these subtle differences and enabling creative selection based on pose and expression.",
                "position": 317
            },
            {
                "img": "https://arxiv.org/html/2512.05113/x6.png",
                "caption": "Figure 8:Validation on Simulated Dataset.Qualitative comparison between 4DGaussians (left) and 4DGaussians + Splannequin (right) on synthetic scenes with ground truth. With Splannequin, the results better preserve geometric details and suppressed artifacts, as validated against static reference frames. Insets highlight regions of improved structural fidelity.",
                "position": 320
            },
            {
                "img": "https://arxiv.org/html/2512.05113/x7.png",
                "caption": "Figure 9:Effect of Confidence Weighting.Visualization comparing results with (right) and without (left) confidence weighting. Without confidence, regularization can over-smooth the frame.",
                "position": 746
            },
            {
                "img": "https://arxiv.org/html/2512.05113/x8.png",
                "caption": "Figure 10:User study results.Our method was preferred in 96% of comparisons for better visual appeal and fewer artifacts. 80% of our results were perceived as more ”perfectly frozen” than the original captures, validating our approach.",
                "position": 749
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    }
]