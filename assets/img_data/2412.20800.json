[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20800/x1.png",
                "caption": "Figure 1:Comparison of text fidelity and visual aesthetics between SDXL[15], DPO[27], and our VMix. DPO can generate attributes that SDXL fails to produce, but it fails to align with human visual fine-grained preferences. Our method achieves better text fidelity and visual aesthetics simultaneously.",
                "position": 87
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20800/x2.png",
                "caption": "Figure 2:Illustration of of VMix. (a)In the initialization stage, pre-defined aesthetic labels are transformed into [CLS] tokens through CLIP, thereby obtaining AesEmb, which only need to be processed once at the beginning of training. (b)In the training stage, a project layer first maps the input aesthetic descriptionya‚Å¢e‚Å¢ssubscriptùë¶ùëéùëíùë†y_{aes}italic_y start_POSTSUBSCRIPT italic_a italic_e italic_s end_POSTSUBSCRIPTinto an embeddingfasubscriptùëìùëéf_{a}italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPTof the same token dimension as the content text embeddingftsubscriptùëìùë°f_{t}italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The text embeddingftsubscriptùëìùë°f_{t}italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTis then integrated into the denoising network through value-mixed cross-attention. (c)In the inference stage, VMix extract all positive aesthetic embedding from AesEmb to form the aesthetic input, along with the content input, is fed into the model for the denoising process.",
                "position": 161
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20800/x3.png",
                "caption": "Figure 3:Qualitative comparison with various state-of-the-art methods. All results are based on Stable Diffusion[20]. Our VMix method outperforms others, significantly enhancing the quality of image generation across various fine-grained aesthetic dimensions.",
                "position": 247
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x4.png",
                "caption": "Figure 4:Qualitative comparison with various state-of-the-art methods. All the results of the methods are based on the SDXL[15]. Our VMix method outperforms others, significantly enhancing the quality of image generation.",
                "position": 251
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20800/x5.png",
                "caption": "Figure 5:Qualitative results. We compare images generated by VMix-integrated personalized models with those from standard personalized models. On the left are images produced by the personalized model with VMix integration, while on the right are images from the standard personalized model without modifications.",
                "position": 534
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x6.png",
                "caption": "Figure 6:User study. We report the user preference between using VMix and not using VMix.",
                "position": 537
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x7.png",
                "caption": "(a)",
                "position": 540
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x7.png",
                "caption": "(a)",
                "position": 543
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x8.png",
                "caption": "(b)",
                "position": 552
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x9.png",
                "caption": "Figure 8:Ablation Study for AesEmb of VMix.Left: The effects of using all aesthetic labels versus not using them.Right: The effects of using single-dimensional aesthetic labels.",
                "position": 562
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.20800/x10.png",
                "caption": "Figure 9:Visualization results of different training steps. Prompts: (1) A teddy bear walking in the snowstorm. (2) A bridge is depicted in the water.",
                "position": 1087
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x11.png",
                "caption": "Figure 10:Visualization results of attention maps. VMix is capable of maintaining attention maps that closely resembles that of the baseline(SD[20]) while further enhancing the quality of the generated images.",
                "position": 1090
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x12.png",
                "caption": "Figure 11:Qualitative comparison. Prompts: (1) Kitten in the forest with flowers with sunlight on them, Cinematic lighting, Unreal Engine 5. (2) Close-up of a young girl wearing a flower crown in the garden, portrait. (3) A green vase with several red roses in it.",
                "position": 1093
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x13.png",
                "caption": "Figure 12:Qualitative results about VMix with ControlNet[36]and IP-Adapter[32]. Prompt: a young woman with long, wavy brown hair. she is wearing a sleeveless floral dress with a pattern of various flowers and leaves. the woman is holding a white, fluffy cat close to her face, seemingly in a moment of affection and joy. her eyes are closed, suggesting she is savoring the moment.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x14.png",
                "caption": "Figure 13:Qualitative comparison between results with VMix(on the right) and without VMix(on the left), shows that VMix significantly enhances the quality of image generation.",
                "position": 1106
            },
            {
                "img": "https://arxiv.org/html/2412.20800/x15.png",
                "caption": "Figure 14:Qualitative comparison between results with VMix(on the right) and without VMix(on the left), shows that VMix significantly enhances the quality of image generation.",
                "position": 1109
            }
        ]
    },
    {
        "header": "6Supplementary",
        "images": []
    }
]