[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.09595/x1.png",
                "caption": "",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x2.png",
                "caption": "Figure 2:Overview of our method.Llama-Meshunifies text and 3D mesh in a uniform format by representing the numerical values of vertex coordinates and face definitions of a 3D mesh as plain text. Our model is trained using text and 3D interleaved data end-to-end. Therefore, with a single, unified model, we can generate both text and 3D meshes.",
                "position": 109
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.09595/x3.png",
                "caption": "Figure 3:Gallery of generations fromLlama-Mesh.We can generate high-quality and diverse meshes with artist-like created topology.",
                "position": 138
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.09595/x4.png",
                "caption": "Figure 4:Illustration of our 3D representation approach.Left: A snippet of an OBJ file represented as plain text, containing vertex (v) and face (f) definitions. Right: The 3D object rendered from the OBJ file. We enable the LLM to process and generate 3D meshes by converting the mesh data into a textual format.",
                "position": 188
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x5.png",
                "caption": "Figure 5:Illustration of our vertex quantization method.Top:The original OBJ file represents vertex coordinates in decimal values, splitting a single coordinate into several tokens.Bottom:After quantization, we represent the vertices as integers containing fewer tokens and are processed by LLM more efficiently.",
                "position": 208
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x6.png",
                "caption": "Figure 6:Illustration of mesh generation capability from an LLM without finetuning.Left:results from ChatGPT-4o.Right:results from LLaMA 3.1 8B-Instruct. Pretrained LLMs can generate simple 3D objects in text format; however, mesh quality and complexity are often unsatisfactory. OBJ files from the internet may vary slightly in format. The […] indicates omitted text.",
                "position": 229
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x7.png",
                "caption": "Figure 7:More dialog results.Llama-Meshachieves several new tasks, including mesh generation and understanding, while completing other tasks like the original LLM. […]: we omit some text to make the snippet fit into the page.",
                "position": 234
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x8.png",
                "caption": "Figure 8:Training dataset curated forLlama-Mesh.We use a combination of rule-based methods in(a)and(b)and LLM-augmented methods in(c)and(d)to construct an SFT dataset for mesh generation and understanding.<start/end of mesh>is shown here for illustration only and does not appear in the training data.",
                "position": 254
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.09595/x9.png",
                "caption": "Figure 9:Training loss ofLlama-Mesh.The model adapts quickly to the new modality. We do not observe loss instabilities during training.\nTotal training time comparisons are in Table2.",
                "position": 275
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x10.png",
                "caption": "Figure 10:Diversity of generations.Llama-Meshcan generate diverse shapes given the same text prompt.",
                "position": 327
            },
            {
                "img": "https://arxiv.org/html/2411.09595/x11.png",
                "caption": "Figure 11:Comparison ofLlama-Meshand baselines on text-to-mesh generation.Our method achieves a competitive mesh quality.",
                "position": 344
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Reproducibility",
        "images": []
    },
    {
        "header": "Ethics Statements",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]