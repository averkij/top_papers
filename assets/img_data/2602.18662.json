[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Problem Formulation",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18662/x1.png",
                "caption": "Figure 2:Overview of the large causal model (LCM) pipeline. (1) Synthetic and realistic TSCM generators produce training pairs of multivariate time series and their lagged causal graphs. (2) The LCM is trained via supervised learning on these pairs to discover a lagged adjacency tensorùî∏^\\hat{\\mathbb{A}}for a time seriesùêó‚àà‚ÑùL√óV\\mathbf{X}\\in\\mathbb{R}^{L\\times V}, padded and normalized for stability. (3) At inference (CD phase), the pre-trained LCM predicts causal strengths on unseen datasets in a zero-shot manner.",
                "position": 383
            }
        ]
    },
    {
        "header": "4Model Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18662/x2.png",
                "caption": "Figure 3:A multivariate time series is embedded via Conv1D layers and positional\nencodings, processed through a Transformer encoder stack with optional distillation\nblocks, and augmented with lagged cross-correlations (training aids). A feedforward head outputs a lagged adjacency tensor representing the discovered temporal causal graph.",
                "position": 407
            }
        ]
    },
    {
        "header": "5Training Setup",
        "images": []
    },
    {
        "header": "6Experimental Setup",
        "images": []
    },
    {
        "header": "7Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18662/x3.png",
                "caption": "Figure 4:Running times (in seconds) for LCMs and baseline algorithms on theSynthetic_2holdout set, averaged over 10 runs. Traditional methods (e.g., PCMCI & DYNOTEARS) scale superlinearly with lag and variable count, while Transformer-based LCMs remain effectively independent of input dimensionality due to their constant-time forward pass.",
                "position": 1059
            }
        ]
    },
    {
        "header": "8Model Complexity",
        "images": []
    },
    {
        "header": "9Training Data‚ÄìModel Size Convergence",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18662/assets/model_convergence.png",
                "caption": "Figure 5:Empirical convergence of LCMs with increasing training data. Test AUC for\n500K, 1M, and 2M parameter models trained on subsampled datasets. Validation/test\nsets are fixed to isolate the effect of data scale.",
                "position": 1115
            }
        ]
    },
    {
        "header": "10Concluding Remarks & Future Work",
        "images": []
    },
    {
        "header": "11Limitations",
        "images": []
    },
    {
        "header": "12Impact Statement",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.18662/assets/heatmap_example.png",
                "caption": "Figure 8:Heatmap visualization of the discovered lagged adjacency matrix (bottom row) compared to the ground truth (top row) in an example withnmax=12n_{\\text{max}}=12and‚Ñìmax=3\\ell_{\\text{max}}=3using the pretrainedLCM-2.4Mmodel. Brighter colors in the predicted adjacency indicate stronger confidence for edge existence.",
                "position": 2351
            },
            {
                "img": "https://arxiv.org/html/2602.18662/x4.png",
                "caption": "Figure 9:Paired median AUC differences relative to the reference model acrossSyntheticcollections. Positive values indicate improved performance. Statistical significance is determined via Wilcoxon signed-rank test with Bonferroni correction.",
                "position": 2370
            },
            {
                "img": "https://arxiv.org/html/2602.18662/x5.png",
                "caption": "Figure 10:Paired median AUC differences acrossSemi-Syntheticcollections. Positive values indicate improved performance. Statistical significance is determined via Wilcoxon signed-rank test with Bonferroni correction.",
                "position": 2373
            },
            {
                "img": "https://arxiv.org/html/2602.18662/x6.png",
                "caption": "Figure 11:Paired median AUC differences acrossRealisticcollections. Positive values indicate improved performance. Statistical significance is determined via Wilcoxon signed-rank test with Bonferroni correction.",
                "position": 2376
            }
        ]
    },
    {
        "header": "References",
        "images": []
    }
]