[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16921/x1.png",
                "caption": "Figure 1:Overview of AuditDM.We propose to train anauditormodel to systematically discover capability gaps in an MLLM by generating failure-inducing question–image pairs.\nWe show three automatically generated examples of weaknesses in object relationships.\nThe proposed framework offers diagnostic insight and enables targeted rectification via auditor-guided feedback.",
                "position": 94
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16921/x2.png",
                "caption": "(a)Improving PaliGemma2",
                "position": 136
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x2.png",
                "caption": "(a)Improving PaliGemma2",
                "position": 139
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x3.png",
                "caption": "(b)Improving Gemma3",
                "position": 144
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3AuditDM",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16921/x4.png",
                "caption": "Figure 3:AuditDM architecture.AuditDM fine-tunes an MLLM into anauditorthat generates challenging probing questions and counterfactual images (via captions for image regeneration or editing commands), yielding question–image pairs on which the target model fails while the MLLM ensemble agrees, thus exposing capability gaps and failure modes.\nThe auditor is trained to maximize prediction discrepancy between the target and the ensemble.\nOnce trained, it identifies weaknesses and failure cases in a single inference pass.",
                "position": 333
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16921/x5.png",
                "caption": "Figure 4:AuditDM identifies the top 15 failure modes and challenging task categories for PaliGemma2‑3B and 28B models at 448px2, and we report normalized per-category failure rates.Tasks are ordered left to right, beginning with the most pronounced weaknesses of the 3B model and progressing to those of the 28B.\nNotably, we observe that for certain tasks, the 28B model performs significantly worse than the 3B model.\nFor example, on challenging images, the 28B model struggles more with color recognition and counting, and is more prone to hallucination.",
                "position": 509
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x6.png",
                "caption": "Figure 5:Generated examples for each failure category.To better demonstrate the effectiveness, we focus on examples withoriginal imagesandgenerated questions.\nImage-question pairs with both generated images and questions are provided in Fig.6.\nSome images are cropped or rotated for better figure layout. Original images and additional examples are provided in Sec.C.",
                "position": 518
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x7.png",
                "caption": "Figure 6:AuditDM efficiently detects fine-grained visual cues that are irrelevant to the task/question yet still alter model predictions.We target PaliGemma2‑28B (448px2) and showcase small modifications that fool the 28B model but not the 3B model, highlighting the effectiveness of our method in finding failures even in very powerful models.\nFor each example, we show the original image (left), the modified image (right), and the corresponding answers.\nOur analysis shows that even the PaliGemma-2 28B model is highlysensitive to minor changes in task-irrelevant objects, suggesting that current MLLMs may stillfail to ground visual reasoning in the correct evidence.Our results further indicate that the 28B modelis not necessarily more robust than the smaller 3B variantand continues to exhibit various weaknesses.\nBy isolating fine-grained cues that change predictions,AuditDM reveals what visual evidence drives model behavior and affects outputs, characterizing the model’s vulnerabilities and brittleness.\nAdditional examples are provided in SecC.",
                "position": 526
            }
        ]
    },
    {
        "header": "5Limitations and Future Work",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Overview",
        "images": []
    },
    {
        "header": "AMethod and Implementation Details",
        "images": []
    },
    {
        "header": "BAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.16921/x8.png",
                "caption": "Figure 7:Generated examples for each failure category.To better demonstrate the effectiveness, we focus on examples withoriginal imagesandgenerated questions.",
                "position": 2597
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x9.png",
                "caption": "Figure 8:Generated examples for each failure category.To better demonstrate the effectiveness, we focus on examples withoriginal imagesandgenerated questions.",
                "position": 2603
            },
            {
                "img": "https://arxiv.org/html/2512.16921/x10.png",
                "caption": "Figure 9:Additional examples of fine-grained visual cues that are irrelevant to the task or question but still alter the model’s predictions.We target PaliGemma2‑28B (448px2) and showcase small modifications that fool the 28B model but not the 3B model, highlighting the effectiveness of our method in finding failures even in very powerful models.\nFor each example, we show the original image (left), the modified image (right), and the corresponding answers.",
                "position": 2609
            }
        ]
    },
    {
        "header": "CAdditional Qualitative Examples",
        "images": []
    }
]