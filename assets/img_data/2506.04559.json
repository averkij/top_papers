[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/x1.png",
                "caption": "Figure 1:Scalable multi-modal reasoning of RACRO.RACRO reveals better scalability compared to the traditional visual alignment, while remaining computationally efficient.",
                "position": 155
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x2.png",
                "caption": "(a)Existing MLLM alignment methods",
                "position": 193
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x2.png",
                "caption": "(a)Existing MLLM alignment methods",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x3.png",
                "caption": "(b)RACRO (ours)",
                "position": 201
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/x4.png",
                "caption": "Figure 3:Inaccurate visual captions result in reasoning failure.MLLMs might produce hallucinated (left), vague, or incomplete captions (middle), particularly for complex visual reasoning, while captions containing necessary query-relevant contexts are essential for successful reasoning (right).",
                "position": 244
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x5.png",
                "caption": "Figure 4:Caption Reward Optimizationreinforcescaptionsthat induce correctreasoningresults via reinforcement learning with verifiable rewards (RLVR).",
                "position": 339
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/x6.png",
                "caption": "Figure 5:Ablation on the choice of reasoner.",
                "position": 1211
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x6.png",
                "caption": "Figure 5:Ablation on the choice of reasoner.",
                "position": 1214
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x7.png",
                "caption": "Figure 6:Ablation on CRO and GRPO.",
                "position": 1219
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x8.png",
                "caption": "Figure 7:Pairwise comparisonon caption quality.",
                "position": 1234
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AModel Configuration for Figure1",
        "images": []
    },
    {
        "header": "Appendix BPrompt Templates Used in RACRO",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/x9.png",
                "caption": "Figure 8:Prompt templates used by the reasoner LLM for inference.",
                "position": 2222
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x10.png",
                "caption": "Figure 9:Prompt templates used by the reasoner LLM for training.",
                "position": 2225
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x11.png",
                "caption": "Figure 10:Prompt templates used by the MLLM to obtain the tentative response.The placeholder is for the question.",
                "position": 2228
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x12.png",
                "caption": "Figure 11:Prompt templates used by the MLLM to obtain the query-conditioned captions.",
                "position": 2231
            }
        ]
    },
    {
        "header": "Appendix CExperimental Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/x13.png",
                "caption": "Figure 12:Prompt templates used for GPT evaluations on caption qualities.",
                "position": 2297
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x14.png",
                "caption": "(a)Qwen2.5-VL-3B",
                "position": 2351
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x14.png",
                "caption": "(a)Qwen2.5-VL-3B",
                "position": 2354
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x15.png",
                "caption": "(b)Qwen2.5-VL-7B",
                "position": 2359
            },
            {
                "img": "https://arxiv.org/html/2506.04559/x16.png",
                "caption": "(c)Qwen2.5-VL-32B",
                "position": 2365
            }
        ]
    },
    {
        "header": "Appendix DCase Study",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case1.jpg",
                "caption": "Table 7:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 2415
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case2.jpg",
                "caption": "Table 8:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 2651
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case3.jpg",
                "caption": "Table 9:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 2752
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case4.jpg",
                "caption": "Table 10:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 2888
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case5.jpg",
                "caption": "Table 11:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 2996
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case6.jpg",
                "caption": "Table 12:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 3079
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case8.jpg",
                "caption": "Table 13:Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 3193
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case9.jpg",
                "caption": "Table 14:Case Study with Qwen2.5-VL-32B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 3285
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case10.jpg",
                "caption": "Table 15:Case Study with Qwen2.5-VL-32B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 3629
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case11.jpg",
                "caption": "Table 16:Case Study with Qwen2.5-VL-32B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 3942
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case12.jpg",
                "caption": "Table 17:Case Study with Qwen2.5-VL-32B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 4143
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/case13.jpg",
                "caption": "Table 18:Case Study with Qwen2.5-VL-32B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred.",
                "position": 4434
            },
            {
                "img": "https://arxiv.org/html/2506.04559/extracted/6514115/figures/r_case_1.jpg",
                "caption": "Table 19:Reasoning Case Study with Qwen2.5-VL-3B.Additional visual details that are relevant to the question but are only generated by MLLMs withCROare highlighted inred. Reasoning process that show confusing and contradiction are highlighted inbrown.",
                "position": 4660
            }
        ]
    },
    {
        "header": "Appendix EBroader Impacts",
        "images": []
    },
    {
        "header": "Appendix FLimitation",
        "images": []
    },
    {
        "header": "Appendix GMore Discussions",
        "images": []
    }
]