[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04797/x1.png",
                "caption": "Figure 1:SIMA 2is a Gemini-based agent that reasons, acts, and engages in dialogue across diverse embodied 3D virtual worlds. In the top left panel, we see an example of the agent responding to the user in No Man’s Sky. As compared with SIMA 1, SIMA 2 is a step-change improvement in embodied performance, and it is even capable of self-improving in previously unseen environments.",
                "position": 162
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background & Related Works",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04797/assets/sima2_environments.png",
                "caption": "Figure 2:Environments. The grid shows a sampling of images across the video game environments used to train and evaluate SIMA 2. Due to the complexity of open-world commercial video games, agents must handle a near-limitless variety of 3D configurations, menus, and underlying environment dynamics. This provides an ideal setting to develop and test embodied agents. By acquiring general embodiment capabilities in these environments, SIMA 2 is able to generalize in non-trivial ways to entirely new environments, including photorealistic environments generated by Genie 3.",
                "position": 226
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x2.png",
                "caption": "Figure 3:Agent-Environment Interface. The agent receives a prompt that includes the current instruction. Conditioning on recent frames, the agent outputs internal reasoning, dialogue, and actions, with the agent specifying which modalities to produce at any given step.",
                "position": 259
            }
        ]
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04797/x3.png",
                "caption": "Figure 4:Embodied Dialogue & Basic Reasoning. SIMA 2 contains a variety of new capabilities, including embodied dialogue and basic reasoning. Above, SIMA 2 answers a user’s question through embodied interaction. Below, the agent correctly reasons that it needs to go to aredhouse based on the user’s instruction. These new capabilities are unlocked by using Gemini within SIMA 2.",
                "position": 481
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x4.png",
                "caption": "Figure 5:Complex Instructions & Multi-modal Prompting. By inheriting Gemini’s language understanding capabilities, SIMA 2 can handle a variety of novel, complex instructions, including breaking down instructions to successfully navigate to a specific room. SIMA 2 can also be prompted with images, including sketches, to specify locations, paths, or objects.",
                "position": 495
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x5.png",
                "caption": "Figure 6:Average Performance on Embodied Tasks. Performance is averaged over training environments for each type of evaluation (human or automatic). We plot human performance both with and without the time restrictions imposed on agents. SIMA 2 effectively doubles the average success rate of SIMA 1, approaching human-level performance in both cases.",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x6.png",
                "caption": "Figure 7:Performance Across Skill Categories. SIMA 2 significantly improves over SIMA 1 across multiple skill categories. In categories like interaction and object management, SIMA 2 nearly closes the gap with human-level performance. However, in other categories, like resource gathering and combat, SIMA 2 still has room for improvement.",
                "position": 521
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x7.png",
                "caption": "Figure 8:Performance onHumanEvaluations By Environment. Bars show the task success rate of SIMA 1, SIMA 2, and humans on a suite of tasks from training environments, with success measured by 5 independent human ratings per trial. Human performance is plotted subject to the same timeout restrictions as imposed on agents (darker) and with this restriction removed (lighter). SIMA 2 improves significantly over SIMA 1 across all environments, nearly closing the gap with human performance in many cases.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x8.png",
                "caption": "Figure 9:Performance onAutomaticEvaluations By Environment. Bars show the task success rate of SIMA 1, SIMA 2, and humans on a suite of tasks from training environments, with success measured by ground truth rewards (Construction Lab, Playhouse, and WorldLab) or programmatic evaluation (all other environments). Where applicable, human performance is plotted with and without the same timeout restrictions as imposed on agents. SIMA 2 improves significantly over SIMA 1 across nearly all environments, almost closing the gap with human performance in many cases.",
                "position": 533
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x9.png",
                "caption": "Figure 10:Held-Out Environment Performance. SIMA 2 outperforms SIMA 1 on two held-out environments (i.e., unseen during training): ASKA and MineDojo. This demonstrates that SIMA 2 is a more general agent, capable of performing non-trivial tasks in new settings.",
                "position": 549
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x10.png",
                "caption": "Figure 11:SIMA 1 vs. SIMA 2 inASKAandMinecraft(Held-Out Environments). SIMA 2 generalizes to non-trivial tasks in environments entirely held out from training, whereas SIMA 1 struggles in these settings. In addition to completing these tasks, SIMA 2’s dialogue output indicates that it correctly identifies key on-screen events to help drive behavior, such as recognizing a campfire or a zombie. SIMA 2 can even generalize to entirely new menus, identifying on-screen text to select the correct buttons.",
                "position": 555
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x11.png",
                "caption": "",
                "position": 559
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x12.png",
                "caption": "Figure 12:SIMA 2 inThe Gunk(Held-Out Environment). Through manual instruction, SIMA 2 progressed through the first 15-20 minutes of The Gunk, a story-driven action-adventure game previously unseen during training. Along the event progression (top), circles denote game-defined milestones, and squares denote other notable events. SIMA 2 identified on-screen targets and reasoned through the appropriate actions using on-screen cues, enabling the completion of highly novel tasks.",
                "position": 577
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x13.png",
                "caption": "Figure 13:SIMA 2 inGenie 3(Held-Out Environments). We deployed SIMA 2 across a range of naturalistic and urban photorealistic environments generated by Genie 3. Despite learning embodiment skills purely in research and video game environments, we find that SIMA 2 performs well, particularly at navigation-based tasks, even in these novel photorealistic settings.",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x14.png",
                "caption": "Figure 14:Complex Multi-modal Instruction Following. By combining Gemini Pro with SIMA 2, we can enable even more advanced reasoning capabilities. In this case, the combined agent successfully uses a complex diagram to complete the multi-step task of building a campfire. Throughout, the agent communicates its current actions and intended next steps.",
                "position": 691
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x15.png",
                "caption": "Figure 15:Self-Improvement on a Fixed Set of Tasks inASKA. To isolate the improvement aspect of our learning process, independent of the task setter, we first use a fixed set of tasks in ASKA. Over successive iterations (darker blue points and curves), we see that performance steadily improves, eventually exceeding a score of5050across the full task set (the threshold for “success”). Performance approaches, and in some cases even exceeds, the scores of reference trajectories from humans.",
                "position": 719
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x16.png",
                "caption": "(a)",
                "position": 761
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x16.png",
                "caption": "(a)",
                "position": 764
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x17.png",
                "caption": "(b)",
                "position": 769
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x18.png",
                "caption": "Figure 17:Self-Improvement inGenie 3. We deploy SIMA 2 on a set of train tasks in urban environments from Genie 3,e.g., finding a lollipop in a candy store. Using our self-improvement process, we see broad improvement in scores across nearly all train tasks. More importantly, these improvements also extend to a set of held-out test tasks in natural environments,e.g., enabling the agent to navigate to a red mushroom. This suggests a route toward open-ended self-improvement in increasingly diverse environments to obtain more general and capable agents.",
                "position": 787
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "SIMA 2 Team",
        "images": []
    },
    {
        "header": "Appendix AEmbodied Skill Categories",
        "images": []
    },
    {
        "header": "Appendix BAdditional Results Combining Gemini Pro & SIMA 2",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.04797/x19.png",
                "caption": "Figure 18:Abstract Reasoning. The combined Gemini Pro + SIMA 2 agent successfully incorporates the user’s initial instruction to“do the opposite of what I tell you.”The agent correctly applies this form of abstract reasoning to a series of navigation, menu use, and tool use tasks, demonstrating both memory and more advanced reasoning.",
                "position": 980
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x20.png",
                "caption": "Figure 19:Active Exploration. The combined Gemini Pro + SIMA 2 agent plays the game 21 questions with a user, asking questions and using the user’s answers to drive active exploration. Again, this highlights the advanced capabilities of the combined agent to use both memory and reasoning to complete a novel task.",
                "position": 989
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x21.png",
                "caption": "Figure 20:Self-Improvement Behavior. Through training on self-generated experience, SIMA 2 is capable of acquiring new skills in a previously unseen environment, ASKA. After running multiple iterations of self-improvement, the agent learns to recognize a novel object (rain collector) and perform a new skill (extinguishing a campfire).",
                "position": 997
            },
            {
                "img": "https://arxiv.org/html/2512.04797/x22.png",
                "caption": "Figure 21:ASKA Technology Tree. Starting from a new game, the diagram shows theminimaltech tree required to summon the first villager (a core mechanic of the game).",
                "position": 1000
            }
        ]
    },
    {
        "header": "Appendix CAdditional Self-Improvement Results",
        "images": []
    }
]