[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06945/figs/case.png",
                "caption": "Figure 1:As shown in (a), we illustrate an example of Interleaving Reasoning Generation (IRG).\nGiven a prompt, the model first produces a text‑based reasoning process and then generates an image conditioned on that reasoning. Next, building upon the initial image, the model reflects on how to improve its quality and produces a refined image through this reflection process.\nIRG can substantially enhance image generation quality.\nFor instance, in the top case of (a), IRG improves upon the previous generated image via multi‑turn reasoning, enhancing rendering textures, shadow realism, and other visual properties.\nIn the bottom case of (a), IRG significantly improves fine‑grained details, such as the delicate structures of fingers—highlighted within the red box (as detailed in (b)).\nAs shown in (c), compared to current SoTA models, our proposed IRG achieves clearly superior performance across multiple mainstream T2I benchmarks.",
                "position": 128
            },
            {
                "img": "https://arxiv.org/html/2509.06945/figs/big_case.png",
                "caption": "Figure 2:Visualization results of IRG at 1024×1024 resolution.\nThe examples are selected from WISE(Niu et al.,2025), TIIF(Wei et al.,2025), and GenAI-Bench(Li et al.,2024a).",
                "position": 138
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06945/figs/overview.png",
                "caption": "Figure 3:Overview of our proposed IRG training and inference pipeline.\nIRG learns the text-based thinking process and the complete high-quality image generation pipeline under six decomposed learning modes.\nDuring inference, we introduce a dedicated CFG condition design(Ho & Salimans,2022)for IRG’s improved image generation steps.",
                "position": 188
            }
        ]
    },
    {
        "header": "2Method",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.06945/figs/compare.png",
                "caption": "Figure 4:Visualization comparison results of BAGEL(Deng et al.,2025), BAGEL w/ self-CoT(Deng et al.,2025), IRG reasoning step 1 and our proposed IRG at 1024×1024 resolution.\nThe examples are selected from WISE(Niu et al.,2025)and GenAI-Bench(Li et al.,2024a).\nRed boxes highlight the fine-grained details that have obvious flaws.",
                "position": 2212
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]