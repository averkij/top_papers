[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Cheating strategies",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x1.png",
                "caption": "Figure 2:Loss curves of adversarial suffix and our methods, indicating that adversarial suffix is ineffective on AlpacaEval 2.0.",
                "position": 205
            }
        ]
    },
    {
        "header": "4Cheating GPT-4 based automatic LLM benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x2.png",
                "caption": "Figure 3:Boxplot of thelog⁡p⁢(𝚠𝚒𝚗𝚗𝚎𝚛=𝙽𝚞𝚕𝚕𝙼𝚘𝚍𝚎𝚕)𝑝𝚠𝚒𝚗𝚗𝚎𝚛𝙽𝚞𝚕𝚕𝙼𝚘𝚍𝚎𝚕\\log p(\\mathtt{winner}=\\mathtt{NullModel})roman_log italic_p ( typewriter_winner = typewriter_NullModel )using different null responses.\nThe response of each index can be found in Table4.\nThe target model’s responses are positioned in the second slot by “Default” and swapped to the first slot in “Swap”.\nOur structured response (marked as “Ours”) achieves the lowest log probabilities compared to the other 16 persuasive responses.",
                "position": 378
            }
        ]
    },
    {
        "header": "5Ablation studies on open-source auto-annotators",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x3.png",
                "caption": "(a)",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x3.png",
                "caption": "(a)",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x4.png",
                "caption": "(b)",
                "position": 563
            }
        ]
    },
    {
        "header": "6Anti-cheating strategies",
        "images": []
    },
    {
        "header": "7Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x5.png",
                "caption": "(a)Null Model",
                "position": 734
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x5.png",
                "caption": "(a)Null Model",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x6.png",
                "caption": "(b)GPT-3.5-0613",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x7.png",
                "caption": "(c)Null Model",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x8.png",
                "caption": "(d)GPT-3.5-0613",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x9.png",
                "caption": "Figure 6:PPL (windowed) of responses from various sources.\nWe plot the windowed perplexity (PPL) for GPT-4 Preview (11/06), GPT-3.5 Turbo (06/13), and LLaMA2-Chat 7B.\nThe cyan dashed line indicates the PPL of our structured response with a76.8%percent76.876.8\\%76.8 %LC win rate while the pink one represents the PPL of our RS-augmented structured response with a86.5%percent86.586.5\\%86.5 %LC win rate.\nThe results suggest that PPL filter is insufficient to defend our structured response.",
                "position": 796
            }
        ]
    },
    {
        "header": "8Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation details",
        "images": []
    }
]