[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3Cheating strategies",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x1.png",
                "caption": "Figure 2:Loss curves of adversarial suffix and our methods, indicating that adversarial suffix is ineffective on AlpacaEval 2.0.",
                "position": 205
            }
        ]
    },
    {
        "header": "4Cheating GPT-4 based automatic LLM benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x2.png",
                "caption": "Figure 3:Boxplot of thelogâ¡pâ¢(ğš ğš’ğš—ğš—ğšğš›=ğ™½ğšğš•ğš•ğ™¼ğš˜ğšğšğš•)ğ‘ğš ğš’ğš—ğš—ğšğš›ğ™½ğšğš•ğš•ğ™¼ğš˜ğšğšğš•\\log p(\\mathtt{winner}=\\mathtt{NullModel})roman_log italic_p ( typewriter_winner = typewriter_NullModel )using different null responses.\nThe response of each index can be found in Table4.\nThe target modelâ€™s responses are positioned in the second slot by â€œDefaultâ€ and swapped to the first slot in â€œSwapâ€.\nOur structured response (marked as â€œOursâ€) achieves the lowest log probabilities compared to the other 16 persuasive responses.",
                "position": 378
            }
        ]
    },
    {
        "header": "5Ablation studies on open-source auto-annotators",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x3.png",
                "caption": "(a)",
                "position": 554
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x3.png",
                "caption": "(a)",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x4.png",
                "caption": "(b)",
                "position": 563
            }
        ]
    },
    {
        "header": "6Anti-cheating strategies",
        "images": []
    },
    {
        "header": "7Related work",
        "images": [
            {
                "img": "https://arxiv.org/html/2410.07137/x5.png",
                "caption": "(a)Null Model",
                "position": 734
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x5.png",
                "caption": "(a)Null Model",
                "position": 737
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x6.png",
                "caption": "(b)GPT-3.5-0613",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x7.png",
                "caption": "(c)Null Model",
                "position": 747
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x8.png",
                "caption": "(d)GPT-3.5-0613",
                "position": 752
            },
            {
                "img": "https://arxiv.org/html/2410.07137/x9.png",
                "caption": "Figure 6:PPL (windowed) of responses from various sources.\nWe plot the windowed perplexity (PPL) for GPT-4 Preview (11/06), GPT-3.5 Turbo (06/13), and LLaMA2-Chat 7B.\nThe cyan dashed line indicates the PPL of our structured response with a76.8%percent76.876.8\\%76.8 %LC win rate while the pink one represents the PPL of our RS-augmented structured response with a86.5%percent86.586.5\\%86.5 %LC win rate.\nThe results suggest that PPL filter is insufficient to defend our structured response.",
                "position": 796
            }
        ]
    },
    {
        "header": "8Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation details",
        "images": []
    }
]