[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.13347/extracted/6631791/figures/rocket_16761028.png",
                "caption": "",
                "position": 80
            },
            {
                "img": "https://arxiv.org/html/2507.13347/extracted/6631791/figures/github-logo_25231.png",
                "caption": "",
                "position": 86
            },
            {
                "img": "https://arxiv.org/html/2507.13347/x1.png",
                "caption": "",
                "position": 92
            },
            {
                "img": "https://arxiv.org/html/2507.13347/x2.png",
                "caption": "",
                "position": 104
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.13347/x3.png",
                "caption": "Figure 2:œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTdemonstrates significant convergence acceleration (a) and enhanced scalability (b) compared to its non-equivariant counterpart. PI denotes thePermutation-EquIvariant property.",
                "position": 120
            },
            {
                "img": "https://arxiv.org/html/2507.13347/x4.png",
                "caption": "Figure 3:Performance comparison across different reference frames.While previous methods, even with DINO-based selection, show inconsistent results,œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTconsistently delivers superior and stable performance, demonstrating its robustness.",
                "position": 132
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.13347/x5.png",
                "caption": "Figure 4:Unlike prior methods that designate areference viewby concatenating a special token (Type A) or adding a learnable embedding (Type B),œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTachieves permutation equivariance by eliminating this requirement altogether. Instead, it employs relative supervision, making our approach inherently robust to the order of input views.",
                "position": 200
            },
            {
                "img": "https://arxiv.org/html/2507.13347/x6.png",
                "caption": "Figure 5:Comparison of predicted pose distributions. Our predicted pose distribution exhibits a clear low-dimensional structure.",
                "position": 370
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.13347/x7.png",
                "caption": "Figure 6:Qualitative comparison of multi-view 3D reconstruction.Compared to other multi-frame feed-forward reconstruction methods,œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTproduces cleaner, more accurate and more complete reconstructions with fewer artifacts.",
                "position": 413
            },
            {
                "img": "https://arxiv.org/html/2507.13347/x8.png",
                "caption": "Figure 7:Qualitative comparison of in-the-wild multi-view 3D reconstruction.œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTdemonstrates superior robustness on challenging in-the-wild sequences, consistently producing more coherent and complete 3D structures for both dynamic and complex static scenes compared to other feed-forward approaches.",
                "position": 1347
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.13347/x9.png",
                "caption": "Figure 8:Comparison of predicted pose distributions. We visualize the predicted pose distributions in 3D space.œÄ3superscriptùúã3\\pi^{3}italic_œÄ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPTshows a clear low-dimensional structure, while VGGT‚Äôs distribution is scattered.",
                "position": 2459
            },
            {
                "img": "https://arxiv.org/html/2507.13347/extracted/6631791/figures/scaling_curve.jpg",
                "caption": "Figure 9:Comparison of the PI model (solid colored lines) against the non-PI baseline (dashed lines) across three model scales. The metric shown is the average of Accuracy and Completeness on the 7-Scenes[27]and NRGBD[1]datasets. The shaded area visually represents the performance improvement gained by the PI model.",
                "position": 2476
            }
        ]
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    }
]