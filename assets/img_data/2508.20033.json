[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.20033/x1.png",
                "caption": "",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x2.png",
                "caption": "(a)Open-source systems, Search AIs, and DeepScholar-base, each with Llama-4-Scout-17B-16E-Instruct model.",
                "position": 116
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x3.png",
                "caption": "(a)Open-source systems, Search AIs, and DeepScholar-base, each with Llama-4-Scout-17B-16E-Instruct model.",
                "position": 125
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x4.png",
                "caption": "(b)Search AIs with proprietary models (o3, Claude-opus-4, Gemini-2.5-pro), OpenAI DeepResearch, and DeepScholar-base (GPT4.1, Claude-opus-4)",
                "position": 130
            }
        ]
    },
    {
        "header": "1.Introduction",
        "images": []
    },
    {
        "header": "2.The DeepScholar Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.20033/x5.png",
                "caption": "Figure 2.DeepScholarBench Overview. To curate our dataset with real and challenging research tasks, we scrape recent, high-quality ArXiv papers from diverse domains, and extracting key attributes from each paper through an automated data pipeline that can easily be re-run. Our dataset task is to generate a related works section given information about a paper, such as it’s title and abstract. The DeepScholar-bench evaluation framework then holistically measures performance of generated reports on three key dimensions: knowledge synthesis, retrieval quality and verifiability.",
                "position": 278
            }
        ]
    },
    {
        "header": "3.The DeepScholar Evaluation Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.20033/x6.png",
                "caption": "Figure 3.Overview of DeepScholar-base. The system iteratively writes queries and performs web search, before passing the search results through series of semantic operators using the LOTUS system for LLM-based data-processing, including a filtering step to discard irrelevant sources, a top-k ranking step to re-rank the most relevant sources, and a final aggregation step to generate the final report from all remaining sources.",
                "position": 359
            }
        ]
    },
    {
        "header": "4.DeepScholar-base",
        "images": []
    },
    {
        "header": "5.Experimental Results",
        "images": []
    },
    {
        "header": "6.Related Work",
        "images": []
    },
    {
        "header": "7.Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.20033/x7.png",
                "caption": "Figure 4.DeepScholar-bench dataset schema.",
                "position": 2061
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x8.png",
                "caption": "Figure 8.Citation importance breakdown in DeepScholar-Bench. Each bar corresponds to a single human exemplar related work section, sorted by the total number of citations. Bars are color-coded to indicateimportant ArXiv citations(red),important non-ArXiv citations(orange), andnon-essential citations(blue).",
                "position": 2612
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x9.png",
                "caption": "Figure 10.Ablation study on citation coverage with different window sizes.\nFor each claim, we measure whether any citation within a sliding window of[−w,+w][-w,+w]sentences supports it.",
                "position": 2672
            },
            {
                "img": "https://arxiv.org/html/2508.20033/x10.png",
                "caption": "Figure 11.Distribution of citation counts (Document Importance) for references in human-written exemplars.\nFigure (a) shows all references, while Panel (b) restricts to ArXiv references only.\nCitation counts are plotted on a logarithmic scale.",
                "position": 2687
            }
        ]
    },
    {
        "header": "8.Appendix",
        "images": []
    }
]