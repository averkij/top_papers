[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15082/x1.png",
                "caption": "Figure 1:Left:Standard unlearning methods are applied equally to all points in the forget set.\nHere, outlier points in the model’s hidden space (visualized in 2D) contribute to the unintentional forgetting of points outside of the forget set (i.e. collateral damage).Right:By finding a lower-variance coreset within the forget set,UPCOREreduces damage while maintaining forget performance via positive transfer from the coreset to the pruned points.",
                "position": 165
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": []
    },
    {
        "header": "3Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15082/x2.png",
                "caption": "Figure 2:UPCOREhas four stages. First, we extract hidden states from the LLM to be modified; second, we identify outliers using Isolation Forests; third, we prune outliers to select a core forget set, and fourth, we perform unlearning on the coreset.",
                "position": 283
            }
        ]
    },
    {
        "header": "4Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15082/x3.png",
                "caption": "Figure 3:Trading-off between deletion effectiveness and model utility forms a Pareto frontier across epochs, shown here averaged across Counterfact topics using Gradient Ascent. Our proposed AUC metric quantifies the area under these curves, withUPCOREconsistently achieving the highest AUC across all settings.",
                "position": 443
            }
        ]
    },
    {
        "header": "5Experimental Results and Discussion",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15082/x4.png",
                "caption": "Figure 4:AUC between forget set ROUGE and neighborhood data ROUGE averaged across topics in Counterfact.UPCOREreduces damage to neighborhood data.",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x5.png",
                "caption": "Figure 5:Impact of scaling the coreset size on performance: AUC scores on different utility sets, averaged across Counterfact topics, for various pruning percentages.",
                "position": 863
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x6.png",
                "caption": "Figure 6:Hidden state variance of the baseline andUPCOREforget sets across the six Counterfact forget topics.UPCOREconsistently reduces variance using Isolation Forest as expected.",
                "position": 873
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Background",
        "images": [
            {
                "img": "https://arxiv.org/html/2502.15082/x7.png",
                "caption": "(a)Model utility and hidden state variance of the forget data show a strong negative correlation of -0.714 across data from multiple topics.",
                "position": 1726
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x7.png",
                "caption": "(a)Model utility and hidden state variance of the forget data show a strong negative correlation of -0.714 across data from multiple topics.",
                "position": 1729
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x8.png",
                "caption": "(b)Drop in model utility after unlearning and base model’s confidence on the forget data do not show any strong correlation with a Pearson correlation value of -0.021.",
                "position": 1734
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x9.png",
                "caption": "(a)Hidden state variance of the core forget set plotted against the pruning percentage across topics. The variance of the core forget data decreases nearly linearly as the pruning percentage increases.",
                "position": 1742
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x9.png",
                "caption": "(a)Hidden state variance of the core forget set plotted against the pruning percentage across topics. The variance of the core forget data decreases nearly linearly as the pruning percentage increases.",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2502.15082/x10.png",
                "caption": "(b)Drop in MMLU after unlearning vs. the gradient similarity between MMLU data and topic forget data. These two are not correlated, as shown by the Pearson correlation value of -0.020.",
                "position": 1750
            }
        ]
    },
    {
        "header": "Appendix BMethod Details and Analysis",
        "images": []
    }
]