[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/visual_proof_1.png",
                "caption": "Figure 1:G-RNNs are not generally flow equivariant.We show this by simple counterexample with:ht+1=ht+ftsubscriptâ„ğ‘¡1subscriptâ„ğ‘¡subscriptğ‘“ğ‘¡h_{t+1}=h_{t}+f_{t}italic_h start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. See Â§A.4for the full proof.",
                "position": 384
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/train_loss_2digit_small.png",
                "caption": "Figure 2:Increased flow equivariance increases training speed on data with flow symmetry. Validation loss vs. train steps.",
                "position": 616
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/train_loss_2digit_small.png",
                "caption": "Figure 2:Increased flow equivariance increases training speed on data with flow symmetry. Validation loss vs. train steps.",
                "position": 619
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x1.png",
                "caption": "Figure 3:FERNNs exhibit next-step prediction length-generalization capabilities far surpassing G-RNNs on simple flows. We plot samples for the forward prediction trajectories of a G-RNN and FERNN-V2Tsubscriptsuperscriptğ‘‰ğ‘‡2V^{T}_{2}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTtrained on Translating MNISTV2Tsuperscriptsubscriptğ‘‰2ğ‘‡V_{2}^{T}italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPTto predict 10-steps into the future (down-sampled by a factor of 4 in time for visualization). We see the G-RNN performs well on this training regime but diverges rapidly with lengths longer than training. The FERNN generalizes nearly perfectly. On the right, we plot this forward prediction error vs. the forward prediction timestep for both models.",
                "position": 689
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x2.png",
                "caption": "Figure 4:FERNNs exhibit next-step prediction generalization to previously unseen rotation flow velocities where G-RNNs fail. Samples of forward predictions for FERNN-V4Rsubscriptsuperscriptğ‘‰ğ‘…4V^{R}_{4}italic_V start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPTtrained on Rotating MNIST withV1Rsubscriptsuperscriptğ‘‰ğ‘…1V^{R}_{1}italic_V start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTand tested onV5Rsubscriptsuperscriptğ‘‰ğ‘…5V^{R}_{5}italic_V start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT. We see the FERNN-V4Rsubscriptsuperscriptğ‘‰ğ‘…4V^{R}_{4}italic_V start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPTachieves near perfect forward-prediction performance in this range. On the right we plot the full distribution of error acrossVtâ¢eâ¢sâ¢tsubscriptğ‘‰ğ‘¡ğ‘’ğ‘ ğ‘¡V_{test}italic_V start_POSTSUBSCRIPT italic_t italic_e italic_s italic_t end_POSTSUBSCRIPT.",
                "position": 698
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x3.png",
                "caption": "Figure 5:FERNNs exhibit next-step prediction generalization to previously unseen translation flow velocities where G-RNNs fail. Samples of forward prediction trajectories for FERNN-V2Tsubscriptsuperscriptğ‘‰ğ‘‡2V^{T}_{2}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTtrained on Translating MNIST withV1Tsubscriptsuperscriptğ‘‰ğ‘‡1V^{T}_{1}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTand tested onV2Tsubscriptsuperscriptğ‘‰ğ‘‡2V^{T}_{2}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. On the right we plot the full distribution of error across the 2D velocity coordinates inVtâ¢eâ¢sâ¢tsubscriptğ‘‰ğ‘¡ğ‘’ğ‘ ğ‘¡V_{test}italic_V start_POSTSUBSCRIPT italic_t italic_e italic_s italic_t end_POSTSUBSCRIPT.",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x4.png",
                "caption": "Figure 6:FERNNs outperform non-equivariant models on action recognition undergoing out-of-distribution flows (orange). Test accuracy of models trained on KTH Action Recognition with no motionV0Tsubscriptsuperscriptğ‘‰ğ‘‡0V^{T}_{0}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT(top row) and trained on data augmented by flow generatorsV1Tsubscriptsuperscriptğ‘‰ğ‘‡1V^{T}_{1}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(bottom row). The models are tested on data augmented by flow generatorsV0Tsubscriptsuperscriptğ‘‰ğ‘‡0V^{T}_{0}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT,V1Tsubscriptsuperscriptğ‘‰ğ‘‡1V^{T}_{1}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,V2Tsubscriptsuperscriptğ‘‰ğ‘‡2V^{T}_{2}italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT(columns).",
                "position": 768
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x5.png",
                "caption": "Figure 7:A visualization of the same counter example of Figure1from the main text, but for the Flow Equivariant RNN. We see that the model is built with a set of extraVğ‘‰Vitalic_Vchannels, depicted as the three separate rows of hidden states, where each row flows independently per timestep according to itsÎ½ğœˆ\\nuitalic_Î½parameter (e.g. the bottom row flows with velocityâˆ’11-1- 1, to the left, while the top row flows with velocity1111to the right). When the model is then processing an input with a corresponding flow symmetry (for example a motion of velocity1111to the right), the corresponding flowing channel of the hidden state processes this input in the same reference frame, as if it were stationary (the top row in this example). The remaining rows then process the input with a difference corresponding to the difference in velocity between the hidden state channel and the input velocity. We see that this results in theÎ½âˆ’Î½^ğœˆ^ğœˆ\\nu-\\hat{\\nu}italic_Î½ - over^ start_ARG italic_Î½ end_ARGchannel permutation in the latent space (the vertical shift in theVğ‘‰Vitalic_Vdimension by 1 row).",
                "position": 2645
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/samples/KTH_V0.png",
                "caption": "(a)Original KTH datasetV0Tsuperscriptsubscriptğ‘‰0ğ‘‡V_{0}^{T}italic_V start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT",
                "position": 2993
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/samples/KTH_V0.png",
                "caption": "(a)Original KTH datasetV0Tsuperscriptsubscriptğ‘‰0ğ‘‡V_{0}^{T}italic_V start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT",
                "position": 2996
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/samples/KTH_V1.png",
                "caption": "(b)KTH withV=V1Tğ‘‰superscriptsubscriptğ‘‰1ğ‘‡V=V_{1}^{T}italic_V = italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT",
                "position": 3001
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/samples/KTH_V2.png",
                "caption": "(c)KTH withV=V2Tğ‘‰superscriptsubscriptğ‘‰2ğ‘‡V=V_{2}^{T}italic_V = italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT",
                "position": 3006
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x6.png",
                "caption": "Figure 9:In-distribution sequence predictions for the models from Table1& Figure2, trained on Rotating MNISTV4Rsubscriptsuperscriptğ‘‰ğ‘…4V^{R}_{4}italic_V start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT(left) and Translating MNISTV2Tsuperscriptsubscriptğ‘‰2ğ‘‡V_{2}^{T}italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT(right), evaluated on the same flows.",
                "position": 3190
            },
            {
                "img": "https://arxiv.org/html/2507.14793/extracted/6636682/figs/rot_mnist_lengen.png",
                "caption": "Figure 10:MSE vs. Forward prediction horizon for models on Rotating MNIST. Analogous plot to Figure3(right) but for Rotating MNIST.",
                "position": 3200
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x7.png",
                "caption": "Figure 11:Samples from models trained on Translating MNISTV2Tsuperscriptsubscriptğ‘‰2ğ‘‡V_{2}^{T}italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPTwith training sequence lengths of 20, tested on sequence lengths of 80. We plot the 70-forward prediction steps here, subsampled by half in time (giving 35 elements).",
                "position": 3211
            },
            {
                "img": "https://arxiv.org/html/2507.14793/x8.png",
                "caption": "Figure 12:Samples from models trained on Rotating MNISTV1Rsuperscriptsubscriptğ‘‰1ğ‘…V_{1}^{R}italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT(left) and Translating MNISTV1Tsuperscriptsubscriptğ‘‰1ğ‘‡V_{1}^{T}italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT(right), and tested on sequences with significantly higher velocity flows (V4Rsuperscriptsubscriptğ‘‰4ğ‘…V_{4}^{R}italic_V start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPTandV2Tsuperscriptsubscriptğ‘‰2ğ‘‡V_{2}^{T}italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPTrespectively). We see that the FERNN (bottom rows) has no problem generalizing to these new velocities despite never having seen them in training, while the G-RNN (top) fails. The specific flows plotted in this example areÂ±40â¢dâ¢eâ¢gsâ¢tâ¢eâ¢pplus-or-minus40ğ‘‘ğ‘’ğ‘”ğ‘ ğ‘¡ğ‘’ğ‘\\pm 40\\frac{deg}{step}Â± 40 divide start_ARG italic_d italic_e italic_g end_ARG start_ARG italic_s italic_t italic_e italic_p end_ARGfor Rotating MNIST (left), andÎ½=(Â±2,Â±2)ğœˆplus-or-minus2plus-or-minus2\\nu=(\\pm 2,\\pm 2)italic_Î½ = ( Â± 2 , Â± 2 )for Translating MNIST.",
                "position": 3222
            }
        ]
    },
    {
        "header": "Appendix",
        "images": []
    }
]