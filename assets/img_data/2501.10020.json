[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.10020/x1.png",
                "caption": "Figure 1:Examples of animatable 2D cartoon characters generated by Textoon.",
                "position": 60
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.10020/x2.png",
                "caption": "Figure 2:Pipeline of the Textoon. The framework includes text parsing, controllable appearance generation, re-editing, and component completion and repair modules.",
                "position": 124
            }
        ]
    },
    {
        "header": "3Live2D Generation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.10020/x3.png",
                "caption": "Figure 3:Meshes of different layers.",
                "position": 149
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x4.png",
                "caption": "Figure 4:Splitting model components, larger elements can be utilized to create short variations.",
                "position": 159
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x5.png",
                "caption": "Figure 5:Using the fine-tuned LLM to parse component categories from complex input text.",
                "position": 169
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x6.png",
                "caption": "Figure 6:The divisions of each component within our template model.",
                "position": 185
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x7.png",
                "caption": "Figure 7:Restoring the back hair: First, extract the pixels (b) from the generated image using the model pattern (a). Then, fill the area occluded by the head with pixels from the region connected to the front hair (c). Finally, perform image-to-image generation (d).",
                "position": 202
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x8.png",
                "caption": "Figure 8:Live2D model supporting ARKit lip-sync driving.",
                "position": 212
            },
            {
                "img": "https://arxiv.org/html/2501.10020/x9.png",
                "caption": "Figure 9:The overall animation effects of the generated Live2D model.",
                "position": 215
            }
        ]
    },
    {
        "header": "4Results",
        "images": []
    },
    {
        "header": "5Limitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.10020/x10.png",
                "caption": "Figure 10:Examples of Live2D cartoon characters created along with their corresponding text prompts.",
                "position": 233
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]