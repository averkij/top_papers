[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x1.png",
                "caption": "Figure 1:FVDs of short clips generated by different models and methods.",
                "position": 120
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x2.png",
                "caption": "Figure 2:Examples of error accumulation (first two rows) and memory bottleneck (last two rows).",
                "position": 152
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x3.png",
                "caption": "Figure 3:This figure indicatesMeta-ARVDMframework. The left part if the initialization stage, which denoises withMinitsubscriptùëÄinitM_{{\\text{init}}}italic_M start_POSTSUBSCRIPT init end_POSTSUBSCRIPTsteps. We add noise to the output of this stage to form the starting point of theARgeneration stage. We then auto-regressively apply Algorithm3for denoising. Themonotonicity,circularity, and0‚àíT0ùëá0-T0 - italic_Tboundaryrequirements for plausible implementation are marked in the figure. Here‚Ñã‚Å¢({Yi+4+jtjI}j=14)‚Ñãsuperscriptsubscriptsuperscriptsubscriptùëåùëñ4ùëósuperscriptsubscriptùë°ùëóIùëó14\\mathcal{H}(\\{Y_{i+4+j}^{t_{j}^{\\mathrm{I}}}\\}_{j=1}^{4})caligraphic_H ( { italic_Y start_POSTSUBSCRIPT italic_i + 4 + italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_I end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT )are all the frames before the execution of the(i/2+2)ùëñ22(i/2+2)( italic_i / 2 + 2 )-th iteration.",
                "position": 236
            }
        ]
    },
    {
        "header": "3A General Framework of ARVDMs",
        "images": []
    },
    {
        "header": "4Performance Analysis ofMeta-ARVDM",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x4.png",
                "caption": "Figure 4:The simplified setting for the proof of lower bounds.",
                "position": 556
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x5.png",
                "caption": "Figure 5:Network structure of adding information of previous frames into eachARstep. Herewmsubscriptùë§ùëöw_{m}italic_w start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPTis the number of past frames provided for the denoising network, andwùë§witalic_wis the number of frames to denoise. The superscriptMùëÄMitalic_Mrefers to the past frames and actions (memory).",
                "position": 594
            }
        ]
    },
    {
        "header": "5Mitigation of the Memory Bottleneck",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x6.png",
                "caption": "Figure 6:An example of the memory retrieval task in DMLab.",
                "position": 942
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x7.png",
                "caption": "Figure 7:Retrieval examples of DMLab. In contrast to Oasis in Figure2, which fails to generate a consistent scene, the improved models can retrieve the wall/floor color, texture, and decoration (e.g. paint on the wall) from previously seen mazes.",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x8.png",
                "caption": "Figure 8:Retrieval examples of Minecraft. The memory-enhanced model accurately recalls and retrieves scenes previously encountered in earlier views.",
                "position": 948
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x9.png",
                "caption": "Figure 9:Correlation between Memory Bottleneck and Error Accumulation.",
                "position": 952
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x10.png",
                "caption": "",
                "position": 955
            }
        ]
    },
    {
        "header": "6Conclusions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ANotations",
        "images": []
    },
    {
        "header": "Appendix BRelated Works",
        "images": []
    },
    {
        "header": "Appendix CDiscussion of Extensions",
        "images": []
    },
    {
        "header": "Appendix DDemos of Existing Methods and Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x11.png",
                "caption": "",
                "position": 1816
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x12.png",
                "caption": "",
                "position": 1841
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x13.png",
                "caption": "",
                "position": 1866
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x14.png",
                "caption": "",
                "position": 1891
            }
        ]
    },
    {
        "header": "Appendix EDemos of Our Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x15.png",
                "caption": "Figure 10:Recall demonstrations on DMLab. The left frames represent the expected ground truth, while the right frames, outlined with a red square, are generated by the model.",
                "position": 1920
            },
            {
                "img": "https://arxiv.org/html/2503.10704/x16.png",
                "caption": "Figure 11:Recall demonstrations on Minecraft. The left frames represent the expected ground truth, while the right frames, outlined with a red square, are generated by the model. The first 4 frames without red squares are provided context.",
                "position": 1923
            }
        ]
    },
    {
        "header": "Appendix FComparison ofChe et¬†al. (2024)and Our Channel Concatenation Structure",
        "images": []
    },
    {
        "header": "Appendix GExplanations of the Compression Network",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x17.png",
                "caption": "Figure 12:The network structure adopted to compress the past frames and actions.",
                "position": 1940
            }
        ]
    },
    {
        "header": "Appendix HError Accumulation in DMLabs and Minecraft",
        "images": []
    },
    {
        "header": "Appendix ISSIM Values Benchmark For Minecraft",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x18.png",
                "caption": "Figure 13:Minecraft Example Pairs from Minecraft Across Varying SSIM Score Ranges",
                "position": 2050
            }
        ]
    },
    {
        "header": "Appendix JExperimental Details",
        "images": []
    },
    {
        "header": "Appendix KFormal statement of Assumption4.3",
        "images": []
    },
    {
        "header": "Appendix LProof of Theorem4.4",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10704/x19.png",
                "caption": "Figure 14:The examples ofùí¢‚Å¢(‚ãÖ)ùí¢‚ãÖ\\mathcal{G}(\\cdot)caligraphic_G ( ‚ãÖ )and‚Ñã‚Å¢(‚ãÖ)‚Ñã‚ãÖ\\mathcal{H}(\\cdot)caligraphic_H ( ‚ãÖ ).",
                "position": 2143
            }
        ]
    },
    {
        "header": "Appendix MProof of Theorem4.5",
        "images": []
    },
    {
        "header": "Appendix NProof of Supporting Propositions",
        "images": []
    },
    {
        "header": "Appendix OSupporting Lemmas",
        "images": []
    }
]