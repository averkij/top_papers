[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16538/x1.png",
                "caption": "Figure 1:Existingreference-freemetrics like EMScore[31]often fail to detect factual inaccuracies and lack a consistent scoring scale.VC-Inspectoraddresses these limitations by providingfactually grounded,interpretable evaluations with explanations.",
                "position": 119
            },
            {
                "img": "https://arxiv.org/html/2509.16538/x2.png",
                "caption": "",
                "position": 123
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16538/x3.png",
                "caption": "Figure 2:(left) We present a data generation pipeline designed to systematically create synthetic video captions with diverse quality scores, along with explanations for the assigned scores. (right) This dataset was subsequently used for instruction tuning theVC-Inspector.",
                "position": 200
            }
        ]
    },
    {
        "header": "3Video Caption Quality Estimation",
        "images": []
    },
    {
        "header": "4VC-Inspector: Instruction Tuning for Factually Grounded Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16538/x4.png",
                "caption": "Figure 3:Data generation pipeline to create a synthetic dataset for training VC-Inspector. While both “talking” and “holding” were identified as actions, only “holding” was sampled for replacement in the synthetic dataset.",
                "position": 309
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16538/x5.png",
                "caption": "Table 3:Human correlation scores on the VATEX-EVAL[31]dataset.∗indicates results reported from[32]due to GPT-4 licensing issue. The best score for each column section isbolded.\nPlease note that this work focuses on theNo Referencesetting.Our best model has outperformed all other models in this setting, while remaining competitive with metrics that rely on references.",
                "position": 493
            },
            {
                "img": "https://arxiv.org/html/2509.16538/x6.png",
                "caption": "",
                "position": 865
            }
        ]
    },
    {
        "header": "6Conclusion and Discussion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix APrompts",
        "images": []
    },
    {
        "header": "Appendix BEvaluation on Explanation Quality",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.16538/x7.png",
                "caption": "Figure 5:Additional visual examples on VATEX-Eval.VC-Inspectoridentifies the incorrect objects (highlighted in red) and assigns scores aligned with human evaluators.",
                "position": 1733
            },
            {
                "img": "https://arxiv.org/html/2509.16538/x8.png",
                "caption": "",
                "position": 1745
            },
            {
                "img": "https://arxiv.org/html/2509.16538/x9.png",
                "caption": "",
                "position": 1751
            }
        ]
    },
    {
        "header": "Appendix CAdditional Visual Examples",
        "images": []
    }
]