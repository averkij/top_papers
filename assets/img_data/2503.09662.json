[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09662/x4.png",
                "caption": "",
                "position": 27
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x5.png",
                "caption": "",
                "position": 30
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x7.png",
                "caption": "",
                "position": 32
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x1.png",
                "caption": "",
                "position": 123
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09662/x2.png",
                "caption": "Figure 2:A concise explanation of whyCoRe2is effective (diffusion model for an example): we train a weak model to reflect the easy-to-learn components. Then, W2S guidance is employed to refine the more (fine-grained) difficult-to-learn components.",
                "position": 132
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x3.png",
                "caption": "Figure 3:Overview ofCollect,ReflectandRefine(CoRe2). We initially generate trajectories corresponding to CFG to collect data. Next, we train a weak model (i.e., the noise model equipped with MoE-LoRA) to capture the mapping from the conditional output to the CFG output, reflecting the easy-to-learn content. Finally, we employ W2S guidance to refine the conditional output (i.e., the fast mode) and the CFG output (i.e., slow mode), thereby enhancing the critical fine-grained information that is challenging to learn.",
                "position": 135
            }
        ]
    },
    {
        "header": "2Preliminaries",
        "images": []
    },
    {
        "header": "3CoRe2Framework",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09662/x6.png",
                "caption": "Figure 4:Framework of noise model‚Äôs backbone and MoE-LoRA. We employ MM-DiT-Block to construct noise model for SD3.5 and SDXL, and we utilize MoE-LoRA to reflect easy-to-learn content across different timesteps. For LlamaGen, we replace the backbone with its native Llama block[41]w/o MoE-LoRA.",
                "position": 283
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x8.png",
                "caption": "Figure 5:Visualization of the frequency histogram with the W2S guidanceœµstrongt‚àíœµweaktsubscriptsuperscriptitalic-œµùë°strongsubscriptsuperscriptitalic-œµùë°weak\\epsilon^{t}_{\\textrm{strong}}\\!-\\!\\epsilon^{t}_{\\textrm{weak}}italic_œµ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT strong end_POSTSUBSCRIPT - italic_œµ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT weak end_POSTSUBSCRIPTand CFGœµcondt‚àíœµuncondtsubscriptsuperscriptitalic-œµùë°condsubscriptsuperscriptitalic-œµùë°uncond\\epsilon^{t}_{\\textrm{cond}}\\!-\\!\\epsilon^{t}_{\\textrm{uncond}}italic_œµ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT cond end_POSTSUBSCRIPT - italic_œµ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT uncond end_POSTSUBSCRIPTin SDXL. Note that W2S guidance inCoRe2incorporates more high-frequency information compared to standard CFG. This effectively mitigates the base model‚Äôs limitations in generating fine-grained yet challenging-to-learn content during the pre-training phase.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x9.png",
                "caption": "Figure 6:Visualization of the model output obtained byCoRe2, compared with those from the strong model (i.e., standard CFG) and the weak model (i.e., the noise model). We begin by generating 500 initial Gaussian noise samples and their corresponding model outputs for the text prompt ‚Äúolympic swimming pool‚Äù. These are then projected into a lower-dimensional space using T-SNE[42]to produce the clear visualization.",
                "position": 376
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09662/x10.png",
                "caption": "Figure 7:Visualization of the standard sampling,CoRe2andZ-CoRe2on SD3.5, SDXL and LlamaGen. Compared to standard sampling,CoRe2andZ-CoRe2excel in generating images with more intricate high-frequency details, while also improving semantic consistency. In AppendixC.3, we present additional visualizations ofCoRe2across four distinct styles: anime, concept art, painting, and photography.",
                "position": 1265
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x11.png",
                "caption": "Figure 8:Ablation study of iteration numbers during theReflectphase using SD3.5. We find that the 10k iterations version contribute the best performance to the full-capacityCoRe2.",
                "position": 1268
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x12.png",
                "caption": "Figure 9:Ablation study ofœâw2ssubscriptùúîw2s\\omega_{\\textrm{w2s}}italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPTon SDXL. We observe thatCoRe2achieves optimal performance whenœâw2s=2.5subscriptùúîw2s2.5\\omega_{\\textrm{w2s}}=2.5italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPT = 2.5.",
                "position": 1286
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x13.png",
                "caption": "Figure 10:Ablation study ofœâw2ssubscriptùúîw2s\\omega_{\\textrm{w2s}}italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPTon SD3.5. We observe thatCoRe2achieves optimal performance whenœâw2s=1.5subscriptùúîw2s1.5\\omega_{\\textrm{w2s}}=1.5italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPT = 1.5.",
                "position": 1289
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix ABenchmark and Dataset",
        "images": []
    },
    {
        "header": "Appendix BDetail Implementation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09662/x14.png",
                "caption": "Figure 11:Visualization of the (modified)CoRe2and the standard sampling on FLUX. Compared toCoRe2, which is obtained through the complete three-stage pipeline, the (modified)CoRe2faces a limitation due to the lack of an open-sourced version of FLUX without CFG distillation. As a result, we treat FLUX.1-schnell a weak model, while FLUX.1-dev as a strong model when executing W2S guidance. Although FLUX falls slightly short in delivering the significant gains over standard sampling as seen inCoRe2in Fig.7, it nonetheless demonstrates a certain degree of improvement in both visual quality and semantic consistency of the generated images.",
                "position": 2427
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x15.png",
                "caption": "Figure 12:Ablation study ofœâw2ssubscriptùúîw2s\\omega_{\\textrm{w2s}}italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPTon LlamaGen. We observe thatCoRe2achieves optimal performance whenœâw2s=1.5subscriptùúîw2s1.5\\omega_{\\textrm{w2s}}=1.5italic_œâ start_POSTSUBSCRIPT w2s end_POSTSUBSCRIPT = 1.5.",
                "position": 2658
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x16.png",
                "caption": "Figure 13:Visualization comparison about the standard sampling andCoRe2in anime style on SD3.5.",
                "position": 2675
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x17.png",
                "caption": "Figure 14:Visualization comparison about the standard sampling andCoRe2in concept-art style on SD3.5.",
                "position": 2678
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x18.png",
                "caption": "Figure 15:Visualization comparison about the standard sampling andCoRe2in painting style on SD3.5.",
                "position": 2681
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x19.png",
                "caption": "Figure 16:Visualization comparison about the standard sampling andCoRe2in photography style on SD3.5.",
                "position": 2684
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x20.png",
                "caption": "Figure 17:Visualization comparison about the standard sampling andCoRe2in anime style on SDXL.",
                "position": 2687
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x21.png",
                "caption": "Figure 18:Visualization comparison about the standard sampling andCoRe2in concept-art style on SDXL.",
                "position": 2690
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x22.png",
                "caption": "Figure 19:Visualization comparison about the standard sampling andCoRe2in painting style on SDXL.",
                "position": 2693
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x23.png",
                "caption": "Figure 20:Visualization comparison about the standard sampling andCoRe2in photography style on SDXL.",
                "position": 2696
            },
            {
                "img": "https://arxiv.org/html/2503.09662/x24.png",
                "caption": "Figure 21:Visualization comparison about the standard sampling andCoRe2on LlamaGen.",
                "position": 2699
            }
        ]
    },
    {
        "header": "Appendix CHow Does W2S Guidance Work?",
        "images": []
    }
]