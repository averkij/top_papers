[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x1.png",
                "caption": "Figure 1:Comparison of text-to-image generation methods on two metrics, GenEval and T2I CompBench (higher is better for both). Despite significantly smaller model size, our proposed DiT-Air achieves state-of-the-art results. Note that, for our model, we report the full model size including text encoder and VAE. A detailed parameter breakdown is provided in AppendixG.",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2503.10618/",
                "caption": "Figure 2:Sample images from our proposed DiT-Air, each with the text prompt below it. See AppendixHfor more examples.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Architecture Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x3.png",
                "caption": "Figure 3:Overview of Latent Diffusion Training.During training,𝐱𝐱\\mathbf{x}bold_xis encoded into a latent𝐳0subscript𝐳0\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTvia a VAE, and the text promptp𝑝pitalic_pis mapped to embeddings𝐜𝐜\\mathbf{c}bold_c. A forward diffusion adds noise to𝐳0subscript𝐳0\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and the model learns to reverse this process by predicting the noise (or similar target) at each timestep.",
                "position": 245
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/Pixart.png",
                "caption": "Figure 4:Comparison of Diffusion Transformer Architectures.Element-wise operations are denoted by∙∙\\bullet∙, and sequence-wise operations by∘\\circ∘. The details of inputs𝐜𝐜\\mathbf{c}bold_c,𝐳𝐳\\mathbf{z}bold_z,t𝑡titalic_tcan be found in Figure3.\nPixArt-α𝛼\\alphaitalic_αrelies on sequential self- and cross-attention, whereas MMDiT uses a dual-stream approach with separate parameters for text and image tokens. Our proposed DiT-Air resembles a vanilla DiT that processes concatenated text and noises.",
                "position": 279
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/SD3.png",
                "caption": "",
                "position": 283
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/Simple_DiT.png",
                "caption": "",
                "position": 284
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x4.png",
                "caption": "Figure 5:Validation Loss vs. Model Size for PixArt-α𝛼\\alphaitalic_α, MMDiT, and DiT-Air.The plot illustrates the scaling behavior of three architectures across model sizes ranging from S to XXL, where the model size refers only to the diffusion transformer component (excluding the text encoder and VAE). The x-axis is in logarithmic scale, and the fitted lines depict the scaling trend using the formulaL=a⋅Sb𝐿⋅𝑎superscript𝑆𝑏L=a\\cdot S^{b}italic_L = italic_a ⋅ italic_S start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT. Among the three, DiT-Air achieves the best parameter efficiency.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2503.10618/x5.png",
                "caption": "Figure 6:Benchmark Performance Across Model Scales.The plots compare PixArt-α𝛼\\alphaitalic_α, MMDiT, and DiT-Air across six evaluation metrics. DiT-Air demonstrates strong parameter efficiency, achieving competitive performance with fewer parameters. The x-axis is in logarithmic scale, and error bounds are indicated where applicable.",
                "position": 533
            }
        ]
    },
    {
        "header": "5Text Encoders and VAEs",
        "images": []
    },
    {
        "header": "6Final Models",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BEvaluation",
        "images": []
    },
    {
        "header": "Appendix CDetailed Text Encoder Ablation Studies",
        "images": []
    },
    {
        "header": "Appendix DProgressive VAE Training Studies",
        "images": []
    },
    {
        "header": "Appendix ESupervised Fine-Tuning and Data Curation",
        "images": []
    },
    {
        "header": "Appendix FReward Fine-tuning",
        "images": []
    },
    {
        "header": "Appendix GState-of-the-Art Model Size Breakdown",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x6.png",
                "caption": "Figure 7:Sample images from our DiT-Air/XXL illustrating different capabilities",
                "position": 2448
            },
            {
                "img": "https://arxiv.org/html/2503.10618/x7.png",
                "caption": "Figure 8:Sample images from our DiT-Air/L-Lite illustrating different capabilities",
                "position": 2451
            }
        ]
    },
    {
        "header": "Appendix HGeneration Examples",
        "images": []
    }
]