[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x1.png",
                "caption": "Figure 1:Comparison of text-to-image generation methods on two metrics, GenEval and T2I CompBench (higher is better for both). Despite significantly smaller model size, our proposed DiT-AirÂ achieves state-of-the-art results. Note that, for our model, we report the full model size including text encoder and VAE. A detailed parameter breakdown is provided in AppendixG.",
                "position": 179
            },
            {
                "img": "https://arxiv.org/html/2503.10618/",
                "caption": "Figure 2:Sample images from our proposed DiT-Air, each with the text prompt below it. See AppendixHfor more examples.",
                "position": 185
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Architecture Design",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x3.png",
                "caption": "Figure 3:Overview of Latent Diffusion Training.During training,ğ±ğ±\\mathbf{x}bold_xis encoded into a latentğ³0subscriptğ³0\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPTvia a VAE, and the text promptpğ‘pitalic_pis mapped to embeddingsğœğœ\\mathbf{c}bold_c. A forward diffusion adds noise toğ³0subscriptğ³0\\mathbf{z}_{0}bold_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and the model learns to reverse this process by predicting the noise (or similar target) at each timestep.",
                "position": 245
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/Pixart.png",
                "caption": "Figure 4:Comparison of Diffusion Transformer Architectures.Element-wise operations are denoted byâˆ™âˆ™\\bulletâˆ™, and sequence-wise operations byâˆ˜\\circâˆ˜. The details of inputsğœğœ\\mathbf{c}bold_c,ğ³ğ³\\mathbf{z}bold_z,tğ‘¡titalic_tcan be found in Figure3.\nPixArt-Î±ğ›¼\\alphaitalic_Î±relies on sequential self- and cross-attention, whereas MMDiT uses a dual-stream approach with separate parameters for text and image tokens. Our proposed DiT-AirÂ resembles a vanilla DiT that processes concatenated text and noises.",
                "position": 279
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/SD3.png",
                "caption": "",
                "position": 283
            },
            {
                "img": "https://arxiv.org/html/2503.10618/extracted/6276989/Figure/Simple_DiT.png",
                "caption": "",
                "position": 284
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x4.png",
                "caption": "Figure 5:Validation Loss vs.Â Model Size for PixArt-Î±ğ›¼\\alphaitalic_Î±, MMDiT, and DiT-Air.The plot illustrates the scaling behavior of three architectures across model sizes ranging from S to XXL, where the model size refers only to the diffusion transformer component (excluding the text encoder and VAE). The x-axis is in logarithmic scale, and the fitted lines depict the scaling trend using the formulaL=aâ‹…Sbğ¿â‹…ğ‘superscriptğ‘†ğ‘L=a\\cdot S^{b}italic_L = italic_a â‹… italic_S start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT. Among the three, DiT-AirÂ achieves the best parameter efficiency.",
                "position": 530
            },
            {
                "img": "https://arxiv.org/html/2503.10618/x5.png",
                "caption": "Figure 6:Benchmark Performance Across Model Scales.The plots compare PixArt-Î±ğ›¼\\alphaitalic_Î±, MMDiT, and DiT-AirÂ across six evaluation metrics. DiT-AirÂ demonstrates strong parameter efficiency, achieving competitive performance with fewer parameters. The x-axis is in logarithmic scale, and error bounds are indicated where applicable.",
                "position": 533
            }
        ]
    },
    {
        "header": "5Text Encoders and VAEs",
        "images": []
    },
    {
        "header": "6Final Models",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BEvaluation",
        "images": []
    },
    {
        "header": "Appendix CDetailed Text Encoder Ablation Studies",
        "images": []
    },
    {
        "header": "Appendix DProgressive VAE Training Studies",
        "images": []
    },
    {
        "header": "Appendix ESupervised Fine-Tuning and Data Curation",
        "images": []
    },
    {
        "header": "Appendix FReward Fine-tuning",
        "images": []
    },
    {
        "header": "Appendix GState-of-the-Art Model Size Breakdown",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.10618/x6.png",
                "caption": "Figure 7:Sample images from our DiT-Air/XXL illustrating different capabilities",
                "position": 2448
            },
            {
                "img": "https://arxiv.org/html/2503.10618/x7.png",
                "caption": "Figure 8:Sample images from our DiT-Air/L-Lite illustrating different capabilities",
                "position": 2451
            }
        ]
    },
    {
        "header": "Appendix HGeneration Examples",
        "images": []
    }
]