[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x1.png",
                "caption": "",
                "position": 94
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x2.png",
                "caption": "Figure 2:Frequency map visualization of upsampled VAE latent. The upsampled latent serves as an approximation of a continuous signal.Left: Illustration of latent upsampling algorithm. For an encoder that downsamples the image by8×8\\times8 ×, we can leverage its shift-equivariance to achieve2×2\\times2 ×upsampling of the latent. By shifting the input image by 4 pixels, we create a 0.5-pixel shift in the latent. Combining these fractional shifted latents yields a higher-resolution latent.Right: Visualization of8×8\\times8 ×upsampled latent in both spatial and frequency domains. (a) AF-VAE with random weights, (b) AF-VAE without equivariance loss, (c) AF-VAE with equivariance loss. Ideally, a correctly band-limited latent would only use1/8181/81 / 8of the frequencies in the upsampled frequency domain. During training, the aliasing effects in a randomly initialized VAE with alias-free modules become more prominent; however, our proposed equivariance loss helps suppress the aliasing during training.",
                "position": 131
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x3.png",
                "caption": "Figure 3:The architecture of AF-LDM. Both VAE and U-Net of SD can be represented by an encoder-decoder structure. We implement ideal upsample, ideal downsample and filtered nonlinearity following[18,30].",
                "position": 247
            }
        ]
    },
    {
        "header": "4Experiment",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x4.png",
                "caption": "Figure 4:Visualization of LDM latent fractional shifts. The latent is obtained by DDIM inversion. The difference map between outputs and shifted outputs is given in the bottom right corner.",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x5.png",
                "caption": "Figure 5:Shift-equivariance during denoising process. We perform two denoising processes: one with Gaussian noise and the other with a1/2121/21 / 2pixel-shifted version of the same noise, computing the SPSNR after each denoising step. The experiment is conducted on 10,000 samples over 20 denoising steps.",
                "position": 623
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x6.png",
                "caption": "Figure 6:Quantitative comparison of fractional shift consistency. We horizontally shift latents by1/8181/81 / 8pixels per step and compute the average SPSNR for the VAE decoder and LDM pipeline for each step. The VAE is tested on 500 ImageNet validation images, and LDM is tested on 500 FFHQ images.",
                "position": 629
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x7.png",
                "caption": "Figure 7:Warping consistency experiments. Given neighboring frames and their ground truth optical flow, we can warp the inverted latents and compute the inversion warping error. We then reconstruct an inverted latent and its warped version to test the generation warping error. Cross-Frame attention (CFA) is enabled in both inversion and generation. The input warping error is computed as a reference.",
                "position": 636
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x8.png",
                "caption": "Figure 8:Qualitative comparison of video editing consistency between SD and AF-SD using warping-equivariant video editing. Texture flickering can be observed in SD’s results. More results are available in the supplementary.",
                "position": 642
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x9.png",
                "caption": "Figure 9:Qualitative comparison of shift-equivairance in latent I2SB4×4\\times4 ×super-resolution results.",
                "position": 687
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x10.png",
                "caption": "Figure 10:Qualitative comparison of shift-equivariance in YOSO normal estimation. The contrast of local regions is enhanced. Please refer to the supplementary for a clearer video comparison.",
                "position": 696
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AImplementation Details",
        "images": []
    },
    {
        "header": "BDetails of Video Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x11.png",
                "caption": "Figure 11:Visualization of warping-equivariant video editing.",
                "position": 1862
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x12.png",
                "caption": "Figure 12:Visualization of image interpolation. It is recommended\nto view it on the project page.",
                "position": 1865
            }
        ]
    },
    {
        "header": "CComparison to State-of-the-art Zero-shot Video Editing Methods",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x13.png",
                "caption": "Figure 13:Comparison on video editing. Prompt: “a wolf”→→\\rightarrow→“A Husty”.",
                "position": 1877
            }
        ]
    },
    {
        "header": "DLimitation",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09419/x14.png",
                "caption": "Figure 14:Quantitative comparison of SD VAE and AF-VAE in latent shifting experiments. Shift offsets are 1, 19, 37, 55, 74, and 92 pixels.",
                "position": 1921
            },
            {
                "img": "https://arxiv.org/html/2503.09419/x15.png",
                "caption": "Figure 15:Quantitative comparison of FFHQ unconditional LDM and AF-LDM in noisy latent shifting experiments. Latents are obtained from DDIM inversion. Shift offsets are 1, 19, 37, 55, 74, and 92 pixels.",
                "position": 1924
            }
        ]
    },
    {
        "header": "EMore Qualitative Results",
        "images": []
    }
]