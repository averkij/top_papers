[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03448/x1.png",
                "caption": "Figure 1:L2Tvs. standard CLM over raw text.",
                "position": 191
            }
        ]
    },
    {
        "header": "2L2T: Language Learning Tasks",
        "images": []
    },
    {
        "header": "3Experimental Setup",
        "images": []
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03448/x2.png",
                "caption": "Figure 2:Accuracy by linguistic subfield in BLiMP between Raw and L2T across model sizes and training steps using Disjoint Raw and L2T data.",
                "position": 854
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Work",
        "images": []
    },
    {
        "header": "Appendix BDetails on L2T: Language Learning Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03448/x3.png",
                "caption": "Figure 3:Overview of the 14 language learning tasks.\nColors denote linguistic granularity: character (blue), word (green), sentence (orange), and discourse (purple).",
                "position": 2176
            }
        ]
    },
    {
        "header": "Appendix CExtended Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03448/x4.png",
                "caption": "Figure 4:Linguistic competence comparisons on BLiMP between different L2T models trained on specific 25B token single task data.",
                "position": 3076
            },
            {
                "img": "https://arxiv.org/html/2601.03448/x5.png",
                "caption": "Figure 5:Linguistic competence comparisons on BLiMP between different L2T models trained on specific 25B token single task data.",
                "position": 3081
            },
            {
                "img": "https://arxiv.org/html/2601.03448/x6.png",
                "caption": "Figure 6:General benchmark performance comparison between different L2T models trained on specific 25B token single task data.",
                "position": 3086
            }
        ]
    },
    {
        "header": "Appendix DEffectiveness of Individual Tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.03448/x7.png",
                "caption": "Figure 7:Performance on general benchmarks for 500M models pre-trained with different mixing ratios of standard Raw vs. L2T data for 100B tokens. L2T 100% stands for no standard raw text mixed, i.e. 100% L2T data.",
                "position": 3114
            },
            {
                "img": "https://arxiv.org/html/2601.03448/x8.png",
                "caption": "Figure 8:Linguistic competence comparisons by linguistic subfield on BLiMP between Raw and L2T 500M models with different mixing ratios of standard raw text.\n100% stands for no standard raw text mixed.",
                "position": 3119
            }
        ]
    },
    {
        "header": "Appendix EMixing Ratio of Raw and L2T Data",
        "images": []
    },
    {
        "header": "Appendix FQualitative Analysis",
        "images": []
    },
    {
        "header": "Appendix GLicense",
        "images": []
    },
    {
        "header": "Appendix HUse of Generative AI Tools",
        "images": []
    }
]