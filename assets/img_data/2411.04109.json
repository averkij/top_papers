[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Self-consistency Preference Optimization",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04109/x1.png",
                "caption": "Figure 1:Self-consistency Preference Optimization(ScPO).\nGiven a query, we sample multiple responses from the current model‚Ñ≥tsubscript‚Ñ≥ùë°\\mathcal{M}_{t}caligraphic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTand count the frequency of each answer (i.e., votes).\nWe select the highest and lowest votes as chosen and rejected responses (middle), and use these preference pairs to train the model with weighted‚ÑíScPOsubscript‚ÑíScPO\\mathcal{L}_{\\textsc{ScPO}{}}caligraphic_L start_POSTSUBSCRIPT ScPO end_POSTSUBSCRIPTloss (right).\nWe employ a similar pipeline for generating new queries from the model itself (left), filtering out data where self-consistency is low.",
                "position": 192
            }
        ]
    },
    {
        "header": "3Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04109/x2.png",
                "caption": "Table 1:GSM8K zero-shot accuracy after training Llama-3 Base 8B withScPOand baselines, using greedy or self-consistency (SC)-based inference. The best performance is inbold, and second-best isunderlined. We list train set sizes for each method:\n‚ÄúSeed‚Äù corresponds to seed problems in the train set, whereas ‚ÄúGen.‚Äù indicates additional problems generated by the model (without answers).\nIRPOGold, andScPOSemi‚Å¢-‚Å¢Sup.Semi-Sup{}_{\\mathrm{Semi\\text{-}Sup.}}start_FLOATSUBSCRIPT roman_Semi - roman_Sup . end_FLOATSUBSCRIPT, highlighted ingreen, use the gold answers to create preference pairs (when available, indicated with‚Ä†).",
                "position": 366
            }
        ]
    },
    {
        "header": "4Main Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04109/x2.png",
                "caption": "Table 2:MATH zero-shot accuracy after training Llama-3 Base 8B withScPOand baselines, using greedy or self-consistency (SC)-based inference. Train data size: ‚ÄúSeed‚Äù corresponds to seed queries in the train set, ‚ÄúGen.‚Äù are additional model-generated problems (without answers). IRPOGoldandScPOSemi‚Å¢-‚Å¢Sup.Semi-Sup{}_{\\mathrm{Semi\\text{-}Sup.}}start_FLOATSUBSCRIPT roman_Semi - roman_Sup . end_FLOATSUBSCRIPT, highlighted ingreen, use gold answers to train (indicated with‚Ä†).",
                "position": 419
            }
        ]
    },
    {
        "header": "5Ablations and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.04109/x2.png",
                "caption": "Figure 2:Vote share (%) of the most consistent response:ùí±‚Å¢(y+)/kùí±superscriptùë¶ùëò\\mathcal{V}(y^{+})/kcaligraphic_V ( italic_y start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) / italic_kincreases with iterations across all datasets.",
                "position": 692
            },
            {
                "img": "https://arxiv.org/html/2411.04109/x3.png",
                "caption": "Figure 3:Comparing the quality of metrics: self-consistency (SC) and ArmoRM to distinguish between correct and incorrect responses.",
                "position": 758
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelationship between Consistency and Accuracy",
        "images": []
    },
    {
        "header": "Appendix BTransduction During Inference",
        "images": []
    },
    {
        "header": "Appendix CPrompts",
        "images": []
    }
]