[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03800/new_fig2.png",
                "caption": "Figure 1:We visualize gradient activation maps for both global and local queries on global model (CT-CLIP) and local model (fVLM). Each row shows model attention for either a local (top) or global (bottom) query, with ground truth (GT) segmentations color-coded by sentence. The global model fails to detect tumor given a local query. The local model does not capture relevant anatomical regions given a global query. Our model effectively attends to relevant regions in both cases, demonstrating superior multi-scale understanding.",
                "position": 106
            },
            {
                "img": "https://arxiv.org/html/2509.03800/new_fig1.png",
                "caption": "Figure 2:Left:Global zero-shot performance of MedVista3D-ViT on CT-RATE.AUC scores are reported per disease, reflecting the modelâ€™s generalization across diverse pathologies.Right:LLM-based refinement of radiology reports.To address ambiguity and inconsistency in uncurated CT-RATE reports, we apply large language models (e.g., GPT-4o, Qwen2.5) to rewrite them with improved clarity and clinical coherence.",
                "position": 109
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03800/new_fig4.png",
                "caption": "Figure 3:a). MedVista3D encodes 3D CT volumes at both global and local scales. For local alignment, visual organ embeddings are paired with organ and semantic-enriched phrases. For global alignment, global volume embedding is matched with the report embedding and its semantic-enriched versions augmented by LLMs. b). A radiology semantic matching bank maintains a queue of text embeddings from diverse radiology descriptions. For each query, a top-k similarity search retrieves semantically matching texts, filtering out less relevant ones.",
                "position": 163
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03800/new_fig5.png",
                "caption": "Figure 4:Impact of region masking on attention for CLIP, fVLM and MedVista3D (on CT-RATE). We visualize the attention maps of [CLS] token with other patch tokens given CT volume with (top) and without (bottom) region mask. MedVista3D remains focused on important organs regardless of masking. With mask CLIP shows diffuse attention; fVLM struggles without the mask.",
                "position": 810
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    },
    {
        "header": "Appendix ABroader Impact",
        "images": []
    },
    {
        "header": "Appendix BImplementation details",
        "images": []
    },
    {
        "header": "Appendix CGlobal vs Local Alignment",
        "images": []
    },
    {
        "header": "Appendix DPrompting LLMs for improving disease semantics",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.03800/prompt.png",
                "caption": "Figure 5:Prompts for report-level rewrites to emphasize disease presences.",
                "position": 2642
            },
            {
                "img": "https://arxiv.org/html/2509.03800/prompt2.png",
                "caption": "Figure 6:Prompts for region-level rewrite with few-shot prompting.",
                "position": 2645
            }
        ]
    },
    {
        "header": "Appendix ETraining algorithm",
        "images": []
    }
]