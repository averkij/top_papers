[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19865/x1.png",
                "caption": "Figure 1:Comparison between symbolic knowledge distillation (SKD) and our method. (1) the teacher model generates multiple reasoning chains for a given question, (2) SKD supervised fine-tunes on the correct reasoning chains, and (3) our method incorporates bidirectional reasoning, learning from both Q-to-A and A-to-Q using our multi-task objectives.",
                "position": 113
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19865/x2.png",
                "caption": "Figure 2:RevThinkconsists of two stages: (1) Data augmentation and (2) Student model learning. First, given a dataset𝒟={(Q(i),A(i))}i=1n𝒟superscriptsubscriptsuperscript𝑄𝑖superscript𝐴𝑖𝑖1𝑛\\mathcal{D}=\\{(Q^{(i)},A^{(i)})\\}_{i=1}^{n}caligraphic_D = { ( italic_Q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we augment it by prompting the teacher model to generate forward reasoning, backward question, and backward reasoning. We keep instances only with correct forward reasoning (validated by the ground truth) and consistent forward-backward reasoning (validated by the teacher model). This yields an augmented dataset𝒟aug=(Q(i),Rf(i),Qb(i),Rb(i))i=1nsubscript𝒟augsuperscriptsubscriptsuperscript𝑄𝑖subscriptsuperscript𝑅𝑖𝑓subscriptsuperscript𝑄𝑖𝑏subscriptsuperscript𝑅𝑖𝑏𝑖1𝑛\\mathcal{D}_{\\text{aug}}=(Q^{(i)},R^{(i)}_{f},Q^{(i)}_{b},R^{(i)}_{b})_{i=1}^{n}caligraphic_D start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT = ( italic_Q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , italic_R start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT , italic_Q start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT , italic_R start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Next, we train the student model with three objectives:Q→Rf→𝑄subscript𝑅𝑓Q\\rightarrow R_{f}italic_Q → italic_R start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT,Q→Qb→𝑄subscript𝑄𝑏Q\\rightarrow Q_{b}italic_Q → italic_Q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPTandQb→Rb→subscript𝑄𝑏subscript𝑅𝑏Q_{b}\\rightarrow R_{b}italic_Q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT → italic_R start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT, enabling the student to reason in both directions during training. At test time, the student model performs only forward reasoning, making test-time compute as efficient as zero-shot prompting.",
                "position": 171
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experimental Setup",
        "images": []
    },
    {
        "header": "5Results and Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.19865/x3.png",
                "caption": "Figure 3:Comparison ofRevThinkand the SFT baseline with different sample sizes. Notably,RevThinkshows sample efficiency by largely outperforming SFT given any portion of the training data. Furthermore, our method with only 10% of training data outperforms SFT with the full training data on StrategyQA.",
                "position": 525
            },
            {
                "img": "https://arxiv.org/html/2411.19865/x4.png",
                "caption": "Figure 4:Comparison of different learning sources and the combination of input/output. We denoteX→Y→𝑋𝑌X\\rightarrow Yitalic_X → italic_Yas “givenX𝑋Xitalic_Xas the input to generateY𝑌Yitalic_Y”. Also, we use&\\&&to denote simultaneous learning from different combinations.RevThink’s learning to generate forward questions, backward questions and backward reasoning is the most effective, while only learning from generating backward reasoning is the least effective.",
                "position": 532
            },
            {
                "img": "https://arxiv.org/html/2411.19865/x5.png",
                "caption": "Figure 5:The average token counts per sampleused in trainingversus thetest-timeaccuracy. The dashed line shows the regression over the baselines. Our method outperforms the baselines with only a slight increase in token count. Note thatRevThinkgenerates a comparable number of tokens across all baselines at test time.",
                "position": 576
            },
            {
                "img": "https://arxiv.org/html/2411.19865/x6.png",
                "caption": "Figure 6:RevThinkscales effectively with student model size. Notably, Mistral-7B +RevThinkoutperforms Mistral-8x22B (the red dashed line) by 8.36%.",
                "position": 583
            },
            {
                "img": "https://arxiv.org/html/2411.19865/x7.png",
                "caption": "Figure 7:The break down analysis of the MATH dataset. Each grouped bar shows our results on the left and the SKD baseline on the right.",
                "position": 677
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Limitations",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Analysis",
        "images": []
    },
    {
        "header": "Appendix BPrompt for Backward Question Generation",
        "images": []
    },
    {
        "header": "Appendix CPrompt for Verification",
        "images": []
    },
    {
        "header": "Appendix DExamples of the Augmented Data",
        "images": []
    },
    {
        "header": "Appendix EDataset Statistics",
        "images": []
    }
]