[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Analyzing Token Embedding Geometry",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13672/x1.png",
                "caption": "(a)Norm inflation",
                "position": 158
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x1.png",
                "caption": "(a)Norm inflation",
                "position": 161
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x2.png",
                "caption": "(b)Semantic drift",
                "position": 166
            },
            {
                "img": "https://arxiv.org/html/2512.13672/figs/emp_val.png",
                "caption": "Figure 2:Position prediction accuracy fromLN\\mathrm{LN}outputs under varying embedding magnitudes, compared with trained TI and DTI embeddings.",
                "position": 294
            }
        ]
    },
    {
        "header": "3Method: Directional Textual Inversion",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13672/x3.png",
                "caption": "Figure 3:We compare DTI with previous methods across diverse subjects and textual prompts, spanning simple descriptions to complex variations in attributes, backgrounds, and styles (same random seeds). All results in this figure are generated with SDXL (SANA in Appendix Figure9).",
                "position": 630
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x4.png",
                "caption": "Figure 4:We compare images generated by a TI and our DTI. Two personalized subjects are interpolated, including interpolation between inanimate and animate subjects, live subjects, and human faces. Images are generated with interpolation ratio[0.0,0.35,0.40,0.45,0.50,0.55,0.60,0.65,1.0][0.0,0.35,0.40,0.45,0.50,0.55,0.60,0.65,1.0]for better visualization. Our DTI offers smooth interpolation between concepts, expanding the personalization in more creative axis.",
                "position": 693
            }
        ]
    },
    {
        "header": "5Related Work",
        "images": []
    },
    {
        "header": "6Discussion & Conclusion",
        "images": []
    },
    {
        "header": "Reproducibility Statement",
        "images": []
    },
    {
        "header": "LLM Usage Statement",
        "images": []
    },
    {
        "header": "Appendix AEmbedding norm and direction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13672/x5.png",
                "caption": "Figure 5:Effect of magnitude change.We set the magnitude to a fixed value to analyze the impact of magnitude changes. The resulting outputs show no noticeable difference.",
                "position": 782
            }
        ]
    },
    {
        "header": "Appendix BProofs for theoretical statements",
        "images": []
    },
    {
        "header": "Appendix CExtended Methods",
        "images": []
    },
    {
        "header": "Appendix DExtended Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13672/x6.png",
                "caption": "Figure 6:Qualitative results with DCO(lee_direct_2024).We provide the comparison of the output images of DCO + TI and DCO + DTI. The results suggest our DTI’s superiority in text fidelity while preserving strong image similarity.",
                "position": 1250
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x7.png",
                "caption": "Figure 7:User Study Design.We conducted a user study with 100 participants recruited via Amazon Mechanical Turk to evaluate 20 questions. The evaluation focused on two key aspects: subject similarity (10 questions) and text prompt fidelity (10 questions). To ensure fair comparison, the random seed was fixed and option order was shuffled.",
                "position": 1346
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x8.png",
                "caption": "Figure 8:Qualitative results with SDXL.Here, we provide more qualitative comparison with TI and CrossInit. Our DTI consistently generates results that precisely reflect the user text prompts, maintaining the subject similarity at the same time.",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x9.png",
                "caption": "Figure 9:Qualitative results with SANA1.5-1.6B.Here, we provide more qualitative comparison with TI and CrossInit on SANA. Our DTI consistently generates results that precisely reflect the user text prompts, maintaining the subject similarity at the same time.",
                "position": 1368
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x10.png",
                "caption": "Figure 10:Comparison with additional baselines.We provide qualitative comparisons against additional TI-enhancing methods—P+, NeTI, and CoRe. Because these baselines are built on SD2.1-base, we apply DTI using the same pre-trained backbone to ensure fairness. The results demonstrate that DTI attains higher text fidelity while maintaining subject similarity.",
                "position": 1371
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x11.png",
                "caption": "Figure 11:Qualitative results with TI/DTI with LoRA on SDXL.We have performed qualitative comparison of applying TI and DTI on model fine-tuning methods using LoRA (rank 32). DTI consistently improves the text prompt fidelity compared to TI.",
                "position": 1374
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x12.png",
                "caption": "Figure 12:Stylization.Qualitative comparison of personalization with diverse style inputs.",
                "position": 1381
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x12.png",
                "caption": "Figure 12:Stylization.Qualitative comparison of personalization with diverse style inputs.",
                "position": 1384
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x13.png",
                "caption": "Figure 13:My subject in my style.Qualitative comparison of subject-style mixing within the same prompt.",
                "position": 1389
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x14.png",
                "caption": "Figure 14:Comparison of face personalization methods.We compare our method and Textual Inversion (TI) against CrossInit, which specifically targets face personalization. To prevent bias from celebrity faces, we evaluate personalization using two alternative sources: images generated by DALL⋅\\cdotE(ramesh_zero-shot_2021)(top row) and randomly selected images from the FFHQ(karras2019style)(bottom row).",
                "position": 1412
            }
        ]
    },
    {
        "header": "Appendix EAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.13672/x15.png",
                "caption": "Figure 15:Interpolation options for TI.We compare several interpolation options for TI, including linear interpolation, SLERP with normalization and adjusted norms. While these approaches exhibit minor differences in behavior, none produce smooth transitions between concepts. In contrast, our DTI with SLERP achieves noticeably smoother and more consistent interpolations.",
                "position": 1423
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x16.png",
                "caption": "Figure 16:Ablation on magnitude settings.For consistency and ease of use, all magnitudes in this paper are set to the average value computed over the model’s vocabulary (see ablation in Table 3). To evaluate the effect of using concept-specific magnitudes (e.g., the magnitude of ‘cat’ for the concept ¡cat¿), we provide ablation results under different magnitude settings. The results show that small deviations from the default magnitude do not lead to noticeable differences in output quality.",
                "position": 1426
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x17.png",
                "caption": "Figure 17:Multi-concept experiments.We further evaluate DTI by combining multiple learned concepts within a single prompt. The results demonstrate that DTI can successfully integrate multiple concepts, while the second column shows failure cases exhibiting attribute binding issues.",
                "position": 1429
            },
            {
                "img": "https://arxiv.org/html/2512.13672/x18.png",
                "caption": "Figure 18:Failure cases.We present examples of three representative failure modes: (1) subjects that require high visual detail, (2) prompts that are vague or difficult to faithfully depict, and (3) prompts that involve attribute modification (e.g., color changes).",
                "position": 1432
            }
        ]
    },
    {
        "header": "Appendix FSocietal impacts",
        "images": []
    }
]