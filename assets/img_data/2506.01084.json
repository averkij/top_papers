[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/tobe_or_not_tobe_pipeline.png",
                "caption": "Figure 1:Overview of thezip2zipinference pipeline.At each decoding step, the model has a growingcontextcomposed of bothbase tokens(blue) andhypertokens(green). Thestatic vocabularyof size 6 remains fixed, while thedynamic vocabularyis continuously expanded by merging co-occurring tokens usingLZW compression. Thecodebook(right) maps hypertoken IDs to their corresponding base tokens. As decoding progresses, new hypertokens created at steptùë°titalic_t(e.g., ‚Äúto be‚Äù, ‚Äúor not‚Äù) becomeimmediatelyavailable for reuse at stept+limit-fromùë°t{+}italic_t +. Additionally, output tokens, once generated,instantlybecome eligible for compression. Hypertokens are also eligible for merging, enabling the formation ofnested hypertokens. The final output sequence (bottom) is reconstructed via LZW decompression.",
                "position": 125
            }
        ]
    },
    {
        "header": "2zip2zip",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/zip2zip_architecture_v3.png",
                "caption": "Figure 2:zip2ziparchitecture.At inference time, base tokens are compressed into hypertokens using LZW (Steps 1‚Äì2). A hyper-encoder computes embeddings for hypertokens (Step 3‚Äì4), which are processed by the base LLM (Steps 5‚Äì6). Output representations are projected jointly on base and hyper-projection layers (Step 7), producing joint logits and sampled tokens (Steps 8‚Äì10), which can be decoded back to base tokens (Steps 11‚Äì12).",
                "position": 179
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/illustrative_example_new.png",
                "caption": "Figure 3:Zip2Zip output examples.Blue: base tokens;Yellow: hypertokens (composed of 2 base tokens);Orange: hypertokens (composed of 3+ base tokens).",
                "position": 295
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/sections/07_evaluation/tokenizer_performance_comparison.png",
                "caption": "Figure 4:zip2ziptokenizer latency (ms) vs.¬†HF tokenizer.",
                "position": 863
            }
        ]
    },
    {
        "header": "4Related Work",
        "images": []
    },
    {
        "header": "5Discussion and Limitations",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAblation Studies",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/ablation_merge_size.png",
                "caption": "Figure 5:Effect of maximum merge sizeMùëÄMitalic_Mon zip2zip training loss:M=1ùëÄ1M=1italic_M = 1(no compression) achieves the lowest loss overall. Among compressed settings,M=3ùëÄ3M=3italic_M = 3performs best, whileM=2ùëÄ2M=2italic_M = 2shows the worst convergence. LargerMùëÄMitalic_M(4 and 5) yield slightly worse results thanM=3ùëÄ3M=3italic_M = 3.",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/ablation_layer.png",
                "caption": "Figure 6:Effect of hyper-encoder architecture on zip2zip training loss.Averaging (no additional parameters) converges quickly but to a higher loss. As architectural complexity increases‚Äîfrom attention to transformer layers‚Äîconvergence becomes slower, but the final loss is lower. This highlights a trade-off between training speed and modeling capacity.",
                "position": 1920
            }
        ]
    },
    {
        "header": "Appendix BFLOPs Estimation forzip2zip",
        "images": []
    },
    {
        "header": "Appendix CAdditional Results",
        "images": []
    },
    {
        "header": "Appendix DTechnical Details",
        "images": []
    },
    {
        "header": "Appendix EData Mixture",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/data_mixture_of_zip2zip_1B_dataset.png",
                "caption": "Figure 7:Left: Proportional breakdown of the fine-tuning dataset across five domains. Right: Cumulative distribution of input sequence lengths per domain (log scale). Code and multilingual data exhibit longer tail distributions, indicating greater variability in sequence lengths.",
                "position": 2376
            }
        ]
    },
    {
        "header": "Appendix FToken Stream Visualization",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/attention-code-default.png",
                "caption": "(a)Default Tokenization of some Python code.",
                "position": 2383
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/attention-code-default.png",
                "caption": "(a)Default Tokenization of some Python code.",
                "position": 2386
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/attention-code-zip2zip.png",
                "caption": "(b)The same code with adaptive tokenization.",
                "position": 2391
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/mRNA-default.png",
                "caption": "(c)Default Tokenization of some biomedical text.",
                "position": 2397
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/mRNA-zip2zip.png",
                "caption": "(d)The same text with adaptive tokenization.",
                "position": 2402
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/french-default.png",
                "caption": "(e)Default Tokenization of text in French.",
                "position": 2408
            },
            {
                "img": "https://arxiv.org/html/2506.01084/extracted/6502042/figure/token_stream/french-zip2zip.png",
                "caption": "(f)The same text with adaptive tokenization.",
                "position": 2413
            }
        ]
    },
    {
        "header": "NeurIPS Paper Checklist",
        "images": []
    }
]