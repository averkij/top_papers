[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/figures/1_intro/scatter.png",
                "caption": "Figure 1:Parameterâ€“performance scaling of base and instruct models on agentic benchmarks.\nThe trend line represents the desired agent performance with the smallest possible number of parameters, among which Youtu-LLM stands out as a lightweight yet strong performer.",
                "position": 254
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x1.png",
                "caption": "Figure 2:Multi-field general capability comparison of similarly sized models. Youtu-LLM shows a balanced and competitive profile, highlighting its general-purpose performance potential under limited parameter budgets.",
                "position": 261
            }
        ]
    },
    {
        "header": "2Pre-Training Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x2.png",
                "caption": "Figure 3:Above: Vanilla long CoT enables thorough response preparation, while it can also tend to overthinking and unnecessary repetition. Below: Our agentic thinking paradigm implements a defined reasoning architecture that guides models through sequential steps of analysis, plan, action, reflection and summary. This disciplined process fosters the development of agentic capabilities.",
                "position": 365
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x3.png",
                "caption": "Figure 4:The illustration of the designed math agent framework for math trajectory construction.",
                "position": 726
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x4.png",
                "caption": "Figure 5:The Synthesis pipeline of Code Trajectories.",
                "position": 799
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x5.png",
                "caption": "(a)Successful Trajectories.",
                "position": 816
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x5.png",
                "caption": "(a)Successful Trajectories.",
                "position": 819
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x6.png",
                "caption": "(b)Failed Trajectories.",
                "position": 824
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x7.png",
                "caption": "Figure 7:The trajectory synthesis pipeline of the closed-ended DR.",
                "position": 876
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x8.png",
                "caption": "Figure 8:The trajectory synthesis pipeline of the open-ended DR report generation.",
                "position": 897
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x9.png",
                "caption": "Figure 9:The inverse trajectory synthesis pipeline of the open-ended DR.",
                "position": 928
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x10.png",
                "caption": "Figure 10:Our trajectory construction strategy for synthesizing tool-use and planning data.",
                "position": 1006
            }
        ]
    },
    {
        "header": "3Pre-training of Youtu-LLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x11.png",
                "caption": "Figure 11:The pre-training recipe for Youtu-LLM. At the top, we illustrate the variations in the data recipe from Stage 1 to Stage 4, and it can be clearly observed that the average quality of the data gradually improves as the stages move forward. At the bottom, we draw the learning rate scheduler aligned with the data recipe.",
                "position": 1221
            }
        ]
    },
    {
        "header": "4Post-training of Youtu-LLM",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x12.png",
                "caption": "Figure 12:Overview of our data engineering workflow for high-quality Supervised Fine-Tuning.",
                "position": 1250
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x13.png",
                "caption": "Figure 13:Training Dynamics with BF16/FP16 precision and consistent sampling. The reported accuracy metrics are derived from internal mathematical and coding benchmarks.",
                "position": 1406
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x14.png",
                "caption": "Figure 14:The impact of training data scaling on APTBench performance.",
                "position": 2424
            },
            {
                "img": "https://arxiv.org/html/2512.24618/figures/4_posttrain/pass_at_k_comparison.png",
                "caption": "Figure 15:Pass@k comparison on SWE-Bench-Verified with Openhands scaffold across different models (with 95% confidence intervals smeared).",
                "position": 2511
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AContributions and Acknowledgments",
        "images": []
    },
    {
        "header": "Appendix BThe Impact of Agentic-CoT Trajectory Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x15.png",
                "caption": "Figure 16:Ablation experimental results of agentic-CoT trajectory data on APT-Math.",
                "position": 3861
            }
        ]
    },
    {
        "header": "Appendix CThe Impact of Math Trajectory Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x16.png",
                "caption": "Figure 17:Ablation experimental results for different mask training strategies of math trajectories.",
                "position": 3893
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x17.png",
                "caption": "Figure 18:Ablation experiments results of mathematical trajectory training at different up-sampling rates.",
                "position": 3901
            }
        ]
    },
    {
        "header": "Appendix DThe Impact of Deep Research Trajectory Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x18.png",
                "caption": "Figure 19:Ablation experimental results for different mask training strategies of deep research.",
                "position": 3948
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x19.png",
                "caption": "Figure 20:Ablation experimental results of deep research trajectory data on APT-DR.",
                "position": 3973
            }
        ]
    },
    {
        "header": "Appendix EThe Impact of Code Trajectory Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/figures/appendix/EnvSetup_8k.png",
                "caption": "Figure 21:Ablation experimental results for different mask training strategies code trajectory data (EnvSetup).",
                "position": 3990
            },
            {
                "img": "https://arxiv.org/html/2512.24618/figures/appendix/IssueFix_8k.png",
                "caption": "Figure 22:Ablation experimental results for different mask training strategies of code trajectory data (IssueFix).",
                "position": 3993
            },
            {
                "img": "https://arxiv.org/html/2512.24618/figures/appendix/EnvSetup.png",
                "caption": "Figure 23:Ablation experimental results of code trajectory data on APT-Code-EnvSetup.",
                "position": 4005
            },
            {
                "img": "https://arxiv.org/html/2512.24618/figures/appendix/IssueFix.png",
                "caption": "Figure 24:Ablation experimental results of code trajectory data on APT-Code-IssueFix.",
                "position": 4008
            }
        ]
    },
    {
        "header": "Appendix FThe Impact of Tool-use Trajectory Data",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24618/x20.png",
                "caption": "Figure 25:Ablation experimental results of tool-use trajectory data, concerning masking and up-sampling strategy. The metrics reported are the sub-scores of four evaluation dimensions in APTBench, as well as the overall average score.",
                "position": 4039
            },
            {
                "img": "https://arxiv.org/html/2512.24618/x21.png",
                "caption": "Figure 26:Ablation experimental results of mini SFT over less-agentic and agentic base models.",
                "position": 4049
            }
        ]
    },
    {
        "header": "Appendix GCase Study",
        "images": []
    }
]