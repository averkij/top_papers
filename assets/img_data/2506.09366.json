[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x1.png",
                "caption": "Figure 1:SkillBlenderperformsversatileautonomous humanoid loco-manipulation tasks within different embodiments and environments, givenonly one or twointuitive reward terms.",
                "position": 128
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x2.png",
                "caption": "Figure 2:Overview ofSkillBlender. We first pretrain goal-conditioned primitive expert skills that are task-agnostic, reusable, and physically interpretable, and then reuse and blend these skills to achieve complex whole-body loco-manipulation tasks givenonly one or twotask-specific reward terms.",
                "position": 198
            }
        ]
    },
    {
        "header": "3SkillBlender",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x3.png",
                "caption": "Figure 3:OurSkillBenchis a parallel, cross-embodiment, and diverse simulated benchmark containing three embodiments, four primitive skills, and eight loco-manipulation tasks.",
                "position": 315
            }
        ]
    },
    {
        "header": "4SkillBench",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x4.png",
                "caption": "Figure 4:Qualitative comparison between different methods. OurSkillBlendernot only achieves higher task accuracy, but also avoids reward hacking and yields more natural and feasible movements.",
                "position": 971
            }
        ]
    },
    {
        "header": "6Conclusions, Limitations, and Future Works",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AObservation Space",
        "images": []
    },
    {
        "header": "Appendix BAction Space",
        "images": []
    },
    {
        "header": "Appendix CLow-Level Primitive Skill Specifications",
        "images": []
    },
    {
        "header": "Appendix DHigh-Level Loco-Manipulation Task Specifications",
        "images": []
    },
    {
        "header": "Appendix EImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x5.png",
                "caption": "Figure 5:An example of GPT-4o reasoning to perform skill selection on theFarReachtask.",
                "position": 2234
            }
        ]
    },
    {
        "header": "Appendix FMorphology Details",
        "images": []
    },
    {
        "header": "Appendix GAdditional Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x6.png",
                "caption": "Figure 6:Qualitative results on G1 and H1-2 embodiments. Our method produces more accurate and natural movements, validating our frameworkâ€™s superiority across multiple embodiments.",
                "position": 2841
            },
            {
                "img": "https://arxiv.org/html/2506.09366/x7.png",
                "caption": "Figure 7:Visualization of whole-body per-joint weights at different stages of three different tasks. More blue means moreReaching, and more green means moreWalking.",
                "position": 2849
            },
            {
                "img": "https://arxiv.org/html/2506.09366/x8.png",
                "caption": "Figure 8:Ego-centric visual observations, including RGB, depth (point cloud), and segmentation masks.",
                "position": 2863
            }
        ]
    },
    {
        "header": "Appendix HReal-World Skill Deployment",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.09366/x9.png",
                "caption": "Figure 9:Demonstrations of our primitive skill sim2real deployment. We control the humanoid to perform periodicalReachingandSquatting.",
                "position": 2916
            }
        ]
    },
    {
        "header": "Appendix ICommon Failure Cases",
        "images": []
    },
    {
        "header": "Appendix JBroader Impacts",
        "images": []
    }
]