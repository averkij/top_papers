[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x1.png",
                "caption": "Figure 1:The Remote Labor Index (RLI) represents a broad range of projects from across the remote labor economy, including game development, product design, architecture, and data analysis. All projects represent real work that was performed by human professionals.",
                "position": 246
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x2.png",
                "caption": "Figure 2:All AI agents tested automate at most2.5%2.5\\%of tasks on RLI, showing that most economically valuable remote work currently remains far beyond their capabilities.",
                "position": 264
            }
        ]
    },
    {
        "header": "3Remote Labor Index",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x3.png",
                "caption": "Figure 3:RLI captures a wide array of project types, spanning2323categories of work from the Upwork taxonomy. Here, we show the top seven categories.",
                "position": 323
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x4.png",
                "caption": "Figure 4:RLI spans a broad range of difficulty, with project costs reaching over$​10,000\\mathdollar 10,\\!000and completion times for human professionals reaching over100100hours. All project costs and completion times come directly from human professionals who completed the projects. In total, the projects in RLI represent over6,0006,\\!000hours of real work valued at over$​140,000\\mathdollar 140,\\!000.",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x5.png",
                "caption": "Figure 5:RLI projects were extensively filtered and cleaned to ensure quality. Projects were sourced primarily from the remote labor market and secondarily from deliverables representing uncommon and emerging types of remote work work. (For details, see AppendixC.)",
                "position": 386
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x6.png",
                "caption": "Figure 6:RLI is far closer to the complexity and diversity of real freelance labor than previous comparable benchmarks. Left: The average completion time for humans on RLI projects matches the true Upwork distribution. Right: Previous benchmarks primarily focus on tasks involving software engineering or web-based research and writing, but real remote labor markets have far more diversity.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x7.png",
                "caption": "Figure 7:Evaluation Pipeline: For each RLI project, AI deliverables are rigorously checked against human gold-standard deliverables and the requirements in the project brief for flaws and to determine whether the AI deliverable would be accepted as work product in a realistic freelance setting. Evaluating AI deliverables is itself a highly agentic task, so automating evaluation with LLMs is not currently feasible. Thus, all evaluations are performed manually by trained workers and subject experts. Inter-annotator agreement is above94%94\\%.",
                "position": 459
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x8.png",
                "caption": "Figure 8:Relative performance (Elo) scores show that AI agents are making steady progress on RLI and there are meaningful differences between models, despite all models falling short of the human baseline of1,0001,\\!000. Compared to the automation rate metric, Elo score provides a better measure of partial progress across all projects, including projects that are not solved yet.",
                "position": 588
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x9.png",
                "caption": "Figure 9:Here we show a successful project completion from Sonnet 4.5. Simple web visualizations that only require writing code are well within the capabilities of current AI agents, but this work makes up a small slice of all remote labor. Additional examples of successes and failures are shown inFigures˜16and17.",
                "position": 701
            }
        ]
    },
    {
        "header": "5Discussion",
        "images": []
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x10.png",
                "caption": "Figure 10:Autoflation on RLI: the percentage decrease in the cost of completing the fixed RLI project bundle, using AI agents to complete projects if they successfully complete them at lower cost than humans. As AI systems achieve the same deliverables at lower effective cost, the price of this work declines.",
                "position": 1341
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.26787/x11.png",
                "caption": "Figure 11:Each evaluator was given a soft maximum of2020minutes for model vs human evaluations and3030minutes for model vs model evaluations (the latter requires inspecting more files and takes more time). In preliminary testing, we found this duration was adequate for nearly all projects. Total evaluation time per project is higher, as22to33evaluations were performed to obtain a majority vote.",
                "position": 1402
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x12.png",
                "caption": "Figure 12:The average cost of generating AI deliverables was$​2.34\\mathdollar 2.34. In all cases, models stopped generating before exceeding$​30\\mathdollar 30of API costs.",
                "position": 1569
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x13.png",
                "caption": "Figure 13:Evaluation platform view with the ring 3D model project example.",
                "position": 1732
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x14.png",
                "caption": "Figure 14:RLI projects involve significantly more diverse file types than previous comparable benchmarks. Left: Average number of files per project for inputs and human deliverables across benchmarks. Right: Total unique file types found in inputs and human deliverables across benchmarks.",
                "position": 1740
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x15.png",
                "caption": "Figure 15:Project cost and completion time are highly correlated on a log-log scale.",
                "position": 2064
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x16.png",
                "caption": "Figure 16:AI agents leverage image generation tools to solve some marketing projects in RLI. Here we show a successful project completion from Manus.",
                "position": 2070
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x17.png",
                "caption": "Figure 17:Agents fail to successfully complete the vast majority of RLI projects. Here we show failed projects for Gemini 2.5 Pro (top) and GPT-5 (bottom).",
                "position": 2073
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x18.png",
                "caption": "Figure 18:Detailed project examples with extended briefs.",
                "position": 2079
            },
            {
                "img": "https://arxiv.org/html/2510.26787/x19.png",
                "caption": "Figure 19:Detailed project examples with extended briefs.",
                "position": 2082
            }
        ]
    },
    {
        "header": "Appendix CDataset Details",
        "images": []
    }
]