[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10825/x1.png",
                "caption": "Fig. 1:Conversational behaviours and Bales’ socio-emotional roles in chain-of-thought reasoning.a, Proportion of reasoning traces containing each conversational behaviour (question answering, perspective shift, conflict of perspectives, and reconciliation).b, Proportion of Bales’ twelve socio-emotional roles expressed in reasoning traces, grouped into four higher-level categories:askversusgiveinformation, andpositiveversusnegativeemotional roles (seeExtended Data Fig. 3for definitions of all twelve roles).c, Jaccard index measuring the balance of each socio-emotional role pair, defined as the number of reasoning traces containing both roles divided by the number containing either role (i.e., ask & give; positive & negative).d, Distribution of the number of distinct perspectives in reasoning traces, identified using an LLM-as-judge.e, Differences in problem complexity by the presence of conversational behaviours and higher-level socio-emotional roles in DeepSeek-R1, measured on a seven-point Likert scale (1 = extremely easy; 7 = extremely difficult) using an LLM-as-judge. Points indicate mean complexity for traces where the behaviour or role is present (red) or absent (blue).f, Differences in problem complexity by the presence of conversational behaviours and socio-emotional roles in DeepSeek-R1, measured by instruction-tuned (non-reasoning) models’ error rates on the same problems (seeMethods: Measurements).\nError bars indicate 95% confidence intervals.",
                "position": 134
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x2.png",
                "caption": "Fig. 2:Steering conversational features improves reasoning.a, Illustration of sparse autoencoder feature 30939 in DeepSeek-R1-Llama-8B, summarized as a discourse marker for surprise, realization, or acknowledgment in conversational settings.Conversation ratioindicates the proportion of conversational contexts among all contexts in which this feature is activated.Percentileindicates where this feature’s conversation ratio ranks among all features (N=32,768N=32{,}768).Sparsityrefers to the fraction of tokens on which this feature activates across the entire corpus.Activation strengthshows the magnitude of activation in the top-activating examples.\nThe examples illustrate this feature’s activation within conversational turn-taking contexts.b, Results of a steering experiment using the activation-addition method.\nAdding the feature 30939 vector with a strength of 10 doubles accuracy on a complex counting task.\nThe inset shows the causal change in conversational behaviours induced by steering this feature.c, Violin plots showing accuracy improvements from steering feature 30939, compared with a randomly selected conversational SAE feature and a randomly selected non-conversational SAE feature.d, Cognitive behaviours—including verification, backtracking, subgoal setting, and backward chaining—are causally associated with steering the activation of feature 30939.e, Structural equation model results showing that steering feature 30939 from 0 to+10+10has both a direct effect on reasoning accuracy and a significant indirect effect mediated through cognitive behaviours (verification, subgoal setting, and backward chaining).\nBold coefficients indicate statistical significance (p<0.05\\emph{p}<0.05).\n***p<0.001\\emph{p}<0.001, **p<0.01\\emph{p}<0.01, *p<0.05\\emph{p}<0.05.",
                "position": 181
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x3.png",
                "caption": "Fig. 3:Personality and expertise diversity in reasoning traces.a,Personality diversity of implicit reasoning perspectives inferred from each reasoning trace using an LLM-as-judge and the BFI-10 (10-Item Big Five Personality Inventory). For each Big Five dimension, diversity is quantified as the standard deviation across inferred personalities. Reasoning models (DeepSeek-R1 and QwQ-32B) exhibit markedly higher diversity in openness, neuroticism, agreeableness, and extraversion. Kernel density estimation (KDE) plots show the distribution of personality traits across reasoning traces.b,Embedding space of expertise identified by the LLM-as-judge, projected into two dimensions using UMAP and rendered with an energy-minimization layout, revealing coherent and consistent skill proximities.c,Expertise diversity of implicit reasoning perspectives inferred from each reasoning trace, measured as the mean cosine distance between each expertise-related embedding and the centroid of all embeddings in the semantic space. Reasoning models exhibit substantially greater expertise diversity than non-reasoning models.d,Sparse autoencoder (SAE) schema and feature identification underlying the steering experiments.e,Design of the steering experiment. SAE feature 30939—capturing a discourse marker for surprise, realization, or acknowledgment indicative of persona and perspective shifts—is increased or decreased with a steering strength of 10. Example reasoning traces illustrate that negative steering induces linear chain-of-thought trajectories, no steering yields subtle perspective shifts enabling self-checking, and positive steering induces frequent and pronounced perspective shifts that explore fundamentally different solution strategies.f, g,Distributions of coverage and entropy for SAE personality-related (f) and expertise-related (g) features under feature 30939 steering. Error bars indicate 95% confidence intervals; solid horizontal lines denote medians and dashed lines indicate interquartile ranges (25th–75th percentiles).",
                "position": 233
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x4.png",
                "caption": "Fig. 4:Occurrence of social behaviours in accuracy-rewarded reinforcement learning and the effect of fine-tuning with conversational scaffolding.a,Comparison of the accuracy trajectory of reinforcement learning rewarded with problem-solving accuracy for the baseline Qwen-2.5-3B model and the same model initially fine-tuned to simulate social interaction through multi-agent dialogue generated by Qwen-2.5-32B. The socially initialized model reaches maximum accuracy more rapidly, whereas the baseline model eventually catches up and does so by adopting conversational behaviours, including questioning and answering, perspective shifts, and perspective conflict.b,Trajectories of individual conversational behaviours within the reinforcement-learned baseline model from panel a. Question-and-answer behaviour emerges first, followed by perspective shifts and conflicts, which rise in close synchrony. Reconciliation behaviour shows little increase, suggesting that individual approaches compete rather than forming an effective ensemble. Lines are smoothed using an exponential moving average (span = 9), and shaded regions indicate 95% confidence intervals.c–d,Comparison of the Qwen-2.5 baseline model at training step 40 versus step 120. At step 40, the model primarily engages in linear chain-of-thought reasoning, whereas by step 120, two distinctive simulated personas have emerged that explicitly recognize their collectivity through the use of the pronoun “we”.e,Personality profiles inferred by the LLM-as-judge. The step-40 model exhibits a strong all-around problem-solving profile, characterized by high conscientiousness, moderately high openness and agreeableness, lower extraversion, and notably low neuroticism. In contrast, the two collaborative agents observed at step 120 display differentiated personality profiles: one emphasizes trial-and-error problem solving, while the other specializes in metacognitive reasoning about problem solvability across alternative approaches. The trial-and-error agent is less extraverted and more agreeable than the step-40 agent, whereas the solvability-focused agent is more open and substantially less conscientious.",
                "position": 271
            }
        ]
    },
    {
        "header": "Discussion",
        "images": []
    },
    {
        "header": "Methods",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "Competing Interests",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Extended Data Figures",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.10825/x5.png",
                "caption": "Extended Data Fig. 1:Distribution of reasoning trace length.a,Kernel density plot showing the distribution of reasoning trace length, measured by the number of words per reasoning trace.b,Kernel density plot showing the distribution of log-transformed reasoning trace length.",
                "position": 1668
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x6.png",
                "caption": "Extended Data Fig. 2:Conversation excerpt in DeepSeek-R1 reasoning traces.a,Representative excerpt from a chemistry problem-solving trace showing multi-turn dialogue between distinct cognitive personas. Each utterance is annotated with conversational behaviors (blue) and socio-emotional roles (yellow).b,Big Five personality profiles for the five personas identified via LLM-as-judge. Radar charts display normalized trait scores (1–5 scale) for Extraversion (E), Agreeableness (A), Conscientiousness (C), Neuroticism (N), and Openness (O). Each persona exhibits domain expertise profiles. For detailed coding procedures and additional annotated examples, seeSupplementary Methods: Annotated Examples.",
                "position": 1671
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x7.png",
                "caption": "Extended Data Fig. 3:Bales’ detailed socio-emotional roles in chain-of-thought reasoning.a,Proportion of Bales’ 12 socio-emotional roles expressed in reasoning traces (seeFig. 1for higher-level aggregations of the socio-emotional roles).b,Differences in problem complexity by the presence of detailed socio-emotional roles in DeepSeek-R1 (measured on a 7-point Likert scale from 1 [extremely easy] to 7 [extremely difficult] using LLM-as-judge or by error rates in non-reasoning models). Points indicate mean complexity for reasoning traces where the behavior/role is present (red) or absent (blue).",
                "position": 1674
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x8.png",
                "caption": "Extended Data Fig. 4:Mediation analysis linking reasoning models (DeepSeek-R1 and QwQ-32B) to accuracy advantages through simulated social behaviours.Mediation structure linking DeepSeek-R1 and QwQ-32B (relative to instruction-tuned models) to improved task accuracy through conversational behaviours and socio-emotional roles (red), cognitive reasoning behaviours (blue), and the indirect pathway through which social behaviors facilitate cognitive reasoning (orange) as estimated in a structural equation model of labeled reasoning traces. Arrows denote direct and indirect effects. The direct pink pathway indicates the unmediated effect of DeepSeek-R1 and QwQ-32B on accuracy. *p<0.05p<0.05, **p<0.01p<0.01, ***p<0.001p<0.001.a,Summary estimates following various model paths, such that conversational behaviors and socio-emotional roles (seeFig. 1andExtended Data Fig. 1) directly and indirectly contribute to the accuracy improvement. To illustrate the relative contribution of each pathway, we report the proportional share of each pathway on model accuracy, calculated as the value of each pathway coefficient divided by the sum of coefficient values across all pathways. This demonstrates that more than 20% of accuracy is explained by the direct and indirect effect of social behaviours manifest in the reasoning trace.b,Coefficient matrices underlying the structural equation model (SEM), where labels in the figure index the estimates within the matrices. The red panels show the effects of DeepSeek-R1 and QwQ-32B on social behaviors and the effects of social behaviors on accuracy. The orange panel displays the effects of social behaviors on cognitive behaviors. The blue panels present the effects of DeepSeek-R1 and QwQ-32B on cognitive behaviors and the effects of cognitive behaviors on accuracy. Bolded coefficients indicate statistical significance (p<0.05p<0.05). Full coefficient estimates are reported inSupplementary Table 1.",
                "position": 1677
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x9.png",
                "caption": "Extended Data Fig. 5:LLM-as-judge benchmark results for identifying latent voices.Using the Intelligence Squared Debates Corpus (N=1,196N=1{,}196conversations), we validate the LLM-as-judge’s ability to identify distinct speakers when speaker labels are hidden, and dialogue is concatenated into a single block of text.a,Predicted versus actual number of agents in each conversation (Spearman’sρ=0.86\\rho=0.86,p<1×10−323p<1\\times 10^{-323}). Violin plots show the distribution of predictions for each actual agent count; points and error bars indicate means and 95% confidence intervals.b,Predicted versus actual number of conversational turns (Spearman’sρ=0.89\\rho=0.89,p<1×10−323p<1\\times 10^{-323}).c,Speaker attribution accuracy as a function of the number of agents. Accuracy is highest for two speakers (82%) and decreases as the number of speakers increases, but remains well above the random baseline (dashed line) across all conditions. Weighted accuracy across all conversations is 73%.d,Predicted expertise diversity (based on LLM-inferred descriptions and embeddings) versus actual biography diversity among debate participants (Spearman’sρ=0.55\\rho=0.55,p<1×10−97p<1\\times 10^{-97}), demonstrating that the LLM-as-judge captures meaningful variation in domain expertise that corresponds to ground-truth biographical differences.",
                "position": 1680
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x10.png",
                "caption": "Extended Data Fig. 6:SAE-based personality and expertise diversity estimates applied to model activations in reasoning traces.a,Distribution of coverage and entropy for SAE personality-related features.b,Distribution of coverage and entropy for SAE expertise-related features. Error bars in all panels indicate 95% confidence intervals. The solid horizontal line indicates the median, and dashed lines denote the interquartile range (IQR, 25th–75th percentiles).",
                "position": 1683
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x11.png",
                "caption": "Extended Data Fig. 7:Fine-tuning with conversational scaffolding accelerates reasoning improvement during reinforcement learning.a,Trajectory of conversational behaviors in the Qwen-2.5-3B base model during reinforcement learning. Question-and-answering behavior emerges first and increases most rapidly, followed by conflict of perspectives and perspective shifts rising in parallel. Reconciliation remains low throughout, suggesting competing approaches rather than integration. The trajectory of model accuracy shows how the uptick of questions, answers, and interacting perspectives correlated with an acceleration in model improvement.b,Trajectory of cognitive behaviors in the same model. Verification increases most dramatically during training, following in lockstep with the presence of question asking and answering. This is followed by backtracking, which follows conflicts between perspectives. Subgoal setting and backward chaining show more modest gains before a gradual decline. Shaded regions indicate 95% confidence intervals.",
                "position": 1686
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x12.png",
                "caption": "Extended Data Fig. 8:Fine-tuning with dialogue vs. monologue scaffolding accelerates reasoning improvement during reinforcement learning.a,Accuracy trajectories during reinforcement learning on the Countdown task for Qwen-2.5-3B.b,Accuracy trajectories for Llama-3.2-3B. Models initially fine-tuned with multi-agent dialogues (red) reach high accuracy faster than models fine-tuned with monologue-style reasoning (blue), though both eventually converge. The base model without fine-tuning (default; light green colors) learns more slowly.",
                "position": 1689
            },
            {
                "img": "https://arxiv.org/html/2601.10825/x13.png",
                "caption": "Extended Data Fig. 9:Conversational scaffolding transfers to misinformation detection under reinforcement learning.a,Illustration of the Countdown task and the PolitiFact misinformation-detection task.b,Validation accuracy during RL on PolitiFact, comparing social interaction (red) and single-voice, default reasoning CoT (green) format.",
                "position": 1692
            }
        ]
    },
    {
        "header": "Extended Data Tables",
        "images": []
    },
    {
        "header": "Supplementary Information",
        "images": []
    },
    {
        "header": "Supplementary Tables",
        "images": []
    }
]