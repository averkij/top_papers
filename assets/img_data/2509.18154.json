[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18154/x1.png",
                "caption": "",
                "position": 97
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x2.png",
                "caption": "",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18154/x3.png",
                "caption": "Figure 1:An overview of the MiniCPM-V 4.5 architecture. The model processes diverse visual inputs, such as high-resolution images and high frame rate videos. After the image partitioning and video packing processes, these inputs are encoded by a visual encoder and then fed into the unified 3D-Resampler. This module efficiently compresses both image and video features into a compact token sequence (achieving up to 16×\\timescompression rate for images and an additional 6×\\timesfor videos), which is then processed by the LLM decoder. The decoder can generate responses in two distinct styles: a concise, short reasoning mode or a step-by-step, long reasoning mode.",
                "position": 160
            }
        ]
    },
    {
        "header": "2Approach",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18154/tex/figs/ocr.png",
                "caption": "Figure 2:Unified paradigm for document knowledge and OCR learning via dynamic visual corruption. We create a spectrum of training tasks through varied corruption levels: low corruption preserves readability to learn robust OCR, high corruption forces the model to perform contextual inference, and moderate corruption requires integrated inference from visual clues and context.",
                "position": 268
            }
        ]
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18154/x4.png",
                "caption": "(a)OpenCompass",
                "position": 1973
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x4.png",
                "caption": "(a)OpenCompass",
                "position": 1976
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x5.png",
                "caption": "(b)Response Length",
                "position": 1981
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x6.png",
                "caption": "(c)Entropy",
                "position": 1986
            }
        ]
    },
    {
        "header": "4Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.18154/x7.png",
                "caption": "Figure 5:A case of comprehensive real-world reasoning.",
                "position": 3047
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x8.png",
                "caption": "Figure 6:A case of comprehensive real-world reasoning in Chinese.",
                "position": 3050
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x9.png",
                "caption": "Figure 7:A case of creative writing in Chinese.",
                "position": 3053
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x10.png",
                "caption": "Figure 8:A case of world knowledge understanding.",
                "position": 3061
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x11.png",
                "caption": "Figure 9:A case of world knowledge understanding in Chinese.",
                "position": 3064
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x12.png",
                "caption": "Figure 10:A case of handwritten text recognition.",
                "position": 3072
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x13.png",
                "caption": "Figure 11:A case of handwritten text recognition in Chinese.",
                "position": 3075
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x14.png",
                "caption": "Figure 12:A case of table content extraction.",
                "position": 3078
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x15.png",
                "caption": "Figure 13:A case of chemistry problem solving in Chinese.",
                "position": 3086
            },
            {
                "img": "https://arxiv.org/html/2509.18154/x16.png",
                "caption": "Figure 14:A case of multi-image statistical problem solving.",
                "position": 3089
            }
        ]
    },
    {
        "header": "Appendix BQualitative Cases",
        "images": []
    }
]