[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18554/x1.png",
                "caption": "Figure 1:An overview of the data extraction process. A sample generated using the prompt<|endoftext|><|user|>\\nis used as a query for a vector search to find the best semantic match from the training data. The figure highlights the difference between a high embedding similarity score (0.97) and a much lower string-match similarity score (0.68), demonstrating that semantic similarity is more effective for detecting this form of data memorisation.",
                "position": 210
            }
        ]
    },
    {
        "header": "2Nomenclature",
        "images": []
    },
    {
        "header": "3Extracting alignment data with neural embeddings",
        "images": []
    },
    {
        "header": "4Large scale extraction of SFT data",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18554/x2.png",
                "caption": "(a)Distribution of Levenshtein scores.",
                "position": 425
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x2.png",
                "caption": "(a)Distribution of Levenshtein scores.",
                "position": 428
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x3.png",
                "caption": "(b)Distribution of Indel scores.",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x4.png",
                "caption": "(a)Distribution ofgemini-embedding-001scores.",
                "position": 453
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x4.png",
                "caption": "(a)Distribution ofgemini-embedding-001scores.",
                "position": 456
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x5.png",
                "caption": "(b)Levenshtein vs embedding scores.",
                "position": 461
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x6.png",
                "caption": "(a)Empirical distribution of coverage of post-training set.",
                "position": 478
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x6.png",
                "caption": "(a)Empirical distribution of coverage of post-training set.",
                "position": 481
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x7.png",
                "caption": "(b)Empirical cumulative distribution of coverage of post-training set.",
                "position": 486
            }
        ]
    },
    {
        "header": "5Large scale extraction of RL data",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18554/x8.png",
                "caption": "Figure 8:Count of training samples (prompt only) with likelihood above a certain threshold before and after RL. The entire train set contains142142,770770samples. The base model is Qwen2.5 7B. After RL, many training prompts achieve a higher likelihood.",
                "position": 641
            },
            {
                "img": "https://arxiv.org/html/2510.18554/x9.png",
                "caption": "Figure 9:RL training using the ORZ(Hu et al.,2025)dataset and a dataset that was extracted using our method. Surprisingly, we are able to recover most of the performance with our simple extraction method.",
                "position": 646
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Author contributions",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExtended background",
        "images": []
    },
    {
        "header": "Appendix BAccidental gradient alignment",
        "images": []
    },
    {
        "header": "Appendix CPrefixes used for generation",
        "images": []
    },
    {
        "header": "Appendix DFailure cases of string matching",
        "images": []
    },
    {
        "header": "Appendix EExamples of data extracted using our attack",
        "images": []
    }
]