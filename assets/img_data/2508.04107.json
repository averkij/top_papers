[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04107/x1.png",
                "caption": "Figure 1:Performance ofMLLMSegon Referring Expression Segmentation (RES), showing consistent improvement over state-of-the-art methods.",
                "position": 103
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04107/x2.png",
                "caption": "Figure 2:Overview of the proposedMLLMSeg, where the detailed structure of light-weight mask decoder is shown in Figure3.",
                "position": 167
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.04107/x3.png",
                "caption": "Figure 3:Overview of the light-weight mask decoder with detail-enhanced and semantic-consistent feature fusion module (DSFF).",
                "position": 243
            },
            {
                "img": "https://arxiv.org/html/2508.04107/x4.png",
                "caption": "Figure 4:Visualization ofTi​m​g1T^{1}_{img}from the visual encoder,Ti​m​g2T^{2}_{img}from the large language model, andTv​lT_{vl}from the cross-attention ofTi​m​g1T^{1}_{img}andTi​m​g2T^{2}_{img}.",
                "position": 246
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]