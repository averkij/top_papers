[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Background and Related Work",
        "images": []
    },
    {
        "header": "3Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18672/x1.png",
                "caption": "Figure 1:Although training and validation loss decrease as the total number of parameters grows, the task loss on GSM8K can sometimes worsen with larger models.Training and validation losses steadily decrease as total or active parameters increase. The HellaSwag task loss follows this scaling trend, whereas GSM8K task loss worsens once total parameters exceed a threshold.",
                "position": 338
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x2.png",
                "caption": "Figure 2:For GSM8K and GSM-Plus, once the training loss drops below a certain point, the task loss starts to increase.Results of scaling total parameters by increasing the number of experts, with model width and top-kkheld constant.\nFor TriviaQA and HellaSwag, the task loss falls monotonically as training loss decreases.\nBy contrast, GSM8K and GSM-Plus show a U-shaped trend: task loss declines with training loss only until a threshold, beyond which further reductions in training loss hurt task performance.\nThat threshold moves lower as active parameter count increases, models with more active parameters achieve a lower optimal task loss.\nNo such active parameters dependence appears for TriviaQA, HellaSwag.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x3.png",
                "caption": "Figure 3:Downstream accuracy when scaling total parameters via expert count with width and top-kkfixed.TriviaQA and HellaSwag exhibit steadily improving accuracy as pre-training loss decreases, whereas GSM8K shows a non-monotonic trend: further reductions in pre-training loss do not always improve accuracy and can even degrade performance.",
                "position": 403
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x4.png",
                "caption": "Figure 4:Effect of sparsity on performance across different tasksWe vary sparsity (1 - top-kk/Experts) and plot the relationship between pre-training loss and benchmark error rate, including intermediate checkpoints.\nFor TriviaQA and HellaSwag, the error rate clearly tracks training loss and is largely insensitive to sparsity.\nIn contrast, reasoning-intensive tasks such as GSM8K and GSM-Plus exhibit a strong dependence of error rate on sparsity.",
                "position": 407
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x5.png",
                "caption": "Figure 5:At fixed active parameter counts, higher sparsity (lower density) consistently improves performance, but at larger active parameter counts, GSM8K and GSM-Plus shift their optima back toward dense models.Task loss (top row) and Accuracy (bottom row) against MoE Density k/E for a fixed active parameter budget.In the left two tasks (TriviaQA, HellaSwag), increasing sparsity consistently lowers task loss and raises accuracy across all active parameter budgets, in contrast, in the right two tasks (GSM8K, GSM-Plus), once active parameter counts become large, this trend reverses and denser models begin to outperform their sparser counterparts. Dashed segments mark the inverse‑scaling regime that starts at the black circle; solid segments show the standard scaling region to the right.",
                "position": 430
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x6.png",
                "caption": "",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x7.png",
                "caption": "Figure 6:Effect of Test-Time Compute and GRPO on the\nloss–accuracy trade-off.Although both methods yield performance\nimprovements that scale with model size, the loss–accuracy\ntrade-off onGSM8Kremains. Left: Final training loss\nvs accuracy under Test-Time Compute (Self-Consistency). Right:\nFinal training loss vs accuracy after GRPO post-training.",
                "position": 438
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x8.png",
                "caption": "Figure 7:Effect of TPP on performance across different tasks.For TriviaQA and HellaSwag, performance improves as the number of parameters increases.\nIn contrast, for reasoning-intensive tasks such as GSM8K and GSM-Plus, performance deteriorates when the number of parameters becomes too large, indicating that there exists an optimal data to total parameter ratio for these tasks. Even at fixed TPP, models with larger top-kkvalues consistently outperform those with smaller top-kkon reasoning tasks.",
                "position": 459
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x9.png",
                "caption": "Figure 8:For reasoning tasks like GSM8K and GSM-Plus, the relationship between training loss and downstream performance is dependent on the choice of optimization hyperparameters.The learning rate also impacts downstream accuracy.\nFor the maximum eigenvalue, we evaluated the maximum eigenvalue of fisher information matrix under a K-FAC approximation(Martens & Grosse,2015; Eschenhagen et al.,2023).\nFollowing(Grosse et al.,2023), we calculate the maximum eigenvalues only for linear layers.\nWe find that higher learning rates lead to a lower maximum eigenvalue, which is consistent with existing research indicating that convergence to flatter minima improves generalization(Hochreiter & Schmidhuber,1997; Keskar et al.,2017; Jiang et al.,2020).",
                "position": 483
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x10.png",
                "caption": "Figure 9:Effect of model depth on TPP-performance trade-offs.",
                "position": 515
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x11.png",
                "caption": "Figure 10:At fixed active parameter counts, higher sparsity (lower density) consistently improves performance, but at larger active parameter counts, HumanEval and MBPP shift their optima back toward dense models.Accuracy against MoE Density k/E for a fixed active parameter budget.In the left two tasks (TriviaQA, HellaSwag), increasing sparsity consistently raises accuracy across all active parameter budgets, in contrast, in the right two tasks (HumanEval, MBPP), once active parameter counts become large, this trend reverses and denser models begin to outperform their sparser counterparts. Dashed segments mark the inverse‑scaling regime that starts at the black circle; solid segments show the standard scaling region to the right.",
                "position": 533
            }
        ]
    },
    {
        "header": "4Discussion and Limitations",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Author Contributions",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18672/x12.png",
                "caption": "Figure 11:Learning-rate sweep for width=2048=2048.We varied the number of experts and swept the learning rate. For both 16 and 32 experts,5×10−65\\times 10^{-6}produces the most stable training.",
                "position": 2068
            }
        ]
    },
    {
        "header": "Appendix BEvaluation Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.18672/x13.png",
                "caption": "Figure 12:Comparison of GSM8K accuracy for models fine-tuned with GRPO on different training datasets (left: GSM8K, right: MATH 500).Performance decline is consistently observed across different training datasets.",
                "position": 2213
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x14.png",
                "caption": "Figure 13:GSM8K accuracy of model (d=1024) across different shot counts.Because few shot performance is unstable and dropped significantly for models with a small number of experts, zero shot is used for Test-Time Compute.",
                "position": 2233
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x15.png",
                "caption": "Figure 14:Comparison of performance decline across different temperature settings (pass@1, d=1024).A consistent performance decline is observed regardless of temperature, and overall accuracy increases as temperature decreases (i.e., approaches greedy).",
                "position": 2243
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x16.png",
                "caption": "Figure 15:Accuracy across generation budgets with increased sample counts.With an active parameter count of 8 (top 8), the performance decline is gradually alleviated as the budget increases, whereas with an active parameter count of 2 (top 2), the decline is amplified, resulting in a more pronounced U shaped trend.",
                "position": 2253
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x17.png",
                "caption": "Figure 16:Increasing the top-k parameter only at inference time does not improve performance.Performance comparison under TTC for a Mixture-of-Experts model (hidden dimension 2048, 128 experts, top-2) as the top-k parameter is increased. While doubling k can occasionally improve Pass@1, applying TTC ultimately shows that the original top-2 configuration delivers the highest performance.",
                "position": 2262
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x18.png",
                "caption": "Figure 17:Performance versus MoE density after removing GSM8K-related training data.Task loss (top) and accuracy (bottom) are plotted against MoE density (k/E) for a fixed active parameter budget. While performance on memorization tasks (TriviaQA, HellaSwag) improves with sparsity, the trend reverses for math reasoning tasks (GSM8K, GSM-Plus) at larger active parameter counts. Dashed segments mark the inverse-scaling regime.",
                "position": 2279
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x19.png",
                "caption": "",
                "position": 2283
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x20.png",
                "caption": "Figure 18:GSM8K performance without GSM8K-related training data: Pass@1 (left), TTC with 128 budget (center), and after GRPO (right)",
                "position": 2287
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x21.png",
                "caption": "",
                "position": 2290
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x22.png",
                "caption": "Figure 19:Analysis of solvable problems across different numbers of experts on GSM8K.This graph displays the number of problems that were commonly solvable or unsolvable across models with varying numbers of experts.",
                "position": 2305
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x23.png",
                "caption": "Figure 20:Although training and validation losses generally decrease as the total number of parameters increases, validation loss for the largest models does not fully converge.HellaSwag task loss follows this favorable scaling trend, but HumanEval task loss sometimes worsens once the total number of parameters exceeds a certain threshold.",
                "position": 2315
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x24.png",
                "caption": "Figure 21:For HumanEval and MBPP, once the training loss drops below a certain point, the task loss starts to increase.Results of scaling total parameters by increasing the number of experts, with model width and top-kkheld constant.\nFor TriviaQA, HellaSwag, and task loss falls monotonically as training loss decreases.\nBy contrast, HumanEval and MBPP show a U-shaped trend: task loss declines with training loss only until a threshold, beyond which further reductions in training loss hurt task performance.",
                "position": 2319
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x25.png",
                "caption": "Figure 22:Downstream accuracy when scaling total parameters via expert count with width and top-kkfixed.TriviaQA and HellaSwag exhibit steadily improving accuracy as pre-training loss decreases, whereas HumanEval shows a non-monotonic trend: further reductions in pre-training loss do not always improve accuracy and can even degrade performance.",
                "position": 2325
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x26.png",
                "caption": "Figure 23:At fixed active parameter counts, higher sparsity (lower density) consistently improves performance, but at larger active parameter counts, HumanEval and MBPP shift their optima back toward dense models.Task loss against MoE Density k/E for a fixed active parameter budget.In the left two tasks (TriviaQA, HellaSwag), increasing sparsity consistently lowers task loss across all active parameter budgets, in contrast, in the right two tasks (HumanEval, MBPP), once active parameter counts become large, this trend reverses and denser models begin to outperform their sparser counterparts. Dashed segments mark the inverse‑scaling regime that starts at the black circle; solid segments show the standard scaling region to the right.",
                "position": 2329
            },
            {
                "img": "https://arxiv.org/html/2508.18672/x27.png",
                "caption": "Figure 24:Effect of TPP on performance across different tasks.For TriviaQA and HellaSwag, performance improves as the number of parameters increases.\nIn contrast, for reasoning-intensive tasks such as HumanEval and MBPP, performance deteriorates when the number of parameters becomes too large, indicating that there exists an optimal data to parameter ratio for these tasks.",
                "position": 2332
            }
        ]
    },
    {
        "header": "Appendix CAdditional Experiments",
        "images": []
    }
]