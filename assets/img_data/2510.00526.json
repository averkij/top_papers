[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00526/x1.png",
                "caption": "Figure 1:The model capability continuum of SFT objectives in Post-Training.At the model-strong (MS) end, where base models already encode extensive priors (e.g., Llama 3 reports 25% math pretraining tokens(Grattafiori et al.,2024)),\nprior-leaning objectives that downweight low-probability tokens (e.g.,−p-p,−p10-p^{10}, or thresholded variants) consistently outperform NLL by up to 16%.\nAt the model-weak (MW) end, where no useful priors exist (e.g., no figfont puzzles in pretraining data), the standard NLL dominates.\nIn the model-intermediate (MI) region (e.g., medical reasoning, where models rely on partial world knowledge),\nthe gap between objectives narrows and no single choice consistently prevails.\nThis continuum highlights how the effectiveness of an SFT objective depends critically on the capability of the base model.",
                "position": 176
            }
        ]
    },
    {
        "header": "2A Unified Categorization of SFT Training Objectives",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00526/x2.png",
                "caption": "Figure 2:The logit gradientsWf​(p)W_{f}(p)of different functions.",
                "position": 289
            }
        ]
    },
    {
        "header": "3Main Experiments",
        "images": []
    },
    {
        "header": "4Empirical Analysis",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.00526/x3.png",
                "caption": "Figure 3:Performance under quantile thresholdingfor−log⁡(p)-\\log(p),−p-p, andlog⁡(1−p)\\log(1-p).\nLetQpercentileQ_{\\text{percentile}}denote the predicted probability at the specified percentile of the training set.\n(≥\\geqPercentile) corresponds toI=[Qpercentile,1]I=[Q_{\\text{percentile}},1]in Eq.4,\nwhile (≤\\leqPercentile) corresponds toI=[0,Qpercentile]I=[0,Q_{\\text{percentile}}].\nKey findings:\n(1) low-probability tokens consistently harm performance across all objectives;\n(2) when training on all tokens, objectives that de-emphasize low-probability tokens (−p-pandlog⁡(1−p)\\log(1-p)) outperform−log⁡(p)-\\log(p);\n(3) restricting training to only the top 10% of tokens yields the strongest improvements across all objectives, surpassing standard SFT.",
                "position": 913
            },
            {
                "img": "https://arxiv.org/html/2510.00526/x4.png",
                "caption": "Figure 4:Analysis of MS and MW ends in terms of objective convexity (with Eq.3) and likelihood estimation.\nIn MS, more concave (prior-leaning) objectives yield better downstream accuracy, while in MW, more convex (prior-averse) objectives dominate.\nThe likelihood estimation results align with these trends, suggesting that objective shape directly interacts with model prior strength.",
                "position": 942
            }
        ]
    },
    {
        "header": "5Theoretical Analysis",
        "images": []
    },
    {
        "header": "6Conclusion and Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARelated Works",
        "images": []
    },
    {
        "header": "Appendix BDetailed Experimental Setup",
        "images": []
    },
    {
        "header": "Appendix CAdditional Experiment Results",
        "images": []
    },
    {
        "header": "Appendix DLimitation",
        "images": []
    },
    {
        "header": "Appendix EProofs for Sec.2",
        "images": []
    },
    {
        "header": "Appendix FMain Theoretical Results",
        "images": []
    }
]