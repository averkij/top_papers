[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Overview",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/model.png",
                "caption": "Figure 1:The architecture of iFlyBot-VLA consists primarily of a language transformer backbone and an action expert network. The model generates executable robot actions through a combination of explicit and implicit planning. The key–value (KV) cache from the VLM component is passed to the downstream action expert, while the FAST Action Token—which corresponds to the implicit planning process—is not forwarded to the Action Expert",
                "position": 183
            }
        ]
    },
    {
        "header": "3iFlyBot-VLA Model",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/lam.png",
                "caption": "Figure 2:Architecture of the latent action token encoding expert network",
                "position": 277
            }
        ]
    },
    {
        "header": "4Training Strategy",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/data.png",
                "caption": "Figure 3:The data used for training the latent action token encoding expert network",
                "position": 352
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x1.png",
                "caption": "Figure 4:Overview of our dataset.The pretraining mixture consists of subsets of OXE, AgiBot_World, self-collected manipulation data, and VQA data.\nThe left figure shows the proportion of different datasets in the pretraining mixture,\nwhile the right figure illustrates the composition of QA datasets during the pretraining stage.",
                "position": 358
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/Libero.png",
                "caption": "Figure 5:Task suites in the LIBERO dataset.",
                "position": 426
            },
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/comp.png",
                "caption": "Figure 6:Comparison of iFlyBot-VLA and representative VLA models on the LIBERO simulator dataset.",
                "position": 487
            },
            {
                "img": "https://arxiv.org/html/2511.01914/iFlyBot_images/abla.png",
                "caption": "Figure 7:Ablation results showing the effect of different components of iFlyBot-VLA in the LIBERO simulator.",
                "position": 500
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x2.png",
                "caption": "Figure 8:Experiment Settings of Generalizable Pick-and-Place.(a) Examples of seen and unseen objects — left: seen, right: unseen.\n(b) Illustration of varying illumination conditions.\n(c) Demonstration of grasping experiments in different scenes.",
                "position": 546
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x3.png",
                "caption": "Figure 9:Experiment Results of General Pick-and-Place.Success rate of our policy and baseline.",
                "position": 557
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x4.png",
                "caption": "Figure 10:Experiment Results of Long-Horizon Manipulation Tasks.(a) Detailed steps of parcel sorting.\n(b) Results of our policy and baseline.",
                "position": 569
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x5.png",
                "caption": "Figure 11:Detailed Description of the Clothes Folding Task(a) Initial state of the clothes.\n(b) Challenging actions involved in \"flattening\"",
                "position": 580
            },
            {
                "img": "https://arxiv.org/html/2511.01914/x6.png",
                "caption": "Figure 12:We defined a step-by-step evaluation protocol and summarized the corresponding results as follows:(a) Step Definition for the Folding Task.\n(b) Completion rate of each step.",
                "position": 617
            }
        ]
    },
    {
        "header": "6Limitation and Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]