[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26574/x1.png",
                "caption": "",
                "position": 128
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Design choices ofCritPt",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26574/x2.png",
                "caption": "Figure 1:CritPt’s challenges (left) and checkpoints (right) cover three flavors of physics research – theoretical, experimental, and computational – encountered by physics researchers.",
                "position": 672
            }
        ]
    },
    {
        "header": "3Evaluation pipeline",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26574/x3.png",
                "caption": "Figure 2:A schematic overview of the two-step generation process and the grading system.Left: The two-step generation protocol separates problem-solving (first round) from answer formatting (second round).Right: The automated grading system compares the model output against the gold answer from experts using scripts customized according to the expected answer format.",
                "position": 956
            }
        ]
    },
    {
        "header": "4Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.26574/x4.png",
                "caption": "Figure 3:A comparison of 10 models’ performance on 70 testCritPtchallenges. Each model is tested on every challenge in five independent runs.Main plot: the average accuracy over all runs and all challenges for each model.Inset a: the average number of reasoning tokens used per run for each model.Inset b: the average cost (USD) per run, calculated from token usage and API pricing for each model (A.4).",
                "position": 1849
            },
            {
                "img": "https://arxiv.org/html/2509.26574/x5.png",
                "caption": "Figure 4:Schematic of the two experimental setups for evaluating sequential checkpoints within a multi-turn conversation.\n(a) Self-carryover without expert answer: The model’s own output from the previous checkpoint is used as context for the next one.\n(b) Oracle carryover with expert answers: The correct answer (shown in red) to the previous checkpoint is provided before the model attempts the next checkpoint.",
                "position": 1915
            },
            {
                "img": "https://arxiv.org/html/2509.26574/x6.png",
                "caption": "Figure 5:A comparison of 10 models’ performance on the 187 testCritPtcheckpoints.\nThe average accuracy is aggregated over all runs and all checkpoints, in two setups respectively.\nSolid bar reports the self-carryover without expert answer, while the hatched pattern reports oracle carryover with expert answers.",
                "position": 1920
            },
            {
                "img": "https://arxiv.org/html/2509.26574/x7.png",
                "caption": "Figure 6:Percentage ofCritPtproblems consistently solved by models.\nA problem is considered consistently solved if at least four out of five independent runs yield the correct final answer.\n(a) Percentage of challenges consistently solved.\n(b) Percentage of checkpoints consistently solved.",
                "position": 1953
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledgments and Disclosure of Funding",
        "images": []
    },
    {
        "header": "Appendix AAppendix",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]