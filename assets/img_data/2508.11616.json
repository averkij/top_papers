[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11616/x1.png",
                "caption": "Figure 1:Illustration of multimodal reward-guided decoding (MRGD) for MLLMs. At each iteration,kkcandidate completions (sentences in our case) to a partial response are sampled from the MLLM and evaluated according to a linear combination of rewards (the process is illustrated for the first selected completion and omitted elsewhere). The completion with largest score is selected and added to the context to generate the nextkkcandidates, until the<EOS>token is encountered.",
                "position": 145
            }
        ]
    },
    {
        "header": "2Related work",
        "images": []
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2508.11616/x2.png",
                "caption": "(a)Reward valuerhalr_{\\text{hal}}(left) and CHAIRi(right), MRGD withw=1.0w{=}1.0.",
                "position": 829
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x2.png",
                "caption": "(a)Reward valuerhalr_{\\text{hal}}(left) and CHAIRi(right), MRGD withw=1.0w{=}1.0.",
                "position": 832
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x3.png",
                "caption": "(b)Reward valuerrecr_{\\text{rec}}(left) and Recall (right), MRGD withw=0.0w{=}0.0.",
                "position": 838
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x4.png",
                "caption": "Figure 3:Object precision and recall for LLaVA-1.5 on COCO, withT=1T{=}1.\nVaryingwwmodulates the precision-recall trade-off under a fixed compute budget, while increasing compute via a largerkkimproves both precision and recall, significantly surpassing greedy search and bringing the trade-off curve closer to the ideal.",
                "position": 1033
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x5.png",
                "caption": "(a)",
                "position": 1062
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x5.png",
                "caption": "(a)",
                "position": 1065
            },
            {
                "img": "https://arxiv.org/html/2508.11616/x6.png",
                "caption": "(b)",
                "position": 1071
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "Acknowledments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "6Experiments",
        "images": []
    }
]