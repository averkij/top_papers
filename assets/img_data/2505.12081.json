[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12081/x1.png",
                "caption": "Figure 1:(a) VisionReasoner addresses diverse tasks within a unified framework. It generates a reasoning process and outputs the expected result corresponding to each query. (b) VisionReasoner significantly outperforms Qwen2.5VL. (c) VisionReasoner retains strong VQA capabilities.",
                "position": 106
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12081/x2.png",
                "caption": "Figure 2:Illustration of VisionReasoner. (a) For a given imageùêàùêà\\mathbf{I}bold_Iand text instructionùêìùêì\\mathbf{T}bold_T, our model generates the expected output corresponding to the instruction. (b) For each observationoisubscriptùëúùëño_{i}italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we calculate the rewards (Section3.3) and attain the optimal match of multi-objects (Section3.4)",
                "position": 221
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.12081/x3.png",
                "caption": "Figure 3:Examples from evaluation benchmarks. Zoom in for better viewing.",
                "position": 347
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x4.png",
                "caption": "Figure 4:Ablation on non-repeat reward. (a) Consistent performance gain across different datasets using non-repeated reward. (b) Non-repeat rewards lead to shorter response lengths.",
                "position": 810
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x4.png",
                "caption": "Figure 4:Ablation on non-repeat reward. (a) Consistent performance gain across different datasets using non-repeated reward. (b) Non-repeat rewards lead to shorter response lengths.",
                "position": 813
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x5.png",
                "caption": "Figure 5:Different sampling number.",
                "position": 951
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x5.png",
                "caption": "Figure 5:Different sampling number.",
                "position": 955
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x6.png",
                "caption": "Figure 6:Reasoning vs.¬†no reasoning",
                "position": 959
            },
            {
                "img": "https://arxiv.org/html/2505.12081/x7.png",
                "caption": "",
                "position": 965
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]