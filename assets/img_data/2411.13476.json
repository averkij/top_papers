[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x1.png",
                "caption": "Figure 1:Effects of positional shifts on attention computations under different settings.Left: Attention differenceDùê∑Ditalic_D(Eq.4) plotted against varying positional shiftŒî1subscriptŒî1\\Delta_{1}roman_Œî start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(withŒî2=16subscriptŒî216\\Delta_{2}=16roman_Œî start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 16fixed). Pretrained models under BFloat16 (blue line) exhibit significant discrepancies compared to Float32 (yellow line) and random initialization (green line), indicating that the relative positional encoding property of RoPE is broken under BFloat16 and that pretraining amplifies this effect.Middle: Per-token attention differences betweenŒî1=0subscriptŒî10\\Delta_{1}=0roman_Œî start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0andŒî2=16subscriptŒî216\\Delta_{2}=16roman_Œî start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 16, highlighting the first token accounts for most of the attention difference observed.Right: Attention logit difference (Eq.5) for the first token as sequence length increases, showing increased discrepancies with longer sequences.",
                "position": 122
            },
            {
                "img": "https://arxiv.org/html/2411.13476/x2.png",
                "caption": "Figure 2:Illustrations of different attention paradigms. Left: Standard intra-document attention. Middle: Our improved version, intra-document attention withposition ID resetper document. Right:AnchorAttentionincorporating a shared anchor token,ùíúùíú\\mathscr{A}script_A.",
                "position": 137
            }
        ]
    },
    {
        "header": "2Discrepancies in RoPE‚Äôs Relative Positional Encoding",
        "images": []
    },
    {
        "header": "3AnchorAttention",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x3.png",
                "caption": "Figure 3:Resetting position IDs improves performance, contradicting theoretical predictions of RoPE.",
                "position": 339
            }
        ]
    },
    {
        "header": "4Long-Context Extension Protocol",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x4.png",
                "caption": "Figure 4:RULER performance varies during long-context training, we recommend reporting the averaged RULER performance rather than just the final training step.\nPPL remains unchanged after the first several steps, failing to reflect improvements in long-context ability.",
                "position": 497
            }
        ]
    },
    {
        "header": "5Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x5.png",
                "caption": "Figure 5:Illustrations of domain tagging and interleaved chunks.\nLeft: AnchorAttention with domain tagging, whereùíØ1subscriptùíØ1\\mathscr{T}_{1}script_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTdenotes the domain of documentd1subscriptd1\\textbf{{d}}_{1}d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nMiddle: Intra-document attention with interleaved chunks; documents are split into shuffled, interleaved chunks, preserving the original order within each document.\nRight: AnchorAttention with interleaved chunks.",
                "position": 817
            },
            {
                "img": "https://arxiv.org/html/2411.13476/x6.png",
                "caption": "Figure 6:Estimated training time required to process 1 billion tokens at various context lengths using different attention mechanisms. OurAnchorAttentionreduce more than50%percent5050\\%50 %of time needed by Full Attention.",
                "position": 1349
            }
        ]
    },
    {
        "header": "6Related Work",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Future Work",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ARotary Positional Embedding (RoPE) and Relative Positional Encoding",
        "images": []
    },
    {
        "header": "Appendix BAnalyses of Attention Discrepancies with RoPE under BFloat16",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x7.png",
                "caption": "Figure 7:Visualization of attention score differences under BFloat16 for individual samples.",
                "position": 2390
            }
        ]
    },
    {
        "header": "Appendix CData Statistics",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.13476/x8.png",
                "caption": "Figure 8:Training Data Sequence Length Distribution",
                "position": 2545
            }
        ]
    },
    {
        "header": "Appendix DLLaMA-2-7BRULER Performance",
        "images": []
    },
    {
        "header": "Appendix ELongbench full result",
        "images": []
    }
]