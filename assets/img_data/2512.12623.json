[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12623/logo/ucsb.png",
                "caption": "",
                "position": 70
            },
            {
                "img": "https://arxiv.org/html/2512.12623/logo/stanford.png",
                "caption": "",
                "position": 70
            },
            {
                "img": "https://arxiv.org/html/2512.12623/logo/ucsc.png",
                "caption": "",
                "position": 71
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x1.png",
                "caption": "Figure 1:Comparison between DMLR and two reasoning paradigms. (A) Text-only reasoning: relies solely on explicit CoT, often causing visual grounding errors and redundant steps. (B) Think-with-Image reasoning: depends on external perception tools, leading to unstable tool calls and extra overhead. (C) DMLR (ours): refines latent think tokens in the latent space through confidence-guided optimization and dynamically injects visual information, achieving self-improving reasoning without additional training while maintaining high efficiency.",
                "position": 83
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary and Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12623/x2.png",
                "caption": "Figure 2:Analysis of visual dependency in reasoning. (A) Token-level distribution shows visual sensitivity is concentrated in a few tokens. (B) Chain-level distribution reveals large variation in visual reliance across reasoning trajectories.",
                "position": 160
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x3.png",
                "caption": "Figure 3:Analysis of the relationship between confidence and reasoning quality. (A) Correct reasoning chains exhibit substantially higher frequencies of positive confidence gains than incorrect ones. (B) Faithful reasoning shows consistently stronger confidence improvement than spurious reasoning.",
                "position": 196
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x3.png",
                "caption": "Figure 3:Analysis of the relationship between confidence and reasoning quality. (A) Correct reasoning chains exhibit substantially higher frequencies of positive confidence gains than incorrect ones. (B) Faithful reasoning shows consistently stronger confidence improvement than spurious reasoning.",
                "position": 198
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x4.png",
                "caption": "Figure 4:Analysis of the relationship between confidence and visual grounding. (A) Hallucinated steps show lower confidence than non-hallucinated ones. (B) Hallucinated steps exhibit weaker image relevancy than their counterparts.",
                "position": 202
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12623/x5.png",
                "caption": "Figure 5:Overview of the proposed DMLR framework.\nThe model performs exploration through controlled noise (Eq.5) and iteratively optimizes the latent think tokens via confidence-guided policy updates (Eq.8â€“9).\nDynamic Visual Injection (Eq.10) selects and updates the best visual patches during optimization, and the optimized latent tokens are decoded (Eq.3) to produce the output.",
                "position": 247
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12623/x6.png",
                "caption": "Figure 6:Effect of iterations on performance. For both the base model and the reasoning model, accuracy on both datasets increases as the number of iterations grows.",
                "position": 957
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x6.png",
                "caption": "Figure 6:Effect of iterations on performance. For both the base model and the reasoning model, accuracy on both datasets increases as the number of iterations grows.",
                "position": 959
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x7.png",
                "caption": "Figure 7:(A) Effect of the number of injected candidate visual patches on performance. (B) Impact of noise magnitude (%) on performance. All results are evaluated on the MathVision dataset.",
                "position": 964
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x8.png",
                "caption": "Figure 8:Confidence reward and best visual patch injection across iterations. Both the base model and the reasoning model exhibit a clear positive correlation.",
                "position": 974
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x8.png",
                "caption": "Figure 8:Confidence reward and best visual patch injection across iterations. Both the base model and the reasoning model exhibit a clear positive correlation.",
                "position": 976
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x9.png",
                "caption": "Figure 9:Effect of the number of latent tokens. Increasing the number of latent tokens initially improves performance, but excessive tokens lead to noticeable degradation.",
                "position": 981
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x10.png",
                "caption": "Figure 10:Qualitative analysis of our DMLR framework.\n(A) Visual comparison of visual grounding behaviors between Explicit CoT and DMLR across diverse queries. DMLR produces more focused and stable visual grounding than explicit CoT.\n(B) Perception optimization across latent think token iterations, where visual attention becomes progressively sharper and better aligned with relevant regions.\n(C) Visualization of latent embeddings showing the geometric separation of latent think tokens, text tokens, and image tokens, illustrating the structured organization of the latent reasoning space.",
                "position": 992
            },
            {
                "img": "https://arxiv.org/html/2512.12623/x11.png",
                "caption": "Figure 11:Comparison of efficiency and accuracy across various reasoning methods on the MathVision Benchmark.\nDMLR achieves the best overall trade-off, delivering higher accuracy while maintaining strong inference efficiency.\nThe x-axis reports the efficiency metric(Acc/AvgBatchTime)2(\\text{Acc}/\\text{AvgBatchTime})^{2}.",
                "position": 1017
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AMore Detailed about Evaluation",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.12623/img/example/mmvp1.jpg",
                "caption": "",
                "position": 1948
            },
            {
                "img": "https://arxiv.org/html/2512.12623/img/example/mathvision1.png",
                "caption": "",
                "position": 1990
            }
        ]
    },
    {
        "header": "Appendix BCase Study",
        "images": []
    }
]