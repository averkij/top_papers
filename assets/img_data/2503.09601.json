[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09601/x1.png",
                "caption": "",
                "position": 67
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09601/x2.png",
                "caption": "Figure 2:RewardSDS illustration.An image is first rendered from a given view andNùëÅNitalic_Nrandom noises are applied (at a given timestep). The noisy images are then scored by denoising them and applying a reward model on the output. These scores are then mapped to corresponding weights, which are used to weigh the contribution of each noisy sample in score distillation.",
                "position": 121
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09601/x3.png",
                "caption": "Figure 3:Qualitative comparison of generated outputs using different reward models for RewardSDS and the SDS baseline.",
                "position": 378
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x4.png",
                "caption": "Figure 4:Qualitative comparison of zero-shot text-to-image generation using SDS, RewardSDS (ours), VSD, RewardVDS (ours)",
                "position": 485
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x5.png",
                "caption": "Figure 5:Qualitative comparison of text-to-3D generation based on (a) NeRF and (b) 3DGs, in comparison to MVDream.",
                "position": 571
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x6.png",
                "caption": "",
                "position": 579
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x7.png",
                "caption": "Figure 6:Qualitative comparison of text-to-3D generation using different reward models. We consider a NeRF backbone optimized with RewardSDS, either using the ImageReward reward model or Aesthetic Score reward model. As can be seen, using aesthetic reward results in adding bushes (top row) and a different (more aesthetic) color (both rows).",
                "position": 589
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x8.png",
                "caption": "Figure 7:Qualitative comparison of image editing. We compare DDS to our adaptation, RewardDDS.",
                "position": 640
            },
            {
                "img": "https://arxiv.org/html/2503.09601/extracted/6274092/figs/ablation_scaling.png",
                "caption": "Figure 8:The top graph shows the impact of the number of reward-based steps (KùêæKitalic_K), the middle graph presents the impact of the number of reward-based steps (SùëÜSitalic_S), and the bottom graph illustrates the impact of the number of considered noises (NùëÅNitalic_N).",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2503.09601/extracted/6274092/figs/time_vs_quality.png",
                "caption": "Figure 9:Tradeoff between running time and generation quality.",
                "position": 728
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAdditional Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2503.09601/x9.png",
                "caption": "Figure 10:Qualitative comparison of generated outputs using different reward models for RewardVSD and the VSD baseline. Each row corresponds to a different reward model, with the input prompts shown at the bottom, taken from Drawbench.",
                "position": 1512
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x10.png",
                "caption": "Figure 11:Qualitative results illustrating the effect of the number of considered noises (NùëÅNitalic_N). The top row presents the baseline method, while the input prompts are displayed below the images.",
                "position": 1517
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x11.png",
                "caption": "Figure 12:Qualitative results illustrating\ntext-to-3D results for SDS compared to RewardSDS and for VSD compared to our RewardVSD (without MVDream‚Äôs pretraining).",
                "position": 1560
            },
            {
                "img": "https://arxiv.org/html/2503.09601/x12.png",
                "caption": "Figure 13:Qualitative comparison between SDS-Bridge and RewardSDS-Bridge.",
                "position": 1580
            }
        ]
    },
    {
        "header": "Appendix BImplementation details.",
        "images": []
    },
    {
        "header": "Appendix CHand-Crafted Prompts for NeRF-Based MVDream Evaluation",
        "images": []
    }
]