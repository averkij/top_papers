[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Datasets",
        "images": []
    },
    {
        "header": "4Tokenization Metrics",
        "images": []
    },
    {
        "header": "5Pre-Transformer Tokenization Benchmarks",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06942/word-cola-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for CoLA (Train/Test). Test coverage accumulates faster than train up to 95% and then saturates, while train coverage increases gradually, indicating that many frequent train types do not transfer cleanly to the test distribution.",
                "position": 1071
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-cola-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for CoLA (Train/Test). Test coverage accumulates faster than train up to 95% and then saturates, while train coverage increases gradually, indicating that many frequent train types do not transfer cleanly to the test distribution.",
                "position": 1074
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-cola-success.png",
                "caption": "(b)Train token coverage vs. CoLA score (MCC). Each point uses the smallest top-K achieving the indicated train coverage. Performance is negative across the range and degrades slightly as coverage grows (≈\\approx-10 at 50% to≈\\approx-36 at 100%), suggesting the word-level model fails to capture grammatical acceptability even with full coverage.",
                "position": 1079
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-sst2-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for SST‑2 (Train/Test). Test coverage rises sharply and saturates around 93–95% with a relatively small K, while train coverage increases gradually, indicating a mismatch in how the ranked word list accumulates coverage across splits.",
                "position": 1095
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-sst2-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for SST‑2 (Train/Test). Test coverage rises sharply and saturates around 93–95% with a relatively small K, while train coverage increases gradually, indicating a mismatch in how the ranked word list accumulates coverage across splits.",
                "position": 1098
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-sst2-success.png",
                "caption": "(b)Train token coverage vs. SST‑2 accuracy. Each point uses the smallest top‑K achieving the shown train coverage. Accuracy jumps from 69% at 50% coverage to 85% by 75–80%, then remains flat near 85% through 100% coverage.",
                "position": 1103
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-word-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for train and test. Curves show how much of the ranked word vocabulary must be retained to reach a given coverage on each split; test coverage lags train, indicating distribution shift.",
                "position": 1124
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-word-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for train and test. Curves show how much of the ranked word vocabulary must be retained to reach a given coverage on each split; test coverage lags train, indicating distribution shift.",
                "position": 1127
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-word-success.png",
                "caption": "(b)Train token coverage vs. NER F1. Each point uses the smallest top‑K word list that achieves the indicated training token coverage; despite increasing coverage, F1 remains around 0.5.",
                "position": 1132
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-word-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for BOUN, train and test. Train coverage increases only gradually with larger K/|V|, while the test split accumulates coverage differently, indicating a mismatch between the ranked word list and the test distribution.",
                "position": 1150
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-word-vocab.png",
                "caption": "(a)Token coverage vs. required vocabulary fraction (K/|V|) for BOUN, train and test. Train coverage increases only gradually with larger K/|V|, while the test split accumulates coverage differently, indicating a mismatch between the ranked word list and the test distribution.",
                "position": 1153
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-word-success.png",
                "caption": "(b)Train token coverage vs. POS, LAS, and Morph F1. Each point uses the smallest top‑K word list achieving the indicated train coverage. All three metrics reach their plateau by 75% coverage and remain essentially flat thereafter (POS≈\\approx60, LAS≈\\approx19, Morpha≈a\\approx12).",
                "position": 1158
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-cola-exp.png",
                "caption": "(a)CoLA (word-level, top-80% vocab). Low-contrast, diffuse attributions: OOVs are only mildly weighted; “biçimbirime/biçimbirimler” receive modest intensity; no clear morphosyntactic signal.",
                "position": 1178
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-cola-exp.png",
                "caption": "(a)CoLA (word-level, top-80% vocab). Low-contrast, diffuse attributions: OOVs are only mildly weighted; “biçimbirime/biçimbirimler” receive modest intensity; no clear morphosyntactic signal.",
                "position": 1181
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-sst2-explain.png",
                "caption": "(b)SST‑2 (word-level, top-80% vocab). Attribution concentrates on polarity cues and verbs, e.g., “memnun etmedi,” “klişe,” “ağır,” “Sıkıldığım,” “tavsiye edemeyeceğim,” “tercih/edebilir.”",
                "position": 1186
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-ner-explain.png",
                "caption": "(a)NER example (top-80% vocab). Dates (“1949’da”, “1 Ekim 1949’da”) receive the clearest emphasis; OOV entities (“Mao”, “Cumhuriyeti’ni”, “Pekin’i”) are de-emphasized, consistent with F1≈\\approx0.50.",
                "position": 1196
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-ner-explain.png",
                "caption": "(a)NER example (top-80% vocab). Dates (“1949’da”, “1 Ekim 1949’da”) receive the clearest emphasis; OOV entities (“Mao”, “Cumhuriyeti’ni”, “Pekin’i”) are de-emphasized, consistent with F1≈\\approx0.50.",
                "position": 1199
            },
            {
                "img": "https://arxiv.org/html/2602.06942/word-pos-explain.png",
                "caption": "(b)POS example (top-80% vocab). Emphasis shifts to in-vocab function words (“Bir”, “yandan”, “da”), while OOV content words receive flat, low weights, indicating limited morphological awareness.",
                "position": 1204
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-cola-vocab.png",
                "caption": "(a)CoLA: Token cov. vs. vocab. frac.",
                "position": 1285
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-cola-vocab.png",
                "caption": "(a)CoLA: Token cov. vs. vocab. frac.",
                "position": 1288
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-mnli-vocab.png",
                "caption": "(b)MNLI: Token cov. vs. vocab. frac.",
                "position": 1293
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-sst2-vocab.png",
                "caption": "(c)SST-2: Token cov. vs. vocab. frac.",
                "position": 1298
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-cola-success.png",
                "caption": "(d)CoLA: Train cov. vs. Matthews",
                "position": 1304
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-mnli-success.png",
                "caption": "(e)MNLI: Train cov. vs. Acc",
                "position": 1309
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-sst2-success.png",
                "caption": "(f)SST-2: Train cov. vs. Acc",
                "position": 1314
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-NER-vocab.png",
                "caption": "(a)Token coverage as a function of retained morpheme vocabulary on train and test. Coverage saturates around 88–90% of the full vocabulary, indicating that a compact core yields near‑perfect coverage on both splits.",
                "position": 1337
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-NER-vocab.png",
                "caption": "(a)Token coverage as a function of retained morpheme vocabulary on train and test. Coverage saturates around 88–90% of the full vocabulary, indicating that a compact core yields near‑perfect coverage on both splits.",
                "position": 1340
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-NER-success.png",
                "caption": "(b)NER span‑F1 versus train token coverage. F1 rises rapidly up to 80–85% coverage and then plateaus, showing diminishing returns from rare morphemes beyond this point.",
                "position": 1345
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-POS-vocab.png",
                "caption": "(a)Train token coverage vs. task performance. POS and Morph F1s climb steeply and saturate by 85–88% coverage; LAS remains stable across pruning once coverage is high.",
                "position": 1362
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-POS-vocab.png",
                "caption": "(a)Train token coverage vs. task performance. POS and Morph F1s climb steeply and saturate by 85–88% coverage; LAS remains stable across pruning once coverage is high.",
                "position": 1365
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-POS-success.png",
                "caption": "(b)Token coverage as a function of retained morpheme vocabulary. Test coverage reaches 100% by 2–75% of the vocabulary; train coverage hits 100% around 83–85%",
                "position": 1370
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-cola-explain.png",
                "caption": "(a)CoLA token/morpheme attributions.",
                "position": 1387
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-cola-explain.png",
                "caption": "(a)CoLA token/morpheme attributions.",
                "position": 1390
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-sst2-explain.png",
                "caption": "(b)SST-2: token/morpheme attributions.",
                "position": 1395
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-ner-explain.png",
                "caption": "(a)NER: morpheme-level attributions highlighting dates, apostrophes, and case markers.",
                "position": 1405
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-ner-explain.png",
                "caption": "(a)NER: morpheme-level attributions highlighting dates, apostrophes, and case markers.",
                "position": 1408
            },
            {
                "img": "https://arxiv.org/html/2602.06942/subwords-pos-explain.png",
                "caption": "(b)POS: contributions of derivational/inflectional suffixes to tag decisions.",
                "position": 1413
            }
        ]
    },
    {
        "header": "6WordPiece Tokenization",
        "images": [
            {
                "img": "https://arxiv.org/html/2602.06942/fertility.png",
                "caption": "(a)",
                "position": 1710
            },
            {
                "img": "https://arxiv.org/html/2602.06942/fertility.png",
                "caption": "(a)",
                "position": 1713
            },
            {
                "img": "https://arxiv.org/html/2602.06942/cont-tokens.png",
                "caption": "(b)",
                "position": 1719
            },
            {
                "img": "https://arxiv.org/html/2602.06942/cola-2k.png",
                "caption": "(a)2k vocabulary -Minimal corpus combination. LIME highlights the “kullan ##ma ##bil ##en” span as the dominant driver, but the signal is fragmented across multiple continuation pieces. This diffusion creates mild spillover to nearby tokens and lowers attribution sharpness. Overall, the violation is detectable but less clean due to higher segmentation granularity.",
                "position": 2398
            },
            {
                "img": "https://arxiv.org/html/2602.06942/cola-2k.png",
                "caption": "(a)2k vocabulary -Minimal corpus combination. LIME highlights the “kullan ##ma ##bil ##en” span as the dominant driver, but the signal is fragmented across multiple continuation pieces. This diffusion creates mild spillover to nearby tokens and lowers attribution sharpness. Overall, the violation is detectable but less clean due to higher segmentation granularity.",
                "position": 2401
            },
            {
                "img": "https://arxiv.org/html/2602.06942/cola-32k.png",
                "caption": "(b)32k vocabulary size - minimal corpus combination. The explanation mass is sharply localized on “kullanma ##bilen,” yielding a compact, high-contrast peak with minimal spillover. Reduced fragmentation improves attribution stability and interpretability, making the offending span visually unambiguous. This cleaner focus aligns with the identical split observed across larger vocabularies. 32k-medium, 52k-medium and 52k-alldata produced the same subwords and weights.",
                "position": 2407
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-2k-minimal.png",
                "caption": "(a)Token-weight heatmap using a minimal wordpiece vocab. Saliency clusters around the core negative judgment “memnun etmedi,” with additional activation on the cliché/insufficient-action span (“fazla kli…,” “istenilen… verem…”) and the pacing critique (“ağır ilerleyen”). Some fragmentation appears on subwords like “##eme/##ilen,” but the pattern still foregrounds dissatisfaction. Closing hedge (“edebilir”) receives low weight, keeping the overall attribution negative.",
                "position": 2417
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-2k-minimal.png",
                "caption": "(a)Token-weight heatmap using a minimal wordpiece vocab. Saliency clusters around the core negative judgment “memnun etmedi,” with additional activation on the cliché/insufficient-action span (“fazla kli…,” “istenilen… verem…”) and the pacing critique (“ağır ilerleyen”). Some fragmentation appears on subwords like “##eme/##ilen,” but the pattern still foregrounds dissatisfaction. Closing hedge (“edebilir”) receives low weight, keeping the overall attribution negative.",
                "position": 2420
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-32k-minimal.png",
                "caption": "(b)With a leaner vocabulary, negative evidence is still concentrated but slightly more diffuse across subword splits. The maxima remain on “memnun etmedi,” followed by “verem…/##eyen” and “ağır/ilerleyen.” The cliché cue (“fazla klişe”) is visible though softened by subword segmentation. Sentence scaffolding (e.g., “olarak,” “da”) is minimally weighted, suggesting the model’s attention is driven by evaluative content rather than syntax.",
                "position": 2425
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-32k-medium.png",
                "caption": "(c)Medium-size wordpiece tokenizer yields crisper peaks on semantically pivotal words. “Etmedi” is the single strongest token, paired with elevated weight on “memnun,” “veremeyen,” and “ağır.” The cliché complaint (“fazla klişe”) is distinctly highlighted. Weights over connective and function words stay uniformly light, and the permissive ending (“tercih/edebilir”) remains downweighted, indicating a model focus on the negative appraisal.",
                "position": 2431
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-52k-alldata.png",
                "caption": "(d)Higher-resolution wordpiece coverage cleanly isolates key negatives. “Etmedi” and “memnun” dominate, while “veremeyen,” “ağır,” and the boredom span (“Sıkı ##ldığı”) receive consistent emphasis. The recommendation clause (“pek… edemeyeceğim”) is present but moderate, and the final concessive allowance (“izlemeyi tercih edebilir”) is intentionally subdued, reflecting a strong overall negative stance with a light hedge.",
                "position": 2436
            },
            {
                "img": "https://arxiv.org/html/2602.06942/sst-128k-medium.png",
                "caption": "(e)Byte-level/large-vocab tokenization produces sharp, contiguous highlights on full words. The strongest weights fall on “etmedi,” “memnun,” and “veremeyen,” with sustained support on “ağır ilerleyen” and the cliché marker “fazla klişe.” Discomfort/boredom cues (“Sıkı… kısımlar”) are clearly captured. Tokens tied to curiosity or allowance near the end carry comparatively low weight, preserving the dominant negative interpretation.",
                "position": 2442
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-2k-minimal.png",
                "caption": "(a)2k-Minimal: Entity saliency is fragmented across many subwords: strong reds on DATE pieces (“19 ##4 ##9 ’ da”), high on “Ma ##o” (PERSON), and moderate on GPE core (“Ç ##in … Cumhur ##iyet ##i”). Apostrophes and case clitics get light positives; non-entity context remains near zero.",
                "position": 2521
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-2k-minimal.png",
                "caption": "(a)2k-Minimal: Entity saliency is fragmented across many subwords: strong reds on DATE pieces (“19 ##4 ##9 ’ da”), high on “Ma ##o” (PERSON), and moderate on GPE core (“Ç ##in … Cumhur ##iyet ##i”). Apostrophes and case clitics get light positives; non-entity context remains near zero.",
                "position": 2524
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-32k-minimal.png",
                "caption": "(b)32k-Minimal: Importance concentrates on full entity tokens: strong on “194’ ##9 da” and “1 Ekim 194’ ##9 da” (DATE), sharp on “Ma ##o” (PERSON), and highest within “Çin Halk Cumhuriyeti’ ni” (GPE). Context words are largely neutral; punctuation slightly negative. The tokenization and model weights are same for 32k-Medium and 52k-Alldata.",
                "position": 2530
            },
            {
                "img": "https://arxiv.org/html/2602.06942/ner-128k-medium.png",
                "caption": "(c)Saliency collapses onto intact whole-word entities: “1949” (DATE), “Mao” (PERSON), and “Cumhuriyeti” within the GPE show the strongest weights; clitics and punctuation are minimal, indicating reliance on large, unbroken entity chunks.",
                "position": 2536
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-2k-minimal.png",
                "caption": "(a)2k-Minimal: Attributions diffuse across tokens with peaks on the finite verb chain (kar + ##alı + ##yor + ##dum). Non-verb morphology (Loc, Plur) is visible but weaker, reflecting lower LAS and stronger reliance on overt inflectional cues.",
                "position": 2616
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-2k-minimal.png",
                "caption": "(a)2k-Minimal: Attributions diffuse across tokens with peaks on the finite verb chain (kar + ##alı + ##yor + ##dum). Non-verb morphology (Loc, Plur) is visible but weaker, reflecting lower LAS and stronger reliance on overt inflectional cues.",
                "position": 2619
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-32k-minimal.png",
                "caption": "(b)32k-Minimal: Sharper, more localized saliency: predicate morphemes dominate, with clearer emphasis on object “öyküler” and oblique “çizgisi+nde,” consistent with mid‑vocab LAS gains.",
                "position": 2625
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-32k-medium.png",
                "caption": "(c)32k-Medium: Attributions are sharp and linguistically aligned: highest saliency on the finite predicate chain (“kara + ##lıyordum”), with clear emphasis on the object (“öyküler”) and the oblique (“çizgisi + ##nde”), while possessive/genitive cues (“öykü ##cül ##üğü ##n”) are moderately weighted—matching strong LAS/POS with stable morphology at this vocabulary size.",
                "position": 2631
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-52K-alldata.png",
                "caption": "(d)52k-Alldata: Most balanced map: strong predicate focus alongside higher weights on possessive/genitive and case markers (“öykücülüğün”, “çizgisi+nde”) and plural object (“öyküler”), aligning with peak POS/LAS and stable morphology.",
                "position": 2637
            },
            {
                "img": "https://arxiv.org/html/2602.06942/pos-128k-medium.png",
                "caption": "(e)128k-Medium: High confidence on the predicate (“karalıyordum”) but reduced visibility of non-verb morphology; larger subwords under-segment inflectional cues, consistent with slight Morph accuracy softening at very large vocabularies.",
                "position": 2643
            }
        ]
    },
    {
        "header": "7Optimal Ways of Tokenizing Turkish",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AExplainability Tools",
        "images": []
    },
    {
        "header": "Appendix BComprehensive Morphology Diagnostics by Vocabulary Size",
        "images": []
    }
]