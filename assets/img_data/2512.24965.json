[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/x1.png",
                "caption": "Figure 2:ScreenDrag Automated Data Collection Pipeline.ScreenDrag automated data generation pipeline for continuous trajectory-based GUI interaction data. The pipeline includes three stages:(i) Element Parsing:The software application UI is parsed with UI Automation of Windows SDK in order to retrieve the UI element metadata.(ii) Task Proposal:Given the UI element metadata, an LLM will be prompted to generate a drag instruction, the expected metadata change and the drag code with dense trajectory.(iii) Trajectory Synthesis:The drag code will be executed in the software environment. A rule-based verifier will check the parsed metadata from UI states before and after the drag to ensure that the metadata change satisfies the expectation.",
                "position": 154
            }
        ]
    },
    {
        "header": "3ScreenDrag Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/x2.png",
                "caption": "Figure 3:ScreenDrag Data Distribution.The inner ring indicates the five equally distributed domains. The outer ring demonstrates per-category breakdowns with shares of the full dataset.",
                "position": 224
            },
            {
                "img": "https://arxiv.org/html/2512.24965/x3.png",
                "caption": "Figure 4:Comparison between offline evaluation and online evaluation pipelines of ScreenDrag:(i) Offline evaluationis based on the distance of prediction and ground-truth in independent trunks;(ii) Online evaluationis incremental over sequential trunks, and based on the final outcome.",
                "position": 264
            },
            {
                "img": "https://arxiv.org/html/2512.24965/x4.png",
                "caption": "Figure 5:Overview of ShowUI-π\\pi.Given a task query and visual observations, the model first processes them through the VLM to obtain intermediate hidden states, which are then attended by the action expert. During interaction, the predicted actions update the environment, the next observation is encoded, and a new action chunk is produced—enabling fine-grained, closed-loop cursor control.",
                "position": 267
            },
            {
                "img": "https://arxiv.org/html/2512.24965/x5.png",
                "caption": "Figure 6:Architecture of ShowUI-π\\pi.ShowUI-π\\piuses an LLM with cross-attention to a lightweight action expert to generate unified action chunks that handle both discrete clicks and continuous drag segments.",
                "position": 295
            }
        ]
    },
    {
        "header": "4ShowUI-π\\piModel",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/chart/visualization_assets/powerpoint_trajectory.png",
                "caption": "Table 8:Illustration of ShowUI-π\\pipredicted trajectories across four domains.ShowUI-π\\pigenerates smooth, human-like trajectories that closely follow the instructed paths.",
                "position": 979
            },
            {
                "img": "https://arxiv.org/html/2512.24965/chart/visualization_assets/handwriting_trajectory.png",
                "caption": "",
                "position": 1027
            },
            {
                "img": "https://arxiv.org/html/2512.24965/chart/visualization_assets/premiere_trajectory.png",
                "caption": "",
                "position": 1043
            },
            {
                "img": "https://arxiv.org/html/2512.24965/chart/visualization_assets/captcha_trajectory.png",
                "caption": "",
                "position": 1059
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "Appendix AMore Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/dev.png",
                "caption": "Table 9:Performance breakdown of various models across application categories on ScreenSpot-Pro.",
                "position": 1098
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/creative.png",
                "caption": "",
                "position": 1113
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/cad.png",
                "caption": "",
                "position": 1116
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/scientific.png",
                "caption": "",
                "position": 1119
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/office.png",
                "caption": "",
                "position": 1122
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/os.png",
                "caption": "",
                "position": 1125
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/symbols/dev.png",
                "caption": "Table 11:Performance breakdown of models trained using different data recipe across application categories on ScreenSpot-Pro.",
                "position": 1511
            }
        ]
    },
    {
        "header": "Appendix BSetup",
        "images": []
    },
    {
        "header": "Appendix CDataset Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00000_captcha_drag_and_drop/frame_1_idx_0000.png",
                "caption": "Table 13:Examples of task trajectories from five domains.Three frames from the episode are shown for each task.",
                "position": 1767
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00000_captcha_drag_and_drop/frame_2_idx_0010.png",
                "caption": "",
                "position": 1814
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00000_captcha_drag_and_drop/frame_3_idx_0020.png",
                "caption": "",
                "position": 1818
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00500_captcha_rotate/frame_1_idx_0000.png",
                "caption": "",
                "position": 1830
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00500_captcha_rotate/frame_2_idx_0010.png",
                "caption": "",
                "position": 1834
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_00500_captcha_rotate/frame_3_idx_0020.png",
                "caption": "",
                "position": 1838
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_01000_captcha_slide/frame_1_idx_0000.png",
                "caption": "",
                "position": 1850
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_01000_captcha_slide/frame_2_idx_0010.png",
                "caption": "",
                "position": 1854
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/captcha/episode_01000_captcha_slide/frame_3_idx_0020.png",
                "caption": "",
                "position": 1858
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/episode_01500/frame_1_idx_0000.png",
                "caption": "",
                "position": 1874
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/episode_01500/frame_2_idx_0010.png",
                "caption": "",
                "position": 1878
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/episode_01500/frame_3_idx_0020.png",
                "caption": "",
                "position": 1882
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/file_manager/01_Q1Report_before.png",
                "caption": "",
                "position": 1894
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/file_manager/01_Q1Report_mid.png",
                "caption": "",
                "position": 1898
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/desktop/file_manager/01_Q1Report_after.png",
                "caption": "",
                "position": 1902
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/handwriting/episode_09131_handwriting_helloworld/frame_1_idx_0000.png",
                "caption": "",
                "position": 1918
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/handwriting/episode_09131_handwriting_helloworld/frame_4_idx_0003.png",
                "caption": "",
                "position": 1922
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/handwriting/episode_09131_handwriting_helloworld/frame_8_idx_0007.png",
                "caption": "",
                "position": 1926
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/rotate/rotate_animals_Animals_and_insects_coloring_book_slide_11_Lion_0_20251014014745_before.png",
                "caption": "",
                "position": 1942
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/rotate/rotate_animals_Animals_and_insects_coloring_book_slide_11_Lion_0_20251014014745_mid.png",
                "caption": "",
                "position": 1946
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/rotate/rotate_animals_Animals_and_insects_coloring_book_slide_11_Lion_0_20251014014745_after.png",
                "caption": "",
                "position": 1950
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/diagonal_resize/3D_float_design_slide_1_Title_TextBox_0_20251009222030_before.png",
                "caption": "",
                "position": 1962
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/diagonal_resize/3D_float_design_slide_1_Title_TextBox_0_20251009222030_mid.png",
                "caption": "",
                "position": 1966
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/diagonal_resize/3D_float_design_slide_1_Title_TextBox_0_20251009222030_after.png",
                "caption": "",
                "position": 1970
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/h_resize/hresize_clean_Cityscape_photo_calendar_slide_12_Title_TextBox_0_20250514122259_before.png",
                "caption": "",
                "position": 1982
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/h_resize/hresize_clean_Cityscape_photo_calendar_slide_12_Title_TextBox_0_20250514122259_mid.png",
                "caption": "",
                "position": 1986
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/powerpoint/h_resize/hresize_clean_Cityscape_photo_calendar_slide_12_Title_TextBox_0_20250514122259_after.png",
                "caption": "",
                "position": 1990
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/premiere/episode_22071/frame_1_idx_0000.png",
                "caption": "",
                "position": 2006
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/premiere/episode_22071/frame_2_idx_0010.png",
                "caption": "",
                "position": 2010
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/data_observations/premiere/episode_22071/frame_3_idx_0020.png",
                "caption": "",
                "position": 2014
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/close-loop/closed_loop_mapping_powerpoint_step_prev.png",
                "caption": "(a) The model predicts a coordinate close to the dense trajectory points.",
                "position": 2027
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/close-loop/closed_loop_mapping_powerpoint_step_prev.png",
                "caption": "(a) The model predicts a coordinate close to the dense trajectory points.",
                "position": 2030
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/close-loop/closed_loop_mapping_powerpoint_step_curr.png",
                "caption": "(b) The prediction is mapped to its closest trajectory point.",
                "position": 2035
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/close-loop/closed_loop_mapping_powerpoint_step_prefix.png",
                "caption": "(c) The model receives the next observation at the mapped trajectory point.",
                "position": 2040
            }
        ]
    },
    {
        "header": "Appendix DFailure Cases of Baseline Models",
        "images": [
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case0_cannot_rotate.png",
                "caption": "Figure 8:Know-How but does not have the tool.The baseline formulates a correct plan to rotate the textbox by dragging the handle above the textbox ”AGENDA” with an arc trajectory, however, the baseline is not equipped with such a drag tool, it is only trained and equipped with linear drags, thus failing the task.",
                "position": 2058
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case1_intent.png",
                "caption": "Figure 9:Gap between discrete tool use and continuous drag.The baseline formulates a correct plan to drag the file icon to the folder and successfully locates the file icon’s initial position, but the execution fails mid-trajectory, leaving the icon stranded far from the target.",
                "position": 2068
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case2_safety.png",
                "caption": "Figure 10:Safety over action.The model initiates a drag on the captcha slider but immediately halts and issues a refusal, misinterpreting the standard UI interaction as a safety violation.",
                "position": 2078
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case3_semantic.png",
                "caption": "Figure 11:Semantic misread.The model misinterprets the visual instruction, moving the cursor to a non-target corner instead of the canvas, indicating a failure in task understanding.",
                "position": 2086
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case4_primitive.png",
                "caption": "Figure 12:Wrong primitive choice.Instead of a continuous drag action required for the slider, the baseline issues a series of discrete clicks, failing to execute the task.",
                "position": 2095
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case5_precision.png",
                "caption": "Figure 13:Geometric precision.The predicted trajectory follows the correct direction but significantly overshoots the target, highlighting a lack of fine-grained action control.",
                "position": 2105
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case6_dialogue.png",
                "caption": "Figure 14:Dialogue hijacks control.The model pauses execution to ask for unnecessary clarification, halting progress in an embodied setting where autonomous action is expected.",
                "position": 2114
            },
            {
                "img": "https://arxiv.org/html/2512.24965/appendix/case_study/case7_termination.png",
                "caption": "Figure 15:Early termination.The model terminates the episode immediately with an “Instruction Unclear” error, refusing to attempt the task.",
                "position": 2122
            }
        ]
    },
    {
        "header": "Appendix ELimitations and Future Work",
        "images": []
    }
]