[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04575/extracted/6119149/images/logo.jpg",
                "caption": "",
                "position": 99
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04575/x1.png",
                "caption": "Figure 1:InfiGUIAgentis trained in two stages.Stage 1cultivates fundamental abilities using diverse datasets covering GUI understanding (element recognition and layout comprehension), question answering, instruction grounding, general knowledge, and tool usage.Stage 2introduces native advanced reasoning, employed during both training and inference. This stage follows a cyclical process at each step, consisting ofReflection,Hierarchical Reasoning(strategic and tactical layers),Action, andExpectation. Each step receives the overall task, the history of previous screenshots and reasoning, and the current environment as input.Reflectionassesses the previous action’s outcome against its expectation, whileExpectationpredicts the outcome of the current action for subsequent reflection.",
                "position": 237
            }
        ]
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04575/x2.png",
                "caption": "",
                "position": 445
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x3.png",
                "caption": "",
                "position": 628
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": []
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": [
            {
                "img": "https://arxiv.org/html/2501.04575/x4.png",
                "caption": "Figure 2:Case of GUI Understanding.",
                "position": 1780
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x5.png",
                "caption": "Figure 3:Case of Grounding.",
                "position": 1783
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x6.png",
                "caption": "Figure 4:Case of Question Answering.",
                "position": 1786
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x7.png",
                "caption": "Figure 5:Case of Native Advanced Reasoning. The agent’s goal is to reply to a message",
                "position": 1793
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x8.png",
                "caption": "Figure 6:Case of Native Advanced Reasoning. The agent’s goal is to create a new contact.",
                "position": 1796
            },
            {
                "img": "https://arxiv.org/html/2501.04575/x9.png",
                "caption": "Figure 7:Case of Native Advanced Reasoning. The agent’s goal is to create a new contact.",
                "position": 1799
            }
        ]
    },
    {
        "header": "Appendix ACases",
        "images": []
    }
]