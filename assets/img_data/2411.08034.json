[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/figs/diff_main6.png",
                "caption": "Figure 1:A Unified Framework:We fine-tune a pre-trained Diffusion Model (DM), for visual perception tasks. We take a RGB image, and a conditional image (i.e. next video frame, occlusion mask, etc.), along with the noised image of the ground truth prediction. Our model generates predictions for visual tasks such as depth estimation, optical flow prediction, and amodal segmentation, based on the conditional task embedding. We train a generalist model that can perform all three tasks with exceptional performance.",
                "position": 93
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Generative Pre-Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/figs/loss_vs_macs_model_scaling_PRETRAIN.png",
                "caption": "Figure 2:Scaling at Model Size:For generative pre-training of DiT models, we observe clear power law scaling behavior as we increase the model size.",
                "position": 148
            }
        ]
    },
    {
        "header": "4Fine-Tuning for Perceptual tasks",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/figs/loss_vs_macs_model_scaling.png",
                "caption": "Figure 3:Effect of Model Size:We fine-tune a1-a6 models on the Hypersim dataset for 30K iterations with an exponential decay learning rate schedule from3‚Å¢e3ùëí3e3 italic_e-5555to3‚Å¢e3ùëí3e3 italic_e-7777. We observe a strong correlation between the fine-tuning loss scaling law and validation metric scaling laws.",
                "position": 279
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/depth_abs_vs_macs_model_scaling_v2.png",
                "caption": "",
                "position": 288
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/depth_delta1_vs_macs_model_scaling_v2.png",
                "caption": "",
                "position": 293
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/depth_a4_abs_vs_macs_model_scaling_v2.png",
                "caption": "Figure 4:Effect of Scaling Model Pre-training Compute on Depth Estimation:(a) Depth Absolute Relative Error vs. MACs. (b) Depth Delta1 Error vs. MACs. We pre-train four a4 models with 60K, 80K, 100K, and 120K steps. These models are then fine-tuned for 30K steps on the Hypersim depth estimation dataset. We observe a clear power law as we increase the DiT pre-training compute across depth estimation validation metrics.",
                "position": 306
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/depth_a4_delta1_vs_macs_model_scaling_v2.png",
                "caption": "",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/graphs/absrel_dense_xl_resolution_scaling.png",
                "caption": "Figure 5:Effect of Image Resolution.We fine-tune DiT-XL and DiT-MoE L/2 models with resolutions of256√ó256256256256\\times 256256 √ó 256and512√ó512512512512\\times 512512 √ó 512. We observe a power law when increasing image resolution during training. By scaling the number of tokens per image by 4√ó\\times√ó, we achieve strong performance on Depth Absolute Error, displaying the effect of increasing total dataset tokens for dense visual perception tasks such as depth estimation.",
                "position": 328
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/graphs/absrel_moe_l2_resolution_scaling.png",
                "caption": "",
                "position": 337
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/upcycling_delta1_vs_macs_v2.png",
                "caption": "Figure 6:Effect of Upcycling.We upcycle a2, a3, and a4 models fine-tuned for depth estimation with a varying number of total/active model experts. We continue fine-tuning each upcycled model for 15K iterations on the Hypersim depth estimation dataset. We observe a clear scaling law in the validation metrics as we increase fine-tuning compute with upcycling. The upcycled models can also achieve equivalent or superior performance to our dense a5 and a6 checkpoints, each of which utilize more compute during pre-training and fine-tuning. Increasing the total model experts and total active experts can also improve the downstream performance.",
                "position": 350
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/upcycling_abs_vs_macs_v2.png",
                "caption": "",
                "position": 359
            }
        ]
    },
    {
        "header": "5Scaling Test-Time Compute",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/figs/diff_main7.png",
                "caption": "Figure 7:Inference Scaling:Diffusion models by design allow efficient scaling of test-time compute. First, we can simply increase the number of denoising steps to increase the compute spent at inference. Since we are estimating deterministic outputs, we can then initialize multiple noise latents and ensemble the predictions to get a better estimation. Finally, we can also reallocate our test-time compute budget for low and high frequency denoising by modifying the noise variance schedule.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/v5_graphs/v5d_inference_scaling_num_steps_delta1.png",
                "caption": "Figure 8:Effect of Number of Sampling Steps.(a) Delta1 Error vs. Number of Steps. (b) Absolute Relative Error vs. Number of Steps. For each model, we sample forT‚àà[1,2,5,10,20,50,100]ùëá125102050100T\\in\\left[1,2,5,10,20,50,100\\right]italic_T ‚àà [ 1 , 2 , 5 , 10 , 20 , 50 , 100 ]steps with the DDIM sampler. We show a clear power law scaling behavior in (a) and (b), displaying the effectiveness of scaling test-time compute by increasing the number of diffusion sampling steps.",
                "position": 384
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/v5_graphs/v5d_inference_scaling_num_steps_absrel.png",
                "caption": "",
                "position": 393
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/v5_graphs/v5d_inference_scaling_num_samples_delta1.png",
                "caption": "Figure 9:Effect of Test Time Ensembling.(a) Delta1 Error vs. Number of Forward Passes. (b) Absolute Relative Error vs. Number of Forward Passes. Ensembling multiple predictions from distinct noise initializations displays power law scaling behavior. We apply test-time ensembling values ofN‚àà[1,2,5,10,15,20]ùëÅ125101520N\\in\\left[1,2,5,10,15,20\\right]italic_N ‚àà [ 1 , 2 , 5 , 10 , 15 , 20 ].",
                "position": 409
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/v5_graphs/v5d_inference_scaling_num_samples_absrel.png",
                "caption": "",
                "position": 418
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/fig10_absrel_v2.png",
                "caption": "Figure 10:Effect of Noise Variance (Beta) Schedule.We fine-tune a4 models with three different beta schedules: linear, scaled linear, cosine. Reallocating compute with the cosine schedule to spend more time denoising at earlier timesteps significantly improved Delta1 and Absolute Relative Error rates.",
                "position": 431
            },
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/arxiv_scaling_pngs/fig10_delta1_v2.png",
                "caption": "",
                "position": 440
            }
        ]
    },
    {
        "header": "6Putting It All Together",
        "images": [
            {
                "img": "https://arxiv.org/html/2411.08034/extracted/5996753/figs/high_dpi_figure_6x6_labeled_final_.png",
                "caption": "Figure 11:Depth Estimation, Optical Flow Estimation, and Amodal Segmentation Examples:Each row showcases results from our models for different tasks. (a) Depth estimation, with relative scale and shift. (b) Optical flow, with scale and shift. (c) Amodal segmentation, where the model sees an RGB image and segmentation of the occluded object; the task is to predict the amodal image.",
                "position": 748
            }
        ]
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "8Acknowledgments",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]