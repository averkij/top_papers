[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/misraj_logo_1.png",
                "caption": "",
                "position": 150
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/plot_chrf_score_1.png",
                "caption": "ChrF++ scores",
                "position": 162
            },
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/plot_chrf_score_1.png",
                "caption": "ChrF++ scores",
                "position": 165
            },
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/plot_comet_score_1.png",
                "caption": "COMET scores",
                "position": 170
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Data",
        "images": []
    },
    {
        "header": "4Tarjama-25: Bidirectional Arabic-English Translation Benchmark",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/tarjama25_domains.png",
                "caption": "Рис. 2:Domain Coverage in Tarjama-25 Benchmark",
                "position": 371
            }
        ]
    },
    {
        "header": "5Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/pretraining_data_format.png",
                "caption": "Рис. 3:Illustration of the two data formats used in Mutarjim: (Left) pre-training stream data format; (Right) fine-tuning data sample.",
                "position": 418
            },
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/pretraining_data_format.png",
                "caption": "",
                "position": 421
            },
            {
                "img": "https://arxiv.org/html/2505.17894/extracted/6471717/figures/finetune_data_format.png",
                "caption": "",
                "position": 425
            }
        ]
    },
    {
        "header": "6Experiment and Results",
        "images": []
    },
    {
        "header": "7Evaluation",
        "images": []
    },
    {
        "header": "8Conclusion",
        "images": []
    },
    {
        "header": "Список литературы",
        "images": []
    },
    {
        "header": "Приложение AEvaluation details",
        "images": []
    },
    {
        "header": "Приложение BTraning Details",
        "images": []
    },
    {
        "header": "Приложение CMutarjim Translation Examples",
        "images": [
            {
                "img": "https://arxiv.org/html/2505.17894/x1.png",
                "caption": "Таблица 8:Examples of English-to-Arabic Mutarjim Translation.",
                "position": 1762
            },
            {
                "img": "https://arxiv.org/html/2505.17894/x2.png",
                "caption": "Таблица 9:Examples of Arabic-to-English Mutarjim Translation.",
                "position": 1770
            },
            {
                "img": "https://arxiv.org/html/2505.17894/x3.png",
                "caption": "Таблица 10:Prompts used for each model during the evaluation process. Models like Mutarjim and NLLB are translation-specific systems that don’t require prompting, while LLMs require structured prompts with varying degrees of specificity.",
                "position": 1786
            }
        ]
    },
    {
        "header": "Приложение DEvaluation Models Prompts",
        "images": []
    }
]