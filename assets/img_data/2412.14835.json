[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Preliminary",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.14835/x1.png",
                "caption": "Figure 1:The statistics of our hybrid-modal retrieval corpus.",
                "position": 242
            }
        ]
    },
    {
        "header": "4Methodology",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.14835/x2.png",
                "caption": "Figure 2:The pipeline of our unified multimodal retrieval module.",
                "position": 313
            },
            {
                "img": "https://arxiv.org/html/2412.14835/x3.png",
                "caption": "Figure 3:The overall framework of AR-MCTS: The retrieval module actively retrieves key insights at each step of the MCTS process. Then, the states of the MCTS is enhanced with different insights to expand the possible action space of the MLLM. Notably, one state of each step, such as stateS1,3superscriptùëÜ13S^{1,3}italic_S start_POSTSUPERSCRIPT 1 , 3 end_POSTSUPERSCRIPTandS2,3superscriptùëÜ23S^{2,3}italic_S start_POSTSUPERSCRIPT 2 , 3 end_POSTSUPERSCRIPTin this figure, no insights are provided, and the state is a direct output of the MLLM.",
                "position": 333
            },
            {
                "img": "https://arxiv.org/html/2412.14835/x4.png",
                "caption": "Table 1:Mathematical reasoning assessment on different MLLMs usingMathVistaandWe-MathtestminiSets. In the case ofMathVista, we picked 6 categories from the original 12: ALL (overall accuracy), GPS (geometry problem solving), MWP (math word problems), ALG (algebraic reasoning), GEO (geometry reasoning), and STA (statistical reasoning). ForWe-Math, we selected 8 categories: S1 (one-step problems), S2 (two-step problems), S3 (three-step problems), AVG (strict overall average scores), IK (insufficient knowledge), IG (inadequate generalization), CM (complete mastery), and RM (rote memorization). The top scores for each model are highlighted inbold.",
                "position": 433
            }
        ]
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.14835/x4.png",
                "caption": "Figure 4:Scaling analysis on inference samplings.Random Choicedenotes the average result of randomly sampling from 1 to 32.",
                "position": 1067
            },
            {
                "img": "https://arxiv.org/html/2412.14835/x5.png",
                "caption": "Figure 5:The visualization of the cadidate reasoning paths.",
                "position": 1086
            },
            {
                "img": "https://arxiv.org/html/2412.14835/x6.png",
                "caption": "Figure 6:The accuracy comparison of solution sampling.",
                "position": 1089
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "AMore Details about AR-MCTS",
        "images": []
    },
    {
        "header": "BMore Details about Experimental Setup",
        "images": [
            {
                "img": "https://arxiv.org/html/2412.14835/x7.png",
                "caption": "Figure 7:The composition analysis on retrieval corpus ofWe-MathandMathVista.",
                "position": 3238
            }
        ]
    },
    {
        "header": "CMore Details about Experimental Results",
        "images": []
    },
    {
        "header": "DLimitations and Future Work",
        "images": []
    }
]