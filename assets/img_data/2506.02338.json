[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x1.png",
                "caption": "Figure 1:Comparison of RLVR performance between the base model (Qwen-2.5-0.5B) and the model trained on the Long CoT Collection (Qwen-2.5-0.5B-LC) on MATH500 and GPQA.",
                "position": 190
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x2.png",
                "caption": "Figure 2:Overview of our data construction pipeline. First, we collect an 1K seed dataset of reasoning flow and thought token length (1). Using it as a demonstration, we annotate long CoT rationales on new questions and scale it up to 100K data points (2-4).",
                "position": 247
            }
        ]
    },
    {
        "header": "3The Long CoT Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x3.png",
                "caption": "Figure 3:The top 15 most common root verbs and\ntheir top 3 direct noun objects in the collected\nreasoning flow.",
                "position": 304
            }
        ]
    },
    {
        "header": "4Dataset Analyses",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x4.png",
                "caption": "Figure 4:Head-to-head comparison of the generated CoT quality with the R1 output(Ye et¬†al.,2025).",
                "position": 341
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x5.png",
                "caption": "Figure 5:Comparison of the number of reasoning tokens used by each model.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x6.png",
                "caption": "Figure 6:Results of best-of-nùëõnitalic_nexperiments with Llama-3.1-8B-Instruct and Qwen-2.5-7B-Instruct.",
                "position": 364
            }
        ]
    },
    {
        "header": "5Effect of the Long CoT Collection",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x7.png",
                "caption": "Figure 7:The Pearson correlation (R2superscriptùëÖ2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT) between generated tokens and o1-mini thought tokens. We leverage 100% budget (left), 50% budget (mid), and 25% budget (right) to generate the collections of long CoT rationales.",
                "position": 535
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x8.png",
                "caption": "Figure 8:The token count distribution for each collection generated by adjusting the thought budget.",
                "position": 538
            }
        ]
    },
    {
        "header": "6Thought Budget Control",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "Limitations and Future Work",
        "images": []
    },
    {
        "header": "Acknowledgements",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ADetails of the Data Construction",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x9.png",
                "caption": "Figure 9:Distribution of the number of reasoning outlines (top), thought length (middle), and the difference between the length of the reference models‚Äô rationale and the generated rationale (bottom).",
                "position": 1223
            }
        ]
    },
    {
        "header": "Appendix BImplementation Details",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x10.png",
                "caption": "Figure 10:Length, answer, and format rewards across three models in LIMO dataset(Ye et¬†al.,2025).",
                "position": 1433
            }
        ]
    },
    {
        "header": "Appendix CImpact on the Verifiable Rewards",
        "images": []
    },
    {
        "header": "Appendix DDetails on Analyses",
        "images": []
    },
    {
        "header": "Appendix EExamples of the Long CoT Collection",
        "images": []
    },
    {
        "header": "Appendix FPrompts",
        "images": []
    },
    {
        "header": "Appendix GUsage of AI Assistant",
        "images": [
            {
                "img": "https://arxiv.org/html/2506.02338/x11.png",
                "caption": "Figure 11:Results of Llama-3.1-8B-LC on MMLU-Pro broken down by domain.",
                "position": 1562
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x12.png",
                "caption": "Figure 12:Results of Qwen-2.5-7B-LC on MMLU-Pro broken down by domain.",
                "position": 1565
            },
            {
                "img": "https://arxiv.org/html/2506.02338/extracted/6506176/figure/length_reward.png",
                "caption": "Figure 13:Heatmap of the thought budget function, defined as1‚àí|min‚Å°(x,y)max‚Å°(x,y)‚àí1|1ùë•ùë¶ùë•ùë¶11-\\left|\\frac{\\min(x,y)}{\\max(x,y)}-1\\right|1 - | divide start_ARG roman_min ( italic_x , italic_y ) end_ARG start_ARG roman_max ( italic_x , italic_y ) end_ARG - 1 |, wherexùë•xitalic_xandyùë¶yitalic_yare positive integers. Brighter regions indicate higher rewards, which occur whenxùë•xitalic_xandyùë¶yitalic_yare closer in value.",
                "position": 1568
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x13.png",
                "caption": "Figure 14:An example instance from the Long CoT Collection.",
                "position": 1571
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x14.png",
                "caption": "Figure 15:An example response from Llama-3.1-8B-LC (Ours), which trained on the Long CoT Collection.",
                "position": 1575
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x15.png",
                "caption": "Figure 16:Prompt used for stepwise long CoT generation.",
                "position": 1578
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x16.png",
                "caption": "Figure 17:Prompt used for filtering the incorrect rationales.",
                "position": 1581
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x17.png",
                "caption": "Figure 18:Prompt used for qualitative analysis on Reasoning Flow. We assign the position of A/B randomly.",
                "position": 1585
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x18.png",
                "caption": "Figure 19:Prompt used for qualitative analysis on Reasoning Strategy. We assign the position of A/B randomly.",
                "position": 1588
            },
            {
                "img": "https://arxiv.org/html/2506.02338/x19.png",
                "caption": "Figure 20:Prompt used for qualitative analysis on Correctness. We assign the position of A/B randomly.",
                "position": 1591
            }
        ]
    },
    {
        "header": "Appendix HArtifact Licenses",
        "images": []
    }
]