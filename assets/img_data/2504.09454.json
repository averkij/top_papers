[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/motivation_v1_2.png",
                "caption": "Figure 1:Illustration of our motivation. Compression here refers to the VAE + Patchify operation. (a) Existing fixed-compression diffusion transformer (DiT)ignore information density. Fixed large compression leads to limited local realism due to the limited representation of a few tokens preventing accurate recovery of rich information, whereas fixed small compression leads to limited global consistency and high computational complexity due to the burden of global modeling across patched latents. Samples in (a) are obtained from[38]. (b) Our Dynamic Diffusion Transformer (D2iT) adopts adynamic compression strategyand adds multi-grained noise based on information density, achieving unified global consistency and local realism.",
                "position": 74
            }
        ]
    },
    {
        "header": "2Related Works",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/camera_ready/framework_camera_ready.png",
                "caption": "Figure 2:The overview of our proposed two-stage framework.\n(1) Stage 1: DVAE dynamically assigns different grained codes to each image region through the Herarchical Encoder and Dynamic Grained Coding (DGC) module.\n(2) Stage 2: D2iT consists Dynamic Grain Transformer and Dynamic Content Transformer, which respectively model the spatial granularity information and content information. We present the network with two granularities. The grain map uses ‘1’ to denote coarse-grained regions and ‘2’ for fine-grained regions.",
                "position": 121
            }
        ]
    },
    {
        "header": "3Method",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/FFHQ_vision.png",
                "caption": "Figure 3:Qualitative results of our unconditional generation on FFHQ. In the grain map, red blocks represent fine-grained regions, while blue blocks indicate coarse-grained regions.",
                "position": 342
            },
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/ImageNet_vision.png",
                "caption": "Figure 4:Qualitative results of D2iT-XL on ImageNet. The grain maps are generated by the Dynamic Grain Transformer based on class labels, and the images are generated by the Dynamic Content Transformer based on class labels and grain maps.",
                "position": 416
            },
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/ablation_first_stage_2.png",
                "caption": "Figure 5:The curves of different grain ratios of reconstruction quality (rFID) to generation quality (FID) on FFHQ.",
                "position": 692
            },
            {
                "img": "https://arxiv.org/html/2504.09454/extracted/6357231/images_v2/FID_imageNet4.png",
                "caption": "Figure 6:Training convergence comparison of DiT and our D2iT with different parameters on ImageNet. FID-50K is evaluated.",
                "position": 701
            }
        ]
    },
    {
        "header": "5Conclusion & Future Direction",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]