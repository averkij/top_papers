[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18821/x1.png",
                "caption": "Figure 1:Performance gains of deep search agents trained via Search Self-play (SSP) across various agentic benchmarks. Our SSP method uniformly surpasses multiple strong open-source baselines without any agentic data annotation and additional supervision.",
                "position": 136
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18821/x2.png",
                "caption": "Figure 2:Examples of Search Self-play with a given ground-truth“Dr. Will Boyd”. Provided with the ground-truth, theproposeriteratively uses search tools to excavate implicit factual evidence, then generates a challenging search question. Then the solver leverages all search results from the proposer’s trajectory as the RAG materials to predict the answer without searching, to validate the question’s correctness.\nOnce verified, the solver follows the ordinary deep search pipeline to explore the solution via multi-turn agentic rollout.",
                "position": 187
            }
        ]
    },
    {
        "header": "3Methodology",
        "images": []
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18821/figures/critic_score_plot.png",
                "caption": "(a)In-Game Training Reward",
                "position": 713
            },
            {
                "img": "https://arxiv.org/html/2510.18821/figures/critic_score_plot.png",
                "caption": "(a)In-Game Training Reward",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2510.18821/figures/nq_reward_plot.png",
                "caption": "(b)Evaluation Score on NQ",
                "position": 721
            },
            {
                "img": "https://arxiv.org/html/2510.18821/figures/2wiki_reward_plot.png",
                "caption": "(c)Evaluation Score on 2Wiki",
                "position": 726
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AImplementation Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Experimental Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.18821/x3.png",
                "caption": "(a)Search Tool Usage",
                "position": 2181
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x3.png",
                "caption": "(a)Search Tool Usage",
                "position": 2184
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x4.png",
                "caption": "(b)Trajectory Length Statistics",
                "position": 2189
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x5.png",
                "caption": "(c)Performance on GeneralQA Benchmarks",
                "position": 2195
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x6.png",
                "caption": "(d)Performance on Multi-HopQA Benchmarks",
                "position": 2200
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x7.png",
                "caption": "(a)In-Game Reward Dynamics",
                "position": 2230
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x7.png",
                "caption": "(a)In-Game Reward Dynamics",
                "position": 2233
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x8.png",
                "caption": "(b)Proposer Policy Entropy",
                "position": 2238
            },
            {
                "img": "https://arxiv.org/html/2510.18821/x9.png",
                "caption": "(c)Valid Question Rate",
                "position": 2243
            }
        ]
    },
    {
        "header": "Appendix CSelf-play Examples",
        "images": []
    },
    {
        "header": "Appendix DPrompts",
        "images": []
    },
    {
        "header": "Appendix EHacking Question Cases",
        "images": []
    }
]