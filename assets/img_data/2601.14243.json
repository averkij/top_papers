[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14243/figures/teaser_3.png",
                "caption": "Figure 1:Overview of RL training different between JetRL and other methods.JetRL proposes unified precision flow for FP8 RL training accommodate both performance and throughput .",
                "position": 115
            },
            {
                "img": "https://arxiv.org/html/2601.14243/x1.png",
                "caption": "Figure 2:Rollout Generation dominates the RL training latency.When the rollout length is larger than 8k, rollout will take>75%>75\\%of the total latency, making it the primary bottleneck.",
                "position": 118
            },
            {
                "img": "https://arxiv.org/html/2601.14243/x2.png",
                "caption": "Figure 3:Naive BF16 Train + FP8 Rollout fails when rollout context length increases.We observe that although the BF16-Train-FP8-Rollout method might exhibit similar performance compared with BF16 training, its performance quickly degrades as we extend the rollout length to more than 8k. We use the Qwen3-8B-Base model for this experiment, and evaluate and train on MATH.",
                "position": 121
            }
        ]
    },
    {
        "header": "2Background",
        "images": []
    },
    {
        "header": "3Motivation",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14243/x3.png",
                "caption": "Figure 4:We conduct training using Qwen3-8B (reasoning) and Qwen3-8B-Base on MATH. When the model is trained on a task that is easy for itself, BF16-Train-FP8-Rollout is less likely to degrade. When the task is hard for the model we trained on, degradation is likely to happen.",
                "position": 344
            }
        ]
    },
    {
        "header": "4Jet-RL: Enabling on-policy FP8 RL Training",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.14243/x4.png",
                "caption": "Figure 5:Overall FP8 precision flow of Jet-RL.\nThe inference graph is a subgraph of the training graph.",
                "position": 373
            },
            {
                "img": "https://arxiv.org/html/2601.14243/x5.png",
                "caption": "Figure 6:Our quantization scheme for a linear layer. The FProp GEMM and the WGrad GEMM uses an(1×128)×(128×128)(1\\times 128)\\times(128\\times 128)FP8 Matmul kernel, while the DGrad GEMM uses an(1×128)×(128×1)(1\\times 128)\\times(128\\times 1)FP8 matmul kernel.",
                "position": 378
            }
        ]
    },
    {
        "header": "5Evaluation",
        "images": []
    },
    {
        "header": "6Related Works",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    }
]