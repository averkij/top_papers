[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21802/x1.png",
                "caption": "Figure 1:Performance comparison for different numbers of denoising steps optimized. The performance improvement of DanceGRPO relies on more steps optimized. MixGRPO achieves optimal performance while requiring only 4 steps.",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2507.21802/x2.png",
                "caption": "Figure 2:Visualization of t-SNE(Van der Maaten & Hinton,2008)for images sampled with different strategies. Employing SDE sampling in the early stages of the denoising process results in a more discrete data distribution.",
                "position": 147
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21802/x3.png",
                "caption": "Figure 3:Qualitative comparison. MixGRPO achieve superior performance in semantics, aesthetics and text-image alignment.",
                "position": 396
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21802/x4.png",
                "caption": "Figure 4:Qualitative comparison with different training-time sampling steps. The performance of MixGRPO does not significantly decrease with the reduction in overhead.∗The Frozen strategy means that optimization is only employed at the initial denoising steps.",
                "position": 548
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AHybrid Inference for Solving Reward Hacking",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21802/x5.png",
                "caption": "Figure 5:Qualitative comparison with different hybrid inference percentages",
                "position": 1646
            }
        ]
    },
    {
        "header": "Appendix BDPM-Solver++ for Recitified Flow",
        "images": []
    },
    {
        "header": "Appendix CMixGRPO-Flash Algorithm",
        "images": [
            {
                "img": "https://arxiv.org/html/2507.21802/x6.png",
                "caption": "Figure 6:Comparison of the visualization results of FLUX, DanceGRPO, and MixGRPO under HPS-v2.1 as the reward model.",
                "position": 1865
            },
            {
                "img": "https://arxiv.org/html/2507.21802/x7.png",
                "caption": "Figure 7:Comparison of the visualization results of FLUX, DanceGRPO, and MixGRPO under HPS-v2.1 and CLIP Score as the reward models.",
                "position": 1868
            }
        ]
    },
    {
        "header": "Appendix DMore visualized results",
        "images": []
    }
]