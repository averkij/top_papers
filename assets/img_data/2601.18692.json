[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18692/x1.png",
                "caption": "Figure 1:OverviewofLingBot-VLA. We scale dual-arm robot data collected in the real world for pre-training.LingBot-VLAcan be easily and efficiently transferred to downstream tasks. Moreover, we conduct a systematic assessment across three robotic embodiments, which demonstrates the clear superiority of our model.",
                "position": 196
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3Pre-training Dataset",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18692/x2.png",
                "caption": "Figure 2:Visualization of pre-training datasetused byLingBot-VLA.",
                "position": 272
            }
        ]
    },
    {
        "header": "4Model Training",
        "images": []
    },
    {
        "header": "5Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2601.18692/x3.png",
                "caption": "(a)",
                "position": 467
            },
            {
                "img": "https://arxiv.org/html/2601.18692/x3.png",
                "caption": "(a)",
                "position": 470
            },
            {
                "img": "https://arxiv.org/html/2601.18692/x4.png",
                "caption": "(b)",
                "position": 476
            },
            {
                "img": "https://arxiv.org/html/2601.18692/x5.png",
                "caption": "(a)Qwen2.5-VL-3B-π\\pimodel",
                "position": 692
            },
            {
                "img": "https://arxiv.org/html/2601.18692/x5.png",
                "caption": "(a)Qwen2.5-VL-3B-π\\pimodel",
                "position": 695
            },
            {
                "img": "https://arxiv.org/html/2601.18692/x6.png",
                "caption": "(b)PaliGemma-3B-pt-224-π\\pimodel",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2601.18692/figures/experiment/pre_training_data_scaling_law/Aggregated_Progress_Rate.png",
                "caption": "(a)Progress Rate (PS)",
                "position": 739
            },
            {
                "img": "https://arxiv.org/html/2601.18692/figures/experiment/pre_training_data_scaling_law/Aggregated_Progress_Rate.png",
                "caption": "(a)Progress Rate (PS)",
                "position": 742
            },
            {
                "img": "https://arxiv.org/html/2601.18692/figures/experiment/pre_training_data_scaling_law/Aggregated_Success_Rate.png",
                "caption": "(b)Success Rate (SR)",
                "position": 748
            },
            {
                "img": "https://arxiv.org/html/2601.18692/figures/experiment/post_training_data_scaling_law/Dual_Axis_Success_Progress.png",
                "caption": "Figure 6:Data efficiencyofLingBot-VLApost-training.",
                "position": 759
            }
        ]
    },
    {
        "header": "6Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix",
        "images": []
    },
    {
        "header": "Appendix AExperiment",
        "images": []
    }
]