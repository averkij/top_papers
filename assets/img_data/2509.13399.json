[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.13399/x1.png",
                "caption": "Figure 1:Overview of our workflow and representative model’s performance.\nFor visualization, we adopt two thresholds: a consistency score of at least9090and a visual quality score of at least66.\nDetails of the automated evaluation pipeline are provided in Figure2and Section3.\nIn multi-turn editing, models exhibit distinct weaknesses:GPT-Image-1struggles with content consistency,Qwen-Image-Editunderperforms in both visual quality and content consistency, andFLUX.1-Kontext-devlags in instruction following, whereasNano Bananashows no single dominant weakness.\nA comprehensive analysis is presented in Sec.5and Tab.2.",
                "position": 137
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.13399/x2.png",
                "caption": "Figure 2:Framework ofEdiVal-Agent. It first decomposes images into semantically meaningful objects, such asmetal yellow signandmetal brown pole, and identifies their contextual relationships, e.g., they are both inforeground. It then generates diverse and proper editing scenarios at scale which are based on the initial analysis, e.g.,Change the color of metal brown pole to gray. Finally, it systematically evaluates editing model outputs from multiple axes, including instruction following, content consistency, and visual quality, specifically by integrating VLMs (Qwen2.5-VL) with open-vocabulary object detectors (Grouding-DINO) to assess instruction following, using semantic-level feature extractors (DINOv3) and pixel-level metrics (L1L_{1}distance) to evaluate content consistency, and leveraging human preference models (HPSv3) to judge visual quality. Our agentic pipeline is agnostic to the expert tools used and can be readily enhanced with more advanced tools in the future.",
                "position": 160
            }
        ]
    },
    {
        "header": "2Related Work",
        "images": []
    },
    {
        "header": "3\\faRobotEdiVal-Agent",
        "images": []
    },
    {
        "header": "4Measuring Human Agreement",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.13399/figures/agreement_analysis.png",
                "caption": "Figure 3:Results of human agreement. Dashed lines represent the average accuracy of each method.EdiVal-Agentachieves 81.3% human agreement accuracy, significantly outperforming the VLM (Qwen2.5-VL) at 75.2% and thresholded CLIP_dir at 65.4%. Note that the CLIP_dir threshold is tuned separately for each task. The inner-annotation baselines indicate the ceiling performance achievable by the tools.",
                "position": 394
            }
        ]
    },
    {
        "header": "5Benchmarking Multi-turn Editing",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.13399/x3.png",
                "caption": "Figure 4:Marginal instruction-following across turns.",
                "position": 656
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x4.png",
                "caption": "Figure 5:Marginal task success rate grouped by task types for GPT-Image-1. It performs relatively well on attribute-centric tasks such ascolor_alterandmaterial_alter, but poorly onposition_changeandcount_change, indicating weaknesses in spatial and numerical reasoning, respectively. We note that other editing models exhibit similar behavior.",
                "position": 690
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_input_raw.jpg",
                "caption": "(a)Base Image",
                "position": 693
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_input_raw.jpg",
                "caption": "(a)Base Image",
                "position": 696
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_gpt4o.png",
                "caption": "(b)GPT-Image-1 (✓)",
                "position": 701
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_nano.png",
                "caption": "(c)Nano Banana (✓)",
                "position": 706
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_gemini.png",
                "caption": "(d)Gemini 2.0 Flash (×)",
                "position": 711
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/count/466_qwen.png",
                "caption": "(e)Qwen-Image-Edit (×)",
                "position": 716
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x5.png",
                "caption": "(a)Base Image",
                "position": 738
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x5.png",
                "caption": "(a)Base Image",
                "position": 741
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x6.png",
                "caption": "(b)GPT-Image-1 (95.19)",
                "position": 746
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x7.png",
                "caption": "(c)Nano Banana (98.05)",
                "position": 751
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x8.png",
                "caption": "(d)Qwen-Image-Edit (94.96)",
                "position": 757
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/consistency/353_raw_background.jpg",
                "caption": "(a)Base Image",
                "position": 771
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/consistency/353_raw_background.jpg",
                "caption": "(a)Base Image",
                "position": 774
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/consistency/353_qwen_background.jpg",
                "caption": "(b)Qwen-Image-Edit",
                "position": 779
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x9.png",
                "caption": "Table 3:Human Preference Scores (HPS), absolute changeΔ\\Delta, and techniques across three refinement turns.dark reddenotes thebestvalue in the column (i.e., the least difference in human preference score);lighter reddenotes thesecond-best.\nFor the HPS columns higher values are better (stronger perceived aesthetics).\nFor theΔ\\Deltacolumns smaller values are better (stronger fidelity to the base image).",
                "position": 800
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x9.png",
                "caption": "Figure 9:Per-image 99.9% luminance quantile across turns. Higher values indicate more extreme bright pixels and greater risk of over-exposure.",
                "position": 945
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw.png",
                "caption": "(a)HPS: 4.25VLM: 85Luminance:0.7",
                "position": 967
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw.png",
                "caption": "(a)HPS: 4.25VLM: 85Luminance:0.7",
                "position": 970
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw_turn_1.png",
                "caption": "(b)HPS: 6.19VLM: 85Luminance: 0.60",
                "position": 977
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw_turn_2.png",
                "caption": "(c)HPS: 4.19VLM: 85Luminance: 0.97",
                "position": 984
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw_turn_3.png",
                "caption": "(d)HPS: 3.34VLM: 60Luminance: 1.00",
                "position": 991
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x10.png",
                "caption": "Table 4:Turn-3 instruction following: Multi-turn vs. single-shot complex prompts, grouped by technique.Boldindicates which setting is higher for each model.",
                "position": 1018
            },
            {
                "img": "https://arxiv.org/html/2509.13399/x10.png",
                "caption": "Figure 11:Marginal task-success rate of thelastinstruction as a function of complex prompt length (levelsC=1,2,3C=1,2,3).",
                "position": 1105
            }
        ]
    },
    {
        "header": "6Limitation and Discussion",
        "images": []
    },
    {
        "header": "7Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAlgorithmic Details",
        "images": []
    },
    {
        "header": "Appendix BAdditional Evaluation Results",
        "images": []
    },
    {
        "header": "Appendix CHuman Agreement",
        "images": []
    },
    {
        "header": "Appendix DVLMs failing to judge visual quality",
        "images": [
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_7_input_raw_turn_3.png",
                "caption": "(a)Visual quality (Qwen2.5-VL: 60, HPSv3: 1.61).",
                "position": 5048
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_7_input_raw_turn_3.png",
                "caption": "(a)Visual quality (Qwen2.5-VL: 60, HPSv3: 1.61).",
                "position": 5051
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/luminance/qwen_268_input_raw_turn_3.png",
                "caption": "(b)Visual quality (Qwen2.5-VL: 60, HPSv3: 3.35).",
                "position": 5056
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/nano/442_input_raw.jpg",
                "caption": "Figure 13:T1: Change the color of pumpkin to purple; T2: Change the background to forest; T3: Remove fabric orange bow.Row-wise quality examples for the first four models: Nano Banana, GPT-Image-1, Gemini 2.0 Flash, and Qwen-Image-Edit. Each row shows generations for Input and three editing turns.",
                "position": 5070
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/nano/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5085
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/nano/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5086
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/nano/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5087
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gpt4o/442_input_raw.png",
                "caption": "",
                "position": 5091
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gpt4o/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5092
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gpt4o/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5093
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gpt4o/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5094
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gemini/442_input_raw.jpg",
                "caption": "",
                "position": 5098
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gemini/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5099
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gemini/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5100
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/gemini/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5101
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/qwen/442_input_raw.png",
                "caption": "",
                "position": 5105
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/qwen/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5106
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/qwen/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5107
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/qwen/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5108
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/stepedit/442_input_raw.png",
                "caption": "Figure 14:T1: Change the color of pumpkin to purple; T2: Change the background to forest; T3: Remove fabric orange bow.Row-wise quality examples for the remaining models: Step1X-Edit, FLUX.1-kontext-dev, OmniGen, AnyEdit, UltraEdit, MagicBrush, and IP2P.",
                "position": 5114
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/stepedit/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5129
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/stepedit/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5130
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/stepedit/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5131
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/flux/442_input_raw.png",
                "caption": "",
                "position": 5135
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/flux/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5136
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/flux/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5137
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/flux/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5138
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/omnigen/442_input_raw.png",
                "caption": "",
                "position": 5142
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/omnigen/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5143
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/omnigen/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5144
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/omnigen/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5145
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/anyedit/442_input_raw.png",
                "caption": "",
                "position": 5149
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/anyedit/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5150
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/anyedit/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5151
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/anyedit/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5152
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ultraedit/442_input_raw.png",
                "caption": "",
                "position": 5156
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ultraedit/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5157
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ultraedit/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5158
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ultraedit/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5159
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/magicbrush/442_input_raw.png",
                "caption": "",
                "position": 5163
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/magicbrush/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5164
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/magicbrush/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5165
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/magicbrush/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5166
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ip2p2/442_input_raw.png",
                "caption": "",
                "position": 5170
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ip2p2/442_input_raw_turn_1.png",
                "caption": "",
                "position": 5171
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ip2p2/442_input_raw_turn_2.png",
                "caption": "",
                "position": 5172
            },
            {
                "img": "https://arxiv.org/html/2509.13399/figures/quality/ip2p2/442_input_raw_turn_3.png",
                "caption": "",
                "position": 5173
            }
        ]
    },
    {
        "header": "Appendix EMore Quality Examples",
        "images": []
    }
]