[
    {
        "header": "Abstract",
        "images": []
    },
    {
        "header": "1Introduction",
        "images": []
    },
    {
        "header": "2POPE",
        "images": []
    },
    {
        "header": "3RePOPE",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/repope_pos_err.png",
                "caption": "Figure 1:RePOPE annotation examplesThe first row displays images that do not contain the object but are incorrectly labeled as “Yes” in POPE. The second row shows images where the object is present but mistakenly labeled as “No.” The object’s presence is highlighted with a red box. The third row illustrates cases of inconsistent labeling in POPE, which we annotate as “ambiguous.” Examples include a “teddy bear” being categorized as a bear, a motorcycle being considered a motorized bicycle, and airport vehicles being classified as cars. Since these categorizations are subjective and MSCOCO labels are inconsistent, we exclude such cases from the benchmark.",
                "position": 140
            },
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/repope_neg_err.png",
                "caption": "",
                "position": 147
            },
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/repope_ambiguous.png",
                "caption": "",
                "position": 150
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/scatter_tp_fp.png",
                "caption": "Figure 2:POPE vs RePOPE:Due to the high error rate on the positive labels, the number of TP is significantly reduced across all models. Regarding FP, we observe different patterns across the three subsets: on the random subset, the number of false positives almost doubles for most of the models, results on popular are relatively stable, and on adversarial we observe a slight reduction of false positives. The ranking according to the F1 score is heavily impacted by the relabeling. The top models (Ovis2-4B/-8B) on the popular and adversarial split for POPE, also achieve the top ranks on random for RePOPE.",
                "position": 232
            },
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/scatter_f1.png",
                "caption": "",
                "position": 245
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix AAppendix: Additional Plots",
        "images": [
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/scatter_tpr_tnr.png",
                "caption": "Figure 3:POPE vs. RePOPE: Precision and RecallThe models’ precision decreases on RePOPE while the true positive rate (TPR) improves. Effects on the true negative rate (TNR) are small but sufficient to change the ranking, and due to the larger amount of label errors in the positive questions, the models’ yes rates decrease on the relabeled dataset.",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2504.15707/extracted/6379763/images/scatter_acc.png",
                "caption": "Figure 4:POPE vs. RePOPE: AccuracyWe observe a similar pattern as for the F1 score. However, note that for RePOPE the number of positive and negative samples is not balanced anymore. Thus, accuracy needs to be interpreted with care.",
                "position": 436
            }
        ]
    },
    {
        "header": "Appendix BAppendix: Full Results POPE",
        "images": []
    },
    {
        "header": "Appendix CAppendix: Full Results RePOPE",
        "images": []
    }
]