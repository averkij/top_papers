[
    {
        "header": "Abstract",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13678/x1.png",
                "caption": "Figure 1:FlashWorldenables fast and high-quality 3D scene generation across diverse scenes.",
                "position": 70
            }
        ]
    },
    {
        "header": "1Introduction",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13678/x2.png",
                "caption": "Figure 2:A brief comparison of different 3D scene generation methods.MV-oriented diffusion methods (i.e., CAT3D(Gao et al.,2024), Bolt3D(Szymanowicz et al.,2025), Wonderland(Liang et al.,2025), and Oursw/MV-Diff) suffer from noisy textures due to multi-view inconsistency.\nMV-oriented distillation further exacerbates this flaw (i.e., Oursw/MV-Dist).\n3D-oriented diffusion methods (i.e., Oursw/3D-Diff) suffer from blurry visual effect.\nOur cross-mode distillation model (i.e., Ours) simultaneously solves these, making the quality of the novel view close to the input view.\nThe time cost per scene, tested on a single GPU, is presented at the bottom of each method.",
                "position": 89
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x3.png",
                "caption": "",
                "position": 99
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x4.png",
                "caption": "",
                "position": 100
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x5.png",
                "caption": "",
                "position": 101
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x6.png",
                "caption": "",
                "position": 116
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x7.png",
                "caption": "",
                "position": 117
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x8.png",
                "caption": "",
                "position": 118
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x9.png",
                "caption": "",
                "position": 119
            }
        ]
    },
    {
        "header": "2Preliminary",
        "images": []
    },
    {
        "header": "3Method",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13678/x10.png",
                "caption": "Figure 3:Method overview.We first pre-train a dual-mode multi-view latent diffusion model using multi-view datasets, and then employ an cross-mode distillation post-training strategy to accelerate generation while enhancing visual quality and inheriting 3D consistency.",
                "position": 216
            }
        ]
    },
    {
        "header": "4Experiments",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13678/x11.png",
                "caption": "Figure 4:Image-to-3D scene generation results of different methods.",
                "position": 315
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x12.png",
                "caption": "",
                "position": 324
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x13.png",
                "caption": "",
                "position": 325
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x14.png",
                "caption": "",
                "position": 339
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x15.png",
                "caption": "",
                "position": 340
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x16.png",
                "caption": "",
                "position": 341
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x17.png",
                "caption": "Figure 5:Text-to-3D scene generation results of different methods.",
                "position": 361
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x18.png",
                "caption": "",
                "position": 432
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x19.png",
                "caption": "",
                "position": 433
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x20.png",
                "caption": "",
                "position": 434
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x21.png",
                "caption": "",
                "position": 449
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x22.png",
                "caption": "",
                "position": 450
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x23.png",
                "caption": "",
                "position": 451
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x24.png",
                "caption": "",
                "position": 452
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x25.png",
                "caption": "Figure 6:3D scene generation results of different methods on WorldScore benchmark.",
                "position": 702
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x26.png",
                "caption": "",
                "position": 710
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x27.png",
                "caption": "",
                "position": 717
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x28.png",
                "caption": "",
                "position": 718
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x29.png",
                "caption": "",
                "position": 725
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x30.png",
                "caption": "",
                "position": 726
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x31.png",
                "caption": "Figure 7:Qualitative ablation studies.Prompts: (Top) “A vintage clock hanging on a brick wall”; (Bottom) “A bright sunflower in a field”.",
                "position": 1146
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x32.png",
                "caption": "",
                "position": 1163
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x33.png",
                "caption": "",
                "position": 1164
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x34.png",
                "caption": "",
                "position": 1165
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x35.png",
                "caption": "",
                "position": 1166
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x36.png",
                "caption": "",
                "position": 1167
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x37.png",
                "caption": "",
                "position": 1170
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x38.png",
                "caption": "",
                "position": 1171
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x39.png",
                "caption": "",
                "position": 1172
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x40.png",
                "caption": "",
                "position": 1173
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x41.png",
                "caption": "",
                "position": 1174
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x42.png",
                "caption": "",
                "position": 1175
            }
        ]
    },
    {
        "header": "5Conclusion",
        "images": []
    },
    {
        "header": "References",
        "images": []
    },
    {
        "header": "Appendix ATraining Details",
        "images": []
    },
    {
        "header": "Appendix BRelated Works",
        "images": []
    },
    {
        "header": "Appendix CLimitations",
        "images": []
    },
    {
        "header": "Appendix DRGBD Rendering Results",
        "images": [
            {
                "img": "https://arxiv.org/html/2510.13678/x43.png",
                "caption": "Figure 8:RGBD rendering results.",
                "position": 2512
            },
            {
                "img": "https://arxiv.org/html/2510.13678/x44.png",
                "caption": "Figure 9:More generation results.All images are rendered with generated 3DGS.",
                "position": 2515
            }
        ]
    },
    {
        "header": "Appendix EMore Results",
        "images": []
    }
]